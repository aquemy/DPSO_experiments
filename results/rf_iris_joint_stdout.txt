SCENARIO:
 {
    "control": {
        "seed": 42
    }, 
    "file_name": "rf_iris_joint", 
    "policy": null, 
    "setup": {
        "algorithm": "RandomForest", 
        "dataset": "iris", 
        "policy": "joint", 
        "runtime": 300
    }, 
    "title": "Random Forest on Iris with Joint policy"
}
Best score: 0.953333333333 (0.06) [J] | Score: 0.953333333333 (0.06) [J]
Best score: 0.953333333333 (0.06) [J] | Score: 0.82 (0.103494497975) [J]
Best score: 0.966666666667 (0.04472135955) [J] | Score: 0.966666666667 (0.04472135955) [J]
Best score: 0.966666666667 (0.04472135955) [J] | Score: 0.946666666667 (0.0581186525805) [J]
Best score: 0.966666666667 (0.04472135955) [J] | Score: 0.94 (0.0466666666667) [J]
Best score: 0.966666666667 (0.04472135955) [J] | Score: 0.953333333333 (0.030550504633) [J]
Best score: 0.966666666667 (0.04472135955) [J] | Score: 0.686666666667 (0.030550504633) [J]
JoblibValueError
___________________________________________________________________________
...........................................................................
/home/aquemy/dev/dp_hyperparameters/extension/main.py in <module>()
     27 
     28     serializer.serialize_results(scenario, policy)
     29 
     30 if __name__ == "__main__":
     31     args = cli.parse_args()
---> 32     main(args)

...........................................................................
/home/aquemy/dev/dp_hyperparameters/extension/main.py in main(args=Namespace(customize=[(['control', 'seed'], '42')...io='./scenarios/rf_iris_joint.yaml', verbosity=0))
     21         test_size=0.4, 
     22         random_state=scenario['control']['seed']
     23     )
     24 
     25     policy = policies.initiate(scenario['setup']['policy'], config)
---> 26     policy.run(X,y)
        policy.run = <bound method Joint.run of <experiment.policies.joint.Joint object>>
        X = array([[5.1, 3.5, 1.4, 0.2],
       [4.9, 3. , 1....2, 3.4, 5.4, 2.3],
       [5.9, 3. , 5.1, 1.8]])
        y = array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,... 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2])
     27 
     28     serializer.serialize_results(scenario, policy)
     29 
     30 if __name__ == "__main__":

...........................................................................
/home/aquemy/dev/dp_hyperparameters/extension/experiment/policies/joint.py in run(self=<experiment.policies.joint.Joint object>, X=array([[5.1, 3.5, 1.4, 0.2],
       [4.9, 3. , 1....2, 3.4, 5.4, 2.3],
       [5.9, 3. , 5.1, 1.8]]), y=array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,... 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]))
     32             algo=tpe.suggest, 
     33             max_evals=None,
     34             max_time=self.config['time'],     
     35             trials=trials,
     36             show_progressbar=False,
---> 37             verbose=0
     38         )
     39 
     40         best_config = self.context['best_config']
     41         super(Joint, self).display_step_results(best_config)

...........................................................................
/home/aquemy/dev/dp_hyperparameters/extension/hyperopt/fmin.py in fmin(fn=<functools.partial object>, space={'algorithm': {'bootstrap': <hyperopt.pyll.base.Apply object>, 'criterion': <hyperopt.pyll.base.Apply object>, 'max_depth': <hyperopt.pyll.base.Apply object>, 'max_features': <hyperopt.pyll.base.Apply object>, 'max_leaf_nodes': <hyperopt.pyll.base.Apply object>, 'min_samples_split': <hyperopt.pyll.base.Apply object>, 'n_estimators': <hyperopt.pyll.base.Apply object>}, 'pipeline': {'features': <hyperopt.pyll.base.Apply object>, 'normalizer': <hyperopt.pyll.base.Apply object>, 'rebalance': <hyperopt.pyll.base.Apply object>}}, algo=<function suggest>, max_evals=9223372036854775807, max_time=300, trials=<hyperopt.base.Trials object>, rstate=<mtrand.RandomState object>, allow_trials_fmin=True, pass_expr_memo_ctrl=None, catch_eval_exceptions=False, verbose=0, return_argmin=True, points_to_evaluate=None, max_queue_len=1, show_progressbar=False)
    406             pass_expr_memo_ctrl=pass_expr_memo_ctrl,
    407             verbose=verbose,
    408             catch_eval_exceptions=catch_eval_exceptions,
    409             return_argmin=return_argmin,
    410             show_progressbar=show_progressbar,
--> 411             max_time=max_time
        max_time = 300
    412         )
    413 
    414     if trials is None:
    415         if points_to_evaluate is None:

...........................................................................
/home/aquemy/dev/dp_hyperparameters/extension/hyperopt/base.py in fmin(self=<hyperopt.base.Trials object>, fn=<functools.partial object>, space={'algorithm': {'bootstrap': <hyperopt.pyll.base.Apply object>, 'criterion': <hyperopt.pyll.base.Apply object>, 'max_depth': <hyperopt.pyll.base.Apply object>, 'max_features': <hyperopt.pyll.base.Apply object>, 'max_leaf_nodes': <hyperopt.pyll.base.Apply object>, 'min_samples_split': <hyperopt.pyll.base.Apply object>, 'n_estimators': <hyperopt.pyll.base.Apply object>}, 'pipeline': {'features': <hyperopt.pyll.base.Apply object>, 'normalizer': <hyperopt.pyll.base.Apply object>, 'rebalance': <hyperopt.pyll.base.Apply object>}}, algo=<function suggest>, max_evals=9223372036854775807, max_time=300, rstate=<mtrand.RandomState object>, verbose=0, pass_expr_memo_ctrl=None, catch_eval_exceptions=False, return_argmin=True, show_progressbar=False)
    636             verbose=verbose,
    637             allow_trials_fmin=False,  # -- prevent recursion
    638             pass_expr_memo_ctrl=pass_expr_memo_ctrl,
    639             catch_eval_exceptions=catch_eval_exceptions,
    640             return_argmin=return_argmin,
--> 641             show_progressbar=show_progressbar)
        show_progressbar = False
    642 
    643 
    644 def trials_from_docs(docs, validate=True, **kwargs):
    645     """Construct a Trials base class instance from a list of trials documents

...........................................................................
/home/aquemy/dev/dp_hyperparameters/extension/hyperopt/fmin.py in fmin(fn=<functools.partial object>, space={'algorithm': {'bootstrap': <hyperopt.pyll.base.Apply object>, 'criterion': <hyperopt.pyll.base.Apply object>, 'max_depth': <hyperopt.pyll.base.Apply object>, 'max_features': <hyperopt.pyll.base.Apply object>, 'max_leaf_nodes': <hyperopt.pyll.base.Apply object>, 'min_samples_split': <hyperopt.pyll.base.Apply object>, 'n_estimators': <hyperopt.pyll.base.Apply object>}, 'pipeline': {'features': <hyperopt.pyll.base.Apply object>, 'normalizer': <hyperopt.pyll.base.Apply object>, 'rebalance': <hyperopt.pyll.base.Apply object>}}, algo=<function suggest>, max_evals=9223372036854775807, max_time=300, trials=<hyperopt.base.Trials object>, rstate=<mtrand.RandomState object>, allow_trials_fmin=False, pass_expr_memo_ctrl=None, catch_eval_exceptions=False, verbose=0, return_argmin=True, points_to_evaluate=None, max_queue_len=1, show_progressbar=False)
    426                     verbose=verbose,
    427                     max_queue_len=max_queue_len,
    428                     show_progressbar=show_progressbar,
    429                     max_time=max_time)
    430     rval.catch_eval_exceptions = catch_eval_exceptions
--> 431     rval.exhaust()
        rval.exhaust = <bound method FMinIter.exhaust of <hyperopt.fmin.FMinIter object>>
    432     if return_argmin:
    433         return trials.argmin
    434     elif len(trials) > 0:
    435         # Only if there are some succesfull trail runs, return the best point in the evaluation space

...........................................................................
/home/aquemy/dev/dp_hyperparameters/extension/hyperopt/fmin.py in exhaust(self=<hyperopt.fmin.FMinIter object>)
    273             raise StopIteration()
    274         return self.trials
    275 
    276     def exhaust(self):
    277         n_done = len(self.trials)
--> 278         self.run(self.max_evals - n_done, block_until_done=self.asynchronous)
        self.run = <bound method FMinIter.run of <hyperopt.fmin.FMinIter object>>
        self.max_evals = 9223372036854775807
        n_done = 0
        self.asynchronous = False
    279         self.trials.refresh()
    280         return self
    281 
    282 

...........................................................................
/home/aquemy/dev/dp_hyperparameters/extension/hyperopt/fmin.py in run(self=<hyperopt.fmin.FMinIter object>, N=9223372036854775807, block_until_done=False)
    232                     if self.asynchronous:
    233                         # -- wait for workers to fill in the trials
    234                         time.sleep(self.poll_interval_secs)
    235                     else:
    236                         # -- loop over trials and do the jobs directly
--> 237                         self.serial_evaluate()
        self.serial_evaluate = <bound method FMinIter.serial_evaluate of <hyperopt.fmin.FMinIter object>>
    238                     try:
    239                         res = [d['result']['loss'] for d in
    240                                          self.trials.trials if
    241                                          d['result']['status'] == 'ok']

...........................................................................
/home/aquemy/dev/dp_hyperparameters/extension/hyperopt/fmin.py in serial_evaluate(self=<hyperopt.fmin.FMinIter object>, N=-1)
    138                 trial['book_time'] = now
    139                 trial['refresh_time'] = now
    140                 spec = base.spec_from_misc(trial['misc'])
    141                 ctrl = base.Ctrl(self.trials, current_trial=trial)
    142                 try:
--> 143                     result = self.domain.evaluate(spec, ctrl)
        result = undefined
        self.domain.evaluate = <bound method Domain.evaluate of <hyperopt.base.Domain object>>
        spec = {'bootstrap': 1, 'criterion': 1, 'features': 1, 'features_PCA_features__n_components': 1, 'max_depth': 3, 'max_features': 2, 'max_leaf_nodes': 2, 'min_samples_split': 2, 'n_estimators': 0, 'normalizer': 1, ...}
        ctrl = <hyperopt.base.Ctrl object>
    144                 except Exception as e:
    145                     logger.info('job exception: %s' % str(e))
    146                     trial['state'] = base.JOB_STATE_ERROR
    147                     trial['misc']['error'] = (str(type(e)), str(e))

...........................................................................
/home/aquemy/dev/dp_hyperparameters/extension/hyperopt/base.py in evaluate(self=<hyperopt.base.Domain object>, config={'bootstrap': 1, 'criterion': 1, 'features': 1, 'features_PCA_features__n_components': 1, 'max_depth': 3, 'max_features': 2, 'max_leaf_nodes': 2, 'min_samples_split': 2, 'n_estimators': 0, 'normalizer': 1, ...}, ctrl=<hyperopt.base.Ctrl object>, attach_attachments=True)
    841             #    or the normal Python part (self.fn)
    842             pyll_rval = pyll.rec_eval(
    843                 self.expr,
    844                 memo=memo,
    845                 print_node_on_error=self.rec_eval_print_node_on_error)
--> 846             rval = self.fn(pyll_rval)
        rval = undefined
        self.fn = <functools.partial object>
        pyll_rval = {'algorithm': {'bootstrap': False, 'criterion': 'entropy', 'max_depth': 4, 'max_features': 3, 'max_leaf_nodes': 5, 'min_samples_split': 5, 'n_estimators': 10}, 'pipeline': {'features': ('features_PCA', {'features__n_components': 2}), 'normalizer': ('normalizer_StandardScaler', {'normalizer__with_mean': True, 'normalizer__with_std': False}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 6})}}
    847 
    848         if isinstance(rval, (float, int, np.number)):
    849             dict_rval = {'loss': float(rval), 'status': STATUS_OK}
    850         else:

...........................................................................
/home/aquemy/dev/dp_hyperparameters/extension/experiment/objective.py in objective_joint(wconfig={'algorithm': {'bootstrap': False, 'criterion': 'entropy', 'max_depth': 4, 'max_features': 3, 'max_leaf_nodes': 5, 'min_samples_split': 5, 'n_estimators': 10}, 'pipeline': {'features': ('features_PCA', {'features__n_components': 2}), 'normalizer': ('normalizer_StandardScaler', {'normalizer__with_mean': True, 'normalizer__with_std': False}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 6})}}, algorithm='RandomForest', X=array([[5.1, 3.5, 1.4, 0.2],
       [4.9, 3. , 1....2, 3.4, 5.4, 2.3],
       [5.9, 3. , 5.1, 1.8]]), y=array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,... 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]), context={'baseline_score': 0.9466666666666667, 'baseline_score_std': 0.04988876515698587, 'best_config': {'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': 1, 'max_features': None, 'max_leaf_nodes': None, 'min_samples_split': 5, 'n_estimators': 75}, 'config_hash': {'algorithm': '94b0d7a654c508cc63643f78fe4f0f07e6f07c1e', 'config': '4403c5a85e951938d3c454e961d3a412780722f6', 'pipeline': '3e47444880d8367fbac2faaba2e52a917274aa58'}, 'duration': 0.8397619724273682, 'iteration': 2, 'loss': 0.03333333333333344, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_PCA', {'features__n_components': 3}), 'normalizer': ('normalizer_MinMaxScaler', {}), 'rebalance': ('rebalance_NoneType', {})}, 'score': 0.9666666666666666, ...}, 'history': [{'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': 2, 'max_features': None, 'max_leaf_nodes': 5, 'min_samples_split': 2, 'n_estimators': 75}, 'config_hash': {'algorithm': '3af5b0cce71c8fe2545246ca24ff5bc3dd516e06', 'config': 'db6ac7e6d348155757e4794bb5f88fe2b4f63d50', 'pipeline': '8d59f4b94cef6be9306ed86a22a9570fa670d567'}, 'duration': 1.149928092956543, 'iteration': 0, 'loss': 0.046666666666666634, 'max_history_score': 0.9533333333333334, 'max_history_score_std': 0.059999999999999984, 'max_history_step': 'joint', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 4, 'features__selectkbest__k': 3}), 'normalizer': ('normalizer_StandardScaler', {'normalizer__with_mean': True, 'normalizer__with_std': True}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 6})}, 'score': 0.9533333333333334, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': 1, 'max_features': 2, 'max_leaf_nodes': 2, 'min_samples_split': 5, 'n_estimators': 100}, 'config_hash': {'algorithm': 'e13eb05fd9a62d2f63bbb1c1deff0cd620d5e6ab', 'config': '4db6fb84d85f52659f780e682ffac5712c3d8a94', 'pipeline': '64c9a1ca9d53ae67244bdd942f4db36a3c05218c'}, 'duration': 1.7678282260894775, 'iteration': 1, 'loss': 0.18000000000000005, 'max_history_score': 0.9533333333333334, 'max_history_score_std': 0.059999999999999984, 'max_history_step': 'joint', 'pipeline': {'features': ('features_NoneType', {}), 'normalizer': ('normalizer_PowerTransformer', {}), 'rebalance': ('rebalance_NearMiss', {'rebalance__n_neighbors': 1})}, 'score': 0.82, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': 1, 'max_features': None, 'max_leaf_nodes': None, 'min_samples_split': 5, 'n_estimators': 75}, 'config_hash': {'algorithm': '94b0d7a654c508cc63643f78fe4f0f07e6f07c1e', 'config': '4403c5a85e951938d3c454e961d3a412780722f6', 'pipeline': '3e47444880d8367fbac2faaba2e52a917274aa58'}, 'duration': 0.8397619724273682, 'iteration': 2, 'loss': 0.03333333333333344, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_PCA', {'features__n_components': 3}), 'normalizer': ('normalizer_MinMaxScaler', {}), 'rebalance': ('rebalance_NoneType', {})}, 'score': 0.9666666666666666, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': None, 'max_features': None, 'max_leaf_nodes': 3, 'min_samples_split': 3, 'n_estimators': 75}, 'config_hash': {'algorithm': 'e8332f0a8902bda03bf70e7978cc5d52affb29d3', 'config': 'a064e2df18ab98d44dabcefbc7bed94913f1d0be', 'pipeline': '7eea819c2a8c103c4b1e9e9c1e224aebba95081f'}, 'duration': 0.8501448631286621, 'iteration': 3, 'loss': 0.053333333333333344, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 2, 'features__selectkbest__k': 4}), 'normalizer': ('normalizer_NoneType', {}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 7})}, 'score': 0.9466666666666667, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'entropy', 'max_depth': 3, 'max_features': 3, 'max_leaf_nodes': None, 'min_samples_split': 5, 'n_estimators': 75}, 'config_hash': {'algorithm': '7a4491035bc6bd737fe9a8cda8a79a02d02d5c74', 'config': '0ddb6f5cab3db4dddd7682966a57205f3e329ad4', 'pipeline': 'a9ae03fe38334f6868cbf84cdd3d629d4bbe3fb0'}, 'duration': 1.1026010513305664, 'iteration': 4, 'loss': 0.05999999999999994, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 2, 'features__selectkbest__k': 1}), 'normalizer': ('normalizer_NoneType', {}), 'rebalance': ('rebalance_NoneType', {})}, 'score': 0.9400000000000001, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'gini', 'max_depth': 3, 'max_features': 1, 'max_leaf_nodes': 5, 'min_samples_split': 2, 'n_estimators': 25}, 'config_hash': {'algorithm': '9826d20b2d6a0f559cf7f16450ce7526f07e8434', 'config': '49f25751bca61cdd461a8cbd2923689b642f98ed', 'pipeline': '19b249664c5bf067de1fed4334a296f947ce774a'}, 'duration': 0.35647010803222656, 'iteration': 5, 'loss': 0.046666666666666634, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_NoneType', {}), 'normalizer': ('normalizer_NoneType', {}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 6})}, 'score': 0.9533333333333334, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'gini', 'max_depth': 2, 'max_features': 1, 'max_leaf_nodes': 2, 'min_samples_split': 2, 'n_estimators': 50}, 'config_hash': {'algorithm': '0a4f6fbb07e0f32c6f675489a0fc82eee05bd8e1', 'config': '5c3a2b6f5e63fb45f10e41e0318b354912ec44f6', 'pipeline': 'dc3b9f176f090005e38b142f11d80e93a7dc5d5e'}, 'duration': 0.7213859558105469, 'iteration': 6, 'loss': 0.31333333333333324, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 1, 'features__selectkbest__k': 4}), 'normalizer': ('normalizer_PowerTransformer', {}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 7})}, 'score': 0.6866666666666668, ...}], 'history_hash': ['db6ac7e6d348155757e4794bb5f88fe2b4f63d50', '4db6fb84d85f52659f780e682ffac5712c3d8a94', '4403c5a85e951938d3c454e961d3a412780722f6', 'a064e2df18ab98d44dabcefbc7bed94913f1d0be', '0ddb6f5cab3db4dddd7682966a57205f3e329ad4', '49f25751bca61cdd461a8cbd2923689b642f98ed', '5c3a2b6f5e63fb45f10e41e0318b354912ec44f6'], 'history_index': {'0ddb6f5cab3db4dddd7682966a57205f3e329ad4': 4, '4403c5a85e951938d3c454e961d3a412780722f6': 2, '49f25751bca61cdd461a8cbd2923689b642f98ed': 5, '4db6fb84d85f52659f780e682ffac5712c3d8a94': 1, '5c3a2b6f5e63fb45f10e41e0318b354912ec44f6': 6, 'a064e2df18ab98d44dabcefbc7bed94913f1d0be': 3, 'db6ac7e6d348155757e4794bb5f88fe2b4f63d50': 0}, 'iteration': 6, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint'}, config={'algorithm': 'RandomForest', 'seed': 42, 'time': 300})
    108 
    109 def objective_algo(algo_config, current_pipeline_config, algorithm, X, y, context, config):
    110     return objective(current_pipeline_config, algo_config, algorithm, X, y, context, config, step='algorithm')
    111 
    112 def objective_joint(wconfig, algorithm, X, y, context, config):
--> 113     return objective(wconfig['pipeline'], wconfig['algorithm'], algorithm, X, y, context, config, step='joint')
        wconfig = {'algorithm': {'bootstrap': False, 'criterion': 'entropy', 'max_depth': 4, 'max_features': 3, 'max_leaf_nodes': 5, 'min_samples_split': 5, 'n_estimators': 10}, 'pipeline': {'features': ('features_PCA', {'features__n_components': 2}), 'normalizer': ('normalizer_StandardScaler', {'normalizer__with_mean': True, 'normalizer__with_std': False}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 6})}}
        algorithm = 'RandomForest'
        X = array([[5.1, 3.5, 1.4, 0.2],
       [4.9, 3. , 1....2, 3.4, 5.4, 2.3],
       [5.9, 3. , 5.1, 1.8]])
        y = array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,... 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2])
        context = {'baseline_score': 0.9466666666666667, 'baseline_score_std': 0.04988876515698587, 'best_config': {'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': 1, 'max_features': None, 'max_leaf_nodes': None, 'min_samples_split': 5, 'n_estimators': 75}, 'config_hash': {'algorithm': '94b0d7a654c508cc63643f78fe4f0f07e6f07c1e', 'config': '4403c5a85e951938d3c454e961d3a412780722f6', 'pipeline': '3e47444880d8367fbac2faaba2e52a917274aa58'}, 'duration': 0.8397619724273682, 'iteration': 2, 'loss': 0.03333333333333344, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_PCA', {'features__n_components': 3}), 'normalizer': ('normalizer_MinMaxScaler', {}), 'rebalance': ('rebalance_NoneType', {})}, 'score': 0.9666666666666666, ...}, 'history': [{'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': 2, 'max_features': None, 'max_leaf_nodes': 5, 'min_samples_split': 2, 'n_estimators': 75}, 'config_hash': {'algorithm': '3af5b0cce71c8fe2545246ca24ff5bc3dd516e06', 'config': 'db6ac7e6d348155757e4794bb5f88fe2b4f63d50', 'pipeline': '8d59f4b94cef6be9306ed86a22a9570fa670d567'}, 'duration': 1.149928092956543, 'iteration': 0, 'loss': 0.046666666666666634, 'max_history_score': 0.9533333333333334, 'max_history_score_std': 0.059999999999999984, 'max_history_step': 'joint', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 4, 'features__selectkbest__k': 3}), 'normalizer': ('normalizer_StandardScaler', {'normalizer__with_mean': True, 'normalizer__with_std': True}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 6})}, 'score': 0.9533333333333334, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': 1, 'max_features': 2, 'max_leaf_nodes': 2, 'min_samples_split': 5, 'n_estimators': 100}, 'config_hash': {'algorithm': 'e13eb05fd9a62d2f63bbb1c1deff0cd620d5e6ab', 'config': '4db6fb84d85f52659f780e682ffac5712c3d8a94', 'pipeline': '64c9a1ca9d53ae67244bdd942f4db36a3c05218c'}, 'duration': 1.7678282260894775, 'iteration': 1, 'loss': 0.18000000000000005, 'max_history_score': 0.9533333333333334, 'max_history_score_std': 0.059999999999999984, 'max_history_step': 'joint', 'pipeline': {'features': ('features_NoneType', {}), 'normalizer': ('normalizer_PowerTransformer', {}), 'rebalance': ('rebalance_NearMiss', {'rebalance__n_neighbors': 1})}, 'score': 0.82, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': 1, 'max_features': None, 'max_leaf_nodes': None, 'min_samples_split': 5, 'n_estimators': 75}, 'config_hash': {'algorithm': '94b0d7a654c508cc63643f78fe4f0f07e6f07c1e', 'config': '4403c5a85e951938d3c454e961d3a412780722f6', 'pipeline': '3e47444880d8367fbac2faaba2e52a917274aa58'}, 'duration': 0.8397619724273682, 'iteration': 2, 'loss': 0.03333333333333344, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_PCA', {'features__n_components': 3}), 'normalizer': ('normalizer_MinMaxScaler', {}), 'rebalance': ('rebalance_NoneType', {})}, 'score': 0.9666666666666666, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': None, 'max_features': None, 'max_leaf_nodes': 3, 'min_samples_split': 3, 'n_estimators': 75}, 'config_hash': {'algorithm': 'e8332f0a8902bda03bf70e7978cc5d52affb29d3', 'config': 'a064e2df18ab98d44dabcefbc7bed94913f1d0be', 'pipeline': '7eea819c2a8c103c4b1e9e9c1e224aebba95081f'}, 'duration': 0.8501448631286621, 'iteration': 3, 'loss': 0.053333333333333344, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 2, 'features__selectkbest__k': 4}), 'normalizer': ('normalizer_NoneType', {}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 7})}, 'score': 0.9466666666666667, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'entropy', 'max_depth': 3, 'max_features': 3, 'max_leaf_nodes': None, 'min_samples_split': 5, 'n_estimators': 75}, 'config_hash': {'algorithm': '7a4491035bc6bd737fe9a8cda8a79a02d02d5c74', 'config': '0ddb6f5cab3db4dddd7682966a57205f3e329ad4', 'pipeline': 'a9ae03fe38334f6868cbf84cdd3d629d4bbe3fb0'}, 'duration': 1.1026010513305664, 'iteration': 4, 'loss': 0.05999999999999994, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 2, 'features__selectkbest__k': 1}), 'normalizer': ('normalizer_NoneType', {}), 'rebalance': ('rebalance_NoneType', {})}, 'score': 0.9400000000000001, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'gini', 'max_depth': 3, 'max_features': 1, 'max_leaf_nodes': 5, 'min_samples_split': 2, 'n_estimators': 25}, 'config_hash': {'algorithm': '9826d20b2d6a0f559cf7f16450ce7526f07e8434', 'config': '49f25751bca61cdd461a8cbd2923689b642f98ed', 'pipeline': '19b249664c5bf067de1fed4334a296f947ce774a'}, 'duration': 0.35647010803222656, 'iteration': 5, 'loss': 0.046666666666666634, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_NoneType', {}), 'normalizer': ('normalizer_NoneType', {}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 6})}, 'score': 0.9533333333333334, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'gini', 'max_depth': 2, 'max_features': 1, 'max_leaf_nodes': 2, 'min_samples_split': 2, 'n_estimators': 50}, 'config_hash': {'algorithm': '0a4f6fbb07e0f32c6f675489a0fc82eee05bd8e1', 'config': '5c3a2b6f5e63fb45f10e41e0318b354912ec44f6', 'pipeline': 'dc3b9f176f090005e38b142f11d80e93a7dc5d5e'}, 'duration': 0.7213859558105469, 'iteration': 6, 'loss': 0.31333333333333324, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 1, 'features__selectkbest__k': 4}), 'normalizer': ('normalizer_PowerTransformer', {}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 7})}, 'score': 0.6866666666666668, ...}], 'history_hash': ['db6ac7e6d348155757e4794bb5f88fe2b4f63d50', '4db6fb84d85f52659f780e682ffac5712c3d8a94', '4403c5a85e951938d3c454e961d3a412780722f6', 'a064e2df18ab98d44dabcefbc7bed94913f1d0be', '0ddb6f5cab3db4dddd7682966a57205f3e329ad4', '49f25751bca61cdd461a8cbd2923689b642f98ed', '5c3a2b6f5e63fb45f10e41e0318b354912ec44f6'], 'history_index': {'0ddb6f5cab3db4dddd7682966a57205f3e329ad4': 4, '4403c5a85e951938d3c454e961d3a412780722f6': 2, '49f25751bca61cdd461a8cbd2923689b642f98ed': 5, '4db6fb84d85f52659f780e682ffac5712c3d8a94': 1, '5c3a2b6f5e63fb45f10e41e0318b354912ec44f6': 6, 'a064e2df18ab98d44dabcefbc7bed94913f1d0be': 3, 'db6ac7e6d348155757e4794bb5f88fe2b4f63d50': 0}, 'iteration': 6, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint'}
        config = {'algorithm': 'RandomForest', 'seed': 42, 'time': 300}
    114 
    115 
    116 def get_baseline_score(algorithm, X, y, seed):
    117     pipeline, _ = pipeline_conf_to_full_pipeline(

...........................................................................
/home/aquemy/dev/dp_hyperparameters/extension/experiment/objective.py in objective(pipeline_config={'features': ('features_PCA', {'features__n_components': 2}), 'normalizer': ('normalizer_StandardScaler', {'normalizer__with_mean': True, 'normalizer__with_std': False}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 6})}, algo_config={'bootstrap': False, 'criterion': 'entropy', 'max_depth': 4, 'max_features': 3, 'max_leaf_nodes': 5, 'min_samples_split': 5, 'n_estimators': 10}, algorithm='RandomForest', X=array([[5.1, 3.5, 1.4, 0.2],
       [4.9, 3. , 1....2, 3.4, 5.4, 2.3],
       [5.9, 3. , 5.1, 1.8]]), y=array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,... 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]), context={'baseline_score': 0.9466666666666667, 'baseline_score_std': 0.04988876515698587, 'best_config': {'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': 1, 'max_features': None, 'max_leaf_nodes': None, 'min_samples_split': 5, 'n_estimators': 75}, 'config_hash': {'algorithm': '94b0d7a654c508cc63643f78fe4f0f07e6f07c1e', 'config': '4403c5a85e951938d3c454e961d3a412780722f6', 'pipeline': '3e47444880d8367fbac2faaba2e52a917274aa58'}, 'duration': 0.8397619724273682, 'iteration': 2, 'loss': 0.03333333333333344, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_PCA', {'features__n_components': 3}), 'normalizer': ('normalizer_MinMaxScaler', {}), 'rebalance': ('rebalance_NoneType', {})}, 'score': 0.9666666666666666, ...}, 'history': [{'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': 2, 'max_features': None, 'max_leaf_nodes': 5, 'min_samples_split': 2, 'n_estimators': 75}, 'config_hash': {'algorithm': '3af5b0cce71c8fe2545246ca24ff5bc3dd516e06', 'config': 'db6ac7e6d348155757e4794bb5f88fe2b4f63d50', 'pipeline': '8d59f4b94cef6be9306ed86a22a9570fa670d567'}, 'duration': 1.149928092956543, 'iteration': 0, 'loss': 0.046666666666666634, 'max_history_score': 0.9533333333333334, 'max_history_score_std': 0.059999999999999984, 'max_history_step': 'joint', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 4, 'features__selectkbest__k': 3}), 'normalizer': ('normalizer_StandardScaler', {'normalizer__with_mean': True, 'normalizer__with_std': True}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 6})}, 'score': 0.9533333333333334, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': 1, 'max_features': 2, 'max_leaf_nodes': 2, 'min_samples_split': 5, 'n_estimators': 100}, 'config_hash': {'algorithm': 'e13eb05fd9a62d2f63bbb1c1deff0cd620d5e6ab', 'config': '4db6fb84d85f52659f780e682ffac5712c3d8a94', 'pipeline': '64c9a1ca9d53ae67244bdd942f4db36a3c05218c'}, 'duration': 1.7678282260894775, 'iteration': 1, 'loss': 0.18000000000000005, 'max_history_score': 0.9533333333333334, 'max_history_score_std': 0.059999999999999984, 'max_history_step': 'joint', 'pipeline': {'features': ('features_NoneType', {}), 'normalizer': ('normalizer_PowerTransformer', {}), 'rebalance': ('rebalance_NearMiss', {'rebalance__n_neighbors': 1})}, 'score': 0.82, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': 1, 'max_features': None, 'max_leaf_nodes': None, 'min_samples_split': 5, 'n_estimators': 75}, 'config_hash': {'algorithm': '94b0d7a654c508cc63643f78fe4f0f07e6f07c1e', 'config': '4403c5a85e951938d3c454e961d3a412780722f6', 'pipeline': '3e47444880d8367fbac2faaba2e52a917274aa58'}, 'duration': 0.8397619724273682, 'iteration': 2, 'loss': 0.03333333333333344, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_PCA', {'features__n_components': 3}), 'normalizer': ('normalizer_MinMaxScaler', {}), 'rebalance': ('rebalance_NoneType', {})}, 'score': 0.9666666666666666, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': None, 'max_features': None, 'max_leaf_nodes': 3, 'min_samples_split': 3, 'n_estimators': 75}, 'config_hash': {'algorithm': 'e8332f0a8902bda03bf70e7978cc5d52affb29d3', 'config': 'a064e2df18ab98d44dabcefbc7bed94913f1d0be', 'pipeline': '7eea819c2a8c103c4b1e9e9c1e224aebba95081f'}, 'duration': 0.8501448631286621, 'iteration': 3, 'loss': 0.053333333333333344, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 2, 'features__selectkbest__k': 4}), 'normalizer': ('normalizer_NoneType', {}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 7})}, 'score': 0.9466666666666667, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'entropy', 'max_depth': 3, 'max_features': 3, 'max_leaf_nodes': None, 'min_samples_split': 5, 'n_estimators': 75}, 'config_hash': {'algorithm': '7a4491035bc6bd737fe9a8cda8a79a02d02d5c74', 'config': '0ddb6f5cab3db4dddd7682966a57205f3e329ad4', 'pipeline': 'a9ae03fe38334f6868cbf84cdd3d629d4bbe3fb0'}, 'duration': 1.1026010513305664, 'iteration': 4, 'loss': 0.05999999999999994, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 2, 'features__selectkbest__k': 1}), 'normalizer': ('normalizer_NoneType', {}), 'rebalance': ('rebalance_NoneType', {})}, 'score': 0.9400000000000001, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'gini', 'max_depth': 3, 'max_features': 1, 'max_leaf_nodes': 5, 'min_samples_split': 2, 'n_estimators': 25}, 'config_hash': {'algorithm': '9826d20b2d6a0f559cf7f16450ce7526f07e8434', 'config': '49f25751bca61cdd461a8cbd2923689b642f98ed', 'pipeline': '19b249664c5bf067de1fed4334a296f947ce774a'}, 'duration': 0.35647010803222656, 'iteration': 5, 'loss': 0.046666666666666634, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_NoneType', {}), 'normalizer': ('normalizer_NoneType', {}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 6})}, 'score': 0.9533333333333334, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'gini', 'max_depth': 2, 'max_features': 1, 'max_leaf_nodes': 2, 'min_samples_split': 2, 'n_estimators': 50}, 'config_hash': {'algorithm': '0a4f6fbb07e0f32c6f675489a0fc82eee05bd8e1', 'config': '5c3a2b6f5e63fb45f10e41e0318b354912ec44f6', 'pipeline': 'dc3b9f176f090005e38b142f11d80e93a7dc5d5e'}, 'duration': 0.7213859558105469, 'iteration': 6, 'loss': 0.31333333333333324, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 1, 'features__selectkbest__k': 4}), 'normalizer': ('normalizer_PowerTransformer', {}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 7})}, 'score': 0.6866666666666668, ...}], 'history_hash': ['db6ac7e6d348155757e4794bb5f88fe2b4f63d50', '4db6fb84d85f52659f780e682ffac5712c3d8a94', '4403c5a85e951938d3c454e961d3a412780722f6', 'a064e2df18ab98d44dabcefbc7bed94913f1d0be', '0ddb6f5cab3db4dddd7682966a57205f3e329ad4', '49f25751bca61cdd461a8cbd2923689b642f98ed', '5c3a2b6f5e63fb45f10e41e0318b354912ec44f6'], 'history_index': {'0ddb6f5cab3db4dddd7682966a57205f3e329ad4': 4, '4403c5a85e951938d3c454e961d3a412780722f6': 2, '49f25751bca61cdd461a8cbd2923689b642f98ed': 5, '4db6fb84d85f52659f780e682ffac5712c3d8a94': 1, '5c3a2b6f5e63fb45f10e41e0318b354912ec44f6': 6, 'a064e2df18ab98d44dabcefbc7bed94913f1d0be': 3, 'db6ac7e6d348155757e4794bb5f88fe2b4f63d50': 0}, 'iteration': 6, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint'}, config={'algorithm': 'RandomForest', 'seed': 42, 'time': 300}, step='joint')
     45                 y,
     46                 cv=10,
     47                 n_jobs=-1,
     48                 return_estimator=False,
     49                 return_train_score=False,
---> 50                 verbose=0)
     51         score = np.mean(scores['test_score'])
     52         std = np.std(scores['test_score'])
     53         status = STATUS_OK
     54     except Exception as e:

...........................................................................
/home/aquemy/.local/lib/python2.7/site-packages/sklearn/model_selection/_validation.py in cross_validate(estimator=Pipeline(memory=None,
     steps=[('rebalance', ...e=42,
            verbose=0, warm_start=False))]), X=array([[5.1, 3.5, 1.4, 0.2],
       [4.9, 3. , 1....2, 3.4, 5.4, 2.3],
       [5.9, 3. , 5.1, 1.8]]), y=array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,... 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]), groups=None, scoring=None, cv=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1, verbose=0, fit_params=None, pre_dispatch='2*n_jobs', return_train_score=False, return_estimator=False, error_score='raise-deprecating')
    235         delayed(_fit_and_score)(
    236             clone(estimator), X, y, scorers, train, test, verbose, None,
    237             fit_params, return_train_score=return_train_score,
    238             return_times=True, return_estimator=return_estimator,
    239             error_score=error_score)
--> 240         for train, test in cv.split(X, y, groups))
        cv.split = <bound method StratifiedKFold.split of Stratifie...d(n_splits=10, random_state=None, shuffle=False)>
        X = array([[5.1, 3.5, 1.4, 0.2],
       [4.9, 3. , 1....2, 3.4, 5.4, 2.3],
       [5.9, 3. , 5.1, 1.8]])
        y = array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,... 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2])
        groups = None
    241 
    242     zipped_scores = list(zip(*scores))
    243     if return_train_score:
    244         train_scores = zipped_scores.pop(0)

...........................................................................
/home/aquemy/.local/lib/python2.7/site-packages/sklearn/externals/joblib/parallel.py in __call__(self=Parallel(n_jobs=-1), iterable=<generator object <genexpr>>)
    925                 # No need to wait for async callbacks to trigger to
    926                 # consumption.
    927                 self._iterating = False
    928 
    929             with self._backend.retrieval_context():
--> 930                 self.retrieve()
        self.retrieve = <bound method Parallel.retrieve of Parallel(n_jobs=-1)>
    931             # Make sure that we get a last message telling us we are done
    932             elapsed_time = time.time() - self._start_time
    933             self._print('Done %3i out of %3i | elapsed: %s finished',
    934                         (len(self._output), len(self._output),

---------------------------------------------------------------------------
Joblib worker traceback:
---------------------------------------------------------------------------
ValueError                                         Mon Jun 17 13:10:38 2019
PID: 20853                                  Python 2.7.15+: /usr/bin/python
...........................................................................
/home/aquemy/.local/lib/python2.7/site-packages/sklearn/externals/joblib/parallel.py in __call__(self=<sklearn.externals.joblib.parallel.BatchedCalls object>)
    220     def __call__(self):
    221         # Set the default nested backend to self._backend but do not set the
    222         # change the default number of processes to -1
    223         with parallel_backend(self._backend, n_jobs=self._n_jobs):
    224             return [func(*args, **kwargs)
--> 225                     for func, args, kwargs in self.items]
        func = <function _fit_and_score>
        args = (Pipeline(memory=None,
     steps=[('rebalance', ...e=42,
            verbose=0, warm_start=False))]), array([[5.1, 3.5, 1.4, 0.2],
       [4.9, 3. , 1....2, 3.4, 5.4, 2.3],
       [5.9, 3. , 5.1, 1.8]]), array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,... 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]), {'score': <function _passthrough_scorer>}, array([  5,   6,   7,   8,   9,  10,  11,  12,  ..., 142, 143, 144,
       145, 146, 147, 148, 149]), array([  0,   1,   2,   3,   4,  50,  51,  52,  53,  54, 100, 101, 102,
       103, 104]), 0, None, None)
        kwargs = {'error_score': 'raise-deprecating', 'return_estimator': False, 'return_times': True, 'return_train_score': False}
        self.items = [(<function _fit_and_score>, (Pipeline(memory=None,
     steps=[('rebalance', ...e=42,
            verbose=0, warm_start=False))]), array([[5.1, 3.5, 1.4, 0.2],
       [4.9, 3. , 1....2, 3.4, 5.4, 2.3],
       [5.9, 3. , 5.1, 1.8]]), array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,... 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]), {'score': <function _passthrough_scorer>}, array([  5,   6,   7,   8,   9,  10,  11,  12,  ..., 142, 143, 144,
       145, 146, 147, 148, 149]), array([  0,   1,   2,   3,   4,  50,  51,  52,  53,  54, 100, 101, 102,
       103, 104]), 0, None, None), {'error_score': 'raise-deprecating', 'return_estimator': False, 'return_times': True, 'return_train_score': False})]
    226 
    227     def __len__(self):
    228         return self._size
    229 

...........................................................................
/home/aquemy/.local/lib/python2.7/site-packages/sklearn/model_selection/_validation.py in _fit_and_score(estimator=Pipeline(memory=None,
     steps=[('rebalance', ...e=42,
            verbose=0, warm_start=False))]), X=array([[5.1, 3.5, 1.4, 0.2],
       [4.9, 3. , 1....2, 3.4, 5.4, 2.3],
       [5.9, 3. , 5.1, 1.8]]), y=array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,... 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]), scorer={'score': <function _passthrough_scorer>}, train=array([  5,   6,   7,   8,   9,  10,  11,  12,  ..., 142, 143, 144,
       145, 146, 147, 148, 149]), test=array([  0,   1,   2,   3,   4,  50,  51,  52,  53,  54, 100, 101, 102,
       103, 104]), verbose=0, parameters=None, fit_params={}, return_train_score=False, return_parameters=False, return_n_test_samples=False, return_times=True, return_estimator=False, error_score='raise-deprecating')
    523 
    524     try:
    525         if y_train is None:
    526             estimator.fit(X_train, **fit_params)
    527         else:
--> 528             estimator.fit(X_train, y_train, **fit_params)
        estimator.fit = <bound method Pipeline.fit of Pipeline(memory=No...=42,
            verbose=0, warm_start=False))])>
        X_train = array([[5.4, 3.9, 1.7, 0.4],
       [4.6, 3.4, 1....2, 3.4, 5.4, 2.3],
       [5.9, 3. , 5.1, 1.8]])
        y_train = array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,
       2, 2, 2])
        fit_params = {}
    529 
    530     except Exception as e:
    531         # Note fit time as time until error
    532         fit_time = time.time() - start_time

...........................................................................
/usr/local/lib/python2.7/dist-packages/imblearn/pipeline.py in fit(self=Pipeline(memory=None,
     steps=[('rebalance', ...e=42,
            verbose=0, warm_start=False))]), X=array([[5.4, 3.9, 1.7, 0.4],
       [4.6, 3.4, 1....2, 3.4, 5.4, 2.3],
       [5.9, 3. , 5.1, 1.8]]), y=array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,
       2, 2, 2]), **fit_params={})
    234             This estimator
    235 
    236         """
    237         Xt, yt, fit_params = self._fit(X, y, **fit_params)
    238         if self._final_estimator is not None:
--> 239             self._final_estimator.fit(Xt, yt, **fit_params)
        self._final_estimator.fit = <bound method RandomForestClassifier.fit of Rand...ate=42,
            verbose=0, warm_start=False)>
        Xt = array([[-2.26811251,  0.74059504],
       [-2.80... 0.14061757],
       [ 1.40511042, -0.26816151]])
        yt = array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,
       2, 2, 2])
        fit_params = {}
    240         return self
    241 
    242     def fit_transform(self, X, y=None, **fit_params):
    243         """Fit the model and transform with the final estimator

...........................................................................
/home/aquemy/.local/lib/python2.7/site-packages/sklearn/ensemble/forest.py in fit(self=RandomForestClassifier(bootstrap=False, class_we...tate=42,
            verbose=0, warm_start=False), X=array([[-2.2681124 ,  0.74059504],
       [-2.80...      [ 1.4051104 , -0.2681615 ]], dtype=float32), y=array([[0.],
       [0.],
       [0.],
       [0...    [2.],
       [2.],
       [2.],
       [2.]]), sample_weight=None)
    328             trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,
    329                              **_joblib_parallel_args(prefer='threads'))(
    330                 delayed(_parallel_build_trees)(
    331                     t, self, X, y, sample_weight, i, len(trees),
    332                     verbose=self.verbose, class_weight=self.class_weight)
--> 333                 for i, t in enumerate(trees))
        i = 9
    334 
    335             # Collect newly grown trees
    336             self.estimators_.extend(trees)
    337 

...........................................................................
/home/aquemy/.local/lib/python2.7/site-packages/sklearn/externals/joblib/parallel.py in __call__(self=Parallel(n_jobs=1), iterable=<generator object <genexpr>>)
    912             # self._original_iterator is None, then this means either
    913             # that pre_dispatch == "all", n_jobs == 1 or that the first batch
    914             # was very quick and its callback already dispatched all the
    915             # remaining jobs.
    916             self._iterating = False
--> 917             if self.dispatch_one_batch(iterator):
        self.dispatch_one_batch = <bound method Parallel.dispatch_one_batch of Parallel(n_jobs=1)>
        iterator = <generator object <genexpr>>
    918                 self._iterating = self._original_iterator is not None
    919 
    920             while self.dispatch_one_batch(iterator):
    921                 pass

...........................................................................
/home/aquemy/.local/lib/python2.7/site-packages/sklearn/externals/joblib/parallel.py in dispatch_one_batch(self=Parallel(n_jobs=1), iterator=<generator object <genexpr>>)
    754                                  self._pickle_cache)
    755             if len(tasks) == 0:
    756                 # No more tasks available in the iterator: tell caller to stop.
    757                 return False
    758             else:
--> 759                 self._dispatch(tasks)
        self._dispatch = <bound method Parallel._dispatch of Parallel(n_jobs=1)>
        tasks = <sklearn.externals.joblib.parallel.BatchedCalls object>
    760                 return True
    761 
    762     def _print(self, msg, msg_args):
    763         """Display the message on stout or stderr depending on verbosity"""

...........................................................................
/home/aquemy/.local/lib/python2.7/site-packages/sklearn/externals/joblib/parallel.py in _dispatch(self=Parallel(n_jobs=1), batch=<sklearn.externals.joblib.parallel.BatchedCalls object>)
    711 
    712         dispatch_timestamp = time.time()
    713         cb = BatchCompletionCallBack(dispatch_timestamp, len(batch), self)
    714         with self._lock:
    715             job_idx = len(self._jobs)
--> 716             job = self._backend.apply_async(batch, callback=cb)
        job = undefined
        self._backend.apply_async = <bound method SequentialBackend.apply_async of <...lib._parallel_backends.SequentialBackend object>>
        batch = <sklearn.externals.joblib.parallel.BatchedCalls object>
        cb = <sklearn.externals.joblib.parallel.BatchCompletionCallBack object>
    717             # A job can complete so quickly than its callback is
    718             # called before we get here, causing self._jobs to
    719             # grow. To ensure correct results ordering, .insert is
    720             # used (rather than .append) in the following line

...........................................................................
/home/aquemy/.local/lib/python2.7/site-packages/sklearn/externals/joblib/_parallel_backends.py in apply_async(self=<sklearn.externals.joblib._parallel_backends.SequentialBackend object>, func=<sklearn.externals.joblib.parallel.BatchedCalls object>, callback=<sklearn.externals.joblib.parallel.BatchCompletionCallBack object>)
    177             raise ValueError('n_jobs == 0 in Parallel has no meaning')
    178         return 1
    179 
    180     def apply_async(self, func, callback=None):
    181         """Schedule a func to be run"""
--> 182         result = ImmediateResult(func)
        result = undefined
        func = <sklearn.externals.joblib.parallel.BatchedCalls object>
    183         if callback:
    184             callback(result)
    185         return result
    186 

...........................................................................
/home/aquemy/.local/lib/python2.7/site-packages/sklearn/externals/joblib/_parallel_backends.py in __init__(self=<sklearn.externals.joblib._parallel_backends.ImmediateResult object>, batch=<sklearn.externals.joblib.parallel.BatchedCalls object>)
    544 
    545 class ImmediateResult(object):
    546     def __init__(self, batch):
    547         # Don't delay the application, to avoid keeping the input
    548         # arguments in memory
--> 549         self.results = batch()
        self.results = undefined
        batch = <sklearn.externals.joblib.parallel.BatchedCalls object>
    550 
    551     def get(self):
    552         return self.results
    553 

...........................................................................
/home/aquemy/.local/lib/python2.7/site-packages/sklearn/externals/joblib/parallel.py in __call__(self=<sklearn.externals.joblib.parallel.BatchedCalls object>)
    220     def __call__(self):
    221         # Set the default nested backend to self._backend but do not set the
    222         # change the default number of processes to -1
    223         with parallel_backend(self._backend, n_jobs=self._n_jobs):
    224             return [func(*args, **kwargs)
--> 225                     for func, args, kwargs in self.items]
        func = <function _parallel_build_trees>
        args = (DecisionTreeClassifier(class_weight=None, criter...=False, random_state=1608637542, splitter='best'), RandomForestClassifier(bootstrap=False, class_we...tate=42,
            verbose=0, warm_start=False), array([[-2.2681124 ,  0.74059504],
       [-2.80...      [ 1.4051104 , -0.2681615 ]], dtype=float32), array([[0.],
       [0.],
       [0.],
       [0...    [2.],
       [2.],
       [2.],
       [2.]]), None, 0, 10)
        kwargs = {'class_weight': None, 'verbose': 0}
        self.items = [(<function _parallel_build_trees>, (DecisionTreeClassifier(class_weight=None, criter...=False, random_state=1608637542, splitter='best'), RandomForestClassifier(bootstrap=False, class_we...tate=42,
            verbose=0, warm_start=False), array([[-2.2681124 ,  0.74059504],
       [-2.80...      [ 1.4051104 , -0.2681615 ]], dtype=float32), array([[0.],
       [0.],
       [0.],
       [0...    [2.],
       [2.],
       [2.],
       [2.]]), None, 0, 10), {'class_weight': None, 'verbose': 0})]
    226 
    227     def __len__(self):
    228         return self._size
    229 

...........................................................................
/home/aquemy/.local/lib/python2.7/site-packages/sklearn/ensemble/forest.py in _parallel_build_trees(tree=DecisionTreeClassifier(class_weight=None, criter...=False, random_state=1608637542, splitter='best'), forest=RandomForestClassifier(bootstrap=False, class_we...tate=42,
            verbose=0, warm_start=False), X=array([[-2.2681124 ,  0.74059504],
       [-2.80...      [ 1.4051104 , -0.2681615 ]], dtype=float32), y=array([[0.],
       [0.],
       [0.],
       [0...    [2.],
       [2.],
       [2.],
       [2.]]), sample_weight=None, tree_idx=0, n_trees=10, verbose=0, class_weight=None)
    116         elif class_weight == 'balanced_subsample':
    117             curr_sample_weight *= compute_sample_weight('balanced', y, indices)
    118 
    119         tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)
    120     else:
--> 121         tree.fit(X, y, sample_weight=sample_weight, check_input=False)
        tree.fit = <bound method DecisionTreeClassifier.fit of Deci...False, random_state=1608637542, splitter='best')>
        X = array([[-2.2681124 ,  0.74059504],
       [-2.80...      [ 1.4051104 , -0.2681615 ]], dtype=float32)
        y = array([[0.],
       [0.],
       [0.],
       [0...    [2.],
       [2.],
       [2.],
       [2.]])
        sample_weight = None
    122 
    123     return tree
    124 
    125 

...........................................................................
/home/aquemy/.local/lib/python2.7/site-packages/sklearn/tree/tree.py in fit(self=DecisionTreeClassifier(class_weight=None, criter...=False, random_state=1608637542, splitter='best'), X=array([[-2.2681124 ,  0.74059504],
       [-2.80...      [ 1.4051104 , -0.2681615 ]], dtype=float32), y=array([[0.],
       [0.],
       [0.],
       [0...    [2.],
       [2.],
       [2.],
       [2.]]), sample_weight=None, check_input=False, X_idx_sorted=None)
    796 
    797         super(DecisionTreeClassifier, self).fit(
    798             X, y,
    799             sample_weight=sample_weight,
    800             check_input=check_input,
--> 801             X_idx_sorted=X_idx_sorted)
        X_idx_sorted = None
    802         return self
    803 
    804     def predict_proba(self, X, check_input=True):
    805         """Predict class probabilities of the input samples X.

...........................................................................
/home/aquemy/.local/lib/python2.7/site-packages/sklearn/tree/tree.py in fit(self=DecisionTreeClassifier(class_weight=None, criter...=False, random_state=1608637542, splitter='best'), X=array([[-2.2681124 ,  0.74059504],
       [-2.80...      [ 1.4051104 , -0.2681615 ]], dtype=float32), y=array([[0.],
       [0.],
       [0.],
       [0...    [2.],
       [2.],
       [2.],
       [2.]]), sample_weight=None, check_input=False, X_idx_sorted=None)
    237         if not 0 <= self.min_weight_fraction_leaf <= 0.5:
    238             raise ValueError("min_weight_fraction_leaf must in [0, 0.5]")
    239         if max_depth <= 0:
    240             raise ValueError("max_depth must be greater than zero. ")
    241         if not (0 < max_features <= self.n_features_):
--> 242             raise ValueError("max_features must be in (0, n_features]")
    243         if not isinstance(max_leaf_nodes, (numbers.Integral, np.integer)):
    244             raise ValueError("max_leaf_nodes must be integral number but was "
    245                              "%r" % max_leaf_nodes)
    246         if -1 < max_leaf_nodes < 2:

ValueError: max_features must be in (0, n_features]
___________________________________________________________________________
Best score: 0.966666666667 (0.04472135955) [J] | Score: 0.0 (0.0) [J]
Best score: 0.966666666667 (0.04472135955) [J] | Score: 0.666666666667 (1.11022302463e-16) [J]
Best score: 0.966666666667 (0.04472135955) [J] | Score: 0.946666666667 (0.049888765157) [J]
Best score: 0.966666666667 (0.04472135955) [J] | Score: 0.953333333333 (0.0520683311727) [J]
Best score: 0.966666666667 (0.04472135955) [J] | Score: 0.806666666667 (0.131487219489) [J]
Best score: 0.966666666667 (0.04472135955) [J] | Score: 0.946666666667 (0.049888765157) [J]
Best score: 0.966666666667 (0.04472135955) [J] | Score: 0.96 (0.0326598632371) [J]
Best score: 0.966666666667 (0.04472135955) [J] | Score: 0.953333333333 (0.0426874949162) [J]
Best score: 0.966666666667 (0.04472135955) [J] | Score: 0.953333333333 (0.0520683311727) [J]
Best score: 0.966666666667 (0.04472135955) [J] | Score: 0.946666666667 (0.0653197264742) [J]
Best score: 0.966666666667 (0.04472135955) [J] | Score: 0.76 (0.0533333333333) [J]
Best score: 0.966666666667 (0.04472135955) [J] | Score: 0.766666666667 (0.0614636297153) [J]
Best score: 0.966666666667 (0.04472135955) [J] | Score: 0.913333333333 (0.0845905169363) [J]
Best score: 0.966666666667 (0.04472135955) [J] | Score: 0.94 (0.0553774924195) [J]
JoblibValueError
___________________________________________________________________________
...........................................................................
/home/aquemy/dev/dp_hyperparameters/extension/main.py in <module>()
     27 
     28     serializer.serialize_results(scenario, policy)
     29 
     30 if __name__ == "__main__":
     31     args = cli.parse_args()
---> 32     main(args)

...........................................................................
/home/aquemy/dev/dp_hyperparameters/extension/main.py in main(args=Namespace(customize=[(['control', 'seed'], '42')...io='./scenarios/rf_iris_joint.yaml', verbosity=0))
     21         test_size=0.4, 
     22         random_state=scenario['control']['seed']
     23     )
     24 
     25     policy = policies.initiate(scenario['setup']['policy'], config)
---> 26     policy.run(X,y)
        policy.run = <bound method Joint.run of <experiment.policies.joint.Joint object>>
        X = array([[5.1, 3.5, 1.4, 0.2],
       [4.9, 3. , 1....2, 3.4, 5.4, 2.3],
       [5.9, 3. , 5.1, 1.8]])
        y = array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,... 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2])
     27 
     28     serializer.serialize_results(scenario, policy)
     29 
     30 if __name__ == "__main__":

...........................................................................
/home/aquemy/dev/dp_hyperparameters/extension/experiment/policies/joint.py in run(self=<experiment.policies.joint.Joint object>, X=array([[5.1, 3.5, 1.4, 0.2],
       [4.9, 3. , 1....2, 3.4, 5.4, 2.3],
       [5.9, 3. , 5.1, 1.8]]), y=array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,... 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]))
     32             algo=tpe.suggest, 
     33             max_evals=None,
     34             max_time=self.config['time'],     
     35             trials=trials,
     36             show_progressbar=False,
---> 37             verbose=0
     38         )
     39 
     40         best_config = self.context['best_config']
     41         super(Joint, self).display_step_results(best_config)

...........................................................................
/home/aquemy/dev/dp_hyperparameters/extension/hyperopt/fmin.py in fmin(fn=<functools.partial object>, space={'algorithm': {'bootstrap': <hyperopt.pyll.base.Apply object>, 'criterion': <hyperopt.pyll.base.Apply object>, 'max_depth': <hyperopt.pyll.base.Apply object>, 'max_features': <hyperopt.pyll.base.Apply object>, 'max_leaf_nodes': <hyperopt.pyll.base.Apply object>, 'min_samples_split': <hyperopt.pyll.base.Apply object>, 'n_estimators': <hyperopt.pyll.base.Apply object>}, 'pipeline': {'features': <hyperopt.pyll.base.Apply object>, 'normalizer': <hyperopt.pyll.base.Apply object>, 'rebalance': <hyperopt.pyll.base.Apply object>}}, algo=<function suggest>, max_evals=9223372036854775807, max_time=300, trials=<hyperopt.base.Trials object>, rstate=<mtrand.RandomState object>, allow_trials_fmin=True, pass_expr_memo_ctrl=None, catch_eval_exceptions=False, verbose=0, return_argmin=True, points_to_evaluate=None, max_queue_len=1, show_progressbar=False)
    406             pass_expr_memo_ctrl=pass_expr_memo_ctrl,
    407             verbose=verbose,
    408             catch_eval_exceptions=catch_eval_exceptions,
    409             return_argmin=return_argmin,
    410             show_progressbar=show_progressbar,
--> 411             max_time=max_time
        max_time = 300
    412         )
    413 
    414     if trials is None:
    415         if points_to_evaluate is None:

...........................................................................
/home/aquemy/dev/dp_hyperparameters/extension/hyperopt/base.py in fmin(self=<hyperopt.base.Trials object>, fn=<functools.partial object>, space={'algorithm': {'bootstrap': <hyperopt.pyll.base.Apply object>, 'criterion': <hyperopt.pyll.base.Apply object>, 'max_depth': <hyperopt.pyll.base.Apply object>, 'max_features': <hyperopt.pyll.base.Apply object>, 'max_leaf_nodes': <hyperopt.pyll.base.Apply object>, 'min_samples_split': <hyperopt.pyll.base.Apply object>, 'n_estimators': <hyperopt.pyll.base.Apply object>}, 'pipeline': {'features': <hyperopt.pyll.base.Apply object>, 'normalizer': <hyperopt.pyll.base.Apply object>, 'rebalance': <hyperopt.pyll.base.Apply object>}}, algo=<function suggest>, max_evals=9223372036854775807, max_time=300, rstate=<mtrand.RandomState object>, verbose=0, pass_expr_memo_ctrl=None, catch_eval_exceptions=False, return_argmin=True, show_progressbar=False)
    636             verbose=verbose,
    637             allow_trials_fmin=False,  # -- prevent recursion
    638             pass_expr_memo_ctrl=pass_expr_memo_ctrl,
    639             catch_eval_exceptions=catch_eval_exceptions,
    640             return_argmin=return_argmin,
--> 641             show_progressbar=show_progressbar)
        show_progressbar = False
    642 
    643 
    644 def trials_from_docs(docs, validate=True, **kwargs):
    645     """Construct a Trials base class instance from a list of trials documents

...........................................................................
/home/aquemy/dev/dp_hyperparameters/extension/hyperopt/fmin.py in fmin(fn=<functools.partial object>, space={'algorithm': {'bootstrap': <hyperopt.pyll.base.Apply object>, 'criterion': <hyperopt.pyll.base.Apply object>, 'max_depth': <hyperopt.pyll.base.Apply object>, 'max_features': <hyperopt.pyll.base.Apply object>, 'max_leaf_nodes': <hyperopt.pyll.base.Apply object>, 'min_samples_split': <hyperopt.pyll.base.Apply object>, 'n_estimators': <hyperopt.pyll.base.Apply object>}, 'pipeline': {'features': <hyperopt.pyll.base.Apply object>, 'normalizer': <hyperopt.pyll.base.Apply object>, 'rebalance': <hyperopt.pyll.base.Apply object>}}, algo=<function suggest>, max_evals=9223372036854775807, max_time=300, trials=<hyperopt.base.Trials object>, rstate=<mtrand.RandomState object>, allow_trials_fmin=False, pass_expr_memo_ctrl=None, catch_eval_exceptions=False, verbose=0, return_argmin=True, points_to_evaluate=None, max_queue_len=1, show_progressbar=False)
    426                     verbose=verbose,
    427                     max_queue_len=max_queue_len,
    428                     show_progressbar=show_progressbar,
    429                     max_time=max_time)
    430     rval.catch_eval_exceptions = catch_eval_exceptions
--> 431     rval.exhaust()
        rval.exhaust = <bound method FMinIter.exhaust of <hyperopt.fmin.FMinIter object>>
    432     if return_argmin:
    433         return trials.argmin
    434     elif len(trials) > 0:
    435         # Only if there are some succesfull trail runs, return the best point in the evaluation space

...........................................................................
/home/aquemy/dev/dp_hyperparameters/extension/hyperopt/fmin.py in exhaust(self=<hyperopt.fmin.FMinIter object>)
    273             raise StopIteration()
    274         return self.trials
    275 
    276     def exhaust(self):
    277         n_done = len(self.trials)
--> 278         self.run(self.max_evals - n_done, block_until_done=self.asynchronous)
        self.run = <bound method FMinIter.run of <hyperopt.fmin.FMinIter object>>
        self.max_evals = 9223372036854775807
        n_done = 0
        self.asynchronous = False
    279         self.trials.refresh()
    280         return self
    281 
    282 

...........................................................................
/home/aquemy/dev/dp_hyperparameters/extension/hyperopt/fmin.py in run(self=<hyperopt.fmin.FMinIter object>, N=9223372036854775807, block_until_done=False)
    232                     if self.asynchronous:
    233                         # -- wait for workers to fill in the trials
    234                         time.sleep(self.poll_interval_secs)
    235                     else:
    236                         # -- loop over trials and do the jobs directly
--> 237                         self.serial_evaluate()
        self.serial_evaluate = <bound method FMinIter.serial_evaluate of <hyperopt.fmin.FMinIter object>>
    238                     try:
    239                         res = [d['result']['loss'] for d in
    240                                          self.trials.trials if
    241                                          d['result']['status'] == 'ok']

...........................................................................
/home/aquemy/dev/dp_hyperparameters/extension/hyperopt/fmin.py in serial_evaluate(self=<hyperopt.fmin.FMinIter object>, N=-1)
    138                 trial['book_time'] = now
    139                 trial['refresh_time'] = now
    140                 spec = base.spec_from_misc(trial['misc'])
    141                 ctrl = base.Ctrl(self.trials, current_trial=trial)
    142                 try:
--> 143                     result = self.domain.evaluate(spec, ctrl)
        result = undefined
        self.domain.evaluate = <bound method Domain.evaluate of <hyperopt.base.Domain object>>
        spec = {'bootstrap': 0, 'criterion': 1, 'features': 1, 'features_PCA_features__n_components': 0, 'max_depth': 3, 'max_features': 1, 'max_leaf_nodes': 3, 'min_samples_split': 1, 'n_estimators': 1, 'normalizer': 3, ...}
        ctrl = <hyperopt.base.Ctrl object>
    144                 except Exception as e:
    145                     logger.info('job exception: %s' % str(e))
    146                     trial['state'] = base.JOB_STATE_ERROR
    147                     trial['misc']['error'] = (str(type(e)), str(e))

...........................................................................
/home/aquemy/dev/dp_hyperparameters/extension/hyperopt/base.py in evaluate(self=<hyperopt.base.Domain object>, config={'bootstrap': 0, 'criterion': 1, 'features': 1, 'features_PCA_features__n_components': 0, 'max_depth': 3, 'max_features': 1, 'max_leaf_nodes': 3, 'min_samples_split': 1, 'n_estimators': 1, 'normalizer': 3, ...}, ctrl=<hyperopt.base.Ctrl object>, attach_attachments=True)
    841             #    or the normal Python part (self.fn)
    842             pyll_rval = pyll.rec_eval(
    843                 self.expr,
    844                 memo=memo,
    845                 print_node_on_error=self.rec_eval_print_node_on_error)
--> 846             rval = self.fn(pyll_rval)
        rval = undefined
        self.fn = <functools.partial object>
        pyll_rval = {'algorithm': {'bootstrap': True, 'criterion': 'entropy', 'max_depth': 4, 'max_features': 2, 'max_leaf_nodes': None, 'min_samples_split': 3, 'n_estimators': 25}, 'pipeline': {'features': ('features_PCA', {'features__n_components': 1}), 'normalizer': ('normalizer_MinMaxScaler', {}), 'rebalance': ('rebalance_NoneType', {})}}
    847 
    848         if isinstance(rval, (float, int, np.number)):
    849             dict_rval = {'loss': float(rval), 'status': STATUS_OK}
    850         else:

...........................................................................
/home/aquemy/dev/dp_hyperparameters/extension/experiment/objective.py in objective_joint(wconfig={'algorithm': {'bootstrap': True, 'criterion': 'entropy', 'max_depth': 4, 'max_features': 2, 'max_leaf_nodes': None, 'min_samples_split': 3, 'n_estimators': 25}, 'pipeline': {'features': ('features_PCA', {'features__n_components': 1}), 'normalizer': ('normalizer_MinMaxScaler', {}), 'rebalance': ('rebalance_NoneType', {})}}, algorithm='RandomForest', X=array([[5.1, 3.5, 1.4, 0.2],
       [4.9, 3. , 1....2, 3.4, 5.4, 2.3],
       [5.9, 3. , 5.1, 1.8]]), y=array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,... 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]), context={'baseline_score': 0.9466666666666667, 'baseline_score_std': 0.04988876515698587, 'best_config': {'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': 1, 'max_features': None, 'max_leaf_nodes': None, 'min_samples_split': 5, 'n_estimators': 75}, 'config_hash': {'algorithm': '94b0d7a654c508cc63643f78fe4f0f07e6f07c1e', 'config': '4403c5a85e951938d3c454e961d3a412780722f6', 'pipeline': '3e47444880d8367fbac2faaba2e52a917274aa58'}, 'duration': 0.8397619724273682, 'iteration': 2, 'loss': 0.03333333333333344, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_PCA', {'features__n_components': 3}), 'normalizer': ('normalizer_MinMaxScaler', {}), 'rebalance': ('rebalance_NoneType', {})}, 'score': 0.9666666666666666, ...}, 'history': [{'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': 2, 'max_features': None, 'max_leaf_nodes': 5, 'min_samples_split': 2, 'n_estimators': 75}, 'config_hash': {'algorithm': '3af5b0cce71c8fe2545246ca24ff5bc3dd516e06', 'config': 'db6ac7e6d348155757e4794bb5f88fe2b4f63d50', 'pipeline': '8d59f4b94cef6be9306ed86a22a9570fa670d567'}, 'duration': 1.149928092956543, 'iteration': 0, 'loss': 0.046666666666666634, 'max_history_score': 0.9533333333333334, 'max_history_score_std': 0.059999999999999984, 'max_history_step': 'joint', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 4, 'features__selectkbest__k': 3}), 'normalizer': ('normalizer_StandardScaler', {'normalizer__with_mean': True, 'normalizer__with_std': True}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 6})}, 'score': 0.9533333333333334, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': 1, 'max_features': 2, 'max_leaf_nodes': 2, 'min_samples_split': 5, 'n_estimators': 100}, 'config_hash': {'algorithm': 'e13eb05fd9a62d2f63bbb1c1deff0cd620d5e6ab', 'config': '4db6fb84d85f52659f780e682ffac5712c3d8a94', 'pipeline': '64c9a1ca9d53ae67244bdd942f4db36a3c05218c'}, 'duration': 1.7678282260894775, 'iteration': 1, 'loss': 0.18000000000000005, 'max_history_score': 0.9533333333333334, 'max_history_score_std': 0.059999999999999984, 'max_history_step': 'joint', 'pipeline': {'features': ('features_NoneType', {}), 'normalizer': ('normalizer_PowerTransformer', {}), 'rebalance': ('rebalance_NearMiss', {'rebalance__n_neighbors': 1})}, 'score': 0.82, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': 1, 'max_features': None, 'max_leaf_nodes': None, 'min_samples_split': 5, 'n_estimators': 75}, 'config_hash': {'algorithm': '94b0d7a654c508cc63643f78fe4f0f07e6f07c1e', 'config': '4403c5a85e951938d3c454e961d3a412780722f6', 'pipeline': '3e47444880d8367fbac2faaba2e52a917274aa58'}, 'duration': 0.8397619724273682, 'iteration': 2, 'loss': 0.03333333333333344, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_PCA', {'features__n_components': 3}), 'normalizer': ('normalizer_MinMaxScaler', {}), 'rebalance': ('rebalance_NoneType', {})}, 'score': 0.9666666666666666, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': None, 'max_features': None, 'max_leaf_nodes': 3, 'min_samples_split': 3, 'n_estimators': 75}, 'config_hash': {'algorithm': 'e8332f0a8902bda03bf70e7978cc5d52affb29d3', 'config': 'a064e2df18ab98d44dabcefbc7bed94913f1d0be', 'pipeline': '7eea819c2a8c103c4b1e9e9c1e224aebba95081f'}, 'duration': 0.8501448631286621, 'iteration': 3, 'loss': 0.053333333333333344, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 2, 'features__selectkbest__k': 4}), 'normalizer': ('normalizer_NoneType', {}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 7})}, 'score': 0.9466666666666667, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'entropy', 'max_depth': 3, 'max_features': 3, 'max_leaf_nodes': None, 'min_samples_split': 5, 'n_estimators': 75}, 'config_hash': {'algorithm': '7a4491035bc6bd737fe9a8cda8a79a02d02d5c74', 'config': '0ddb6f5cab3db4dddd7682966a57205f3e329ad4', 'pipeline': 'a9ae03fe38334f6868cbf84cdd3d629d4bbe3fb0'}, 'duration': 1.1026010513305664, 'iteration': 4, 'loss': 0.05999999999999994, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 2, 'features__selectkbest__k': 1}), 'normalizer': ('normalizer_NoneType', {}), 'rebalance': ('rebalance_NoneType', {})}, 'score': 0.9400000000000001, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'gini', 'max_depth': 3, 'max_features': 1, 'max_leaf_nodes': 5, 'min_samples_split': 2, 'n_estimators': 25}, 'config_hash': {'algorithm': '9826d20b2d6a0f559cf7f16450ce7526f07e8434', 'config': '49f25751bca61cdd461a8cbd2923689b642f98ed', 'pipeline': '19b249664c5bf067de1fed4334a296f947ce774a'}, 'duration': 0.35647010803222656, 'iteration': 5, 'loss': 0.046666666666666634, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_NoneType', {}), 'normalizer': ('normalizer_NoneType', {}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 6})}, 'score': 0.9533333333333334, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'gini', 'max_depth': 2, 'max_features': 1, 'max_leaf_nodes': 2, 'min_samples_split': 2, 'n_estimators': 50}, 'config_hash': {'algorithm': '0a4f6fbb07e0f32c6f675489a0fc82eee05bd8e1', 'config': '5c3a2b6f5e63fb45f10e41e0318b354912ec44f6', 'pipeline': 'dc3b9f176f090005e38b142f11d80e93a7dc5d5e'}, 'duration': 0.7213859558105469, 'iteration': 6, 'loss': 0.31333333333333324, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 1, 'features__selectkbest__k': 4}), 'normalizer': ('normalizer_PowerTransformer', {}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 7})}, 'score': 0.6866666666666668, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'entropy', 'max_depth': 4, 'max_features': 3, 'max_leaf_nodes': 5, 'min_samples_split': 5, 'n_estimators': 10}, 'config_hash': {'algorithm': 'b8112b97ecfc10f00a195af661dcc861cac21289', 'config': 'd3b129b397350f1b6572651c67c01de49b4b174c', 'pipeline': '5b0357ed7072c37b3d6f458bb5d49ff7d825f603'}, 'duration': 0.8299109935760498, 'iteration': 7, 'loss': 1.0, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_PCA', {'features__n_components': 2}), 'normalizer': ('normalizer_StandardScaler', {'normalizer__with_mean': True, 'normalizer__with_std': False}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 6})}, 'score': 0.0, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'gini', 'max_depth': 4, 'max_features': None, 'max_leaf_nodes': 2, 'min_samples_split': 5, 'n_estimators': 100}, 'config_hash': {'algorithm': '40ca24df19b8d164d9d098a6bed1ce056fbbb961', 'config': '813bde1108cc3c4b9bfb3a22cbb421bda7eac671', 'pipeline': '74a7b8705a1c22f7dea5e44e4ebda8f1e48add71'}, 'duration': 2.2111589908599854, 'iteration': 8, 'loss': 0.33333333333333326, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_PCA', {'features__n_components': 2}), 'normalizer': ('normalizer_StandardScaler', {'normalizer__with_mean': False, 'normalizer__with_std': True}), 'rebalance': ('rebalance_NearMiss', {'rebalance__n_neighbors': 2})}, 'score': 0.6666666666666667, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'entropy', 'max_depth': 2, 'max_features': 1, 'max_leaf_nodes': 5, 'min_samples_split': 2, 'n_estimators': 100}, 'config_hash': {'algorithm': '331418a5c12cf1453876eef85e9d98fc8e54fa11', 'config': '31930b6860ed406d59bf7e59ba1925d94704bd3b', 'pipeline': '054bef356f90ec6f644ef3ffc688766744db51c2'}, 'duration': 1.0501940250396729, 'iteration': 9, 'loss': 0.053333333333333344, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_SelectKBest', {'features__k': 1}), 'normalizer': ('normalizer_RobustScaler', {'normalizer__quantile_range': (...), 'normalizer__with_centering': True, 'normalizer__with_scaling': True}), 'rebalance': ('rebalance_NearMiss', {'rebalance__n_neighbors': 2})}, 'score': 0.9466666666666667, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'entropy', 'max_depth': 3, 'max_features': None, 'max_leaf_nodes': 3, 'min_samples_split': 2, 'n_estimators': 100}, 'config_hash': {'algorithm': 'dbc1b8126649fe93dce5fbb37e4015b0acfb179e', 'config': '9913cd550615a9d0946ab4a755a8b9f619e442fd', 'pipeline': 'dd626121cea079ebb32e184ca65483ec7a6d7f59'}, 'duration': 1.120617151260376, 'iteration': 10, 'loss': 0.046666666666666634, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 2, 'features__selectkbest__k': 1}), 'normalizer': ('normalizer_MinMaxScaler', {}), 'rebalance': ('rebalance_NoneType', {})}, 'score': 0.9533333333333334, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'gini', 'max_depth': 3, 'max_features': 3, 'max_leaf_nodes': None, 'min_samples_split': 3, 'n_estimators': 75}, 'config_hash': {'algorithm': '34917a130df5a975f78bd7ec1a0c7b1ffdc787a9', 'config': '95fc8cadc088141290b7de9c388977e4685f0108', 'pipeline': '550d10faf2f08db48516cc3501558816d6a99bc0'}, 'duration': 1.4287099838256836, 'iteration': 11, 'loss': 0.19333333333333313, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 3, 'features__selectkbest__k': 4}), 'normalizer': ('normalizer_StandardScaler', {'normalizer__with_mean': False, 'normalizer__with_std': False}), 'rebalance': ('rebalance_CondensedNearestNeighbour', {'rebalance__n_neighbors': 1})}, 'score': 0.8066666666666669, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'entropy', 'max_depth': 1, 'max_features': 2, 'max_leaf_nodes': 5, 'min_samples_split': 2, 'n_estimators': 75}, 'config_hash': {'algorithm': '33f9abb4aee44a395a9f3b3ffa9ce80a8cdaed7c', 'config': '40fa726f0360cf6af55f9b5902d399d02f61f157', 'pipeline': 'cfd1d20841fe2153da762c95e79f95a3fb1e426a'}, 'duration': 1.2978079319000244, 'iteration': 12, 'loss': 0.053333333333333344, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_PCA', {'features__n_components': 4}), 'normalizer': ('normalizer_MinMaxScaler', {}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 7})}, 'score': 0.9466666666666667, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'entropy', 'max_depth': 4, 'max_features': 2, 'max_leaf_nodes': 5, 'min_samples_split': 3, 'n_estimators': 25}, 'config_hash': {'algorithm': '210111ec6562d09eb093e98ed69ef1c662e11a50', 'config': '0fb8e77c7bd9a58b72f1b33c21a59a09a8c676ba', 'pipeline': '5d269d759e0c7926a685a14b263ace8ae0071e4b'}, 'duration': 0.36649012565612793, 'iteration': 13, 'loss': 0.040000000000000036, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 2, 'features__selectkbest__k': 2}), 'normalizer': ('normalizer_NoneType', {}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 7})}, 'score': 0.96, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'entropy', 'max_depth': 3, 'max_features': 1, 'max_leaf_nodes': 5, 'min_samples_split': 2, 'n_estimators': 25}, 'config_hash': {'algorithm': '0e989a03980101fabf79eda3326ed2870e11d690', 'config': 'f4bffd5d8c67a9c5321a9943c4a99678f59a02b7', 'pipeline': '865ee1e3fe8334c3d5ecb2038d5a5d1b3ba50e75'}, 'duration': 0.35639500617980957, 'iteration': 14, 'loss': 0.046666666666666634, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_NoneType', {}), 'normalizer': ('normalizer_RobustScaler', {'normalizer__quantile_range': (...), 'normalizer__with_centering': True, 'normalizer__with_scaling': False}), 'rebalance': ('rebalance_NoneType', {})}, 'score': 0.9533333333333334, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'entropy', 'max_depth': None, 'max_features': 3, 'max_leaf_nodes': 3, 'min_samples_split': 5, 'n_estimators': 10}, 'config_hash': {'algorithm': '9c592e876c13de5e23e6de5b868e01755d63e72e', 'config': '1e6a68cd1eeac886d90724d78b1cb5fb76a3cde4', 'pipeline': '5a1ca4d82f21b7de0d2c918630a42510673fa36e'}, 'duration': 0.18141412734985352, 'iteration': 15, 'loss': 0.046666666666666634, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_SelectKBest', {'features__k': 3}), 'normalizer': ('normalizer_RobustScaler', {'normalizer__quantile_range': (...), 'normalizer__with_centering': True, 'normalizer__with_scaling': True}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 6})}, 'score': 0.9533333333333334, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': 1, 'max_features': None, 'max_leaf_nodes': None, 'min_samples_split': 5, 'n_estimators': 10}, 'config_hash': {'algorithm': '8bed77aef289bfd453b2858bd288ae5ba7160f2b', 'config': '781185bcb8999045de8d489f253a1a1ba4247932', 'pipeline': '1ece7eabedc2be9e5b0a1be65c570d08ffa3eb54'}, 'duration': 0.1636829376220703, 'iteration': 16, 'loss': 0.053333333333333344, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_NoneType', {}), 'normalizer': ('normalizer_NoneType', {}), 'rebalance': ('rebalance_NearMiss', {'rebalance__n_neighbors': 1})}, 'score': 0.9466666666666667, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'gini', 'max_depth': 3, 'max_features': 2, 'max_leaf_nodes': 2, 'min_samples_split': 5, 'n_estimators': 75}, 'config_hash': {'algorithm': '617b97d9ba21d3373bc51ffa9cccf9c6f91a77b3', 'config': '99fb425b4e8c5d80228cab94202252aa25cdf77c', 'pipeline': 'd6242929c3b515c7719e60423023ac604311afc3'}, 'duration': 0.8468999862670898, 'iteration': 17, 'loss': 0.24, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_PCA', {'features__n_components': 4}), 'normalizer': ('normalizer_PowerTransformer', {}), 'rebalance': ('rebalance_NearMiss', {'rebalance__n_neighbors': 2})}, 'score': 0.76, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': 1, 'max_features': 1, 'max_leaf_nodes': 2, 'min_samples_split': 5, 'n_estimators': 50}, 'config_hash': {'algorithm': 'b92d2697cdd4979da443369d6596229ec091626a', 'config': 'c513a3e13281206ad76187dd817b1fff93d54fe1', 'pipeline': 'c4b4f914a3ca8df967cade997a90366d85a371b9'}, 'duration': 0.6724588871002197, 'iteration': 18, 'loss': 0.23333333333333328, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 1, 'features__selectkbest__k': 3}), 'normalizer': ('normalizer_StandardScaler', {'normalizer__with_mean': True, 'normalizer__with_std': True}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 5})}, 'score': 0.7666666666666667, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'entropy', 'max_depth': None, 'max_features': None, 'max_leaf_nodes': 5, 'min_samples_split': 5, 'n_estimators': 10}, 'config_hash': {'algorithm': 'a0115de695e6cca2e81cbfb54df79bf4b43608b1', 'config': 'ba194015e20b5d67770e8c67342c3d8d0d01dc41', 'pipeline': '8d45fabfeb85ffdcabf7076bd0e65fffe97ce928'}, 'duration': 0.19424200057983398, 'iteration': 19, 'loss': 0.08666666666666667, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_PCA', {'features__n_components': 3}), 'normalizer': ('normalizer_NoneType', {}), 'rebalance': ('rebalance_NoneType', {})}, 'score': 0.9133333333333333, ...}, ...], 'history_hash': ['db6ac7e6d348155757e4794bb5f88fe2b4f63d50', '4db6fb84d85f52659f780e682ffac5712c3d8a94', '4403c5a85e951938d3c454e961d3a412780722f6', 'a064e2df18ab98d44dabcefbc7bed94913f1d0be', '0ddb6f5cab3db4dddd7682966a57205f3e329ad4', '49f25751bca61cdd461a8cbd2923689b642f98ed', '5c3a2b6f5e63fb45f10e41e0318b354912ec44f6', 'd3b129b397350f1b6572651c67c01de49b4b174c', '813bde1108cc3c4b9bfb3a22cbb421bda7eac671', '31930b6860ed406d59bf7e59ba1925d94704bd3b', '9913cd550615a9d0946ab4a755a8b9f619e442fd', '95fc8cadc088141290b7de9c388977e4685f0108', '40fa726f0360cf6af55f9b5902d399d02f61f157', '0fb8e77c7bd9a58b72f1b33c21a59a09a8c676ba', 'f4bffd5d8c67a9c5321a9943c4a99678f59a02b7', '1e6a68cd1eeac886d90724d78b1cb5fb76a3cde4', '781185bcb8999045de8d489f253a1a1ba4247932', '99fb425b4e8c5d80228cab94202252aa25cdf77c', 'c513a3e13281206ad76187dd817b1fff93d54fe1', 'ba194015e20b5d67770e8c67342c3d8d0d01dc41', ...], 'history_index': {'0ddb6f5cab3db4dddd7682966a57205f3e329ad4': 4, '0fb8e77c7bd9a58b72f1b33c21a59a09a8c676ba': 13, '156cf80babab134353766c500267028d67005289': 20, '1e6a68cd1eeac886d90724d78b1cb5fb76a3cde4': 15, '31930b6860ed406d59bf7e59ba1925d94704bd3b': 9, '40fa726f0360cf6af55f9b5902d399d02f61f157': 12, '4403c5a85e951938d3c454e961d3a412780722f6': 2, '49f25751bca61cdd461a8cbd2923689b642f98ed': 5, '4db6fb84d85f52659f780e682ffac5712c3d8a94': 1, '5c3a2b6f5e63fb45f10e41e0318b354912ec44f6': 6, ...}, 'iteration': 20, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint'}, config={'algorithm': 'RandomForest', 'seed': 42, 'time': 300})
    108 
    109 def objective_algo(algo_config, current_pipeline_config, algorithm, X, y, context, config):
    110     return objective(current_pipeline_config, algo_config, algorithm, X, y, context, config, step='algorithm')
    111 
    112 def objective_joint(wconfig, algorithm, X, y, context, config):
--> 113     return objective(wconfig['pipeline'], wconfig['algorithm'], algorithm, X, y, context, config, step='joint')
        wconfig = {'algorithm': {'bootstrap': True, 'criterion': 'entropy', 'max_depth': 4, 'max_features': 2, 'max_leaf_nodes': None, 'min_samples_split': 3, 'n_estimators': 25}, 'pipeline': {'features': ('features_PCA', {'features__n_components': 1}), 'normalizer': ('normalizer_MinMaxScaler', {}), 'rebalance': ('rebalance_NoneType', {})}}
        algorithm = 'RandomForest'
        X = array([[5.1, 3.5, 1.4, 0.2],
       [4.9, 3. , 1....2, 3.4, 5.4, 2.3],
       [5.9, 3. , 5.1, 1.8]])
        y = array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,... 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2])
        context = {'baseline_score': 0.9466666666666667, 'baseline_score_std': 0.04988876515698587, 'best_config': {'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': 1, 'max_features': None, 'max_leaf_nodes': None, 'min_samples_split': 5, 'n_estimators': 75}, 'config_hash': {'algorithm': '94b0d7a654c508cc63643f78fe4f0f07e6f07c1e', 'config': '4403c5a85e951938d3c454e961d3a412780722f6', 'pipeline': '3e47444880d8367fbac2faaba2e52a917274aa58'}, 'duration': 0.8397619724273682, 'iteration': 2, 'loss': 0.03333333333333344, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_PCA', {'features__n_components': 3}), 'normalizer': ('normalizer_MinMaxScaler', {}), 'rebalance': ('rebalance_NoneType', {})}, 'score': 0.9666666666666666, ...}, 'history': [{'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': 2, 'max_features': None, 'max_leaf_nodes': 5, 'min_samples_split': 2, 'n_estimators': 75}, 'config_hash': {'algorithm': '3af5b0cce71c8fe2545246ca24ff5bc3dd516e06', 'config': 'db6ac7e6d348155757e4794bb5f88fe2b4f63d50', 'pipeline': '8d59f4b94cef6be9306ed86a22a9570fa670d567'}, 'duration': 1.149928092956543, 'iteration': 0, 'loss': 0.046666666666666634, 'max_history_score': 0.9533333333333334, 'max_history_score_std': 0.059999999999999984, 'max_history_step': 'joint', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 4, 'features__selectkbest__k': 3}), 'normalizer': ('normalizer_StandardScaler', {'normalizer__with_mean': True, 'normalizer__with_std': True}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 6})}, 'score': 0.9533333333333334, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': 1, 'max_features': 2, 'max_leaf_nodes': 2, 'min_samples_split': 5, 'n_estimators': 100}, 'config_hash': {'algorithm': 'e13eb05fd9a62d2f63bbb1c1deff0cd620d5e6ab', 'config': '4db6fb84d85f52659f780e682ffac5712c3d8a94', 'pipeline': '64c9a1ca9d53ae67244bdd942f4db36a3c05218c'}, 'duration': 1.7678282260894775, 'iteration': 1, 'loss': 0.18000000000000005, 'max_history_score': 0.9533333333333334, 'max_history_score_std': 0.059999999999999984, 'max_history_step': 'joint', 'pipeline': {'features': ('features_NoneType', {}), 'normalizer': ('normalizer_PowerTransformer', {}), 'rebalance': ('rebalance_NearMiss', {'rebalance__n_neighbors': 1})}, 'score': 0.82, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': 1, 'max_features': None, 'max_leaf_nodes': None, 'min_samples_split': 5, 'n_estimators': 75}, 'config_hash': {'algorithm': '94b0d7a654c508cc63643f78fe4f0f07e6f07c1e', 'config': '4403c5a85e951938d3c454e961d3a412780722f6', 'pipeline': '3e47444880d8367fbac2faaba2e52a917274aa58'}, 'duration': 0.8397619724273682, 'iteration': 2, 'loss': 0.03333333333333344, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_PCA', {'features__n_components': 3}), 'normalizer': ('normalizer_MinMaxScaler', {}), 'rebalance': ('rebalance_NoneType', {})}, 'score': 0.9666666666666666, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': None, 'max_features': None, 'max_leaf_nodes': 3, 'min_samples_split': 3, 'n_estimators': 75}, 'config_hash': {'algorithm': 'e8332f0a8902bda03bf70e7978cc5d52affb29d3', 'config': 'a064e2df18ab98d44dabcefbc7bed94913f1d0be', 'pipeline': '7eea819c2a8c103c4b1e9e9c1e224aebba95081f'}, 'duration': 0.8501448631286621, 'iteration': 3, 'loss': 0.053333333333333344, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 2, 'features__selectkbest__k': 4}), 'normalizer': ('normalizer_NoneType', {}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 7})}, 'score': 0.9466666666666667, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'entropy', 'max_depth': 3, 'max_features': 3, 'max_leaf_nodes': None, 'min_samples_split': 5, 'n_estimators': 75}, 'config_hash': {'algorithm': '7a4491035bc6bd737fe9a8cda8a79a02d02d5c74', 'config': '0ddb6f5cab3db4dddd7682966a57205f3e329ad4', 'pipeline': 'a9ae03fe38334f6868cbf84cdd3d629d4bbe3fb0'}, 'duration': 1.1026010513305664, 'iteration': 4, 'loss': 0.05999999999999994, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 2, 'features__selectkbest__k': 1}), 'normalizer': ('normalizer_NoneType', {}), 'rebalance': ('rebalance_NoneType', {})}, 'score': 0.9400000000000001, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'gini', 'max_depth': 3, 'max_features': 1, 'max_leaf_nodes': 5, 'min_samples_split': 2, 'n_estimators': 25}, 'config_hash': {'algorithm': '9826d20b2d6a0f559cf7f16450ce7526f07e8434', 'config': '49f25751bca61cdd461a8cbd2923689b642f98ed', 'pipeline': '19b249664c5bf067de1fed4334a296f947ce774a'}, 'duration': 0.35647010803222656, 'iteration': 5, 'loss': 0.046666666666666634, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_NoneType', {}), 'normalizer': ('normalizer_NoneType', {}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 6})}, 'score': 0.9533333333333334, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'gini', 'max_depth': 2, 'max_features': 1, 'max_leaf_nodes': 2, 'min_samples_split': 2, 'n_estimators': 50}, 'config_hash': {'algorithm': '0a4f6fbb07e0f32c6f675489a0fc82eee05bd8e1', 'config': '5c3a2b6f5e63fb45f10e41e0318b354912ec44f6', 'pipeline': 'dc3b9f176f090005e38b142f11d80e93a7dc5d5e'}, 'duration': 0.7213859558105469, 'iteration': 6, 'loss': 0.31333333333333324, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 1, 'features__selectkbest__k': 4}), 'normalizer': ('normalizer_PowerTransformer', {}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 7})}, 'score': 0.6866666666666668, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'entropy', 'max_depth': 4, 'max_features': 3, 'max_leaf_nodes': 5, 'min_samples_split': 5, 'n_estimators': 10}, 'config_hash': {'algorithm': 'b8112b97ecfc10f00a195af661dcc861cac21289', 'config': 'd3b129b397350f1b6572651c67c01de49b4b174c', 'pipeline': '5b0357ed7072c37b3d6f458bb5d49ff7d825f603'}, 'duration': 0.8299109935760498, 'iteration': 7, 'loss': 1.0, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_PCA', {'features__n_components': 2}), 'normalizer': ('normalizer_StandardScaler', {'normalizer__with_mean': True, 'normalizer__with_std': False}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 6})}, 'score': 0.0, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'gini', 'max_depth': 4, 'max_features': None, 'max_leaf_nodes': 2, 'min_samples_split': 5, 'n_estimators': 100}, 'config_hash': {'algorithm': '40ca24df19b8d164d9d098a6bed1ce056fbbb961', 'config': '813bde1108cc3c4b9bfb3a22cbb421bda7eac671', 'pipeline': '74a7b8705a1c22f7dea5e44e4ebda8f1e48add71'}, 'duration': 2.2111589908599854, 'iteration': 8, 'loss': 0.33333333333333326, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_PCA', {'features__n_components': 2}), 'normalizer': ('normalizer_StandardScaler', {'normalizer__with_mean': False, 'normalizer__with_std': True}), 'rebalance': ('rebalance_NearMiss', {'rebalance__n_neighbors': 2})}, 'score': 0.6666666666666667, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'entropy', 'max_depth': 2, 'max_features': 1, 'max_leaf_nodes': 5, 'min_samples_split': 2, 'n_estimators': 100}, 'config_hash': {'algorithm': '331418a5c12cf1453876eef85e9d98fc8e54fa11', 'config': '31930b6860ed406d59bf7e59ba1925d94704bd3b', 'pipeline': '054bef356f90ec6f644ef3ffc688766744db51c2'}, 'duration': 1.0501940250396729, 'iteration': 9, 'loss': 0.053333333333333344, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_SelectKBest', {'features__k': 1}), 'normalizer': ('normalizer_RobustScaler', {'normalizer__quantile_range': (...), 'normalizer__with_centering': True, 'normalizer__with_scaling': True}), 'rebalance': ('rebalance_NearMiss', {'rebalance__n_neighbors': 2})}, 'score': 0.9466666666666667, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'entropy', 'max_depth': 3, 'max_features': None, 'max_leaf_nodes': 3, 'min_samples_split': 2, 'n_estimators': 100}, 'config_hash': {'algorithm': 'dbc1b8126649fe93dce5fbb37e4015b0acfb179e', 'config': '9913cd550615a9d0946ab4a755a8b9f619e442fd', 'pipeline': 'dd626121cea079ebb32e184ca65483ec7a6d7f59'}, 'duration': 1.120617151260376, 'iteration': 10, 'loss': 0.046666666666666634, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 2, 'features__selectkbest__k': 1}), 'normalizer': ('normalizer_MinMaxScaler', {}), 'rebalance': ('rebalance_NoneType', {})}, 'score': 0.9533333333333334, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'gini', 'max_depth': 3, 'max_features': 3, 'max_leaf_nodes': None, 'min_samples_split': 3, 'n_estimators': 75}, 'config_hash': {'algorithm': '34917a130df5a975f78bd7ec1a0c7b1ffdc787a9', 'config': '95fc8cadc088141290b7de9c388977e4685f0108', 'pipeline': '550d10faf2f08db48516cc3501558816d6a99bc0'}, 'duration': 1.4287099838256836, 'iteration': 11, 'loss': 0.19333333333333313, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 3, 'features__selectkbest__k': 4}), 'normalizer': ('normalizer_StandardScaler', {'normalizer__with_mean': False, 'normalizer__with_std': False}), 'rebalance': ('rebalance_CondensedNearestNeighbour', {'rebalance__n_neighbors': 1})}, 'score': 0.8066666666666669, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'entropy', 'max_depth': 1, 'max_features': 2, 'max_leaf_nodes': 5, 'min_samples_split': 2, 'n_estimators': 75}, 'config_hash': {'algorithm': '33f9abb4aee44a395a9f3b3ffa9ce80a8cdaed7c', 'config': '40fa726f0360cf6af55f9b5902d399d02f61f157', 'pipeline': 'cfd1d20841fe2153da762c95e79f95a3fb1e426a'}, 'duration': 1.2978079319000244, 'iteration': 12, 'loss': 0.053333333333333344, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_PCA', {'features__n_components': 4}), 'normalizer': ('normalizer_MinMaxScaler', {}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 7})}, 'score': 0.9466666666666667, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'entropy', 'max_depth': 4, 'max_features': 2, 'max_leaf_nodes': 5, 'min_samples_split': 3, 'n_estimators': 25}, 'config_hash': {'algorithm': '210111ec6562d09eb093e98ed69ef1c662e11a50', 'config': '0fb8e77c7bd9a58b72f1b33c21a59a09a8c676ba', 'pipeline': '5d269d759e0c7926a685a14b263ace8ae0071e4b'}, 'duration': 0.36649012565612793, 'iteration': 13, 'loss': 0.040000000000000036, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 2, 'features__selectkbest__k': 2}), 'normalizer': ('normalizer_NoneType', {}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 7})}, 'score': 0.96, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'entropy', 'max_depth': 3, 'max_features': 1, 'max_leaf_nodes': 5, 'min_samples_split': 2, 'n_estimators': 25}, 'config_hash': {'algorithm': '0e989a03980101fabf79eda3326ed2870e11d690', 'config': 'f4bffd5d8c67a9c5321a9943c4a99678f59a02b7', 'pipeline': '865ee1e3fe8334c3d5ecb2038d5a5d1b3ba50e75'}, 'duration': 0.35639500617980957, 'iteration': 14, 'loss': 0.046666666666666634, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_NoneType', {}), 'normalizer': ('normalizer_RobustScaler', {'normalizer__quantile_range': (...), 'normalizer__with_centering': True, 'normalizer__with_scaling': False}), 'rebalance': ('rebalance_NoneType', {})}, 'score': 0.9533333333333334, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'entropy', 'max_depth': None, 'max_features': 3, 'max_leaf_nodes': 3, 'min_samples_split': 5, 'n_estimators': 10}, 'config_hash': {'algorithm': '9c592e876c13de5e23e6de5b868e01755d63e72e', 'config': '1e6a68cd1eeac886d90724d78b1cb5fb76a3cde4', 'pipeline': '5a1ca4d82f21b7de0d2c918630a42510673fa36e'}, 'duration': 0.18141412734985352, 'iteration': 15, 'loss': 0.046666666666666634, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_SelectKBest', {'features__k': 3}), 'normalizer': ('normalizer_RobustScaler', {'normalizer__quantile_range': (...), 'normalizer__with_centering': True, 'normalizer__with_scaling': True}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 6})}, 'score': 0.9533333333333334, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': 1, 'max_features': None, 'max_leaf_nodes': None, 'min_samples_split': 5, 'n_estimators': 10}, 'config_hash': {'algorithm': '8bed77aef289bfd453b2858bd288ae5ba7160f2b', 'config': '781185bcb8999045de8d489f253a1a1ba4247932', 'pipeline': '1ece7eabedc2be9e5b0a1be65c570d08ffa3eb54'}, 'duration': 0.1636829376220703, 'iteration': 16, 'loss': 0.053333333333333344, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_NoneType', {}), 'normalizer': ('normalizer_NoneType', {}), 'rebalance': ('rebalance_NearMiss', {'rebalance__n_neighbors': 1})}, 'score': 0.9466666666666667, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'gini', 'max_depth': 3, 'max_features': 2, 'max_leaf_nodes': 2, 'min_samples_split': 5, 'n_estimators': 75}, 'config_hash': {'algorithm': '617b97d9ba21d3373bc51ffa9cccf9c6f91a77b3', 'config': '99fb425b4e8c5d80228cab94202252aa25cdf77c', 'pipeline': 'd6242929c3b515c7719e60423023ac604311afc3'}, 'duration': 0.8468999862670898, 'iteration': 17, 'loss': 0.24, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_PCA', {'features__n_components': 4}), 'normalizer': ('normalizer_PowerTransformer', {}), 'rebalance': ('rebalance_NearMiss', {'rebalance__n_neighbors': 2})}, 'score': 0.76, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': 1, 'max_features': 1, 'max_leaf_nodes': 2, 'min_samples_split': 5, 'n_estimators': 50}, 'config_hash': {'algorithm': 'b92d2697cdd4979da443369d6596229ec091626a', 'config': 'c513a3e13281206ad76187dd817b1fff93d54fe1', 'pipeline': 'c4b4f914a3ca8df967cade997a90366d85a371b9'}, 'duration': 0.6724588871002197, 'iteration': 18, 'loss': 0.23333333333333328, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 1, 'features__selectkbest__k': 3}), 'normalizer': ('normalizer_StandardScaler', {'normalizer__with_mean': True, 'normalizer__with_std': True}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 5})}, 'score': 0.7666666666666667, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'entropy', 'max_depth': None, 'max_features': None, 'max_leaf_nodes': 5, 'min_samples_split': 5, 'n_estimators': 10}, 'config_hash': {'algorithm': 'a0115de695e6cca2e81cbfb54df79bf4b43608b1', 'config': 'ba194015e20b5d67770e8c67342c3d8d0d01dc41', 'pipeline': '8d45fabfeb85ffdcabf7076bd0e65fffe97ce928'}, 'duration': 0.19424200057983398, 'iteration': 19, 'loss': 0.08666666666666667, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_PCA', {'features__n_components': 3}), 'normalizer': ('normalizer_NoneType', {}), 'rebalance': ('rebalance_NoneType', {})}, 'score': 0.9133333333333333, ...}, ...], 'history_hash': ['db6ac7e6d348155757e4794bb5f88fe2b4f63d50', '4db6fb84d85f52659f780e682ffac5712c3d8a94', '4403c5a85e951938d3c454e961d3a412780722f6', 'a064e2df18ab98d44dabcefbc7bed94913f1d0be', '0ddb6f5cab3db4dddd7682966a57205f3e329ad4', '49f25751bca61cdd461a8cbd2923689b642f98ed', '5c3a2b6f5e63fb45f10e41e0318b354912ec44f6', 'd3b129b397350f1b6572651c67c01de49b4b174c', '813bde1108cc3c4b9bfb3a22cbb421bda7eac671', '31930b6860ed406d59bf7e59ba1925d94704bd3b', '9913cd550615a9d0946ab4a755a8b9f619e442fd', '95fc8cadc088141290b7de9c388977e4685f0108', '40fa726f0360cf6af55f9b5902d399d02f61f157', '0fb8e77c7bd9a58b72f1b33c21a59a09a8c676ba', 'f4bffd5d8c67a9c5321a9943c4a99678f59a02b7', '1e6a68cd1eeac886d90724d78b1cb5fb76a3cde4', '781185bcb8999045de8d489f253a1a1ba4247932', '99fb425b4e8c5d80228cab94202252aa25cdf77c', 'c513a3e13281206ad76187dd817b1fff93d54fe1', 'ba194015e20b5d67770e8c67342c3d8d0d01dc41', ...], 'history_index': {'0ddb6f5cab3db4dddd7682966a57205f3e329ad4': 4, '0fb8e77c7bd9a58b72f1b33c21a59a09a8c676ba': 13, '156cf80babab134353766c500267028d67005289': 20, '1e6a68cd1eeac886d90724d78b1cb5fb76a3cde4': 15, '31930b6860ed406d59bf7e59ba1925d94704bd3b': 9, '40fa726f0360cf6af55f9b5902d399d02f61f157': 12, '4403c5a85e951938d3c454e961d3a412780722f6': 2, '49f25751bca61cdd461a8cbd2923689b642f98ed': 5, '4db6fb84d85f52659f780e682ffac5712c3d8a94': 1, '5c3a2b6f5e63fb45f10e41e0318b354912ec44f6': 6, ...}, 'iteration': 20, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint'}
        config = {'algorithm': 'RandomForest', 'seed': 42, 'time': 300}
    114 
    115 
    116 def get_baseline_score(algorithm, X, y, seed):
    117     pipeline, _ = pipeline_conf_to_full_pipeline(

...........................................................................
/home/aquemy/dev/dp_hyperparameters/extension/experiment/objective.py in objective(pipeline_config={'features': ('features_PCA', {'features__n_components': 1}), 'normalizer': ('normalizer_MinMaxScaler', {}), 'rebalance': ('rebalance_NoneType', {})}, algo_config={'bootstrap': True, 'criterion': 'entropy', 'max_depth': 4, 'max_features': 2, 'max_leaf_nodes': None, 'min_samples_split': 3, 'n_estimators': 25}, algorithm='RandomForest', X=array([[5.1, 3.5, 1.4, 0.2],
       [4.9, 3. , 1....2, 3.4, 5.4, 2.3],
       [5.9, 3. , 5.1, 1.8]]), y=array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,... 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]), context={'baseline_score': 0.9466666666666667, 'baseline_score_std': 0.04988876515698587, 'best_config': {'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': 1, 'max_features': None, 'max_leaf_nodes': None, 'min_samples_split': 5, 'n_estimators': 75}, 'config_hash': {'algorithm': '94b0d7a654c508cc63643f78fe4f0f07e6f07c1e', 'config': '4403c5a85e951938d3c454e961d3a412780722f6', 'pipeline': '3e47444880d8367fbac2faaba2e52a917274aa58'}, 'duration': 0.8397619724273682, 'iteration': 2, 'loss': 0.03333333333333344, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_PCA', {'features__n_components': 3}), 'normalizer': ('normalizer_MinMaxScaler', {}), 'rebalance': ('rebalance_NoneType', {})}, 'score': 0.9666666666666666, ...}, 'history': [{'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': 2, 'max_features': None, 'max_leaf_nodes': 5, 'min_samples_split': 2, 'n_estimators': 75}, 'config_hash': {'algorithm': '3af5b0cce71c8fe2545246ca24ff5bc3dd516e06', 'config': 'db6ac7e6d348155757e4794bb5f88fe2b4f63d50', 'pipeline': '8d59f4b94cef6be9306ed86a22a9570fa670d567'}, 'duration': 1.149928092956543, 'iteration': 0, 'loss': 0.046666666666666634, 'max_history_score': 0.9533333333333334, 'max_history_score_std': 0.059999999999999984, 'max_history_step': 'joint', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 4, 'features__selectkbest__k': 3}), 'normalizer': ('normalizer_StandardScaler', {'normalizer__with_mean': True, 'normalizer__with_std': True}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 6})}, 'score': 0.9533333333333334, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': 1, 'max_features': 2, 'max_leaf_nodes': 2, 'min_samples_split': 5, 'n_estimators': 100}, 'config_hash': {'algorithm': 'e13eb05fd9a62d2f63bbb1c1deff0cd620d5e6ab', 'config': '4db6fb84d85f52659f780e682ffac5712c3d8a94', 'pipeline': '64c9a1ca9d53ae67244bdd942f4db36a3c05218c'}, 'duration': 1.7678282260894775, 'iteration': 1, 'loss': 0.18000000000000005, 'max_history_score': 0.9533333333333334, 'max_history_score_std': 0.059999999999999984, 'max_history_step': 'joint', 'pipeline': {'features': ('features_NoneType', {}), 'normalizer': ('normalizer_PowerTransformer', {}), 'rebalance': ('rebalance_NearMiss', {'rebalance__n_neighbors': 1})}, 'score': 0.82, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': 1, 'max_features': None, 'max_leaf_nodes': None, 'min_samples_split': 5, 'n_estimators': 75}, 'config_hash': {'algorithm': '94b0d7a654c508cc63643f78fe4f0f07e6f07c1e', 'config': '4403c5a85e951938d3c454e961d3a412780722f6', 'pipeline': '3e47444880d8367fbac2faaba2e52a917274aa58'}, 'duration': 0.8397619724273682, 'iteration': 2, 'loss': 0.03333333333333344, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_PCA', {'features__n_components': 3}), 'normalizer': ('normalizer_MinMaxScaler', {}), 'rebalance': ('rebalance_NoneType', {})}, 'score': 0.9666666666666666, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': None, 'max_features': None, 'max_leaf_nodes': 3, 'min_samples_split': 3, 'n_estimators': 75}, 'config_hash': {'algorithm': 'e8332f0a8902bda03bf70e7978cc5d52affb29d3', 'config': 'a064e2df18ab98d44dabcefbc7bed94913f1d0be', 'pipeline': '7eea819c2a8c103c4b1e9e9c1e224aebba95081f'}, 'duration': 0.8501448631286621, 'iteration': 3, 'loss': 0.053333333333333344, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 2, 'features__selectkbest__k': 4}), 'normalizer': ('normalizer_NoneType', {}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 7})}, 'score': 0.9466666666666667, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'entropy', 'max_depth': 3, 'max_features': 3, 'max_leaf_nodes': None, 'min_samples_split': 5, 'n_estimators': 75}, 'config_hash': {'algorithm': '7a4491035bc6bd737fe9a8cda8a79a02d02d5c74', 'config': '0ddb6f5cab3db4dddd7682966a57205f3e329ad4', 'pipeline': 'a9ae03fe38334f6868cbf84cdd3d629d4bbe3fb0'}, 'duration': 1.1026010513305664, 'iteration': 4, 'loss': 0.05999999999999994, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 2, 'features__selectkbest__k': 1}), 'normalizer': ('normalizer_NoneType', {}), 'rebalance': ('rebalance_NoneType', {})}, 'score': 0.9400000000000001, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'gini', 'max_depth': 3, 'max_features': 1, 'max_leaf_nodes': 5, 'min_samples_split': 2, 'n_estimators': 25}, 'config_hash': {'algorithm': '9826d20b2d6a0f559cf7f16450ce7526f07e8434', 'config': '49f25751bca61cdd461a8cbd2923689b642f98ed', 'pipeline': '19b249664c5bf067de1fed4334a296f947ce774a'}, 'duration': 0.35647010803222656, 'iteration': 5, 'loss': 0.046666666666666634, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_NoneType', {}), 'normalizer': ('normalizer_NoneType', {}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 6})}, 'score': 0.9533333333333334, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'gini', 'max_depth': 2, 'max_features': 1, 'max_leaf_nodes': 2, 'min_samples_split': 2, 'n_estimators': 50}, 'config_hash': {'algorithm': '0a4f6fbb07e0f32c6f675489a0fc82eee05bd8e1', 'config': '5c3a2b6f5e63fb45f10e41e0318b354912ec44f6', 'pipeline': 'dc3b9f176f090005e38b142f11d80e93a7dc5d5e'}, 'duration': 0.7213859558105469, 'iteration': 6, 'loss': 0.31333333333333324, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 1, 'features__selectkbest__k': 4}), 'normalizer': ('normalizer_PowerTransformer', {}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 7})}, 'score': 0.6866666666666668, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'entropy', 'max_depth': 4, 'max_features': 3, 'max_leaf_nodes': 5, 'min_samples_split': 5, 'n_estimators': 10}, 'config_hash': {'algorithm': 'b8112b97ecfc10f00a195af661dcc861cac21289', 'config': 'd3b129b397350f1b6572651c67c01de49b4b174c', 'pipeline': '5b0357ed7072c37b3d6f458bb5d49ff7d825f603'}, 'duration': 0.8299109935760498, 'iteration': 7, 'loss': 1.0, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_PCA', {'features__n_components': 2}), 'normalizer': ('normalizer_StandardScaler', {'normalizer__with_mean': True, 'normalizer__with_std': False}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 6})}, 'score': 0.0, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'gini', 'max_depth': 4, 'max_features': None, 'max_leaf_nodes': 2, 'min_samples_split': 5, 'n_estimators': 100}, 'config_hash': {'algorithm': '40ca24df19b8d164d9d098a6bed1ce056fbbb961', 'config': '813bde1108cc3c4b9bfb3a22cbb421bda7eac671', 'pipeline': '74a7b8705a1c22f7dea5e44e4ebda8f1e48add71'}, 'duration': 2.2111589908599854, 'iteration': 8, 'loss': 0.33333333333333326, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_PCA', {'features__n_components': 2}), 'normalizer': ('normalizer_StandardScaler', {'normalizer__with_mean': False, 'normalizer__with_std': True}), 'rebalance': ('rebalance_NearMiss', {'rebalance__n_neighbors': 2})}, 'score': 0.6666666666666667, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'entropy', 'max_depth': 2, 'max_features': 1, 'max_leaf_nodes': 5, 'min_samples_split': 2, 'n_estimators': 100}, 'config_hash': {'algorithm': '331418a5c12cf1453876eef85e9d98fc8e54fa11', 'config': '31930b6860ed406d59bf7e59ba1925d94704bd3b', 'pipeline': '054bef356f90ec6f644ef3ffc688766744db51c2'}, 'duration': 1.0501940250396729, 'iteration': 9, 'loss': 0.053333333333333344, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_SelectKBest', {'features__k': 1}), 'normalizer': ('normalizer_RobustScaler', {'normalizer__quantile_range': (...), 'normalizer__with_centering': True, 'normalizer__with_scaling': True}), 'rebalance': ('rebalance_NearMiss', {'rebalance__n_neighbors': 2})}, 'score': 0.9466666666666667, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'entropy', 'max_depth': 3, 'max_features': None, 'max_leaf_nodes': 3, 'min_samples_split': 2, 'n_estimators': 100}, 'config_hash': {'algorithm': 'dbc1b8126649fe93dce5fbb37e4015b0acfb179e', 'config': '9913cd550615a9d0946ab4a755a8b9f619e442fd', 'pipeline': 'dd626121cea079ebb32e184ca65483ec7a6d7f59'}, 'duration': 1.120617151260376, 'iteration': 10, 'loss': 0.046666666666666634, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 2, 'features__selectkbest__k': 1}), 'normalizer': ('normalizer_MinMaxScaler', {}), 'rebalance': ('rebalance_NoneType', {})}, 'score': 0.9533333333333334, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'gini', 'max_depth': 3, 'max_features': 3, 'max_leaf_nodes': None, 'min_samples_split': 3, 'n_estimators': 75}, 'config_hash': {'algorithm': '34917a130df5a975f78bd7ec1a0c7b1ffdc787a9', 'config': '95fc8cadc088141290b7de9c388977e4685f0108', 'pipeline': '550d10faf2f08db48516cc3501558816d6a99bc0'}, 'duration': 1.4287099838256836, 'iteration': 11, 'loss': 0.19333333333333313, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 3, 'features__selectkbest__k': 4}), 'normalizer': ('normalizer_StandardScaler', {'normalizer__with_mean': False, 'normalizer__with_std': False}), 'rebalance': ('rebalance_CondensedNearestNeighbour', {'rebalance__n_neighbors': 1})}, 'score': 0.8066666666666669, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'entropy', 'max_depth': 1, 'max_features': 2, 'max_leaf_nodes': 5, 'min_samples_split': 2, 'n_estimators': 75}, 'config_hash': {'algorithm': '33f9abb4aee44a395a9f3b3ffa9ce80a8cdaed7c', 'config': '40fa726f0360cf6af55f9b5902d399d02f61f157', 'pipeline': 'cfd1d20841fe2153da762c95e79f95a3fb1e426a'}, 'duration': 1.2978079319000244, 'iteration': 12, 'loss': 0.053333333333333344, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_PCA', {'features__n_components': 4}), 'normalizer': ('normalizer_MinMaxScaler', {}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 7})}, 'score': 0.9466666666666667, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'entropy', 'max_depth': 4, 'max_features': 2, 'max_leaf_nodes': 5, 'min_samples_split': 3, 'n_estimators': 25}, 'config_hash': {'algorithm': '210111ec6562d09eb093e98ed69ef1c662e11a50', 'config': '0fb8e77c7bd9a58b72f1b33c21a59a09a8c676ba', 'pipeline': '5d269d759e0c7926a685a14b263ace8ae0071e4b'}, 'duration': 0.36649012565612793, 'iteration': 13, 'loss': 0.040000000000000036, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 2, 'features__selectkbest__k': 2}), 'normalizer': ('normalizer_NoneType', {}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 7})}, 'score': 0.96, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'entropy', 'max_depth': 3, 'max_features': 1, 'max_leaf_nodes': 5, 'min_samples_split': 2, 'n_estimators': 25}, 'config_hash': {'algorithm': '0e989a03980101fabf79eda3326ed2870e11d690', 'config': 'f4bffd5d8c67a9c5321a9943c4a99678f59a02b7', 'pipeline': '865ee1e3fe8334c3d5ecb2038d5a5d1b3ba50e75'}, 'duration': 0.35639500617980957, 'iteration': 14, 'loss': 0.046666666666666634, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_NoneType', {}), 'normalizer': ('normalizer_RobustScaler', {'normalizer__quantile_range': (...), 'normalizer__with_centering': True, 'normalizer__with_scaling': False}), 'rebalance': ('rebalance_NoneType', {})}, 'score': 0.9533333333333334, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'entropy', 'max_depth': None, 'max_features': 3, 'max_leaf_nodes': 3, 'min_samples_split': 5, 'n_estimators': 10}, 'config_hash': {'algorithm': '9c592e876c13de5e23e6de5b868e01755d63e72e', 'config': '1e6a68cd1eeac886d90724d78b1cb5fb76a3cde4', 'pipeline': '5a1ca4d82f21b7de0d2c918630a42510673fa36e'}, 'duration': 0.18141412734985352, 'iteration': 15, 'loss': 0.046666666666666634, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_SelectKBest', {'features__k': 3}), 'normalizer': ('normalizer_RobustScaler', {'normalizer__quantile_range': (...), 'normalizer__with_centering': True, 'normalizer__with_scaling': True}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 6})}, 'score': 0.9533333333333334, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': 1, 'max_features': None, 'max_leaf_nodes': None, 'min_samples_split': 5, 'n_estimators': 10}, 'config_hash': {'algorithm': '8bed77aef289bfd453b2858bd288ae5ba7160f2b', 'config': '781185bcb8999045de8d489f253a1a1ba4247932', 'pipeline': '1ece7eabedc2be9e5b0a1be65c570d08ffa3eb54'}, 'duration': 0.1636829376220703, 'iteration': 16, 'loss': 0.053333333333333344, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_NoneType', {}), 'normalizer': ('normalizer_NoneType', {}), 'rebalance': ('rebalance_NearMiss', {'rebalance__n_neighbors': 1})}, 'score': 0.9466666666666667, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'gini', 'max_depth': 3, 'max_features': 2, 'max_leaf_nodes': 2, 'min_samples_split': 5, 'n_estimators': 75}, 'config_hash': {'algorithm': '617b97d9ba21d3373bc51ffa9cccf9c6f91a77b3', 'config': '99fb425b4e8c5d80228cab94202252aa25cdf77c', 'pipeline': 'd6242929c3b515c7719e60423023ac604311afc3'}, 'duration': 0.8468999862670898, 'iteration': 17, 'loss': 0.24, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_PCA', {'features__n_components': 4}), 'normalizer': ('normalizer_PowerTransformer', {}), 'rebalance': ('rebalance_NearMiss', {'rebalance__n_neighbors': 2})}, 'score': 0.76, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': 1, 'max_features': 1, 'max_leaf_nodes': 2, 'min_samples_split': 5, 'n_estimators': 50}, 'config_hash': {'algorithm': 'b92d2697cdd4979da443369d6596229ec091626a', 'config': 'c513a3e13281206ad76187dd817b1fff93d54fe1', 'pipeline': 'c4b4f914a3ca8df967cade997a90366d85a371b9'}, 'duration': 0.6724588871002197, 'iteration': 18, 'loss': 0.23333333333333328, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 1, 'features__selectkbest__k': 3}), 'normalizer': ('normalizer_StandardScaler', {'normalizer__with_mean': True, 'normalizer__with_std': True}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 5})}, 'score': 0.7666666666666667, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'entropy', 'max_depth': None, 'max_features': None, 'max_leaf_nodes': 5, 'min_samples_split': 5, 'n_estimators': 10}, 'config_hash': {'algorithm': 'a0115de695e6cca2e81cbfb54df79bf4b43608b1', 'config': 'ba194015e20b5d67770e8c67342c3d8d0d01dc41', 'pipeline': '8d45fabfeb85ffdcabf7076bd0e65fffe97ce928'}, 'duration': 0.19424200057983398, 'iteration': 19, 'loss': 0.08666666666666667, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_PCA', {'features__n_components': 3}), 'normalizer': ('normalizer_NoneType', {}), 'rebalance': ('rebalance_NoneType', {})}, 'score': 0.9133333333333333, ...}, ...], 'history_hash': ['db6ac7e6d348155757e4794bb5f88fe2b4f63d50', '4db6fb84d85f52659f780e682ffac5712c3d8a94', '4403c5a85e951938d3c454e961d3a412780722f6', 'a064e2df18ab98d44dabcefbc7bed94913f1d0be', '0ddb6f5cab3db4dddd7682966a57205f3e329ad4', '49f25751bca61cdd461a8cbd2923689b642f98ed', '5c3a2b6f5e63fb45f10e41e0318b354912ec44f6', 'd3b129b397350f1b6572651c67c01de49b4b174c', '813bde1108cc3c4b9bfb3a22cbb421bda7eac671', '31930b6860ed406d59bf7e59ba1925d94704bd3b', '9913cd550615a9d0946ab4a755a8b9f619e442fd', '95fc8cadc088141290b7de9c388977e4685f0108', '40fa726f0360cf6af55f9b5902d399d02f61f157', '0fb8e77c7bd9a58b72f1b33c21a59a09a8c676ba', 'f4bffd5d8c67a9c5321a9943c4a99678f59a02b7', '1e6a68cd1eeac886d90724d78b1cb5fb76a3cde4', '781185bcb8999045de8d489f253a1a1ba4247932', '99fb425b4e8c5d80228cab94202252aa25cdf77c', 'c513a3e13281206ad76187dd817b1fff93d54fe1', 'ba194015e20b5d67770e8c67342c3d8d0d01dc41', ...], 'history_index': {'0ddb6f5cab3db4dddd7682966a57205f3e329ad4': 4, '0fb8e77c7bd9a58b72f1b33c21a59a09a8c676ba': 13, '156cf80babab134353766c500267028d67005289': 20, '1e6a68cd1eeac886d90724d78b1cb5fb76a3cde4': 15, '31930b6860ed406d59bf7e59ba1925d94704bd3b': 9, '40fa726f0360cf6af55f9b5902d399d02f61f157': 12, '4403c5a85e951938d3c454e961d3a412780722f6': 2, '49f25751bca61cdd461a8cbd2923689b642f98ed': 5, '4db6fb84d85f52659f780e682ffac5712c3d8a94': 1, '5c3a2b6f5e63fb45f10e41e0318b354912ec44f6': 6, ...}, 'iteration': 20, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint'}, config={'algorithm': 'RandomForest', 'seed': 42, 'time': 300}, step='joint')
     45                 y,
     46                 cv=10,
     47                 n_jobs=-1,
     48                 return_estimator=False,
     49                 return_train_score=False,
---> 50                 verbose=0)
     51         score = np.mean(scores['test_score'])
     52         std = np.std(scores['test_score'])
     53         status = STATUS_OK
     54     except Exception as e:

...........................................................................
/home/aquemy/.local/lib/python2.7/site-packages/sklearn/model_selection/_validation.py in cross_validate(estimator=Pipeline(memory=None,
     steps=[('normalizer',... random_state=42, verbose=0, warm_start=False))]), X=array([[5.1, 3.5, 1.4, 0.2],
       [4.9, 3. , 1....2, 3.4, 5.4, 2.3],
       [5.9, 3. , 5.1, 1.8]]), y=array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,... 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]), groups=None, scoring=None, cv=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1, verbose=0, fit_params=None, pre_dispatch='2*n_jobs', return_train_score=False, return_estimator=False, error_score='raise-deprecating')
    235         delayed(_fit_and_score)(
    236             clone(estimator), X, y, scorers, train, test, verbose, None,
    237             fit_params, return_train_score=return_train_score,
    238             return_times=True, return_estimator=return_estimator,
    239             error_score=error_score)
--> 240         for train, test in cv.split(X, y, groups))
        cv.split = <bound method StratifiedKFold.split of Stratifie...d(n_splits=10, random_state=None, shuffle=False)>
        X = array([[5.1, 3.5, 1.4, 0.2],
       [4.9, 3. , 1....2, 3.4, 5.4, 2.3],
       [5.9, 3. , 5.1, 1.8]])
        y = array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,... 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2])
        groups = None
    241 
    242     zipped_scores = list(zip(*scores))
    243     if return_train_score:
    244         train_scores = zipped_scores.pop(0)

...........................................................................
/home/aquemy/.local/lib/python2.7/site-packages/sklearn/externals/joblib/parallel.py in __call__(self=Parallel(n_jobs=-1), iterable=<generator object <genexpr>>)
    925                 # No need to wait for async callbacks to trigger to
    926                 # consumption.
    927                 self._iterating = False
    928 
    929             with self._backend.retrieval_context():
--> 930                 self.retrieve()
        self.retrieve = <bound method Parallel.retrieve of Parallel(n_jobs=-1)>
    931             # Make sure that we get a last message telling us we are done
    932             elapsed_time = time.time() - self._start_time
    933             self._print('Done %3i out of %3i | elapsed: %s finished',
    934                         (len(self._output), len(self._output),

---------------------------------------------------------------------------
Joblib worker traceback:
---------------------------------------------------------------------------
ValueError                                         Mon Jun 17 13:10:50 2019
PID: 20905                                  Python 2.7.15+: /usr/bin/python
...........................................................................
/home/aquemy/.local/lib/python2.7/site-packages/sklearn/externals/joblib/parallel.py in __call__(self=<sklearn.externals.joblib.parallel.BatchedCalls object>)
    220     def __call__(self):
    221         # Set the default nested backend to self._backend but do not set the
    222         # change the default number of processes to -1
    223         with parallel_backend(self._backend, n_jobs=self._n_jobs):
    224             return [func(*args, **kwargs)
--> 225                     for func, args, kwargs in self.items]
        func = <function _fit_and_score>
        args = (Pipeline(memory=None,
     steps=[('normalizer',... random_state=42, verbose=0, warm_start=False))]), array([[5.1, 3.5, 1.4, 0.2],
       [4.9, 3. , 1....2, 3.4, 5.4, 2.3],
       [5.9, 3. , 5.1, 1.8]]), array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,... 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]), {'score': <function _passthrough_scorer>}, array([  5,   6,   7,   8,   9,  10,  11,  12,  ..., 142, 143, 144,
       145, 146, 147, 148, 149]), array([  0,   1,   2,   3,   4,  50,  51,  52,  53,  54, 100, 101, 102,
       103, 104]), 0, None, None)
        kwargs = {'error_score': 'raise-deprecating', 'return_estimator': False, 'return_times': True, 'return_train_score': False}
        self.items = [(<function _fit_and_score>, (Pipeline(memory=None,
     steps=[('normalizer',... random_state=42, verbose=0, warm_start=False))]), array([[5.1, 3.5, 1.4, 0.2],
       [4.9, 3. , 1....2, 3.4, 5.4, 2.3],
       [5.9, 3. , 5.1, 1.8]]), array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,... 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]), {'score': <function _passthrough_scorer>}, array([  5,   6,   7,   8,   9,  10,  11,  12,  ..., 142, 143, 144,
       145, 146, 147, 148, 149]), array([  0,   1,   2,   3,   4,  50,  51,  52,  53,  54, 100, 101, 102,
       103, 104]), 0, None, None), {'error_score': 'raise-deprecating', 'return_estimator': False, 'return_times': True, 'return_train_score': False})]
    226 
    227     def __len__(self):
    228         return self._size
    229 

...........................................................................
/home/aquemy/.local/lib/python2.7/site-packages/sklearn/model_selection/_validation.py in _fit_and_score(estimator=Pipeline(memory=None,
     steps=[('normalizer',... random_state=42, verbose=0, warm_start=False))]), X=array([[5.1, 3.5, 1.4, 0.2],
       [4.9, 3. , 1....2, 3.4, 5.4, 2.3],
       [5.9, 3. , 5.1, 1.8]]), y=array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,... 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]), scorer={'score': <function _passthrough_scorer>}, train=array([  5,   6,   7,   8,   9,  10,  11,  12,  ..., 142, 143, 144,
       145, 146, 147, 148, 149]), test=array([  0,   1,   2,   3,   4,  50,  51,  52,  53,  54, 100, 101, 102,
       103, 104]), verbose=0, parameters=None, fit_params={}, return_train_score=False, return_parameters=False, return_n_test_samples=False, return_times=True, return_estimator=False, error_score='raise-deprecating')
    523 
    524     try:
    525         if y_train is None:
    526             estimator.fit(X_train, **fit_params)
    527         else:
--> 528             estimator.fit(X_train, y_train, **fit_params)
        estimator.fit = <bound method Pipeline.fit of Pipeline(memory=No...random_state=42, verbose=0, warm_start=False))])>
        X_train = array([[5.4, 3.9, 1.7, 0.4],
       [4.6, 3.4, 1....2, 3.4, 5.4, 2.3],
       [5.9, 3. , 5.1, 1.8]])
        y_train = array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,
       2, 2, 2])
        fit_params = {}
    529 
    530     except Exception as e:
    531         # Note fit time as time until error
    532         fit_time = time.time() - start_time

...........................................................................
/usr/local/lib/python2.7/dist-packages/imblearn/pipeline.py in fit(self=Pipeline(memory=None,
     steps=[('normalizer',... random_state=42, verbose=0, warm_start=False))]), X=array([[5.4, 3.9, 1.7, 0.4],
       [4.6, 3.4, 1....2, 3.4, 5.4, 2.3],
       [5.9, 3. , 5.1, 1.8]]), y=array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,
       2, 2, 2]), **fit_params={})
    234             This estimator
    235 
    236         """
    237         Xt, yt, fit_params = self._fit(X, y, **fit_params)
    238         if self._final_estimator is not None:
--> 239             self._final_estimator.fit(Xt, yt, **fit_params)
        self._final_estimator.fit = <bound method RandomForestClassifier.fit of Rand...e, random_state=42, verbose=0, warm_start=False)>
        Xt = array([[-5.33848470e-01],
       [-6.53381800e-0...    [ 4.89816648e-01],
       [ 3.15349702e-01]])
        yt = array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,
       2, 2, 2])
        fit_params = {}
    240         return self
    241 
    242     def fit_transform(self, X, y=None, **fit_params):
    243         """Fit the model and transform with the final estimator

...........................................................................
/home/aquemy/.local/lib/python2.7/site-packages/sklearn/ensemble/forest.py in fit(self=RandomForestClassifier(bootstrap=True, class_wei...se, random_state=42, verbose=0, warm_start=False), X=array([[-5.33848464e-01],
       [-6.53381824e-0...6e-01],
       [ 3.15349698e-01]], dtype=float32), y=array([[0.],
       [0.],
       [0.],
       [0...    [2.],
       [2.],
       [2.],
       [2.]]), sample_weight=None)
    328             trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,
    329                              **_joblib_parallel_args(prefer='threads'))(
    330                 delayed(_parallel_build_trees)(
    331                     t, self, X, y, sample_weight, i, len(trees),
    332                     verbose=self.verbose, class_weight=self.class_weight)
--> 333                 for i, t in enumerate(trees))
        i = 24
    334 
    335             # Collect newly grown trees
    336             self.estimators_.extend(trees)
    337 

...........................................................................
/home/aquemy/.local/lib/python2.7/site-packages/sklearn/externals/joblib/parallel.py in __call__(self=Parallel(n_jobs=1), iterable=<generator object <genexpr>>)
    912             # self._original_iterator is None, then this means either
    913             # that pre_dispatch == "all", n_jobs == 1 or that the first batch
    914             # was very quick and its callback already dispatched all the
    915             # remaining jobs.
    916             self._iterating = False
--> 917             if self.dispatch_one_batch(iterator):
        self.dispatch_one_batch = <bound method Parallel.dispatch_one_batch of Parallel(n_jobs=1)>
        iterator = <generator object <genexpr>>
    918                 self._iterating = self._original_iterator is not None
    919 
    920             while self.dispatch_one_batch(iterator):
    921                 pass

...........................................................................
/home/aquemy/.local/lib/python2.7/site-packages/sklearn/externals/joblib/parallel.py in dispatch_one_batch(self=Parallel(n_jobs=1), iterator=<generator object <genexpr>>)
    754                                  self._pickle_cache)
    755             if len(tasks) == 0:
    756                 # No more tasks available in the iterator: tell caller to stop.
    757                 return False
    758             else:
--> 759                 self._dispatch(tasks)
        self._dispatch = <bound method Parallel._dispatch of Parallel(n_jobs=1)>
        tasks = <sklearn.externals.joblib.parallel.BatchedCalls object>
    760                 return True
    761 
    762     def _print(self, msg, msg_args):
    763         """Display the message on stout or stderr depending on verbosity"""

...........................................................................
/home/aquemy/.local/lib/python2.7/site-packages/sklearn/externals/joblib/parallel.py in _dispatch(self=Parallel(n_jobs=1), batch=<sklearn.externals.joblib.parallel.BatchedCalls object>)
    711 
    712         dispatch_timestamp = time.time()
    713         cb = BatchCompletionCallBack(dispatch_timestamp, len(batch), self)
    714         with self._lock:
    715             job_idx = len(self._jobs)
--> 716             job = self._backend.apply_async(batch, callback=cb)
        job = undefined
        self._backend.apply_async = <bound method SequentialBackend.apply_async of <...lib._parallel_backends.SequentialBackend object>>
        batch = <sklearn.externals.joblib.parallel.BatchedCalls object>
        cb = <sklearn.externals.joblib.parallel.BatchCompletionCallBack object>
    717             # A job can complete so quickly than its callback is
    718             # called before we get here, causing self._jobs to
    719             # grow. To ensure correct results ordering, .insert is
    720             # used (rather than .append) in the following line

...........................................................................
/home/aquemy/.local/lib/python2.7/site-packages/sklearn/externals/joblib/_parallel_backends.py in apply_async(self=<sklearn.externals.joblib._parallel_backends.SequentialBackend object>, func=<sklearn.externals.joblib.parallel.BatchedCalls object>, callback=<sklearn.externals.joblib.parallel.BatchCompletionCallBack object>)
    177             raise ValueError('n_jobs == 0 in Parallel has no meaning')
    178         return 1
    179 
    180     def apply_async(self, func, callback=None):
    181         """Schedule a func to be run"""
--> 182         result = ImmediateResult(func)
        result = undefined
        func = <sklearn.externals.joblib.parallel.BatchedCalls object>
    183         if callback:
    184             callback(result)
    185         return result
    186 

...........................................................................
/home/aquemy/.local/lib/python2.7/site-packages/sklearn/externals/joblib/_parallel_backends.py in __init__(self=<sklearn.externals.joblib._parallel_backends.ImmediateResult object>, batch=<sklearn.externals.joblib.parallel.BatchedCalls object>)
    544 
    545 class ImmediateResult(object):
    546     def __init__(self, batch):
    547         # Don't delay the application, to avoid keeping the input
    548         # arguments in memory
--> 549         self.results = batch()
        self.results = undefined
        batch = <sklearn.externals.joblib.parallel.BatchedCalls object>
    550 
    551     def get(self):
    552         return self.results
    553 

...........................................................................
/home/aquemy/.local/lib/python2.7/site-packages/sklearn/externals/joblib/parallel.py in __call__(self=<sklearn.externals.joblib.parallel.BatchedCalls object>)
    220     def __call__(self):
    221         # Set the default nested backend to self._backend but do not set the
    222         # change the default number of processes to -1
    223         with parallel_backend(self._backend, n_jobs=self._n_jobs):
    224             return [func(*args, **kwargs)
--> 225                     for func, args, kwargs in self.items]
        func = <function _parallel_build_trees>
        args = (DecisionTreeClassifier(class_weight=None, criter...=False, random_state=1608637542, splitter='best'), RandomForestClassifier(bootstrap=True, class_wei...se, random_state=42, verbose=0, warm_start=False), array([[-5.33848464e-01],
       [-6.53381824e-0...6e-01],
       [ 3.15349698e-01]], dtype=float32), array([[0.],
       [0.],
       [0.],
       [0...    [2.],
       [2.],
       [2.],
       [2.]]), None, 0, 25)
        kwargs = {'class_weight': None, 'verbose': 0}
        self.items = [(<function _parallel_build_trees>, (DecisionTreeClassifier(class_weight=None, criter...=False, random_state=1608637542, splitter='best'), RandomForestClassifier(bootstrap=True, class_wei...se, random_state=42, verbose=0, warm_start=False), array([[-5.33848464e-01],
       [-6.53381824e-0...6e-01],
       [ 3.15349698e-01]], dtype=float32), array([[0.],
       [0.],
       [0.],
       [0...    [2.],
       [2.],
       [2.],
       [2.]]), None, 0, 25), {'class_weight': None, 'verbose': 0})]
    226 
    227     def __len__(self):
    228         return self._size
    229 

...........................................................................
/home/aquemy/.local/lib/python2.7/site-packages/sklearn/ensemble/forest.py in _parallel_build_trees(tree=DecisionTreeClassifier(class_weight=None, criter...=False, random_state=1608637542, splitter='best'), forest=RandomForestClassifier(bootstrap=True, class_wei...se, random_state=42, verbose=0, warm_start=False), X=array([[-5.33848464e-01],
       [-6.53381824e-0...6e-01],
       [ 3.15349698e-01]], dtype=float32), y=array([[0.],
       [0.],
       [0.],
       [0...    [2.],
       [2.],
       [2.],
       [2.]]), sample_weight=None, tree_idx=0, n_trees=25, verbose=0, class_weight=None)
    114                 simplefilter('ignore', DeprecationWarning)
    115                 curr_sample_weight *= compute_sample_weight('auto', y, indices)
    116         elif class_weight == 'balanced_subsample':
    117             curr_sample_weight *= compute_sample_weight('balanced', y, indices)
    118 
--> 119         tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)
        tree.fit = <bound method DecisionTreeClassifier.fit of Deci...False, random_state=1608637542, splitter='best')>
        X = array([[-5.33848464e-01],
       [-6.53381824e-0...6e-01],
       [ 3.15349698e-01]], dtype=float32)
        y = array([[0.],
       [0.],
       [0.],
       [0...    [2.],
       [2.],
       [2.],
       [2.]])
        sample_weight = None
        curr_sample_weight = array([3., 3., 0., 1., 1., 2., 2., 0., 1., 2., 0... 1., 0., 1., 0., 1., 1., 1., 1., 1., 1., 0., 0.])
    120     else:
    121         tree.fit(X, y, sample_weight=sample_weight, check_input=False)
    122 
    123     return tree

...........................................................................
/home/aquemy/.local/lib/python2.7/site-packages/sklearn/tree/tree.py in fit(self=DecisionTreeClassifier(class_weight=None, criter...=False, random_state=1608637542, splitter='best'), X=array([[-5.33848464e-01],
       [-6.53381824e-0...6e-01],
       [ 3.15349698e-01]], dtype=float32), y=array([[0.],
       [0.],
       [0.],
       [0...    [2.],
       [2.],
       [2.],
       [2.]]), sample_weight=array([3., 3., 0., 1., 1., 2., 2., 0., 1., 2., 0... 1., 0., 1., 0., 1., 1., 1., 1., 1., 1., 0., 0.]), check_input=False, X_idx_sorted=None)
    796 
    797         super(DecisionTreeClassifier, self).fit(
    798             X, y,
    799             sample_weight=sample_weight,
    800             check_input=check_input,
--> 801             X_idx_sorted=X_idx_sorted)
        X_idx_sorted = None
    802         return self
    803 
    804     def predict_proba(self, X, check_input=True):
    805         """Predict class probabilities of the input samples X.

...........................................................................
/home/aquemy/.local/lib/python2.7/site-packages/sklearn/tree/tree.py in fit(self=DecisionTreeClassifier(class_weight=None, criter...=False, random_state=1608637542, splitter='best'), X=array([[-5.33848464e-01],
       [-6.53381824e-0...6e-01],
       [ 3.15349698e-01]], dtype=float32), y=array([[0.],
       [0.],
       [0.],
       [0...    [2.],
       [2.],
       [2.],
       [2.]]), sample_weight=array([3., 3., 0., 1., 1., 2., 2., 0., 1., 2., 0... 1., 0., 1., 0., 1., 1., 1., 1., 1., 1., 0., 0.]), check_input=False, X_idx_sorted=None)
    237         if not 0 <= self.min_weight_fraction_leaf <= 0.5:
    238             raise ValueError("min_weight_fraction_leaf must in [0, 0.5]")
    239         if max_depth <= 0:
    240             raise ValueError("max_depth must be greater than zero. ")
    241         if not (0 < max_features <= self.n_features_):
--> 242             raise ValueError("max_features must be in (0, n_features]")
    243         if not isinstance(max_leaf_nodes, (numbers.Integral, np.integer)):
    244             raise ValueError("max_leaf_nodes must be integral number but was "
    245                              "%r" % max_leaf_nodes)
    246         if -1 < max_leaf_nodes < 2:

ValueError: max_features must be in (0, n_features]
___________________________________________________________________________
Best score: 0.966666666667 (0.04472135955) [J] | Score: 0.0 (0.0) [J]
Best score: 0.966666666667 (0.04472135955) [J] | Score: 0.953333333333 (0.0520683311727) [J]
Best score: 0.966666666667 (0.04472135955) [J] | Score: 0.66 (0.02) [J]
Best score: 0.966666666667 (0.04472135955) [J] | Score: 0.966666666667 (0.04472135955) [J]
Best score: 0.966666666667 (0.04472135955) [J] | Score: 0.966666666667 (0.04472135955) [J]
Best score: 0.966666666667 (0.04472135955) [J] | Score: 0.946666666667 (0.049888765157) [J]
Best score: 0.966666666667 (0.04472135955) [J] | Score: 0.9 (0.0614636297153) [J]
Best score: 0.966666666667 (0.04472135955) [J] | Score: 0.666666666667 (1.11022302463e-16) [J]
Best score: 0.966666666667 (0.04472135955) [J] | Score: 0.92 (0.0832666399786) [J]
Best score: 0.966666666667 (0.04472135955) [J] | Score: 0.966666666667 (0.04472135955) [J]
Best score: 0.966666666667 (0.04472135955) [J] | Score: 0.953333333333 (0.0426874949162) [J]
Best score: 0.966666666667 (0.04472135955) [J] | Score: 0.753333333333 (0.107703296143) [J]
Best score: 0.966666666667 (0.04472135955) [J] | Score: 0.873333333333 (0.062893207547) [J]
JoblibValueError
___________________________________________________________________________
...........................................................................
/home/aquemy/dev/dp_hyperparameters/extension/main.py in <module>()
     27 
     28     serializer.serialize_results(scenario, policy)
     29 
     30 if __name__ == "__main__":
     31     args = cli.parse_args()
---> 32     main(args)

...........................................................................
/home/aquemy/dev/dp_hyperparameters/extension/main.py in main(args=Namespace(customize=[(['control', 'seed'], '42')...io='./scenarios/rf_iris_joint.yaml', verbosity=0))
     21         test_size=0.4, 
     22         random_state=scenario['control']['seed']
     23     )
     24 
     25     policy = policies.initiate(scenario['setup']['policy'], config)
---> 26     policy.run(X,y)
        policy.run = <bound method Joint.run of <experiment.policies.joint.Joint object>>
        X = array([[5.1, 3.5, 1.4, 0.2],
       [4.9, 3. , 1....2, 3.4, 5.4, 2.3],
       [5.9, 3. , 5.1, 1.8]])
        y = array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,... 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2])
     27 
     28     serializer.serialize_results(scenario, policy)
     29 
     30 if __name__ == "__main__":

...........................................................................
/home/aquemy/dev/dp_hyperparameters/extension/experiment/policies/joint.py in run(self=<experiment.policies.joint.Joint object>, X=array([[5.1, 3.5, 1.4, 0.2],
       [4.9, 3. , 1....2, 3.4, 5.4, 2.3],
       [5.9, 3. , 5.1, 1.8]]), y=array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,... 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]))
     32             algo=tpe.suggest, 
     33             max_evals=None,
     34             max_time=self.config['time'],     
     35             trials=trials,
     36             show_progressbar=False,
---> 37             verbose=0
     38         )
     39 
     40         best_config = self.context['best_config']
     41         super(Joint, self).display_step_results(best_config)

...........................................................................
/home/aquemy/dev/dp_hyperparameters/extension/hyperopt/fmin.py in fmin(fn=<functools.partial object>, space={'algorithm': {'bootstrap': <hyperopt.pyll.base.Apply object>, 'criterion': <hyperopt.pyll.base.Apply object>, 'max_depth': <hyperopt.pyll.base.Apply object>, 'max_features': <hyperopt.pyll.base.Apply object>, 'max_leaf_nodes': <hyperopt.pyll.base.Apply object>, 'min_samples_split': <hyperopt.pyll.base.Apply object>, 'n_estimators': <hyperopt.pyll.base.Apply object>}, 'pipeline': {'features': <hyperopt.pyll.base.Apply object>, 'normalizer': <hyperopt.pyll.base.Apply object>, 'rebalance': <hyperopt.pyll.base.Apply object>}}, algo=<function suggest>, max_evals=9223372036854775807, max_time=300, trials=<hyperopt.base.Trials object>, rstate=<mtrand.RandomState object>, allow_trials_fmin=True, pass_expr_memo_ctrl=None, catch_eval_exceptions=False, verbose=0, return_argmin=True, points_to_evaluate=None, max_queue_len=1, show_progressbar=False)
    406             pass_expr_memo_ctrl=pass_expr_memo_ctrl,
    407             verbose=verbose,
    408             catch_eval_exceptions=catch_eval_exceptions,
    409             return_argmin=return_argmin,
    410             show_progressbar=show_progressbar,
--> 411             max_time=max_time
        max_time = 300
    412         )
    413 
    414     if trials is None:
    415         if points_to_evaluate is None:

...........................................................................
/home/aquemy/dev/dp_hyperparameters/extension/hyperopt/base.py in fmin(self=<hyperopt.base.Trials object>, fn=<functools.partial object>, space={'algorithm': {'bootstrap': <hyperopt.pyll.base.Apply object>, 'criterion': <hyperopt.pyll.base.Apply object>, 'max_depth': <hyperopt.pyll.base.Apply object>, 'max_features': <hyperopt.pyll.base.Apply object>, 'max_leaf_nodes': <hyperopt.pyll.base.Apply object>, 'min_samples_split': <hyperopt.pyll.base.Apply object>, 'n_estimators': <hyperopt.pyll.base.Apply object>}, 'pipeline': {'features': <hyperopt.pyll.base.Apply object>, 'normalizer': <hyperopt.pyll.base.Apply object>, 'rebalance': <hyperopt.pyll.base.Apply object>}}, algo=<function suggest>, max_evals=9223372036854775807, max_time=300, rstate=<mtrand.RandomState object>, verbose=0, pass_expr_memo_ctrl=None, catch_eval_exceptions=False, return_argmin=True, show_progressbar=False)
    636             verbose=verbose,
    637             allow_trials_fmin=False,  # -- prevent recursion
    638             pass_expr_memo_ctrl=pass_expr_memo_ctrl,
    639             catch_eval_exceptions=catch_eval_exceptions,
    640             return_argmin=return_argmin,
--> 641             show_progressbar=show_progressbar)
        show_progressbar = False
    642 
    643 
    644 def trials_from_docs(docs, validate=True, **kwargs):
    645     """Construct a Trials base class instance from a list of trials documents

...........................................................................
/home/aquemy/dev/dp_hyperparameters/extension/hyperopt/fmin.py in fmin(fn=<functools.partial object>, space={'algorithm': {'bootstrap': <hyperopt.pyll.base.Apply object>, 'criterion': <hyperopt.pyll.base.Apply object>, 'max_depth': <hyperopt.pyll.base.Apply object>, 'max_features': <hyperopt.pyll.base.Apply object>, 'max_leaf_nodes': <hyperopt.pyll.base.Apply object>, 'min_samples_split': <hyperopt.pyll.base.Apply object>, 'n_estimators': <hyperopt.pyll.base.Apply object>}, 'pipeline': {'features': <hyperopt.pyll.base.Apply object>, 'normalizer': <hyperopt.pyll.base.Apply object>, 'rebalance': <hyperopt.pyll.base.Apply object>}}, algo=<function suggest>, max_evals=9223372036854775807, max_time=300, trials=<hyperopt.base.Trials object>, rstate=<mtrand.RandomState object>, allow_trials_fmin=False, pass_expr_memo_ctrl=None, catch_eval_exceptions=False, verbose=0, return_argmin=True, points_to_evaluate=None, max_queue_len=1, show_progressbar=False)
    426                     verbose=verbose,
    427                     max_queue_len=max_queue_len,
    428                     show_progressbar=show_progressbar,
    429                     max_time=max_time)
    430     rval.catch_eval_exceptions = catch_eval_exceptions
--> 431     rval.exhaust()
        rval.exhaust = <bound method FMinIter.exhaust of <hyperopt.fmin.FMinIter object>>
    432     if return_argmin:
    433         return trials.argmin
    434     elif len(trials) > 0:
    435         # Only if there are some succesfull trail runs, return the best point in the evaluation space

...........................................................................
/home/aquemy/dev/dp_hyperparameters/extension/hyperopt/fmin.py in exhaust(self=<hyperopt.fmin.FMinIter object>)
    273             raise StopIteration()
    274         return self.trials
    275 
    276     def exhaust(self):
    277         n_done = len(self.trials)
--> 278         self.run(self.max_evals - n_done, block_until_done=self.asynchronous)
        self.run = <bound method FMinIter.run of <hyperopt.fmin.FMinIter object>>
        self.max_evals = 9223372036854775807
        n_done = 0
        self.asynchronous = False
    279         self.trials.refresh()
    280         return self
    281 
    282 

...........................................................................
/home/aquemy/dev/dp_hyperparameters/extension/hyperopt/fmin.py in run(self=<hyperopt.fmin.FMinIter object>, N=9223372036854775807, block_until_done=False)
    232                     if self.asynchronous:
    233                         # -- wait for workers to fill in the trials
    234                         time.sleep(self.poll_interval_secs)
    235                     else:
    236                         # -- loop over trials and do the jobs directly
--> 237                         self.serial_evaluate()
        self.serial_evaluate = <bound method FMinIter.serial_evaluate of <hyperopt.fmin.FMinIter object>>
    238                     try:
    239                         res = [d['result']['loss'] for d in
    240                                          self.trials.trials if
    241                                          d['result']['status'] == 'ok']

...........................................................................
/home/aquemy/dev/dp_hyperparameters/extension/hyperopt/fmin.py in serial_evaluate(self=<hyperopt.fmin.FMinIter object>, N=-1)
    138                 trial['book_time'] = now
    139                 trial['refresh_time'] = now
    140                 spec = base.spec_from_misc(trial['misc'])
    141                 ctrl = base.Ctrl(self.trials, current_trial=trial)
    142                 try:
--> 143                     result = self.domain.evaluate(spec, ctrl)
        result = undefined
        self.domain.evaluate = <bound method Domain.evaluate of <hyperopt.base.Domain object>>
        spec = {'bootstrap': 0, 'criterion': 0, 'features': 1, 'features_PCA_features__n_components': 1, 'max_depth': 0, 'max_features': 2, 'max_leaf_nodes': 3, 'min_samples_split': 1, 'n_estimators': 2, 'normalizer': 2, ...}
        ctrl = <hyperopt.base.Ctrl object>
    144                 except Exception as e:
    145                     logger.info('job exception: %s' % str(e))
    146                     trial['state'] = base.JOB_STATE_ERROR
    147                     trial['misc']['error'] = (str(type(e)), str(e))

...........................................................................
/home/aquemy/dev/dp_hyperparameters/extension/hyperopt/base.py in evaluate(self=<hyperopt.base.Domain object>, config={'bootstrap': 0, 'criterion': 0, 'features': 1, 'features_PCA_features__n_components': 1, 'max_depth': 0, 'max_features': 2, 'max_leaf_nodes': 3, 'min_samples_split': 1, 'n_estimators': 2, 'normalizer': 2, ...}, ctrl=<hyperopt.base.Ctrl object>, attach_attachments=True)
    841             #    or the normal Python part (self.fn)
    842             pyll_rval = pyll.rec_eval(
    843                 self.expr,
    844                 memo=memo,
    845                 print_node_on_error=self.rec_eval_print_node_on_error)
--> 846             rval = self.fn(pyll_rval)
        rval = undefined
        self.fn = <functools.partial object>
        pyll_rval = {'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': 1, 'max_features': 3, 'max_leaf_nodes': None, 'min_samples_split': 3, 'n_estimators': 50}, 'pipeline': {'features': ('features_PCA', {'features__n_components': 2}), 'normalizer': ('normalizer_PowerTransformer', {}), 'rebalance': ('rebalance_NoneType', {})}}
    847 
    848         if isinstance(rval, (float, int, np.number)):
    849             dict_rval = {'loss': float(rval), 'status': STATUS_OK}
    850         else:

...........................................................................
/home/aquemy/dev/dp_hyperparameters/extension/experiment/objective.py in objective_joint(wconfig={'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': 1, 'max_features': 3, 'max_leaf_nodes': None, 'min_samples_split': 3, 'n_estimators': 50}, 'pipeline': {'features': ('features_PCA', {'features__n_components': 2}), 'normalizer': ('normalizer_PowerTransformer', {}), 'rebalance': ('rebalance_NoneType', {})}}, algorithm='RandomForest', X=array([[5.1, 3.5, 1.4, 0.2],
       [4.9, 3. , 1....2, 3.4, 5.4, 2.3],
       [5.9, 3. , 5.1, 1.8]]), y=array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,... 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]), context={'baseline_score': 0.9466666666666667, 'baseline_score_std': 0.04988876515698587, 'best_config': {'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': 1, 'max_features': None, 'max_leaf_nodes': None, 'min_samples_split': 5, 'n_estimators': 75}, 'config_hash': {'algorithm': '94b0d7a654c508cc63643f78fe4f0f07e6f07c1e', 'config': '4403c5a85e951938d3c454e961d3a412780722f6', 'pipeline': '3e47444880d8367fbac2faaba2e52a917274aa58'}, 'duration': 0.8397619724273682, 'iteration': 2, 'loss': 0.03333333333333344, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_PCA', {'features__n_components': 3}), 'normalizer': ('normalizer_MinMaxScaler', {}), 'rebalance': ('rebalance_NoneType', {})}, 'score': 0.9666666666666666, ...}, 'history': [{'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': 2, 'max_features': None, 'max_leaf_nodes': 5, 'min_samples_split': 2, 'n_estimators': 75}, 'config_hash': {'algorithm': '3af5b0cce71c8fe2545246ca24ff5bc3dd516e06', 'config': 'db6ac7e6d348155757e4794bb5f88fe2b4f63d50', 'pipeline': '8d59f4b94cef6be9306ed86a22a9570fa670d567'}, 'duration': 1.149928092956543, 'iteration': 0, 'loss': 0.046666666666666634, 'max_history_score': 0.9533333333333334, 'max_history_score_std': 0.059999999999999984, 'max_history_step': 'joint', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 4, 'features__selectkbest__k': 3}), 'normalizer': ('normalizer_StandardScaler', {'normalizer__with_mean': True, 'normalizer__with_std': True}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 6})}, 'score': 0.9533333333333334, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': 1, 'max_features': 2, 'max_leaf_nodes': 2, 'min_samples_split': 5, 'n_estimators': 100}, 'config_hash': {'algorithm': 'e13eb05fd9a62d2f63bbb1c1deff0cd620d5e6ab', 'config': '4db6fb84d85f52659f780e682ffac5712c3d8a94', 'pipeline': '64c9a1ca9d53ae67244bdd942f4db36a3c05218c'}, 'duration': 1.7678282260894775, 'iteration': 1, 'loss': 0.18000000000000005, 'max_history_score': 0.9533333333333334, 'max_history_score_std': 0.059999999999999984, 'max_history_step': 'joint', 'pipeline': {'features': ('features_NoneType', {}), 'normalizer': ('normalizer_PowerTransformer', {}), 'rebalance': ('rebalance_NearMiss', {'rebalance__n_neighbors': 1})}, 'score': 0.82, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': 1, 'max_features': None, 'max_leaf_nodes': None, 'min_samples_split': 5, 'n_estimators': 75}, 'config_hash': {'algorithm': '94b0d7a654c508cc63643f78fe4f0f07e6f07c1e', 'config': '4403c5a85e951938d3c454e961d3a412780722f6', 'pipeline': '3e47444880d8367fbac2faaba2e52a917274aa58'}, 'duration': 0.8397619724273682, 'iteration': 2, 'loss': 0.03333333333333344, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_PCA', {'features__n_components': 3}), 'normalizer': ('normalizer_MinMaxScaler', {}), 'rebalance': ('rebalance_NoneType', {})}, 'score': 0.9666666666666666, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': None, 'max_features': None, 'max_leaf_nodes': 3, 'min_samples_split': 3, 'n_estimators': 75}, 'config_hash': {'algorithm': 'e8332f0a8902bda03bf70e7978cc5d52affb29d3', 'config': 'a064e2df18ab98d44dabcefbc7bed94913f1d0be', 'pipeline': '7eea819c2a8c103c4b1e9e9c1e224aebba95081f'}, 'duration': 0.8501448631286621, 'iteration': 3, 'loss': 0.053333333333333344, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 2, 'features__selectkbest__k': 4}), 'normalizer': ('normalizer_NoneType', {}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 7})}, 'score': 0.9466666666666667, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'entropy', 'max_depth': 3, 'max_features': 3, 'max_leaf_nodes': None, 'min_samples_split': 5, 'n_estimators': 75}, 'config_hash': {'algorithm': '7a4491035bc6bd737fe9a8cda8a79a02d02d5c74', 'config': '0ddb6f5cab3db4dddd7682966a57205f3e329ad4', 'pipeline': 'a9ae03fe38334f6868cbf84cdd3d629d4bbe3fb0'}, 'duration': 1.1026010513305664, 'iteration': 4, 'loss': 0.05999999999999994, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 2, 'features__selectkbest__k': 1}), 'normalizer': ('normalizer_NoneType', {}), 'rebalance': ('rebalance_NoneType', {})}, 'score': 0.9400000000000001, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'gini', 'max_depth': 3, 'max_features': 1, 'max_leaf_nodes': 5, 'min_samples_split': 2, 'n_estimators': 25}, 'config_hash': {'algorithm': '9826d20b2d6a0f559cf7f16450ce7526f07e8434', 'config': '49f25751bca61cdd461a8cbd2923689b642f98ed', 'pipeline': '19b249664c5bf067de1fed4334a296f947ce774a'}, 'duration': 0.35647010803222656, 'iteration': 5, 'loss': 0.046666666666666634, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_NoneType', {}), 'normalizer': ('normalizer_NoneType', {}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 6})}, 'score': 0.9533333333333334, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'gini', 'max_depth': 2, 'max_features': 1, 'max_leaf_nodes': 2, 'min_samples_split': 2, 'n_estimators': 50}, 'config_hash': {'algorithm': '0a4f6fbb07e0f32c6f675489a0fc82eee05bd8e1', 'config': '5c3a2b6f5e63fb45f10e41e0318b354912ec44f6', 'pipeline': 'dc3b9f176f090005e38b142f11d80e93a7dc5d5e'}, 'duration': 0.7213859558105469, 'iteration': 6, 'loss': 0.31333333333333324, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 1, 'features__selectkbest__k': 4}), 'normalizer': ('normalizer_PowerTransformer', {}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 7})}, 'score': 0.6866666666666668, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'entropy', 'max_depth': 4, 'max_features': 3, 'max_leaf_nodes': 5, 'min_samples_split': 5, 'n_estimators': 10}, 'config_hash': {'algorithm': 'b8112b97ecfc10f00a195af661dcc861cac21289', 'config': 'd3b129b397350f1b6572651c67c01de49b4b174c', 'pipeline': '5b0357ed7072c37b3d6f458bb5d49ff7d825f603'}, 'duration': 0.8299109935760498, 'iteration': 7, 'loss': 1.0, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_PCA', {'features__n_components': 2}), 'normalizer': ('normalizer_StandardScaler', {'normalizer__with_mean': True, 'normalizer__with_std': False}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 6})}, 'score': 0.0, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'gini', 'max_depth': 4, 'max_features': None, 'max_leaf_nodes': 2, 'min_samples_split': 5, 'n_estimators': 100}, 'config_hash': {'algorithm': '40ca24df19b8d164d9d098a6bed1ce056fbbb961', 'config': '813bde1108cc3c4b9bfb3a22cbb421bda7eac671', 'pipeline': '74a7b8705a1c22f7dea5e44e4ebda8f1e48add71'}, 'duration': 2.2111589908599854, 'iteration': 8, 'loss': 0.33333333333333326, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_PCA', {'features__n_components': 2}), 'normalizer': ('normalizer_StandardScaler', {'normalizer__with_mean': False, 'normalizer__with_std': True}), 'rebalance': ('rebalance_NearMiss', {'rebalance__n_neighbors': 2})}, 'score': 0.6666666666666667, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'entropy', 'max_depth': 2, 'max_features': 1, 'max_leaf_nodes': 5, 'min_samples_split': 2, 'n_estimators': 100}, 'config_hash': {'algorithm': '331418a5c12cf1453876eef85e9d98fc8e54fa11', 'config': '31930b6860ed406d59bf7e59ba1925d94704bd3b', 'pipeline': '054bef356f90ec6f644ef3ffc688766744db51c2'}, 'duration': 1.0501940250396729, 'iteration': 9, 'loss': 0.053333333333333344, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_SelectKBest', {'features__k': 1}), 'normalizer': ('normalizer_RobustScaler', {'normalizer__quantile_range': (...), 'normalizer__with_centering': True, 'normalizer__with_scaling': True}), 'rebalance': ('rebalance_NearMiss', {'rebalance__n_neighbors': 2})}, 'score': 0.9466666666666667, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'entropy', 'max_depth': 3, 'max_features': None, 'max_leaf_nodes': 3, 'min_samples_split': 2, 'n_estimators': 100}, 'config_hash': {'algorithm': 'dbc1b8126649fe93dce5fbb37e4015b0acfb179e', 'config': '9913cd550615a9d0946ab4a755a8b9f619e442fd', 'pipeline': 'dd626121cea079ebb32e184ca65483ec7a6d7f59'}, 'duration': 1.120617151260376, 'iteration': 10, 'loss': 0.046666666666666634, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 2, 'features__selectkbest__k': 1}), 'normalizer': ('normalizer_MinMaxScaler', {}), 'rebalance': ('rebalance_NoneType', {})}, 'score': 0.9533333333333334, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'gini', 'max_depth': 3, 'max_features': 3, 'max_leaf_nodes': None, 'min_samples_split': 3, 'n_estimators': 75}, 'config_hash': {'algorithm': '34917a130df5a975f78bd7ec1a0c7b1ffdc787a9', 'config': '95fc8cadc088141290b7de9c388977e4685f0108', 'pipeline': '550d10faf2f08db48516cc3501558816d6a99bc0'}, 'duration': 1.4287099838256836, 'iteration': 11, 'loss': 0.19333333333333313, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 3, 'features__selectkbest__k': 4}), 'normalizer': ('normalizer_StandardScaler', {'normalizer__with_mean': False, 'normalizer__with_std': False}), 'rebalance': ('rebalance_CondensedNearestNeighbour', {'rebalance__n_neighbors': 1})}, 'score': 0.8066666666666669, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'entropy', 'max_depth': 1, 'max_features': 2, 'max_leaf_nodes': 5, 'min_samples_split': 2, 'n_estimators': 75}, 'config_hash': {'algorithm': '33f9abb4aee44a395a9f3b3ffa9ce80a8cdaed7c', 'config': '40fa726f0360cf6af55f9b5902d399d02f61f157', 'pipeline': 'cfd1d20841fe2153da762c95e79f95a3fb1e426a'}, 'duration': 1.2978079319000244, 'iteration': 12, 'loss': 0.053333333333333344, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_PCA', {'features__n_components': 4}), 'normalizer': ('normalizer_MinMaxScaler', {}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 7})}, 'score': 0.9466666666666667, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'entropy', 'max_depth': 4, 'max_features': 2, 'max_leaf_nodes': 5, 'min_samples_split': 3, 'n_estimators': 25}, 'config_hash': {'algorithm': '210111ec6562d09eb093e98ed69ef1c662e11a50', 'config': '0fb8e77c7bd9a58b72f1b33c21a59a09a8c676ba', 'pipeline': '5d269d759e0c7926a685a14b263ace8ae0071e4b'}, 'duration': 0.36649012565612793, 'iteration': 13, 'loss': 0.040000000000000036, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 2, 'features__selectkbest__k': 2}), 'normalizer': ('normalizer_NoneType', {}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 7})}, 'score': 0.96, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'entropy', 'max_depth': 3, 'max_features': 1, 'max_leaf_nodes': 5, 'min_samples_split': 2, 'n_estimators': 25}, 'config_hash': {'algorithm': '0e989a03980101fabf79eda3326ed2870e11d690', 'config': 'f4bffd5d8c67a9c5321a9943c4a99678f59a02b7', 'pipeline': '865ee1e3fe8334c3d5ecb2038d5a5d1b3ba50e75'}, 'duration': 0.35639500617980957, 'iteration': 14, 'loss': 0.046666666666666634, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_NoneType', {}), 'normalizer': ('normalizer_RobustScaler', {'normalizer__quantile_range': (...), 'normalizer__with_centering': True, 'normalizer__with_scaling': False}), 'rebalance': ('rebalance_NoneType', {})}, 'score': 0.9533333333333334, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'entropy', 'max_depth': None, 'max_features': 3, 'max_leaf_nodes': 3, 'min_samples_split': 5, 'n_estimators': 10}, 'config_hash': {'algorithm': '9c592e876c13de5e23e6de5b868e01755d63e72e', 'config': '1e6a68cd1eeac886d90724d78b1cb5fb76a3cde4', 'pipeline': '5a1ca4d82f21b7de0d2c918630a42510673fa36e'}, 'duration': 0.18141412734985352, 'iteration': 15, 'loss': 0.046666666666666634, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_SelectKBest', {'features__k': 3}), 'normalizer': ('normalizer_RobustScaler', {'normalizer__quantile_range': (...), 'normalizer__with_centering': True, 'normalizer__with_scaling': True}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 6})}, 'score': 0.9533333333333334, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': 1, 'max_features': None, 'max_leaf_nodes': None, 'min_samples_split': 5, 'n_estimators': 10}, 'config_hash': {'algorithm': '8bed77aef289bfd453b2858bd288ae5ba7160f2b', 'config': '781185bcb8999045de8d489f253a1a1ba4247932', 'pipeline': '1ece7eabedc2be9e5b0a1be65c570d08ffa3eb54'}, 'duration': 0.1636829376220703, 'iteration': 16, 'loss': 0.053333333333333344, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_NoneType', {}), 'normalizer': ('normalizer_NoneType', {}), 'rebalance': ('rebalance_NearMiss', {'rebalance__n_neighbors': 1})}, 'score': 0.9466666666666667, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'gini', 'max_depth': 3, 'max_features': 2, 'max_leaf_nodes': 2, 'min_samples_split': 5, 'n_estimators': 75}, 'config_hash': {'algorithm': '617b97d9ba21d3373bc51ffa9cccf9c6f91a77b3', 'config': '99fb425b4e8c5d80228cab94202252aa25cdf77c', 'pipeline': 'd6242929c3b515c7719e60423023ac604311afc3'}, 'duration': 0.8468999862670898, 'iteration': 17, 'loss': 0.24, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_PCA', {'features__n_components': 4}), 'normalizer': ('normalizer_PowerTransformer', {}), 'rebalance': ('rebalance_NearMiss', {'rebalance__n_neighbors': 2})}, 'score': 0.76, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': 1, 'max_features': 1, 'max_leaf_nodes': 2, 'min_samples_split': 5, 'n_estimators': 50}, 'config_hash': {'algorithm': 'b92d2697cdd4979da443369d6596229ec091626a', 'config': 'c513a3e13281206ad76187dd817b1fff93d54fe1', 'pipeline': 'c4b4f914a3ca8df967cade997a90366d85a371b9'}, 'duration': 0.6724588871002197, 'iteration': 18, 'loss': 0.23333333333333328, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 1, 'features__selectkbest__k': 3}), 'normalizer': ('normalizer_StandardScaler', {'normalizer__with_mean': True, 'normalizer__with_std': True}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 5})}, 'score': 0.7666666666666667, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'entropy', 'max_depth': None, 'max_features': None, 'max_leaf_nodes': 5, 'min_samples_split': 5, 'n_estimators': 10}, 'config_hash': {'algorithm': 'a0115de695e6cca2e81cbfb54df79bf4b43608b1', 'config': 'ba194015e20b5d67770e8c67342c3d8d0d01dc41', 'pipeline': '8d45fabfeb85ffdcabf7076bd0e65fffe97ce928'}, 'duration': 0.19424200057983398, 'iteration': 19, 'loss': 0.08666666666666667, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_PCA', {'features__n_components': 3}), 'normalizer': ('normalizer_NoneType', {}), 'rebalance': ('rebalance_NoneType', {})}, 'score': 0.9133333333333333, ...}, ...], 'history_hash': ['db6ac7e6d348155757e4794bb5f88fe2b4f63d50', '4db6fb84d85f52659f780e682ffac5712c3d8a94', '4403c5a85e951938d3c454e961d3a412780722f6', 'a064e2df18ab98d44dabcefbc7bed94913f1d0be', '0ddb6f5cab3db4dddd7682966a57205f3e329ad4', '49f25751bca61cdd461a8cbd2923689b642f98ed', '5c3a2b6f5e63fb45f10e41e0318b354912ec44f6', 'd3b129b397350f1b6572651c67c01de49b4b174c', '813bde1108cc3c4b9bfb3a22cbb421bda7eac671', '31930b6860ed406d59bf7e59ba1925d94704bd3b', '9913cd550615a9d0946ab4a755a8b9f619e442fd', '95fc8cadc088141290b7de9c388977e4685f0108', '40fa726f0360cf6af55f9b5902d399d02f61f157', '0fb8e77c7bd9a58b72f1b33c21a59a09a8c676ba', 'f4bffd5d8c67a9c5321a9943c4a99678f59a02b7', '1e6a68cd1eeac886d90724d78b1cb5fb76a3cde4', '781185bcb8999045de8d489f253a1a1ba4247932', '99fb425b4e8c5d80228cab94202252aa25cdf77c', 'c513a3e13281206ad76187dd817b1fff93d54fe1', 'ba194015e20b5d67770e8c67342c3d8d0d01dc41', ...], 'history_index': {'0ddb6f5cab3db4dddd7682966a57205f3e329ad4': 4, '0fb8e77c7bd9a58b72f1b33c21a59a09a8c676ba': 13, '156cf80babab134353766c500267028d67005289': 20, '1e6a68cd1eeac886d90724d78b1cb5fb76a3cde4': 15, '2587c6d43f2a5d889b90dd460ee3c097a92f0cae': 29, '31930b6860ed406d59bf7e59ba1925d94704bd3b': 9, '40fa726f0360cf6af55f9b5902d399d02f61f157': 12, '4403c5a85e951938d3c454e961d3a412780722f6': 2, '49f25751bca61cdd461a8cbd2923689b642f98ed': 5, '4d8b9fc7c086a13edb2485ce038dbc69100bd639': 22, ...}, 'iteration': 33, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint'}, config={'algorithm': 'RandomForest', 'seed': 42, 'time': 300})
    108 
    109 def objective_algo(algo_config, current_pipeline_config, algorithm, X, y, context, config):
    110     return objective(current_pipeline_config, algo_config, algorithm, X, y, context, config, step='algorithm')
    111 
    112 def objective_joint(wconfig, algorithm, X, y, context, config):
--> 113     return objective(wconfig['pipeline'], wconfig['algorithm'], algorithm, X, y, context, config, step='joint')
        wconfig = {'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': 1, 'max_features': 3, 'max_leaf_nodes': None, 'min_samples_split': 3, 'n_estimators': 50}, 'pipeline': {'features': ('features_PCA', {'features__n_components': 2}), 'normalizer': ('normalizer_PowerTransformer', {}), 'rebalance': ('rebalance_NoneType', {})}}
        algorithm = 'RandomForest'
        X = array([[5.1, 3.5, 1.4, 0.2],
       [4.9, 3. , 1....2, 3.4, 5.4, 2.3],
       [5.9, 3. , 5.1, 1.8]])
        y = array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,... 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2])
        context = {'baseline_score': 0.9466666666666667, 'baseline_score_std': 0.04988876515698587, 'best_config': {'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': 1, 'max_features': None, 'max_leaf_nodes': None, 'min_samples_split': 5, 'n_estimators': 75}, 'config_hash': {'algorithm': '94b0d7a654c508cc63643f78fe4f0f07e6f07c1e', 'config': '4403c5a85e951938d3c454e961d3a412780722f6', 'pipeline': '3e47444880d8367fbac2faaba2e52a917274aa58'}, 'duration': 0.8397619724273682, 'iteration': 2, 'loss': 0.03333333333333344, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_PCA', {'features__n_components': 3}), 'normalizer': ('normalizer_MinMaxScaler', {}), 'rebalance': ('rebalance_NoneType', {})}, 'score': 0.9666666666666666, ...}, 'history': [{'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': 2, 'max_features': None, 'max_leaf_nodes': 5, 'min_samples_split': 2, 'n_estimators': 75}, 'config_hash': {'algorithm': '3af5b0cce71c8fe2545246ca24ff5bc3dd516e06', 'config': 'db6ac7e6d348155757e4794bb5f88fe2b4f63d50', 'pipeline': '8d59f4b94cef6be9306ed86a22a9570fa670d567'}, 'duration': 1.149928092956543, 'iteration': 0, 'loss': 0.046666666666666634, 'max_history_score': 0.9533333333333334, 'max_history_score_std': 0.059999999999999984, 'max_history_step': 'joint', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 4, 'features__selectkbest__k': 3}), 'normalizer': ('normalizer_StandardScaler', {'normalizer__with_mean': True, 'normalizer__with_std': True}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 6})}, 'score': 0.9533333333333334, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': 1, 'max_features': 2, 'max_leaf_nodes': 2, 'min_samples_split': 5, 'n_estimators': 100}, 'config_hash': {'algorithm': 'e13eb05fd9a62d2f63bbb1c1deff0cd620d5e6ab', 'config': '4db6fb84d85f52659f780e682ffac5712c3d8a94', 'pipeline': '64c9a1ca9d53ae67244bdd942f4db36a3c05218c'}, 'duration': 1.7678282260894775, 'iteration': 1, 'loss': 0.18000000000000005, 'max_history_score': 0.9533333333333334, 'max_history_score_std': 0.059999999999999984, 'max_history_step': 'joint', 'pipeline': {'features': ('features_NoneType', {}), 'normalizer': ('normalizer_PowerTransformer', {}), 'rebalance': ('rebalance_NearMiss', {'rebalance__n_neighbors': 1})}, 'score': 0.82, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': 1, 'max_features': None, 'max_leaf_nodes': None, 'min_samples_split': 5, 'n_estimators': 75}, 'config_hash': {'algorithm': '94b0d7a654c508cc63643f78fe4f0f07e6f07c1e', 'config': '4403c5a85e951938d3c454e961d3a412780722f6', 'pipeline': '3e47444880d8367fbac2faaba2e52a917274aa58'}, 'duration': 0.8397619724273682, 'iteration': 2, 'loss': 0.03333333333333344, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_PCA', {'features__n_components': 3}), 'normalizer': ('normalizer_MinMaxScaler', {}), 'rebalance': ('rebalance_NoneType', {})}, 'score': 0.9666666666666666, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': None, 'max_features': None, 'max_leaf_nodes': 3, 'min_samples_split': 3, 'n_estimators': 75}, 'config_hash': {'algorithm': 'e8332f0a8902bda03bf70e7978cc5d52affb29d3', 'config': 'a064e2df18ab98d44dabcefbc7bed94913f1d0be', 'pipeline': '7eea819c2a8c103c4b1e9e9c1e224aebba95081f'}, 'duration': 0.8501448631286621, 'iteration': 3, 'loss': 0.053333333333333344, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 2, 'features__selectkbest__k': 4}), 'normalizer': ('normalizer_NoneType', {}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 7})}, 'score': 0.9466666666666667, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'entropy', 'max_depth': 3, 'max_features': 3, 'max_leaf_nodes': None, 'min_samples_split': 5, 'n_estimators': 75}, 'config_hash': {'algorithm': '7a4491035bc6bd737fe9a8cda8a79a02d02d5c74', 'config': '0ddb6f5cab3db4dddd7682966a57205f3e329ad4', 'pipeline': 'a9ae03fe38334f6868cbf84cdd3d629d4bbe3fb0'}, 'duration': 1.1026010513305664, 'iteration': 4, 'loss': 0.05999999999999994, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 2, 'features__selectkbest__k': 1}), 'normalizer': ('normalizer_NoneType', {}), 'rebalance': ('rebalance_NoneType', {})}, 'score': 0.9400000000000001, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'gini', 'max_depth': 3, 'max_features': 1, 'max_leaf_nodes': 5, 'min_samples_split': 2, 'n_estimators': 25}, 'config_hash': {'algorithm': '9826d20b2d6a0f559cf7f16450ce7526f07e8434', 'config': '49f25751bca61cdd461a8cbd2923689b642f98ed', 'pipeline': '19b249664c5bf067de1fed4334a296f947ce774a'}, 'duration': 0.35647010803222656, 'iteration': 5, 'loss': 0.046666666666666634, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_NoneType', {}), 'normalizer': ('normalizer_NoneType', {}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 6})}, 'score': 0.9533333333333334, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'gini', 'max_depth': 2, 'max_features': 1, 'max_leaf_nodes': 2, 'min_samples_split': 2, 'n_estimators': 50}, 'config_hash': {'algorithm': '0a4f6fbb07e0f32c6f675489a0fc82eee05bd8e1', 'config': '5c3a2b6f5e63fb45f10e41e0318b354912ec44f6', 'pipeline': 'dc3b9f176f090005e38b142f11d80e93a7dc5d5e'}, 'duration': 0.7213859558105469, 'iteration': 6, 'loss': 0.31333333333333324, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 1, 'features__selectkbest__k': 4}), 'normalizer': ('normalizer_PowerTransformer', {}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 7})}, 'score': 0.6866666666666668, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'entropy', 'max_depth': 4, 'max_features': 3, 'max_leaf_nodes': 5, 'min_samples_split': 5, 'n_estimators': 10}, 'config_hash': {'algorithm': 'b8112b97ecfc10f00a195af661dcc861cac21289', 'config': 'd3b129b397350f1b6572651c67c01de49b4b174c', 'pipeline': '5b0357ed7072c37b3d6f458bb5d49ff7d825f603'}, 'duration': 0.8299109935760498, 'iteration': 7, 'loss': 1.0, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_PCA', {'features__n_components': 2}), 'normalizer': ('normalizer_StandardScaler', {'normalizer__with_mean': True, 'normalizer__with_std': False}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 6})}, 'score': 0.0, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'gini', 'max_depth': 4, 'max_features': None, 'max_leaf_nodes': 2, 'min_samples_split': 5, 'n_estimators': 100}, 'config_hash': {'algorithm': '40ca24df19b8d164d9d098a6bed1ce056fbbb961', 'config': '813bde1108cc3c4b9bfb3a22cbb421bda7eac671', 'pipeline': '74a7b8705a1c22f7dea5e44e4ebda8f1e48add71'}, 'duration': 2.2111589908599854, 'iteration': 8, 'loss': 0.33333333333333326, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_PCA', {'features__n_components': 2}), 'normalizer': ('normalizer_StandardScaler', {'normalizer__with_mean': False, 'normalizer__with_std': True}), 'rebalance': ('rebalance_NearMiss', {'rebalance__n_neighbors': 2})}, 'score': 0.6666666666666667, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'entropy', 'max_depth': 2, 'max_features': 1, 'max_leaf_nodes': 5, 'min_samples_split': 2, 'n_estimators': 100}, 'config_hash': {'algorithm': '331418a5c12cf1453876eef85e9d98fc8e54fa11', 'config': '31930b6860ed406d59bf7e59ba1925d94704bd3b', 'pipeline': '054bef356f90ec6f644ef3ffc688766744db51c2'}, 'duration': 1.0501940250396729, 'iteration': 9, 'loss': 0.053333333333333344, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_SelectKBest', {'features__k': 1}), 'normalizer': ('normalizer_RobustScaler', {'normalizer__quantile_range': (...), 'normalizer__with_centering': True, 'normalizer__with_scaling': True}), 'rebalance': ('rebalance_NearMiss', {'rebalance__n_neighbors': 2})}, 'score': 0.9466666666666667, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'entropy', 'max_depth': 3, 'max_features': None, 'max_leaf_nodes': 3, 'min_samples_split': 2, 'n_estimators': 100}, 'config_hash': {'algorithm': 'dbc1b8126649fe93dce5fbb37e4015b0acfb179e', 'config': '9913cd550615a9d0946ab4a755a8b9f619e442fd', 'pipeline': 'dd626121cea079ebb32e184ca65483ec7a6d7f59'}, 'duration': 1.120617151260376, 'iteration': 10, 'loss': 0.046666666666666634, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 2, 'features__selectkbest__k': 1}), 'normalizer': ('normalizer_MinMaxScaler', {}), 'rebalance': ('rebalance_NoneType', {})}, 'score': 0.9533333333333334, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'gini', 'max_depth': 3, 'max_features': 3, 'max_leaf_nodes': None, 'min_samples_split': 3, 'n_estimators': 75}, 'config_hash': {'algorithm': '34917a130df5a975f78bd7ec1a0c7b1ffdc787a9', 'config': '95fc8cadc088141290b7de9c388977e4685f0108', 'pipeline': '550d10faf2f08db48516cc3501558816d6a99bc0'}, 'duration': 1.4287099838256836, 'iteration': 11, 'loss': 0.19333333333333313, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 3, 'features__selectkbest__k': 4}), 'normalizer': ('normalizer_StandardScaler', {'normalizer__with_mean': False, 'normalizer__with_std': False}), 'rebalance': ('rebalance_CondensedNearestNeighbour', {'rebalance__n_neighbors': 1})}, 'score': 0.8066666666666669, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'entropy', 'max_depth': 1, 'max_features': 2, 'max_leaf_nodes': 5, 'min_samples_split': 2, 'n_estimators': 75}, 'config_hash': {'algorithm': '33f9abb4aee44a395a9f3b3ffa9ce80a8cdaed7c', 'config': '40fa726f0360cf6af55f9b5902d399d02f61f157', 'pipeline': 'cfd1d20841fe2153da762c95e79f95a3fb1e426a'}, 'duration': 1.2978079319000244, 'iteration': 12, 'loss': 0.053333333333333344, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_PCA', {'features__n_components': 4}), 'normalizer': ('normalizer_MinMaxScaler', {}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 7})}, 'score': 0.9466666666666667, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'entropy', 'max_depth': 4, 'max_features': 2, 'max_leaf_nodes': 5, 'min_samples_split': 3, 'n_estimators': 25}, 'config_hash': {'algorithm': '210111ec6562d09eb093e98ed69ef1c662e11a50', 'config': '0fb8e77c7bd9a58b72f1b33c21a59a09a8c676ba', 'pipeline': '5d269d759e0c7926a685a14b263ace8ae0071e4b'}, 'duration': 0.36649012565612793, 'iteration': 13, 'loss': 0.040000000000000036, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 2, 'features__selectkbest__k': 2}), 'normalizer': ('normalizer_NoneType', {}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 7})}, 'score': 0.96, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'entropy', 'max_depth': 3, 'max_features': 1, 'max_leaf_nodes': 5, 'min_samples_split': 2, 'n_estimators': 25}, 'config_hash': {'algorithm': '0e989a03980101fabf79eda3326ed2870e11d690', 'config': 'f4bffd5d8c67a9c5321a9943c4a99678f59a02b7', 'pipeline': '865ee1e3fe8334c3d5ecb2038d5a5d1b3ba50e75'}, 'duration': 0.35639500617980957, 'iteration': 14, 'loss': 0.046666666666666634, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_NoneType', {}), 'normalizer': ('normalizer_RobustScaler', {'normalizer__quantile_range': (...), 'normalizer__with_centering': True, 'normalizer__with_scaling': False}), 'rebalance': ('rebalance_NoneType', {})}, 'score': 0.9533333333333334, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'entropy', 'max_depth': None, 'max_features': 3, 'max_leaf_nodes': 3, 'min_samples_split': 5, 'n_estimators': 10}, 'config_hash': {'algorithm': '9c592e876c13de5e23e6de5b868e01755d63e72e', 'config': '1e6a68cd1eeac886d90724d78b1cb5fb76a3cde4', 'pipeline': '5a1ca4d82f21b7de0d2c918630a42510673fa36e'}, 'duration': 0.18141412734985352, 'iteration': 15, 'loss': 0.046666666666666634, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_SelectKBest', {'features__k': 3}), 'normalizer': ('normalizer_RobustScaler', {'normalizer__quantile_range': (...), 'normalizer__with_centering': True, 'normalizer__with_scaling': True}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 6})}, 'score': 0.9533333333333334, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': 1, 'max_features': None, 'max_leaf_nodes': None, 'min_samples_split': 5, 'n_estimators': 10}, 'config_hash': {'algorithm': '8bed77aef289bfd453b2858bd288ae5ba7160f2b', 'config': '781185bcb8999045de8d489f253a1a1ba4247932', 'pipeline': '1ece7eabedc2be9e5b0a1be65c570d08ffa3eb54'}, 'duration': 0.1636829376220703, 'iteration': 16, 'loss': 0.053333333333333344, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_NoneType', {}), 'normalizer': ('normalizer_NoneType', {}), 'rebalance': ('rebalance_NearMiss', {'rebalance__n_neighbors': 1})}, 'score': 0.9466666666666667, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'gini', 'max_depth': 3, 'max_features': 2, 'max_leaf_nodes': 2, 'min_samples_split': 5, 'n_estimators': 75}, 'config_hash': {'algorithm': '617b97d9ba21d3373bc51ffa9cccf9c6f91a77b3', 'config': '99fb425b4e8c5d80228cab94202252aa25cdf77c', 'pipeline': 'd6242929c3b515c7719e60423023ac604311afc3'}, 'duration': 0.8468999862670898, 'iteration': 17, 'loss': 0.24, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_PCA', {'features__n_components': 4}), 'normalizer': ('normalizer_PowerTransformer', {}), 'rebalance': ('rebalance_NearMiss', {'rebalance__n_neighbors': 2})}, 'score': 0.76, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': 1, 'max_features': 1, 'max_leaf_nodes': 2, 'min_samples_split': 5, 'n_estimators': 50}, 'config_hash': {'algorithm': 'b92d2697cdd4979da443369d6596229ec091626a', 'config': 'c513a3e13281206ad76187dd817b1fff93d54fe1', 'pipeline': 'c4b4f914a3ca8df967cade997a90366d85a371b9'}, 'duration': 0.6724588871002197, 'iteration': 18, 'loss': 0.23333333333333328, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 1, 'features__selectkbest__k': 3}), 'normalizer': ('normalizer_StandardScaler', {'normalizer__with_mean': True, 'normalizer__with_std': True}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 5})}, 'score': 0.7666666666666667, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'entropy', 'max_depth': None, 'max_features': None, 'max_leaf_nodes': 5, 'min_samples_split': 5, 'n_estimators': 10}, 'config_hash': {'algorithm': 'a0115de695e6cca2e81cbfb54df79bf4b43608b1', 'config': 'ba194015e20b5d67770e8c67342c3d8d0d01dc41', 'pipeline': '8d45fabfeb85ffdcabf7076bd0e65fffe97ce928'}, 'duration': 0.19424200057983398, 'iteration': 19, 'loss': 0.08666666666666667, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_PCA', {'features__n_components': 3}), 'normalizer': ('normalizer_NoneType', {}), 'rebalance': ('rebalance_NoneType', {})}, 'score': 0.9133333333333333, ...}, ...], 'history_hash': ['db6ac7e6d348155757e4794bb5f88fe2b4f63d50', '4db6fb84d85f52659f780e682ffac5712c3d8a94', '4403c5a85e951938d3c454e961d3a412780722f6', 'a064e2df18ab98d44dabcefbc7bed94913f1d0be', '0ddb6f5cab3db4dddd7682966a57205f3e329ad4', '49f25751bca61cdd461a8cbd2923689b642f98ed', '5c3a2b6f5e63fb45f10e41e0318b354912ec44f6', 'd3b129b397350f1b6572651c67c01de49b4b174c', '813bde1108cc3c4b9bfb3a22cbb421bda7eac671', '31930b6860ed406d59bf7e59ba1925d94704bd3b', '9913cd550615a9d0946ab4a755a8b9f619e442fd', '95fc8cadc088141290b7de9c388977e4685f0108', '40fa726f0360cf6af55f9b5902d399d02f61f157', '0fb8e77c7bd9a58b72f1b33c21a59a09a8c676ba', 'f4bffd5d8c67a9c5321a9943c4a99678f59a02b7', '1e6a68cd1eeac886d90724d78b1cb5fb76a3cde4', '781185bcb8999045de8d489f253a1a1ba4247932', '99fb425b4e8c5d80228cab94202252aa25cdf77c', 'c513a3e13281206ad76187dd817b1fff93d54fe1', 'ba194015e20b5d67770e8c67342c3d8d0d01dc41', ...], 'history_index': {'0ddb6f5cab3db4dddd7682966a57205f3e329ad4': 4, '0fb8e77c7bd9a58b72f1b33c21a59a09a8c676ba': 13, '156cf80babab134353766c500267028d67005289': 20, '1e6a68cd1eeac886d90724d78b1cb5fb76a3cde4': 15, '2587c6d43f2a5d889b90dd460ee3c097a92f0cae': 29, '31930b6860ed406d59bf7e59ba1925d94704bd3b': 9, '40fa726f0360cf6af55f9b5902d399d02f61f157': 12, '4403c5a85e951938d3c454e961d3a412780722f6': 2, '49f25751bca61cdd461a8cbd2923689b642f98ed': 5, '4d8b9fc7c086a13edb2485ce038dbc69100bd639': 22, ...}, 'iteration': 33, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint'}
        config = {'algorithm': 'RandomForest', 'seed': 42, 'time': 300}
    114 
    115 
    116 def get_baseline_score(algorithm, X, y, seed):
    117     pipeline, _ = pipeline_conf_to_full_pipeline(

...........................................................................
/home/aquemy/dev/dp_hyperparameters/extension/experiment/objective.py in objective(pipeline_config={'features': ('features_PCA', {'features__n_components': 2}), 'normalizer': ('normalizer_PowerTransformer', {}), 'rebalance': ('rebalance_NoneType', {})}, algo_config={'bootstrap': True, 'criterion': 'gini', 'max_depth': 1, 'max_features': 3, 'max_leaf_nodes': None, 'min_samples_split': 3, 'n_estimators': 50}, algorithm='RandomForest', X=array([[5.1, 3.5, 1.4, 0.2],
       [4.9, 3. , 1....2, 3.4, 5.4, 2.3],
       [5.9, 3. , 5.1, 1.8]]), y=array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,... 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]), context={'baseline_score': 0.9466666666666667, 'baseline_score_std': 0.04988876515698587, 'best_config': {'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': 1, 'max_features': None, 'max_leaf_nodes': None, 'min_samples_split': 5, 'n_estimators': 75}, 'config_hash': {'algorithm': '94b0d7a654c508cc63643f78fe4f0f07e6f07c1e', 'config': '4403c5a85e951938d3c454e961d3a412780722f6', 'pipeline': '3e47444880d8367fbac2faaba2e52a917274aa58'}, 'duration': 0.8397619724273682, 'iteration': 2, 'loss': 0.03333333333333344, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_PCA', {'features__n_components': 3}), 'normalizer': ('normalizer_MinMaxScaler', {}), 'rebalance': ('rebalance_NoneType', {})}, 'score': 0.9666666666666666, ...}, 'history': [{'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': 2, 'max_features': None, 'max_leaf_nodes': 5, 'min_samples_split': 2, 'n_estimators': 75}, 'config_hash': {'algorithm': '3af5b0cce71c8fe2545246ca24ff5bc3dd516e06', 'config': 'db6ac7e6d348155757e4794bb5f88fe2b4f63d50', 'pipeline': '8d59f4b94cef6be9306ed86a22a9570fa670d567'}, 'duration': 1.149928092956543, 'iteration': 0, 'loss': 0.046666666666666634, 'max_history_score': 0.9533333333333334, 'max_history_score_std': 0.059999999999999984, 'max_history_step': 'joint', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 4, 'features__selectkbest__k': 3}), 'normalizer': ('normalizer_StandardScaler', {'normalizer__with_mean': True, 'normalizer__with_std': True}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 6})}, 'score': 0.9533333333333334, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': 1, 'max_features': 2, 'max_leaf_nodes': 2, 'min_samples_split': 5, 'n_estimators': 100}, 'config_hash': {'algorithm': 'e13eb05fd9a62d2f63bbb1c1deff0cd620d5e6ab', 'config': '4db6fb84d85f52659f780e682ffac5712c3d8a94', 'pipeline': '64c9a1ca9d53ae67244bdd942f4db36a3c05218c'}, 'duration': 1.7678282260894775, 'iteration': 1, 'loss': 0.18000000000000005, 'max_history_score': 0.9533333333333334, 'max_history_score_std': 0.059999999999999984, 'max_history_step': 'joint', 'pipeline': {'features': ('features_NoneType', {}), 'normalizer': ('normalizer_PowerTransformer', {}), 'rebalance': ('rebalance_NearMiss', {'rebalance__n_neighbors': 1})}, 'score': 0.82, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': 1, 'max_features': None, 'max_leaf_nodes': None, 'min_samples_split': 5, 'n_estimators': 75}, 'config_hash': {'algorithm': '94b0d7a654c508cc63643f78fe4f0f07e6f07c1e', 'config': '4403c5a85e951938d3c454e961d3a412780722f6', 'pipeline': '3e47444880d8367fbac2faaba2e52a917274aa58'}, 'duration': 0.8397619724273682, 'iteration': 2, 'loss': 0.03333333333333344, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_PCA', {'features__n_components': 3}), 'normalizer': ('normalizer_MinMaxScaler', {}), 'rebalance': ('rebalance_NoneType', {})}, 'score': 0.9666666666666666, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': None, 'max_features': None, 'max_leaf_nodes': 3, 'min_samples_split': 3, 'n_estimators': 75}, 'config_hash': {'algorithm': 'e8332f0a8902bda03bf70e7978cc5d52affb29d3', 'config': 'a064e2df18ab98d44dabcefbc7bed94913f1d0be', 'pipeline': '7eea819c2a8c103c4b1e9e9c1e224aebba95081f'}, 'duration': 0.8501448631286621, 'iteration': 3, 'loss': 0.053333333333333344, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 2, 'features__selectkbest__k': 4}), 'normalizer': ('normalizer_NoneType', {}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 7})}, 'score': 0.9466666666666667, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'entropy', 'max_depth': 3, 'max_features': 3, 'max_leaf_nodes': None, 'min_samples_split': 5, 'n_estimators': 75}, 'config_hash': {'algorithm': '7a4491035bc6bd737fe9a8cda8a79a02d02d5c74', 'config': '0ddb6f5cab3db4dddd7682966a57205f3e329ad4', 'pipeline': 'a9ae03fe38334f6868cbf84cdd3d629d4bbe3fb0'}, 'duration': 1.1026010513305664, 'iteration': 4, 'loss': 0.05999999999999994, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 2, 'features__selectkbest__k': 1}), 'normalizer': ('normalizer_NoneType', {}), 'rebalance': ('rebalance_NoneType', {})}, 'score': 0.9400000000000001, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'gini', 'max_depth': 3, 'max_features': 1, 'max_leaf_nodes': 5, 'min_samples_split': 2, 'n_estimators': 25}, 'config_hash': {'algorithm': '9826d20b2d6a0f559cf7f16450ce7526f07e8434', 'config': '49f25751bca61cdd461a8cbd2923689b642f98ed', 'pipeline': '19b249664c5bf067de1fed4334a296f947ce774a'}, 'duration': 0.35647010803222656, 'iteration': 5, 'loss': 0.046666666666666634, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_NoneType', {}), 'normalizer': ('normalizer_NoneType', {}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 6})}, 'score': 0.9533333333333334, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'gini', 'max_depth': 2, 'max_features': 1, 'max_leaf_nodes': 2, 'min_samples_split': 2, 'n_estimators': 50}, 'config_hash': {'algorithm': '0a4f6fbb07e0f32c6f675489a0fc82eee05bd8e1', 'config': '5c3a2b6f5e63fb45f10e41e0318b354912ec44f6', 'pipeline': 'dc3b9f176f090005e38b142f11d80e93a7dc5d5e'}, 'duration': 0.7213859558105469, 'iteration': 6, 'loss': 0.31333333333333324, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 1, 'features__selectkbest__k': 4}), 'normalizer': ('normalizer_PowerTransformer', {}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 7})}, 'score': 0.6866666666666668, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'entropy', 'max_depth': 4, 'max_features': 3, 'max_leaf_nodes': 5, 'min_samples_split': 5, 'n_estimators': 10}, 'config_hash': {'algorithm': 'b8112b97ecfc10f00a195af661dcc861cac21289', 'config': 'd3b129b397350f1b6572651c67c01de49b4b174c', 'pipeline': '5b0357ed7072c37b3d6f458bb5d49ff7d825f603'}, 'duration': 0.8299109935760498, 'iteration': 7, 'loss': 1.0, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_PCA', {'features__n_components': 2}), 'normalizer': ('normalizer_StandardScaler', {'normalizer__with_mean': True, 'normalizer__with_std': False}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 6})}, 'score': 0.0, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'gini', 'max_depth': 4, 'max_features': None, 'max_leaf_nodes': 2, 'min_samples_split': 5, 'n_estimators': 100}, 'config_hash': {'algorithm': '40ca24df19b8d164d9d098a6bed1ce056fbbb961', 'config': '813bde1108cc3c4b9bfb3a22cbb421bda7eac671', 'pipeline': '74a7b8705a1c22f7dea5e44e4ebda8f1e48add71'}, 'duration': 2.2111589908599854, 'iteration': 8, 'loss': 0.33333333333333326, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_PCA', {'features__n_components': 2}), 'normalizer': ('normalizer_StandardScaler', {'normalizer__with_mean': False, 'normalizer__with_std': True}), 'rebalance': ('rebalance_NearMiss', {'rebalance__n_neighbors': 2})}, 'score': 0.6666666666666667, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'entropy', 'max_depth': 2, 'max_features': 1, 'max_leaf_nodes': 5, 'min_samples_split': 2, 'n_estimators': 100}, 'config_hash': {'algorithm': '331418a5c12cf1453876eef85e9d98fc8e54fa11', 'config': '31930b6860ed406d59bf7e59ba1925d94704bd3b', 'pipeline': '054bef356f90ec6f644ef3ffc688766744db51c2'}, 'duration': 1.0501940250396729, 'iteration': 9, 'loss': 0.053333333333333344, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_SelectKBest', {'features__k': 1}), 'normalizer': ('normalizer_RobustScaler', {'normalizer__quantile_range': (...), 'normalizer__with_centering': True, 'normalizer__with_scaling': True}), 'rebalance': ('rebalance_NearMiss', {'rebalance__n_neighbors': 2})}, 'score': 0.9466666666666667, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'entropy', 'max_depth': 3, 'max_features': None, 'max_leaf_nodes': 3, 'min_samples_split': 2, 'n_estimators': 100}, 'config_hash': {'algorithm': 'dbc1b8126649fe93dce5fbb37e4015b0acfb179e', 'config': '9913cd550615a9d0946ab4a755a8b9f619e442fd', 'pipeline': 'dd626121cea079ebb32e184ca65483ec7a6d7f59'}, 'duration': 1.120617151260376, 'iteration': 10, 'loss': 0.046666666666666634, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 2, 'features__selectkbest__k': 1}), 'normalizer': ('normalizer_MinMaxScaler', {}), 'rebalance': ('rebalance_NoneType', {})}, 'score': 0.9533333333333334, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'gini', 'max_depth': 3, 'max_features': 3, 'max_leaf_nodes': None, 'min_samples_split': 3, 'n_estimators': 75}, 'config_hash': {'algorithm': '34917a130df5a975f78bd7ec1a0c7b1ffdc787a9', 'config': '95fc8cadc088141290b7de9c388977e4685f0108', 'pipeline': '550d10faf2f08db48516cc3501558816d6a99bc0'}, 'duration': 1.4287099838256836, 'iteration': 11, 'loss': 0.19333333333333313, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 3, 'features__selectkbest__k': 4}), 'normalizer': ('normalizer_StandardScaler', {'normalizer__with_mean': False, 'normalizer__with_std': False}), 'rebalance': ('rebalance_CondensedNearestNeighbour', {'rebalance__n_neighbors': 1})}, 'score': 0.8066666666666669, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'entropy', 'max_depth': 1, 'max_features': 2, 'max_leaf_nodes': 5, 'min_samples_split': 2, 'n_estimators': 75}, 'config_hash': {'algorithm': '33f9abb4aee44a395a9f3b3ffa9ce80a8cdaed7c', 'config': '40fa726f0360cf6af55f9b5902d399d02f61f157', 'pipeline': 'cfd1d20841fe2153da762c95e79f95a3fb1e426a'}, 'duration': 1.2978079319000244, 'iteration': 12, 'loss': 0.053333333333333344, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_PCA', {'features__n_components': 4}), 'normalizer': ('normalizer_MinMaxScaler', {}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 7})}, 'score': 0.9466666666666667, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'entropy', 'max_depth': 4, 'max_features': 2, 'max_leaf_nodes': 5, 'min_samples_split': 3, 'n_estimators': 25}, 'config_hash': {'algorithm': '210111ec6562d09eb093e98ed69ef1c662e11a50', 'config': '0fb8e77c7bd9a58b72f1b33c21a59a09a8c676ba', 'pipeline': '5d269d759e0c7926a685a14b263ace8ae0071e4b'}, 'duration': 0.36649012565612793, 'iteration': 13, 'loss': 0.040000000000000036, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 2, 'features__selectkbest__k': 2}), 'normalizer': ('normalizer_NoneType', {}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 7})}, 'score': 0.96, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'entropy', 'max_depth': 3, 'max_features': 1, 'max_leaf_nodes': 5, 'min_samples_split': 2, 'n_estimators': 25}, 'config_hash': {'algorithm': '0e989a03980101fabf79eda3326ed2870e11d690', 'config': 'f4bffd5d8c67a9c5321a9943c4a99678f59a02b7', 'pipeline': '865ee1e3fe8334c3d5ecb2038d5a5d1b3ba50e75'}, 'duration': 0.35639500617980957, 'iteration': 14, 'loss': 0.046666666666666634, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_NoneType', {}), 'normalizer': ('normalizer_RobustScaler', {'normalizer__quantile_range': (...), 'normalizer__with_centering': True, 'normalizer__with_scaling': False}), 'rebalance': ('rebalance_NoneType', {})}, 'score': 0.9533333333333334, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'entropy', 'max_depth': None, 'max_features': 3, 'max_leaf_nodes': 3, 'min_samples_split': 5, 'n_estimators': 10}, 'config_hash': {'algorithm': '9c592e876c13de5e23e6de5b868e01755d63e72e', 'config': '1e6a68cd1eeac886d90724d78b1cb5fb76a3cde4', 'pipeline': '5a1ca4d82f21b7de0d2c918630a42510673fa36e'}, 'duration': 0.18141412734985352, 'iteration': 15, 'loss': 0.046666666666666634, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_SelectKBest', {'features__k': 3}), 'normalizer': ('normalizer_RobustScaler', {'normalizer__quantile_range': (...), 'normalizer__with_centering': True, 'normalizer__with_scaling': True}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 6})}, 'score': 0.9533333333333334, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': 1, 'max_features': None, 'max_leaf_nodes': None, 'min_samples_split': 5, 'n_estimators': 10}, 'config_hash': {'algorithm': '8bed77aef289bfd453b2858bd288ae5ba7160f2b', 'config': '781185bcb8999045de8d489f253a1a1ba4247932', 'pipeline': '1ece7eabedc2be9e5b0a1be65c570d08ffa3eb54'}, 'duration': 0.1636829376220703, 'iteration': 16, 'loss': 0.053333333333333344, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_NoneType', {}), 'normalizer': ('normalizer_NoneType', {}), 'rebalance': ('rebalance_NearMiss', {'rebalance__n_neighbors': 1})}, 'score': 0.9466666666666667, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'gini', 'max_depth': 3, 'max_features': 2, 'max_leaf_nodes': 2, 'min_samples_split': 5, 'n_estimators': 75}, 'config_hash': {'algorithm': '617b97d9ba21d3373bc51ffa9cccf9c6f91a77b3', 'config': '99fb425b4e8c5d80228cab94202252aa25cdf77c', 'pipeline': 'd6242929c3b515c7719e60423023ac604311afc3'}, 'duration': 0.8468999862670898, 'iteration': 17, 'loss': 0.24, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_PCA', {'features__n_components': 4}), 'normalizer': ('normalizer_PowerTransformer', {}), 'rebalance': ('rebalance_NearMiss', {'rebalance__n_neighbors': 2})}, 'score': 0.76, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': 1, 'max_features': 1, 'max_leaf_nodes': 2, 'min_samples_split': 5, 'n_estimators': 50}, 'config_hash': {'algorithm': 'b92d2697cdd4979da443369d6596229ec091626a', 'config': 'c513a3e13281206ad76187dd817b1fff93d54fe1', 'pipeline': 'c4b4f914a3ca8df967cade997a90366d85a371b9'}, 'duration': 0.6724588871002197, 'iteration': 18, 'loss': 0.23333333333333328, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 1, 'features__selectkbest__k': 3}), 'normalizer': ('normalizer_StandardScaler', {'normalizer__with_mean': True, 'normalizer__with_std': True}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 5})}, 'score': 0.7666666666666667, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'entropy', 'max_depth': None, 'max_features': None, 'max_leaf_nodes': 5, 'min_samples_split': 5, 'n_estimators': 10}, 'config_hash': {'algorithm': 'a0115de695e6cca2e81cbfb54df79bf4b43608b1', 'config': 'ba194015e20b5d67770e8c67342c3d8d0d01dc41', 'pipeline': '8d45fabfeb85ffdcabf7076bd0e65fffe97ce928'}, 'duration': 0.19424200057983398, 'iteration': 19, 'loss': 0.08666666666666667, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_PCA', {'features__n_components': 3}), 'normalizer': ('normalizer_NoneType', {}), 'rebalance': ('rebalance_NoneType', {})}, 'score': 0.9133333333333333, ...}, ...], 'history_hash': ['db6ac7e6d348155757e4794bb5f88fe2b4f63d50', '4db6fb84d85f52659f780e682ffac5712c3d8a94', '4403c5a85e951938d3c454e961d3a412780722f6', 'a064e2df18ab98d44dabcefbc7bed94913f1d0be', '0ddb6f5cab3db4dddd7682966a57205f3e329ad4', '49f25751bca61cdd461a8cbd2923689b642f98ed', '5c3a2b6f5e63fb45f10e41e0318b354912ec44f6', 'd3b129b397350f1b6572651c67c01de49b4b174c', '813bde1108cc3c4b9bfb3a22cbb421bda7eac671', '31930b6860ed406d59bf7e59ba1925d94704bd3b', '9913cd550615a9d0946ab4a755a8b9f619e442fd', '95fc8cadc088141290b7de9c388977e4685f0108', '40fa726f0360cf6af55f9b5902d399d02f61f157', '0fb8e77c7bd9a58b72f1b33c21a59a09a8c676ba', 'f4bffd5d8c67a9c5321a9943c4a99678f59a02b7', '1e6a68cd1eeac886d90724d78b1cb5fb76a3cde4', '781185bcb8999045de8d489f253a1a1ba4247932', '99fb425b4e8c5d80228cab94202252aa25cdf77c', 'c513a3e13281206ad76187dd817b1fff93d54fe1', 'ba194015e20b5d67770e8c67342c3d8d0d01dc41', ...], 'history_index': {'0ddb6f5cab3db4dddd7682966a57205f3e329ad4': 4, '0fb8e77c7bd9a58b72f1b33c21a59a09a8c676ba': 13, '156cf80babab134353766c500267028d67005289': 20, '1e6a68cd1eeac886d90724d78b1cb5fb76a3cde4': 15, '2587c6d43f2a5d889b90dd460ee3c097a92f0cae': 29, '31930b6860ed406d59bf7e59ba1925d94704bd3b': 9, '40fa726f0360cf6af55f9b5902d399d02f61f157': 12, '4403c5a85e951938d3c454e961d3a412780722f6': 2, '49f25751bca61cdd461a8cbd2923689b642f98ed': 5, '4d8b9fc7c086a13edb2485ce038dbc69100bd639': 22, ...}, 'iteration': 33, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint'}, config={'algorithm': 'RandomForest', 'seed': 42, 'time': 300}, step='joint')
     45                 y,
     46                 cv=10,
     47                 n_jobs=-1,
     48                 return_estimator=False,
     49                 return_train_score=False,
---> 50                 verbose=0)
     51         score = np.mean(scores['test_score'])
     52         std = np.std(scores['test_score'])
     53         status = STATUS_OK
     54     except Exception as e:

...........................................................................
/home/aquemy/.local/lib/python2.7/site-packages/sklearn/model_selection/_validation.py in cross_validate(estimator=Pipeline(memory=None,
     steps=[('normalizer',... random_state=42, verbose=0, warm_start=False))]), X=array([[5.1, 3.5, 1.4, 0.2],
       [4.9, 3. , 1....2, 3.4, 5.4, 2.3],
       [5.9, 3. , 5.1, 1.8]]), y=array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,... 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]), groups=None, scoring=None, cv=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1, verbose=0, fit_params=None, pre_dispatch='2*n_jobs', return_train_score=False, return_estimator=False, error_score='raise-deprecating')
    235         delayed(_fit_and_score)(
    236             clone(estimator), X, y, scorers, train, test, verbose, None,
    237             fit_params, return_train_score=return_train_score,
    238             return_times=True, return_estimator=return_estimator,
    239             error_score=error_score)
--> 240         for train, test in cv.split(X, y, groups))
        cv.split = <bound method StratifiedKFold.split of Stratifie...d(n_splits=10, random_state=None, shuffle=False)>
        X = array([[5.1, 3.5, 1.4, 0.2],
       [4.9, 3. , 1....2, 3.4, 5.4, 2.3],
       [5.9, 3. , 5.1, 1.8]])
        y = array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,... 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2])
        groups = None
    241 
    242     zipped_scores = list(zip(*scores))
    243     if return_train_score:
    244         train_scores = zipped_scores.pop(0)

...........................................................................
/home/aquemy/.local/lib/python2.7/site-packages/sklearn/externals/joblib/parallel.py in __call__(self=Parallel(n_jobs=-1), iterable=<generator object <genexpr>>)
    925                 # No need to wait for async callbacks to trigger to
    926                 # consumption.
    927                 self._iterating = False
    928 
    929             with self._backend.retrieval_context():
--> 930                 self.retrieve()
        self.retrieve = <bound method Parallel.retrieve of Parallel(n_jobs=-1)>
    931             # Make sure that we get a last message telling us we are done
    932             elapsed_time = time.time() - self._start_time
    933             self._print('Done %3i out of %3i | elapsed: %s finished',
    934                         (len(self._output), len(self._output),

---------------------------------------------------------------------------
Joblib worker traceback:
---------------------------------------------------------------------------
ValueError                                         Mon Jun 17 13:11:03 2019
PID: 20951                                  Python 2.7.15+: /usr/bin/python
...........................................................................
/home/aquemy/.local/lib/python2.7/site-packages/sklearn/externals/joblib/parallel.py in __call__(self=<sklearn.externals.joblib.parallel.BatchedCalls object>)
    220     def __call__(self):
    221         # Set the default nested backend to self._backend but do not set the
    222         # change the default number of processes to -1
    223         with parallel_backend(self._backend, n_jobs=self._n_jobs):
    224             return [func(*args, **kwargs)
--> 225                     for func, args, kwargs in self.items]
        func = <function _fit_and_score>
        args = (Pipeline(memory=None,
     steps=[('normalizer',... random_state=42, verbose=0, warm_start=False))]), array([[5.1, 3.5, 1.4, 0.2],
       [4.9, 3. , 1....2, 3.4, 5.4, 2.3],
       [5.9, 3. , 5.1, 1.8]]), array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,... 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]), {'score': <function _passthrough_scorer>}, array([  5,   6,   7,   8,   9,  10,  11,  12,  ..., 142, 143, 144,
       145, 146, 147, 148, 149]), array([  0,   1,   2,   3,   4,  50,  51,  52,  53,  54, 100, 101, 102,
       103, 104]), 0, None, None)
        kwargs = {'error_score': 'raise-deprecating', 'return_estimator': False, 'return_times': True, 'return_train_score': False}
        self.items = [(<function _fit_and_score>, (Pipeline(memory=None,
     steps=[('normalizer',... random_state=42, verbose=0, warm_start=False))]), array([[5.1, 3.5, 1.4, 0.2],
       [4.9, 3. , 1....2, 3.4, 5.4, 2.3],
       [5.9, 3. , 5.1, 1.8]]), array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,... 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]), {'score': <function _passthrough_scorer>}, array([  5,   6,   7,   8,   9,  10,  11,  12,  ..., 142, 143, 144,
       145, 146, 147, 148, 149]), array([  0,   1,   2,   3,   4,  50,  51,  52,  53,  54, 100, 101, 102,
       103, 104]), 0, None, None), {'error_score': 'raise-deprecating', 'return_estimator': False, 'return_times': True, 'return_train_score': False})]
    226 
    227     def __len__(self):
    228         return self._size
    229 

...........................................................................
/home/aquemy/.local/lib/python2.7/site-packages/sklearn/model_selection/_validation.py in _fit_and_score(estimator=Pipeline(memory=None,
     steps=[('normalizer',... random_state=42, verbose=0, warm_start=False))]), X=array([[5.1, 3.5, 1.4, 0.2],
       [4.9, 3. , 1....2, 3.4, 5.4, 2.3],
       [5.9, 3. , 5.1, 1.8]]), y=array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,... 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]), scorer={'score': <function _passthrough_scorer>}, train=array([  5,   6,   7,   8,   9,  10,  11,  12,  ..., 142, 143, 144,
       145, 146, 147, 148, 149]), test=array([  0,   1,   2,   3,   4,  50,  51,  52,  53,  54, 100, 101, 102,
       103, 104]), verbose=0, parameters=None, fit_params={}, return_train_score=False, return_parameters=False, return_n_test_samples=False, return_times=True, return_estimator=False, error_score='raise-deprecating')
    523 
    524     try:
    525         if y_train is None:
    526             estimator.fit(X_train, **fit_params)
    527         else:
--> 528             estimator.fit(X_train, y_train, **fit_params)
        estimator.fit = <bound method Pipeline.fit of Pipeline(memory=No...random_state=42, verbose=0, warm_start=False))])>
        X_train = array([[5.4, 3.9, 1.7, 0.4],
       [4.6, 3.4, 1....2, 3.4, 5.4, 2.3],
       [5.9, 3. , 5.1, 1.8]])
        y_train = array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,
       2, 2, 2])
        fit_params = {}
    529 
    530     except Exception as e:
    531         # Note fit time as time until error
    532         fit_time = time.time() - start_time

...........................................................................
/usr/local/lib/python2.7/dist-packages/imblearn/pipeline.py in fit(self=Pipeline(memory=None,
     steps=[('normalizer',... random_state=42, verbose=0, warm_start=False))]), X=array([[5.4, 3.9, 1.7, 0.4],
       [4.6, 3.4, 1....2, 3.4, 5.4, 2.3],
       [5.9, 3. , 5.1, 1.8]]), y=array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,
       2, 2, 2]), **fit_params={})
    234             This estimator
    235 
    236         """
    237         Xt, yt, fit_params = self._fit(X, y, **fit_params)
    238         if self._final_estimator is not None:
--> 239             self._final_estimator.fit(Xt, yt, **fit_params)
        self._final_estimator.fit = <bound method RandomForestClassifier.fit of Rand...e, random_state=42, verbose=0, warm_start=False)>
        Xt = array([[-1.98266263, -1.3698261 ],
       [-2.52...-1.04473537],
       [ 1.01037195, -0.06807576]])
        yt = array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,
       2, 2, 2])
        fit_params = {}
    240         return self
    241 
    242     def fit_transform(self, X, y=None, **fit_params):
    243         """Fit the model and transform with the final estimator

...........................................................................
/home/aquemy/.local/lib/python2.7/site-packages/sklearn/ensemble/forest.py in fit(self=RandomForestClassifier(bootstrap=True, class_wei...se, random_state=42, verbose=0, warm_start=False), X=array([[-1.9826627 , -1.3698261 ],
       [-2.52...      [ 1.0103719 , -0.06807576]], dtype=float32), y=array([[0.],
       [0.],
       [0.],
       [0...    [2.],
       [2.],
       [2.],
       [2.]]), sample_weight=None)
    328             trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,
    329                              **_joblib_parallel_args(prefer='threads'))(
    330                 delayed(_parallel_build_trees)(
    331                     t, self, X, y, sample_weight, i, len(trees),
    332                     verbose=self.verbose, class_weight=self.class_weight)
--> 333                 for i, t in enumerate(trees))
        i = 49
    334 
    335             # Collect newly grown trees
    336             self.estimators_.extend(trees)
    337 

...........................................................................
/home/aquemy/.local/lib/python2.7/site-packages/sklearn/externals/joblib/parallel.py in __call__(self=Parallel(n_jobs=1), iterable=<generator object <genexpr>>)
    912             # self._original_iterator is None, then this means either
    913             # that pre_dispatch == "all", n_jobs == 1 or that the first batch
    914             # was very quick and its callback already dispatched all the
    915             # remaining jobs.
    916             self._iterating = False
--> 917             if self.dispatch_one_batch(iterator):
        self.dispatch_one_batch = <bound method Parallel.dispatch_one_batch of Parallel(n_jobs=1)>
        iterator = <generator object <genexpr>>
    918                 self._iterating = self._original_iterator is not None
    919 
    920             while self.dispatch_one_batch(iterator):
    921                 pass

...........................................................................
/home/aquemy/.local/lib/python2.7/site-packages/sklearn/externals/joblib/parallel.py in dispatch_one_batch(self=Parallel(n_jobs=1), iterator=<generator object <genexpr>>)
    754                                  self._pickle_cache)
    755             if len(tasks) == 0:
    756                 # No more tasks available in the iterator: tell caller to stop.
    757                 return False
    758             else:
--> 759                 self._dispatch(tasks)
        self._dispatch = <bound method Parallel._dispatch of Parallel(n_jobs=1)>
        tasks = <sklearn.externals.joblib.parallel.BatchedCalls object>
    760                 return True
    761 
    762     def _print(self, msg, msg_args):
    763         """Display the message on stout or stderr depending on verbosity"""

...........................................................................
/home/aquemy/.local/lib/python2.7/site-packages/sklearn/externals/joblib/parallel.py in _dispatch(self=Parallel(n_jobs=1), batch=<sklearn.externals.joblib.parallel.BatchedCalls object>)
    711 
    712         dispatch_timestamp = time.time()
    713         cb = BatchCompletionCallBack(dispatch_timestamp, len(batch), self)
    714         with self._lock:
    715             job_idx = len(self._jobs)
--> 716             job = self._backend.apply_async(batch, callback=cb)
        job = undefined
        self._backend.apply_async = <bound method SequentialBackend.apply_async of <...lib._parallel_backends.SequentialBackend object>>
        batch = <sklearn.externals.joblib.parallel.BatchedCalls object>
        cb = <sklearn.externals.joblib.parallel.BatchCompletionCallBack object>
    717             # A job can complete so quickly than its callback is
    718             # called before we get here, causing self._jobs to
    719             # grow. To ensure correct results ordering, .insert is
    720             # used (rather than .append) in the following line

...........................................................................
/home/aquemy/.local/lib/python2.7/site-packages/sklearn/externals/joblib/_parallel_backends.py in apply_async(self=<sklearn.externals.joblib._parallel_backends.SequentialBackend object>, func=<sklearn.externals.joblib.parallel.BatchedCalls object>, callback=<sklearn.externals.joblib.parallel.BatchCompletionCallBack object>)
    177             raise ValueError('n_jobs == 0 in Parallel has no meaning')
    178         return 1
    179 
    180     def apply_async(self, func, callback=None):
    181         """Schedule a func to be run"""
--> 182         result = ImmediateResult(func)
        result = undefined
        func = <sklearn.externals.joblib.parallel.BatchedCalls object>
    183         if callback:
    184             callback(result)
    185         return result
    186 

...........................................................................
/home/aquemy/.local/lib/python2.7/site-packages/sklearn/externals/joblib/_parallel_backends.py in __init__(self=<sklearn.externals.joblib._parallel_backends.ImmediateResult object>, batch=<sklearn.externals.joblib.parallel.BatchedCalls object>)
    544 
    545 class ImmediateResult(object):
    546     def __init__(self, batch):
    547         # Don't delay the application, to avoid keeping the input
    548         # arguments in memory
--> 549         self.results = batch()
        self.results = undefined
        batch = <sklearn.externals.joblib.parallel.BatchedCalls object>
    550 
    551     def get(self):
    552         return self.results
    553 

...........................................................................
/home/aquemy/.local/lib/python2.7/site-packages/sklearn/externals/joblib/parallel.py in __call__(self=<sklearn.externals.joblib.parallel.BatchedCalls object>)
    220     def __call__(self):
    221         # Set the default nested backend to self._backend but do not set the
    222         # change the default number of processes to -1
    223         with parallel_backend(self._backend, n_jobs=self._n_jobs):
    224             return [func(*args, **kwargs)
--> 225                     for func, args, kwargs in self.items]
        func = <function _parallel_build_trees>
        args = (DecisionTreeClassifier(class_weight=None, criter...=False, random_state=1608637542, splitter='best'), RandomForestClassifier(bootstrap=True, class_wei...se, random_state=42, verbose=0, warm_start=False), array([[-1.9826627 , -1.3698261 ],
       [-2.52...      [ 1.0103719 , -0.06807576]], dtype=float32), array([[0.],
       [0.],
       [0.],
       [0...    [2.],
       [2.],
       [2.],
       [2.]]), None, 0, 50)
        kwargs = {'class_weight': None, 'verbose': 0}
        self.items = [(<function _parallel_build_trees>, (DecisionTreeClassifier(class_weight=None, criter...=False, random_state=1608637542, splitter='best'), RandomForestClassifier(bootstrap=True, class_wei...se, random_state=42, verbose=0, warm_start=False), array([[-1.9826627 , -1.3698261 ],
       [-2.52...      [ 1.0103719 , -0.06807576]], dtype=float32), array([[0.],
       [0.],
       [0.],
       [0...    [2.],
       [2.],
       [2.],
       [2.]]), None, 0, 50), {'class_weight': None, 'verbose': 0})]
    226 
    227     def __len__(self):
    228         return self._size
    229 

...........................................................................
/home/aquemy/.local/lib/python2.7/site-packages/sklearn/ensemble/forest.py in _parallel_build_trees(tree=DecisionTreeClassifier(class_weight=None, criter...=False, random_state=1608637542, splitter='best'), forest=RandomForestClassifier(bootstrap=True, class_wei...se, random_state=42, verbose=0, warm_start=False), X=array([[-1.9826627 , -1.3698261 ],
       [-2.52...      [ 1.0103719 , -0.06807576]], dtype=float32), y=array([[0.],
       [0.],
       [0.],
       [0...    [2.],
       [2.],
       [2.],
       [2.]]), sample_weight=None, tree_idx=0, n_trees=50, verbose=0, class_weight=None)
    114                 simplefilter('ignore', DeprecationWarning)
    115                 curr_sample_weight *= compute_sample_weight('auto', y, indices)
    116         elif class_weight == 'balanced_subsample':
    117             curr_sample_weight *= compute_sample_weight('balanced', y, indices)
    118 
--> 119         tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)
        tree.fit = <bound method DecisionTreeClassifier.fit of Deci...False, random_state=1608637542, splitter='best')>
        X = array([[-1.9826627 , -1.3698261 ],
       [-2.52...      [ 1.0103719 , -0.06807576]], dtype=float32)
        y = array([[0.],
       [0.],
       [0.],
       [0...    [2.],
       [2.],
       [2.],
       [2.]])
        sample_weight = None
        curr_sample_weight = array([3., 3., 0., 1., 1., 2., 2., 0., 1., 2., 0... 1., 0., 1., 0., 1., 1., 1., 1., 1., 1., 0., 0.])
    120     else:
    121         tree.fit(X, y, sample_weight=sample_weight, check_input=False)
    122 
    123     return tree

...........................................................................
/home/aquemy/.local/lib/python2.7/site-packages/sklearn/tree/tree.py in fit(self=DecisionTreeClassifier(class_weight=None, criter...=False, random_state=1608637542, splitter='best'), X=array([[-1.9826627 , -1.3698261 ],
       [-2.52...      [ 1.0103719 , -0.06807576]], dtype=float32), y=array([[0.],
       [0.],
       [0.],
       [0...    [2.],
       [2.],
       [2.],
       [2.]]), sample_weight=array([3., 3., 0., 1., 1., 2., 2., 0., 1., 2., 0... 1., 0., 1., 0., 1., 1., 1., 1., 1., 1., 0., 0.]), check_input=False, X_idx_sorted=None)
    796 
    797         super(DecisionTreeClassifier, self).fit(
    798             X, y,
    799             sample_weight=sample_weight,
    800             check_input=check_input,
--> 801             X_idx_sorted=X_idx_sorted)
        X_idx_sorted = None
    802         return self
    803 
    804     def predict_proba(self, X, check_input=True):
    805         """Predict class probabilities of the input samples X.

...........................................................................
/home/aquemy/.local/lib/python2.7/site-packages/sklearn/tree/tree.py in fit(self=DecisionTreeClassifier(class_weight=None, criter...=False, random_state=1608637542, splitter='best'), X=array([[-1.9826627 , -1.3698261 ],
       [-2.52...      [ 1.0103719 , -0.06807576]], dtype=float32), y=array([[0.],
       [0.],
       [0.],
       [0...    [2.],
       [2.],
       [2.],
       [2.]]), sample_weight=array([3., 3., 0., 1., 1., 2., 2., 0., 1., 2., 0... 1., 0., 1., 0., 1., 1., 1., 1., 1., 1., 0., 0.]), check_input=False, X_idx_sorted=None)
    237         if not 0 <= self.min_weight_fraction_leaf <= 0.5:
    238             raise ValueError("min_weight_fraction_leaf must in [0, 0.5]")
    239         if max_depth <= 0:
    240             raise ValueError("max_depth must be greater than zero. ")
    241         if not (0 < max_features <= self.n_features_):
--> 242             raise ValueError("max_features must be in (0, n_features]")
    243         if not isinstance(max_leaf_nodes, (numbers.Integral, np.integer)):
    244             raise ValueError("max_leaf_nodes must be integral number but was "
    245                              "%r" % max_leaf_nodes)
    246         if -1 < max_leaf_nodes < 2:

ValueError: max_features must be in (0, n_features]
___________________________________________________________________________
Best score: 0.966666666667 (0.04472135955) [J] | Score: 0.0 (0.0) [J]
Best score: 0.966666666667 (0.04472135955) [J] | Score: 0.933333333333 (0.0596284794) [J]
Best score: 0.966666666667 (0.04472135955) [J] | Score: 0.666666666667 (1.11022302463e-16) [J]
Best score: 0.966666666667 (0.04472135955) [J] | Score: 0.8 (0.0894427191) [J]
Best score: 0.966666666667 (0.04472135955) [J] | Score: 0.953333333333 (0.0520683311727) [J]
Best score: 0.966666666667 (0.04472135955) [J] | Score: 0.96 (0.0533333333333) [J]
Best score: 0.966666666667 (0.04472135955) [J] | Score: 0.7 (0.0333333333333) [J]
Best score: 0.966666666667 (0.04472135955) [J] | Score: 0.913333333333 (0.0669991708075) [J]
Best score: 0.966666666667 (0.04472135955) [J] | Score: 0.966666666667 (0.0333333333333) [J]
Best score: 0.966666666667 (0.04472135955) [J] | Score: 0.966666666667 (0.0333333333333) [J]
Best score: 0.966666666667 (0.04472135955) [J] | Score: 0.966666666667 (0.0333333333333) [J]
Best score: 0.966666666667 (0.04472135955) [J] | Score: 0.953333333333 (0.0426874949162) [J]
Best score: 0.966666666667 (0.04472135955) [J] | Score: 0.966666666667 (0.0333333333333) [J]
Best score: 0.966666666667 (0.04472135955) [J] | Score: 0.96 (0.0442216638714) [J]
Best score: 0.966666666667 (0.04472135955) [J] | Score: 0.96 (0.0442216638714) [J]
Best score: 0.966666666667 (0.04472135955) [J] | Score: 0.946666666667 (0.049888765157) [J]
Best score: 0.966666666667 (0.04472135955) [J] | Score: 0.9 (0.04472135955) [J]
JoblibValueError
___________________________________________________________________________
...........................................................................
/home/aquemy/dev/dp_hyperparameters/extension/main.py in <module>()
     27 
     28     serializer.serialize_results(scenario, policy)
     29 
     30 if __name__ == "__main__":
     31     args = cli.parse_args()
---> 32     main(args)

...........................................................................
/home/aquemy/dev/dp_hyperparameters/extension/main.py in main(args=Namespace(customize=[(['control', 'seed'], '42')...io='./scenarios/rf_iris_joint.yaml', verbosity=0))
     21         test_size=0.4, 
     22         random_state=scenario['control']['seed']
     23     )
     24 
     25     policy = policies.initiate(scenario['setup']['policy'], config)
---> 26     policy.run(X,y)
        policy.run = <bound method Joint.run of <experiment.policies.joint.Joint object>>
        X = array([[5.1, 3.5, 1.4, 0.2],
       [4.9, 3. , 1....2, 3.4, 5.4, 2.3],
       [5.9, 3. , 5.1, 1.8]])
        y = array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,... 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2])
     27 
     28     serializer.serialize_results(scenario, policy)
     29 
     30 if __name__ == "__main__":

...........................................................................
/home/aquemy/dev/dp_hyperparameters/extension/experiment/policies/joint.py in run(self=<experiment.policies.joint.Joint object>, X=array([[5.1, 3.5, 1.4, 0.2],
       [4.9, 3. , 1....2, 3.4, 5.4, 2.3],
       [5.9, 3. , 5.1, 1.8]]), y=array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,... 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]))
     32             algo=tpe.suggest, 
     33             max_evals=None,
     34             max_time=self.config['time'],     
     35             trials=trials,
     36             show_progressbar=False,
---> 37             verbose=0
     38         )
     39 
     40         best_config = self.context['best_config']
     41         super(Joint, self).display_step_results(best_config)

...........................................................................
/home/aquemy/dev/dp_hyperparameters/extension/hyperopt/fmin.py in fmin(fn=<functools.partial object>, space={'algorithm': {'bootstrap': <hyperopt.pyll.base.Apply object>, 'criterion': <hyperopt.pyll.base.Apply object>, 'max_depth': <hyperopt.pyll.base.Apply object>, 'max_features': <hyperopt.pyll.base.Apply object>, 'max_leaf_nodes': <hyperopt.pyll.base.Apply object>, 'min_samples_split': <hyperopt.pyll.base.Apply object>, 'n_estimators': <hyperopt.pyll.base.Apply object>}, 'pipeline': {'features': <hyperopt.pyll.base.Apply object>, 'normalizer': <hyperopt.pyll.base.Apply object>, 'rebalance': <hyperopt.pyll.base.Apply object>}}, algo=<function suggest>, max_evals=9223372036854775807, max_time=300, trials=<hyperopt.base.Trials object>, rstate=<mtrand.RandomState object>, allow_trials_fmin=True, pass_expr_memo_ctrl=None, catch_eval_exceptions=False, verbose=0, return_argmin=True, points_to_evaluate=None, max_queue_len=1, show_progressbar=False)
    406             pass_expr_memo_ctrl=pass_expr_memo_ctrl,
    407             verbose=verbose,
    408             catch_eval_exceptions=catch_eval_exceptions,
    409             return_argmin=return_argmin,
    410             show_progressbar=show_progressbar,
--> 411             max_time=max_time
        max_time = 300
    412         )
    413 
    414     if trials is None:
    415         if points_to_evaluate is None:

...........................................................................
/home/aquemy/dev/dp_hyperparameters/extension/hyperopt/base.py in fmin(self=<hyperopt.base.Trials object>, fn=<functools.partial object>, space={'algorithm': {'bootstrap': <hyperopt.pyll.base.Apply object>, 'criterion': <hyperopt.pyll.base.Apply object>, 'max_depth': <hyperopt.pyll.base.Apply object>, 'max_features': <hyperopt.pyll.base.Apply object>, 'max_leaf_nodes': <hyperopt.pyll.base.Apply object>, 'min_samples_split': <hyperopt.pyll.base.Apply object>, 'n_estimators': <hyperopt.pyll.base.Apply object>}, 'pipeline': {'features': <hyperopt.pyll.base.Apply object>, 'normalizer': <hyperopt.pyll.base.Apply object>, 'rebalance': <hyperopt.pyll.base.Apply object>}}, algo=<function suggest>, max_evals=9223372036854775807, max_time=300, rstate=<mtrand.RandomState object>, verbose=0, pass_expr_memo_ctrl=None, catch_eval_exceptions=False, return_argmin=True, show_progressbar=False)
    636             verbose=verbose,
    637             allow_trials_fmin=False,  # -- prevent recursion
    638             pass_expr_memo_ctrl=pass_expr_memo_ctrl,
    639             catch_eval_exceptions=catch_eval_exceptions,
    640             return_argmin=return_argmin,
--> 641             show_progressbar=show_progressbar)
        show_progressbar = False
    642 
    643 
    644 def trials_from_docs(docs, validate=True, **kwargs):
    645     """Construct a Trials base class instance from a list of trials documents

...........................................................................
/home/aquemy/dev/dp_hyperparameters/extension/hyperopt/fmin.py in fmin(fn=<functools.partial object>, space={'algorithm': {'bootstrap': <hyperopt.pyll.base.Apply object>, 'criterion': <hyperopt.pyll.base.Apply object>, 'max_depth': <hyperopt.pyll.base.Apply object>, 'max_features': <hyperopt.pyll.base.Apply object>, 'max_leaf_nodes': <hyperopt.pyll.base.Apply object>, 'min_samples_split': <hyperopt.pyll.base.Apply object>, 'n_estimators': <hyperopt.pyll.base.Apply object>}, 'pipeline': {'features': <hyperopt.pyll.base.Apply object>, 'normalizer': <hyperopt.pyll.base.Apply object>, 'rebalance': <hyperopt.pyll.base.Apply object>}}, algo=<function suggest>, max_evals=9223372036854775807, max_time=300, trials=<hyperopt.base.Trials object>, rstate=<mtrand.RandomState object>, allow_trials_fmin=False, pass_expr_memo_ctrl=None, catch_eval_exceptions=False, verbose=0, return_argmin=True, points_to_evaluate=None, max_queue_len=1, show_progressbar=False)
    426                     verbose=verbose,
    427                     max_queue_len=max_queue_len,
    428                     show_progressbar=show_progressbar,
    429                     max_time=max_time)
    430     rval.catch_eval_exceptions = catch_eval_exceptions
--> 431     rval.exhaust()
        rval.exhaust = <bound method FMinIter.exhaust of <hyperopt.fmin.FMinIter object>>
    432     if return_argmin:
    433         return trials.argmin
    434     elif len(trials) > 0:
    435         # Only if there are some succesfull trail runs, return the best point in the evaluation space

...........................................................................
/home/aquemy/dev/dp_hyperparameters/extension/hyperopt/fmin.py in exhaust(self=<hyperopt.fmin.FMinIter object>)
    273             raise StopIteration()
    274         return self.trials
    275 
    276     def exhaust(self):
    277         n_done = len(self.trials)
--> 278         self.run(self.max_evals - n_done, block_until_done=self.asynchronous)
        self.run = <bound method FMinIter.run of <hyperopt.fmin.FMinIter object>>
        self.max_evals = 9223372036854775807
        n_done = 0
        self.asynchronous = False
    279         self.trials.refresh()
    280         return self
    281 
    282 

...........................................................................
/home/aquemy/dev/dp_hyperparameters/extension/hyperopt/fmin.py in run(self=<hyperopt.fmin.FMinIter object>, N=9223372036854775807, block_until_done=False)
    232                     if self.asynchronous:
    233                         # -- wait for workers to fill in the trials
    234                         time.sleep(self.poll_interval_secs)
    235                     else:
    236                         # -- loop over trials and do the jobs directly
--> 237                         self.serial_evaluate()
        self.serial_evaluate = <bound method FMinIter.serial_evaluate of <hyperopt.fmin.FMinIter object>>
    238                     try:
    239                         res = [d['result']['loss'] for d in
    240                                          self.trials.trials if
    241                                          d['result']['status'] == 'ok']

...........................................................................
/home/aquemy/dev/dp_hyperparameters/extension/hyperopt/fmin.py in serial_evaluate(self=<hyperopt.fmin.FMinIter object>, N=-1)
    138                 trial['book_time'] = now
    139                 trial['refresh_time'] = now
    140                 spec = base.spec_from_misc(trial['misc'])
    141                 ctrl = base.Ctrl(self.trials, current_trial=trial)
    142                 try:
--> 143                     result = self.domain.evaluate(spec, ctrl)
        result = undefined
        self.domain.evaluate = <bound method Domain.evaluate of <hyperopt.base.Domain object>>
        spec = {'bootstrap': 0, 'criterion': 0, 'features': 1, 'features_PCA_features__n_components': 0, 'max_depth': 4, 'max_features': 1, 'max_leaf_nodes': 3, 'min_samples_split': 1, 'n_estimators': 2, 'normalizer': 3, ...}
        ctrl = <hyperopt.base.Ctrl object>
    144                 except Exception as e:
    145                     logger.info('job exception: %s' % str(e))
    146                     trial['state'] = base.JOB_STATE_ERROR
    147                     trial['misc']['error'] = (str(type(e)), str(e))

...........................................................................
/home/aquemy/dev/dp_hyperparameters/extension/hyperopt/base.py in evaluate(self=<hyperopt.base.Domain object>, config={'bootstrap': 0, 'criterion': 0, 'features': 1, 'features_PCA_features__n_components': 0, 'max_depth': 4, 'max_features': 1, 'max_leaf_nodes': 3, 'min_samples_split': 1, 'n_estimators': 2, 'normalizer': 3, ...}, ctrl=<hyperopt.base.Ctrl object>, attach_attachments=True)
    841             #    or the normal Python part (self.fn)
    842             pyll_rval = pyll.rec_eval(
    843                 self.expr,
    844                 memo=memo,
    845                 print_node_on_error=self.rec_eval_print_node_on_error)
--> 846             rval = self.fn(pyll_rval)
        rval = undefined
        self.fn = <functools.partial object>
        pyll_rval = {'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': None, 'max_features': 2, 'max_leaf_nodes': None, 'min_samples_split': 3, 'n_estimators': 50}, 'pipeline': {'features': ('features_PCA', {'features__n_components': 1}), 'normalizer': ('normalizer_MinMaxScaler', {}), 'rebalance': ('rebalance_NoneType', {})}}
    847 
    848         if isinstance(rval, (float, int, np.number)):
    849             dict_rval = {'loss': float(rval), 'status': STATUS_OK}
    850         else:

...........................................................................
/home/aquemy/dev/dp_hyperparameters/extension/experiment/objective.py in objective_joint(wconfig={'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': None, 'max_features': 2, 'max_leaf_nodes': None, 'min_samples_split': 3, 'n_estimators': 50}, 'pipeline': {'features': ('features_PCA', {'features__n_components': 1}), 'normalizer': ('normalizer_MinMaxScaler', {}), 'rebalance': ('rebalance_NoneType', {})}}, algorithm='RandomForest', X=array([[5.1, 3.5, 1.4, 0.2],
       [4.9, 3. , 1....2, 3.4, 5.4, 2.3],
       [5.9, 3. , 5.1, 1.8]]), y=array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,... 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]), context={'baseline_score': 0.9466666666666667, 'baseline_score_std': 0.04988876515698587, 'best_config': {'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': 1, 'max_features': None, 'max_leaf_nodes': None, 'min_samples_split': 5, 'n_estimators': 75}, 'config_hash': {'algorithm': '94b0d7a654c508cc63643f78fe4f0f07e6f07c1e', 'config': '4403c5a85e951938d3c454e961d3a412780722f6', 'pipeline': '3e47444880d8367fbac2faaba2e52a917274aa58'}, 'duration': 0.8397619724273682, 'iteration': 2, 'loss': 0.03333333333333344, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_PCA', {'features__n_components': 3}), 'normalizer': ('normalizer_MinMaxScaler', {}), 'rebalance': ('rebalance_NoneType', {})}, 'score': 0.9666666666666666, ...}, 'history': [{'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': 2, 'max_features': None, 'max_leaf_nodes': 5, 'min_samples_split': 2, 'n_estimators': 75}, 'config_hash': {'algorithm': '3af5b0cce71c8fe2545246ca24ff5bc3dd516e06', 'config': 'db6ac7e6d348155757e4794bb5f88fe2b4f63d50', 'pipeline': '8d59f4b94cef6be9306ed86a22a9570fa670d567'}, 'duration': 1.149928092956543, 'iteration': 0, 'loss': 0.046666666666666634, 'max_history_score': 0.9533333333333334, 'max_history_score_std': 0.059999999999999984, 'max_history_step': 'joint', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 4, 'features__selectkbest__k': 3}), 'normalizer': ('normalizer_StandardScaler', {'normalizer__with_mean': True, 'normalizer__with_std': True}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 6})}, 'score': 0.9533333333333334, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': 1, 'max_features': 2, 'max_leaf_nodes': 2, 'min_samples_split': 5, 'n_estimators': 100}, 'config_hash': {'algorithm': 'e13eb05fd9a62d2f63bbb1c1deff0cd620d5e6ab', 'config': '4db6fb84d85f52659f780e682ffac5712c3d8a94', 'pipeline': '64c9a1ca9d53ae67244bdd942f4db36a3c05218c'}, 'duration': 1.7678282260894775, 'iteration': 1, 'loss': 0.18000000000000005, 'max_history_score': 0.9533333333333334, 'max_history_score_std': 0.059999999999999984, 'max_history_step': 'joint', 'pipeline': {'features': ('features_NoneType', {}), 'normalizer': ('normalizer_PowerTransformer', {}), 'rebalance': ('rebalance_NearMiss', {'rebalance__n_neighbors': 1})}, 'score': 0.82, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': 1, 'max_features': None, 'max_leaf_nodes': None, 'min_samples_split': 5, 'n_estimators': 75}, 'config_hash': {'algorithm': '94b0d7a654c508cc63643f78fe4f0f07e6f07c1e', 'config': '4403c5a85e951938d3c454e961d3a412780722f6', 'pipeline': '3e47444880d8367fbac2faaba2e52a917274aa58'}, 'duration': 0.8397619724273682, 'iteration': 2, 'loss': 0.03333333333333344, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_PCA', {'features__n_components': 3}), 'normalizer': ('normalizer_MinMaxScaler', {}), 'rebalance': ('rebalance_NoneType', {})}, 'score': 0.9666666666666666, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': None, 'max_features': None, 'max_leaf_nodes': 3, 'min_samples_split': 3, 'n_estimators': 75}, 'config_hash': {'algorithm': 'e8332f0a8902bda03bf70e7978cc5d52affb29d3', 'config': 'a064e2df18ab98d44dabcefbc7bed94913f1d0be', 'pipeline': '7eea819c2a8c103c4b1e9e9c1e224aebba95081f'}, 'duration': 0.8501448631286621, 'iteration': 3, 'loss': 0.053333333333333344, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 2, 'features__selectkbest__k': 4}), 'normalizer': ('normalizer_NoneType', {}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 7})}, 'score': 0.9466666666666667, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'entropy', 'max_depth': 3, 'max_features': 3, 'max_leaf_nodes': None, 'min_samples_split': 5, 'n_estimators': 75}, 'config_hash': {'algorithm': '7a4491035bc6bd737fe9a8cda8a79a02d02d5c74', 'config': '0ddb6f5cab3db4dddd7682966a57205f3e329ad4', 'pipeline': 'a9ae03fe38334f6868cbf84cdd3d629d4bbe3fb0'}, 'duration': 1.1026010513305664, 'iteration': 4, 'loss': 0.05999999999999994, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 2, 'features__selectkbest__k': 1}), 'normalizer': ('normalizer_NoneType', {}), 'rebalance': ('rebalance_NoneType', {})}, 'score': 0.9400000000000001, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'gini', 'max_depth': 3, 'max_features': 1, 'max_leaf_nodes': 5, 'min_samples_split': 2, 'n_estimators': 25}, 'config_hash': {'algorithm': '9826d20b2d6a0f559cf7f16450ce7526f07e8434', 'config': '49f25751bca61cdd461a8cbd2923689b642f98ed', 'pipeline': '19b249664c5bf067de1fed4334a296f947ce774a'}, 'duration': 0.35647010803222656, 'iteration': 5, 'loss': 0.046666666666666634, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_NoneType', {}), 'normalizer': ('normalizer_NoneType', {}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 6})}, 'score': 0.9533333333333334, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'gini', 'max_depth': 2, 'max_features': 1, 'max_leaf_nodes': 2, 'min_samples_split': 2, 'n_estimators': 50}, 'config_hash': {'algorithm': '0a4f6fbb07e0f32c6f675489a0fc82eee05bd8e1', 'config': '5c3a2b6f5e63fb45f10e41e0318b354912ec44f6', 'pipeline': 'dc3b9f176f090005e38b142f11d80e93a7dc5d5e'}, 'duration': 0.7213859558105469, 'iteration': 6, 'loss': 0.31333333333333324, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 1, 'features__selectkbest__k': 4}), 'normalizer': ('normalizer_PowerTransformer', {}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 7})}, 'score': 0.6866666666666668, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'entropy', 'max_depth': 4, 'max_features': 3, 'max_leaf_nodes': 5, 'min_samples_split': 5, 'n_estimators': 10}, 'config_hash': {'algorithm': 'b8112b97ecfc10f00a195af661dcc861cac21289', 'config': 'd3b129b397350f1b6572651c67c01de49b4b174c', 'pipeline': '5b0357ed7072c37b3d6f458bb5d49ff7d825f603'}, 'duration': 0.8299109935760498, 'iteration': 7, 'loss': 1.0, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_PCA', {'features__n_components': 2}), 'normalizer': ('normalizer_StandardScaler', {'normalizer__with_mean': True, 'normalizer__with_std': False}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 6})}, 'score': 0.0, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'gini', 'max_depth': 4, 'max_features': None, 'max_leaf_nodes': 2, 'min_samples_split': 5, 'n_estimators': 100}, 'config_hash': {'algorithm': '40ca24df19b8d164d9d098a6bed1ce056fbbb961', 'config': '813bde1108cc3c4b9bfb3a22cbb421bda7eac671', 'pipeline': '74a7b8705a1c22f7dea5e44e4ebda8f1e48add71'}, 'duration': 2.2111589908599854, 'iteration': 8, 'loss': 0.33333333333333326, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_PCA', {'features__n_components': 2}), 'normalizer': ('normalizer_StandardScaler', {'normalizer__with_mean': False, 'normalizer__with_std': True}), 'rebalance': ('rebalance_NearMiss', {'rebalance__n_neighbors': 2})}, 'score': 0.6666666666666667, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'entropy', 'max_depth': 2, 'max_features': 1, 'max_leaf_nodes': 5, 'min_samples_split': 2, 'n_estimators': 100}, 'config_hash': {'algorithm': '331418a5c12cf1453876eef85e9d98fc8e54fa11', 'config': '31930b6860ed406d59bf7e59ba1925d94704bd3b', 'pipeline': '054bef356f90ec6f644ef3ffc688766744db51c2'}, 'duration': 1.0501940250396729, 'iteration': 9, 'loss': 0.053333333333333344, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_SelectKBest', {'features__k': 1}), 'normalizer': ('normalizer_RobustScaler', {'normalizer__quantile_range': (...), 'normalizer__with_centering': True, 'normalizer__with_scaling': True}), 'rebalance': ('rebalance_NearMiss', {'rebalance__n_neighbors': 2})}, 'score': 0.9466666666666667, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'entropy', 'max_depth': 3, 'max_features': None, 'max_leaf_nodes': 3, 'min_samples_split': 2, 'n_estimators': 100}, 'config_hash': {'algorithm': 'dbc1b8126649fe93dce5fbb37e4015b0acfb179e', 'config': '9913cd550615a9d0946ab4a755a8b9f619e442fd', 'pipeline': 'dd626121cea079ebb32e184ca65483ec7a6d7f59'}, 'duration': 1.120617151260376, 'iteration': 10, 'loss': 0.046666666666666634, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 2, 'features__selectkbest__k': 1}), 'normalizer': ('normalizer_MinMaxScaler', {}), 'rebalance': ('rebalance_NoneType', {})}, 'score': 0.9533333333333334, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'gini', 'max_depth': 3, 'max_features': 3, 'max_leaf_nodes': None, 'min_samples_split': 3, 'n_estimators': 75}, 'config_hash': {'algorithm': '34917a130df5a975f78bd7ec1a0c7b1ffdc787a9', 'config': '95fc8cadc088141290b7de9c388977e4685f0108', 'pipeline': '550d10faf2f08db48516cc3501558816d6a99bc0'}, 'duration': 1.4287099838256836, 'iteration': 11, 'loss': 0.19333333333333313, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 3, 'features__selectkbest__k': 4}), 'normalizer': ('normalizer_StandardScaler', {'normalizer__with_mean': False, 'normalizer__with_std': False}), 'rebalance': ('rebalance_CondensedNearestNeighbour', {'rebalance__n_neighbors': 1})}, 'score': 0.8066666666666669, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'entropy', 'max_depth': 1, 'max_features': 2, 'max_leaf_nodes': 5, 'min_samples_split': 2, 'n_estimators': 75}, 'config_hash': {'algorithm': '33f9abb4aee44a395a9f3b3ffa9ce80a8cdaed7c', 'config': '40fa726f0360cf6af55f9b5902d399d02f61f157', 'pipeline': 'cfd1d20841fe2153da762c95e79f95a3fb1e426a'}, 'duration': 1.2978079319000244, 'iteration': 12, 'loss': 0.053333333333333344, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_PCA', {'features__n_components': 4}), 'normalizer': ('normalizer_MinMaxScaler', {}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 7})}, 'score': 0.9466666666666667, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'entropy', 'max_depth': 4, 'max_features': 2, 'max_leaf_nodes': 5, 'min_samples_split': 3, 'n_estimators': 25}, 'config_hash': {'algorithm': '210111ec6562d09eb093e98ed69ef1c662e11a50', 'config': '0fb8e77c7bd9a58b72f1b33c21a59a09a8c676ba', 'pipeline': '5d269d759e0c7926a685a14b263ace8ae0071e4b'}, 'duration': 0.36649012565612793, 'iteration': 13, 'loss': 0.040000000000000036, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 2, 'features__selectkbest__k': 2}), 'normalizer': ('normalizer_NoneType', {}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 7})}, 'score': 0.96, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'entropy', 'max_depth': 3, 'max_features': 1, 'max_leaf_nodes': 5, 'min_samples_split': 2, 'n_estimators': 25}, 'config_hash': {'algorithm': '0e989a03980101fabf79eda3326ed2870e11d690', 'config': 'f4bffd5d8c67a9c5321a9943c4a99678f59a02b7', 'pipeline': '865ee1e3fe8334c3d5ecb2038d5a5d1b3ba50e75'}, 'duration': 0.35639500617980957, 'iteration': 14, 'loss': 0.046666666666666634, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_NoneType', {}), 'normalizer': ('normalizer_RobustScaler', {'normalizer__quantile_range': (...), 'normalizer__with_centering': True, 'normalizer__with_scaling': False}), 'rebalance': ('rebalance_NoneType', {})}, 'score': 0.9533333333333334, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'entropy', 'max_depth': None, 'max_features': 3, 'max_leaf_nodes': 3, 'min_samples_split': 5, 'n_estimators': 10}, 'config_hash': {'algorithm': '9c592e876c13de5e23e6de5b868e01755d63e72e', 'config': '1e6a68cd1eeac886d90724d78b1cb5fb76a3cde4', 'pipeline': '5a1ca4d82f21b7de0d2c918630a42510673fa36e'}, 'duration': 0.18141412734985352, 'iteration': 15, 'loss': 0.046666666666666634, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_SelectKBest', {'features__k': 3}), 'normalizer': ('normalizer_RobustScaler', {'normalizer__quantile_range': (...), 'normalizer__with_centering': True, 'normalizer__with_scaling': True}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 6})}, 'score': 0.9533333333333334, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': 1, 'max_features': None, 'max_leaf_nodes': None, 'min_samples_split': 5, 'n_estimators': 10}, 'config_hash': {'algorithm': '8bed77aef289bfd453b2858bd288ae5ba7160f2b', 'config': '781185bcb8999045de8d489f253a1a1ba4247932', 'pipeline': '1ece7eabedc2be9e5b0a1be65c570d08ffa3eb54'}, 'duration': 0.1636829376220703, 'iteration': 16, 'loss': 0.053333333333333344, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_NoneType', {}), 'normalizer': ('normalizer_NoneType', {}), 'rebalance': ('rebalance_NearMiss', {'rebalance__n_neighbors': 1})}, 'score': 0.9466666666666667, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'gini', 'max_depth': 3, 'max_features': 2, 'max_leaf_nodes': 2, 'min_samples_split': 5, 'n_estimators': 75}, 'config_hash': {'algorithm': '617b97d9ba21d3373bc51ffa9cccf9c6f91a77b3', 'config': '99fb425b4e8c5d80228cab94202252aa25cdf77c', 'pipeline': 'd6242929c3b515c7719e60423023ac604311afc3'}, 'duration': 0.8468999862670898, 'iteration': 17, 'loss': 0.24, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_PCA', {'features__n_components': 4}), 'normalizer': ('normalizer_PowerTransformer', {}), 'rebalance': ('rebalance_NearMiss', {'rebalance__n_neighbors': 2})}, 'score': 0.76, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': 1, 'max_features': 1, 'max_leaf_nodes': 2, 'min_samples_split': 5, 'n_estimators': 50}, 'config_hash': {'algorithm': 'b92d2697cdd4979da443369d6596229ec091626a', 'config': 'c513a3e13281206ad76187dd817b1fff93d54fe1', 'pipeline': 'c4b4f914a3ca8df967cade997a90366d85a371b9'}, 'duration': 0.6724588871002197, 'iteration': 18, 'loss': 0.23333333333333328, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 1, 'features__selectkbest__k': 3}), 'normalizer': ('normalizer_StandardScaler', {'normalizer__with_mean': True, 'normalizer__with_std': True}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 5})}, 'score': 0.7666666666666667, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'entropy', 'max_depth': None, 'max_features': None, 'max_leaf_nodes': 5, 'min_samples_split': 5, 'n_estimators': 10}, 'config_hash': {'algorithm': 'a0115de695e6cca2e81cbfb54df79bf4b43608b1', 'config': 'ba194015e20b5d67770e8c67342c3d8d0d01dc41', 'pipeline': '8d45fabfeb85ffdcabf7076bd0e65fffe97ce928'}, 'duration': 0.19424200057983398, 'iteration': 19, 'loss': 0.08666666666666667, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_PCA', {'features__n_components': 3}), 'normalizer': ('normalizer_NoneType', {}), 'rebalance': ('rebalance_NoneType', {})}, 'score': 0.9133333333333333, ...}, ...], 'history_hash': ['db6ac7e6d348155757e4794bb5f88fe2b4f63d50', '4db6fb84d85f52659f780e682ffac5712c3d8a94', '4403c5a85e951938d3c454e961d3a412780722f6', 'a064e2df18ab98d44dabcefbc7bed94913f1d0be', '0ddb6f5cab3db4dddd7682966a57205f3e329ad4', '49f25751bca61cdd461a8cbd2923689b642f98ed', '5c3a2b6f5e63fb45f10e41e0318b354912ec44f6', 'd3b129b397350f1b6572651c67c01de49b4b174c', '813bde1108cc3c4b9bfb3a22cbb421bda7eac671', '31930b6860ed406d59bf7e59ba1925d94704bd3b', '9913cd550615a9d0946ab4a755a8b9f619e442fd', '95fc8cadc088141290b7de9c388977e4685f0108', '40fa726f0360cf6af55f9b5902d399d02f61f157', '0fb8e77c7bd9a58b72f1b33c21a59a09a8c676ba', 'f4bffd5d8c67a9c5321a9943c4a99678f59a02b7', '1e6a68cd1eeac886d90724d78b1cb5fb76a3cde4', '781185bcb8999045de8d489f253a1a1ba4247932', '99fb425b4e8c5d80228cab94202252aa25cdf77c', 'c513a3e13281206ad76187dd817b1fff93d54fe1', 'ba194015e20b5d67770e8c67342c3d8d0d01dc41', ...], 'history_index': {'013329309d510b94f19d930320402d65f953a847': 39, '0ddb6f5cab3db4dddd7682966a57205f3e329ad4': 4, '0fb8e77c7bd9a58b72f1b33c21a59a09a8c676ba': 13, '111ffc790caf02104464bfa2f448cba7c56c71dc': 46, '156cf80babab134353766c500267028d67005289': 20, '1bdf98e491eb63eb3f054bf53ec3f59eb069a514': 48, '1e20329d45731242c54299decd0ae5580e91079a': 38, '1e6a68cd1eeac886d90724d78b1cb5fb76a3cde4': 15, '2587c6d43f2a5d889b90dd460ee3c097a92f0cae': 29, '2c475237d3b27993f262faaf85669f17d08d9898': 36, ...}, 'iteration': 50, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint'}, config={'algorithm': 'RandomForest', 'seed': 42, 'time': 300})
    108 
    109 def objective_algo(algo_config, current_pipeline_config, algorithm, X, y, context, config):
    110     return objective(current_pipeline_config, algo_config, algorithm, X, y, context, config, step='algorithm')
    111 
    112 def objective_joint(wconfig, algorithm, X, y, context, config):
--> 113     return objective(wconfig['pipeline'], wconfig['algorithm'], algorithm, X, y, context, config, step='joint')
        wconfig = {'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': None, 'max_features': 2, 'max_leaf_nodes': None, 'min_samples_split': 3, 'n_estimators': 50}, 'pipeline': {'features': ('features_PCA', {'features__n_components': 1}), 'normalizer': ('normalizer_MinMaxScaler', {}), 'rebalance': ('rebalance_NoneType', {})}}
        algorithm = 'RandomForest'
        X = array([[5.1, 3.5, 1.4, 0.2],
       [4.9, 3. , 1....2, 3.4, 5.4, 2.3],
       [5.9, 3. , 5.1, 1.8]])
        y = array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,... 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2])
        context = {'baseline_score': 0.9466666666666667, 'baseline_score_std': 0.04988876515698587, 'best_config': {'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': 1, 'max_features': None, 'max_leaf_nodes': None, 'min_samples_split': 5, 'n_estimators': 75}, 'config_hash': {'algorithm': '94b0d7a654c508cc63643f78fe4f0f07e6f07c1e', 'config': '4403c5a85e951938d3c454e961d3a412780722f6', 'pipeline': '3e47444880d8367fbac2faaba2e52a917274aa58'}, 'duration': 0.8397619724273682, 'iteration': 2, 'loss': 0.03333333333333344, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_PCA', {'features__n_components': 3}), 'normalizer': ('normalizer_MinMaxScaler', {}), 'rebalance': ('rebalance_NoneType', {})}, 'score': 0.9666666666666666, ...}, 'history': [{'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': 2, 'max_features': None, 'max_leaf_nodes': 5, 'min_samples_split': 2, 'n_estimators': 75}, 'config_hash': {'algorithm': '3af5b0cce71c8fe2545246ca24ff5bc3dd516e06', 'config': 'db6ac7e6d348155757e4794bb5f88fe2b4f63d50', 'pipeline': '8d59f4b94cef6be9306ed86a22a9570fa670d567'}, 'duration': 1.149928092956543, 'iteration': 0, 'loss': 0.046666666666666634, 'max_history_score': 0.9533333333333334, 'max_history_score_std': 0.059999999999999984, 'max_history_step': 'joint', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 4, 'features__selectkbest__k': 3}), 'normalizer': ('normalizer_StandardScaler', {'normalizer__with_mean': True, 'normalizer__with_std': True}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 6})}, 'score': 0.9533333333333334, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': 1, 'max_features': 2, 'max_leaf_nodes': 2, 'min_samples_split': 5, 'n_estimators': 100}, 'config_hash': {'algorithm': 'e13eb05fd9a62d2f63bbb1c1deff0cd620d5e6ab', 'config': '4db6fb84d85f52659f780e682ffac5712c3d8a94', 'pipeline': '64c9a1ca9d53ae67244bdd942f4db36a3c05218c'}, 'duration': 1.7678282260894775, 'iteration': 1, 'loss': 0.18000000000000005, 'max_history_score': 0.9533333333333334, 'max_history_score_std': 0.059999999999999984, 'max_history_step': 'joint', 'pipeline': {'features': ('features_NoneType', {}), 'normalizer': ('normalizer_PowerTransformer', {}), 'rebalance': ('rebalance_NearMiss', {'rebalance__n_neighbors': 1})}, 'score': 0.82, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': 1, 'max_features': None, 'max_leaf_nodes': None, 'min_samples_split': 5, 'n_estimators': 75}, 'config_hash': {'algorithm': '94b0d7a654c508cc63643f78fe4f0f07e6f07c1e', 'config': '4403c5a85e951938d3c454e961d3a412780722f6', 'pipeline': '3e47444880d8367fbac2faaba2e52a917274aa58'}, 'duration': 0.8397619724273682, 'iteration': 2, 'loss': 0.03333333333333344, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_PCA', {'features__n_components': 3}), 'normalizer': ('normalizer_MinMaxScaler', {}), 'rebalance': ('rebalance_NoneType', {})}, 'score': 0.9666666666666666, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': None, 'max_features': None, 'max_leaf_nodes': 3, 'min_samples_split': 3, 'n_estimators': 75}, 'config_hash': {'algorithm': 'e8332f0a8902bda03bf70e7978cc5d52affb29d3', 'config': 'a064e2df18ab98d44dabcefbc7bed94913f1d0be', 'pipeline': '7eea819c2a8c103c4b1e9e9c1e224aebba95081f'}, 'duration': 0.8501448631286621, 'iteration': 3, 'loss': 0.053333333333333344, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 2, 'features__selectkbest__k': 4}), 'normalizer': ('normalizer_NoneType', {}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 7})}, 'score': 0.9466666666666667, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'entropy', 'max_depth': 3, 'max_features': 3, 'max_leaf_nodes': None, 'min_samples_split': 5, 'n_estimators': 75}, 'config_hash': {'algorithm': '7a4491035bc6bd737fe9a8cda8a79a02d02d5c74', 'config': '0ddb6f5cab3db4dddd7682966a57205f3e329ad4', 'pipeline': 'a9ae03fe38334f6868cbf84cdd3d629d4bbe3fb0'}, 'duration': 1.1026010513305664, 'iteration': 4, 'loss': 0.05999999999999994, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 2, 'features__selectkbest__k': 1}), 'normalizer': ('normalizer_NoneType', {}), 'rebalance': ('rebalance_NoneType', {})}, 'score': 0.9400000000000001, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'gini', 'max_depth': 3, 'max_features': 1, 'max_leaf_nodes': 5, 'min_samples_split': 2, 'n_estimators': 25}, 'config_hash': {'algorithm': '9826d20b2d6a0f559cf7f16450ce7526f07e8434', 'config': '49f25751bca61cdd461a8cbd2923689b642f98ed', 'pipeline': '19b249664c5bf067de1fed4334a296f947ce774a'}, 'duration': 0.35647010803222656, 'iteration': 5, 'loss': 0.046666666666666634, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_NoneType', {}), 'normalizer': ('normalizer_NoneType', {}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 6})}, 'score': 0.9533333333333334, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'gini', 'max_depth': 2, 'max_features': 1, 'max_leaf_nodes': 2, 'min_samples_split': 2, 'n_estimators': 50}, 'config_hash': {'algorithm': '0a4f6fbb07e0f32c6f675489a0fc82eee05bd8e1', 'config': '5c3a2b6f5e63fb45f10e41e0318b354912ec44f6', 'pipeline': 'dc3b9f176f090005e38b142f11d80e93a7dc5d5e'}, 'duration': 0.7213859558105469, 'iteration': 6, 'loss': 0.31333333333333324, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 1, 'features__selectkbest__k': 4}), 'normalizer': ('normalizer_PowerTransformer', {}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 7})}, 'score': 0.6866666666666668, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'entropy', 'max_depth': 4, 'max_features': 3, 'max_leaf_nodes': 5, 'min_samples_split': 5, 'n_estimators': 10}, 'config_hash': {'algorithm': 'b8112b97ecfc10f00a195af661dcc861cac21289', 'config': 'd3b129b397350f1b6572651c67c01de49b4b174c', 'pipeline': '5b0357ed7072c37b3d6f458bb5d49ff7d825f603'}, 'duration': 0.8299109935760498, 'iteration': 7, 'loss': 1.0, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_PCA', {'features__n_components': 2}), 'normalizer': ('normalizer_StandardScaler', {'normalizer__with_mean': True, 'normalizer__with_std': False}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 6})}, 'score': 0.0, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'gini', 'max_depth': 4, 'max_features': None, 'max_leaf_nodes': 2, 'min_samples_split': 5, 'n_estimators': 100}, 'config_hash': {'algorithm': '40ca24df19b8d164d9d098a6bed1ce056fbbb961', 'config': '813bde1108cc3c4b9bfb3a22cbb421bda7eac671', 'pipeline': '74a7b8705a1c22f7dea5e44e4ebda8f1e48add71'}, 'duration': 2.2111589908599854, 'iteration': 8, 'loss': 0.33333333333333326, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_PCA', {'features__n_components': 2}), 'normalizer': ('normalizer_StandardScaler', {'normalizer__with_mean': False, 'normalizer__with_std': True}), 'rebalance': ('rebalance_NearMiss', {'rebalance__n_neighbors': 2})}, 'score': 0.6666666666666667, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'entropy', 'max_depth': 2, 'max_features': 1, 'max_leaf_nodes': 5, 'min_samples_split': 2, 'n_estimators': 100}, 'config_hash': {'algorithm': '331418a5c12cf1453876eef85e9d98fc8e54fa11', 'config': '31930b6860ed406d59bf7e59ba1925d94704bd3b', 'pipeline': '054bef356f90ec6f644ef3ffc688766744db51c2'}, 'duration': 1.0501940250396729, 'iteration': 9, 'loss': 0.053333333333333344, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_SelectKBest', {'features__k': 1}), 'normalizer': ('normalizer_RobustScaler', {'normalizer__quantile_range': (...), 'normalizer__with_centering': True, 'normalizer__with_scaling': True}), 'rebalance': ('rebalance_NearMiss', {'rebalance__n_neighbors': 2})}, 'score': 0.9466666666666667, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'entropy', 'max_depth': 3, 'max_features': None, 'max_leaf_nodes': 3, 'min_samples_split': 2, 'n_estimators': 100}, 'config_hash': {'algorithm': 'dbc1b8126649fe93dce5fbb37e4015b0acfb179e', 'config': '9913cd550615a9d0946ab4a755a8b9f619e442fd', 'pipeline': 'dd626121cea079ebb32e184ca65483ec7a6d7f59'}, 'duration': 1.120617151260376, 'iteration': 10, 'loss': 0.046666666666666634, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 2, 'features__selectkbest__k': 1}), 'normalizer': ('normalizer_MinMaxScaler', {}), 'rebalance': ('rebalance_NoneType', {})}, 'score': 0.9533333333333334, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'gini', 'max_depth': 3, 'max_features': 3, 'max_leaf_nodes': None, 'min_samples_split': 3, 'n_estimators': 75}, 'config_hash': {'algorithm': '34917a130df5a975f78bd7ec1a0c7b1ffdc787a9', 'config': '95fc8cadc088141290b7de9c388977e4685f0108', 'pipeline': '550d10faf2f08db48516cc3501558816d6a99bc0'}, 'duration': 1.4287099838256836, 'iteration': 11, 'loss': 0.19333333333333313, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 3, 'features__selectkbest__k': 4}), 'normalizer': ('normalizer_StandardScaler', {'normalizer__with_mean': False, 'normalizer__with_std': False}), 'rebalance': ('rebalance_CondensedNearestNeighbour', {'rebalance__n_neighbors': 1})}, 'score': 0.8066666666666669, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'entropy', 'max_depth': 1, 'max_features': 2, 'max_leaf_nodes': 5, 'min_samples_split': 2, 'n_estimators': 75}, 'config_hash': {'algorithm': '33f9abb4aee44a395a9f3b3ffa9ce80a8cdaed7c', 'config': '40fa726f0360cf6af55f9b5902d399d02f61f157', 'pipeline': 'cfd1d20841fe2153da762c95e79f95a3fb1e426a'}, 'duration': 1.2978079319000244, 'iteration': 12, 'loss': 0.053333333333333344, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_PCA', {'features__n_components': 4}), 'normalizer': ('normalizer_MinMaxScaler', {}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 7})}, 'score': 0.9466666666666667, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'entropy', 'max_depth': 4, 'max_features': 2, 'max_leaf_nodes': 5, 'min_samples_split': 3, 'n_estimators': 25}, 'config_hash': {'algorithm': '210111ec6562d09eb093e98ed69ef1c662e11a50', 'config': '0fb8e77c7bd9a58b72f1b33c21a59a09a8c676ba', 'pipeline': '5d269d759e0c7926a685a14b263ace8ae0071e4b'}, 'duration': 0.36649012565612793, 'iteration': 13, 'loss': 0.040000000000000036, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 2, 'features__selectkbest__k': 2}), 'normalizer': ('normalizer_NoneType', {}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 7})}, 'score': 0.96, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'entropy', 'max_depth': 3, 'max_features': 1, 'max_leaf_nodes': 5, 'min_samples_split': 2, 'n_estimators': 25}, 'config_hash': {'algorithm': '0e989a03980101fabf79eda3326ed2870e11d690', 'config': 'f4bffd5d8c67a9c5321a9943c4a99678f59a02b7', 'pipeline': '865ee1e3fe8334c3d5ecb2038d5a5d1b3ba50e75'}, 'duration': 0.35639500617980957, 'iteration': 14, 'loss': 0.046666666666666634, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_NoneType', {}), 'normalizer': ('normalizer_RobustScaler', {'normalizer__quantile_range': (...), 'normalizer__with_centering': True, 'normalizer__with_scaling': False}), 'rebalance': ('rebalance_NoneType', {})}, 'score': 0.9533333333333334, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'entropy', 'max_depth': None, 'max_features': 3, 'max_leaf_nodes': 3, 'min_samples_split': 5, 'n_estimators': 10}, 'config_hash': {'algorithm': '9c592e876c13de5e23e6de5b868e01755d63e72e', 'config': '1e6a68cd1eeac886d90724d78b1cb5fb76a3cde4', 'pipeline': '5a1ca4d82f21b7de0d2c918630a42510673fa36e'}, 'duration': 0.18141412734985352, 'iteration': 15, 'loss': 0.046666666666666634, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_SelectKBest', {'features__k': 3}), 'normalizer': ('normalizer_RobustScaler', {'normalizer__quantile_range': (...), 'normalizer__with_centering': True, 'normalizer__with_scaling': True}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 6})}, 'score': 0.9533333333333334, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': 1, 'max_features': None, 'max_leaf_nodes': None, 'min_samples_split': 5, 'n_estimators': 10}, 'config_hash': {'algorithm': '8bed77aef289bfd453b2858bd288ae5ba7160f2b', 'config': '781185bcb8999045de8d489f253a1a1ba4247932', 'pipeline': '1ece7eabedc2be9e5b0a1be65c570d08ffa3eb54'}, 'duration': 0.1636829376220703, 'iteration': 16, 'loss': 0.053333333333333344, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_NoneType', {}), 'normalizer': ('normalizer_NoneType', {}), 'rebalance': ('rebalance_NearMiss', {'rebalance__n_neighbors': 1})}, 'score': 0.9466666666666667, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'gini', 'max_depth': 3, 'max_features': 2, 'max_leaf_nodes': 2, 'min_samples_split': 5, 'n_estimators': 75}, 'config_hash': {'algorithm': '617b97d9ba21d3373bc51ffa9cccf9c6f91a77b3', 'config': '99fb425b4e8c5d80228cab94202252aa25cdf77c', 'pipeline': 'd6242929c3b515c7719e60423023ac604311afc3'}, 'duration': 0.8468999862670898, 'iteration': 17, 'loss': 0.24, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_PCA', {'features__n_components': 4}), 'normalizer': ('normalizer_PowerTransformer', {}), 'rebalance': ('rebalance_NearMiss', {'rebalance__n_neighbors': 2})}, 'score': 0.76, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': 1, 'max_features': 1, 'max_leaf_nodes': 2, 'min_samples_split': 5, 'n_estimators': 50}, 'config_hash': {'algorithm': 'b92d2697cdd4979da443369d6596229ec091626a', 'config': 'c513a3e13281206ad76187dd817b1fff93d54fe1', 'pipeline': 'c4b4f914a3ca8df967cade997a90366d85a371b9'}, 'duration': 0.6724588871002197, 'iteration': 18, 'loss': 0.23333333333333328, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 1, 'features__selectkbest__k': 3}), 'normalizer': ('normalizer_StandardScaler', {'normalizer__with_mean': True, 'normalizer__with_std': True}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 5})}, 'score': 0.7666666666666667, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'entropy', 'max_depth': None, 'max_features': None, 'max_leaf_nodes': 5, 'min_samples_split': 5, 'n_estimators': 10}, 'config_hash': {'algorithm': 'a0115de695e6cca2e81cbfb54df79bf4b43608b1', 'config': 'ba194015e20b5d67770e8c67342c3d8d0d01dc41', 'pipeline': '8d45fabfeb85ffdcabf7076bd0e65fffe97ce928'}, 'duration': 0.19424200057983398, 'iteration': 19, 'loss': 0.08666666666666667, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_PCA', {'features__n_components': 3}), 'normalizer': ('normalizer_NoneType', {}), 'rebalance': ('rebalance_NoneType', {})}, 'score': 0.9133333333333333, ...}, ...], 'history_hash': ['db6ac7e6d348155757e4794bb5f88fe2b4f63d50', '4db6fb84d85f52659f780e682ffac5712c3d8a94', '4403c5a85e951938d3c454e961d3a412780722f6', 'a064e2df18ab98d44dabcefbc7bed94913f1d0be', '0ddb6f5cab3db4dddd7682966a57205f3e329ad4', '49f25751bca61cdd461a8cbd2923689b642f98ed', '5c3a2b6f5e63fb45f10e41e0318b354912ec44f6', 'd3b129b397350f1b6572651c67c01de49b4b174c', '813bde1108cc3c4b9bfb3a22cbb421bda7eac671', '31930b6860ed406d59bf7e59ba1925d94704bd3b', '9913cd550615a9d0946ab4a755a8b9f619e442fd', '95fc8cadc088141290b7de9c388977e4685f0108', '40fa726f0360cf6af55f9b5902d399d02f61f157', '0fb8e77c7bd9a58b72f1b33c21a59a09a8c676ba', 'f4bffd5d8c67a9c5321a9943c4a99678f59a02b7', '1e6a68cd1eeac886d90724d78b1cb5fb76a3cde4', '781185bcb8999045de8d489f253a1a1ba4247932', '99fb425b4e8c5d80228cab94202252aa25cdf77c', 'c513a3e13281206ad76187dd817b1fff93d54fe1', 'ba194015e20b5d67770e8c67342c3d8d0d01dc41', ...], 'history_index': {'013329309d510b94f19d930320402d65f953a847': 39, '0ddb6f5cab3db4dddd7682966a57205f3e329ad4': 4, '0fb8e77c7bd9a58b72f1b33c21a59a09a8c676ba': 13, '111ffc790caf02104464bfa2f448cba7c56c71dc': 46, '156cf80babab134353766c500267028d67005289': 20, '1bdf98e491eb63eb3f054bf53ec3f59eb069a514': 48, '1e20329d45731242c54299decd0ae5580e91079a': 38, '1e6a68cd1eeac886d90724d78b1cb5fb76a3cde4': 15, '2587c6d43f2a5d889b90dd460ee3c097a92f0cae': 29, '2c475237d3b27993f262faaf85669f17d08d9898': 36, ...}, 'iteration': 50, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint'}
        config = {'algorithm': 'RandomForest', 'seed': 42, 'time': 300}
    114 
    115 
    116 def get_baseline_score(algorithm, X, y, seed):
    117     pipeline, _ = pipeline_conf_to_full_pipeline(

...........................................................................
/home/aquemy/dev/dp_hyperparameters/extension/experiment/objective.py in objective(pipeline_config={'features': ('features_PCA', {'features__n_components': 1}), 'normalizer': ('normalizer_MinMaxScaler', {}), 'rebalance': ('rebalance_NoneType', {})}, algo_config={'bootstrap': True, 'criterion': 'gini', 'max_depth': None, 'max_features': 2, 'max_leaf_nodes': None, 'min_samples_split': 3, 'n_estimators': 50}, algorithm='RandomForest', X=array([[5.1, 3.5, 1.4, 0.2],
       [4.9, 3. , 1....2, 3.4, 5.4, 2.3],
       [5.9, 3. , 5.1, 1.8]]), y=array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,... 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]), context={'baseline_score': 0.9466666666666667, 'baseline_score_std': 0.04988876515698587, 'best_config': {'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': 1, 'max_features': None, 'max_leaf_nodes': None, 'min_samples_split': 5, 'n_estimators': 75}, 'config_hash': {'algorithm': '94b0d7a654c508cc63643f78fe4f0f07e6f07c1e', 'config': '4403c5a85e951938d3c454e961d3a412780722f6', 'pipeline': '3e47444880d8367fbac2faaba2e52a917274aa58'}, 'duration': 0.8397619724273682, 'iteration': 2, 'loss': 0.03333333333333344, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_PCA', {'features__n_components': 3}), 'normalizer': ('normalizer_MinMaxScaler', {}), 'rebalance': ('rebalance_NoneType', {})}, 'score': 0.9666666666666666, ...}, 'history': [{'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': 2, 'max_features': None, 'max_leaf_nodes': 5, 'min_samples_split': 2, 'n_estimators': 75}, 'config_hash': {'algorithm': '3af5b0cce71c8fe2545246ca24ff5bc3dd516e06', 'config': 'db6ac7e6d348155757e4794bb5f88fe2b4f63d50', 'pipeline': '8d59f4b94cef6be9306ed86a22a9570fa670d567'}, 'duration': 1.149928092956543, 'iteration': 0, 'loss': 0.046666666666666634, 'max_history_score': 0.9533333333333334, 'max_history_score_std': 0.059999999999999984, 'max_history_step': 'joint', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 4, 'features__selectkbest__k': 3}), 'normalizer': ('normalizer_StandardScaler', {'normalizer__with_mean': True, 'normalizer__with_std': True}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 6})}, 'score': 0.9533333333333334, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': 1, 'max_features': 2, 'max_leaf_nodes': 2, 'min_samples_split': 5, 'n_estimators': 100}, 'config_hash': {'algorithm': 'e13eb05fd9a62d2f63bbb1c1deff0cd620d5e6ab', 'config': '4db6fb84d85f52659f780e682ffac5712c3d8a94', 'pipeline': '64c9a1ca9d53ae67244bdd942f4db36a3c05218c'}, 'duration': 1.7678282260894775, 'iteration': 1, 'loss': 0.18000000000000005, 'max_history_score': 0.9533333333333334, 'max_history_score_std': 0.059999999999999984, 'max_history_step': 'joint', 'pipeline': {'features': ('features_NoneType', {}), 'normalizer': ('normalizer_PowerTransformer', {}), 'rebalance': ('rebalance_NearMiss', {'rebalance__n_neighbors': 1})}, 'score': 0.82, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': 1, 'max_features': None, 'max_leaf_nodes': None, 'min_samples_split': 5, 'n_estimators': 75}, 'config_hash': {'algorithm': '94b0d7a654c508cc63643f78fe4f0f07e6f07c1e', 'config': '4403c5a85e951938d3c454e961d3a412780722f6', 'pipeline': '3e47444880d8367fbac2faaba2e52a917274aa58'}, 'duration': 0.8397619724273682, 'iteration': 2, 'loss': 0.03333333333333344, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_PCA', {'features__n_components': 3}), 'normalizer': ('normalizer_MinMaxScaler', {}), 'rebalance': ('rebalance_NoneType', {})}, 'score': 0.9666666666666666, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': None, 'max_features': None, 'max_leaf_nodes': 3, 'min_samples_split': 3, 'n_estimators': 75}, 'config_hash': {'algorithm': 'e8332f0a8902bda03bf70e7978cc5d52affb29d3', 'config': 'a064e2df18ab98d44dabcefbc7bed94913f1d0be', 'pipeline': '7eea819c2a8c103c4b1e9e9c1e224aebba95081f'}, 'duration': 0.8501448631286621, 'iteration': 3, 'loss': 0.053333333333333344, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 2, 'features__selectkbest__k': 4}), 'normalizer': ('normalizer_NoneType', {}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 7})}, 'score': 0.9466666666666667, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'entropy', 'max_depth': 3, 'max_features': 3, 'max_leaf_nodes': None, 'min_samples_split': 5, 'n_estimators': 75}, 'config_hash': {'algorithm': '7a4491035bc6bd737fe9a8cda8a79a02d02d5c74', 'config': '0ddb6f5cab3db4dddd7682966a57205f3e329ad4', 'pipeline': 'a9ae03fe38334f6868cbf84cdd3d629d4bbe3fb0'}, 'duration': 1.1026010513305664, 'iteration': 4, 'loss': 0.05999999999999994, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 2, 'features__selectkbest__k': 1}), 'normalizer': ('normalizer_NoneType', {}), 'rebalance': ('rebalance_NoneType', {})}, 'score': 0.9400000000000001, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'gini', 'max_depth': 3, 'max_features': 1, 'max_leaf_nodes': 5, 'min_samples_split': 2, 'n_estimators': 25}, 'config_hash': {'algorithm': '9826d20b2d6a0f559cf7f16450ce7526f07e8434', 'config': '49f25751bca61cdd461a8cbd2923689b642f98ed', 'pipeline': '19b249664c5bf067de1fed4334a296f947ce774a'}, 'duration': 0.35647010803222656, 'iteration': 5, 'loss': 0.046666666666666634, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_NoneType', {}), 'normalizer': ('normalizer_NoneType', {}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 6})}, 'score': 0.9533333333333334, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'gini', 'max_depth': 2, 'max_features': 1, 'max_leaf_nodes': 2, 'min_samples_split': 2, 'n_estimators': 50}, 'config_hash': {'algorithm': '0a4f6fbb07e0f32c6f675489a0fc82eee05bd8e1', 'config': '5c3a2b6f5e63fb45f10e41e0318b354912ec44f6', 'pipeline': 'dc3b9f176f090005e38b142f11d80e93a7dc5d5e'}, 'duration': 0.7213859558105469, 'iteration': 6, 'loss': 0.31333333333333324, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 1, 'features__selectkbest__k': 4}), 'normalizer': ('normalizer_PowerTransformer', {}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 7})}, 'score': 0.6866666666666668, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'entropy', 'max_depth': 4, 'max_features': 3, 'max_leaf_nodes': 5, 'min_samples_split': 5, 'n_estimators': 10}, 'config_hash': {'algorithm': 'b8112b97ecfc10f00a195af661dcc861cac21289', 'config': 'd3b129b397350f1b6572651c67c01de49b4b174c', 'pipeline': '5b0357ed7072c37b3d6f458bb5d49ff7d825f603'}, 'duration': 0.8299109935760498, 'iteration': 7, 'loss': 1.0, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_PCA', {'features__n_components': 2}), 'normalizer': ('normalizer_StandardScaler', {'normalizer__with_mean': True, 'normalizer__with_std': False}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 6})}, 'score': 0.0, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'gini', 'max_depth': 4, 'max_features': None, 'max_leaf_nodes': 2, 'min_samples_split': 5, 'n_estimators': 100}, 'config_hash': {'algorithm': '40ca24df19b8d164d9d098a6bed1ce056fbbb961', 'config': '813bde1108cc3c4b9bfb3a22cbb421bda7eac671', 'pipeline': '74a7b8705a1c22f7dea5e44e4ebda8f1e48add71'}, 'duration': 2.2111589908599854, 'iteration': 8, 'loss': 0.33333333333333326, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_PCA', {'features__n_components': 2}), 'normalizer': ('normalizer_StandardScaler', {'normalizer__with_mean': False, 'normalizer__with_std': True}), 'rebalance': ('rebalance_NearMiss', {'rebalance__n_neighbors': 2})}, 'score': 0.6666666666666667, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'entropy', 'max_depth': 2, 'max_features': 1, 'max_leaf_nodes': 5, 'min_samples_split': 2, 'n_estimators': 100}, 'config_hash': {'algorithm': '331418a5c12cf1453876eef85e9d98fc8e54fa11', 'config': '31930b6860ed406d59bf7e59ba1925d94704bd3b', 'pipeline': '054bef356f90ec6f644ef3ffc688766744db51c2'}, 'duration': 1.0501940250396729, 'iteration': 9, 'loss': 0.053333333333333344, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_SelectKBest', {'features__k': 1}), 'normalizer': ('normalizer_RobustScaler', {'normalizer__quantile_range': (...), 'normalizer__with_centering': True, 'normalizer__with_scaling': True}), 'rebalance': ('rebalance_NearMiss', {'rebalance__n_neighbors': 2})}, 'score': 0.9466666666666667, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'entropy', 'max_depth': 3, 'max_features': None, 'max_leaf_nodes': 3, 'min_samples_split': 2, 'n_estimators': 100}, 'config_hash': {'algorithm': 'dbc1b8126649fe93dce5fbb37e4015b0acfb179e', 'config': '9913cd550615a9d0946ab4a755a8b9f619e442fd', 'pipeline': 'dd626121cea079ebb32e184ca65483ec7a6d7f59'}, 'duration': 1.120617151260376, 'iteration': 10, 'loss': 0.046666666666666634, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 2, 'features__selectkbest__k': 1}), 'normalizer': ('normalizer_MinMaxScaler', {}), 'rebalance': ('rebalance_NoneType', {})}, 'score': 0.9533333333333334, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'gini', 'max_depth': 3, 'max_features': 3, 'max_leaf_nodes': None, 'min_samples_split': 3, 'n_estimators': 75}, 'config_hash': {'algorithm': '34917a130df5a975f78bd7ec1a0c7b1ffdc787a9', 'config': '95fc8cadc088141290b7de9c388977e4685f0108', 'pipeline': '550d10faf2f08db48516cc3501558816d6a99bc0'}, 'duration': 1.4287099838256836, 'iteration': 11, 'loss': 0.19333333333333313, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 3, 'features__selectkbest__k': 4}), 'normalizer': ('normalizer_StandardScaler', {'normalizer__with_mean': False, 'normalizer__with_std': False}), 'rebalance': ('rebalance_CondensedNearestNeighbour', {'rebalance__n_neighbors': 1})}, 'score': 0.8066666666666669, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'entropy', 'max_depth': 1, 'max_features': 2, 'max_leaf_nodes': 5, 'min_samples_split': 2, 'n_estimators': 75}, 'config_hash': {'algorithm': '33f9abb4aee44a395a9f3b3ffa9ce80a8cdaed7c', 'config': '40fa726f0360cf6af55f9b5902d399d02f61f157', 'pipeline': 'cfd1d20841fe2153da762c95e79f95a3fb1e426a'}, 'duration': 1.2978079319000244, 'iteration': 12, 'loss': 0.053333333333333344, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_PCA', {'features__n_components': 4}), 'normalizer': ('normalizer_MinMaxScaler', {}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 7})}, 'score': 0.9466666666666667, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'entropy', 'max_depth': 4, 'max_features': 2, 'max_leaf_nodes': 5, 'min_samples_split': 3, 'n_estimators': 25}, 'config_hash': {'algorithm': '210111ec6562d09eb093e98ed69ef1c662e11a50', 'config': '0fb8e77c7bd9a58b72f1b33c21a59a09a8c676ba', 'pipeline': '5d269d759e0c7926a685a14b263ace8ae0071e4b'}, 'duration': 0.36649012565612793, 'iteration': 13, 'loss': 0.040000000000000036, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 2, 'features__selectkbest__k': 2}), 'normalizer': ('normalizer_NoneType', {}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 7})}, 'score': 0.96, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'entropy', 'max_depth': 3, 'max_features': 1, 'max_leaf_nodes': 5, 'min_samples_split': 2, 'n_estimators': 25}, 'config_hash': {'algorithm': '0e989a03980101fabf79eda3326ed2870e11d690', 'config': 'f4bffd5d8c67a9c5321a9943c4a99678f59a02b7', 'pipeline': '865ee1e3fe8334c3d5ecb2038d5a5d1b3ba50e75'}, 'duration': 0.35639500617980957, 'iteration': 14, 'loss': 0.046666666666666634, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_NoneType', {}), 'normalizer': ('normalizer_RobustScaler', {'normalizer__quantile_range': (...), 'normalizer__with_centering': True, 'normalizer__with_scaling': False}), 'rebalance': ('rebalance_NoneType', {})}, 'score': 0.9533333333333334, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'entropy', 'max_depth': None, 'max_features': 3, 'max_leaf_nodes': 3, 'min_samples_split': 5, 'n_estimators': 10}, 'config_hash': {'algorithm': '9c592e876c13de5e23e6de5b868e01755d63e72e', 'config': '1e6a68cd1eeac886d90724d78b1cb5fb76a3cde4', 'pipeline': '5a1ca4d82f21b7de0d2c918630a42510673fa36e'}, 'duration': 0.18141412734985352, 'iteration': 15, 'loss': 0.046666666666666634, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_SelectKBest', {'features__k': 3}), 'normalizer': ('normalizer_RobustScaler', {'normalizer__quantile_range': (...), 'normalizer__with_centering': True, 'normalizer__with_scaling': True}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 6})}, 'score': 0.9533333333333334, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': 1, 'max_features': None, 'max_leaf_nodes': None, 'min_samples_split': 5, 'n_estimators': 10}, 'config_hash': {'algorithm': '8bed77aef289bfd453b2858bd288ae5ba7160f2b', 'config': '781185bcb8999045de8d489f253a1a1ba4247932', 'pipeline': '1ece7eabedc2be9e5b0a1be65c570d08ffa3eb54'}, 'duration': 0.1636829376220703, 'iteration': 16, 'loss': 0.053333333333333344, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_NoneType', {}), 'normalizer': ('normalizer_NoneType', {}), 'rebalance': ('rebalance_NearMiss', {'rebalance__n_neighbors': 1})}, 'score': 0.9466666666666667, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'gini', 'max_depth': 3, 'max_features': 2, 'max_leaf_nodes': 2, 'min_samples_split': 5, 'n_estimators': 75}, 'config_hash': {'algorithm': '617b97d9ba21d3373bc51ffa9cccf9c6f91a77b3', 'config': '99fb425b4e8c5d80228cab94202252aa25cdf77c', 'pipeline': 'd6242929c3b515c7719e60423023ac604311afc3'}, 'duration': 0.8468999862670898, 'iteration': 17, 'loss': 0.24, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_PCA', {'features__n_components': 4}), 'normalizer': ('normalizer_PowerTransformer', {}), 'rebalance': ('rebalance_NearMiss', {'rebalance__n_neighbors': 2})}, 'score': 0.76, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': 1, 'max_features': 1, 'max_leaf_nodes': 2, 'min_samples_split': 5, 'n_estimators': 50}, 'config_hash': {'algorithm': 'b92d2697cdd4979da443369d6596229ec091626a', 'config': 'c513a3e13281206ad76187dd817b1fff93d54fe1', 'pipeline': 'c4b4f914a3ca8df967cade997a90366d85a371b9'}, 'duration': 0.6724588871002197, 'iteration': 18, 'loss': 0.23333333333333328, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 1, 'features__selectkbest__k': 3}), 'normalizer': ('normalizer_StandardScaler', {'normalizer__with_mean': True, 'normalizer__with_std': True}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 5})}, 'score': 0.7666666666666667, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'entropy', 'max_depth': None, 'max_features': None, 'max_leaf_nodes': 5, 'min_samples_split': 5, 'n_estimators': 10}, 'config_hash': {'algorithm': 'a0115de695e6cca2e81cbfb54df79bf4b43608b1', 'config': 'ba194015e20b5d67770e8c67342c3d8d0d01dc41', 'pipeline': '8d45fabfeb85ffdcabf7076bd0e65fffe97ce928'}, 'duration': 0.19424200057983398, 'iteration': 19, 'loss': 0.08666666666666667, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_PCA', {'features__n_components': 3}), 'normalizer': ('normalizer_NoneType', {}), 'rebalance': ('rebalance_NoneType', {})}, 'score': 0.9133333333333333, ...}, ...], 'history_hash': ['db6ac7e6d348155757e4794bb5f88fe2b4f63d50', '4db6fb84d85f52659f780e682ffac5712c3d8a94', '4403c5a85e951938d3c454e961d3a412780722f6', 'a064e2df18ab98d44dabcefbc7bed94913f1d0be', '0ddb6f5cab3db4dddd7682966a57205f3e329ad4', '49f25751bca61cdd461a8cbd2923689b642f98ed', '5c3a2b6f5e63fb45f10e41e0318b354912ec44f6', 'd3b129b397350f1b6572651c67c01de49b4b174c', '813bde1108cc3c4b9bfb3a22cbb421bda7eac671', '31930b6860ed406d59bf7e59ba1925d94704bd3b', '9913cd550615a9d0946ab4a755a8b9f619e442fd', '95fc8cadc088141290b7de9c388977e4685f0108', '40fa726f0360cf6af55f9b5902d399d02f61f157', '0fb8e77c7bd9a58b72f1b33c21a59a09a8c676ba', 'f4bffd5d8c67a9c5321a9943c4a99678f59a02b7', '1e6a68cd1eeac886d90724d78b1cb5fb76a3cde4', '781185bcb8999045de8d489f253a1a1ba4247932', '99fb425b4e8c5d80228cab94202252aa25cdf77c', 'c513a3e13281206ad76187dd817b1fff93d54fe1', 'ba194015e20b5d67770e8c67342c3d8d0d01dc41', ...], 'history_index': {'013329309d510b94f19d930320402d65f953a847': 39, '0ddb6f5cab3db4dddd7682966a57205f3e329ad4': 4, '0fb8e77c7bd9a58b72f1b33c21a59a09a8c676ba': 13, '111ffc790caf02104464bfa2f448cba7c56c71dc': 46, '156cf80babab134353766c500267028d67005289': 20, '1bdf98e491eb63eb3f054bf53ec3f59eb069a514': 48, '1e20329d45731242c54299decd0ae5580e91079a': 38, '1e6a68cd1eeac886d90724d78b1cb5fb76a3cde4': 15, '2587c6d43f2a5d889b90dd460ee3c097a92f0cae': 29, '2c475237d3b27993f262faaf85669f17d08d9898': 36, ...}, 'iteration': 50, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint'}, config={'algorithm': 'RandomForest', 'seed': 42, 'time': 300}, step='joint')
     45                 y,
     46                 cv=10,
     47                 n_jobs=-1,
     48                 return_estimator=False,
     49                 return_train_score=False,
---> 50                 verbose=0)
     51         score = np.mean(scores['test_score'])
     52         std = np.std(scores['test_score'])
     53         status = STATUS_OK
     54     except Exception as e:

...........................................................................
/home/aquemy/.local/lib/python2.7/site-packages/sklearn/model_selection/_validation.py in cross_validate(estimator=Pipeline(memory=None,
     steps=[('normalizer',... random_state=42, verbose=0, warm_start=False))]), X=array([[5.1, 3.5, 1.4, 0.2],
       [4.9, 3. , 1....2, 3.4, 5.4, 2.3],
       [5.9, 3. , 5.1, 1.8]]), y=array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,... 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]), groups=None, scoring=None, cv=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1, verbose=0, fit_params=None, pre_dispatch='2*n_jobs', return_train_score=False, return_estimator=False, error_score='raise-deprecating')
    235         delayed(_fit_and_score)(
    236             clone(estimator), X, y, scorers, train, test, verbose, None,
    237             fit_params, return_train_score=return_train_score,
    238             return_times=True, return_estimator=return_estimator,
    239             error_score=error_score)
--> 240         for train, test in cv.split(X, y, groups))
        cv.split = <bound method StratifiedKFold.split of Stratifie...d(n_splits=10, random_state=None, shuffle=False)>
        X = array([[5.1, 3.5, 1.4, 0.2],
       [4.9, 3. , 1....2, 3.4, 5.4, 2.3],
       [5.9, 3. , 5.1, 1.8]])
        y = array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,... 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2])
        groups = None
    241 
    242     zipped_scores = list(zip(*scores))
    243     if return_train_score:
    244         train_scores = zipped_scores.pop(0)

...........................................................................
/home/aquemy/.local/lib/python2.7/site-packages/sklearn/externals/joblib/parallel.py in __call__(self=Parallel(n_jobs=-1), iterable=<generator object <genexpr>>)
    925                 # No need to wait for async callbacks to trigger to
    926                 # consumption.
    927                 self._iterating = False
    928 
    929             with self._backend.retrieval_context():
--> 930                 self.retrieve()
        self.retrieve = <bound method Parallel.retrieve of Parallel(n_jobs=-1)>
    931             # Make sure that we get a last message telling us we are done
    932             elapsed_time = time.time() - self._start_time
    933             self._print('Done %3i out of %3i | elapsed: %s finished',
    934                         (len(self._output), len(self._output),

---------------------------------------------------------------------------
Joblib worker traceback:
---------------------------------------------------------------------------
ValueError                                         Mon Jun 17 13:11:21 2019
PID: 20998                                  Python 2.7.15+: /usr/bin/python
...........................................................................
/home/aquemy/.local/lib/python2.7/site-packages/sklearn/externals/joblib/parallel.py in __call__(self=<sklearn.externals.joblib.parallel.BatchedCalls object>)
    220     def __call__(self):
    221         # Set the default nested backend to self._backend but do not set the
    222         # change the default number of processes to -1
    223         with parallel_backend(self._backend, n_jobs=self._n_jobs):
    224             return [func(*args, **kwargs)
--> 225                     for func, args, kwargs in self.items]
        func = <function _fit_and_score>
        args = (Pipeline(memory=None,
     steps=[('normalizer',... random_state=42, verbose=0, warm_start=False))]), array([[5.1, 3.5, 1.4, 0.2],
       [4.9, 3. , 1....2, 3.4, 5.4, 2.3],
       [5.9, 3. , 5.1, 1.8]]), array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,... 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]), {'score': <function _passthrough_scorer>}, array([  5,   6,   7,   8,   9,  10,  11,  12,  ..., 142, 143, 144,
       145, 146, 147, 148, 149]), array([  0,   1,   2,   3,   4,  50,  51,  52,  53,  54, 100, 101, 102,
       103, 104]), 0, None, None)
        kwargs = {'error_score': 'raise-deprecating', 'return_estimator': False, 'return_times': True, 'return_train_score': False}
        self.items = [(<function _fit_and_score>, (Pipeline(memory=None,
     steps=[('normalizer',... random_state=42, verbose=0, warm_start=False))]), array([[5.1, 3.5, 1.4, 0.2],
       [4.9, 3. , 1....2, 3.4, 5.4, 2.3],
       [5.9, 3. , 5.1, 1.8]]), array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,... 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]), {'score': <function _passthrough_scorer>}, array([  5,   6,   7,   8,   9,  10,  11,  12,  ..., 142, 143, 144,
       145, 146, 147, 148, 149]), array([  0,   1,   2,   3,   4,  50,  51,  52,  53,  54, 100, 101, 102,
       103, 104]), 0, None, None), {'error_score': 'raise-deprecating', 'return_estimator': False, 'return_times': True, 'return_train_score': False})]
    226 
    227     def __len__(self):
    228         return self._size
    229 

...........................................................................
/home/aquemy/.local/lib/python2.7/site-packages/sklearn/model_selection/_validation.py in _fit_and_score(estimator=Pipeline(memory=None,
     steps=[('normalizer',... random_state=42, verbose=0, warm_start=False))]), X=array([[5.1, 3.5, 1.4, 0.2],
       [4.9, 3. , 1....2, 3.4, 5.4, 2.3],
       [5.9, 3. , 5.1, 1.8]]), y=array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,... 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]), scorer={'score': <function _passthrough_scorer>}, train=array([  5,   6,   7,   8,   9,  10,  11,  12,  ..., 142, 143, 144,
       145, 146, 147, 148, 149]), test=array([  0,   1,   2,   3,   4,  50,  51,  52,  53,  54, 100, 101, 102,
       103, 104]), verbose=0, parameters=None, fit_params={}, return_train_score=False, return_parameters=False, return_n_test_samples=False, return_times=True, return_estimator=False, error_score='raise-deprecating')
    523 
    524     try:
    525         if y_train is None:
    526             estimator.fit(X_train, **fit_params)
    527         else:
--> 528             estimator.fit(X_train, y_train, **fit_params)
        estimator.fit = <bound method Pipeline.fit of Pipeline(memory=No...random_state=42, verbose=0, warm_start=False))])>
        X_train = array([[5.4, 3.9, 1.7, 0.4],
       [4.6, 3.4, 1....2, 3.4, 5.4, 2.3],
       [5.9, 3. , 5.1, 1.8]])
        y_train = array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,
       2, 2, 2])
        fit_params = {}
    529 
    530     except Exception as e:
    531         # Note fit time as time until error
    532         fit_time = time.time() - start_time

...........................................................................
/usr/local/lib/python2.7/dist-packages/imblearn/pipeline.py in fit(self=Pipeline(memory=None,
     steps=[('normalizer',... random_state=42, verbose=0, warm_start=False))]), X=array([[5.4, 3.9, 1.7, 0.4],
       [4.6, 3.4, 1....2, 3.4, 5.4, 2.3],
       [5.9, 3. , 5.1, 1.8]]), y=array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,
       2, 2, 2]), **fit_params={})
    234             This estimator
    235 
    236         """
    237         Xt, yt, fit_params = self._fit(X, y, **fit_params)
    238         if self._final_estimator is not None:
--> 239             self._final_estimator.fit(Xt, yt, **fit_params)
        self._final_estimator.fit = <bound method RandomForestClassifier.fit of Rand...e, random_state=42, verbose=0, warm_start=False)>
        Xt = array([[-5.33848470e-01],
       [-6.53381800e-0...    [ 4.89816648e-01],
       [ 3.15349702e-01]])
        yt = array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,
       2, 2, 2])
        fit_params = {}
    240         return self
    241 
    242     def fit_transform(self, X, y=None, **fit_params):
    243         """Fit the model and transform with the final estimator

...........................................................................
/home/aquemy/.local/lib/python2.7/site-packages/sklearn/ensemble/forest.py in fit(self=RandomForestClassifier(bootstrap=True, class_wei...se, random_state=42, verbose=0, warm_start=False), X=array([[-5.33848464e-01],
       [-6.53381824e-0...6e-01],
       [ 3.15349698e-01]], dtype=float32), y=array([[0.],
       [0.],
       [0.],
       [0...    [2.],
       [2.],
       [2.],
       [2.]]), sample_weight=None)
    328             trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,
    329                              **_joblib_parallel_args(prefer='threads'))(
    330                 delayed(_parallel_build_trees)(
    331                     t, self, X, y, sample_weight, i, len(trees),
    332                     verbose=self.verbose, class_weight=self.class_weight)
--> 333                 for i, t in enumerate(trees))
        i = 49
    334 
    335             # Collect newly grown trees
    336             self.estimators_.extend(trees)
    337 

...........................................................................
/home/aquemy/.local/lib/python2.7/site-packages/sklearn/externals/joblib/parallel.py in __call__(self=Parallel(n_jobs=1), iterable=<generator object <genexpr>>)
    912             # self._original_iterator is None, then this means either
    913             # that pre_dispatch == "all", n_jobs == 1 or that the first batch
    914             # was very quick and its callback already dispatched all the
    915             # remaining jobs.
    916             self._iterating = False
--> 917             if self.dispatch_one_batch(iterator):
        self.dispatch_one_batch = <bound method Parallel.dispatch_one_batch of Parallel(n_jobs=1)>
        iterator = <generator object <genexpr>>
    918                 self._iterating = self._original_iterator is not None
    919 
    920             while self.dispatch_one_batch(iterator):
    921                 pass

...........................................................................
/home/aquemy/.local/lib/python2.7/site-packages/sklearn/externals/joblib/parallel.py in dispatch_one_batch(self=Parallel(n_jobs=1), iterator=<generator object <genexpr>>)
    754                                  self._pickle_cache)
    755             if len(tasks) == 0:
    756                 # No more tasks available in the iterator: tell caller to stop.
    757                 return False
    758             else:
--> 759                 self._dispatch(tasks)
        self._dispatch = <bound method Parallel._dispatch of Parallel(n_jobs=1)>
        tasks = <sklearn.externals.joblib.parallel.BatchedCalls object>
    760                 return True
    761 
    762     def _print(self, msg, msg_args):
    763         """Display the message on stout or stderr depending on verbosity"""

...........................................................................
/home/aquemy/.local/lib/python2.7/site-packages/sklearn/externals/joblib/parallel.py in _dispatch(self=Parallel(n_jobs=1), batch=<sklearn.externals.joblib.parallel.BatchedCalls object>)
    711 
    712         dispatch_timestamp = time.time()
    713         cb = BatchCompletionCallBack(dispatch_timestamp, len(batch), self)
    714         with self._lock:
    715             job_idx = len(self._jobs)
--> 716             job = self._backend.apply_async(batch, callback=cb)
        job = undefined
        self._backend.apply_async = <bound method SequentialBackend.apply_async of <...lib._parallel_backends.SequentialBackend object>>
        batch = <sklearn.externals.joblib.parallel.BatchedCalls object>
        cb = <sklearn.externals.joblib.parallel.BatchCompletionCallBack object>
    717             # A job can complete so quickly than its callback is
    718             # called before we get here, causing self._jobs to
    719             # grow. To ensure correct results ordering, .insert is
    720             # used (rather than .append) in the following line

...........................................................................
/home/aquemy/.local/lib/python2.7/site-packages/sklearn/externals/joblib/_parallel_backends.py in apply_async(self=<sklearn.externals.joblib._parallel_backends.SequentialBackend object>, func=<sklearn.externals.joblib.parallel.BatchedCalls object>, callback=<sklearn.externals.joblib.parallel.BatchCompletionCallBack object>)
    177             raise ValueError('n_jobs == 0 in Parallel has no meaning')
    178         return 1
    179 
    180     def apply_async(self, func, callback=None):
    181         """Schedule a func to be run"""
--> 182         result = ImmediateResult(func)
        result = undefined
        func = <sklearn.externals.joblib.parallel.BatchedCalls object>
    183         if callback:
    184             callback(result)
    185         return result
    186 

...........................................................................
/home/aquemy/.local/lib/python2.7/site-packages/sklearn/externals/joblib/_parallel_backends.py in __init__(self=<sklearn.externals.joblib._parallel_backends.ImmediateResult object>, batch=<sklearn.externals.joblib.parallel.BatchedCalls object>)
    544 
    545 class ImmediateResult(object):
    546     def __init__(self, batch):
    547         # Don't delay the application, to avoid keeping the input
    548         # arguments in memory
--> 549         self.results = batch()
        self.results = undefined
        batch = <sklearn.externals.joblib.parallel.BatchedCalls object>
    550 
    551     def get(self):
    552         return self.results
    553 

...........................................................................
/home/aquemy/.local/lib/python2.7/site-packages/sklearn/externals/joblib/parallel.py in __call__(self=<sklearn.externals.joblib.parallel.BatchedCalls object>)
    220     def __call__(self):
    221         # Set the default nested backend to self._backend but do not set the
    222         # change the default number of processes to -1
    223         with parallel_backend(self._backend, n_jobs=self._n_jobs):
    224             return [func(*args, **kwargs)
--> 225                     for func, args, kwargs in self.items]
        func = <function _parallel_build_trees>
        args = (DecisionTreeClassifier(class_weight=None, criter...=False, random_state=1608637542, splitter='best'), RandomForestClassifier(bootstrap=True, class_wei...se, random_state=42, verbose=0, warm_start=False), array([[-5.33848464e-01],
       [-6.53381824e-0...6e-01],
       [ 3.15349698e-01]], dtype=float32), array([[0.],
       [0.],
       [0.],
       [0...    [2.],
       [2.],
       [2.],
       [2.]]), None, 0, 50)
        kwargs = {'class_weight': None, 'verbose': 0}
        self.items = [(<function _parallel_build_trees>, (DecisionTreeClassifier(class_weight=None, criter...=False, random_state=1608637542, splitter='best'), RandomForestClassifier(bootstrap=True, class_wei...se, random_state=42, verbose=0, warm_start=False), array([[-5.33848464e-01],
       [-6.53381824e-0...6e-01],
       [ 3.15349698e-01]], dtype=float32), array([[0.],
       [0.],
       [0.],
       [0...    [2.],
       [2.],
       [2.],
       [2.]]), None, 0, 50), {'class_weight': None, 'verbose': 0})]
    226 
    227     def __len__(self):
    228         return self._size
    229 

...........................................................................
/home/aquemy/.local/lib/python2.7/site-packages/sklearn/ensemble/forest.py in _parallel_build_trees(tree=DecisionTreeClassifier(class_weight=None, criter...=False, random_state=1608637542, splitter='best'), forest=RandomForestClassifier(bootstrap=True, class_wei...se, random_state=42, verbose=0, warm_start=False), X=array([[-5.33848464e-01],
       [-6.53381824e-0...6e-01],
       [ 3.15349698e-01]], dtype=float32), y=array([[0.],
       [0.],
       [0.],
       [0...    [2.],
       [2.],
       [2.],
       [2.]]), sample_weight=None, tree_idx=0, n_trees=50, verbose=0, class_weight=None)
    114                 simplefilter('ignore', DeprecationWarning)
    115                 curr_sample_weight *= compute_sample_weight('auto', y, indices)
    116         elif class_weight == 'balanced_subsample':
    117             curr_sample_weight *= compute_sample_weight('balanced', y, indices)
    118 
--> 119         tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)
        tree.fit = <bound method DecisionTreeClassifier.fit of Deci...False, random_state=1608637542, splitter='best')>
        X = array([[-5.33848464e-01],
       [-6.53381824e-0...6e-01],
       [ 3.15349698e-01]], dtype=float32)
        y = array([[0.],
       [0.],
       [0.],
       [0...    [2.],
       [2.],
       [2.],
       [2.]])
        sample_weight = None
        curr_sample_weight = array([3., 3., 0., 1., 1., 2., 2., 0., 1., 2., 0... 1., 0., 1., 0., 1., 1., 1., 1., 1., 1., 0., 0.])
    120     else:
    121         tree.fit(X, y, sample_weight=sample_weight, check_input=False)
    122 
    123     return tree

...........................................................................
/home/aquemy/.local/lib/python2.7/site-packages/sklearn/tree/tree.py in fit(self=DecisionTreeClassifier(class_weight=None, criter...=False, random_state=1608637542, splitter='best'), X=array([[-5.33848464e-01],
       [-6.53381824e-0...6e-01],
       [ 3.15349698e-01]], dtype=float32), y=array([[0.],
       [0.],
       [0.],
       [0...    [2.],
       [2.],
       [2.],
       [2.]]), sample_weight=array([3., 3., 0., 1., 1., 2., 2., 0., 1., 2., 0... 1., 0., 1., 0., 1., 1., 1., 1., 1., 1., 0., 0.]), check_input=False, X_idx_sorted=None)
    796 
    797         super(DecisionTreeClassifier, self).fit(
    798             X, y,
    799             sample_weight=sample_weight,
    800             check_input=check_input,
--> 801             X_idx_sorted=X_idx_sorted)
        X_idx_sorted = None
    802         return self
    803 
    804     def predict_proba(self, X, check_input=True):
    805         """Predict class probabilities of the input samples X.

...........................................................................
/home/aquemy/.local/lib/python2.7/site-packages/sklearn/tree/tree.py in fit(self=DecisionTreeClassifier(class_weight=None, criter...=False, random_state=1608637542, splitter='best'), X=array([[-5.33848464e-01],
       [-6.53381824e-0...6e-01],
       [ 3.15349698e-01]], dtype=float32), y=array([[0.],
       [0.],
       [0.],
       [0...    [2.],
       [2.],
       [2.],
       [2.]]), sample_weight=array([3., 3., 0., 1., 1., 2., 2., 0., 1., 2., 0... 1., 0., 1., 0., 1., 1., 1., 1., 1., 1., 0., 0.]), check_input=False, X_idx_sorted=None)
    237         if not 0 <= self.min_weight_fraction_leaf <= 0.5:
    238             raise ValueError("min_weight_fraction_leaf must in [0, 0.5]")
    239         if max_depth <= 0:
    240             raise ValueError("max_depth must be greater than zero. ")
    241         if not (0 < max_features <= self.n_features_):
--> 242             raise ValueError("max_features must be in (0, n_features]")
    243         if not isinstance(max_leaf_nodes, (numbers.Integral, np.integer)):
    244             raise ValueError("max_leaf_nodes must be integral number but was "
    245                              "%r" % max_leaf_nodes)
    246         if -1 < max_leaf_nodes < 2:

ValueError: max_features must be in (0, n_features]
___________________________________________________________________________
Best score: 0.966666666667 (0.04472135955) [J] | Score: 0.0 (0.0) [J]
Best score: 0.966666666667 (0.04472135955) [J] | Score: 0.953333333333 (0.0426874949162) [J]
Best score: 0.966666666667 (0.04472135955) [J] | Score: 0.966666666667 (0.0333333333333) [J]
Best score: 0.966666666667 (0.04472135955) [J] | Score: 0.926666666667 (0.0466666666667) [J]
Best score: 0.966666666667 (0.04472135955) [J] | Score: 0.8 (0.1490711985) [J]
Best score: 0.966666666667 (0.04472135955) [J] | Score: 0.966666666667 (0.0333333333333) [J]
Best score: 0.966666666667 (0.04472135955) [J] | Score: 0.666666666667 (1.11022302463e-16) [J]
Best score: 0.966666666667 (0.04472135955) [J] | Score: 0.666666666667 (1.11022302463e-16) [J]
Best score: 0.966666666667 (0.04472135955) [J] | Score: 0.78 (0.111753697428) [J]
Best score: 0.966666666667 (0.04472135955) [J] | Score: 0.966666666667 (0.0333333333333) [J]
Best score: 0.966666666667 (0.04472135955) [J] | Score: 0.686666666667 (0.06) [J]
Best score: 0.966666666667 (0.04472135955) [J] | Score: 0.966666666667 (0.0333333333333) [J]
Best score: 0.966666666667 (0.04472135955) [J] | Score: 0.966666666667 (0.04472135955) [J]
Best score: 0.966666666667 (0.04472135955) [J] | Score: 0.88 (0.0653197264742) [J]
Best score: 0.966666666667 (0.04472135955) [J] | Score: 0.966666666667 (0.0333333333333) [J]
Best score: 0.966666666667 (0.04472135955) [J] | Score: 0.96 (0.0442216638714) [J]
Best score: 0.966666666667 (0.04472135955) [J] | Score: 0.96 (0.0442216638714) [J]
Best score: 0.966666666667 (0.04472135955) [J] | Score: 0.953333333333 (0.0520683311727) [J]
Best score: 0.966666666667 (0.04472135955) [J] | Score: 0.953333333333 (0.06) [J]
Best score: 0.966666666667 (0.04472135955) [J] | Score: 0.666666666667 (1.11022302463e-16) [J]
Best score: 0.966666666667 (0.04472135955) [J] | Score: 0.953333333333 (0.0520683311727) [J]
Best score: 0.966666666667 (0.04472135955) [J] | Score: 0.96 (0.0326598632371) [J]
Best score: 0.966666666667 (0.04472135955) [J] | Score: 0.953333333333 (0.06) [J]
Best score: 0.966666666667 (0.04472135955) [J] | Score: 0.8 (0.129957257931) [J]
Best score: 0.966666666667 (0.04472135955) [J] | Score: 0.966666666667 (0.0333333333333) [J]
Best score: 0.966666666667 (0.04472135955) [J] | Score: 0.946666666667 (0.049888765157) [J]
Best score: 0.966666666667 (0.04472135955) [J] | Score: 0.966666666667 (0.0333333333333) [J]
Best score: 0.966666666667 (0.04472135955) [J] | Score: 0.666666666667 (1.11022302463e-16) [J]
Best score: 0.966666666667 (0.04472135955) [J] | Score: 0.966666666667 (0.04472135955) [J]
Best score: 0.966666666667 (0.04472135955) [J] | Score: 0.966666666667 (0.0333333333333) [J]
Best score: 0.966666666667 (0.04472135955) [J] | Score: 0.946666666667 (0.0581186525805) [J]
Best score: 0.966666666667 (0.04472135955) [J] | Score: 0.966666666667 (0.0333333333333) [J]
Best score: 0.966666666667 (0.04472135955) [J] | Score: 0.486666666667 (0.0845905169363) [J]
Best score: 0.966666666667 (0.04472135955) [J] | Score: 0.846666666667 (0.0896908269805) [J]
Best score: 0.966666666667 (0.04472135955) [J] | Score: 0.946666666667 (0.049888765157) [J]
Best score: 0.966666666667 (0.04472135955) [J] | Score: 0.946666666667 (0.0653197264742) [J]
Best score: 0.966666666667 (0.04472135955) [J] | Score: 0.94 (0.0696020433927) [J]
Best score: 0.966666666667 (0.04472135955) [J] | Score: 0.946666666667 (0.049888765157) [J]
Best score: 0.966666666667 (0.04472135955) [J] | Score: 0.966666666667 (0.0333333333333) [J]
Best score: 0.966666666667 (0.04472135955) [J] | Score: 0.96 (0.0442216638714) [J]
Best score: 0.966666666667 (0.04472135955) [J] | Score: 0.92 (0.0653197264742) [J]
Best score: 0.966666666667 (0.04472135955) [J] | Score: 0.946666666667 (0.049888765157) [J]
Best score: 0.966666666667 (0.04472135955) [J] | Score: 0.966666666667 (0.0333333333333) [J]
Best score: 0.966666666667 (0.04472135955) [J] | Score: 0.946666666667 (0.049888765157) [J]
Best score: 0.966666666667 (0.04472135955) [J] | Score: 0.826666666667 (0.0904310664417) [J]
Best score: 0.966666666667 (0.04472135955) [J] | Score: 0.966666666667 (0.04472135955) [J]
Best score: 0.966666666667 (0.04472135955) [J] | Score: 0.92 (0.04) [J]
JoblibValueError
___________________________________________________________________________
...........................................................................
/home/aquemy/dev/dp_hyperparameters/extension/main.py in <module>()
     27 
     28     serializer.serialize_results(scenario, policy)
     29 
     30 if __name__ == "__main__":
     31     args = cli.parse_args()
---> 32     main(args)

...........................................................................
/home/aquemy/dev/dp_hyperparameters/extension/main.py in main(args=Namespace(customize=[(['control', 'seed'], '42')...io='./scenarios/rf_iris_joint.yaml', verbosity=0))
     21         test_size=0.4, 
     22         random_state=scenario['control']['seed']
     23     )
     24 
     25     policy = policies.initiate(scenario['setup']['policy'], config)
---> 26     policy.run(X,y)
        policy.run = <bound method Joint.run of <experiment.policies.joint.Joint object>>
        X = array([[5.1, 3.5, 1.4, 0.2],
       [4.9, 3. , 1....2, 3.4, 5.4, 2.3],
       [5.9, 3. , 5.1, 1.8]])
        y = array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,... 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2])
     27 
     28     serializer.serialize_results(scenario, policy)
     29 
     30 if __name__ == "__main__":

...........................................................................
/home/aquemy/dev/dp_hyperparameters/extension/experiment/policies/joint.py in run(self=<experiment.policies.joint.Joint object>, X=array([[5.1, 3.5, 1.4, 0.2],
       [4.9, 3. , 1....2, 3.4, 5.4, 2.3],
       [5.9, 3. , 5.1, 1.8]]), y=array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,... 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]))
     32             algo=tpe.suggest, 
     33             max_evals=None,
     34             max_time=self.config['time'],     
     35             trials=trials,
     36             show_progressbar=False,
---> 37             verbose=0
     38         )
     39 
     40         best_config = self.context['best_config']
     41         super(Joint, self).display_step_results(best_config)

...........................................................................
/home/aquemy/dev/dp_hyperparameters/extension/hyperopt/fmin.py in fmin(fn=<functools.partial object>, space={'algorithm': {'bootstrap': <hyperopt.pyll.base.Apply object>, 'criterion': <hyperopt.pyll.base.Apply object>, 'max_depth': <hyperopt.pyll.base.Apply object>, 'max_features': <hyperopt.pyll.base.Apply object>, 'max_leaf_nodes': <hyperopt.pyll.base.Apply object>, 'min_samples_split': <hyperopt.pyll.base.Apply object>, 'n_estimators': <hyperopt.pyll.base.Apply object>}, 'pipeline': {'features': <hyperopt.pyll.base.Apply object>, 'normalizer': <hyperopt.pyll.base.Apply object>, 'rebalance': <hyperopt.pyll.base.Apply object>}}, algo=<function suggest>, max_evals=9223372036854775807, max_time=300, trials=<hyperopt.base.Trials object>, rstate=<mtrand.RandomState object>, allow_trials_fmin=True, pass_expr_memo_ctrl=None, catch_eval_exceptions=False, verbose=0, return_argmin=True, points_to_evaluate=None, max_queue_len=1, show_progressbar=False)
    406             pass_expr_memo_ctrl=pass_expr_memo_ctrl,
    407             verbose=verbose,
    408             catch_eval_exceptions=catch_eval_exceptions,
    409             return_argmin=return_argmin,
    410             show_progressbar=show_progressbar,
--> 411             max_time=max_time
        max_time = 300
    412         )
    413 
    414     if trials is None:
    415         if points_to_evaluate is None:

...........................................................................
/home/aquemy/dev/dp_hyperparameters/extension/hyperopt/base.py in fmin(self=<hyperopt.base.Trials object>, fn=<functools.partial object>, space={'algorithm': {'bootstrap': <hyperopt.pyll.base.Apply object>, 'criterion': <hyperopt.pyll.base.Apply object>, 'max_depth': <hyperopt.pyll.base.Apply object>, 'max_features': <hyperopt.pyll.base.Apply object>, 'max_leaf_nodes': <hyperopt.pyll.base.Apply object>, 'min_samples_split': <hyperopt.pyll.base.Apply object>, 'n_estimators': <hyperopt.pyll.base.Apply object>}, 'pipeline': {'features': <hyperopt.pyll.base.Apply object>, 'normalizer': <hyperopt.pyll.base.Apply object>, 'rebalance': <hyperopt.pyll.base.Apply object>}}, algo=<function suggest>, max_evals=9223372036854775807, max_time=300, rstate=<mtrand.RandomState object>, verbose=0, pass_expr_memo_ctrl=None, catch_eval_exceptions=False, return_argmin=True, show_progressbar=False)
    636             verbose=verbose,
    637             allow_trials_fmin=False,  # -- prevent recursion
    638             pass_expr_memo_ctrl=pass_expr_memo_ctrl,
    639             catch_eval_exceptions=catch_eval_exceptions,
    640             return_argmin=return_argmin,
--> 641             show_progressbar=show_progressbar)
        show_progressbar = False
    642 
    643 
    644 def trials_from_docs(docs, validate=True, **kwargs):
    645     """Construct a Trials base class instance from a list of trials documents

...........................................................................
/home/aquemy/dev/dp_hyperparameters/extension/hyperopt/fmin.py in fmin(fn=<functools.partial object>, space={'algorithm': {'bootstrap': <hyperopt.pyll.base.Apply object>, 'criterion': <hyperopt.pyll.base.Apply object>, 'max_depth': <hyperopt.pyll.base.Apply object>, 'max_features': <hyperopt.pyll.base.Apply object>, 'max_leaf_nodes': <hyperopt.pyll.base.Apply object>, 'min_samples_split': <hyperopt.pyll.base.Apply object>, 'n_estimators': <hyperopt.pyll.base.Apply object>}, 'pipeline': {'features': <hyperopt.pyll.base.Apply object>, 'normalizer': <hyperopt.pyll.base.Apply object>, 'rebalance': <hyperopt.pyll.base.Apply object>}}, algo=<function suggest>, max_evals=9223372036854775807, max_time=300, trials=<hyperopt.base.Trials object>, rstate=<mtrand.RandomState object>, allow_trials_fmin=False, pass_expr_memo_ctrl=None, catch_eval_exceptions=False, verbose=0, return_argmin=True, points_to_evaluate=None, max_queue_len=1, show_progressbar=False)
    426                     verbose=verbose,
    427                     max_queue_len=max_queue_len,
    428                     show_progressbar=show_progressbar,
    429                     max_time=max_time)
    430     rval.catch_eval_exceptions = catch_eval_exceptions
--> 431     rval.exhaust()
        rval.exhaust = <bound method FMinIter.exhaust of <hyperopt.fmin.FMinIter object>>
    432     if return_argmin:
    433         return trials.argmin
    434     elif len(trials) > 0:
    435         # Only if there are some succesfull trail runs, return the best point in the evaluation space

...........................................................................
/home/aquemy/dev/dp_hyperparameters/extension/hyperopt/fmin.py in exhaust(self=<hyperopt.fmin.FMinIter object>)
    273             raise StopIteration()
    274         return self.trials
    275 
    276     def exhaust(self):
    277         n_done = len(self.trials)
--> 278         self.run(self.max_evals - n_done, block_until_done=self.asynchronous)
        self.run = <bound method FMinIter.run of <hyperopt.fmin.FMinIter object>>
        self.max_evals = 9223372036854775807
        n_done = 0
        self.asynchronous = False
    279         self.trials.refresh()
    280         return self
    281 
    282 

...........................................................................
/home/aquemy/dev/dp_hyperparameters/extension/hyperopt/fmin.py in run(self=<hyperopt.fmin.FMinIter object>, N=9223372036854775807, block_until_done=False)
    232                     if self.asynchronous:
    233                         # -- wait for workers to fill in the trials
    234                         time.sleep(self.poll_interval_secs)
    235                     else:
    236                         # -- loop over trials and do the jobs directly
--> 237                         self.serial_evaluate()
        self.serial_evaluate = <bound method FMinIter.serial_evaluate of <hyperopt.fmin.FMinIter object>>
    238                     try:
    239                         res = [d['result']['loss'] for d in
    240                                          self.trials.trials if
    241                                          d['result']['status'] == 'ok']

...........................................................................
/home/aquemy/dev/dp_hyperparameters/extension/hyperopt/fmin.py in serial_evaluate(self=<hyperopt.fmin.FMinIter object>, N=-1)
    138                 trial['book_time'] = now
    139                 trial['refresh_time'] = now
    140                 spec = base.spec_from_misc(trial['misc'])
    141                 ctrl = base.Ctrl(self.trials, current_trial=trial)
    142                 try:
--> 143                     result = self.domain.evaluate(spec, ctrl)
        result = undefined
        self.domain.evaluate = <bound method Domain.evaluate of <hyperopt.base.Domain object>>
        spec = {'bootstrap': 0, 'criterion': 0, 'features': 1, 'features_PCA_features__n_components': 1, 'max_depth': 0, 'max_features': 2, 'max_leaf_nodes': 3, 'min_samples_split': 1, 'n_estimators': 4, 'normalizer': 3, ...}
        ctrl = <hyperopt.base.Ctrl object>
    144                 except Exception as e:
    145                     logger.info('job exception: %s' % str(e))
    146                     trial['state'] = base.JOB_STATE_ERROR
    147                     trial['misc']['error'] = (str(type(e)), str(e))

...........................................................................
/home/aquemy/dev/dp_hyperparameters/extension/hyperopt/base.py in evaluate(self=<hyperopt.base.Domain object>, config={'bootstrap': 0, 'criterion': 0, 'features': 1, 'features_PCA_features__n_components': 1, 'max_depth': 0, 'max_features': 2, 'max_leaf_nodes': 3, 'min_samples_split': 1, 'n_estimators': 4, 'normalizer': 3, ...}, ctrl=<hyperopt.base.Ctrl object>, attach_attachments=True)
    841             #    or the normal Python part (self.fn)
    842             pyll_rval = pyll.rec_eval(
    843                 self.expr,
    844                 memo=memo,
    845                 print_node_on_error=self.rec_eval_print_node_on_error)
--> 846             rval = self.fn(pyll_rval)
        rval = undefined
        self.fn = <functools.partial object>
        pyll_rval = {'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': 1, 'max_features': 3, 'max_leaf_nodes': None, 'min_samples_split': 3, 'n_estimators': 100}, 'pipeline': {'features': ('features_PCA', {'features__n_components': 2}), 'normalizer': ('normalizer_MinMaxScaler', {}), 'rebalance': ('rebalance_CondensedNearestNeighbour', {'rebalance__n_neighbors': 3})}}
    847 
    848         if isinstance(rval, (float, int, np.number)):
    849             dict_rval = {'loss': float(rval), 'status': STATUS_OK}
    850         else:

...........................................................................
/home/aquemy/dev/dp_hyperparameters/extension/experiment/objective.py in objective_joint(wconfig={'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': 1, 'max_features': 3, 'max_leaf_nodes': None, 'min_samples_split': 3, 'n_estimators': 100}, 'pipeline': {'features': ('features_PCA', {'features__n_components': 2}), 'normalizer': ('normalizer_MinMaxScaler', {}), 'rebalance': ('rebalance_CondensedNearestNeighbour', {'rebalance__n_neighbors': 3})}}, algorithm='RandomForest', X=array([[5.1, 3.5, 1.4, 0.2],
       [4.9, 3. , 1....2, 3.4, 5.4, 2.3],
       [5.9, 3. , 5.1, 1.8]]), y=array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,... 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]), context={'baseline_score': 0.9466666666666667, 'baseline_score_std': 0.04988876515698587, 'best_config': {'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': 1, 'max_features': None, 'max_leaf_nodes': None, 'min_samples_split': 5, 'n_estimators': 75}, 'config_hash': {'algorithm': '94b0d7a654c508cc63643f78fe4f0f07e6f07c1e', 'config': '4403c5a85e951938d3c454e961d3a412780722f6', 'pipeline': '3e47444880d8367fbac2faaba2e52a917274aa58'}, 'duration': 0.8397619724273682, 'iteration': 2, 'loss': 0.03333333333333344, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_PCA', {'features__n_components': 3}), 'normalizer': ('normalizer_MinMaxScaler', {}), 'rebalance': ('rebalance_NoneType', {})}, 'score': 0.9666666666666666, ...}, 'history': [{'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': 2, 'max_features': None, 'max_leaf_nodes': 5, 'min_samples_split': 2, 'n_estimators': 75}, 'config_hash': {'algorithm': '3af5b0cce71c8fe2545246ca24ff5bc3dd516e06', 'config': 'db6ac7e6d348155757e4794bb5f88fe2b4f63d50', 'pipeline': '8d59f4b94cef6be9306ed86a22a9570fa670d567'}, 'duration': 1.149928092956543, 'iteration': 0, 'loss': 0.046666666666666634, 'max_history_score': 0.9533333333333334, 'max_history_score_std': 0.059999999999999984, 'max_history_step': 'joint', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 4, 'features__selectkbest__k': 3}), 'normalizer': ('normalizer_StandardScaler', {'normalizer__with_mean': True, 'normalizer__with_std': True}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 6})}, 'score': 0.9533333333333334, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': 1, 'max_features': 2, 'max_leaf_nodes': 2, 'min_samples_split': 5, 'n_estimators': 100}, 'config_hash': {'algorithm': 'e13eb05fd9a62d2f63bbb1c1deff0cd620d5e6ab', 'config': '4db6fb84d85f52659f780e682ffac5712c3d8a94', 'pipeline': '64c9a1ca9d53ae67244bdd942f4db36a3c05218c'}, 'duration': 1.7678282260894775, 'iteration': 1, 'loss': 0.18000000000000005, 'max_history_score': 0.9533333333333334, 'max_history_score_std': 0.059999999999999984, 'max_history_step': 'joint', 'pipeline': {'features': ('features_NoneType', {}), 'normalizer': ('normalizer_PowerTransformer', {}), 'rebalance': ('rebalance_NearMiss', {'rebalance__n_neighbors': 1})}, 'score': 0.82, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': 1, 'max_features': None, 'max_leaf_nodes': None, 'min_samples_split': 5, 'n_estimators': 75}, 'config_hash': {'algorithm': '94b0d7a654c508cc63643f78fe4f0f07e6f07c1e', 'config': '4403c5a85e951938d3c454e961d3a412780722f6', 'pipeline': '3e47444880d8367fbac2faaba2e52a917274aa58'}, 'duration': 0.8397619724273682, 'iteration': 2, 'loss': 0.03333333333333344, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_PCA', {'features__n_components': 3}), 'normalizer': ('normalizer_MinMaxScaler', {}), 'rebalance': ('rebalance_NoneType', {})}, 'score': 0.9666666666666666, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': None, 'max_features': None, 'max_leaf_nodes': 3, 'min_samples_split': 3, 'n_estimators': 75}, 'config_hash': {'algorithm': 'e8332f0a8902bda03bf70e7978cc5d52affb29d3', 'config': 'a064e2df18ab98d44dabcefbc7bed94913f1d0be', 'pipeline': '7eea819c2a8c103c4b1e9e9c1e224aebba95081f'}, 'duration': 0.8501448631286621, 'iteration': 3, 'loss': 0.053333333333333344, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 2, 'features__selectkbest__k': 4}), 'normalizer': ('normalizer_NoneType', {}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 7})}, 'score': 0.9466666666666667, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'entropy', 'max_depth': 3, 'max_features': 3, 'max_leaf_nodes': None, 'min_samples_split': 5, 'n_estimators': 75}, 'config_hash': {'algorithm': '7a4491035bc6bd737fe9a8cda8a79a02d02d5c74', 'config': '0ddb6f5cab3db4dddd7682966a57205f3e329ad4', 'pipeline': 'a9ae03fe38334f6868cbf84cdd3d629d4bbe3fb0'}, 'duration': 1.1026010513305664, 'iteration': 4, 'loss': 0.05999999999999994, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 2, 'features__selectkbest__k': 1}), 'normalizer': ('normalizer_NoneType', {}), 'rebalance': ('rebalance_NoneType', {})}, 'score': 0.9400000000000001, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'gini', 'max_depth': 3, 'max_features': 1, 'max_leaf_nodes': 5, 'min_samples_split': 2, 'n_estimators': 25}, 'config_hash': {'algorithm': '9826d20b2d6a0f559cf7f16450ce7526f07e8434', 'config': '49f25751bca61cdd461a8cbd2923689b642f98ed', 'pipeline': '19b249664c5bf067de1fed4334a296f947ce774a'}, 'duration': 0.35647010803222656, 'iteration': 5, 'loss': 0.046666666666666634, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_NoneType', {}), 'normalizer': ('normalizer_NoneType', {}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 6})}, 'score': 0.9533333333333334, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'gini', 'max_depth': 2, 'max_features': 1, 'max_leaf_nodes': 2, 'min_samples_split': 2, 'n_estimators': 50}, 'config_hash': {'algorithm': '0a4f6fbb07e0f32c6f675489a0fc82eee05bd8e1', 'config': '5c3a2b6f5e63fb45f10e41e0318b354912ec44f6', 'pipeline': 'dc3b9f176f090005e38b142f11d80e93a7dc5d5e'}, 'duration': 0.7213859558105469, 'iteration': 6, 'loss': 0.31333333333333324, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 1, 'features__selectkbest__k': 4}), 'normalizer': ('normalizer_PowerTransformer', {}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 7})}, 'score': 0.6866666666666668, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'entropy', 'max_depth': 4, 'max_features': 3, 'max_leaf_nodes': 5, 'min_samples_split': 5, 'n_estimators': 10}, 'config_hash': {'algorithm': 'b8112b97ecfc10f00a195af661dcc861cac21289', 'config': 'd3b129b397350f1b6572651c67c01de49b4b174c', 'pipeline': '5b0357ed7072c37b3d6f458bb5d49ff7d825f603'}, 'duration': 0.8299109935760498, 'iteration': 7, 'loss': 1.0, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_PCA', {'features__n_components': 2}), 'normalizer': ('normalizer_StandardScaler', {'normalizer__with_mean': True, 'normalizer__with_std': False}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 6})}, 'score': 0.0, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'gini', 'max_depth': 4, 'max_features': None, 'max_leaf_nodes': 2, 'min_samples_split': 5, 'n_estimators': 100}, 'config_hash': {'algorithm': '40ca24df19b8d164d9d098a6bed1ce056fbbb961', 'config': '813bde1108cc3c4b9bfb3a22cbb421bda7eac671', 'pipeline': '74a7b8705a1c22f7dea5e44e4ebda8f1e48add71'}, 'duration': 2.2111589908599854, 'iteration': 8, 'loss': 0.33333333333333326, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_PCA', {'features__n_components': 2}), 'normalizer': ('normalizer_StandardScaler', {'normalizer__with_mean': False, 'normalizer__with_std': True}), 'rebalance': ('rebalance_NearMiss', {'rebalance__n_neighbors': 2})}, 'score': 0.6666666666666667, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'entropy', 'max_depth': 2, 'max_features': 1, 'max_leaf_nodes': 5, 'min_samples_split': 2, 'n_estimators': 100}, 'config_hash': {'algorithm': '331418a5c12cf1453876eef85e9d98fc8e54fa11', 'config': '31930b6860ed406d59bf7e59ba1925d94704bd3b', 'pipeline': '054bef356f90ec6f644ef3ffc688766744db51c2'}, 'duration': 1.0501940250396729, 'iteration': 9, 'loss': 0.053333333333333344, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_SelectKBest', {'features__k': 1}), 'normalizer': ('normalizer_RobustScaler', {'normalizer__quantile_range': (...), 'normalizer__with_centering': True, 'normalizer__with_scaling': True}), 'rebalance': ('rebalance_NearMiss', {'rebalance__n_neighbors': 2})}, 'score': 0.9466666666666667, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'entropy', 'max_depth': 3, 'max_features': None, 'max_leaf_nodes': 3, 'min_samples_split': 2, 'n_estimators': 100}, 'config_hash': {'algorithm': 'dbc1b8126649fe93dce5fbb37e4015b0acfb179e', 'config': '9913cd550615a9d0946ab4a755a8b9f619e442fd', 'pipeline': 'dd626121cea079ebb32e184ca65483ec7a6d7f59'}, 'duration': 1.120617151260376, 'iteration': 10, 'loss': 0.046666666666666634, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 2, 'features__selectkbest__k': 1}), 'normalizer': ('normalizer_MinMaxScaler', {}), 'rebalance': ('rebalance_NoneType', {})}, 'score': 0.9533333333333334, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'gini', 'max_depth': 3, 'max_features': 3, 'max_leaf_nodes': None, 'min_samples_split': 3, 'n_estimators': 75}, 'config_hash': {'algorithm': '34917a130df5a975f78bd7ec1a0c7b1ffdc787a9', 'config': '95fc8cadc088141290b7de9c388977e4685f0108', 'pipeline': '550d10faf2f08db48516cc3501558816d6a99bc0'}, 'duration': 1.4287099838256836, 'iteration': 11, 'loss': 0.19333333333333313, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 3, 'features__selectkbest__k': 4}), 'normalizer': ('normalizer_StandardScaler', {'normalizer__with_mean': False, 'normalizer__with_std': False}), 'rebalance': ('rebalance_CondensedNearestNeighbour', {'rebalance__n_neighbors': 1})}, 'score': 0.8066666666666669, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'entropy', 'max_depth': 1, 'max_features': 2, 'max_leaf_nodes': 5, 'min_samples_split': 2, 'n_estimators': 75}, 'config_hash': {'algorithm': '33f9abb4aee44a395a9f3b3ffa9ce80a8cdaed7c', 'config': '40fa726f0360cf6af55f9b5902d399d02f61f157', 'pipeline': 'cfd1d20841fe2153da762c95e79f95a3fb1e426a'}, 'duration': 1.2978079319000244, 'iteration': 12, 'loss': 0.053333333333333344, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_PCA', {'features__n_components': 4}), 'normalizer': ('normalizer_MinMaxScaler', {}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 7})}, 'score': 0.9466666666666667, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'entropy', 'max_depth': 4, 'max_features': 2, 'max_leaf_nodes': 5, 'min_samples_split': 3, 'n_estimators': 25}, 'config_hash': {'algorithm': '210111ec6562d09eb093e98ed69ef1c662e11a50', 'config': '0fb8e77c7bd9a58b72f1b33c21a59a09a8c676ba', 'pipeline': '5d269d759e0c7926a685a14b263ace8ae0071e4b'}, 'duration': 0.36649012565612793, 'iteration': 13, 'loss': 0.040000000000000036, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 2, 'features__selectkbest__k': 2}), 'normalizer': ('normalizer_NoneType', {}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 7})}, 'score': 0.96, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'entropy', 'max_depth': 3, 'max_features': 1, 'max_leaf_nodes': 5, 'min_samples_split': 2, 'n_estimators': 25}, 'config_hash': {'algorithm': '0e989a03980101fabf79eda3326ed2870e11d690', 'config': 'f4bffd5d8c67a9c5321a9943c4a99678f59a02b7', 'pipeline': '865ee1e3fe8334c3d5ecb2038d5a5d1b3ba50e75'}, 'duration': 0.35639500617980957, 'iteration': 14, 'loss': 0.046666666666666634, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_NoneType', {}), 'normalizer': ('normalizer_RobustScaler', {'normalizer__quantile_range': (...), 'normalizer__with_centering': True, 'normalizer__with_scaling': False}), 'rebalance': ('rebalance_NoneType', {})}, 'score': 0.9533333333333334, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'entropy', 'max_depth': None, 'max_features': 3, 'max_leaf_nodes': 3, 'min_samples_split': 5, 'n_estimators': 10}, 'config_hash': {'algorithm': '9c592e876c13de5e23e6de5b868e01755d63e72e', 'config': '1e6a68cd1eeac886d90724d78b1cb5fb76a3cde4', 'pipeline': '5a1ca4d82f21b7de0d2c918630a42510673fa36e'}, 'duration': 0.18141412734985352, 'iteration': 15, 'loss': 0.046666666666666634, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_SelectKBest', {'features__k': 3}), 'normalizer': ('normalizer_RobustScaler', {'normalizer__quantile_range': (...), 'normalizer__with_centering': True, 'normalizer__with_scaling': True}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 6})}, 'score': 0.9533333333333334, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': 1, 'max_features': None, 'max_leaf_nodes': None, 'min_samples_split': 5, 'n_estimators': 10}, 'config_hash': {'algorithm': '8bed77aef289bfd453b2858bd288ae5ba7160f2b', 'config': '781185bcb8999045de8d489f253a1a1ba4247932', 'pipeline': '1ece7eabedc2be9e5b0a1be65c570d08ffa3eb54'}, 'duration': 0.1636829376220703, 'iteration': 16, 'loss': 0.053333333333333344, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_NoneType', {}), 'normalizer': ('normalizer_NoneType', {}), 'rebalance': ('rebalance_NearMiss', {'rebalance__n_neighbors': 1})}, 'score': 0.9466666666666667, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'gini', 'max_depth': 3, 'max_features': 2, 'max_leaf_nodes': 2, 'min_samples_split': 5, 'n_estimators': 75}, 'config_hash': {'algorithm': '617b97d9ba21d3373bc51ffa9cccf9c6f91a77b3', 'config': '99fb425b4e8c5d80228cab94202252aa25cdf77c', 'pipeline': 'd6242929c3b515c7719e60423023ac604311afc3'}, 'duration': 0.8468999862670898, 'iteration': 17, 'loss': 0.24, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_PCA', {'features__n_components': 4}), 'normalizer': ('normalizer_PowerTransformer', {}), 'rebalance': ('rebalance_NearMiss', {'rebalance__n_neighbors': 2})}, 'score': 0.76, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': 1, 'max_features': 1, 'max_leaf_nodes': 2, 'min_samples_split': 5, 'n_estimators': 50}, 'config_hash': {'algorithm': 'b92d2697cdd4979da443369d6596229ec091626a', 'config': 'c513a3e13281206ad76187dd817b1fff93d54fe1', 'pipeline': 'c4b4f914a3ca8df967cade997a90366d85a371b9'}, 'duration': 0.6724588871002197, 'iteration': 18, 'loss': 0.23333333333333328, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 1, 'features__selectkbest__k': 3}), 'normalizer': ('normalizer_StandardScaler', {'normalizer__with_mean': True, 'normalizer__with_std': True}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 5})}, 'score': 0.7666666666666667, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'entropy', 'max_depth': None, 'max_features': None, 'max_leaf_nodes': 5, 'min_samples_split': 5, 'n_estimators': 10}, 'config_hash': {'algorithm': 'a0115de695e6cca2e81cbfb54df79bf4b43608b1', 'config': 'ba194015e20b5d67770e8c67342c3d8d0d01dc41', 'pipeline': '8d45fabfeb85ffdcabf7076bd0e65fffe97ce928'}, 'duration': 0.19424200057983398, 'iteration': 19, 'loss': 0.08666666666666667, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_PCA', {'features__n_components': 3}), 'normalizer': ('normalizer_NoneType', {}), 'rebalance': ('rebalance_NoneType', {})}, 'score': 0.9133333333333333, ...}, ...], 'history_hash': ['db6ac7e6d348155757e4794bb5f88fe2b4f63d50', '4db6fb84d85f52659f780e682ffac5712c3d8a94', '4403c5a85e951938d3c454e961d3a412780722f6', 'a064e2df18ab98d44dabcefbc7bed94913f1d0be', '0ddb6f5cab3db4dddd7682966a57205f3e329ad4', '49f25751bca61cdd461a8cbd2923689b642f98ed', '5c3a2b6f5e63fb45f10e41e0318b354912ec44f6', 'd3b129b397350f1b6572651c67c01de49b4b174c', '813bde1108cc3c4b9bfb3a22cbb421bda7eac671', '31930b6860ed406d59bf7e59ba1925d94704bd3b', '9913cd550615a9d0946ab4a755a8b9f619e442fd', '95fc8cadc088141290b7de9c388977e4685f0108', '40fa726f0360cf6af55f9b5902d399d02f61f157', '0fb8e77c7bd9a58b72f1b33c21a59a09a8c676ba', 'f4bffd5d8c67a9c5321a9943c4a99678f59a02b7', '1e6a68cd1eeac886d90724d78b1cb5fb76a3cde4', '781185bcb8999045de8d489f253a1a1ba4247932', '99fb425b4e8c5d80228cab94202252aa25cdf77c', 'c513a3e13281206ad76187dd817b1fff93d54fe1', 'ba194015e20b5d67770e8c67342c3d8d0d01dc41', ...], 'history_index': {'013329309d510b94f19d930320402d65f953a847': 39, '038a0f515e2ec894ee8e34f9caa2889eb3ebd5ce': 66, '0659afebf316aafeb75612fb07081a04c28545ed': 74, '0b6551ecfd6f83a15704a9db68f1599c99c6d3ef': 58, '0ddb6f5cab3db4dddd7682966a57205f3e329ad4': 4, '0fb8e77c7bd9a58b72f1b33c21a59a09a8c676ba': 13, '111ffc790caf02104464bfa2f448cba7c56c71dc': 46, '1491c41c81d50fd91883539deec82c61b3ed7935': 84, '156cf80babab134353766c500267028d67005289': 20, '15e0cff8e21e22e019fbe58048fd1b035f9da200': 79, ...}, 'iteration': 97, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint'}, config={'algorithm': 'RandomForest', 'seed': 42, 'time': 300})
    108 
    109 def objective_algo(algo_config, current_pipeline_config, algorithm, X, y, context, config):
    110     return objective(current_pipeline_config, algo_config, algorithm, X, y, context, config, step='algorithm')
    111 
    112 def objective_joint(wconfig, algorithm, X, y, context, config):
--> 113     return objective(wconfig['pipeline'], wconfig['algorithm'], algorithm, X, y, context, config, step='joint')
        wconfig = {'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': 1, 'max_features': 3, 'max_leaf_nodes': None, 'min_samples_split': 3, 'n_estimators': 100}, 'pipeline': {'features': ('features_PCA', {'features__n_components': 2}), 'normalizer': ('normalizer_MinMaxScaler', {}), 'rebalance': ('rebalance_CondensedNearestNeighbour', {'rebalance__n_neighbors': 3})}}
        algorithm = 'RandomForest'
        X = array([[5.1, 3.5, 1.4, 0.2],
       [4.9, 3. , 1....2, 3.4, 5.4, 2.3],
       [5.9, 3. , 5.1, 1.8]])
        y = array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,... 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2])
        context = {'baseline_score': 0.9466666666666667, 'baseline_score_std': 0.04988876515698587, 'best_config': {'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': 1, 'max_features': None, 'max_leaf_nodes': None, 'min_samples_split': 5, 'n_estimators': 75}, 'config_hash': {'algorithm': '94b0d7a654c508cc63643f78fe4f0f07e6f07c1e', 'config': '4403c5a85e951938d3c454e961d3a412780722f6', 'pipeline': '3e47444880d8367fbac2faaba2e52a917274aa58'}, 'duration': 0.8397619724273682, 'iteration': 2, 'loss': 0.03333333333333344, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_PCA', {'features__n_components': 3}), 'normalizer': ('normalizer_MinMaxScaler', {}), 'rebalance': ('rebalance_NoneType', {})}, 'score': 0.9666666666666666, ...}, 'history': [{'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': 2, 'max_features': None, 'max_leaf_nodes': 5, 'min_samples_split': 2, 'n_estimators': 75}, 'config_hash': {'algorithm': '3af5b0cce71c8fe2545246ca24ff5bc3dd516e06', 'config': 'db6ac7e6d348155757e4794bb5f88fe2b4f63d50', 'pipeline': '8d59f4b94cef6be9306ed86a22a9570fa670d567'}, 'duration': 1.149928092956543, 'iteration': 0, 'loss': 0.046666666666666634, 'max_history_score': 0.9533333333333334, 'max_history_score_std': 0.059999999999999984, 'max_history_step': 'joint', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 4, 'features__selectkbest__k': 3}), 'normalizer': ('normalizer_StandardScaler', {'normalizer__with_mean': True, 'normalizer__with_std': True}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 6})}, 'score': 0.9533333333333334, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': 1, 'max_features': 2, 'max_leaf_nodes': 2, 'min_samples_split': 5, 'n_estimators': 100}, 'config_hash': {'algorithm': 'e13eb05fd9a62d2f63bbb1c1deff0cd620d5e6ab', 'config': '4db6fb84d85f52659f780e682ffac5712c3d8a94', 'pipeline': '64c9a1ca9d53ae67244bdd942f4db36a3c05218c'}, 'duration': 1.7678282260894775, 'iteration': 1, 'loss': 0.18000000000000005, 'max_history_score': 0.9533333333333334, 'max_history_score_std': 0.059999999999999984, 'max_history_step': 'joint', 'pipeline': {'features': ('features_NoneType', {}), 'normalizer': ('normalizer_PowerTransformer', {}), 'rebalance': ('rebalance_NearMiss', {'rebalance__n_neighbors': 1})}, 'score': 0.82, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': 1, 'max_features': None, 'max_leaf_nodes': None, 'min_samples_split': 5, 'n_estimators': 75}, 'config_hash': {'algorithm': '94b0d7a654c508cc63643f78fe4f0f07e6f07c1e', 'config': '4403c5a85e951938d3c454e961d3a412780722f6', 'pipeline': '3e47444880d8367fbac2faaba2e52a917274aa58'}, 'duration': 0.8397619724273682, 'iteration': 2, 'loss': 0.03333333333333344, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_PCA', {'features__n_components': 3}), 'normalizer': ('normalizer_MinMaxScaler', {}), 'rebalance': ('rebalance_NoneType', {})}, 'score': 0.9666666666666666, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': None, 'max_features': None, 'max_leaf_nodes': 3, 'min_samples_split': 3, 'n_estimators': 75}, 'config_hash': {'algorithm': 'e8332f0a8902bda03bf70e7978cc5d52affb29d3', 'config': 'a064e2df18ab98d44dabcefbc7bed94913f1d0be', 'pipeline': '7eea819c2a8c103c4b1e9e9c1e224aebba95081f'}, 'duration': 0.8501448631286621, 'iteration': 3, 'loss': 0.053333333333333344, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 2, 'features__selectkbest__k': 4}), 'normalizer': ('normalizer_NoneType', {}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 7})}, 'score': 0.9466666666666667, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'entropy', 'max_depth': 3, 'max_features': 3, 'max_leaf_nodes': None, 'min_samples_split': 5, 'n_estimators': 75}, 'config_hash': {'algorithm': '7a4491035bc6bd737fe9a8cda8a79a02d02d5c74', 'config': '0ddb6f5cab3db4dddd7682966a57205f3e329ad4', 'pipeline': 'a9ae03fe38334f6868cbf84cdd3d629d4bbe3fb0'}, 'duration': 1.1026010513305664, 'iteration': 4, 'loss': 0.05999999999999994, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 2, 'features__selectkbest__k': 1}), 'normalizer': ('normalizer_NoneType', {}), 'rebalance': ('rebalance_NoneType', {})}, 'score': 0.9400000000000001, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'gini', 'max_depth': 3, 'max_features': 1, 'max_leaf_nodes': 5, 'min_samples_split': 2, 'n_estimators': 25}, 'config_hash': {'algorithm': '9826d20b2d6a0f559cf7f16450ce7526f07e8434', 'config': '49f25751bca61cdd461a8cbd2923689b642f98ed', 'pipeline': '19b249664c5bf067de1fed4334a296f947ce774a'}, 'duration': 0.35647010803222656, 'iteration': 5, 'loss': 0.046666666666666634, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_NoneType', {}), 'normalizer': ('normalizer_NoneType', {}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 6})}, 'score': 0.9533333333333334, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'gini', 'max_depth': 2, 'max_features': 1, 'max_leaf_nodes': 2, 'min_samples_split': 2, 'n_estimators': 50}, 'config_hash': {'algorithm': '0a4f6fbb07e0f32c6f675489a0fc82eee05bd8e1', 'config': '5c3a2b6f5e63fb45f10e41e0318b354912ec44f6', 'pipeline': 'dc3b9f176f090005e38b142f11d80e93a7dc5d5e'}, 'duration': 0.7213859558105469, 'iteration': 6, 'loss': 0.31333333333333324, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 1, 'features__selectkbest__k': 4}), 'normalizer': ('normalizer_PowerTransformer', {}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 7})}, 'score': 0.6866666666666668, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'entropy', 'max_depth': 4, 'max_features': 3, 'max_leaf_nodes': 5, 'min_samples_split': 5, 'n_estimators': 10}, 'config_hash': {'algorithm': 'b8112b97ecfc10f00a195af661dcc861cac21289', 'config': 'd3b129b397350f1b6572651c67c01de49b4b174c', 'pipeline': '5b0357ed7072c37b3d6f458bb5d49ff7d825f603'}, 'duration': 0.8299109935760498, 'iteration': 7, 'loss': 1.0, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_PCA', {'features__n_components': 2}), 'normalizer': ('normalizer_StandardScaler', {'normalizer__with_mean': True, 'normalizer__with_std': False}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 6})}, 'score': 0.0, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'gini', 'max_depth': 4, 'max_features': None, 'max_leaf_nodes': 2, 'min_samples_split': 5, 'n_estimators': 100}, 'config_hash': {'algorithm': '40ca24df19b8d164d9d098a6bed1ce056fbbb961', 'config': '813bde1108cc3c4b9bfb3a22cbb421bda7eac671', 'pipeline': '74a7b8705a1c22f7dea5e44e4ebda8f1e48add71'}, 'duration': 2.2111589908599854, 'iteration': 8, 'loss': 0.33333333333333326, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_PCA', {'features__n_components': 2}), 'normalizer': ('normalizer_StandardScaler', {'normalizer__with_mean': False, 'normalizer__with_std': True}), 'rebalance': ('rebalance_NearMiss', {'rebalance__n_neighbors': 2})}, 'score': 0.6666666666666667, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'entropy', 'max_depth': 2, 'max_features': 1, 'max_leaf_nodes': 5, 'min_samples_split': 2, 'n_estimators': 100}, 'config_hash': {'algorithm': '331418a5c12cf1453876eef85e9d98fc8e54fa11', 'config': '31930b6860ed406d59bf7e59ba1925d94704bd3b', 'pipeline': '054bef356f90ec6f644ef3ffc688766744db51c2'}, 'duration': 1.0501940250396729, 'iteration': 9, 'loss': 0.053333333333333344, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_SelectKBest', {'features__k': 1}), 'normalizer': ('normalizer_RobustScaler', {'normalizer__quantile_range': (...), 'normalizer__with_centering': True, 'normalizer__with_scaling': True}), 'rebalance': ('rebalance_NearMiss', {'rebalance__n_neighbors': 2})}, 'score': 0.9466666666666667, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'entropy', 'max_depth': 3, 'max_features': None, 'max_leaf_nodes': 3, 'min_samples_split': 2, 'n_estimators': 100}, 'config_hash': {'algorithm': 'dbc1b8126649fe93dce5fbb37e4015b0acfb179e', 'config': '9913cd550615a9d0946ab4a755a8b9f619e442fd', 'pipeline': 'dd626121cea079ebb32e184ca65483ec7a6d7f59'}, 'duration': 1.120617151260376, 'iteration': 10, 'loss': 0.046666666666666634, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 2, 'features__selectkbest__k': 1}), 'normalizer': ('normalizer_MinMaxScaler', {}), 'rebalance': ('rebalance_NoneType', {})}, 'score': 0.9533333333333334, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'gini', 'max_depth': 3, 'max_features': 3, 'max_leaf_nodes': None, 'min_samples_split': 3, 'n_estimators': 75}, 'config_hash': {'algorithm': '34917a130df5a975f78bd7ec1a0c7b1ffdc787a9', 'config': '95fc8cadc088141290b7de9c388977e4685f0108', 'pipeline': '550d10faf2f08db48516cc3501558816d6a99bc0'}, 'duration': 1.4287099838256836, 'iteration': 11, 'loss': 0.19333333333333313, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 3, 'features__selectkbest__k': 4}), 'normalizer': ('normalizer_StandardScaler', {'normalizer__with_mean': False, 'normalizer__with_std': False}), 'rebalance': ('rebalance_CondensedNearestNeighbour', {'rebalance__n_neighbors': 1})}, 'score': 0.8066666666666669, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'entropy', 'max_depth': 1, 'max_features': 2, 'max_leaf_nodes': 5, 'min_samples_split': 2, 'n_estimators': 75}, 'config_hash': {'algorithm': '33f9abb4aee44a395a9f3b3ffa9ce80a8cdaed7c', 'config': '40fa726f0360cf6af55f9b5902d399d02f61f157', 'pipeline': 'cfd1d20841fe2153da762c95e79f95a3fb1e426a'}, 'duration': 1.2978079319000244, 'iteration': 12, 'loss': 0.053333333333333344, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_PCA', {'features__n_components': 4}), 'normalizer': ('normalizer_MinMaxScaler', {}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 7})}, 'score': 0.9466666666666667, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'entropy', 'max_depth': 4, 'max_features': 2, 'max_leaf_nodes': 5, 'min_samples_split': 3, 'n_estimators': 25}, 'config_hash': {'algorithm': '210111ec6562d09eb093e98ed69ef1c662e11a50', 'config': '0fb8e77c7bd9a58b72f1b33c21a59a09a8c676ba', 'pipeline': '5d269d759e0c7926a685a14b263ace8ae0071e4b'}, 'duration': 0.36649012565612793, 'iteration': 13, 'loss': 0.040000000000000036, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 2, 'features__selectkbest__k': 2}), 'normalizer': ('normalizer_NoneType', {}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 7})}, 'score': 0.96, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'entropy', 'max_depth': 3, 'max_features': 1, 'max_leaf_nodes': 5, 'min_samples_split': 2, 'n_estimators': 25}, 'config_hash': {'algorithm': '0e989a03980101fabf79eda3326ed2870e11d690', 'config': 'f4bffd5d8c67a9c5321a9943c4a99678f59a02b7', 'pipeline': '865ee1e3fe8334c3d5ecb2038d5a5d1b3ba50e75'}, 'duration': 0.35639500617980957, 'iteration': 14, 'loss': 0.046666666666666634, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_NoneType', {}), 'normalizer': ('normalizer_RobustScaler', {'normalizer__quantile_range': (...), 'normalizer__with_centering': True, 'normalizer__with_scaling': False}), 'rebalance': ('rebalance_NoneType', {})}, 'score': 0.9533333333333334, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'entropy', 'max_depth': None, 'max_features': 3, 'max_leaf_nodes': 3, 'min_samples_split': 5, 'n_estimators': 10}, 'config_hash': {'algorithm': '9c592e876c13de5e23e6de5b868e01755d63e72e', 'config': '1e6a68cd1eeac886d90724d78b1cb5fb76a3cde4', 'pipeline': '5a1ca4d82f21b7de0d2c918630a42510673fa36e'}, 'duration': 0.18141412734985352, 'iteration': 15, 'loss': 0.046666666666666634, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_SelectKBest', {'features__k': 3}), 'normalizer': ('normalizer_RobustScaler', {'normalizer__quantile_range': (...), 'normalizer__with_centering': True, 'normalizer__with_scaling': True}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 6})}, 'score': 0.9533333333333334, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': 1, 'max_features': None, 'max_leaf_nodes': None, 'min_samples_split': 5, 'n_estimators': 10}, 'config_hash': {'algorithm': '8bed77aef289bfd453b2858bd288ae5ba7160f2b', 'config': '781185bcb8999045de8d489f253a1a1ba4247932', 'pipeline': '1ece7eabedc2be9e5b0a1be65c570d08ffa3eb54'}, 'duration': 0.1636829376220703, 'iteration': 16, 'loss': 0.053333333333333344, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_NoneType', {}), 'normalizer': ('normalizer_NoneType', {}), 'rebalance': ('rebalance_NearMiss', {'rebalance__n_neighbors': 1})}, 'score': 0.9466666666666667, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'gini', 'max_depth': 3, 'max_features': 2, 'max_leaf_nodes': 2, 'min_samples_split': 5, 'n_estimators': 75}, 'config_hash': {'algorithm': '617b97d9ba21d3373bc51ffa9cccf9c6f91a77b3', 'config': '99fb425b4e8c5d80228cab94202252aa25cdf77c', 'pipeline': 'd6242929c3b515c7719e60423023ac604311afc3'}, 'duration': 0.8468999862670898, 'iteration': 17, 'loss': 0.24, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_PCA', {'features__n_components': 4}), 'normalizer': ('normalizer_PowerTransformer', {}), 'rebalance': ('rebalance_NearMiss', {'rebalance__n_neighbors': 2})}, 'score': 0.76, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': 1, 'max_features': 1, 'max_leaf_nodes': 2, 'min_samples_split': 5, 'n_estimators': 50}, 'config_hash': {'algorithm': 'b92d2697cdd4979da443369d6596229ec091626a', 'config': 'c513a3e13281206ad76187dd817b1fff93d54fe1', 'pipeline': 'c4b4f914a3ca8df967cade997a90366d85a371b9'}, 'duration': 0.6724588871002197, 'iteration': 18, 'loss': 0.23333333333333328, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 1, 'features__selectkbest__k': 3}), 'normalizer': ('normalizer_StandardScaler', {'normalizer__with_mean': True, 'normalizer__with_std': True}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 5})}, 'score': 0.7666666666666667, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'entropy', 'max_depth': None, 'max_features': None, 'max_leaf_nodes': 5, 'min_samples_split': 5, 'n_estimators': 10}, 'config_hash': {'algorithm': 'a0115de695e6cca2e81cbfb54df79bf4b43608b1', 'config': 'ba194015e20b5d67770e8c67342c3d8d0d01dc41', 'pipeline': '8d45fabfeb85ffdcabf7076bd0e65fffe97ce928'}, 'duration': 0.19424200057983398, 'iteration': 19, 'loss': 0.08666666666666667, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_PCA', {'features__n_components': 3}), 'normalizer': ('normalizer_NoneType', {}), 'rebalance': ('rebalance_NoneType', {})}, 'score': 0.9133333333333333, ...}, ...], 'history_hash': ['db6ac7e6d348155757e4794bb5f88fe2b4f63d50', '4db6fb84d85f52659f780e682ffac5712c3d8a94', '4403c5a85e951938d3c454e961d3a412780722f6', 'a064e2df18ab98d44dabcefbc7bed94913f1d0be', '0ddb6f5cab3db4dddd7682966a57205f3e329ad4', '49f25751bca61cdd461a8cbd2923689b642f98ed', '5c3a2b6f5e63fb45f10e41e0318b354912ec44f6', 'd3b129b397350f1b6572651c67c01de49b4b174c', '813bde1108cc3c4b9bfb3a22cbb421bda7eac671', '31930b6860ed406d59bf7e59ba1925d94704bd3b', '9913cd550615a9d0946ab4a755a8b9f619e442fd', '95fc8cadc088141290b7de9c388977e4685f0108', '40fa726f0360cf6af55f9b5902d399d02f61f157', '0fb8e77c7bd9a58b72f1b33c21a59a09a8c676ba', 'f4bffd5d8c67a9c5321a9943c4a99678f59a02b7', '1e6a68cd1eeac886d90724d78b1cb5fb76a3cde4', '781185bcb8999045de8d489f253a1a1ba4247932', '99fb425b4e8c5d80228cab94202252aa25cdf77c', 'c513a3e13281206ad76187dd817b1fff93d54fe1', 'ba194015e20b5d67770e8c67342c3d8d0d01dc41', ...], 'history_index': {'013329309d510b94f19d930320402d65f953a847': 39, '038a0f515e2ec894ee8e34f9caa2889eb3ebd5ce': 66, '0659afebf316aafeb75612fb07081a04c28545ed': 74, '0b6551ecfd6f83a15704a9db68f1599c99c6d3ef': 58, '0ddb6f5cab3db4dddd7682966a57205f3e329ad4': 4, '0fb8e77c7bd9a58b72f1b33c21a59a09a8c676ba': 13, '111ffc790caf02104464bfa2f448cba7c56c71dc': 46, '1491c41c81d50fd91883539deec82c61b3ed7935': 84, '156cf80babab134353766c500267028d67005289': 20, '15e0cff8e21e22e019fbe58048fd1b035f9da200': 79, ...}, 'iteration': 97, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint'}
        config = {'algorithm': 'RandomForest', 'seed': 42, 'time': 300}
    114 
    115 
    116 def get_baseline_score(algorithm, X, y, seed):
    117     pipeline, _ = pipeline_conf_to_full_pipeline(

...........................................................................
/home/aquemy/dev/dp_hyperparameters/extension/experiment/objective.py in objective(pipeline_config={'features': ('features_PCA', {'features__n_components': 2}), 'normalizer': ('normalizer_MinMaxScaler', {}), 'rebalance': ('rebalance_CondensedNearestNeighbour', {'rebalance__n_neighbors': 3})}, algo_config={'bootstrap': True, 'criterion': 'gini', 'max_depth': 1, 'max_features': 3, 'max_leaf_nodes': None, 'min_samples_split': 3, 'n_estimators': 100}, algorithm='RandomForest', X=array([[5.1, 3.5, 1.4, 0.2],
       [4.9, 3. , 1....2, 3.4, 5.4, 2.3],
       [5.9, 3. , 5.1, 1.8]]), y=array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,... 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]), context={'baseline_score': 0.9466666666666667, 'baseline_score_std': 0.04988876515698587, 'best_config': {'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': 1, 'max_features': None, 'max_leaf_nodes': None, 'min_samples_split': 5, 'n_estimators': 75}, 'config_hash': {'algorithm': '94b0d7a654c508cc63643f78fe4f0f07e6f07c1e', 'config': '4403c5a85e951938d3c454e961d3a412780722f6', 'pipeline': '3e47444880d8367fbac2faaba2e52a917274aa58'}, 'duration': 0.8397619724273682, 'iteration': 2, 'loss': 0.03333333333333344, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_PCA', {'features__n_components': 3}), 'normalizer': ('normalizer_MinMaxScaler', {}), 'rebalance': ('rebalance_NoneType', {})}, 'score': 0.9666666666666666, ...}, 'history': [{'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': 2, 'max_features': None, 'max_leaf_nodes': 5, 'min_samples_split': 2, 'n_estimators': 75}, 'config_hash': {'algorithm': '3af5b0cce71c8fe2545246ca24ff5bc3dd516e06', 'config': 'db6ac7e6d348155757e4794bb5f88fe2b4f63d50', 'pipeline': '8d59f4b94cef6be9306ed86a22a9570fa670d567'}, 'duration': 1.149928092956543, 'iteration': 0, 'loss': 0.046666666666666634, 'max_history_score': 0.9533333333333334, 'max_history_score_std': 0.059999999999999984, 'max_history_step': 'joint', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 4, 'features__selectkbest__k': 3}), 'normalizer': ('normalizer_StandardScaler', {'normalizer__with_mean': True, 'normalizer__with_std': True}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 6})}, 'score': 0.9533333333333334, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': 1, 'max_features': 2, 'max_leaf_nodes': 2, 'min_samples_split': 5, 'n_estimators': 100}, 'config_hash': {'algorithm': 'e13eb05fd9a62d2f63bbb1c1deff0cd620d5e6ab', 'config': '4db6fb84d85f52659f780e682ffac5712c3d8a94', 'pipeline': '64c9a1ca9d53ae67244bdd942f4db36a3c05218c'}, 'duration': 1.7678282260894775, 'iteration': 1, 'loss': 0.18000000000000005, 'max_history_score': 0.9533333333333334, 'max_history_score_std': 0.059999999999999984, 'max_history_step': 'joint', 'pipeline': {'features': ('features_NoneType', {}), 'normalizer': ('normalizer_PowerTransformer', {}), 'rebalance': ('rebalance_NearMiss', {'rebalance__n_neighbors': 1})}, 'score': 0.82, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': 1, 'max_features': None, 'max_leaf_nodes': None, 'min_samples_split': 5, 'n_estimators': 75}, 'config_hash': {'algorithm': '94b0d7a654c508cc63643f78fe4f0f07e6f07c1e', 'config': '4403c5a85e951938d3c454e961d3a412780722f6', 'pipeline': '3e47444880d8367fbac2faaba2e52a917274aa58'}, 'duration': 0.8397619724273682, 'iteration': 2, 'loss': 0.03333333333333344, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_PCA', {'features__n_components': 3}), 'normalizer': ('normalizer_MinMaxScaler', {}), 'rebalance': ('rebalance_NoneType', {})}, 'score': 0.9666666666666666, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': None, 'max_features': None, 'max_leaf_nodes': 3, 'min_samples_split': 3, 'n_estimators': 75}, 'config_hash': {'algorithm': 'e8332f0a8902bda03bf70e7978cc5d52affb29d3', 'config': 'a064e2df18ab98d44dabcefbc7bed94913f1d0be', 'pipeline': '7eea819c2a8c103c4b1e9e9c1e224aebba95081f'}, 'duration': 0.8501448631286621, 'iteration': 3, 'loss': 0.053333333333333344, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 2, 'features__selectkbest__k': 4}), 'normalizer': ('normalizer_NoneType', {}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 7})}, 'score': 0.9466666666666667, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'entropy', 'max_depth': 3, 'max_features': 3, 'max_leaf_nodes': None, 'min_samples_split': 5, 'n_estimators': 75}, 'config_hash': {'algorithm': '7a4491035bc6bd737fe9a8cda8a79a02d02d5c74', 'config': '0ddb6f5cab3db4dddd7682966a57205f3e329ad4', 'pipeline': 'a9ae03fe38334f6868cbf84cdd3d629d4bbe3fb0'}, 'duration': 1.1026010513305664, 'iteration': 4, 'loss': 0.05999999999999994, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 2, 'features__selectkbest__k': 1}), 'normalizer': ('normalizer_NoneType', {}), 'rebalance': ('rebalance_NoneType', {})}, 'score': 0.9400000000000001, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'gini', 'max_depth': 3, 'max_features': 1, 'max_leaf_nodes': 5, 'min_samples_split': 2, 'n_estimators': 25}, 'config_hash': {'algorithm': '9826d20b2d6a0f559cf7f16450ce7526f07e8434', 'config': '49f25751bca61cdd461a8cbd2923689b642f98ed', 'pipeline': '19b249664c5bf067de1fed4334a296f947ce774a'}, 'duration': 0.35647010803222656, 'iteration': 5, 'loss': 0.046666666666666634, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_NoneType', {}), 'normalizer': ('normalizer_NoneType', {}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 6})}, 'score': 0.9533333333333334, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'gini', 'max_depth': 2, 'max_features': 1, 'max_leaf_nodes': 2, 'min_samples_split': 2, 'n_estimators': 50}, 'config_hash': {'algorithm': '0a4f6fbb07e0f32c6f675489a0fc82eee05bd8e1', 'config': '5c3a2b6f5e63fb45f10e41e0318b354912ec44f6', 'pipeline': 'dc3b9f176f090005e38b142f11d80e93a7dc5d5e'}, 'duration': 0.7213859558105469, 'iteration': 6, 'loss': 0.31333333333333324, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 1, 'features__selectkbest__k': 4}), 'normalizer': ('normalizer_PowerTransformer', {}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 7})}, 'score': 0.6866666666666668, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'entropy', 'max_depth': 4, 'max_features': 3, 'max_leaf_nodes': 5, 'min_samples_split': 5, 'n_estimators': 10}, 'config_hash': {'algorithm': 'b8112b97ecfc10f00a195af661dcc861cac21289', 'config': 'd3b129b397350f1b6572651c67c01de49b4b174c', 'pipeline': '5b0357ed7072c37b3d6f458bb5d49ff7d825f603'}, 'duration': 0.8299109935760498, 'iteration': 7, 'loss': 1.0, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_PCA', {'features__n_components': 2}), 'normalizer': ('normalizer_StandardScaler', {'normalizer__with_mean': True, 'normalizer__with_std': False}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 6})}, 'score': 0.0, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'gini', 'max_depth': 4, 'max_features': None, 'max_leaf_nodes': 2, 'min_samples_split': 5, 'n_estimators': 100}, 'config_hash': {'algorithm': '40ca24df19b8d164d9d098a6bed1ce056fbbb961', 'config': '813bde1108cc3c4b9bfb3a22cbb421bda7eac671', 'pipeline': '74a7b8705a1c22f7dea5e44e4ebda8f1e48add71'}, 'duration': 2.2111589908599854, 'iteration': 8, 'loss': 0.33333333333333326, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_PCA', {'features__n_components': 2}), 'normalizer': ('normalizer_StandardScaler', {'normalizer__with_mean': False, 'normalizer__with_std': True}), 'rebalance': ('rebalance_NearMiss', {'rebalance__n_neighbors': 2})}, 'score': 0.6666666666666667, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'entropy', 'max_depth': 2, 'max_features': 1, 'max_leaf_nodes': 5, 'min_samples_split': 2, 'n_estimators': 100}, 'config_hash': {'algorithm': '331418a5c12cf1453876eef85e9d98fc8e54fa11', 'config': '31930b6860ed406d59bf7e59ba1925d94704bd3b', 'pipeline': '054bef356f90ec6f644ef3ffc688766744db51c2'}, 'duration': 1.0501940250396729, 'iteration': 9, 'loss': 0.053333333333333344, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_SelectKBest', {'features__k': 1}), 'normalizer': ('normalizer_RobustScaler', {'normalizer__quantile_range': (...), 'normalizer__with_centering': True, 'normalizer__with_scaling': True}), 'rebalance': ('rebalance_NearMiss', {'rebalance__n_neighbors': 2})}, 'score': 0.9466666666666667, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'entropy', 'max_depth': 3, 'max_features': None, 'max_leaf_nodes': 3, 'min_samples_split': 2, 'n_estimators': 100}, 'config_hash': {'algorithm': 'dbc1b8126649fe93dce5fbb37e4015b0acfb179e', 'config': '9913cd550615a9d0946ab4a755a8b9f619e442fd', 'pipeline': 'dd626121cea079ebb32e184ca65483ec7a6d7f59'}, 'duration': 1.120617151260376, 'iteration': 10, 'loss': 0.046666666666666634, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 2, 'features__selectkbest__k': 1}), 'normalizer': ('normalizer_MinMaxScaler', {}), 'rebalance': ('rebalance_NoneType', {})}, 'score': 0.9533333333333334, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'gini', 'max_depth': 3, 'max_features': 3, 'max_leaf_nodes': None, 'min_samples_split': 3, 'n_estimators': 75}, 'config_hash': {'algorithm': '34917a130df5a975f78bd7ec1a0c7b1ffdc787a9', 'config': '95fc8cadc088141290b7de9c388977e4685f0108', 'pipeline': '550d10faf2f08db48516cc3501558816d6a99bc0'}, 'duration': 1.4287099838256836, 'iteration': 11, 'loss': 0.19333333333333313, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 3, 'features__selectkbest__k': 4}), 'normalizer': ('normalizer_StandardScaler', {'normalizer__with_mean': False, 'normalizer__with_std': False}), 'rebalance': ('rebalance_CondensedNearestNeighbour', {'rebalance__n_neighbors': 1})}, 'score': 0.8066666666666669, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'entropy', 'max_depth': 1, 'max_features': 2, 'max_leaf_nodes': 5, 'min_samples_split': 2, 'n_estimators': 75}, 'config_hash': {'algorithm': '33f9abb4aee44a395a9f3b3ffa9ce80a8cdaed7c', 'config': '40fa726f0360cf6af55f9b5902d399d02f61f157', 'pipeline': 'cfd1d20841fe2153da762c95e79f95a3fb1e426a'}, 'duration': 1.2978079319000244, 'iteration': 12, 'loss': 0.053333333333333344, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_PCA', {'features__n_components': 4}), 'normalizer': ('normalizer_MinMaxScaler', {}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 7})}, 'score': 0.9466666666666667, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'entropy', 'max_depth': 4, 'max_features': 2, 'max_leaf_nodes': 5, 'min_samples_split': 3, 'n_estimators': 25}, 'config_hash': {'algorithm': '210111ec6562d09eb093e98ed69ef1c662e11a50', 'config': '0fb8e77c7bd9a58b72f1b33c21a59a09a8c676ba', 'pipeline': '5d269d759e0c7926a685a14b263ace8ae0071e4b'}, 'duration': 0.36649012565612793, 'iteration': 13, 'loss': 0.040000000000000036, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 2, 'features__selectkbest__k': 2}), 'normalizer': ('normalizer_NoneType', {}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 7})}, 'score': 0.96, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'entropy', 'max_depth': 3, 'max_features': 1, 'max_leaf_nodes': 5, 'min_samples_split': 2, 'n_estimators': 25}, 'config_hash': {'algorithm': '0e989a03980101fabf79eda3326ed2870e11d690', 'config': 'f4bffd5d8c67a9c5321a9943c4a99678f59a02b7', 'pipeline': '865ee1e3fe8334c3d5ecb2038d5a5d1b3ba50e75'}, 'duration': 0.35639500617980957, 'iteration': 14, 'loss': 0.046666666666666634, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_NoneType', {}), 'normalizer': ('normalizer_RobustScaler', {'normalizer__quantile_range': (...), 'normalizer__with_centering': True, 'normalizer__with_scaling': False}), 'rebalance': ('rebalance_NoneType', {})}, 'score': 0.9533333333333334, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'entropy', 'max_depth': None, 'max_features': 3, 'max_leaf_nodes': 3, 'min_samples_split': 5, 'n_estimators': 10}, 'config_hash': {'algorithm': '9c592e876c13de5e23e6de5b868e01755d63e72e', 'config': '1e6a68cd1eeac886d90724d78b1cb5fb76a3cde4', 'pipeline': '5a1ca4d82f21b7de0d2c918630a42510673fa36e'}, 'duration': 0.18141412734985352, 'iteration': 15, 'loss': 0.046666666666666634, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_SelectKBest', {'features__k': 3}), 'normalizer': ('normalizer_RobustScaler', {'normalizer__quantile_range': (...), 'normalizer__with_centering': True, 'normalizer__with_scaling': True}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 6})}, 'score': 0.9533333333333334, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': 1, 'max_features': None, 'max_leaf_nodes': None, 'min_samples_split': 5, 'n_estimators': 10}, 'config_hash': {'algorithm': '8bed77aef289bfd453b2858bd288ae5ba7160f2b', 'config': '781185bcb8999045de8d489f253a1a1ba4247932', 'pipeline': '1ece7eabedc2be9e5b0a1be65c570d08ffa3eb54'}, 'duration': 0.1636829376220703, 'iteration': 16, 'loss': 0.053333333333333344, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_NoneType', {}), 'normalizer': ('normalizer_NoneType', {}), 'rebalance': ('rebalance_NearMiss', {'rebalance__n_neighbors': 1})}, 'score': 0.9466666666666667, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'gini', 'max_depth': 3, 'max_features': 2, 'max_leaf_nodes': 2, 'min_samples_split': 5, 'n_estimators': 75}, 'config_hash': {'algorithm': '617b97d9ba21d3373bc51ffa9cccf9c6f91a77b3', 'config': '99fb425b4e8c5d80228cab94202252aa25cdf77c', 'pipeline': 'd6242929c3b515c7719e60423023ac604311afc3'}, 'duration': 0.8468999862670898, 'iteration': 17, 'loss': 0.24, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_PCA', {'features__n_components': 4}), 'normalizer': ('normalizer_PowerTransformer', {}), 'rebalance': ('rebalance_NearMiss', {'rebalance__n_neighbors': 2})}, 'score': 0.76, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': 1, 'max_features': 1, 'max_leaf_nodes': 2, 'min_samples_split': 5, 'n_estimators': 50}, 'config_hash': {'algorithm': 'b92d2697cdd4979da443369d6596229ec091626a', 'config': 'c513a3e13281206ad76187dd817b1fff93d54fe1', 'pipeline': 'c4b4f914a3ca8df967cade997a90366d85a371b9'}, 'duration': 0.6724588871002197, 'iteration': 18, 'loss': 0.23333333333333328, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 1, 'features__selectkbest__k': 3}), 'normalizer': ('normalizer_StandardScaler', {'normalizer__with_mean': True, 'normalizer__with_std': True}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 5})}, 'score': 0.7666666666666667, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'entropy', 'max_depth': None, 'max_features': None, 'max_leaf_nodes': 5, 'min_samples_split': 5, 'n_estimators': 10}, 'config_hash': {'algorithm': 'a0115de695e6cca2e81cbfb54df79bf4b43608b1', 'config': 'ba194015e20b5d67770e8c67342c3d8d0d01dc41', 'pipeline': '8d45fabfeb85ffdcabf7076bd0e65fffe97ce928'}, 'duration': 0.19424200057983398, 'iteration': 19, 'loss': 0.08666666666666667, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_PCA', {'features__n_components': 3}), 'normalizer': ('normalizer_NoneType', {}), 'rebalance': ('rebalance_NoneType', {})}, 'score': 0.9133333333333333, ...}, ...], 'history_hash': ['db6ac7e6d348155757e4794bb5f88fe2b4f63d50', '4db6fb84d85f52659f780e682ffac5712c3d8a94', '4403c5a85e951938d3c454e961d3a412780722f6', 'a064e2df18ab98d44dabcefbc7bed94913f1d0be', '0ddb6f5cab3db4dddd7682966a57205f3e329ad4', '49f25751bca61cdd461a8cbd2923689b642f98ed', '5c3a2b6f5e63fb45f10e41e0318b354912ec44f6', 'd3b129b397350f1b6572651c67c01de49b4b174c', '813bde1108cc3c4b9bfb3a22cbb421bda7eac671', '31930b6860ed406d59bf7e59ba1925d94704bd3b', '9913cd550615a9d0946ab4a755a8b9f619e442fd', '95fc8cadc088141290b7de9c388977e4685f0108', '40fa726f0360cf6af55f9b5902d399d02f61f157', '0fb8e77c7bd9a58b72f1b33c21a59a09a8c676ba', 'f4bffd5d8c67a9c5321a9943c4a99678f59a02b7', '1e6a68cd1eeac886d90724d78b1cb5fb76a3cde4', '781185bcb8999045de8d489f253a1a1ba4247932', '99fb425b4e8c5d80228cab94202252aa25cdf77c', 'c513a3e13281206ad76187dd817b1fff93d54fe1', 'ba194015e20b5d67770e8c67342c3d8d0d01dc41', ...], 'history_index': {'013329309d510b94f19d930320402d65f953a847': 39, '038a0f515e2ec894ee8e34f9caa2889eb3ebd5ce': 66, '0659afebf316aafeb75612fb07081a04c28545ed': 74, '0b6551ecfd6f83a15704a9db68f1599c99c6d3ef': 58, '0ddb6f5cab3db4dddd7682966a57205f3e329ad4': 4, '0fb8e77c7bd9a58b72f1b33c21a59a09a8c676ba': 13, '111ffc790caf02104464bfa2f448cba7c56c71dc': 46, '1491c41c81d50fd91883539deec82c61b3ed7935': 84, '156cf80babab134353766c500267028d67005289': 20, '15e0cff8e21e22e019fbe58048fd1b035f9da200': 79, ...}, 'iteration': 97, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint'}, config={'algorithm': 'RandomForest', 'seed': 42, 'time': 300}, step='joint')
     45                 y,
     46                 cv=10,
     47                 n_jobs=-1,
     48                 return_estimator=False,
     49                 return_train_score=False,
---> 50                 verbose=0)
     51         score = np.mean(scores['test_score'])
     52         std = np.std(scores['test_score'])
     53         status = STATUS_OK
     54     except Exception as e:

...........................................................................
/home/aquemy/.local/lib/python2.7/site-packages/sklearn/model_selection/_validation.py in cross_validate(estimator=Pipeline(memory=None,
     steps=[('rebalance', ... random_state=42, verbose=0, warm_start=False))]), X=array([[5.1, 3.5, 1.4, 0.2],
       [4.9, 3. , 1....2, 3.4, 5.4, 2.3],
       [5.9, 3. , 5.1, 1.8]]), y=array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,... 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]), groups=None, scoring=None, cv=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1, verbose=0, fit_params=None, pre_dispatch='2*n_jobs', return_train_score=False, return_estimator=False, error_score='raise-deprecating')
    235         delayed(_fit_and_score)(
    236             clone(estimator), X, y, scorers, train, test, verbose, None,
    237             fit_params, return_train_score=return_train_score,
    238             return_times=True, return_estimator=return_estimator,
    239             error_score=error_score)
--> 240         for train, test in cv.split(X, y, groups))
        cv.split = <bound method StratifiedKFold.split of Stratifie...d(n_splits=10, random_state=None, shuffle=False)>
        X = array([[5.1, 3.5, 1.4, 0.2],
       [4.9, 3. , 1....2, 3.4, 5.4, 2.3],
       [5.9, 3. , 5.1, 1.8]])
        y = array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,... 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2])
        groups = None
    241 
    242     zipped_scores = list(zip(*scores))
    243     if return_train_score:
    244         train_scores = zipped_scores.pop(0)

...........................................................................
/home/aquemy/.local/lib/python2.7/site-packages/sklearn/externals/joblib/parallel.py in __call__(self=Parallel(n_jobs=-1), iterable=<generator object <genexpr>>)
    925                 # No need to wait for async callbacks to trigger to
    926                 # consumption.
    927                 self._iterating = False
    928 
    929             with self._backend.retrieval_context():
--> 930                 self.retrieve()
        self.retrieve = <bound method Parallel.retrieve of Parallel(n_jobs=-1)>
    931             # Make sure that we get a last message telling us we are done
    932             elapsed_time = time.time() - self._start_time
    933             self._print('Done %3i out of %3i | elapsed: %s finished',
    934                         (len(self._output), len(self._output),

---------------------------------------------------------------------------
Joblib worker traceback:
---------------------------------------------------------------------------
ValueError                                         Mon Jun 17 13:12:02 2019
PID: 21043                                  Python 2.7.15+: /usr/bin/python
...........................................................................
/home/aquemy/.local/lib/python2.7/site-packages/sklearn/externals/joblib/parallel.py in __call__(self=<sklearn.externals.joblib.parallel.BatchedCalls object>)
    220     def __call__(self):
    221         # Set the default nested backend to self._backend but do not set the
    222         # change the default number of processes to -1
    223         with parallel_backend(self._backend, n_jobs=self._n_jobs):
    224             return [func(*args, **kwargs)
--> 225                     for func, args, kwargs in self.items]
        func = <function _fit_and_score>
        args = (Pipeline(memory=None,
     steps=[('rebalance', ... random_state=42, verbose=0, warm_start=False))]), array([[5.1, 3.5, 1.4, 0.2],
       [4.9, 3. , 1....2, 3.4, 5.4, 2.3],
       [5.9, 3. , 5.1, 1.8]]), array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,... 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]), {'score': <function _passthrough_scorer>}, array([  5,   6,   7,   8,   9,  10,  11,  12,  ..., 142, 143, 144,
       145, 146, 147, 148, 149]), array([  0,   1,   2,   3,   4,  50,  51,  52,  53,  54, 100, 101, 102,
       103, 104]), 0, None, None)
        kwargs = {'error_score': 'raise-deprecating', 'return_estimator': False, 'return_times': True, 'return_train_score': False}
        self.items = [(<function _fit_and_score>, (Pipeline(memory=None,
     steps=[('rebalance', ... random_state=42, verbose=0, warm_start=False))]), array([[5.1, 3.5, 1.4, 0.2],
       [4.9, 3. , 1....2, 3.4, 5.4, 2.3],
       [5.9, 3. , 5.1, 1.8]]), array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,... 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]), {'score': <function _passthrough_scorer>}, array([  5,   6,   7,   8,   9,  10,  11,  12,  ..., 142, 143, 144,
       145, 146, 147, 148, 149]), array([  0,   1,   2,   3,   4,  50,  51,  52,  53,  54, 100, 101, 102,
       103, 104]), 0, None, None), {'error_score': 'raise-deprecating', 'return_estimator': False, 'return_times': True, 'return_train_score': False})]
    226 
    227     def __len__(self):
    228         return self._size
    229 

...........................................................................
/home/aquemy/.local/lib/python2.7/site-packages/sklearn/model_selection/_validation.py in _fit_and_score(estimator=Pipeline(memory=None,
     steps=[('rebalance', ... random_state=42, verbose=0, warm_start=False))]), X=array([[5.1, 3.5, 1.4, 0.2],
       [4.9, 3. , 1....2, 3.4, 5.4, 2.3],
       [5.9, 3. , 5.1, 1.8]]), y=array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,... 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]), scorer={'score': <function _passthrough_scorer>}, train=array([  5,   6,   7,   8,   9,  10,  11,  12,  ..., 142, 143, 144,
       145, 146, 147, 148, 149]), test=array([  0,   1,   2,   3,   4,  50,  51,  52,  53,  54, 100, 101, 102,
       103, 104]), verbose=0, parameters=None, fit_params={}, return_train_score=False, return_parameters=False, return_n_test_samples=False, return_times=True, return_estimator=False, error_score='raise-deprecating')
    523 
    524     try:
    525         if y_train is None:
    526             estimator.fit(X_train, **fit_params)
    527         else:
--> 528             estimator.fit(X_train, y_train, **fit_params)
        estimator.fit = <bound method Pipeline.fit of Pipeline(memory=No...random_state=42, verbose=0, warm_start=False))])>
        X_train = array([[5.4, 3.9, 1.7, 0.4],
       [4.6, 3.4, 1....2, 3.4, 5.4, 2.3],
       [5.9, 3. , 5.1, 1.8]])
        y_train = array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,
       2, 2, 2])
        fit_params = {}
    529 
    530     except Exception as e:
    531         # Note fit time as time until error
    532         fit_time = time.time() - start_time

...........................................................................
/usr/local/lib/python2.7/dist-packages/imblearn/pipeline.py in fit(self=Pipeline(memory=None,
     steps=[('rebalance', ... random_state=42, verbose=0, warm_start=False))]), X=array([[5.4, 3.9, 1.7, 0.4],
       [4.6, 3.4, 1....2, 3.4, 5.4, 2.3],
       [5.9, 3. , 5.1, 1.8]]), y=array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,
       2, 2, 2]), **fit_params={})
    234             This estimator
    235 
    236         """
    237         Xt, yt, fit_params = self._fit(X, y, **fit_params)
    238         if self._final_estimator is not None:
--> 239             self._final_estimator.fit(Xt, yt, **fit_params)
        self._final_estimator.fit = <bound method RandomForestClassifier.fit of Rand...e, random_state=42, verbose=0, warm_start=False)>
        Xt = array([[-0.07324939, -0.25370366],
       [-0.12...-0.44843772],
       [ 0.84836974,  0.25925116]])
        yt = array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...0, 0, 0, 0, 0, 0, 0, 0,
       0, 1, 1, 2, 2, 2])
        fit_params = {}
    240         return self
    241 
    242     def fit_transform(self, X, y=None, **fit_params):
    243         """Fit the model and transform with the final estimator

...........................................................................
/home/aquemy/.local/lib/python2.7/site-packages/sklearn/ensemble/forest.py in fit(self=RandomForestClassifier(bootstrap=True, class_wei...se, random_state=42, verbose=0, warm_start=False), X=array([[-0.07324938, -0.25370365],
       [-0.12...      [ 0.8483697 ,  0.25925115]], dtype=float32), y=array([[0.],
       [0.],
       [0.],
       [0...    [1.],
       [2.],
       [2.],
       [2.]]), sample_weight=None)
    328             trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,
    329                              **_joblib_parallel_args(prefer='threads'))(
    330                 delayed(_parallel_build_trees)(
    331                     t, self, X, y, sample_weight, i, len(trees),
    332                     verbose=self.verbose, class_weight=self.class_weight)
--> 333                 for i, t in enumerate(trees))
        i = 99
    334 
    335             # Collect newly grown trees
    336             self.estimators_.extend(trees)
    337 

...........................................................................
/home/aquemy/.local/lib/python2.7/site-packages/sklearn/externals/joblib/parallel.py in __call__(self=Parallel(n_jobs=1), iterable=<generator object <genexpr>>)
    912             # self._original_iterator is None, then this means either
    913             # that pre_dispatch == "all", n_jobs == 1 or that the first batch
    914             # was very quick and its callback already dispatched all the
    915             # remaining jobs.
    916             self._iterating = False
--> 917             if self.dispatch_one_batch(iterator):
        self.dispatch_one_batch = <bound method Parallel.dispatch_one_batch of Parallel(n_jobs=1)>
        iterator = <generator object <genexpr>>
    918                 self._iterating = self._original_iterator is not None
    919 
    920             while self.dispatch_one_batch(iterator):
    921                 pass

...........................................................................
/home/aquemy/.local/lib/python2.7/site-packages/sklearn/externals/joblib/parallel.py in dispatch_one_batch(self=Parallel(n_jobs=1), iterator=<generator object <genexpr>>)
    754                                  self._pickle_cache)
    755             if len(tasks) == 0:
    756                 # No more tasks available in the iterator: tell caller to stop.
    757                 return False
    758             else:
--> 759                 self._dispatch(tasks)
        self._dispatch = <bound method Parallel._dispatch of Parallel(n_jobs=1)>
        tasks = <sklearn.externals.joblib.parallel.BatchedCalls object>
    760                 return True
    761 
    762     def _print(self, msg, msg_args):
    763         """Display the message on stout or stderr depending on verbosity"""

...........................................................................
/home/aquemy/.local/lib/python2.7/site-packages/sklearn/externals/joblib/parallel.py in _dispatch(self=Parallel(n_jobs=1), batch=<sklearn.externals.joblib.parallel.BatchedCalls object>)
    711 
    712         dispatch_timestamp = time.time()
    713         cb = BatchCompletionCallBack(dispatch_timestamp, len(batch), self)
    714         with self._lock:
    715             job_idx = len(self._jobs)
--> 716             job = self._backend.apply_async(batch, callback=cb)
        job = undefined
        self._backend.apply_async = <bound method SequentialBackend.apply_async of <...lib._parallel_backends.SequentialBackend object>>
        batch = <sklearn.externals.joblib.parallel.BatchedCalls object>
        cb = <sklearn.externals.joblib.parallel.BatchCompletionCallBack object>
    717             # A job can complete so quickly than its callback is
    718             # called before we get here, causing self._jobs to
    719             # grow. To ensure correct results ordering, .insert is
    720             # used (rather than .append) in the following line

...........................................................................
/home/aquemy/.local/lib/python2.7/site-packages/sklearn/externals/joblib/_parallel_backends.py in apply_async(self=<sklearn.externals.joblib._parallel_backends.SequentialBackend object>, func=<sklearn.externals.joblib.parallel.BatchedCalls object>, callback=<sklearn.externals.joblib.parallel.BatchCompletionCallBack object>)
    177             raise ValueError('n_jobs == 0 in Parallel has no meaning')
    178         return 1
    179 
    180     def apply_async(self, func, callback=None):
    181         """Schedule a func to be run"""
--> 182         result = ImmediateResult(func)
        result = undefined
        func = <sklearn.externals.joblib.parallel.BatchedCalls object>
    183         if callback:
    184             callback(result)
    185         return result
    186 

...........................................................................
/home/aquemy/.local/lib/python2.7/site-packages/sklearn/externals/joblib/_parallel_backends.py in __init__(self=<sklearn.externals.joblib._parallel_backends.ImmediateResult object>, batch=<sklearn.externals.joblib.parallel.BatchedCalls object>)
    544 
    545 class ImmediateResult(object):
    546     def __init__(self, batch):
    547         # Don't delay the application, to avoid keeping the input
    548         # arguments in memory
--> 549         self.results = batch()
        self.results = undefined
        batch = <sklearn.externals.joblib.parallel.BatchedCalls object>
    550 
    551     def get(self):
    552         return self.results
    553 

...........................................................................
/home/aquemy/.local/lib/python2.7/site-packages/sklearn/externals/joblib/parallel.py in __call__(self=<sklearn.externals.joblib.parallel.BatchedCalls object>)
    220     def __call__(self):
    221         # Set the default nested backend to self._backend but do not set the
    222         # change the default number of processes to -1
    223         with parallel_backend(self._backend, n_jobs=self._n_jobs):
    224             return [func(*args, **kwargs)
--> 225                     for func, args, kwargs in self.items]
        func = <function _parallel_build_trees>
        args = (DecisionTreeClassifier(class_weight=None, criter...=False, random_state=1608637542, splitter='best'), RandomForestClassifier(bootstrap=True, class_wei...se, random_state=42, verbose=0, warm_start=False), array([[-0.07324938, -0.25370365],
       [-0.12...      [ 0.8483697 ,  0.25925115]], dtype=float32), array([[0.],
       [0.],
       [0.],
       [0...    [1.],
       [2.],
       [2.],
       [2.]]), None, 0, 100)
        kwargs = {'class_weight': None, 'verbose': 0}
        self.items = [(<function _parallel_build_trees>, (DecisionTreeClassifier(class_weight=None, criter...=False, random_state=1608637542, splitter='best'), RandomForestClassifier(bootstrap=True, class_wei...se, random_state=42, verbose=0, warm_start=False), array([[-0.07324938, -0.25370365],
       [-0.12...      [ 0.8483697 ,  0.25925115]], dtype=float32), array([[0.],
       [0.],
       [0.],
       [0...    [1.],
       [2.],
       [2.],
       [2.]]), None, 0, 100), {'class_weight': None, 'verbose': 0})]
    226 
    227     def __len__(self):
    228         return self._size
    229 

...........................................................................
/home/aquemy/.local/lib/python2.7/site-packages/sklearn/ensemble/forest.py in _parallel_build_trees(tree=DecisionTreeClassifier(class_weight=None, criter...=False, random_state=1608637542, splitter='best'), forest=RandomForestClassifier(bootstrap=True, class_wei...se, random_state=42, verbose=0, warm_start=False), X=array([[-0.07324938, -0.25370365],
       [-0.12...      [ 0.8483697 ,  0.25925115]], dtype=float32), y=array([[0.],
       [0.],
       [0.],
       [0...    [1.],
       [2.],
       [2.],
       [2.]]), sample_weight=None, tree_idx=0, n_trees=100, verbose=0, class_weight=None)
    114                 simplefilter('ignore', DeprecationWarning)
    115                 curr_sample_weight *= compute_sample_weight('auto', y, indices)
    116         elif class_weight == 'balanced_subsample':
    117             curr_sample_weight *= compute_sample_weight('balanced', y, indices)
    118 
--> 119         tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)
        tree.fit = <bound method DecisionTreeClassifier.fit of Deci...False, random_state=1608637542, splitter='best')>
        X = array([[-0.07324938, -0.25370365],
       [-0.12...      [ 0.8483697 ,  0.25925115]], dtype=float32)
        y = array([[0.],
       [0.],
       [0.],
       [0...    [1.],
       [2.],
       [2.],
       [2.]])
        sample_weight = None
        curr_sample_weight = array([2., 0., 2., 1., 2., 0., 1., 2., 1., 1., 2... 0., 2., 0., 5., 0., 2., 0., 0., 1., 0., 0., 3.])
    120     else:
    121         tree.fit(X, y, sample_weight=sample_weight, check_input=False)
    122 
    123     return tree

...........................................................................
/home/aquemy/.local/lib/python2.7/site-packages/sklearn/tree/tree.py in fit(self=DecisionTreeClassifier(class_weight=None, criter...=False, random_state=1608637542, splitter='best'), X=array([[-0.07324938, -0.25370365],
       [-0.12...      [ 0.8483697 ,  0.25925115]], dtype=float32), y=array([[0.],
       [0.],
       [0.],
       [0...    [1.],
       [2.],
       [2.],
       [2.]]), sample_weight=array([2., 0., 2., 1., 2., 0., 1., 2., 1., 1., 2... 0., 2., 0., 5., 0., 2., 0., 0., 1., 0., 0., 3.]), check_input=False, X_idx_sorted=None)
    796 
    797         super(DecisionTreeClassifier, self).fit(
    798             X, y,
    799             sample_weight=sample_weight,
    800             check_input=check_input,
--> 801             X_idx_sorted=X_idx_sorted)
        X_idx_sorted = None
    802         return self
    803 
    804     def predict_proba(self, X, check_input=True):
    805         """Predict class probabilities of the input samples X.

...........................................................................
/home/aquemy/.local/lib/python2.7/site-packages/sklearn/tree/tree.py in fit(self=DecisionTreeClassifier(class_weight=None, criter...=False, random_state=1608637542, splitter='best'), X=array([[-0.07324938, -0.25370365],
       [-0.12...      [ 0.8483697 ,  0.25925115]], dtype=float32), y=array([[0.],
       [0.],
       [0.],
       [0...    [1.],
       [2.],
       [2.],
       [2.]]), sample_weight=array([2., 0., 2., 1., 2., 0., 1., 2., 1., 1., 2... 0., 2., 0., 5., 0., 2., 0., 0., 1., 0., 0., 3.]), check_input=False, X_idx_sorted=None)
    237         if not 0 <= self.min_weight_fraction_leaf <= 0.5:
    238             raise ValueError("min_weight_fraction_leaf must in [0, 0.5]")
    239         if max_depth <= 0:
    240             raise ValueError("max_depth must be greater than zero. ")
    241         if not (0 < max_features <= self.n_features_):
--> 242             raise ValueError("max_features must be in (0, n_features]")
    243         if not isinstance(max_leaf_nodes, (numbers.Integral, np.integer)):
    244             raise ValueError("max_leaf_nodes must be integral number but was "
    245                              "%r" % max_leaf_nodes)
    246         if -1 < max_leaf_nodes < 2:

ValueError: max_features must be in (0, n_features]
___________________________________________________________________________
Best score: 0.966666666667 (0.04472135955) [J] | Score: 0.0 (0.0) [J]
Best score: 0.966666666667 (0.04472135955) [J] | Score: 0.96 (0.0442216638714) [J]
Best score: 0.966666666667 (0.04472135955) [J] | Score: 0.96 (0.0442216638714) [J]
Best score: 0.966666666667 (0.04472135955) [J] | Score: 0.96 (0.0442216638714) [J]
Best score: 0.966666666667 (0.04472135955) [J] | Score: 0.946666666667 (0.049888765157) [J]
Best score: 0.966666666667 (0.04472135955) [J] | Score: 0.946666666667 (0.0581186525805) [J]
Best score: 0.966666666667 (0.04472135955) [J] | Score: 0.92 (0.049888765157) [J]
Best score: 0.966666666667 (0.04472135955) [J] | Score: 0.666666666667 (1.11022302463e-16) [J]
Best score: 0.966666666667 (0.04472135955) [J] | Score: 0.946666666667 (0.049888765157) [J]
Best score: 0.966666666667 (0.04472135955) [J] | Score: 0.926666666667 (0.0466666666667) [J]
Best score: 0.966666666667 (0.04472135955) [J] | Score: 0.953333333333 (0.06) [J]
Best score: 0.966666666667 (0.04472135955) [J] | Score: 0.96 (0.0326598632371) [J]
Best score: 0.966666666667 (0.04472135955) [J] | Score: 0.66 (0.02) [J]
Best score: 0.966666666667 (0.04472135955) [J] | Score: 0.953333333333 (0.0426874949162) [J]
Best score: 0.966666666667 (0.04472135955) [J] | Score: 0.94 (0.0553774924195) [J]
Best score: 0.966666666667 (0.0333333333333) [J] | Score: 0.966666666667 (0.0333333333333) [J]
Best score: 0.966666666667 (0.0333333333333) [J] | Score: 0.713333333333 (0.0733333333333) [J]
Best score: 0.966666666667 (0.0333333333333) [J] | Score: 0.893333333333 (0.0853749898324) [J]
Best score: 0.966666666667 (0.0333333333333) [J] | Score: 0.906666666667 (0.08) [J]
Best score: 0.966666666667 (0.0333333333333) [J] | Score: 0.86 (0.109341463112) [J]
Best score: 0.966666666667 (0.0333333333333) [J] | Score: 0.953333333333 (0.0520683311727) [J]
Best score: 0.966666666667 (0.0333333333333) [J] | Score: 0.666666666667 (0.0516397779494) [J]
Best score: 0.966666666667 (0.0333333333333) [J] | Score: 0.906666666667 (0.0853749898324) [J]
Best score: 0.966666666667 (0.0333333333333) [J] | Score: 0.66 (0.02) [J]
Best score: 0.966666666667 (0.0333333333333) [J] | Score: 0.926666666667 (0.0696020433927) [J]
Best score: 0.966666666667 (0.0333333333333) [J] | Score: 0.666666666667 (1.11022302463e-16) [J]
Best score: 0.966666666667 (0.0333333333333) [J] | Score: 0.9 (0.0802772971919) [J]
Best score: 0.966666666667 (0.0333333333333) [J] | Score: 0.666666666667 (1.11022302463e-16) [J]
Best score: 0.966666666667 (0.0333333333333) [J] | Score: 0.646666666667 (0.0426874949162) [J]
Best score: 0.966666666667 (0.0333333333333) [J] | Score: 0.906666666667 (0.0679869268479) [J]
Best score: 0.966666666667 (0.0333333333333) [J] | Score: 0.666666666667 (1.11022302463e-16) [J]
Best score: 0.966666666667 (0.0333333333333) [J] | Score: 0.906666666667 (0.0853749898324) [J]
Best score: 0.966666666667 (0.0333333333333) [J] | Score: 0.666666666667 (1.11022302463e-16) [J]
Best score: 0.966666666667 (0.0333333333333) [J] | Score: 0.873333333333 (0.0916515138991) [J]
Best score: 0.966666666667 (0.0333333333333) [J] | Score: 0.866666666667 (0.0988826464946) [J]
Best score: 0.966666666667 (0.0333333333333) [J] | Score: 0.653333333333 (0.04) [J]
Best score: 0.966666666667 (0.0333333333333) [J] | Score: 0.893333333333 (0.08) [J]
Best score: 0.966666666667 (0.0333333333333) [J] | Score: 0.873333333333 (0.105198225587) [J]
Best score: 0.966666666667 (0.0333333333333) [J] | Score: 0.826666666667 (0.130639452948) [J]
Best score: 0.966666666667 (0.0333333333333) [J] | Score: 0.906666666667 (0.0679869268479) [J]
Best score: 0.966666666667 (0.0333333333333) [J] | Score: 0.646666666667 (0.0426874949162) [J]
Best score: 0.966666666667 (0.0333333333333) [J] | Score: 0.86 (0.075718777944) [J]
Best score: 0.966666666667 (0.0333333333333) [J] | Score: 0.893333333333 (0.0742368581711) [J]
Best score: 0.966666666667 (0.0333333333333) [J] | Score: 0.913333333333 (0.0669991708075) [J]
JoblibValueError
___________________________________________________________________________
...........................................................................
/home/aquemy/dev/dp_hyperparameters/extension/main.py in <module>()
     27 
     28     serializer.serialize_results(scenario, policy)
     29 
     30 if __name__ == "__main__":
     31     args = cli.parse_args()
---> 32     main(args)

...........................................................................
/home/aquemy/dev/dp_hyperparameters/extension/main.py in main(args=Namespace(customize=[(['control', 'seed'], '42')...io='./scenarios/rf_iris_joint.yaml', verbosity=0))
     21         test_size=0.4, 
     22         random_state=scenario['control']['seed']
     23     )
     24 
     25     policy = policies.initiate(scenario['setup']['policy'], config)
---> 26     policy.run(X,y)
        policy.run = <bound method Joint.run of <experiment.policies.joint.Joint object>>
        X = array([[5.1, 3.5, 1.4, 0.2],
       [4.9, 3. , 1....2, 3.4, 5.4, 2.3],
       [5.9, 3. , 5.1, 1.8]])
        y = array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,... 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2])
     27 
     28     serializer.serialize_results(scenario, policy)
     29 
     30 if __name__ == "__main__":

...........................................................................
/home/aquemy/dev/dp_hyperparameters/extension/experiment/policies/joint.py in run(self=<experiment.policies.joint.Joint object>, X=array([[5.1, 3.5, 1.4, 0.2],
       [4.9, 3. , 1....2, 3.4, 5.4, 2.3],
       [5.9, 3. , 5.1, 1.8]]), y=array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,... 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]))
     32             algo=tpe.suggest, 
     33             max_evals=None,
     34             max_time=self.config['time'],     
     35             trials=trials,
     36             show_progressbar=False,
---> 37             verbose=0
     38         )
     39 
     40         best_config = self.context['best_config']
     41         super(Joint, self).display_step_results(best_config)

...........................................................................
/home/aquemy/dev/dp_hyperparameters/extension/hyperopt/fmin.py in fmin(fn=<functools.partial object>, space={'algorithm': {'bootstrap': <hyperopt.pyll.base.Apply object>, 'criterion': <hyperopt.pyll.base.Apply object>, 'max_depth': <hyperopt.pyll.base.Apply object>, 'max_features': <hyperopt.pyll.base.Apply object>, 'max_leaf_nodes': <hyperopt.pyll.base.Apply object>, 'min_samples_split': <hyperopt.pyll.base.Apply object>, 'n_estimators': <hyperopt.pyll.base.Apply object>}, 'pipeline': {'features': <hyperopt.pyll.base.Apply object>, 'normalizer': <hyperopt.pyll.base.Apply object>, 'rebalance': <hyperopt.pyll.base.Apply object>}}, algo=<function suggest>, max_evals=9223372036854775807, max_time=300, trials=<hyperopt.base.Trials object>, rstate=<mtrand.RandomState object>, allow_trials_fmin=True, pass_expr_memo_ctrl=None, catch_eval_exceptions=False, verbose=0, return_argmin=True, points_to_evaluate=None, max_queue_len=1, show_progressbar=False)
    406             pass_expr_memo_ctrl=pass_expr_memo_ctrl,
    407             verbose=verbose,
    408             catch_eval_exceptions=catch_eval_exceptions,
    409             return_argmin=return_argmin,
    410             show_progressbar=show_progressbar,
--> 411             max_time=max_time
        max_time = 300
    412         )
    413 
    414     if trials is None:
    415         if points_to_evaluate is None:

...........................................................................
/home/aquemy/dev/dp_hyperparameters/extension/hyperopt/base.py in fmin(self=<hyperopt.base.Trials object>, fn=<functools.partial object>, space={'algorithm': {'bootstrap': <hyperopt.pyll.base.Apply object>, 'criterion': <hyperopt.pyll.base.Apply object>, 'max_depth': <hyperopt.pyll.base.Apply object>, 'max_features': <hyperopt.pyll.base.Apply object>, 'max_leaf_nodes': <hyperopt.pyll.base.Apply object>, 'min_samples_split': <hyperopt.pyll.base.Apply object>, 'n_estimators': <hyperopt.pyll.base.Apply object>}, 'pipeline': {'features': <hyperopt.pyll.base.Apply object>, 'normalizer': <hyperopt.pyll.base.Apply object>, 'rebalance': <hyperopt.pyll.base.Apply object>}}, algo=<function suggest>, max_evals=9223372036854775807, max_time=300, rstate=<mtrand.RandomState object>, verbose=0, pass_expr_memo_ctrl=None, catch_eval_exceptions=False, return_argmin=True, show_progressbar=False)
    636             verbose=verbose,
    637             allow_trials_fmin=False,  # -- prevent recursion
    638             pass_expr_memo_ctrl=pass_expr_memo_ctrl,
    639             catch_eval_exceptions=catch_eval_exceptions,
    640             return_argmin=return_argmin,
--> 641             show_progressbar=show_progressbar)
        show_progressbar = False
    642 
    643 
    644 def trials_from_docs(docs, validate=True, **kwargs):
    645     """Construct a Trials base class instance from a list of trials documents

...........................................................................
/home/aquemy/dev/dp_hyperparameters/extension/hyperopt/fmin.py in fmin(fn=<functools.partial object>, space={'algorithm': {'bootstrap': <hyperopt.pyll.base.Apply object>, 'criterion': <hyperopt.pyll.base.Apply object>, 'max_depth': <hyperopt.pyll.base.Apply object>, 'max_features': <hyperopt.pyll.base.Apply object>, 'max_leaf_nodes': <hyperopt.pyll.base.Apply object>, 'min_samples_split': <hyperopt.pyll.base.Apply object>, 'n_estimators': <hyperopt.pyll.base.Apply object>}, 'pipeline': {'features': <hyperopt.pyll.base.Apply object>, 'normalizer': <hyperopt.pyll.base.Apply object>, 'rebalance': <hyperopt.pyll.base.Apply object>}}, algo=<function suggest>, max_evals=9223372036854775807, max_time=300, trials=<hyperopt.base.Trials object>, rstate=<mtrand.RandomState object>, allow_trials_fmin=False, pass_expr_memo_ctrl=None, catch_eval_exceptions=False, verbose=0, return_argmin=True, points_to_evaluate=None, max_queue_len=1, show_progressbar=False)
    426                     verbose=verbose,
    427                     max_queue_len=max_queue_len,
    428                     show_progressbar=show_progressbar,
    429                     max_time=max_time)
    430     rval.catch_eval_exceptions = catch_eval_exceptions
--> 431     rval.exhaust()
        rval.exhaust = <bound method FMinIter.exhaust of <hyperopt.fmin.FMinIter object>>
    432     if return_argmin:
    433         return trials.argmin
    434     elif len(trials) > 0:
    435         # Only if there are some succesfull trail runs, return the best point in the evaluation space

...........................................................................
/home/aquemy/dev/dp_hyperparameters/extension/hyperopt/fmin.py in exhaust(self=<hyperopt.fmin.FMinIter object>)
    273             raise StopIteration()
    274         return self.trials
    275 
    276     def exhaust(self):
    277         n_done = len(self.trials)
--> 278         self.run(self.max_evals - n_done, block_until_done=self.asynchronous)
        self.run = <bound method FMinIter.run of <hyperopt.fmin.FMinIter object>>
        self.max_evals = 9223372036854775807
        n_done = 0
        self.asynchronous = False
    279         self.trials.refresh()
    280         return self
    281 
    282 

...........................................................................
/home/aquemy/dev/dp_hyperparameters/extension/hyperopt/fmin.py in run(self=<hyperopt.fmin.FMinIter object>, N=9223372036854775807, block_until_done=False)
    232                     if self.asynchronous:
    233                         # -- wait for workers to fill in the trials
    234                         time.sleep(self.poll_interval_secs)
    235                     else:
    236                         # -- loop over trials and do the jobs directly
--> 237                         self.serial_evaluate()
        self.serial_evaluate = <bound method FMinIter.serial_evaluate of <hyperopt.fmin.FMinIter object>>
    238                     try:
    239                         res = [d['result']['loss'] for d in
    240                                          self.trials.trials if
    241                                          d['result']['status'] == 'ok']

...........................................................................
/home/aquemy/dev/dp_hyperparameters/extension/hyperopt/fmin.py in serial_evaluate(self=<hyperopt.fmin.FMinIter object>, N=-1)
    138                 trial['book_time'] = now
    139                 trial['refresh_time'] = now
    140                 spec = base.spec_from_misc(trial['misc'])
    141                 ctrl = base.Ctrl(self.trials, current_trial=trial)
    142                 try:
--> 143                     result = self.domain.evaluate(spec, ctrl)
        result = undefined
        self.domain.evaluate = <bound method Domain.evaluate of <hyperopt.base.Domain object>>
        spec = {'bootstrap': 0, 'criterion': 0, 'features': 3, 'features_FeatureUnion_features__pca__n_components': 0, 'features_FeatureUnion_features__selectkbest__k': 0, 'max_depth': 3, 'max_features': 2, 'max_leaf_nodes': 1, 'min_samples_split': 0, 'n_estimators': 0, ...}
        ctrl = <hyperopt.base.Ctrl object>
    144                 except Exception as e:
    145                     logger.info('job exception: %s' % str(e))
    146                     trial['state'] = base.JOB_STATE_ERROR
    147                     trial['misc']['error'] = (str(type(e)), str(e))

...........................................................................
/home/aquemy/dev/dp_hyperparameters/extension/hyperopt/base.py in evaluate(self=<hyperopt.base.Domain object>, config={'bootstrap': 0, 'criterion': 0, 'features': 3, 'features_FeatureUnion_features__pca__n_components': 0, 'features_FeatureUnion_features__selectkbest__k': 0, 'max_depth': 3, 'max_features': 2, 'max_leaf_nodes': 1, 'min_samples_split': 0, 'n_estimators': 0, ...}, ctrl=<hyperopt.base.Ctrl object>, attach_attachments=True)
    841             #    or the normal Python part (self.fn)
    842             pyll_rval = pyll.rec_eval(
    843                 self.expr,
    844                 memo=memo,
    845                 print_node_on_error=self.rec_eval_print_node_on_error)
--> 846             rval = self.fn(pyll_rval)
        rval = undefined
        self.fn = <functools.partial object>
        pyll_rval = {'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': 4, 'max_features': 3, 'max_leaf_nodes': 3, 'min_samples_split': 2, 'n_estimators': 10}, 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 1, 'features__selectkbest__k': 1}), 'normalizer': ('normalizer_PowerTransformer', {}), 'rebalance': ('rebalance_CondensedNearestNeighbour', {'rebalance__n_neighbors': 2})}}
    847 
    848         if isinstance(rval, (float, int, np.number)):
    849             dict_rval = {'loss': float(rval), 'status': STATUS_OK}
    850         else:

...........................................................................
/home/aquemy/dev/dp_hyperparameters/extension/experiment/objective.py in objective_joint(wconfig={'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': 4, 'max_features': 3, 'max_leaf_nodes': 3, 'min_samples_split': 2, 'n_estimators': 10}, 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 1, 'features__selectkbest__k': 1}), 'normalizer': ('normalizer_PowerTransformer', {}), 'rebalance': ('rebalance_CondensedNearestNeighbour', {'rebalance__n_neighbors': 2})}}, algorithm='RandomForest', X=array([[5.1, 3.5, 1.4, 0.2],
       [4.9, 3. , 1....2, 3.4, 5.4, 2.3],
       [5.9, 3. , 5.1, 1.8]]), y=array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,... 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]), context={'baseline_score': 0.9466666666666667, 'baseline_score_std': 0.04988876515698587, 'best_config': {'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': 4, 'max_features': 3, 'max_leaf_nodes': 3, 'min_samples_split': 3, 'n_estimators': 10}, 'config_hash': {'algorithm': 'ffb7ff225ce3d3712c96cf87fe42202988ee2eb0', 'config': 'bae32f426be9cd6243523c023944a8c148fe4aeb', 'pipeline': 'd2a68bfda6fcdec4ae0ffc7d7b6a2122bc1cd673'}, 'duration': 0.7115809917449951, 'iteration': 113, 'loss': 0.033333333333333215, 'max_history_score': 0.9666666666666668, 'max_history_score_std': 0.033333333333333326, 'max_history_step': 'joint', 'pipeline': {'features': ('features_NoneType', {}), 'normalizer': ('normalizer_PowerTransformer', {}), 'rebalance': ('rebalance_CondensedNearestNeighbour', {'rebalance__n_neighbors': 2})}, 'score': 0.9666666666666668, ...}, 'history': [{'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': 2, 'max_features': None, 'max_leaf_nodes': 5, 'min_samples_split': 2, 'n_estimators': 75}, 'config_hash': {'algorithm': '3af5b0cce71c8fe2545246ca24ff5bc3dd516e06', 'config': 'db6ac7e6d348155757e4794bb5f88fe2b4f63d50', 'pipeline': '8d59f4b94cef6be9306ed86a22a9570fa670d567'}, 'duration': 1.149928092956543, 'iteration': 0, 'loss': 0.046666666666666634, 'max_history_score': 0.9533333333333334, 'max_history_score_std': 0.059999999999999984, 'max_history_step': 'joint', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 4, 'features__selectkbest__k': 3}), 'normalizer': ('normalizer_StandardScaler', {'normalizer__with_mean': True, 'normalizer__with_std': True}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 6})}, 'score': 0.9533333333333334, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': 1, 'max_features': 2, 'max_leaf_nodes': 2, 'min_samples_split': 5, 'n_estimators': 100}, 'config_hash': {'algorithm': 'e13eb05fd9a62d2f63bbb1c1deff0cd620d5e6ab', 'config': '4db6fb84d85f52659f780e682ffac5712c3d8a94', 'pipeline': '64c9a1ca9d53ae67244bdd942f4db36a3c05218c'}, 'duration': 1.7678282260894775, 'iteration': 1, 'loss': 0.18000000000000005, 'max_history_score': 0.9533333333333334, 'max_history_score_std': 0.059999999999999984, 'max_history_step': 'joint', 'pipeline': {'features': ('features_NoneType', {}), 'normalizer': ('normalizer_PowerTransformer', {}), 'rebalance': ('rebalance_NearMiss', {'rebalance__n_neighbors': 1})}, 'score': 0.82, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': 1, 'max_features': None, 'max_leaf_nodes': None, 'min_samples_split': 5, 'n_estimators': 75}, 'config_hash': {'algorithm': '94b0d7a654c508cc63643f78fe4f0f07e6f07c1e', 'config': '4403c5a85e951938d3c454e961d3a412780722f6', 'pipeline': '3e47444880d8367fbac2faaba2e52a917274aa58'}, 'duration': 0.8397619724273682, 'iteration': 2, 'loss': 0.03333333333333344, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_PCA', {'features__n_components': 3}), 'normalizer': ('normalizer_MinMaxScaler', {}), 'rebalance': ('rebalance_NoneType', {})}, 'score': 0.9666666666666666, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': None, 'max_features': None, 'max_leaf_nodes': 3, 'min_samples_split': 3, 'n_estimators': 75}, 'config_hash': {'algorithm': 'e8332f0a8902bda03bf70e7978cc5d52affb29d3', 'config': 'a064e2df18ab98d44dabcefbc7bed94913f1d0be', 'pipeline': '7eea819c2a8c103c4b1e9e9c1e224aebba95081f'}, 'duration': 0.8501448631286621, 'iteration': 3, 'loss': 0.053333333333333344, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 2, 'features__selectkbest__k': 4}), 'normalizer': ('normalizer_NoneType', {}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 7})}, 'score': 0.9466666666666667, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'entropy', 'max_depth': 3, 'max_features': 3, 'max_leaf_nodes': None, 'min_samples_split': 5, 'n_estimators': 75}, 'config_hash': {'algorithm': '7a4491035bc6bd737fe9a8cda8a79a02d02d5c74', 'config': '0ddb6f5cab3db4dddd7682966a57205f3e329ad4', 'pipeline': 'a9ae03fe38334f6868cbf84cdd3d629d4bbe3fb0'}, 'duration': 1.1026010513305664, 'iteration': 4, 'loss': 0.05999999999999994, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 2, 'features__selectkbest__k': 1}), 'normalizer': ('normalizer_NoneType', {}), 'rebalance': ('rebalance_NoneType', {})}, 'score': 0.9400000000000001, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'gini', 'max_depth': 3, 'max_features': 1, 'max_leaf_nodes': 5, 'min_samples_split': 2, 'n_estimators': 25}, 'config_hash': {'algorithm': '9826d20b2d6a0f559cf7f16450ce7526f07e8434', 'config': '49f25751bca61cdd461a8cbd2923689b642f98ed', 'pipeline': '19b249664c5bf067de1fed4334a296f947ce774a'}, 'duration': 0.35647010803222656, 'iteration': 5, 'loss': 0.046666666666666634, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_NoneType', {}), 'normalizer': ('normalizer_NoneType', {}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 6})}, 'score': 0.9533333333333334, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'gini', 'max_depth': 2, 'max_features': 1, 'max_leaf_nodes': 2, 'min_samples_split': 2, 'n_estimators': 50}, 'config_hash': {'algorithm': '0a4f6fbb07e0f32c6f675489a0fc82eee05bd8e1', 'config': '5c3a2b6f5e63fb45f10e41e0318b354912ec44f6', 'pipeline': 'dc3b9f176f090005e38b142f11d80e93a7dc5d5e'}, 'duration': 0.7213859558105469, 'iteration': 6, 'loss': 0.31333333333333324, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 1, 'features__selectkbest__k': 4}), 'normalizer': ('normalizer_PowerTransformer', {}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 7})}, 'score': 0.6866666666666668, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'entropy', 'max_depth': 4, 'max_features': 3, 'max_leaf_nodes': 5, 'min_samples_split': 5, 'n_estimators': 10}, 'config_hash': {'algorithm': 'b8112b97ecfc10f00a195af661dcc861cac21289', 'config': 'd3b129b397350f1b6572651c67c01de49b4b174c', 'pipeline': '5b0357ed7072c37b3d6f458bb5d49ff7d825f603'}, 'duration': 0.8299109935760498, 'iteration': 7, 'loss': 1.0, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_PCA', {'features__n_components': 2}), 'normalizer': ('normalizer_StandardScaler', {'normalizer__with_mean': True, 'normalizer__with_std': False}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 6})}, 'score': 0.0, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'gini', 'max_depth': 4, 'max_features': None, 'max_leaf_nodes': 2, 'min_samples_split': 5, 'n_estimators': 100}, 'config_hash': {'algorithm': '40ca24df19b8d164d9d098a6bed1ce056fbbb961', 'config': '813bde1108cc3c4b9bfb3a22cbb421bda7eac671', 'pipeline': '74a7b8705a1c22f7dea5e44e4ebda8f1e48add71'}, 'duration': 2.2111589908599854, 'iteration': 8, 'loss': 0.33333333333333326, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_PCA', {'features__n_components': 2}), 'normalizer': ('normalizer_StandardScaler', {'normalizer__with_mean': False, 'normalizer__with_std': True}), 'rebalance': ('rebalance_NearMiss', {'rebalance__n_neighbors': 2})}, 'score': 0.6666666666666667, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'entropy', 'max_depth': 2, 'max_features': 1, 'max_leaf_nodes': 5, 'min_samples_split': 2, 'n_estimators': 100}, 'config_hash': {'algorithm': '331418a5c12cf1453876eef85e9d98fc8e54fa11', 'config': '31930b6860ed406d59bf7e59ba1925d94704bd3b', 'pipeline': '054bef356f90ec6f644ef3ffc688766744db51c2'}, 'duration': 1.0501940250396729, 'iteration': 9, 'loss': 0.053333333333333344, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_SelectKBest', {'features__k': 1}), 'normalizer': ('normalizer_RobustScaler', {'normalizer__quantile_range': (...), 'normalizer__with_centering': True, 'normalizer__with_scaling': True}), 'rebalance': ('rebalance_NearMiss', {'rebalance__n_neighbors': 2})}, 'score': 0.9466666666666667, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'entropy', 'max_depth': 3, 'max_features': None, 'max_leaf_nodes': 3, 'min_samples_split': 2, 'n_estimators': 100}, 'config_hash': {'algorithm': 'dbc1b8126649fe93dce5fbb37e4015b0acfb179e', 'config': '9913cd550615a9d0946ab4a755a8b9f619e442fd', 'pipeline': 'dd626121cea079ebb32e184ca65483ec7a6d7f59'}, 'duration': 1.120617151260376, 'iteration': 10, 'loss': 0.046666666666666634, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 2, 'features__selectkbest__k': 1}), 'normalizer': ('normalizer_MinMaxScaler', {}), 'rebalance': ('rebalance_NoneType', {})}, 'score': 0.9533333333333334, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'gini', 'max_depth': 3, 'max_features': 3, 'max_leaf_nodes': None, 'min_samples_split': 3, 'n_estimators': 75}, 'config_hash': {'algorithm': '34917a130df5a975f78bd7ec1a0c7b1ffdc787a9', 'config': '95fc8cadc088141290b7de9c388977e4685f0108', 'pipeline': '550d10faf2f08db48516cc3501558816d6a99bc0'}, 'duration': 1.4287099838256836, 'iteration': 11, 'loss': 0.19333333333333313, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 3, 'features__selectkbest__k': 4}), 'normalizer': ('normalizer_StandardScaler', {'normalizer__with_mean': False, 'normalizer__with_std': False}), 'rebalance': ('rebalance_CondensedNearestNeighbour', {'rebalance__n_neighbors': 1})}, 'score': 0.8066666666666669, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'entropy', 'max_depth': 1, 'max_features': 2, 'max_leaf_nodes': 5, 'min_samples_split': 2, 'n_estimators': 75}, 'config_hash': {'algorithm': '33f9abb4aee44a395a9f3b3ffa9ce80a8cdaed7c', 'config': '40fa726f0360cf6af55f9b5902d399d02f61f157', 'pipeline': 'cfd1d20841fe2153da762c95e79f95a3fb1e426a'}, 'duration': 1.2978079319000244, 'iteration': 12, 'loss': 0.053333333333333344, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_PCA', {'features__n_components': 4}), 'normalizer': ('normalizer_MinMaxScaler', {}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 7})}, 'score': 0.9466666666666667, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'entropy', 'max_depth': 4, 'max_features': 2, 'max_leaf_nodes': 5, 'min_samples_split': 3, 'n_estimators': 25}, 'config_hash': {'algorithm': '210111ec6562d09eb093e98ed69ef1c662e11a50', 'config': '0fb8e77c7bd9a58b72f1b33c21a59a09a8c676ba', 'pipeline': '5d269d759e0c7926a685a14b263ace8ae0071e4b'}, 'duration': 0.36649012565612793, 'iteration': 13, 'loss': 0.040000000000000036, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 2, 'features__selectkbest__k': 2}), 'normalizer': ('normalizer_NoneType', {}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 7})}, 'score': 0.96, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'entropy', 'max_depth': 3, 'max_features': 1, 'max_leaf_nodes': 5, 'min_samples_split': 2, 'n_estimators': 25}, 'config_hash': {'algorithm': '0e989a03980101fabf79eda3326ed2870e11d690', 'config': 'f4bffd5d8c67a9c5321a9943c4a99678f59a02b7', 'pipeline': '865ee1e3fe8334c3d5ecb2038d5a5d1b3ba50e75'}, 'duration': 0.35639500617980957, 'iteration': 14, 'loss': 0.046666666666666634, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_NoneType', {}), 'normalizer': ('normalizer_RobustScaler', {'normalizer__quantile_range': (...), 'normalizer__with_centering': True, 'normalizer__with_scaling': False}), 'rebalance': ('rebalance_NoneType', {})}, 'score': 0.9533333333333334, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'entropy', 'max_depth': None, 'max_features': 3, 'max_leaf_nodes': 3, 'min_samples_split': 5, 'n_estimators': 10}, 'config_hash': {'algorithm': '9c592e876c13de5e23e6de5b868e01755d63e72e', 'config': '1e6a68cd1eeac886d90724d78b1cb5fb76a3cde4', 'pipeline': '5a1ca4d82f21b7de0d2c918630a42510673fa36e'}, 'duration': 0.18141412734985352, 'iteration': 15, 'loss': 0.046666666666666634, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_SelectKBest', {'features__k': 3}), 'normalizer': ('normalizer_RobustScaler', {'normalizer__quantile_range': (...), 'normalizer__with_centering': True, 'normalizer__with_scaling': True}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 6})}, 'score': 0.9533333333333334, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': 1, 'max_features': None, 'max_leaf_nodes': None, 'min_samples_split': 5, 'n_estimators': 10}, 'config_hash': {'algorithm': '8bed77aef289bfd453b2858bd288ae5ba7160f2b', 'config': '781185bcb8999045de8d489f253a1a1ba4247932', 'pipeline': '1ece7eabedc2be9e5b0a1be65c570d08ffa3eb54'}, 'duration': 0.1636829376220703, 'iteration': 16, 'loss': 0.053333333333333344, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_NoneType', {}), 'normalizer': ('normalizer_NoneType', {}), 'rebalance': ('rebalance_NearMiss', {'rebalance__n_neighbors': 1})}, 'score': 0.9466666666666667, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'gini', 'max_depth': 3, 'max_features': 2, 'max_leaf_nodes': 2, 'min_samples_split': 5, 'n_estimators': 75}, 'config_hash': {'algorithm': '617b97d9ba21d3373bc51ffa9cccf9c6f91a77b3', 'config': '99fb425b4e8c5d80228cab94202252aa25cdf77c', 'pipeline': 'd6242929c3b515c7719e60423023ac604311afc3'}, 'duration': 0.8468999862670898, 'iteration': 17, 'loss': 0.24, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_PCA', {'features__n_components': 4}), 'normalizer': ('normalizer_PowerTransformer', {}), 'rebalance': ('rebalance_NearMiss', {'rebalance__n_neighbors': 2})}, 'score': 0.76, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': 1, 'max_features': 1, 'max_leaf_nodes': 2, 'min_samples_split': 5, 'n_estimators': 50}, 'config_hash': {'algorithm': 'b92d2697cdd4979da443369d6596229ec091626a', 'config': 'c513a3e13281206ad76187dd817b1fff93d54fe1', 'pipeline': 'c4b4f914a3ca8df967cade997a90366d85a371b9'}, 'duration': 0.6724588871002197, 'iteration': 18, 'loss': 0.23333333333333328, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 1, 'features__selectkbest__k': 3}), 'normalizer': ('normalizer_StandardScaler', {'normalizer__with_mean': True, 'normalizer__with_std': True}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 5})}, 'score': 0.7666666666666667, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'entropy', 'max_depth': None, 'max_features': None, 'max_leaf_nodes': 5, 'min_samples_split': 5, 'n_estimators': 10}, 'config_hash': {'algorithm': 'a0115de695e6cca2e81cbfb54df79bf4b43608b1', 'config': 'ba194015e20b5d67770e8c67342c3d8d0d01dc41', 'pipeline': '8d45fabfeb85ffdcabf7076bd0e65fffe97ce928'}, 'duration': 0.19424200057983398, 'iteration': 19, 'loss': 0.08666666666666667, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_PCA', {'features__n_components': 3}), 'normalizer': ('normalizer_NoneType', {}), 'rebalance': ('rebalance_NoneType', {})}, 'score': 0.9133333333333333, ...}, ...], 'history_hash': ['db6ac7e6d348155757e4794bb5f88fe2b4f63d50', '4db6fb84d85f52659f780e682ffac5712c3d8a94', '4403c5a85e951938d3c454e961d3a412780722f6', 'a064e2df18ab98d44dabcefbc7bed94913f1d0be', '0ddb6f5cab3db4dddd7682966a57205f3e329ad4', '49f25751bca61cdd461a8cbd2923689b642f98ed', '5c3a2b6f5e63fb45f10e41e0318b354912ec44f6', 'd3b129b397350f1b6572651c67c01de49b4b174c', '813bde1108cc3c4b9bfb3a22cbb421bda7eac671', '31930b6860ed406d59bf7e59ba1925d94704bd3b', '9913cd550615a9d0946ab4a755a8b9f619e442fd', '95fc8cadc088141290b7de9c388977e4685f0108', '40fa726f0360cf6af55f9b5902d399d02f61f157', '0fb8e77c7bd9a58b72f1b33c21a59a09a8c676ba', 'f4bffd5d8c67a9c5321a9943c4a99678f59a02b7', '1e6a68cd1eeac886d90724d78b1cb5fb76a3cde4', '781185bcb8999045de8d489f253a1a1ba4247932', '99fb425b4e8c5d80228cab94202252aa25cdf77c', 'c513a3e13281206ad76187dd817b1fff93d54fe1', 'ba194015e20b5d67770e8c67342c3d8d0d01dc41', ...], 'history_index': {'013329309d510b94f19d930320402d65f953a847': 39, '038a0f515e2ec894ee8e34f9caa2889eb3ebd5ce': 66, '052ae4bf232b316187b078abae42c2be19e16a00': 111, '0659afebf316aafeb75612fb07081a04c28545ed': 74, '06e7cde9f3556cd01332ce389ad1d8925cd4b4a4': 120, '0b6551ecfd6f83a15704a9db68f1599c99c6d3ef': 58, '0ddb6f5cab3db4dddd7682966a57205f3e329ad4': 4, '0fb8e77c7bd9a58b72f1b33c21a59a09a8c676ba': 13, '111e2fd99e871044225b8638df965b2a16868e35': 110, '111ffc790caf02104464bfa2f448cba7c56c71dc': 46, ...}, 'iteration': 141, 'max_history_score': 0.9666666666666668, 'max_history_score_std': 0.033333333333333326, 'max_history_step': 'joint'}, config={'algorithm': 'RandomForest', 'seed': 42, 'time': 300})
    108 
    109 def objective_algo(algo_config, current_pipeline_config, algorithm, X, y, context, config):
    110     return objective(current_pipeline_config, algo_config, algorithm, X, y, context, config, step='algorithm')
    111 
    112 def objective_joint(wconfig, algorithm, X, y, context, config):
--> 113     return objective(wconfig['pipeline'], wconfig['algorithm'], algorithm, X, y, context, config, step='joint')
        wconfig = {'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': 4, 'max_features': 3, 'max_leaf_nodes': 3, 'min_samples_split': 2, 'n_estimators': 10}, 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 1, 'features__selectkbest__k': 1}), 'normalizer': ('normalizer_PowerTransformer', {}), 'rebalance': ('rebalance_CondensedNearestNeighbour', {'rebalance__n_neighbors': 2})}}
        algorithm = 'RandomForest'
        X = array([[5.1, 3.5, 1.4, 0.2],
       [4.9, 3. , 1....2, 3.4, 5.4, 2.3],
       [5.9, 3. , 5.1, 1.8]])
        y = array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,... 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2])
        context = {'baseline_score': 0.9466666666666667, 'baseline_score_std': 0.04988876515698587, 'best_config': {'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': 4, 'max_features': 3, 'max_leaf_nodes': 3, 'min_samples_split': 3, 'n_estimators': 10}, 'config_hash': {'algorithm': 'ffb7ff225ce3d3712c96cf87fe42202988ee2eb0', 'config': 'bae32f426be9cd6243523c023944a8c148fe4aeb', 'pipeline': 'd2a68bfda6fcdec4ae0ffc7d7b6a2122bc1cd673'}, 'duration': 0.7115809917449951, 'iteration': 113, 'loss': 0.033333333333333215, 'max_history_score': 0.9666666666666668, 'max_history_score_std': 0.033333333333333326, 'max_history_step': 'joint', 'pipeline': {'features': ('features_NoneType', {}), 'normalizer': ('normalizer_PowerTransformer', {}), 'rebalance': ('rebalance_CondensedNearestNeighbour', {'rebalance__n_neighbors': 2})}, 'score': 0.9666666666666668, ...}, 'history': [{'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': 2, 'max_features': None, 'max_leaf_nodes': 5, 'min_samples_split': 2, 'n_estimators': 75}, 'config_hash': {'algorithm': '3af5b0cce71c8fe2545246ca24ff5bc3dd516e06', 'config': 'db6ac7e6d348155757e4794bb5f88fe2b4f63d50', 'pipeline': '8d59f4b94cef6be9306ed86a22a9570fa670d567'}, 'duration': 1.149928092956543, 'iteration': 0, 'loss': 0.046666666666666634, 'max_history_score': 0.9533333333333334, 'max_history_score_std': 0.059999999999999984, 'max_history_step': 'joint', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 4, 'features__selectkbest__k': 3}), 'normalizer': ('normalizer_StandardScaler', {'normalizer__with_mean': True, 'normalizer__with_std': True}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 6})}, 'score': 0.9533333333333334, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': 1, 'max_features': 2, 'max_leaf_nodes': 2, 'min_samples_split': 5, 'n_estimators': 100}, 'config_hash': {'algorithm': 'e13eb05fd9a62d2f63bbb1c1deff0cd620d5e6ab', 'config': '4db6fb84d85f52659f780e682ffac5712c3d8a94', 'pipeline': '64c9a1ca9d53ae67244bdd942f4db36a3c05218c'}, 'duration': 1.7678282260894775, 'iteration': 1, 'loss': 0.18000000000000005, 'max_history_score': 0.9533333333333334, 'max_history_score_std': 0.059999999999999984, 'max_history_step': 'joint', 'pipeline': {'features': ('features_NoneType', {}), 'normalizer': ('normalizer_PowerTransformer', {}), 'rebalance': ('rebalance_NearMiss', {'rebalance__n_neighbors': 1})}, 'score': 0.82, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': 1, 'max_features': None, 'max_leaf_nodes': None, 'min_samples_split': 5, 'n_estimators': 75}, 'config_hash': {'algorithm': '94b0d7a654c508cc63643f78fe4f0f07e6f07c1e', 'config': '4403c5a85e951938d3c454e961d3a412780722f6', 'pipeline': '3e47444880d8367fbac2faaba2e52a917274aa58'}, 'duration': 0.8397619724273682, 'iteration': 2, 'loss': 0.03333333333333344, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_PCA', {'features__n_components': 3}), 'normalizer': ('normalizer_MinMaxScaler', {}), 'rebalance': ('rebalance_NoneType', {})}, 'score': 0.9666666666666666, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': None, 'max_features': None, 'max_leaf_nodes': 3, 'min_samples_split': 3, 'n_estimators': 75}, 'config_hash': {'algorithm': 'e8332f0a8902bda03bf70e7978cc5d52affb29d3', 'config': 'a064e2df18ab98d44dabcefbc7bed94913f1d0be', 'pipeline': '7eea819c2a8c103c4b1e9e9c1e224aebba95081f'}, 'duration': 0.8501448631286621, 'iteration': 3, 'loss': 0.053333333333333344, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 2, 'features__selectkbest__k': 4}), 'normalizer': ('normalizer_NoneType', {}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 7})}, 'score': 0.9466666666666667, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'entropy', 'max_depth': 3, 'max_features': 3, 'max_leaf_nodes': None, 'min_samples_split': 5, 'n_estimators': 75}, 'config_hash': {'algorithm': '7a4491035bc6bd737fe9a8cda8a79a02d02d5c74', 'config': '0ddb6f5cab3db4dddd7682966a57205f3e329ad4', 'pipeline': 'a9ae03fe38334f6868cbf84cdd3d629d4bbe3fb0'}, 'duration': 1.1026010513305664, 'iteration': 4, 'loss': 0.05999999999999994, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 2, 'features__selectkbest__k': 1}), 'normalizer': ('normalizer_NoneType', {}), 'rebalance': ('rebalance_NoneType', {})}, 'score': 0.9400000000000001, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'gini', 'max_depth': 3, 'max_features': 1, 'max_leaf_nodes': 5, 'min_samples_split': 2, 'n_estimators': 25}, 'config_hash': {'algorithm': '9826d20b2d6a0f559cf7f16450ce7526f07e8434', 'config': '49f25751bca61cdd461a8cbd2923689b642f98ed', 'pipeline': '19b249664c5bf067de1fed4334a296f947ce774a'}, 'duration': 0.35647010803222656, 'iteration': 5, 'loss': 0.046666666666666634, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_NoneType', {}), 'normalizer': ('normalizer_NoneType', {}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 6})}, 'score': 0.9533333333333334, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'gini', 'max_depth': 2, 'max_features': 1, 'max_leaf_nodes': 2, 'min_samples_split': 2, 'n_estimators': 50}, 'config_hash': {'algorithm': '0a4f6fbb07e0f32c6f675489a0fc82eee05bd8e1', 'config': '5c3a2b6f5e63fb45f10e41e0318b354912ec44f6', 'pipeline': 'dc3b9f176f090005e38b142f11d80e93a7dc5d5e'}, 'duration': 0.7213859558105469, 'iteration': 6, 'loss': 0.31333333333333324, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 1, 'features__selectkbest__k': 4}), 'normalizer': ('normalizer_PowerTransformer', {}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 7})}, 'score': 0.6866666666666668, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'entropy', 'max_depth': 4, 'max_features': 3, 'max_leaf_nodes': 5, 'min_samples_split': 5, 'n_estimators': 10}, 'config_hash': {'algorithm': 'b8112b97ecfc10f00a195af661dcc861cac21289', 'config': 'd3b129b397350f1b6572651c67c01de49b4b174c', 'pipeline': '5b0357ed7072c37b3d6f458bb5d49ff7d825f603'}, 'duration': 0.8299109935760498, 'iteration': 7, 'loss': 1.0, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_PCA', {'features__n_components': 2}), 'normalizer': ('normalizer_StandardScaler', {'normalizer__with_mean': True, 'normalizer__with_std': False}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 6})}, 'score': 0.0, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'gini', 'max_depth': 4, 'max_features': None, 'max_leaf_nodes': 2, 'min_samples_split': 5, 'n_estimators': 100}, 'config_hash': {'algorithm': '40ca24df19b8d164d9d098a6bed1ce056fbbb961', 'config': '813bde1108cc3c4b9bfb3a22cbb421bda7eac671', 'pipeline': '74a7b8705a1c22f7dea5e44e4ebda8f1e48add71'}, 'duration': 2.2111589908599854, 'iteration': 8, 'loss': 0.33333333333333326, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_PCA', {'features__n_components': 2}), 'normalizer': ('normalizer_StandardScaler', {'normalizer__with_mean': False, 'normalizer__with_std': True}), 'rebalance': ('rebalance_NearMiss', {'rebalance__n_neighbors': 2})}, 'score': 0.6666666666666667, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'entropy', 'max_depth': 2, 'max_features': 1, 'max_leaf_nodes': 5, 'min_samples_split': 2, 'n_estimators': 100}, 'config_hash': {'algorithm': '331418a5c12cf1453876eef85e9d98fc8e54fa11', 'config': '31930b6860ed406d59bf7e59ba1925d94704bd3b', 'pipeline': '054bef356f90ec6f644ef3ffc688766744db51c2'}, 'duration': 1.0501940250396729, 'iteration': 9, 'loss': 0.053333333333333344, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_SelectKBest', {'features__k': 1}), 'normalizer': ('normalizer_RobustScaler', {'normalizer__quantile_range': (...), 'normalizer__with_centering': True, 'normalizer__with_scaling': True}), 'rebalance': ('rebalance_NearMiss', {'rebalance__n_neighbors': 2})}, 'score': 0.9466666666666667, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'entropy', 'max_depth': 3, 'max_features': None, 'max_leaf_nodes': 3, 'min_samples_split': 2, 'n_estimators': 100}, 'config_hash': {'algorithm': 'dbc1b8126649fe93dce5fbb37e4015b0acfb179e', 'config': '9913cd550615a9d0946ab4a755a8b9f619e442fd', 'pipeline': 'dd626121cea079ebb32e184ca65483ec7a6d7f59'}, 'duration': 1.120617151260376, 'iteration': 10, 'loss': 0.046666666666666634, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 2, 'features__selectkbest__k': 1}), 'normalizer': ('normalizer_MinMaxScaler', {}), 'rebalance': ('rebalance_NoneType', {})}, 'score': 0.9533333333333334, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'gini', 'max_depth': 3, 'max_features': 3, 'max_leaf_nodes': None, 'min_samples_split': 3, 'n_estimators': 75}, 'config_hash': {'algorithm': '34917a130df5a975f78bd7ec1a0c7b1ffdc787a9', 'config': '95fc8cadc088141290b7de9c388977e4685f0108', 'pipeline': '550d10faf2f08db48516cc3501558816d6a99bc0'}, 'duration': 1.4287099838256836, 'iteration': 11, 'loss': 0.19333333333333313, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 3, 'features__selectkbest__k': 4}), 'normalizer': ('normalizer_StandardScaler', {'normalizer__with_mean': False, 'normalizer__with_std': False}), 'rebalance': ('rebalance_CondensedNearestNeighbour', {'rebalance__n_neighbors': 1})}, 'score': 0.8066666666666669, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'entropy', 'max_depth': 1, 'max_features': 2, 'max_leaf_nodes': 5, 'min_samples_split': 2, 'n_estimators': 75}, 'config_hash': {'algorithm': '33f9abb4aee44a395a9f3b3ffa9ce80a8cdaed7c', 'config': '40fa726f0360cf6af55f9b5902d399d02f61f157', 'pipeline': 'cfd1d20841fe2153da762c95e79f95a3fb1e426a'}, 'duration': 1.2978079319000244, 'iteration': 12, 'loss': 0.053333333333333344, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_PCA', {'features__n_components': 4}), 'normalizer': ('normalizer_MinMaxScaler', {}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 7})}, 'score': 0.9466666666666667, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'entropy', 'max_depth': 4, 'max_features': 2, 'max_leaf_nodes': 5, 'min_samples_split': 3, 'n_estimators': 25}, 'config_hash': {'algorithm': '210111ec6562d09eb093e98ed69ef1c662e11a50', 'config': '0fb8e77c7bd9a58b72f1b33c21a59a09a8c676ba', 'pipeline': '5d269d759e0c7926a685a14b263ace8ae0071e4b'}, 'duration': 0.36649012565612793, 'iteration': 13, 'loss': 0.040000000000000036, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 2, 'features__selectkbest__k': 2}), 'normalizer': ('normalizer_NoneType', {}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 7})}, 'score': 0.96, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'entropy', 'max_depth': 3, 'max_features': 1, 'max_leaf_nodes': 5, 'min_samples_split': 2, 'n_estimators': 25}, 'config_hash': {'algorithm': '0e989a03980101fabf79eda3326ed2870e11d690', 'config': 'f4bffd5d8c67a9c5321a9943c4a99678f59a02b7', 'pipeline': '865ee1e3fe8334c3d5ecb2038d5a5d1b3ba50e75'}, 'duration': 0.35639500617980957, 'iteration': 14, 'loss': 0.046666666666666634, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_NoneType', {}), 'normalizer': ('normalizer_RobustScaler', {'normalizer__quantile_range': (...), 'normalizer__with_centering': True, 'normalizer__with_scaling': False}), 'rebalance': ('rebalance_NoneType', {})}, 'score': 0.9533333333333334, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'entropy', 'max_depth': None, 'max_features': 3, 'max_leaf_nodes': 3, 'min_samples_split': 5, 'n_estimators': 10}, 'config_hash': {'algorithm': '9c592e876c13de5e23e6de5b868e01755d63e72e', 'config': '1e6a68cd1eeac886d90724d78b1cb5fb76a3cde4', 'pipeline': '5a1ca4d82f21b7de0d2c918630a42510673fa36e'}, 'duration': 0.18141412734985352, 'iteration': 15, 'loss': 0.046666666666666634, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_SelectKBest', {'features__k': 3}), 'normalizer': ('normalizer_RobustScaler', {'normalizer__quantile_range': (...), 'normalizer__with_centering': True, 'normalizer__with_scaling': True}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 6})}, 'score': 0.9533333333333334, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': 1, 'max_features': None, 'max_leaf_nodes': None, 'min_samples_split': 5, 'n_estimators': 10}, 'config_hash': {'algorithm': '8bed77aef289bfd453b2858bd288ae5ba7160f2b', 'config': '781185bcb8999045de8d489f253a1a1ba4247932', 'pipeline': '1ece7eabedc2be9e5b0a1be65c570d08ffa3eb54'}, 'duration': 0.1636829376220703, 'iteration': 16, 'loss': 0.053333333333333344, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_NoneType', {}), 'normalizer': ('normalizer_NoneType', {}), 'rebalance': ('rebalance_NearMiss', {'rebalance__n_neighbors': 1})}, 'score': 0.9466666666666667, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'gini', 'max_depth': 3, 'max_features': 2, 'max_leaf_nodes': 2, 'min_samples_split': 5, 'n_estimators': 75}, 'config_hash': {'algorithm': '617b97d9ba21d3373bc51ffa9cccf9c6f91a77b3', 'config': '99fb425b4e8c5d80228cab94202252aa25cdf77c', 'pipeline': 'd6242929c3b515c7719e60423023ac604311afc3'}, 'duration': 0.8468999862670898, 'iteration': 17, 'loss': 0.24, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_PCA', {'features__n_components': 4}), 'normalizer': ('normalizer_PowerTransformer', {}), 'rebalance': ('rebalance_NearMiss', {'rebalance__n_neighbors': 2})}, 'score': 0.76, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': 1, 'max_features': 1, 'max_leaf_nodes': 2, 'min_samples_split': 5, 'n_estimators': 50}, 'config_hash': {'algorithm': 'b92d2697cdd4979da443369d6596229ec091626a', 'config': 'c513a3e13281206ad76187dd817b1fff93d54fe1', 'pipeline': 'c4b4f914a3ca8df967cade997a90366d85a371b9'}, 'duration': 0.6724588871002197, 'iteration': 18, 'loss': 0.23333333333333328, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 1, 'features__selectkbest__k': 3}), 'normalizer': ('normalizer_StandardScaler', {'normalizer__with_mean': True, 'normalizer__with_std': True}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 5})}, 'score': 0.7666666666666667, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'entropy', 'max_depth': None, 'max_features': None, 'max_leaf_nodes': 5, 'min_samples_split': 5, 'n_estimators': 10}, 'config_hash': {'algorithm': 'a0115de695e6cca2e81cbfb54df79bf4b43608b1', 'config': 'ba194015e20b5d67770e8c67342c3d8d0d01dc41', 'pipeline': '8d45fabfeb85ffdcabf7076bd0e65fffe97ce928'}, 'duration': 0.19424200057983398, 'iteration': 19, 'loss': 0.08666666666666667, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_PCA', {'features__n_components': 3}), 'normalizer': ('normalizer_NoneType', {}), 'rebalance': ('rebalance_NoneType', {})}, 'score': 0.9133333333333333, ...}, ...], 'history_hash': ['db6ac7e6d348155757e4794bb5f88fe2b4f63d50', '4db6fb84d85f52659f780e682ffac5712c3d8a94', '4403c5a85e951938d3c454e961d3a412780722f6', 'a064e2df18ab98d44dabcefbc7bed94913f1d0be', '0ddb6f5cab3db4dddd7682966a57205f3e329ad4', '49f25751bca61cdd461a8cbd2923689b642f98ed', '5c3a2b6f5e63fb45f10e41e0318b354912ec44f6', 'd3b129b397350f1b6572651c67c01de49b4b174c', '813bde1108cc3c4b9bfb3a22cbb421bda7eac671', '31930b6860ed406d59bf7e59ba1925d94704bd3b', '9913cd550615a9d0946ab4a755a8b9f619e442fd', '95fc8cadc088141290b7de9c388977e4685f0108', '40fa726f0360cf6af55f9b5902d399d02f61f157', '0fb8e77c7bd9a58b72f1b33c21a59a09a8c676ba', 'f4bffd5d8c67a9c5321a9943c4a99678f59a02b7', '1e6a68cd1eeac886d90724d78b1cb5fb76a3cde4', '781185bcb8999045de8d489f253a1a1ba4247932', '99fb425b4e8c5d80228cab94202252aa25cdf77c', 'c513a3e13281206ad76187dd817b1fff93d54fe1', 'ba194015e20b5d67770e8c67342c3d8d0d01dc41', ...], 'history_index': {'013329309d510b94f19d930320402d65f953a847': 39, '038a0f515e2ec894ee8e34f9caa2889eb3ebd5ce': 66, '052ae4bf232b316187b078abae42c2be19e16a00': 111, '0659afebf316aafeb75612fb07081a04c28545ed': 74, '06e7cde9f3556cd01332ce389ad1d8925cd4b4a4': 120, '0b6551ecfd6f83a15704a9db68f1599c99c6d3ef': 58, '0ddb6f5cab3db4dddd7682966a57205f3e329ad4': 4, '0fb8e77c7bd9a58b72f1b33c21a59a09a8c676ba': 13, '111e2fd99e871044225b8638df965b2a16868e35': 110, '111ffc790caf02104464bfa2f448cba7c56c71dc': 46, ...}, 'iteration': 141, 'max_history_score': 0.9666666666666668, 'max_history_score_std': 0.033333333333333326, 'max_history_step': 'joint'}
        config = {'algorithm': 'RandomForest', 'seed': 42, 'time': 300}
    114 
    115 
    116 def get_baseline_score(algorithm, X, y, seed):
    117     pipeline, _ = pipeline_conf_to_full_pipeline(

...........................................................................
/home/aquemy/dev/dp_hyperparameters/extension/experiment/objective.py in objective(pipeline_config={'features': ('features_FeatureUnion', {'features__pca__n_components': 1, 'features__selectkbest__k': 1}), 'normalizer': ('normalizer_PowerTransformer', {}), 'rebalance': ('rebalance_CondensedNearestNeighbour', {'rebalance__n_neighbors': 2})}, algo_config={'bootstrap': True, 'criterion': 'gini', 'max_depth': 4, 'max_features': 3, 'max_leaf_nodes': 3, 'min_samples_split': 2, 'n_estimators': 10}, algorithm='RandomForest', X=array([[5.1, 3.5, 1.4, 0.2],
       [4.9, 3. , 1....2, 3.4, 5.4, 2.3],
       [5.9, 3. , 5.1, 1.8]]), y=array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,... 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]), context={'baseline_score': 0.9466666666666667, 'baseline_score_std': 0.04988876515698587, 'best_config': {'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': 4, 'max_features': 3, 'max_leaf_nodes': 3, 'min_samples_split': 3, 'n_estimators': 10}, 'config_hash': {'algorithm': 'ffb7ff225ce3d3712c96cf87fe42202988ee2eb0', 'config': 'bae32f426be9cd6243523c023944a8c148fe4aeb', 'pipeline': 'd2a68bfda6fcdec4ae0ffc7d7b6a2122bc1cd673'}, 'duration': 0.7115809917449951, 'iteration': 113, 'loss': 0.033333333333333215, 'max_history_score': 0.9666666666666668, 'max_history_score_std': 0.033333333333333326, 'max_history_step': 'joint', 'pipeline': {'features': ('features_NoneType', {}), 'normalizer': ('normalizer_PowerTransformer', {}), 'rebalance': ('rebalance_CondensedNearestNeighbour', {'rebalance__n_neighbors': 2})}, 'score': 0.9666666666666668, ...}, 'history': [{'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': 2, 'max_features': None, 'max_leaf_nodes': 5, 'min_samples_split': 2, 'n_estimators': 75}, 'config_hash': {'algorithm': '3af5b0cce71c8fe2545246ca24ff5bc3dd516e06', 'config': 'db6ac7e6d348155757e4794bb5f88fe2b4f63d50', 'pipeline': '8d59f4b94cef6be9306ed86a22a9570fa670d567'}, 'duration': 1.149928092956543, 'iteration': 0, 'loss': 0.046666666666666634, 'max_history_score': 0.9533333333333334, 'max_history_score_std': 0.059999999999999984, 'max_history_step': 'joint', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 4, 'features__selectkbest__k': 3}), 'normalizer': ('normalizer_StandardScaler', {'normalizer__with_mean': True, 'normalizer__with_std': True}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 6})}, 'score': 0.9533333333333334, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': 1, 'max_features': 2, 'max_leaf_nodes': 2, 'min_samples_split': 5, 'n_estimators': 100}, 'config_hash': {'algorithm': 'e13eb05fd9a62d2f63bbb1c1deff0cd620d5e6ab', 'config': '4db6fb84d85f52659f780e682ffac5712c3d8a94', 'pipeline': '64c9a1ca9d53ae67244bdd942f4db36a3c05218c'}, 'duration': 1.7678282260894775, 'iteration': 1, 'loss': 0.18000000000000005, 'max_history_score': 0.9533333333333334, 'max_history_score_std': 0.059999999999999984, 'max_history_step': 'joint', 'pipeline': {'features': ('features_NoneType', {}), 'normalizer': ('normalizer_PowerTransformer', {}), 'rebalance': ('rebalance_NearMiss', {'rebalance__n_neighbors': 1})}, 'score': 0.82, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': 1, 'max_features': None, 'max_leaf_nodes': None, 'min_samples_split': 5, 'n_estimators': 75}, 'config_hash': {'algorithm': '94b0d7a654c508cc63643f78fe4f0f07e6f07c1e', 'config': '4403c5a85e951938d3c454e961d3a412780722f6', 'pipeline': '3e47444880d8367fbac2faaba2e52a917274aa58'}, 'duration': 0.8397619724273682, 'iteration': 2, 'loss': 0.03333333333333344, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_PCA', {'features__n_components': 3}), 'normalizer': ('normalizer_MinMaxScaler', {}), 'rebalance': ('rebalance_NoneType', {})}, 'score': 0.9666666666666666, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': None, 'max_features': None, 'max_leaf_nodes': 3, 'min_samples_split': 3, 'n_estimators': 75}, 'config_hash': {'algorithm': 'e8332f0a8902bda03bf70e7978cc5d52affb29d3', 'config': 'a064e2df18ab98d44dabcefbc7bed94913f1d0be', 'pipeline': '7eea819c2a8c103c4b1e9e9c1e224aebba95081f'}, 'duration': 0.8501448631286621, 'iteration': 3, 'loss': 0.053333333333333344, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 2, 'features__selectkbest__k': 4}), 'normalizer': ('normalizer_NoneType', {}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 7})}, 'score': 0.9466666666666667, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'entropy', 'max_depth': 3, 'max_features': 3, 'max_leaf_nodes': None, 'min_samples_split': 5, 'n_estimators': 75}, 'config_hash': {'algorithm': '7a4491035bc6bd737fe9a8cda8a79a02d02d5c74', 'config': '0ddb6f5cab3db4dddd7682966a57205f3e329ad4', 'pipeline': 'a9ae03fe38334f6868cbf84cdd3d629d4bbe3fb0'}, 'duration': 1.1026010513305664, 'iteration': 4, 'loss': 0.05999999999999994, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 2, 'features__selectkbest__k': 1}), 'normalizer': ('normalizer_NoneType', {}), 'rebalance': ('rebalance_NoneType', {})}, 'score': 0.9400000000000001, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'gini', 'max_depth': 3, 'max_features': 1, 'max_leaf_nodes': 5, 'min_samples_split': 2, 'n_estimators': 25}, 'config_hash': {'algorithm': '9826d20b2d6a0f559cf7f16450ce7526f07e8434', 'config': '49f25751bca61cdd461a8cbd2923689b642f98ed', 'pipeline': '19b249664c5bf067de1fed4334a296f947ce774a'}, 'duration': 0.35647010803222656, 'iteration': 5, 'loss': 0.046666666666666634, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_NoneType', {}), 'normalizer': ('normalizer_NoneType', {}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 6})}, 'score': 0.9533333333333334, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'gini', 'max_depth': 2, 'max_features': 1, 'max_leaf_nodes': 2, 'min_samples_split': 2, 'n_estimators': 50}, 'config_hash': {'algorithm': '0a4f6fbb07e0f32c6f675489a0fc82eee05bd8e1', 'config': '5c3a2b6f5e63fb45f10e41e0318b354912ec44f6', 'pipeline': 'dc3b9f176f090005e38b142f11d80e93a7dc5d5e'}, 'duration': 0.7213859558105469, 'iteration': 6, 'loss': 0.31333333333333324, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 1, 'features__selectkbest__k': 4}), 'normalizer': ('normalizer_PowerTransformer', {}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 7})}, 'score': 0.6866666666666668, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'entropy', 'max_depth': 4, 'max_features': 3, 'max_leaf_nodes': 5, 'min_samples_split': 5, 'n_estimators': 10}, 'config_hash': {'algorithm': 'b8112b97ecfc10f00a195af661dcc861cac21289', 'config': 'd3b129b397350f1b6572651c67c01de49b4b174c', 'pipeline': '5b0357ed7072c37b3d6f458bb5d49ff7d825f603'}, 'duration': 0.8299109935760498, 'iteration': 7, 'loss': 1.0, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_PCA', {'features__n_components': 2}), 'normalizer': ('normalizer_StandardScaler', {'normalizer__with_mean': True, 'normalizer__with_std': False}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 6})}, 'score': 0.0, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'gini', 'max_depth': 4, 'max_features': None, 'max_leaf_nodes': 2, 'min_samples_split': 5, 'n_estimators': 100}, 'config_hash': {'algorithm': '40ca24df19b8d164d9d098a6bed1ce056fbbb961', 'config': '813bde1108cc3c4b9bfb3a22cbb421bda7eac671', 'pipeline': '74a7b8705a1c22f7dea5e44e4ebda8f1e48add71'}, 'duration': 2.2111589908599854, 'iteration': 8, 'loss': 0.33333333333333326, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_PCA', {'features__n_components': 2}), 'normalizer': ('normalizer_StandardScaler', {'normalizer__with_mean': False, 'normalizer__with_std': True}), 'rebalance': ('rebalance_NearMiss', {'rebalance__n_neighbors': 2})}, 'score': 0.6666666666666667, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'entropy', 'max_depth': 2, 'max_features': 1, 'max_leaf_nodes': 5, 'min_samples_split': 2, 'n_estimators': 100}, 'config_hash': {'algorithm': '331418a5c12cf1453876eef85e9d98fc8e54fa11', 'config': '31930b6860ed406d59bf7e59ba1925d94704bd3b', 'pipeline': '054bef356f90ec6f644ef3ffc688766744db51c2'}, 'duration': 1.0501940250396729, 'iteration': 9, 'loss': 0.053333333333333344, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_SelectKBest', {'features__k': 1}), 'normalizer': ('normalizer_RobustScaler', {'normalizer__quantile_range': (...), 'normalizer__with_centering': True, 'normalizer__with_scaling': True}), 'rebalance': ('rebalance_NearMiss', {'rebalance__n_neighbors': 2})}, 'score': 0.9466666666666667, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'entropy', 'max_depth': 3, 'max_features': None, 'max_leaf_nodes': 3, 'min_samples_split': 2, 'n_estimators': 100}, 'config_hash': {'algorithm': 'dbc1b8126649fe93dce5fbb37e4015b0acfb179e', 'config': '9913cd550615a9d0946ab4a755a8b9f619e442fd', 'pipeline': 'dd626121cea079ebb32e184ca65483ec7a6d7f59'}, 'duration': 1.120617151260376, 'iteration': 10, 'loss': 0.046666666666666634, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 2, 'features__selectkbest__k': 1}), 'normalizer': ('normalizer_MinMaxScaler', {}), 'rebalance': ('rebalance_NoneType', {})}, 'score': 0.9533333333333334, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'gini', 'max_depth': 3, 'max_features': 3, 'max_leaf_nodes': None, 'min_samples_split': 3, 'n_estimators': 75}, 'config_hash': {'algorithm': '34917a130df5a975f78bd7ec1a0c7b1ffdc787a9', 'config': '95fc8cadc088141290b7de9c388977e4685f0108', 'pipeline': '550d10faf2f08db48516cc3501558816d6a99bc0'}, 'duration': 1.4287099838256836, 'iteration': 11, 'loss': 0.19333333333333313, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 3, 'features__selectkbest__k': 4}), 'normalizer': ('normalizer_StandardScaler', {'normalizer__with_mean': False, 'normalizer__with_std': False}), 'rebalance': ('rebalance_CondensedNearestNeighbour', {'rebalance__n_neighbors': 1})}, 'score': 0.8066666666666669, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'entropy', 'max_depth': 1, 'max_features': 2, 'max_leaf_nodes': 5, 'min_samples_split': 2, 'n_estimators': 75}, 'config_hash': {'algorithm': '33f9abb4aee44a395a9f3b3ffa9ce80a8cdaed7c', 'config': '40fa726f0360cf6af55f9b5902d399d02f61f157', 'pipeline': 'cfd1d20841fe2153da762c95e79f95a3fb1e426a'}, 'duration': 1.2978079319000244, 'iteration': 12, 'loss': 0.053333333333333344, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_PCA', {'features__n_components': 4}), 'normalizer': ('normalizer_MinMaxScaler', {}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 7})}, 'score': 0.9466666666666667, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'entropy', 'max_depth': 4, 'max_features': 2, 'max_leaf_nodes': 5, 'min_samples_split': 3, 'n_estimators': 25}, 'config_hash': {'algorithm': '210111ec6562d09eb093e98ed69ef1c662e11a50', 'config': '0fb8e77c7bd9a58b72f1b33c21a59a09a8c676ba', 'pipeline': '5d269d759e0c7926a685a14b263ace8ae0071e4b'}, 'duration': 0.36649012565612793, 'iteration': 13, 'loss': 0.040000000000000036, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 2, 'features__selectkbest__k': 2}), 'normalizer': ('normalizer_NoneType', {}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 7})}, 'score': 0.96, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'entropy', 'max_depth': 3, 'max_features': 1, 'max_leaf_nodes': 5, 'min_samples_split': 2, 'n_estimators': 25}, 'config_hash': {'algorithm': '0e989a03980101fabf79eda3326ed2870e11d690', 'config': 'f4bffd5d8c67a9c5321a9943c4a99678f59a02b7', 'pipeline': '865ee1e3fe8334c3d5ecb2038d5a5d1b3ba50e75'}, 'duration': 0.35639500617980957, 'iteration': 14, 'loss': 0.046666666666666634, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_NoneType', {}), 'normalizer': ('normalizer_RobustScaler', {'normalizer__quantile_range': (...), 'normalizer__with_centering': True, 'normalizer__with_scaling': False}), 'rebalance': ('rebalance_NoneType', {})}, 'score': 0.9533333333333334, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'entropy', 'max_depth': None, 'max_features': 3, 'max_leaf_nodes': 3, 'min_samples_split': 5, 'n_estimators': 10}, 'config_hash': {'algorithm': '9c592e876c13de5e23e6de5b868e01755d63e72e', 'config': '1e6a68cd1eeac886d90724d78b1cb5fb76a3cde4', 'pipeline': '5a1ca4d82f21b7de0d2c918630a42510673fa36e'}, 'duration': 0.18141412734985352, 'iteration': 15, 'loss': 0.046666666666666634, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_SelectKBest', {'features__k': 3}), 'normalizer': ('normalizer_RobustScaler', {'normalizer__quantile_range': (...), 'normalizer__with_centering': True, 'normalizer__with_scaling': True}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 6})}, 'score': 0.9533333333333334, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': 1, 'max_features': None, 'max_leaf_nodes': None, 'min_samples_split': 5, 'n_estimators': 10}, 'config_hash': {'algorithm': '8bed77aef289bfd453b2858bd288ae5ba7160f2b', 'config': '781185bcb8999045de8d489f253a1a1ba4247932', 'pipeline': '1ece7eabedc2be9e5b0a1be65c570d08ffa3eb54'}, 'duration': 0.1636829376220703, 'iteration': 16, 'loss': 0.053333333333333344, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_NoneType', {}), 'normalizer': ('normalizer_NoneType', {}), 'rebalance': ('rebalance_NearMiss', {'rebalance__n_neighbors': 1})}, 'score': 0.9466666666666667, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'gini', 'max_depth': 3, 'max_features': 2, 'max_leaf_nodes': 2, 'min_samples_split': 5, 'n_estimators': 75}, 'config_hash': {'algorithm': '617b97d9ba21d3373bc51ffa9cccf9c6f91a77b3', 'config': '99fb425b4e8c5d80228cab94202252aa25cdf77c', 'pipeline': 'd6242929c3b515c7719e60423023ac604311afc3'}, 'duration': 0.8468999862670898, 'iteration': 17, 'loss': 0.24, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_PCA', {'features__n_components': 4}), 'normalizer': ('normalizer_PowerTransformer', {}), 'rebalance': ('rebalance_NearMiss', {'rebalance__n_neighbors': 2})}, 'score': 0.76, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': 1, 'max_features': 1, 'max_leaf_nodes': 2, 'min_samples_split': 5, 'n_estimators': 50}, 'config_hash': {'algorithm': 'b92d2697cdd4979da443369d6596229ec091626a', 'config': 'c513a3e13281206ad76187dd817b1fff93d54fe1', 'pipeline': 'c4b4f914a3ca8df967cade997a90366d85a371b9'}, 'duration': 0.6724588871002197, 'iteration': 18, 'loss': 0.23333333333333328, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 1, 'features__selectkbest__k': 3}), 'normalizer': ('normalizer_StandardScaler', {'normalizer__with_mean': True, 'normalizer__with_std': True}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 5})}, 'score': 0.7666666666666667, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'entropy', 'max_depth': None, 'max_features': None, 'max_leaf_nodes': 5, 'min_samples_split': 5, 'n_estimators': 10}, 'config_hash': {'algorithm': 'a0115de695e6cca2e81cbfb54df79bf4b43608b1', 'config': 'ba194015e20b5d67770e8c67342c3d8d0d01dc41', 'pipeline': '8d45fabfeb85ffdcabf7076bd0e65fffe97ce928'}, 'duration': 0.19424200057983398, 'iteration': 19, 'loss': 0.08666666666666667, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_PCA', {'features__n_components': 3}), 'normalizer': ('normalizer_NoneType', {}), 'rebalance': ('rebalance_NoneType', {})}, 'score': 0.9133333333333333, ...}, ...], 'history_hash': ['db6ac7e6d348155757e4794bb5f88fe2b4f63d50', '4db6fb84d85f52659f780e682ffac5712c3d8a94', '4403c5a85e951938d3c454e961d3a412780722f6', 'a064e2df18ab98d44dabcefbc7bed94913f1d0be', '0ddb6f5cab3db4dddd7682966a57205f3e329ad4', '49f25751bca61cdd461a8cbd2923689b642f98ed', '5c3a2b6f5e63fb45f10e41e0318b354912ec44f6', 'd3b129b397350f1b6572651c67c01de49b4b174c', '813bde1108cc3c4b9bfb3a22cbb421bda7eac671', '31930b6860ed406d59bf7e59ba1925d94704bd3b', '9913cd550615a9d0946ab4a755a8b9f619e442fd', '95fc8cadc088141290b7de9c388977e4685f0108', '40fa726f0360cf6af55f9b5902d399d02f61f157', '0fb8e77c7bd9a58b72f1b33c21a59a09a8c676ba', 'f4bffd5d8c67a9c5321a9943c4a99678f59a02b7', '1e6a68cd1eeac886d90724d78b1cb5fb76a3cde4', '781185bcb8999045de8d489f253a1a1ba4247932', '99fb425b4e8c5d80228cab94202252aa25cdf77c', 'c513a3e13281206ad76187dd817b1fff93d54fe1', 'ba194015e20b5d67770e8c67342c3d8d0d01dc41', ...], 'history_index': {'013329309d510b94f19d930320402d65f953a847': 39, '038a0f515e2ec894ee8e34f9caa2889eb3ebd5ce': 66, '052ae4bf232b316187b078abae42c2be19e16a00': 111, '0659afebf316aafeb75612fb07081a04c28545ed': 74, '06e7cde9f3556cd01332ce389ad1d8925cd4b4a4': 120, '0b6551ecfd6f83a15704a9db68f1599c99c6d3ef': 58, '0ddb6f5cab3db4dddd7682966a57205f3e329ad4': 4, '0fb8e77c7bd9a58b72f1b33c21a59a09a8c676ba': 13, '111e2fd99e871044225b8638df965b2a16868e35': 110, '111ffc790caf02104464bfa2f448cba7c56c71dc': 46, ...}, 'iteration': 141, 'max_history_score': 0.9666666666666668, 'max_history_score_std': 0.033333333333333326, 'max_history_step': 'joint'}, config={'algorithm': 'RandomForest', 'seed': 42, 'time': 300}, step='joint')
     45                 y,
     46                 cv=10,
     47                 n_jobs=-1,
     48                 return_estimator=False,
     49                 return_train_score=False,
---> 50                 verbose=0)
     51         score = np.mean(scores['test_score'])
     52         std = np.std(scores['test_score'])
     53         status = STATUS_OK
     54     except Exception as e:

...........................................................................
/home/aquemy/.local/lib/python2.7/site-packages/sklearn/model_selection/_validation.py in cross_validate(estimator=Pipeline(memory=None,
     steps=[('rebalance', ... random_state=42, verbose=0, warm_start=False))]), X=array([[5.1, 3.5, 1.4, 0.2],
       [4.9, 3. , 1....2, 3.4, 5.4, 2.3],
       [5.9, 3. , 5.1, 1.8]]), y=array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,... 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]), groups=None, scoring=None, cv=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1, verbose=0, fit_params=None, pre_dispatch='2*n_jobs', return_train_score=False, return_estimator=False, error_score='raise-deprecating')
    235         delayed(_fit_and_score)(
    236             clone(estimator), X, y, scorers, train, test, verbose, None,
    237             fit_params, return_train_score=return_train_score,
    238             return_times=True, return_estimator=return_estimator,
    239             error_score=error_score)
--> 240         for train, test in cv.split(X, y, groups))
        cv.split = <bound method StratifiedKFold.split of Stratifie...d(n_splits=10, random_state=None, shuffle=False)>
        X = array([[5.1, 3.5, 1.4, 0.2],
       [4.9, 3. , 1....2, 3.4, 5.4, 2.3],
       [5.9, 3. , 5.1, 1.8]])
        y = array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,... 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2])
        groups = None
    241 
    242     zipped_scores = list(zip(*scores))
    243     if return_train_score:
    244         train_scores = zipped_scores.pop(0)

...........................................................................
/home/aquemy/.local/lib/python2.7/site-packages/sklearn/externals/joblib/parallel.py in __call__(self=Parallel(n_jobs=-1), iterable=<generator object <genexpr>>)
    925                 # No need to wait for async callbacks to trigger to
    926                 # consumption.
    927                 self._iterating = False
    928 
    929             with self._backend.retrieval_context():
--> 930                 self.retrieve()
        self.retrieve = <bound method Parallel.retrieve of Parallel(n_jobs=-1)>
    931             # Make sure that we get a last message telling us we are done
    932             elapsed_time = time.time() - self._start_time
    933             self._print('Done %3i out of %3i | elapsed: %s finished',
    934                         (len(self._output), len(self._output),

---------------------------------------------------------------------------
Joblib worker traceback:
---------------------------------------------------------------------------
ValueError                                         Mon Jun 17 13:12:34 2019
PID: 21088                                  Python 2.7.15+: /usr/bin/python
...........................................................................
/home/aquemy/.local/lib/python2.7/site-packages/sklearn/externals/joblib/parallel.py in __call__(self=<sklearn.externals.joblib.parallel.BatchedCalls object>)
    220     def __call__(self):
    221         # Set the default nested backend to self._backend but do not set the
    222         # change the default number of processes to -1
    223         with parallel_backend(self._backend, n_jobs=self._n_jobs):
    224             return [func(*args, **kwargs)
--> 225                     for func, args, kwargs in self.items]
        func = <function _fit_and_score>
        args = (Pipeline(memory=None,
     steps=[('rebalance', ... random_state=42, verbose=0, warm_start=False))]), array([[5.1, 3.5, 1.4, 0.2],
       [4.9, 3. , 1....2, 3.4, 5.4, 2.3],
       [5.9, 3. , 5.1, 1.8]]), array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,... 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]), {'score': <function _passthrough_scorer>}, array([  5,   6,   7,   8,   9,  10,  11,  12,  ..., 142, 143, 144,
       145, 146, 147, 148, 149]), array([  0,   1,   2,   3,   4,  50,  51,  52,  53,  54, 100, 101, 102,
       103, 104]), 0, None, None)
        kwargs = {'error_score': 'raise-deprecating', 'return_estimator': False, 'return_times': True, 'return_train_score': False}
        self.items = [(<function _fit_and_score>, (Pipeline(memory=None,
     steps=[('rebalance', ... random_state=42, verbose=0, warm_start=False))]), array([[5.1, 3.5, 1.4, 0.2],
       [4.9, 3. , 1....2, 3.4, 5.4, 2.3],
       [5.9, 3. , 5.1, 1.8]]), array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,... 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]), {'score': <function _passthrough_scorer>}, array([  5,   6,   7,   8,   9,  10,  11,  12,  ..., 142, 143, 144,
       145, 146, 147, 148, 149]), array([  0,   1,   2,   3,   4,  50,  51,  52,  53,  54, 100, 101, 102,
       103, 104]), 0, None, None), {'error_score': 'raise-deprecating', 'return_estimator': False, 'return_times': True, 'return_train_score': False})]
    226 
    227     def __len__(self):
    228         return self._size
    229 

...........................................................................
/home/aquemy/.local/lib/python2.7/site-packages/sklearn/model_selection/_validation.py in _fit_and_score(estimator=Pipeline(memory=None,
     steps=[('rebalance', ... random_state=42, verbose=0, warm_start=False))]), X=array([[5.1, 3.5, 1.4, 0.2],
       [4.9, 3. , 1....2, 3.4, 5.4, 2.3],
       [5.9, 3. , 5.1, 1.8]]), y=array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,... 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]), scorer={'score': <function _passthrough_scorer>}, train=array([  5,   6,   7,   8,   9,  10,  11,  12,  ..., 142, 143, 144,
       145, 146, 147, 148, 149]), test=array([  0,   1,   2,   3,   4,  50,  51,  52,  53,  54, 100, 101, 102,
       103, 104]), verbose=0, parameters=None, fit_params={}, return_train_score=False, return_parameters=False, return_n_test_samples=False, return_times=True, return_estimator=False, error_score='raise-deprecating')
    523 
    524     try:
    525         if y_train is None:
    526             estimator.fit(X_train, **fit_params)
    527         else:
--> 528             estimator.fit(X_train, y_train, **fit_params)
        estimator.fit = <bound method Pipeline.fit of Pipeline(memory=No...random_state=42, verbose=0, warm_start=False))])>
        X_train = array([[5.4, 3.9, 1.7, 0.4],
       [4.6, 3.4, 1....2, 3.4, 5.4, 2.3],
       [5.9, 3. , 5.1, 1.8]])
        y_train = array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,
       2, 2, 2])
        fit_params = {}
    529 
    530     except Exception as e:
    531         # Note fit time as time until error
    532         fit_time = time.time() - start_time

...........................................................................
/usr/local/lib/python2.7/dist-packages/imblearn/pipeline.py in fit(self=Pipeline(memory=None,
     steps=[('rebalance', ... random_state=42, verbose=0, warm_start=False))]), X=array([[5.4, 3.9, 1.7, 0.4],
       [4.6, 3.4, 1....2, 3.4, 5.4, 2.3],
       [5.9, 3. , 5.1, 1.8]]), y=array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,
       2, 2, 2]), **fit_params={})
    234             This estimator
    235 
    236         """
    237         Xt, yt, fit_params = self._fit(X, y, **fit_params)
    238         if self._final_estimator is not None:
--> 239             self._final_estimator.fit(Xt, yt, **fit_params)
        self._final_estimator.fit = <bound method RandomForestClassifier.fit of Rand...e, random_state=42, verbose=0, warm_start=False)>
        Xt = array([[ 0.43803246,  0.71396658],
       [-0.44... 3.82519555],
       [ 2.00537311,  2.667726  ]])
        yt = array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...0, 0, 0, 0, 0, 0,
       0, 1, 1, 1, 1, 2, 2, 2])
        fit_params = {}
    240         return self
    241 
    242     def fit_transform(self, X, y=None, **fit_params):
    243         """Fit the model and transform with the final estimator

...........................................................................
/home/aquemy/.local/lib/python2.7/site-packages/sklearn/ensemble/forest.py in fit(self=RandomForestClassifier(bootstrap=True, class_wei...se, random_state=42, verbose=0, warm_start=False), X=array([[ 0.43803245,  0.7139666 ],
       [-0.44...      [ 2.005373  ,  2.667726  ]], dtype=float32), y=array([[0.],
       [0.],
       [0.],
       [0...    [1.],
       [2.],
       [2.],
       [2.]]), sample_weight=None)
    328             trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,
    329                              **_joblib_parallel_args(prefer='threads'))(
    330                 delayed(_parallel_build_trees)(
    331                     t, self, X, y, sample_weight, i, len(trees),
    332                     verbose=self.verbose, class_weight=self.class_weight)
--> 333                 for i, t in enumerate(trees))
        i = 9
    334 
    335             # Collect newly grown trees
    336             self.estimators_.extend(trees)
    337 

...........................................................................
/home/aquemy/.local/lib/python2.7/site-packages/sklearn/externals/joblib/parallel.py in __call__(self=Parallel(n_jobs=1), iterable=<generator object <genexpr>>)
    912             # self._original_iterator is None, then this means either
    913             # that pre_dispatch == "all", n_jobs == 1 or that the first batch
    914             # was very quick and its callback already dispatched all the
    915             # remaining jobs.
    916             self._iterating = False
--> 917             if self.dispatch_one_batch(iterator):
        self.dispatch_one_batch = <bound method Parallel.dispatch_one_batch of Parallel(n_jobs=1)>
        iterator = <generator object <genexpr>>
    918                 self._iterating = self._original_iterator is not None
    919 
    920             while self.dispatch_one_batch(iterator):
    921                 pass

...........................................................................
/home/aquemy/.local/lib/python2.7/site-packages/sklearn/externals/joblib/parallel.py in dispatch_one_batch(self=Parallel(n_jobs=1), iterator=<generator object <genexpr>>)
    754                                  self._pickle_cache)
    755             if len(tasks) == 0:
    756                 # No more tasks available in the iterator: tell caller to stop.
    757                 return False
    758             else:
--> 759                 self._dispatch(tasks)
        self._dispatch = <bound method Parallel._dispatch of Parallel(n_jobs=1)>
        tasks = <sklearn.externals.joblib.parallel.BatchedCalls object>
    760                 return True
    761 
    762     def _print(self, msg, msg_args):
    763         """Display the message on stout or stderr depending on verbosity"""

...........................................................................
/home/aquemy/.local/lib/python2.7/site-packages/sklearn/externals/joblib/parallel.py in _dispatch(self=Parallel(n_jobs=1), batch=<sklearn.externals.joblib.parallel.BatchedCalls object>)
    711 
    712         dispatch_timestamp = time.time()
    713         cb = BatchCompletionCallBack(dispatch_timestamp, len(batch), self)
    714         with self._lock:
    715             job_idx = len(self._jobs)
--> 716             job = self._backend.apply_async(batch, callback=cb)
        job = undefined
        self._backend.apply_async = <bound method SequentialBackend.apply_async of <...lib._parallel_backends.SequentialBackend object>>
        batch = <sklearn.externals.joblib.parallel.BatchedCalls object>
        cb = <sklearn.externals.joblib.parallel.BatchCompletionCallBack object>
    717             # A job can complete so quickly than its callback is
    718             # called before we get here, causing self._jobs to
    719             # grow. To ensure correct results ordering, .insert is
    720             # used (rather than .append) in the following line

...........................................................................
/home/aquemy/.local/lib/python2.7/site-packages/sklearn/externals/joblib/_parallel_backends.py in apply_async(self=<sklearn.externals.joblib._parallel_backends.SequentialBackend object>, func=<sklearn.externals.joblib.parallel.BatchedCalls object>, callback=<sklearn.externals.joblib.parallel.BatchCompletionCallBack object>)
    177             raise ValueError('n_jobs == 0 in Parallel has no meaning')
    178         return 1
    179 
    180     def apply_async(self, func, callback=None):
    181         """Schedule a func to be run"""
--> 182         result = ImmediateResult(func)
        result = undefined
        func = <sklearn.externals.joblib.parallel.BatchedCalls object>
    183         if callback:
    184             callback(result)
    185         return result
    186 

...........................................................................
/home/aquemy/.local/lib/python2.7/site-packages/sklearn/externals/joblib/_parallel_backends.py in __init__(self=<sklearn.externals.joblib._parallel_backends.ImmediateResult object>, batch=<sklearn.externals.joblib.parallel.BatchedCalls object>)
    544 
    545 class ImmediateResult(object):
    546     def __init__(self, batch):
    547         # Don't delay the application, to avoid keeping the input
    548         # arguments in memory
--> 549         self.results = batch()
        self.results = undefined
        batch = <sklearn.externals.joblib.parallel.BatchedCalls object>
    550 
    551     def get(self):
    552         return self.results
    553 

...........................................................................
/home/aquemy/.local/lib/python2.7/site-packages/sklearn/externals/joblib/parallel.py in __call__(self=<sklearn.externals.joblib.parallel.BatchedCalls object>)
    220     def __call__(self):
    221         # Set the default nested backend to self._backend but do not set the
    222         # change the default number of processes to -1
    223         with parallel_backend(self._backend, n_jobs=self._n_jobs):
    224             return [func(*args, **kwargs)
--> 225                     for func, args, kwargs in self.items]
        func = <function _parallel_build_trees>
        args = (DecisionTreeClassifier(class_weight=None, criter...=False, random_state=1608637542, splitter='best'), RandomForestClassifier(bootstrap=True, class_wei...se, random_state=42, verbose=0, warm_start=False), array([[ 0.43803245,  0.7139666 ],
       [-0.44...      [ 2.005373  ,  2.667726  ]], dtype=float32), array([[0.],
       [0.],
       [0.],
       [0...    [1.],
       [2.],
       [2.],
       [2.]]), None, 0, 10)
        kwargs = {'class_weight': None, 'verbose': 0}
        self.items = [(<function _parallel_build_trees>, (DecisionTreeClassifier(class_weight=None, criter...=False, random_state=1608637542, splitter='best'), RandomForestClassifier(bootstrap=True, class_wei...se, random_state=42, verbose=0, warm_start=False), array([[ 0.43803245,  0.7139666 ],
       [-0.44...      [ 2.005373  ,  2.667726  ]], dtype=float32), array([[0.],
       [0.],
       [0.],
       [0...    [1.],
       [2.],
       [2.],
       [2.]]), None, 0, 10), {'class_weight': None, 'verbose': 0})]
    226 
    227     def __len__(self):
    228         return self._size
    229 

...........................................................................
/home/aquemy/.local/lib/python2.7/site-packages/sklearn/ensemble/forest.py in _parallel_build_trees(tree=DecisionTreeClassifier(class_weight=None, criter...=False, random_state=1608637542, splitter='best'), forest=RandomForestClassifier(bootstrap=True, class_wei...se, random_state=42, verbose=0, warm_start=False), X=array([[ 0.43803245,  0.7139666 ],
       [-0.44...      [ 2.005373  ,  2.667726  ]], dtype=float32), y=array([[0.],
       [0.],
       [0.],
       [0...    [1.],
       [2.],
       [2.],
       [2.]]), sample_weight=None, tree_idx=0, n_trees=10, verbose=0, class_weight=None)
    114                 simplefilter('ignore', DeprecationWarning)
    115                 curr_sample_weight *= compute_sample_weight('auto', y, indices)
    116         elif class_weight == 'balanced_subsample':
    117             curr_sample_weight *= compute_sample_weight('balanced', y, indices)
    118 
--> 119         tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)
        tree.fit = <bound method DecisionTreeClassifier.fit of Deci...False, random_state=1608637542, splitter='best')>
        X = array([[ 0.43803245,  0.7139666 ],
       [-0.44...      [ 2.005373  ,  2.667726  ]], dtype=float32)
        y = array([[0.],
       [0.],
       [0.],
       [0...    [1.],
       [2.],
       [2.],
       [2.]])
        sample_weight = None
        curr_sample_weight = array([2., 0., 2., 1., 2., 0., 1., 2., 1., 1., 2..., 0., 2., 0., 0., 1., 0., 0., 3., 2.,
       1.])
    120     else:
    121         tree.fit(X, y, sample_weight=sample_weight, check_input=False)
    122 
    123     return tree

...........................................................................
/home/aquemy/.local/lib/python2.7/site-packages/sklearn/tree/tree.py in fit(self=DecisionTreeClassifier(class_weight=None, criter...=False, random_state=1608637542, splitter='best'), X=array([[ 0.43803245,  0.7139666 ],
       [-0.44...      [ 2.005373  ,  2.667726  ]], dtype=float32), y=array([[0.],
       [0.],
       [0.],
       [0...    [1.],
       [2.],
       [2.],
       [2.]]), sample_weight=array([2., 0., 2., 1., 2., 0., 1., 2., 1., 1., 2..., 0., 2., 0., 0., 1., 0., 0., 3., 2.,
       1.]), check_input=False, X_idx_sorted=None)
    796 
    797         super(DecisionTreeClassifier, self).fit(
    798             X, y,
    799             sample_weight=sample_weight,
    800             check_input=check_input,
--> 801             X_idx_sorted=X_idx_sorted)
        X_idx_sorted = None
    802         return self
    803 
    804     def predict_proba(self, X, check_input=True):
    805         """Predict class probabilities of the input samples X.

...........................................................................
/home/aquemy/.local/lib/python2.7/site-packages/sklearn/tree/tree.py in fit(self=DecisionTreeClassifier(class_weight=None, criter...=False, random_state=1608637542, splitter='best'), X=array([[ 0.43803245,  0.7139666 ],
       [-0.44...      [ 2.005373  ,  2.667726  ]], dtype=float32), y=array([[0.],
       [0.],
       [0.],
       [0...    [1.],
       [2.],
       [2.],
       [2.]]), sample_weight=array([2., 0., 2., 1., 2., 0., 1., 2., 1., 1., 2..., 0., 2., 0., 0., 1., 0., 0., 3., 2.,
       1.]), check_input=False, X_idx_sorted=None)
    237         if not 0 <= self.min_weight_fraction_leaf <= 0.5:
    238             raise ValueError("min_weight_fraction_leaf must in [0, 0.5]")
    239         if max_depth <= 0:
    240             raise ValueError("max_depth must be greater than zero. ")
    241         if not (0 < max_features <= self.n_features_):
--> 242             raise ValueError("max_features must be in (0, n_features]")
    243         if not isinstance(max_leaf_nodes, (numbers.Integral, np.integer)):
    244             raise ValueError("max_leaf_nodes must be integral number but was "
    245                              "%r" % max_leaf_nodes)
    246         if -1 < max_leaf_nodes < 2:

ValueError: max_features must be in (0, n_features]
___________________________________________________________________________
Best score: 0.966666666667 (0.0333333333333) [J] | Score: 0.0 (0.0) [J]
Best score: 0.966666666667 (0.0333333333333) [J] | Score: 0.666666666667 (1.11022302463e-16) [J]
Best score: 0.966666666667 (0.0333333333333) [J] | Score: 0.693333333333 (0.104136662345) [J]
Best score: 0.966666666667 (0.0333333333333) [J] | Score: 0.92 (0.0777460252646) [J]
Best score: 0.966666666667 (0.0333333333333) [J] | Score: 0.92 (0.0884433277428) [J]
Best score: 0.966666666667 (0.0333333333333) [J] | Score: 0.913333333333 (0.06) [J]
Best score: 0.966666666667 (0.0333333333333) [J] | Score: 0.94 (0.0813770374382) [J]
Best score: 0.966666666667 (0.0333333333333) [J] | Score: 0.613333333333 (0.049888765157) [J]
Best score: 0.966666666667 (0.0333333333333) [J] | Score: 0.946666666667 (0.0581186525805) [J]
Best score: 0.966666666667 (0.0333333333333) [J] | Score: 0.96 (0.0442216638714) [J]
JoblibValueError
___________________________________________________________________________
...........................................................................
/home/aquemy/dev/dp_hyperparameters/extension/main.py in <module>()
     27 
     28     serializer.serialize_results(scenario, policy)
     29 
     30 if __name__ == "__main__":
     31     args = cli.parse_args()
---> 32     main(args)

...........................................................................
/home/aquemy/dev/dp_hyperparameters/extension/main.py in main(args=Namespace(customize=[(['control', 'seed'], '42')...io='./scenarios/rf_iris_joint.yaml', verbosity=0))
     21         test_size=0.4, 
     22         random_state=scenario['control']['seed']
     23     )
     24 
     25     policy = policies.initiate(scenario['setup']['policy'], config)
---> 26     policy.run(X,y)
        policy.run = <bound method Joint.run of <experiment.policies.joint.Joint object>>
        X = array([[5.1, 3.5, 1.4, 0.2],
       [4.9, 3. , 1....2, 3.4, 5.4, 2.3],
       [5.9, 3. , 5.1, 1.8]])
        y = array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,... 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2])
     27 
     28     serializer.serialize_results(scenario, policy)
     29 
     30 if __name__ == "__main__":

...........................................................................
/home/aquemy/dev/dp_hyperparameters/extension/experiment/policies/joint.py in run(self=<experiment.policies.joint.Joint object>, X=array([[5.1, 3.5, 1.4, 0.2],
       [4.9, 3. , 1....2, 3.4, 5.4, 2.3],
       [5.9, 3. , 5.1, 1.8]]), y=array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,... 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]))
     32             algo=tpe.suggest, 
     33             max_evals=None,
     34             max_time=self.config['time'],     
     35             trials=trials,
     36             show_progressbar=False,
---> 37             verbose=0
     38         )
     39 
     40         best_config = self.context['best_config']
     41         super(Joint, self).display_step_results(best_config)

...........................................................................
/home/aquemy/dev/dp_hyperparameters/extension/hyperopt/fmin.py in fmin(fn=<functools.partial object>, space={'algorithm': {'bootstrap': <hyperopt.pyll.base.Apply object>, 'criterion': <hyperopt.pyll.base.Apply object>, 'max_depth': <hyperopt.pyll.base.Apply object>, 'max_features': <hyperopt.pyll.base.Apply object>, 'max_leaf_nodes': <hyperopt.pyll.base.Apply object>, 'min_samples_split': <hyperopt.pyll.base.Apply object>, 'n_estimators': <hyperopt.pyll.base.Apply object>}, 'pipeline': {'features': <hyperopt.pyll.base.Apply object>, 'normalizer': <hyperopt.pyll.base.Apply object>, 'rebalance': <hyperopt.pyll.base.Apply object>}}, algo=<function suggest>, max_evals=9223372036854775807, max_time=300, trials=<hyperopt.base.Trials object>, rstate=<mtrand.RandomState object>, allow_trials_fmin=True, pass_expr_memo_ctrl=None, catch_eval_exceptions=False, verbose=0, return_argmin=True, points_to_evaluate=None, max_queue_len=1, show_progressbar=False)
    406             pass_expr_memo_ctrl=pass_expr_memo_ctrl,
    407             verbose=verbose,
    408             catch_eval_exceptions=catch_eval_exceptions,
    409             return_argmin=return_argmin,
    410             show_progressbar=show_progressbar,
--> 411             max_time=max_time
        max_time = 300
    412         )
    413 
    414     if trials is None:
    415         if points_to_evaluate is None:

...........................................................................
/home/aquemy/dev/dp_hyperparameters/extension/hyperopt/base.py in fmin(self=<hyperopt.base.Trials object>, fn=<functools.partial object>, space={'algorithm': {'bootstrap': <hyperopt.pyll.base.Apply object>, 'criterion': <hyperopt.pyll.base.Apply object>, 'max_depth': <hyperopt.pyll.base.Apply object>, 'max_features': <hyperopt.pyll.base.Apply object>, 'max_leaf_nodes': <hyperopt.pyll.base.Apply object>, 'min_samples_split': <hyperopt.pyll.base.Apply object>, 'n_estimators': <hyperopt.pyll.base.Apply object>}, 'pipeline': {'features': <hyperopt.pyll.base.Apply object>, 'normalizer': <hyperopt.pyll.base.Apply object>, 'rebalance': <hyperopt.pyll.base.Apply object>}}, algo=<function suggest>, max_evals=9223372036854775807, max_time=300, rstate=<mtrand.RandomState object>, verbose=0, pass_expr_memo_ctrl=None, catch_eval_exceptions=False, return_argmin=True, show_progressbar=False)
    636             verbose=verbose,
    637             allow_trials_fmin=False,  # -- prevent recursion
    638             pass_expr_memo_ctrl=pass_expr_memo_ctrl,
    639             catch_eval_exceptions=catch_eval_exceptions,
    640             return_argmin=return_argmin,
--> 641             show_progressbar=show_progressbar)
        show_progressbar = False
    642 
    643 
    644 def trials_from_docs(docs, validate=True, **kwargs):
    645     """Construct a Trials base class instance from a list of trials documents

...........................................................................
/home/aquemy/dev/dp_hyperparameters/extension/hyperopt/fmin.py in fmin(fn=<functools.partial object>, space={'algorithm': {'bootstrap': <hyperopt.pyll.base.Apply object>, 'criterion': <hyperopt.pyll.base.Apply object>, 'max_depth': <hyperopt.pyll.base.Apply object>, 'max_features': <hyperopt.pyll.base.Apply object>, 'max_leaf_nodes': <hyperopt.pyll.base.Apply object>, 'min_samples_split': <hyperopt.pyll.base.Apply object>, 'n_estimators': <hyperopt.pyll.base.Apply object>}, 'pipeline': {'features': <hyperopt.pyll.base.Apply object>, 'normalizer': <hyperopt.pyll.base.Apply object>, 'rebalance': <hyperopt.pyll.base.Apply object>}}, algo=<function suggest>, max_evals=9223372036854775807, max_time=300, trials=<hyperopt.base.Trials object>, rstate=<mtrand.RandomState object>, allow_trials_fmin=False, pass_expr_memo_ctrl=None, catch_eval_exceptions=False, verbose=0, return_argmin=True, points_to_evaluate=None, max_queue_len=1, show_progressbar=False)
    426                     verbose=verbose,
    427                     max_queue_len=max_queue_len,
    428                     show_progressbar=show_progressbar,
    429                     max_time=max_time)
    430     rval.catch_eval_exceptions = catch_eval_exceptions
--> 431     rval.exhaust()
        rval.exhaust = <bound method FMinIter.exhaust of <hyperopt.fmin.FMinIter object>>
    432     if return_argmin:
    433         return trials.argmin
    434     elif len(trials) > 0:
    435         # Only if there are some succesfull trail runs, return the best point in the evaluation space

...........................................................................
/home/aquemy/dev/dp_hyperparameters/extension/hyperopt/fmin.py in exhaust(self=<hyperopt.fmin.FMinIter object>)
    273             raise StopIteration()
    274         return self.trials
    275 
    276     def exhaust(self):
    277         n_done = len(self.trials)
--> 278         self.run(self.max_evals - n_done, block_until_done=self.asynchronous)
        self.run = <bound method FMinIter.run of <hyperopt.fmin.FMinIter object>>
        self.max_evals = 9223372036854775807
        n_done = 0
        self.asynchronous = False
    279         self.trials.refresh()
    280         return self
    281 
    282 

...........................................................................
/home/aquemy/dev/dp_hyperparameters/extension/hyperopt/fmin.py in run(self=<hyperopt.fmin.FMinIter object>, N=9223372036854775807, block_until_done=False)
    232                     if self.asynchronous:
    233                         # -- wait for workers to fill in the trials
    234                         time.sleep(self.poll_interval_secs)
    235                     else:
    236                         # -- loop over trials and do the jobs directly
--> 237                         self.serial_evaluate()
        self.serial_evaluate = <bound method FMinIter.serial_evaluate of <hyperopt.fmin.FMinIter object>>
    238                     try:
    239                         res = [d['result']['loss'] for d in
    240                                          self.trials.trials if
    241                                          d['result']['status'] == 'ok']

...........................................................................
/home/aquemy/dev/dp_hyperparameters/extension/hyperopt/fmin.py in serial_evaluate(self=<hyperopt.fmin.FMinIter object>, N=-1)
    138                 trial['book_time'] = now
    139                 trial['refresh_time'] = now
    140                 spec = base.spec_from_misc(trial['misc'])
    141                 ctrl = base.Ctrl(self.trials, current_trial=trial)
    142                 try:
--> 143                     result = self.domain.evaluate(spec, ctrl)
        result = undefined
        self.domain.evaluate = <bound method Domain.evaluate of <hyperopt.base.Domain object>>
        spec = {'bootstrap': 0, 'criterion': 0, 'features': 2, 'features_SelectKBest_features__k': 0, 'max_depth': 3, 'max_features': 2, 'max_leaf_nodes': 1, 'min_samples_split': 0, 'n_estimators': 0, 'normalizer': 2, ...}
        ctrl = <hyperopt.base.Ctrl object>
    144                 except Exception as e:
    145                     logger.info('job exception: %s' % str(e))
    146                     trial['state'] = base.JOB_STATE_ERROR
    147                     trial['misc']['error'] = (str(type(e)), str(e))

...........................................................................
/home/aquemy/dev/dp_hyperparameters/extension/hyperopt/base.py in evaluate(self=<hyperopt.base.Domain object>, config={'bootstrap': 0, 'criterion': 0, 'features': 2, 'features_SelectKBest_features__k': 0, 'max_depth': 3, 'max_features': 2, 'max_leaf_nodes': 1, 'min_samples_split': 0, 'n_estimators': 0, 'normalizer': 2, ...}, ctrl=<hyperopt.base.Ctrl object>, attach_attachments=True)
    841             #    or the normal Python part (self.fn)
    842             pyll_rval = pyll.rec_eval(
    843                 self.expr,
    844                 memo=memo,
    845                 print_node_on_error=self.rec_eval_print_node_on_error)
--> 846             rval = self.fn(pyll_rval)
        rval = undefined
        self.fn = <functools.partial object>
        pyll_rval = {'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': 4, 'max_features': 3, 'max_leaf_nodes': 3, 'min_samples_split': 2, 'n_estimators': 10}, 'pipeline': {'features': ('features_SelectKBest', {'features__k': 1}), 'normalizer': ('normalizer_PowerTransformer', {}), 'rebalance': ('rebalance_CondensedNearestNeighbour', {'rebalance__n_neighbors': 2})}}
    847 
    848         if isinstance(rval, (float, int, np.number)):
    849             dict_rval = {'loss': float(rval), 'status': STATUS_OK}
    850         else:

...........................................................................
/home/aquemy/dev/dp_hyperparameters/extension/experiment/objective.py in objective_joint(wconfig={'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': 4, 'max_features': 3, 'max_leaf_nodes': 3, 'min_samples_split': 2, 'n_estimators': 10}, 'pipeline': {'features': ('features_SelectKBest', {'features__k': 1}), 'normalizer': ('normalizer_PowerTransformer', {}), 'rebalance': ('rebalance_CondensedNearestNeighbour', {'rebalance__n_neighbors': 2})}}, algorithm='RandomForest', X=array([[5.1, 3.5, 1.4, 0.2],
       [4.9, 3. , 1....2, 3.4, 5.4, 2.3],
       [5.9, 3. , 5.1, 1.8]]), y=array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,... 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]), context={'baseline_score': 0.9466666666666667, 'baseline_score_std': 0.04988876515698587, 'best_config': {'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': 4, 'max_features': 3, 'max_leaf_nodes': 3, 'min_samples_split': 3, 'n_estimators': 10}, 'config_hash': {'algorithm': 'ffb7ff225ce3d3712c96cf87fe42202988ee2eb0', 'config': 'bae32f426be9cd6243523c023944a8c148fe4aeb', 'pipeline': 'd2a68bfda6fcdec4ae0ffc7d7b6a2122bc1cd673'}, 'duration': 0.7115809917449951, 'iteration': 113, 'loss': 0.033333333333333215, 'max_history_score': 0.9666666666666668, 'max_history_score_std': 0.033333333333333326, 'max_history_step': 'joint', 'pipeline': {'features': ('features_NoneType', {}), 'normalizer': ('normalizer_PowerTransformer', {}), 'rebalance': ('rebalance_CondensedNearestNeighbour', {'rebalance__n_neighbors': 2})}, 'score': 0.9666666666666668, ...}, 'history': [{'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': 2, 'max_features': None, 'max_leaf_nodes': 5, 'min_samples_split': 2, 'n_estimators': 75}, 'config_hash': {'algorithm': '3af5b0cce71c8fe2545246ca24ff5bc3dd516e06', 'config': 'db6ac7e6d348155757e4794bb5f88fe2b4f63d50', 'pipeline': '8d59f4b94cef6be9306ed86a22a9570fa670d567'}, 'duration': 1.149928092956543, 'iteration': 0, 'loss': 0.046666666666666634, 'max_history_score': 0.9533333333333334, 'max_history_score_std': 0.059999999999999984, 'max_history_step': 'joint', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 4, 'features__selectkbest__k': 3}), 'normalizer': ('normalizer_StandardScaler', {'normalizer__with_mean': True, 'normalizer__with_std': True}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 6})}, 'score': 0.9533333333333334, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': 1, 'max_features': 2, 'max_leaf_nodes': 2, 'min_samples_split': 5, 'n_estimators': 100}, 'config_hash': {'algorithm': 'e13eb05fd9a62d2f63bbb1c1deff0cd620d5e6ab', 'config': '4db6fb84d85f52659f780e682ffac5712c3d8a94', 'pipeline': '64c9a1ca9d53ae67244bdd942f4db36a3c05218c'}, 'duration': 1.7678282260894775, 'iteration': 1, 'loss': 0.18000000000000005, 'max_history_score': 0.9533333333333334, 'max_history_score_std': 0.059999999999999984, 'max_history_step': 'joint', 'pipeline': {'features': ('features_NoneType', {}), 'normalizer': ('normalizer_PowerTransformer', {}), 'rebalance': ('rebalance_NearMiss', {'rebalance__n_neighbors': 1})}, 'score': 0.82, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': 1, 'max_features': None, 'max_leaf_nodes': None, 'min_samples_split': 5, 'n_estimators': 75}, 'config_hash': {'algorithm': '94b0d7a654c508cc63643f78fe4f0f07e6f07c1e', 'config': '4403c5a85e951938d3c454e961d3a412780722f6', 'pipeline': '3e47444880d8367fbac2faaba2e52a917274aa58'}, 'duration': 0.8397619724273682, 'iteration': 2, 'loss': 0.03333333333333344, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_PCA', {'features__n_components': 3}), 'normalizer': ('normalizer_MinMaxScaler', {}), 'rebalance': ('rebalance_NoneType', {})}, 'score': 0.9666666666666666, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': None, 'max_features': None, 'max_leaf_nodes': 3, 'min_samples_split': 3, 'n_estimators': 75}, 'config_hash': {'algorithm': 'e8332f0a8902bda03bf70e7978cc5d52affb29d3', 'config': 'a064e2df18ab98d44dabcefbc7bed94913f1d0be', 'pipeline': '7eea819c2a8c103c4b1e9e9c1e224aebba95081f'}, 'duration': 0.8501448631286621, 'iteration': 3, 'loss': 0.053333333333333344, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 2, 'features__selectkbest__k': 4}), 'normalizer': ('normalizer_NoneType', {}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 7})}, 'score': 0.9466666666666667, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'entropy', 'max_depth': 3, 'max_features': 3, 'max_leaf_nodes': None, 'min_samples_split': 5, 'n_estimators': 75}, 'config_hash': {'algorithm': '7a4491035bc6bd737fe9a8cda8a79a02d02d5c74', 'config': '0ddb6f5cab3db4dddd7682966a57205f3e329ad4', 'pipeline': 'a9ae03fe38334f6868cbf84cdd3d629d4bbe3fb0'}, 'duration': 1.1026010513305664, 'iteration': 4, 'loss': 0.05999999999999994, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 2, 'features__selectkbest__k': 1}), 'normalizer': ('normalizer_NoneType', {}), 'rebalance': ('rebalance_NoneType', {})}, 'score': 0.9400000000000001, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'gini', 'max_depth': 3, 'max_features': 1, 'max_leaf_nodes': 5, 'min_samples_split': 2, 'n_estimators': 25}, 'config_hash': {'algorithm': '9826d20b2d6a0f559cf7f16450ce7526f07e8434', 'config': '49f25751bca61cdd461a8cbd2923689b642f98ed', 'pipeline': '19b249664c5bf067de1fed4334a296f947ce774a'}, 'duration': 0.35647010803222656, 'iteration': 5, 'loss': 0.046666666666666634, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_NoneType', {}), 'normalizer': ('normalizer_NoneType', {}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 6})}, 'score': 0.9533333333333334, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'gini', 'max_depth': 2, 'max_features': 1, 'max_leaf_nodes': 2, 'min_samples_split': 2, 'n_estimators': 50}, 'config_hash': {'algorithm': '0a4f6fbb07e0f32c6f675489a0fc82eee05bd8e1', 'config': '5c3a2b6f5e63fb45f10e41e0318b354912ec44f6', 'pipeline': 'dc3b9f176f090005e38b142f11d80e93a7dc5d5e'}, 'duration': 0.7213859558105469, 'iteration': 6, 'loss': 0.31333333333333324, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 1, 'features__selectkbest__k': 4}), 'normalizer': ('normalizer_PowerTransformer', {}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 7})}, 'score': 0.6866666666666668, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'entropy', 'max_depth': 4, 'max_features': 3, 'max_leaf_nodes': 5, 'min_samples_split': 5, 'n_estimators': 10}, 'config_hash': {'algorithm': 'b8112b97ecfc10f00a195af661dcc861cac21289', 'config': 'd3b129b397350f1b6572651c67c01de49b4b174c', 'pipeline': '5b0357ed7072c37b3d6f458bb5d49ff7d825f603'}, 'duration': 0.8299109935760498, 'iteration': 7, 'loss': 1.0, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_PCA', {'features__n_components': 2}), 'normalizer': ('normalizer_StandardScaler', {'normalizer__with_mean': True, 'normalizer__with_std': False}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 6})}, 'score': 0.0, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'gini', 'max_depth': 4, 'max_features': None, 'max_leaf_nodes': 2, 'min_samples_split': 5, 'n_estimators': 100}, 'config_hash': {'algorithm': '40ca24df19b8d164d9d098a6bed1ce056fbbb961', 'config': '813bde1108cc3c4b9bfb3a22cbb421bda7eac671', 'pipeline': '74a7b8705a1c22f7dea5e44e4ebda8f1e48add71'}, 'duration': 2.2111589908599854, 'iteration': 8, 'loss': 0.33333333333333326, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_PCA', {'features__n_components': 2}), 'normalizer': ('normalizer_StandardScaler', {'normalizer__with_mean': False, 'normalizer__with_std': True}), 'rebalance': ('rebalance_NearMiss', {'rebalance__n_neighbors': 2})}, 'score': 0.6666666666666667, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'entropy', 'max_depth': 2, 'max_features': 1, 'max_leaf_nodes': 5, 'min_samples_split': 2, 'n_estimators': 100}, 'config_hash': {'algorithm': '331418a5c12cf1453876eef85e9d98fc8e54fa11', 'config': '31930b6860ed406d59bf7e59ba1925d94704bd3b', 'pipeline': '054bef356f90ec6f644ef3ffc688766744db51c2'}, 'duration': 1.0501940250396729, 'iteration': 9, 'loss': 0.053333333333333344, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_SelectKBest', {'features__k': 1}), 'normalizer': ('normalizer_RobustScaler', {'normalizer__quantile_range': (...), 'normalizer__with_centering': True, 'normalizer__with_scaling': True}), 'rebalance': ('rebalance_NearMiss', {'rebalance__n_neighbors': 2})}, 'score': 0.9466666666666667, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'entropy', 'max_depth': 3, 'max_features': None, 'max_leaf_nodes': 3, 'min_samples_split': 2, 'n_estimators': 100}, 'config_hash': {'algorithm': 'dbc1b8126649fe93dce5fbb37e4015b0acfb179e', 'config': '9913cd550615a9d0946ab4a755a8b9f619e442fd', 'pipeline': 'dd626121cea079ebb32e184ca65483ec7a6d7f59'}, 'duration': 1.120617151260376, 'iteration': 10, 'loss': 0.046666666666666634, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 2, 'features__selectkbest__k': 1}), 'normalizer': ('normalizer_MinMaxScaler', {}), 'rebalance': ('rebalance_NoneType', {})}, 'score': 0.9533333333333334, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'gini', 'max_depth': 3, 'max_features': 3, 'max_leaf_nodes': None, 'min_samples_split': 3, 'n_estimators': 75}, 'config_hash': {'algorithm': '34917a130df5a975f78bd7ec1a0c7b1ffdc787a9', 'config': '95fc8cadc088141290b7de9c388977e4685f0108', 'pipeline': '550d10faf2f08db48516cc3501558816d6a99bc0'}, 'duration': 1.4287099838256836, 'iteration': 11, 'loss': 0.19333333333333313, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 3, 'features__selectkbest__k': 4}), 'normalizer': ('normalizer_StandardScaler', {'normalizer__with_mean': False, 'normalizer__with_std': False}), 'rebalance': ('rebalance_CondensedNearestNeighbour', {'rebalance__n_neighbors': 1})}, 'score': 0.8066666666666669, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'entropy', 'max_depth': 1, 'max_features': 2, 'max_leaf_nodes': 5, 'min_samples_split': 2, 'n_estimators': 75}, 'config_hash': {'algorithm': '33f9abb4aee44a395a9f3b3ffa9ce80a8cdaed7c', 'config': '40fa726f0360cf6af55f9b5902d399d02f61f157', 'pipeline': 'cfd1d20841fe2153da762c95e79f95a3fb1e426a'}, 'duration': 1.2978079319000244, 'iteration': 12, 'loss': 0.053333333333333344, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_PCA', {'features__n_components': 4}), 'normalizer': ('normalizer_MinMaxScaler', {}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 7})}, 'score': 0.9466666666666667, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'entropy', 'max_depth': 4, 'max_features': 2, 'max_leaf_nodes': 5, 'min_samples_split': 3, 'n_estimators': 25}, 'config_hash': {'algorithm': '210111ec6562d09eb093e98ed69ef1c662e11a50', 'config': '0fb8e77c7bd9a58b72f1b33c21a59a09a8c676ba', 'pipeline': '5d269d759e0c7926a685a14b263ace8ae0071e4b'}, 'duration': 0.36649012565612793, 'iteration': 13, 'loss': 0.040000000000000036, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 2, 'features__selectkbest__k': 2}), 'normalizer': ('normalizer_NoneType', {}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 7})}, 'score': 0.96, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'entropy', 'max_depth': 3, 'max_features': 1, 'max_leaf_nodes': 5, 'min_samples_split': 2, 'n_estimators': 25}, 'config_hash': {'algorithm': '0e989a03980101fabf79eda3326ed2870e11d690', 'config': 'f4bffd5d8c67a9c5321a9943c4a99678f59a02b7', 'pipeline': '865ee1e3fe8334c3d5ecb2038d5a5d1b3ba50e75'}, 'duration': 0.35639500617980957, 'iteration': 14, 'loss': 0.046666666666666634, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_NoneType', {}), 'normalizer': ('normalizer_RobustScaler', {'normalizer__quantile_range': (...), 'normalizer__with_centering': True, 'normalizer__with_scaling': False}), 'rebalance': ('rebalance_NoneType', {})}, 'score': 0.9533333333333334, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'entropy', 'max_depth': None, 'max_features': 3, 'max_leaf_nodes': 3, 'min_samples_split': 5, 'n_estimators': 10}, 'config_hash': {'algorithm': '9c592e876c13de5e23e6de5b868e01755d63e72e', 'config': '1e6a68cd1eeac886d90724d78b1cb5fb76a3cde4', 'pipeline': '5a1ca4d82f21b7de0d2c918630a42510673fa36e'}, 'duration': 0.18141412734985352, 'iteration': 15, 'loss': 0.046666666666666634, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_SelectKBest', {'features__k': 3}), 'normalizer': ('normalizer_RobustScaler', {'normalizer__quantile_range': (...), 'normalizer__with_centering': True, 'normalizer__with_scaling': True}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 6})}, 'score': 0.9533333333333334, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': 1, 'max_features': None, 'max_leaf_nodes': None, 'min_samples_split': 5, 'n_estimators': 10}, 'config_hash': {'algorithm': '8bed77aef289bfd453b2858bd288ae5ba7160f2b', 'config': '781185bcb8999045de8d489f253a1a1ba4247932', 'pipeline': '1ece7eabedc2be9e5b0a1be65c570d08ffa3eb54'}, 'duration': 0.1636829376220703, 'iteration': 16, 'loss': 0.053333333333333344, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_NoneType', {}), 'normalizer': ('normalizer_NoneType', {}), 'rebalance': ('rebalance_NearMiss', {'rebalance__n_neighbors': 1})}, 'score': 0.9466666666666667, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'gini', 'max_depth': 3, 'max_features': 2, 'max_leaf_nodes': 2, 'min_samples_split': 5, 'n_estimators': 75}, 'config_hash': {'algorithm': '617b97d9ba21d3373bc51ffa9cccf9c6f91a77b3', 'config': '99fb425b4e8c5d80228cab94202252aa25cdf77c', 'pipeline': 'd6242929c3b515c7719e60423023ac604311afc3'}, 'duration': 0.8468999862670898, 'iteration': 17, 'loss': 0.24, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_PCA', {'features__n_components': 4}), 'normalizer': ('normalizer_PowerTransformer', {}), 'rebalance': ('rebalance_NearMiss', {'rebalance__n_neighbors': 2})}, 'score': 0.76, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': 1, 'max_features': 1, 'max_leaf_nodes': 2, 'min_samples_split': 5, 'n_estimators': 50}, 'config_hash': {'algorithm': 'b92d2697cdd4979da443369d6596229ec091626a', 'config': 'c513a3e13281206ad76187dd817b1fff93d54fe1', 'pipeline': 'c4b4f914a3ca8df967cade997a90366d85a371b9'}, 'duration': 0.6724588871002197, 'iteration': 18, 'loss': 0.23333333333333328, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 1, 'features__selectkbest__k': 3}), 'normalizer': ('normalizer_StandardScaler', {'normalizer__with_mean': True, 'normalizer__with_std': True}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 5})}, 'score': 0.7666666666666667, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'entropy', 'max_depth': None, 'max_features': None, 'max_leaf_nodes': 5, 'min_samples_split': 5, 'n_estimators': 10}, 'config_hash': {'algorithm': 'a0115de695e6cca2e81cbfb54df79bf4b43608b1', 'config': 'ba194015e20b5d67770e8c67342c3d8d0d01dc41', 'pipeline': '8d45fabfeb85ffdcabf7076bd0e65fffe97ce928'}, 'duration': 0.19424200057983398, 'iteration': 19, 'loss': 0.08666666666666667, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_PCA', {'features__n_components': 3}), 'normalizer': ('normalizer_NoneType', {}), 'rebalance': ('rebalance_NoneType', {})}, 'score': 0.9133333333333333, ...}, ...], 'history_hash': ['db6ac7e6d348155757e4794bb5f88fe2b4f63d50', '4db6fb84d85f52659f780e682ffac5712c3d8a94', '4403c5a85e951938d3c454e961d3a412780722f6', 'a064e2df18ab98d44dabcefbc7bed94913f1d0be', '0ddb6f5cab3db4dddd7682966a57205f3e329ad4', '49f25751bca61cdd461a8cbd2923689b642f98ed', '5c3a2b6f5e63fb45f10e41e0318b354912ec44f6', 'd3b129b397350f1b6572651c67c01de49b4b174c', '813bde1108cc3c4b9bfb3a22cbb421bda7eac671', '31930b6860ed406d59bf7e59ba1925d94704bd3b', '9913cd550615a9d0946ab4a755a8b9f619e442fd', '95fc8cadc088141290b7de9c388977e4685f0108', '40fa726f0360cf6af55f9b5902d399d02f61f157', '0fb8e77c7bd9a58b72f1b33c21a59a09a8c676ba', 'f4bffd5d8c67a9c5321a9943c4a99678f59a02b7', '1e6a68cd1eeac886d90724d78b1cb5fb76a3cde4', '781185bcb8999045de8d489f253a1a1ba4247932', '99fb425b4e8c5d80228cab94202252aa25cdf77c', 'c513a3e13281206ad76187dd817b1fff93d54fe1', 'ba194015e20b5d67770e8c67342c3d8d0d01dc41', ...], 'history_index': {'013329309d510b94f19d930320402d65f953a847': 39, '038a0f515e2ec894ee8e34f9caa2889eb3ebd5ce': 66, '052ae4bf232b316187b078abae42c2be19e16a00': 111, '0659afebf316aafeb75612fb07081a04c28545ed': 74, '06e7cde9f3556cd01332ce389ad1d8925cd4b4a4': 120, '0b6551ecfd6f83a15704a9db68f1599c99c6d3ef': 58, '0ddb6f5cab3db4dddd7682966a57205f3e329ad4': 4, '0fb8e77c7bd9a58b72f1b33c21a59a09a8c676ba': 13, '111e2fd99e871044225b8638df965b2a16868e35': 110, '111ffc790caf02104464bfa2f448cba7c56c71dc': 46, ...}, 'iteration': 151, 'max_history_score': 0.9666666666666668, 'max_history_score_std': 0.033333333333333326, 'max_history_step': 'joint'}, config={'algorithm': 'RandomForest', 'seed': 42, 'time': 300})
    108 
    109 def objective_algo(algo_config, current_pipeline_config, algorithm, X, y, context, config):
    110     return objective(current_pipeline_config, algo_config, algorithm, X, y, context, config, step='algorithm')
    111 
    112 def objective_joint(wconfig, algorithm, X, y, context, config):
--> 113     return objective(wconfig['pipeline'], wconfig['algorithm'], algorithm, X, y, context, config, step='joint')
        wconfig = {'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': 4, 'max_features': 3, 'max_leaf_nodes': 3, 'min_samples_split': 2, 'n_estimators': 10}, 'pipeline': {'features': ('features_SelectKBest', {'features__k': 1}), 'normalizer': ('normalizer_PowerTransformer', {}), 'rebalance': ('rebalance_CondensedNearestNeighbour', {'rebalance__n_neighbors': 2})}}
        algorithm = 'RandomForest'
        X = array([[5.1, 3.5, 1.4, 0.2],
       [4.9, 3. , 1....2, 3.4, 5.4, 2.3],
       [5.9, 3. , 5.1, 1.8]])
        y = array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,... 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2])
        context = {'baseline_score': 0.9466666666666667, 'baseline_score_std': 0.04988876515698587, 'best_config': {'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': 4, 'max_features': 3, 'max_leaf_nodes': 3, 'min_samples_split': 3, 'n_estimators': 10}, 'config_hash': {'algorithm': 'ffb7ff225ce3d3712c96cf87fe42202988ee2eb0', 'config': 'bae32f426be9cd6243523c023944a8c148fe4aeb', 'pipeline': 'd2a68bfda6fcdec4ae0ffc7d7b6a2122bc1cd673'}, 'duration': 0.7115809917449951, 'iteration': 113, 'loss': 0.033333333333333215, 'max_history_score': 0.9666666666666668, 'max_history_score_std': 0.033333333333333326, 'max_history_step': 'joint', 'pipeline': {'features': ('features_NoneType', {}), 'normalizer': ('normalizer_PowerTransformer', {}), 'rebalance': ('rebalance_CondensedNearestNeighbour', {'rebalance__n_neighbors': 2})}, 'score': 0.9666666666666668, ...}, 'history': [{'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': 2, 'max_features': None, 'max_leaf_nodes': 5, 'min_samples_split': 2, 'n_estimators': 75}, 'config_hash': {'algorithm': '3af5b0cce71c8fe2545246ca24ff5bc3dd516e06', 'config': 'db6ac7e6d348155757e4794bb5f88fe2b4f63d50', 'pipeline': '8d59f4b94cef6be9306ed86a22a9570fa670d567'}, 'duration': 1.149928092956543, 'iteration': 0, 'loss': 0.046666666666666634, 'max_history_score': 0.9533333333333334, 'max_history_score_std': 0.059999999999999984, 'max_history_step': 'joint', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 4, 'features__selectkbest__k': 3}), 'normalizer': ('normalizer_StandardScaler', {'normalizer__with_mean': True, 'normalizer__with_std': True}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 6})}, 'score': 0.9533333333333334, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': 1, 'max_features': 2, 'max_leaf_nodes': 2, 'min_samples_split': 5, 'n_estimators': 100}, 'config_hash': {'algorithm': 'e13eb05fd9a62d2f63bbb1c1deff0cd620d5e6ab', 'config': '4db6fb84d85f52659f780e682ffac5712c3d8a94', 'pipeline': '64c9a1ca9d53ae67244bdd942f4db36a3c05218c'}, 'duration': 1.7678282260894775, 'iteration': 1, 'loss': 0.18000000000000005, 'max_history_score': 0.9533333333333334, 'max_history_score_std': 0.059999999999999984, 'max_history_step': 'joint', 'pipeline': {'features': ('features_NoneType', {}), 'normalizer': ('normalizer_PowerTransformer', {}), 'rebalance': ('rebalance_NearMiss', {'rebalance__n_neighbors': 1})}, 'score': 0.82, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': 1, 'max_features': None, 'max_leaf_nodes': None, 'min_samples_split': 5, 'n_estimators': 75}, 'config_hash': {'algorithm': '94b0d7a654c508cc63643f78fe4f0f07e6f07c1e', 'config': '4403c5a85e951938d3c454e961d3a412780722f6', 'pipeline': '3e47444880d8367fbac2faaba2e52a917274aa58'}, 'duration': 0.8397619724273682, 'iteration': 2, 'loss': 0.03333333333333344, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_PCA', {'features__n_components': 3}), 'normalizer': ('normalizer_MinMaxScaler', {}), 'rebalance': ('rebalance_NoneType', {})}, 'score': 0.9666666666666666, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': None, 'max_features': None, 'max_leaf_nodes': 3, 'min_samples_split': 3, 'n_estimators': 75}, 'config_hash': {'algorithm': 'e8332f0a8902bda03bf70e7978cc5d52affb29d3', 'config': 'a064e2df18ab98d44dabcefbc7bed94913f1d0be', 'pipeline': '7eea819c2a8c103c4b1e9e9c1e224aebba95081f'}, 'duration': 0.8501448631286621, 'iteration': 3, 'loss': 0.053333333333333344, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 2, 'features__selectkbest__k': 4}), 'normalizer': ('normalizer_NoneType', {}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 7})}, 'score': 0.9466666666666667, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'entropy', 'max_depth': 3, 'max_features': 3, 'max_leaf_nodes': None, 'min_samples_split': 5, 'n_estimators': 75}, 'config_hash': {'algorithm': '7a4491035bc6bd737fe9a8cda8a79a02d02d5c74', 'config': '0ddb6f5cab3db4dddd7682966a57205f3e329ad4', 'pipeline': 'a9ae03fe38334f6868cbf84cdd3d629d4bbe3fb0'}, 'duration': 1.1026010513305664, 'iteration': 4, 'loss': 0.05999999999999994, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 2, 'features__selectkbest__k': 1}), 'normalizer': ('normalizer_NoneType', {}), 'rebalance': ('rebalance_NoneType', {})}, 'score': 0.9400000000000001, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'gini', 'max_depth': 3, 'max_features': 1, 'max_leaf_nodes': 5, 'min_samples_split': 2, 'n_estimators': 25}, 'config_hash': {'algorithm': '9826d20b2d6a0f559cf7f16450ce7526f07e8434', 'config': '49f25751bca61cdd461a8cbd2923689b642f98ed', 'pipeline': '19b249664c5bf067de1fed4334a296f947ce774a'}, 'duration': 0.35647010803222656, 'iteration': 5, 'loss': 0.046666666666666634, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_NoneType', {}), 'normalizer': ('normalizer_NoneType', {}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 6})}, 'score': 0.9533333333333334, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'gini', 'max_depth': 2, 'max_features': 1, 'max_leaf_nodes': 2, 'min_samples_split': 2, 'n_estimators': 50}, 'config_hash': {'algorithm': '0a4f6fbb07e0f32c6f675489a0fc82eee05bd8e1', 'config': '5c3a2b6f5e63fb45f10e41e0318b354912ec44f6', 'pipeline': 'dc3b9f176f090005e38b142f11d80e93a7dc5d5e'}, 'duration': 0.7213859558105469, 'iteration': 6, 'loss': 0.31333333333333324, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 1, 'features__selectkbest__k': 4}), 'normalizer': ('normalizer_PowerTransformer', {}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 7})}, 'score': 0.6866666666666668, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'entropy', 'max_depth': 4, 'max_features': 3, 'max_leaf_nodes': 5, 'min_samples_split': 5, 'n_estimators': 10}, 'config_hash': {'algorithm': 'b8112b97ecfc10f00a195af661dcc861cac21289', 'config': 'd3b129b397350f1b6572651c67c01de49b4b174c', 'pipeline': '5b0357ed7072c37b3d6f458bb5d49ff7d825f603'}, 'duration': 0.8299109935760498, 'iteration': 7, 'loss': 1.0, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_PCA', {'features__n_components': 2}), 'normalizer': ('normalizer_StandardScaler', {'normalizer__with_mean': True, 'normalizer__with_std': False}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 6})}, 'score': 0.0, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'gini', 'max_depth': 4, 'max_features': None, 'max_leaf_nodes': 2, 'min_samples_split': 5, 'n_estimators': 100}, 'config_hash': {'algorithm': '40ca24df19b8d164d9d098a6bed1ce056fbbb961', 'config': '813bde1108cc3c4b9bfb3a22cbb421bda7eac671', 'pipeline': '74a7b8705a1c22f7dea5e44e4ebda8f1e48add71'}, 'duration': 2.2111589908599854, 'iteration': 8, 'loss': 0.33333333333333326, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_PCA', {'features__n_components': 2}), 'normalizer': ('normalizer_StandardScaler', {'normalizer__with_mean': False, 'normalizer__with_std': True}), 'rebalance': ('rebalance_NearMiss', {'rebalance__n_neighbors': 2})}, 'score': 0.6666666666666667, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'entropy', 'max_depth': 2, 'max_features': 1, 'max_leaf_nodes': 5, 'min_samples_split': 2, 'n_estimators': 100}, 'config_hash': {'algorithm': '331418a5c12cf1453876eef85e9d98fc8e54fa11', 'config': '31930b6860ed406d59bf7e59ba1925d94704bd3b', 'pipeline': '054bef356f90ec6f644ef3ffc688766744db51c2'}, 'duration': 1.0501940250396729, 'iteration': 9, 'loss': 0.053333333333333344, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_SelectKBest', {'features__k': 1}), 'normalizer': ('normalizer_RobustScaler', {'normalizer__quantile_range': (...), 'normalizer__with_centering': True, 'normalizer__with_scaling': True}), 'rebalance': ('rebalance_NearMiss', {'rebalance__n_neighbors': 2})}, 'score': 0.9466666666666667, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'entropy', 'max_depth': 3, 'max_features': None, 'max_leaf_nodes': 3, 'min_samples_split': 2, 'n_estimators': 100}, 'config_hash': {'algorithm': 'dbc1b8126649fe93dce5fbb37e4015b0acfb179e', 'config': '9913cd550615a9d0946ab4a755a8b9f619e442fd', 'pipeline': 'dd626121cea079ebb32e184ca65483ec7a6d7f59'}, 'duration': 1.120617151260376, 'iteration': 10, 'loss': 0.046666666666666634, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 2, 'features__selectkbest__k': 1}), 'normalizer': ('normalizer_MinMaxScaler', {}), 'rebalance': ('rebalance_NoneType', {})}, 'score': 0.9533333333333334, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'gini', 'max_depth': 3, 'max_features': 3, 'max_leaf_nodes': None, 'min_samples_split': 3, 'n_estimators': 75}, 'config_hash': {'algorithm': '34917a130df5a975f78bd7ec1a0c7b1ffdc787a9', 'config': '95fc8cadc088141290b7de9c388977e4685f0108', 'pipeline': '550d10faf2f08db48516cc3501558816d6a99bc0'}, 'duration': 1.4287099838256836, 'iteration': 11, 'loss': 0.19333333333333313, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 3, 'features__selectkbest__k': 4}), 'normalizer': ('normalizer_StandardScaler', {'normalizer__with_mean': False, 'normalizer__with_std': False}), 'rebalance': ('rebalance_CondensedNearestNeighbour', {'rebalance__n_neighbors': 1})}, 'score': 0.8066666666666669, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'entropy', 'max_depth': 1, 'max_features': 2, 'max_leaf_nodes': 5, 'min_samples_split': 2, 'n_estimators': 75}, 'config_hash': {'algorithm': '33f9abb4aee44a395a9f3b3ffa9ce80a8cdaed7c', 'config': '40fa726f0360cf6af55f9b5902d399d02f61f157', 'pipeline': 'cfd1d20841fe2153da762c95e79f95a3fb1e426a'}, 'duration': 1.2978079319000244, 'iteration': 12, 'loss': 0.053333333333333344, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_PCA', {'features__n_components': 4}), 'normalizer': ('normalizer_MinMaxScaler', {}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 7})}, 'score': 0.9466666666666667, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'entropy', 'max_depth': 4, 'max_features': 2, 'max_leaf_nodes': 5, 'min_samples_split': 3, 'n_estimators': 25}, 'config_hash': {'algorithm': '210111ec6562d09eb093e98ed69ef1c662e11a50', 'config': '0fb8e77c7bd9a58b72f1b33c21a59a09a8c676ba', 'pipeline': '5d269d759e0c7926a685a14b263ace8ae0071e4b'}, 'duration': 0.36649012565612793, 'iteration': 13, 'loss': 0.040000000000000036, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 2, 'features__selectkbest__k': 2}), 'normalizer': ('normalizer_NoneType', {}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 7})}, 'score': 0.96, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'entropy', 'max_depth': 3, 'max_features': 1, 'max_leaf_nodes': 5, 'min_samples_split': 2, 'n_estimators': 25}, 'config_hash': {'algorithm': '0e989a03980101fabf79eda3326ed2870e11d690', 'config': 'f4bffd5d8c67a9c5321a9943c4a99678f59a02b7', 'pipeline': '865ee1e3fe8334c3d5ecb2038d5a5d1b3ba50e75'}, 'duration': 0.35639500617980957, 'iteration': 14, 'loss': 0.046666666666666634, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_NoneType', {}), 'normalizer': ('normalizer_RobustScaler', {'normalizer__quantile_range': (...), 'normalizer__with_centering': True, 'normalizer__with_scaling': False}), 'rebalance': ('rebalance_NoneType', {})}, 'score': 0.9533333333333334, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'entropy', 'max_depth': None, 'max_features': 3, 'max_leaf_nodes': 3, 'min_samples_split': 5, 'n_estimators': 10}, 'config_hash': {'algorithm': '9c592e876c13de5e23e6de5b868e01755d63e72e', 'config': '1e6a68cd1eeac886d90724d78b1cb5fb76a3cde4', 'pipeline': '5a1ca4d82f21b7de0d2c918630a42510673fa36e'}, 'duration': 0.18141412734985352, 'iteration': 15, 'loss': 0.046666666666666634, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_SelectKBest', {'features__k': 3}), 'normalizer': ('normalizer_RobustScaler', {'normalizer__quantile_range': (...), 'normalizer__with_centering': True, 'normalizer__with_scaling': True}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 6})}, 'score': 0.9533333333333334, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': 1, 'max_features': None, 'max_leaf_nodes': None, 'min_samples_split': 5, 'n_estimators': 10}, 'config_hash': {'algorithm': '8bed77aef289bfd453b2858bd288ae5ba7160f2b', 'config': '781185bcb8999045de8d489f253a1a1ba4247932', 'pipeline': '1ece7eabedc2be9e5b0a1be65c570d08ffa3eb54'}, 'duration': 0.1636829376220703, 'iteration': 16, 'loss': 0.053333333333333344, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_NoneType', {}), 'normalizer': ('normalizer_NoneType', {}), 'rebalance': ('rebalance_NearMiss', {'rebalance__n_neighbors': 1})}, 'score': 0.9466666666666667, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'gini', 'max_depth': 3, 'max_features': 2, 'max_leaf_nodes': 2, 'min_samples_split': 5, 'n_estimators': 75}, 'config_hash': {'algorithm': '617b97d9ba21d3373bc51ffa9cccf9c6f91a77b3', 'config': '99fb425b4e8c5d80228cab94202252aa25cdf77c', 'pipeline': 'd6242929c3b515c7719e60423023ac604311afc3'}, 'duration': 0.8468999862670898, 'iteration': 17, 'loss': 0.24, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_PCA', {'features__n_components': 4}), 'normalizer': ('normalizer_PowerTransformer', {}), 'rebalance': ('rebalance_NearMiss', {'rebalance__n_neighbors': 2})}, 'score': 0.76, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': 1, 'max_features': 1, 'max_leaf_nodes': 2, 'min_samples_split': 5, 'n_estimators': 50}, 'config_hash': {'algorithm': 'b92d2697cdd4979da443369d6596229ec091626a', 'config': 'c513a3e13281206ad76187dd817b1fff93d54fe1', 'pipeline': 'c4b4f914a3ca8df967cade997a90366d85a371b9'}, 'duration': 0.6724588871002197, 'iteration': 18, 'loss': 0.23333333333333328, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 1, 'features__selectkbest__k': 3}), 'normalizer': ('normalizer_StandardScaler', {'normalizer__with_mean': True, 'normalizer__with_std': True}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 5})}, 'score': 0.7666666666666667, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'entropy', 'max_depth': None, 'max_features': None, 'max_leaf_nodes': 5, 'min_samples_split': 5, 'n_estimators': 10}, 'config_hash': {'algorithm': 'a0115de695e6cca2e81cbfb54df79bf4b43608b1', 'config': 'ba194015e20b5d67770e8c67342c3d8d0d01dc41', 'pipeline': '8d45fabfeb85ffdcabf7076bd0e65fffe97ce928'}, 'duration': 0.19424200057983398, 'iteration': 19, 'loss': 0.08666666666666667, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_PCA', {'features__n_components': 3}), 'normalizer': ('normalizer_NoneType', {}), 'rebalance': ('rebalance_NoneType', {})}, 'score': 0.9133333333333333, ...}, ...], 'history_hash': ['db6ac7e6d348155757e4794bb5f88fe2b4f63d50', '4db6fb84d85f52659f780e682ffac5712c3d8a94', '4403c5a85e951938d3c454e961d3a412780722f6', 'a064e2df18ab98d44dabcefbc7bed94913f1d0be', '0ddb6f5cab3db4dddd7682966a57205f3e329ad4', '49f25751bca61cdd461a8cbd2923689b642f98ed', '5c3a2b6f5e63fb45f10e41e0318b354912ec44f6', 'd3b129b397350f1b6572651c67c01de49b4b174c', '813bde1108cc3c4b9bfb3a22cbb421bda7eac671', '31930b6860ed406d59bf7e59ba1925d94704bd3b', '9913cd550615a9d0946ab4a755a8b9f619e442fd', '95fc8cadc088141290b7de9c388977e4685f0108', '40fa726f0360cf6af55f9b5902d399d02f61f157', '0fb8e77c7bd9a58b72f1b33c21a59a09a8c676ba', 'f4bffd5d8c67a9c5321a9943c4a99678f59a02b7', '1e6a68cd1eeac886d90724d78b1cb5fb76a3cde4', '781185bcb8999045de8d489f253a1a1ba4247932', '99fb425b4e8c5d80228cab94202252aa25cdf77c', 'c513a3e13281206ad76187dd817b1fff93d54fe1', 'ba194015e20b5d67770e8c67342c3d8d0d01dc41', ...], 'history_index': {'013329309d510b94f19d930320402d65f953a847': 39, '038a0f515e2ec894ee8e34f9caa2889eb3ebd5ce': 66, '052ae4bf232b316187b078abae42c2be19e16a00': 111, '0659afebf316aafeb75612fb07081a04c28545ed': 74, '06e7cde9f3556cd01332ce389ad1d8925cd4b4a4': 120, '0b6551ecfd6f83a15704a9db68f1599c99c6d3ef': 58, '0ddb6f5cab3db4dddd7682966a57205f3e329ad4': 4, '0fb8e77c7bd9a58b72f1b33c21a59a09a8c676ba': 13, '111e2fd99e871044225b8638df965b2a16868e35': 110, '111ffc790caf02104464bfa2f448cba7c56c71dc': 46, ...}, 'iteration': 151, 'max_history_score': 0.9666666666666668, 'max_history_score_std': 0.033333333333333326, 'max_history_step': 'joint'}
        config = {'algorithm': 'RandomForest', 'seed': 42, 'time': 300}
    114 
    115 
    116 def get_baseline_score(algorithm, X, y, seed):
    117     pipeline, _ = pipeline_conf_to_full_pipeline(

...........................................................................
/home/aquemy/dev/dp_hyperparameters/extension/experiment/objective.py in objective(pipeline_config={'features': ('features_SelectKBest', {'features__k': 1}), 'normalizer': ('normalizer_PowerTransformer', {}), 'rebalance': ('rebalance_CondensedNearestNeighbour', {'rebalance__n_neighbors': 2})}, algo_config={'bootstrap': True, 'criterion': 'gini', 'max_depth': 4, 'max_features': 3, 'max_leaf_nodes': 3, 'min_samples_split': 2, 'n_estimators': 10}, algorithm='RandomForest', X=array([[5.1, 3.5, 1.4, 0.2],
       [4.9, 3. , 1....2, 3.4, 5.4, 2.3],
       [5.9, 3. , 5.1, 1.8]]), y=array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,... 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]), context={'baseline_score': 0.9466666666666667, 'baseline_score_std': 0.04988876515698587, 'best_config': {'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': 4, 'max_features': 3, 'max_leaf_nodes': 3, 'min_samples_split': 3, 'n_estimators': 10}, 'config_hash': {'algorithm': 'ffb7ff225ce3d3712c96cf87fe42202988ee2eb0', 'config': 'bae32f426be9cd6243523c023944a8c148fe4aeb', 'pipeline': 'd2a68bfda6fcdec4ae0ffc7d7b6a2122bc1cd673'}, 'duration': 0.7115809917449951, 'iteration': 113, 'loss': 0.033333333333333215, 'max_history_score': 0.9666666666666668, 'max_history_score_std': 0.033333333333333326, 'max_history_step': 'joint', 'pipeline': {'features': ('features_NoneType', {}), 'normalizer': ('normalizer_PowerTransformer', {}), 'rebalance': ('rebalance_CondensedNearestNeighbour', {'rebalance__n_neighbors': 2})}, 'score': 0.9666666666666668, ...}, 'history': [{'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': 2, 'max_features': None, 'max_leaf_nodes': 5, 'min_samples_split': 2, 'n_estimators': 75}, 'config_hash': {'algorithm': '3af5b0cce71c8fe2545246ca24ff5bc3dd516e06', 'config': 'db6ac7e6d348155757e4794bb5f88fe2b4f63d50', 'pipeline': '8d59f4b94cef6be9306ed86a22a9570fa670d567'}, 'duration': 1.149928092956543, 'iteration': 0, 'loss': 0.046666666666666634, 'max_history_score': 0.9533333333333334, 'max_history_score_std': 0.059999999999999984, 'max_history_step': 'joint', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 4, 'features__selectkbest__k': 3}), 'normalizer': ('normalizer_StandardScaler', {'normalizer__with_mean': True, 'normalizer__with_std': True}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 6})}, 'score': 0.9533333333333334, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': 1, 'max_features': 2, 'max_leaf_nodes': 2, 'min_samples_split': 5, 'n_estimators': 100}, 'config_hash': {'algorithm': 'e13eb05fd9a62d2f63bbb1c1deff0cd620d5e6ab', 'config': '4db6fb84d85f52659f780e682ffac5712c3d8a94', 'pipeline': '64c9a1ca9d53ae67244bdd942f4db36a3c05218c'}, 'duration': 1.7678282260894775, 'iteration': 1, 'loss': 0.18000000000000005, 'max_history_score': 0.9533333333333334, 'max_history_score_std': 0.059999999999999984, 'max_history_step': 'joint', 'pipeline': {'features': ('features_NoneType', {}), 'normalizer': ('normalizer_PowerTransformer', {}), 'rebalance': ('rebalance_NearMiss', {'rebalance__n_neighbors': 1})}, 'score': 0.82, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': 1, 'max_features': None, 'max_leaf_nodes': None, 'min_samples_split': 5, 'n_estimators': 75}, 'config_hash': {'algorithm': '94b0d7a654c508cc63643f78fe4f0f07e6f07c1e', 'config': '4403c5a85e951938d3c454e961d3a412780722f6', 'pipeline': '3e47444880d8367fbac2faaba2e52a917274aa58'}, 'duration': 0.8397619724273682, 'iteration': 2, 'loss': 0.03333333333333344, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_PCA', {'features__n_components': 3}), 'normalizer': ('normalizer_MinMaxScaler', {}), 'rebalance': ('rebalance_NoneType', {})}, 'score': 0.9666666666666666, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': None, 'max_features': None, 'max_leaf_nodes': 3, 'min_samples_split': 3, 'n_estimators': 75}, 'config_hash': {'algorithm': 'e8332f0a8902bda03bf70e7978cc5d52affb29d3', 'config': 'a064e2df18ab98d44dabcefbc7bed94913f1d0be', 'pipeline': '7eea819c2a8c103c4b1e9e9c1e224aebba95081f'}, 'duration': 0.8501448631286621, 'iteration': 3, 'loss': 0.053333333333333344, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 2, 'features__selectkbest__k': 4}), 'normalizer': ('normalizer_NoneType', {}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 7})}, 'score': 0.9466666666666667, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'entropy', 'max_depth': 3, 'max_features': 3, 'max_leaf_nodes': None, 'min_samples_split': 5, 'n_estimators': 75}, 'config_hash': {'algorithm': '7a4491035bc6bd737fe9a8cda8a79a02d02d5c74', 'config': '0ddb6f5cab3db4dddd7682966a57205f3e329ad4', 'pipeline': 'a9ae03fe38334f6868cbf84cdd3d629d4bbe3fb0'}, 'duration': 1.1026010513305664, 'iteration': 4, 'loss': 0.05999999999999994, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 2, 'features__selectkbest__k': 1}), 'normalizer': ('normalizer_NoneType', {}), 'rebalance': ('rebalance_NoneType', {})}, 'score': 0.9400000000000001, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'gini', 'max_depth': 3, 'max_features': 1, 'max_leaf_nodes': 5, 'min_samples_split': 2, 'n_estimators': 25}, 'config_hash': {'algorithm': '9826d20b2d6a0f559cf7f16450ce7526f07e8434', 'config': '49f25751bca61cdd461a8cbd2923689b642f98ed', 'pipeline': '19b249664c5bf067de1fed4334a296f947ce774a'}, 'duration': 0.35647010803222656, 'iteration': 5, 'loss': 0.046666666666666634, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_NoneType', {}), 'normalizer': ('normalizer_NoneType', {}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 6})}, 'score': 0.9533333333333334, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'gini', 'max_depth': 2, 'max_features': 1, 'max_leaf_nodes': 2, 'min_samples_split': 2, 'n_estimators': 50}, 'config_hash': {'algorithm': '0a4f6fbb07e0f32c6f675489a0fc82eee05bd8e1', 'config': '5c3a2b6f5e63fb45f10e41e0318b354912ec44f6', 'pipeline': 'dc3b9f176f090005e38b142f11d80e93a7dc5d5e'}, 'duration': 0.7213859558105469, 'iteration': 6, 'loss': 0.31333333333333324, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 1, 'features__selectkbest__k': 4}), 'normalizer': ('normalizer_PowerTransformer', {}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 7})}, 'score': 0.6866666666666668, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'entropy', 'max_depth': 4, 'max_features': 3, 'max_leaf_nodes': 5, 'min_samples_split': 5, 'n_estimators': 10}, 'config_hash': {'algorithm': 'b8112b97ecfc10f00a195af661dcc861cac21289', 'config': 'd3b129b397350f1b6572651c67c01de49b4b174c', 'pipeline': '5b0357ed7072c37b3d6f458bb5d49ff7d825f603'}, 'duration': 0.8299109935760498, 'iteration': 7, 'loss': 1.0, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_PCA', {'features__n_components': 2}), 'normalizer': ('normalizer_StandardScaler', {'normalizer__with_mean': True, 'normalizer__with_std': False}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 6})}, 'score': 0.0, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'gini', 'max_depth': 4, 'max_features': None, 'max_leaf_nodes': 2, 'min_samples_split': 5, 'n_estimators': 100}, 'config_hash': {'algorithm': '40ca24df19b8d164d9d098a6bed1ce056fbbb961', 'config': '813bde1108cc3c4b9bfb3a22cbb421bda7eac671', 'pipeline': '74a7b8705a1c22f7dea5e44e4ebda8f1e48add71'}, 'duration': 2.2111589908599854, 'iteration': 8, 'loss': 0.33333333333333326, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_PCA', {'features__n_components': 2}), 'normalizer': ('normalizer_StandardScaler', {'normalizer__with_mean': False, 'normalizer__with_std': True}), 'rebalance': ('rebalance_NearMiss', {'rebalance__n_neighbors': 2})}, 'score': 0.6666666666666667, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'entropy', 'max_depth': 2, 'max_features': 1, 'max_leaf_nodes': 5, 'min_samples_split': 2, 'n_estimators': 100}, 'config_hash': {'algorithm': '331418a5c12cf1453876eef85e9d98fc8e54fa11', 'config': '31930b6860ed406d59bf7e59ba1925d94704bd3b', 'pipeline': '054bef356f90ec6f644ef3ffc688766744db51c2'}, 'duration': 1.0501940250396729, 'iteration': 9, 'loss': 0.053333333333333344, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_SelectKBest', {'features__k': 1}), 'normalizer': ('normalizer_RobustScaler', {'normalizer__quantile_range': (...), 'normalizer__with_centering': True, 'normalizer__with_scaling': True}), 'rebalance': ('rebalance_NearMiss', {'rebalance__n_neighbors': 2})}, 'score': 0.9466666666666667, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'entropy', 'max_depth': 3, 'max_features': None, 'max_leaf_nodes': 3, 'min_samples_split': 2, 'n_estimators': 100}, 'config_hash': {'algorithm': 'dbc1b8126649fe93dce5fbb37e4015b0acfb179e', 'config': '9913cd550615a9d0946ab4a755a8b9f619e442fd', 'pipeline': 'dd626121cea079ebb32e184ca65483ec7a6d7f59'}, 'duration': 1.120617151260376, 'iteration': 10, 'loss': 0.046666666666666634, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 2, 'features__selectkbest__k': 1}), 'normalizer': ('normalizer_MinMaxScaler', {}), 'rebalance': ('rebalance_NoneType', {})}, 'score': 0.9533333333333334, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'gini', 'max_depth': 3, 'max_features': 3, 'max_leaf_nodes': None, 'min_samples_split': 3, 'n_estimators': 75}, 'config_hash': {'algorithm': '34917a130df5a975f78bd7ec1a0c7b1ffdc787a9', 'config': '95fc8cadc088141290b7de9c388977e4685f0108', 'pipeline': '550d10faf2f08db48516cc3501558816d6a99bc0'}, 'duration': 1.4287099838256836, 'iteration': 11, 'loss': 0.19333333333333313, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 3, 'features__selectkbest__k': 4}), 'normalizer': ('normalizer_StandardScaler', {'normalizer__with_mean': False, 'normalizer__with_std': False}), 'rebalance': ('rebalance_CondensedNearestNeighbour', {'rebalance__n_neighbors': 1})}, 'score': 0.8066666666666669, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'entropy', 'max_depth': 1, 'max_features': 2, 'max_leaf_nodes': 5, 'min_samples_split': 2, 'n_estimators': 75}, 'config_hash': {'algorithm': '33f9abb4aee44a395a9f3b3ffa9ce80a8cdaed7c', 'config': '40fa726f0360cf6af55f9b5902d399d02f61f157', 'pipeline': 'cfd1d20841fe2153da762c95e79f95a3fb1e426a'}, 'duration': 1.2978079319000244, 'iteration': 12, 'loss': 0.053333333333333344, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_PCA', {'features__n_components': 4}), 'normalizer': ('normalizer_MinMaxScaler', {}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 7})}, 'score': 0.9466666666666667, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'entropy', 'max_depth': 4, 'max_features': 2, 'max_leaf_nodes': 5, 'min_samples_split': 3, 'n_estimators': 25}, 'config_hash': {'algorithm': '210111ec6562d09eb093e98ed69ef1c662e11a50', 'config': '0fb8e77c7bd9a58b72f1b33c21a59a09a8c676ba', 'pipeline': '5d269d759e0c7926a685a14b263ace8ae0071e4b'}, 'duration': 0.36649012565612793, 'iteration': 13, 'loss': 0.040000000000000036, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 2, 'features__selectkbest__k': 2}), 'normalizer': ('normalizer_NoneType', {}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 7})}, 'score': 0.96, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'entropy', 'max_depth': 3, 'max_features': 1, 'max_leaf_nodes': 5, 'min_samples_split': 2, 'n_estimators': 25}, 'config_hash': {'algorithm': '0e989a03980101fabf79eda3326ed2870e11d690', 'config': 'f4bffd5d8c67a9c5321a9943c4a99678f59a02b7', 'pipeline': '865ee1e3fe8334c3d5ecb2038d5a5d1b3ba50e75'}, 'duration': 0.35639500617980957, 'iteration': 14, 'loss': 0.046666666666666634, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_NoneType', {}), 'normalizer': ('normalizer_RobustScaler', {'normalizer__quantile_range': (...), 'normalizer__with_centering': True, 'normalizer__with_scaling': False}), 'rebalance': ('rebalance_NoneType', {})}, 'score': 0.9533333333333334, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'entropy', 'max_depth': None, 'max_features': 3, 'max_leaf_nodes': 3, 'min_samples_split': 5, 'n_estimators': 10}, 'config_hash': {'algorithm': '9c592e876c13de5e23e6de5b868e01755d63e72e', 'config': '1e6a68cd1eeac886d90724d78b1cb5fb76a3cde4', 'pipeline': '5a1ca4d82f21b7de0d2c918630a42510673fa36e'}, 'duration': 0.18141412734985352, 'iteration': 15, 'loss': 0.046666666666666634, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_SelectKBest', {'features__k': 3}), 'normalizer': ('normalizer_RobustScaler', {'normalizer__quantile_range': (...), 'normalizer__with_centering': True, 'normalizer__with_scaling': True}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 6})}, 'score': 0.9533333333333334, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': 1, 'max_features': None, 'max_leaf_nodes': None, 'min_samples_split': 5, 'n_estimators': 10}, 'config_hash': {'algorithm': '8bed77aef289bfd453b2858bd288ae5ba7160f2b', 'config': '781185bcb8999045de8d489f253a1a1ba4247932', 'pipeline': '1ece7eabedc2be9e5b0a1be65c570d08ffa3eb54'}, 'duration': 0.1636829376220703, 'iteration': 16, 'loss': 0.053333333333333344, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_NoneType', {}), 'normalizer': ('normalizer_NoneType', {}), 'rebalance': ('rebalance_NearMiss', {'rebalance__n_neighbors': 1})}, 'score': 0.9466666666666667, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'gini', 'max_depth': 3, 'max_features': 2, 'max_leaf_nodes': 2, 'min_samples_split': 5, 'n_estimators': 75}, 'config_hash': {'algorithm': '617b97d9ba21d3373bc51ffa9cccf9c6f91a77b3', 'config': '99fb425b4e8c5d80228cab94202252aa25cdf77c', 'pipeline': 'd6242929c3b515c7719e60423023ac604311afc3'}, 'duration': 0.8468999862670898, 'iteration': 17, 'loss': 0.24, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_PCA', {'features__n_components': 4}), 'normalizer': ('normalizer_PowerTransformer', {}), 'rebalance': ('rebalance_NearMiss', {'rebalance__n_neighbors': 2})}, 'score': 0.76, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': 1, 'max_features': 1, 'max_leaf_nodes': 2, 'min_samples_split': 5, 'n_estimators': 50}, 'config_hash': {'algorithm': 'b92d2697cdd4979da443369d6596229ec091626a', 'config': 'c513a3e13281206ad76187dd817b1fff93d54fe1', 'pipeline': 'c4b4f914a3ca8df967cade997a90366d85a371b9'}, 'duration': 0.6724588871002197, 'iteration': 18, 'loss': 0.23333333333333328, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 1, 'features__selectkbest__k': 3}), 'normalizer': ('normalizer_StandardScaler', {'normalizer__with_mean': True, 'normalizer__with_std': True}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 5})}, 'score': 0.7666666666666667, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'entropy', 'max_depth': None, 'max_features': None, 'max_leaf_nodes': 5, 'min_samples_split': 5, 'n_estimators': 10}, 'config_hash': {'algorithm': 'a0115de695e6cca2e81cbfb54df79bf4b43608b1', 'config': 'ba194015e20b5d67770e8c67342c3d8d0d01dc41', 'pipeline': '8d45fabfeb85ffdcabf7076bd0e65fffe97ce928'}, 'duration': 0.19424200057983398, 'iteration': 19, 'loss': 0.08666666666666667, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_PCA', {'features__n_components': 3}), 'normalizer': ('normalizer_NoneType', {}), 'rebalance': ('rebalance_NoneType', {})}, 'score': 0.9133333333333333, ...}, ...], 'history_hash': ['db6ac7e6d348155757e4794bb5f88fe2b4f63d50', '4db6fb84d85f52659f780e682ffac5712c3d8a94', '4403c5a85e951938d3c454e961d3a412780722f6', 'a064e2df18ab98d44dabcefbc7bed94913f1d0be', '0ddb6f5cab3db4dddd7682966a57205f3e329ad4', '49f25751bca61cdd461a8cbd2923689b642f98ed', '5c3a2b6f5e63fb45f10e41e0318b354912ec44f6', 'd3b129b397350f1b6572651c67c01de49b4b174c', '813bde1108cc3c4b9bfb3a22cbb421bda7eac671', '31930b6860ed406d59bf7e59ba1925d94704bd3b', '9913cd550615a9d0946ab4a755a8b9f619e442fd', '95fc8cadc088141290b7de9c388977e4685f0108', '40fa726f0360cf6af55f9b5902d399d02f61f157', '0fb8e77c7bd9a58b72f1b33c21a59a09a8c676ba', 'f4bffd5d8c67a9c5321a9943c4a99678f59a02b7', '1e6a68cd1eeac886d90724d78b1cb5fb76a3cde4', '781185bcb8999045de8d489f253a1a1ba4247932', '99fb425b4e8c5d80228cab94202252aa25cdf77c', 'c513a3e13281206ad76187dd817b1fff93d54fe1', 'ba194015e20b5d67770e8c67342c3d8d0d01dc41', ...], 'history_index': {'013329309d510b94f19d930320402d65f953a847': 39, '038a0f515e2ec894ee8e34f9caa2889eb3ebd5ce': 66, '052ae4bf232b316187b078abae42c2be19e16a00': 111, '0659afebf316aafeb75612fb07081a04c28545ed': 74, '06e7cde9f3556cd01332ce389ad1d8925cd4b4a4': 120, '0b6551ecfd6f83a15704a9db68f1599c99c6d3ef': 58, '0ddb6f5cab3db4dddd7682966a57205f3e329ad4': 4, '0fb8e77c7bd9a58b72f1b33c21a59a09a8c676ba': 13, '111e2fd99e871044225b8638df965b2a16868e35': 110, '111ffc790caf02104464bfa2f448cba7c56c71dc': 46, ...}, 'iteration': 151, 'max_history_score': 0.9666666666666668, 'max_history_score_std': 0.033333333333333326, 'max_history_step': 'joint'}, config={'algorithm': 'RandomForest', 'seed': 42, 'time': 300}, step='joint')
     45                 y,
     46                 cv=10,
     47                 n_jobs=-1,
     48                 return_estimator=False,
     49                 return_train_score=False,
---> 50                 verbose=0)
     51         score = np.mean(scores['test_score'])
     52         std = np.std(scores['test_score'])
     53         status = STATUS_OK
     54     except Exception as e:

...........................................................................
/home/aquemy/.local/lib/python2.7/site-packages/sklearn/model_selection/_validation.py in cross_validate(estimator=Pipeline(memory=None,
     steps=[('rebalance', ... random_state=42, verbose=0, warm_start=False))]), X=array([[5.1, 3.5, 1.4, 0.2],
       [4.9, 3. , 1....2, 3.4, 5.4, 2.3],
       [5.9, 3. , 5.1, 1.8]]), y=array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,... 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]), groups=None, scoring=None, cv=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1, verbose=0, fit_params=None, pre_dispatch='2*n_jobs', return_train_score=False, return_estimator=False, error_score='raise-deprecating')
    235         delayed(_fit_and_score)(
    236             clone(estimator), X, y, scorers, train, test, verbose, None,
    237             fit_params, return_train_score=return_train_score,
    238             return_times=True, return_estimator=return_estimator,
    239             error_score=error_score)
--> 240         for train, test in cv.split(X, y, groups))
        cv.split = <bound method StratifiedKFold.split of Stratifie...d(n_splits=10, random_state=None, shuffle=False)>
        X = array([[5.1, 3.5, 1.4, 0.2],
       [4.9, 3. , 1....2, 3.4, 5.4, 2.3],
       [5.9, 3. , 5.1, 1.8]])
        y = array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,... 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2])
        groups = None
    241 
    242     zipped_scores = list(zip(*scores))
    243     if return_train_score:
    244         train_scores = zipped_scores.pop(0)

...........................................................................
/home/aquemy/.local/lib/python2.7/site-packages/sklearn/externals/joblib/parallel.py in __call__(self=Parallel(n_jobs=-1), iterable=<generator object <genexpr>>)
    925                 # No need to wait for async callbacks to trigger to
    926                 # consumption.
    927                 self._iterating = False
    928 
    929             with self._backend.retrieval_context():
--> 930                 self.retrieve()
        self.retrieve = <bound method Parallel.retrieve of Parallel(n_jobs=-1)>
    931             # Make sure that we get a last message telling us we are done
    932             elapsed_time = time.time() - self._start_time
    933             self._print('Done %3i out of %3i | elapsed: %s finished',
    934                         (len(self._output), len(self._output),

---------------------------------------------------------------------------
Joblib worker traceback:
---------------------------------------------------------------------------
ValueError                                         Mon Jun 17 13:12:42 2019
PID: 21131                                  Python 2.7.15+: /usr/bin/python
...........................................................................
/home/aquemy/.local/lib/python2.7/site-packages/sklearn/externals/joblib/parallel.py in __call__(self=<sklearn.externals.joblib.parallel.BatchedCalls object>)
    220     def __call__(self):
    221         # Set the default nested backend to self._backend but do not set the
    222         # change the default number of processes to -1
    223         with parallel_backend(self._backend, n_jobs=self._n_jobs):
    224             return [func(*args, **kwargs)
--> 225                     for func, args, kwargs in self.items]
        func = <function _fit_and_score>
        args = (Pipeline(memory=None,
     steps=[('rebalance', ... random_state=42, verbose=0, warm_start=False))]), array([[5.1, 3.5, 1.4, 0.2],
       [4.9, 3. , 1....2, 3.4, 5.4, 2.3],
       [5.9, 3. , 5.1, 1.8]]), array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,... 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]), {'score': <function _passthrough_scorer>}, array([  5,   6,   7,   8,   9,  10,  11,  12,  ..., 142, 143, 144,
       145, 146, 147, 148, 149]), array([  0,   1,   2,   3,   4,  50,  51,  52,  53,  54, 100, 101, 102,
       103, 104]), 0, None, None)
        kwargs = {'error_score': 'raise-deprecating', 'return_estimator': False, 'return_times': True, 'return_train_score': False}
        self.items = [(<function _fit_and_score>, (Pipeline(memory=None,
     steps=[('rebalance', ... random_state=42, verbose=0, warm_start=False))]), array([[5.1, 3.5, 1.4, 0.2],
       [4.9, 3. , 1....2, 3.4, 5.4, 2.3],
       [5.9, 3. , 5.1, 1.8]]), array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,... 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]), {'score': <function _passthrough_scorer>}, array([  5,   6,   7,   8,   9,  10,  11,  12,  ..., 142, 143, 144,
       145, 146, 147, 148, 149]), array([  0,   1,   2,   3,   4,  50,  51,  52,  53,  54, 100, 101, 102,
       103, 104]), 0, None, None), {'error_score': 'raise-deprecating', 'return_estimator': False, 'return_times': True, 'return_train_score': False})]
    226 
    227     def __len__(self):
    228         return self._size
    229 

...........................................................................
/home/aquemy/.local/lib/python2.7/site-packages/sklearn/model_selection/_validation.py in _fit_and_score(estimator=Pipeline(memory=None,
     steps=[('rebalance', ... random_state=42, verbose=0, warm_start=False))]), X=array([[5.1, 3.5, 1.4, 0.2],
       [4.9, 3. , 1....2, 3.4, 5.4, 2.3],
       [5.9, 3. , 5.1, 1.8]]), y=array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,... 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]), scorer={'score': <function _passthrough_scorer>}, train=array([  5,   6,   7,   8,   9,  10,  11,  12,  ..., 142, 143, 144,
       145, 146, 147, 148, 149]), test=array([  0,   1,   2,   3,   4,  50,  51,  52,  53,  54, 100, 101, 102,
       103, 104]), verbose=0, parameters=None, fit_params={}, return_train_score=False, return_parameters=False, return_n_test_samples=False, return_times=True, return_estimator=False, error_score='raise-deprecating')
    523 
    524     try:
    525         if y_train is None:
    526             estimator.fit(X_train, **fit_params)
    527         else:
--> 528             estimator.fit(X_train, y_train, **fit_params)
        estimator.fit = <bound method Pipeline.fit of Pipeline(memory=No...random_state=42, verbose=0, warm_start=False))])>
        X_train = array([[5.4, 3.9, 1.7, 0.4],
       [4.6, 3.4, 1....2, 3.4, 5.4, 2.3],
       [5.9, 3. , 5.1, 1.8]])
        y_train = array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,
       2, 2, 2])
        fit_params = {}
    529 
    530     except Exception as e:
    531         # Note fit time as time until error
    532         fit_time = time.time() - start_time

...........................................................................
/usr/local/lib/python2.7/dist-packages/imblearn/pipeline.py in fit(self=Pipeline(memory=None,
     steps=[('rebalance', ... random_state=42, verbose=0, warm_start=False))]), X=array([[5.4, 3.9, 1.7, 0.4],
       [4.6, 3.4, 1....2, 3.4, 5.4, 2.3],
       [5.9, 3. , 5.1, 1.8]]), y=array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,
       2, 2, 2]), **fit_params={})
    234             This estimator
    235 
    236         """
    237         Xt, yt, fit_params = self._fit(X, y, **fit_params)
    238         if self._final_estimator is not None:
--> 239             self._final_estimator.fit(Xt, yt, **fit_params)
        self._final_estimator.fit = <bound method RandomForestClassifier.fit of Rand...e, random_state=42, verbose=0, warm_start=False)>
        Xt = array([[ 0.44043722],
       [-0.44756533],
    ...27],
       [ 2.09804146],
       [ 2.00614123]])
        yt = array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...0, 0, 0, 0, 0, 0,
       0, 1, 1, 1, 1, 2, 2, 2])
        fit_params = {}
    240         return self
    241 
    242     def fit_transform(self, X, y=None, **fit_params):
    243         """Fit the model and transform with the final estimator

...........................................................................
/home/aquemy/.local/lib/python2.7/site-packages/sklearn/ensemble/forest.py in fit(self=RandomForestClassifier(bootstrap=True, class_wei...se, random_state=42, verbose=0, warm_start=False), X=array([[ 0.44043723],
       [-0.44756532],
    ....0980415 ],
       [ 2.0061412 ]], dtype=float32), y=array([[0.],
       [0.],
       [0.],
       [0...    [1.],
       [2.],
       [2.],
       [2.]]), sample_weight=None)
    328             trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,
    329                              **_joblib_parallel_args(prefer='threads'))(
    330                 delayed(_parallel_build_trees)(
    331                     t, self, X, y, sample_weight, i, len(trees),
    332                     verbose=self.verbose, class_weight=self.class_weight)
--> 333                 for i, t in enumerate(trees))
        i = 9
    334 
    335             # Collect newly grown trees
    336             self.estimators_.extend(trees)
    337 

...........................................................................
/home/aquemy/.local/lib/python2.7/site-packages/sklearn/externals/joblib/parallel.py in __call__(self=Parallel(n_jobs=1), iterable=<generator object <genexpr>>)
    912             # self._original_iterator is None, then this means either
    913             # that pre_dispatch == "all", n_jobs == 1 or that the first batch
    914             # was very quick and its callback already dispatched all the
    915             # remaining jobs.
    916             self._iterating = False
--> 917             if self.dispatch_one_batch(iterator):
        self.dispatch_one_batch = <bound method Parallel.dispatch_one_batch of Parallel(n_jobs=1)>
        iterator = <generator object <genexpr>>
    918                 self._iterating = self._original_iterator is not None
    919 
    920             while self.dispatch_one_batch(iterator):
    921                 pass

...........................................................................
/home/aquemy/.local/lib/python2.7/site-packages/sklearn/externals/joblib/parallel.py in dispatch_one_batch(self=Parallel(n_jobs=1), iterator=<generator object <genexpr>>)
    754                                  self._pickle_cache)
    755             if len(tasks) == 0:
    756                 # No more tasks available in the iterator: tell caller to stop.
    757                 return False
    758             else:
--> 759                 self._dispatch(tasks)
        self._dispatch = <bound method Parallel._dispatch of Parallel(n_jobs=1)>
        tasks = <sklearn.externals.joblib.parallel.BatchedCalls object>
    760                 return True
    761 
    762     def _print(self, msg, msg_args):
    763         """Display the message on stout or stderr depending on verbosity"""

...........................................................................
/home/aquemy/.local/lib/python2.7/site-packages/sklearn/externals/joblib/parallel.py in _dispatch(self=Parallel(n_jobs=1), batch=<sklearn.externals.joblib.parallel.BatchedCalls object>)
    711 
    712         dispatch_timestamp = time.time()
    713         cb = BatchCompletionCallBack(dispatch_timestamp, len(batch), self)
    714         with self._lock:
    715             job_idx = len(self._jobs)
--> 716             job = self._backend.apply_async(batch, callback=cb)
        job = undefined
        self._backend.apply_async = <bound method SequentialBackend.apply_async of <...lib._parallel_backends.SequentialBackend object>>
        batch = <sklearn.externals.joblib.parallel.BatchedCalls object>
        cb = <sklearn.externals.joblib.parallel.BatchCompletionCallBack object>
    717             # A job can complete so quickly than its callback is
    718             # called before we get here, causing self._jobs to
    719             # grow. To ensure correct results ordering, .insert is
    720             # used (rather than .append) in the following line

...........................................................................
/home/aquemy/.local/lib/python2.7/site-packages/sklearn/externals/joblib/_parallel_backends.py in apply_async(self=<sklearn.externals.joblib._parallel_backends.SequentialBackend object>, func=<sklearn.externals.joblib.parallel.BatchedCalls object>, callback=<sklearn.externals.joblib.parallel.BatchCompletionCallBack object>)
    177             raise ValueError('n_jobs == 0 in Parallel has no meaning')
    178         return 1
    179 
    180     def apply_async(self, func, callback=None):
    181         """Schedule a func to be run"""
--> 182         result = ImmediateResult(func)
        result = undefined
        func = <sklearn.externals.joblib.parallel.BatchedCalls object>
    183         if callback:
    184             callback(result)
    185         return result
    186 

...........................................................................
/home/aquemy/.local/lib/python2.7/site-packages/sklearn/externals/joblib/_parallel_backends.py in __init__(self=<sklearn.externals.joblib._parallel_backends.ImmediateResult object>, batch=<sklearn.externals.joblib.parallel.BatchedCalls object>)
    544 
    545 class ImmediateResult(object):
    546     def __init__(self, batch):
    547         # Don't delay the application, to avoid keeping the input
    548         # arguments in memory
--> 549         self.results = batch()
        self.results = undefined
        batch = <sklearn.externals.joblib.parallel.BatchedCalls object>
    550 
    551     def get(self):
    552         return self.results
    553 

...........................................................................
/home/aquemy/.local/lib/python2.7/site-packages/sklearn/externals/joblib/parallel.py in __call__(self=<sklearn.externals.joblib.parallel.BatchedCalls object>)
    220     def __call__(self):
    221         # Set the default nested backend to self._backend but do not set the
    222         # change the default number of processes to -1
    223         with parallel_backend(self._backend, n_jobs=self._n_jobs):
    224             return [func(*args, **kwargs)
--> 225                     for func, args, kwargs in self.items]
        func = <function _parallel_build_trees>
        args = (DecisionTreeClassifier(class_weight=None, criter...=False, random_state=1608637542, splitter='best'), RandomForestClassifier(bootstrap=True, class_wei...se, random_state=42, verbose=0, warm_start=False), array([[ 0.44043723],
       [-0.44756532],
    ....0980415 ],
       [ 2.0061412 ]], dtype=float32), array([[0.],
       [0.],
       [0.],
       [0...    [1.],
       [2.],
       [2.],
       [2.]]), None, 0, 10)
        kwargs = {'class_weight': None, 'verbose': 0}
        self.items = [(<function _parallel_build_trees>, (DecisionTreeClassifier(class_weight=None, criter...=False, random_state=1608637542, splitter='best'), RandomForestClassifier(bootstrap=True, class_wei...se, random_state=42, verbose=0, warm_start=False), array([[ 0.44043723],
       [-0.44756532],
    ....0980415 ],
       [ 2.0061412 ]], dtype=float32), array([[0.],
       [0.],
       [0.],
       [0...    [1.],
       [2.],
       [2.],
       [2.]]), None, 0, 10), {'class_weight': None, 'verbose': 0})]
    226 
    227     def __len__(self):
    228         return self._size
    229 

...........................................................................
/home/aquemy/.local/lib/python2.7/site-packages/sklearn/ensemble/forest.py in _parallel_build_trees(tree=DecisionTreeClassifier(class_weight=None, criter...=False, random_state=1608637542, splitter='best'), forest=RandomForestClassifier(bootstrap=True, class_wei...se, random_state=42, verbose=0, warm_start=False), X=array([[ 0.44043723],
       [-0.44756532],
    ....0980415 ],
       [ 2.0061412 ]], dtype=float32), y=array([[0.],
       [0.],
       [0.],
       [0...    [1.],
       [2.],
       [2.],
       [2.]]), sample_weight=None, tree_idx=0, n_trees=10, verbose=0, class_weight=None)
    114                 simplefilter('ignore', DeprecationWarning)
    115                 curr_sample_weight *= compute_sample_weight('auto', y, indices)
    116         elif class_weight == 'balanced_subsample':
    117             curr_sample_weight *= compute_sample_weight('balanced', y, indices)
    118 
--> 119         tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)
        tree.fit = <bound method DecisionTreeClassifier.fit of Deci...False, random_state=1608637542, splitter='best')>
        X = array([[ 0.44043723],
       [-0.44756532],
    ....0980415 ],
       [ 2.0061412 ]], dtype=float32)
        y = array([[0.],
       [0.],
       [0.],
       [0...    [1.],
       [2.],
       [2.],
       [2.]])
        sample_weight = None
        curr_sample_weight = array([2., 0., 2., 1., 2., 0., 1., 2., 1., 1., 2..., 0., 2., 0., 0., 1., 0., 0., 3., 2.,
       1.])
    120     else:
    121         tree.fit(X, y, sample_weight=sample_weight, check_input=False)
    122 
    123     return tree

...........................................................................
/home/aquemy/.local/lib/python2.7/site-packages/sklearn/tree/tree.py in fit(self=DecisionTreeClassifier(class_weight=None, criter...=False, random_state=1608637542, splitter='best'), X=array([[ 0.44043723],
       [-0.44756532],
    ....0980415 ],
       [ 2.0061412 ]], dtype=float32), y=array([[0.],
       [0.],
       [0.],
       [0...    [1.],
       [2.],
       [2.],
       [2.]]), sample_weight=array([2., 0., 2., 1., 2., 0., 1., 2., 1., 1., 2..., 0., 2., 0., 0., 1., 0., 0., 3., 2.,
       1.]), check_input=False, X_idx_sorted=None)
    796 
    797         super(DecisionTreeClassifier, self).fit(
    798             X, y,
    799             sample_weight=sample_weight,
    800             check_input=check_input,
--> 801             X_idx_sorted=X_idx_sorted)
        X_idx_sorted = None
    802         return self
    803 
    804     def predict_proba(self, X, check_input=True):
    805         """Predict class probabilities of the input samples X.

...........................................................................
/home/aquemy/.local/lib/python2.7/site-packages/sklearn/tree/tree.py in fit(self=DecisionTreeClassifier(class_weight=None, criter...=False, random_state=1608637542, splitter='best'), X=array([[ 0.44043723],
       [-0.44756532],
    ....0980415 ],
       [ 2.0061412 ]], dtype=float32), y=array([[0.],
       [0.],
       [0.],
       [0...    [1.],
       [2.],
       [2.],
       [2.]]), sample_weight=array([2., 0., 2., 1., 2., 0., 1., 2., 1., 1., 2..., 0., 2., 0., 0., 1., 0., 0., 3., 2.,
       1.]), check_input=False, X_idx_sorted=None)
    237         if not 0 <= self.min_weight_fraction_leaf <= 0.5:
    238             raise ValueError("min_weight_fraction_leaf must in [0, 0.5]")
    239         if max_depth <= 0:
    240             raise ValueError("max_depth must be greater than zero. ")
    241         if not (0 < max_features <= self.n_features_):
--> 242             raise ValueError("max_features must be in (0, n_features]")
    243         if not isinstance(max_leaf_nodes, (numbers.Integral, np.integer)):
    244             raise ValueError("max_leaf_nodes must be integral number but was "
    245                              "%r" % max_leaf_nodes)
    246         if -1 < max_leaf_nodes < 2:

ValueError: max_features must be in (0, n_features]
___________________________________________________________________________
Best score: 0.966666666667 (0.0333333333333) [J] | Score: 0.0 (0.0) [J]
Best score: 0.966666666667 (0.0333333333333) [J] | Score: 0.666666666667 (1.11022302463e-16) [J]
Best score: 0.966666666667 (0.0333333333333) [J] | Score: 0.886666666667 (0.0669991708075) [J]
Best score: 0.966666666667 (0.0333333333333) [J] | Score: 0.953333333333 (0.0520683311727) [J]
Best score: 0.966666666667 (0.0333333333333) [J] | Score: 0.96 (0.0442216638714) [J]
Best score: 0.966666666667 (0.0333333333333) [J] | Score: 0.926666666667 (0.0553774924195) [J]
Best score: 0.966666666667 (0.0333333333333) [J] | Score: 0.653333333333 (0.04) [J]
JoblibValueError
___________________________________________________________________________
...........................................................................
/home/aquemy/dev/dp_hyperparameters/extension/main.py in <module>()
     27 
     28     serializer.serialize_results(scenario, policy)
     29 
     30 if __name__ == "__main__":
     31     args = cli.parse_args()
---> 32     main(args)

...........................................................................
/home/aquemy/dev/dp_hyperparameters/extension/main.py in main(args=Namespace(customize=[(['control', 'seed'], '42')...io='./scenarios/rf_iris_joint.yaml', verbosity=0))
     21         test_size=0.4, 
     22         random_state=scenario['control']['seed']
     23     )
     24 
     25     policy = policies.initiate(scenario['setup']['policy'], config)
---> 26     policy.run(X,y)
        policy.run = <bound method Joint.run of <experiment.policies.joint.Joint object>>
        X = array([[5.1, 3.5, 1.4, 0.2],
       [4.9, 3. , 1....2, 3.4, 5.4, 2.3],
       [5.9, 3. , 5.1, 1.8]])
        y = array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,... 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2])
     27 
     28     serializer.serialize_results(scenario, policy)
     29 
     30 if __name__ == "__main__":

...........................................................................
/home/aquemy/dev/dp_hyperparameters/extension/experiment/policies/joint.py in run(self=<experiment.policies.joint.Joint object>, X=array([[5.1, 3.5, 1.4, 0.2],
       [4.9, 3. , 1....2, 3.4, 5.4, 2.3],
       [5.9, 3. , 5.1, 1.8]]), y=array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,... 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]))
     32             algo=tpe.suggest, 
     33             max_evals=None,
     34             max_time=self.config['time'],     
     35             trials=trials,
     36             show_progressbar=False,
---> 37             verbose=0
     38         )
     39 
     40         best_config = self.context['best_config']
     41         super(Joint, self).display_step_results(best_config)

...........................................................................
/home/aquemy/dev/dp_hyperparameters/extension/hyperopt/fmin.py in fmin(fn=<functools.partial object>, space={'algorithm': {'bootstrap': <hyperopt.pyll.base.Apply object>, 'criterion': <hyperopt.pyll.base.Apply object>, 'max_depth': <hyperopt.pyll.base.Apply object>, 'max_features': <hyperopt.pyll.base.Apply object>, 'max_leaf_nodes': <hyperopt.pyll.base.Apply object>, 'min_samples_split': <hyperopt.pyll.base.Apply object>, 'n_estimators': <hyperopt.pyll.base.Apply object>}, 'pipeline': {'features': <hyperopt.pyll.base.Apply object>, 'normalizer': <hyperopt.pyll.base.Apply object>, 'rebalance': <hyperopt.pyll.base.Apply object>}}, algo=<function suggest>, max_evals=9223372036854775807, max_time=300, trials=<hyperopt.base.Trials object>, rstate=<mtrand.RandomState object>, allow_trials_fmin=True, pass_expr_memo_ctrl=None, catch_eval_exceptions=False, verbose=0, return_argmin=True, points_to_evaluate=None, max_queue_len=1, show_progressbar=False)
    406             pass_expr_memo_ctrl=pass_expr_memo_ctrl,
    407             verbose=verbose,
    408             catch_eval_exceptions=catch_eval_exceptions,
    409             return_argmin=return_argmin,
    410             show_progressbar=show_progressbar,
--> 411             max_time=max_time
        max_time = 300
    412         )
    413 
    414     if trials is None:
    415         if points_to_evaluate is None:

...........................................................................
/home/aquemy/dev/dp_hyperparameters/extension/hyperopt/base.py in fmin(self=<hyperopt.base.Trials object>, fn=<functools.partial object>, space={'algorithm': {'bootstrap': <hyperopt.pyll.base.Apply object>, 'criterion': <hyperopt.pyll.base.Apply object>, 'max_depth': <hyperopt.pyll.base.Apply object>, 'max_features': <hyperopt.pyll.base.Apply object>, 'max_leaf_nodes': <hyperopt.pyll.base.Apply object>, 'min_samples_split': <hyperopt.pyll.base.Apply object>, 'n_estimators': <hyperopt.pyll.base.Apply object>}, 'pipeline': {'features': <hyperopt.pyll.base.Apply object>, 'normalizer': <hyperopt.pyll.base.Apply object>, 'rebalance': <hyperopt.pyll.base.Apply object>}}, algo=<function suggest>, max_evals=9223372036854775807, max_time=300, rstate=<mtrand.RandomState object>, verbose=0, pass_expr_memo_ctrl=None, catch_eval_exceptions=False, return_argmin=True, show_progressbar=False)
    636             verbose=verbose,
    637             allow_trials_fmin=False,  # -- prevent recursion
    638             pass_expr_memo_ctrl=pass_expr_memo_ctrl,
    639             catch_eval_exceptions=catch_eval_exceptions,
    640             return_argmin=return_argmin,
--> 641             show_progressbar=show_progressbar)
        show_progressbar = False
    642 
    643 
    644 def trials_from_docs(docs, validate=True, **kwargs):
    645     """Construct a Trials base class instance from a list of trials documents

...........................................................................
/home/aquemy/dev/dp_hyperparameters/extension/hyperopt/fmin.py in fmin(fn=<functools.partial object>, space={'algorithm': {'bootstrap': <hyperopt.pyll.base.Apply object>, 'criterion': <hyperopt.pyll.base.Apply object>, 'max_depth': <hyperopt.pyll.base.Apply object>, 'max_features': <hyperopt.pyll.base.Apply object>, 'max_leaf_nodes': <hyperopt.pyll.base.Apply object>, 'min_samples_split': <hyperopt.pyll.base.Apply object>, 'n_estimators': <hyperopt.pyll.base.Apply object>}, 'pipeline': {'features': <hyperopt.pyll.base.Apply object>, 'normalizer': <hyperopt.pyll.base.Apply object>, 'rebalance': <hyperopt.pyll.base.Apply object>}}, algo=<function suggest>, max_evals=9223372036854775807, max_time=300, trials=<hyperopt.base.Trials object>, rstate=<mtrand.RandomState object>, allow_trials_fmin=False, pass_expr_memo_ctrl=None, catch_eval_exceptions=False, verbose=0, return_argmin=True, points_to_evaluate=None, max_queue_len=1, show_progressbar=False)
    426                     verbose=verbose,
    427                     max_queue_len=max_queue_len,
    428                     show_progressbar=show_progressbar,
    429                     max_time=max_time)
    430     rval.catch_eval_exceptions = catch_eval_exceptions
--> 431     rval.exhaust()
        rval.exhaust = <bound method FMinIter.exhaust of <hyperopt.fmin.FMinIter object>>
    432     if return_argmin:
    433         return trials.argmin
    434     elif len(trials) > 0:
    435         # Only if there are some succesfull trail runs, return the best point in the evaluation space

...........................................................................
/home/aquemy/dev/dp_hyperparameters/extension/hyperopt/fmin.py in exhaust(self=<hyperopt.fmin.FMinIter object>)
    273             raise StopIteration()
    274         return self.trials
    275 
    276     def exhaust(self):
    277         n_done = len(self.trials)
--> 278         self.run(self.max_evals - n_done, block_until_done=self.asynchronous)
        self.run = <bound method FMinIter.run of <hyperopt.fmin.FMinIter object>>
        self.max_evals = 9223372036854775807
        n_done = 0
        self.asynchronous = False
    279         self.trials.refresh()
    280         return self
    281 
    282 

...........................................................................
/home/aquemy/dev/dp_hyperparameters/extension/hyperopt/fmin.py in run(self=<hyperopt.fmin.FMinIter object>, N=9223372036854775807, block_until_done=False)
    232                     if self.asynchronous:
    233                         # -- wait for workers to fill in the trials
    234                         time.sleep(self.poll_interval_secs)
    235                     else:
    236                         # -- loop over trials and do the jobs directly
--> 237                         self.serial_evaluate()
        self.serial_evaluate = <bound method FMinIter.serial_evaluate of <hyperopt.fmin.FMinIter object>>
    238                     try:
    239                         res = [d['result']['loss'] for d in
    240                                          self.trials.trials if
    241                                          d['result']['status'] == 'ok']

...........................................................................
/home/aquemy/dev/dp_hyperparameters/extension/hyperopt/fmin.py in serial_evaluate(self=<hyperopt.fmin.FMinIter object>, N=-1)
    138                 trial['book_time'] = now
    139                 trial['refresh_time'] = now
    140                 spec = base.spec_from_misc(trial['misc'])
    141                 ctrl = base.Ctrl(self.trials, current_trial=trial)
    142                 try:
--> 143                     result = self.domain.evaluate(spec, ctrl)
        result = undefined
        self.domain.evaluate = <bound method Domain.evaluate of <hyperopt.base.Domain object>>
        spec = {'bootstrap': 0, 'criterion': 0, 'features': 3, 'features_FeatureUnion_features__pca__n_components': 0, 'features_FeatureUnion_features__selectkbest__k': 0, 'max_depth': 3, 'max_features': 2, 'max_leaf_nodes': 1, 'min_samples_split': 2, 'n_estimators': 0, ...}
        ctrl = <hyperopt.base.Ctrl object>
    144                 except Exception as e:
    145                     logger.info('job exception: %s' % str(e))
    146                     trial['state'] = base.JOB_STATE_ERROR
    147                     trial['misc']['error'] = (str(type(e)), str(e))

...........................................................................
/home/aquemy/dev/dp_hyperparameters/extension/hyperopt/base.py in evaluate(self=<hyperopt.base.Domain object>, config={'bootstrap': 0, 'criterion': 0, 'features': 3, 'features_FeatureUnion_features__pca__n_components': 0, 'features_FeatureUnion_features__selectkbest__k': 0, 'max_depth': 3, 'max_features': 2, 'max_leaf_nodes': 1, 'min_samples_split': 2, 'n_estimators': 0, ...}, ctrl=<hyperopt.base.Ctrl object>, attach_attachments=True)
    841             #    or the normal Python part (self.fn)
    842             pyll_rval = pyll.rec_eval(
    843                 self.expr,
    844                 memo=memo,
    845                 print_node_on_error=self.rec_eval_print_node_on_error)
--> 846             rval = self.fn(pyll_rval)
        rval = undefined
        self.fn = <functools.partial object>
        pyll_rval = {'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': 4, 'max_features': 3, 'max_leaf_nodes': 3, 'min_samples_split': 5, 'n_estimators': 10}, 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 1, 'features__selectkbest__k': 1}), 'normalizer': ('normalizer_PowerTransformer', {}), 'rebalance': ('rebalance_CondensedNearestNeighbour', {'rebalance__n_neighbors': 1})}}
    847 
    848         if isinstance(rval, (float, int, np.number)):
    849             dict_rval = {'loss': float(rval), 'status': STATUS_OK}
    850         else:

...........................................................................
/home/aquemy/dev/dp_hyperparameters/extension/experiment/objective.py in objective_joint(wconfig={'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': 4, 'max_features': 3, 'max_leaf_nodes': 3, 'min_samples_split': 5, 'n_estimators': 10}, 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 1, 'features__selectkbest__k': 1}), 'normalizer': ('normalizer_PowerTransformer', {}), 'rebalance': ('rebalance_CondensedNearestNeighbour', {'rebalance__n_neighbors': 1})}}, algorithm='RandomForest', X=array([[5.1, 3.5, 1.4, 0.2],
       [4.9, 3. , 1....2, 3.4, 5.4, 2.3],
       [5.9, 3. , 5.1, 1.8]]), y=array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,... 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]), context={'baseline_score': 0.9466666666666667, 'baseline_score_std': 0.04988876515698587, 'best_config': {'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': 4, 'max_features': 3, 'max_leaf_nodes': 3, 'min_samples_split': 3, 'n_estimators': 10}, 'config_hash': {'algorithm': 'ffb7ff225ce3d3712c96cf87fe42202988ee2eb0', 'config': 'bae32f426be9cd6243523c023944a8c148fe4aeb', 'pipeline': 'd2a68bfda6fcdec4ae0ffc7d7b6a2122bc1cd673'}, 'duration': 0.7115809917449951, 'iteration': 113, 'loss': 0.033333333333333215, 'max_history_score': 0.9666666666666668, 'max_history_score_std': 0.033333333333333326, 'max_history_step': 'joint', 'pipeline': {'features': ('features_NoneType', {}), 'normalizer': ('normalizer_PowerTransformer', {}), 'rebalance': ('rebalance_CondensedNearestNeighbour', {'rebalance__n_neighbors': 2})}, 'score': 0.9666666666666668, ...}, 'history': [{'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': 2, 'max_features': None, 'max_leaf_nodes': 5, 'min_samples_split': 2, 'n_estimators': 75}, 'config_hash': {'algorithm': '3af5b0cce71c8fe2545246ca24ff5bc3dd516e06', 'config': 'db6ac7e6d348155757e4794bb5f88fe2b4f63d50', 'pipeline': '8d59f4b94cef6be9306ed86a22a9570fa670d567'}, 'duration': 1.149928092956543, 'iteration': 0, 'loss': 0.046666666666666634, 'max_history_score': 0.9533333333333334, 'max_history_score_std': 0.059999999999999984, 'max_history_step': 'joint', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 4, 'features__selectkbest__k': 3}), 'normalizer': ('normalizer_StandardScaler', {'normalizer__with_mean': True, 'normalizer__with_std': True}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 6})}, 'score': 0.9533333333333334, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': 1, 'max_features': 2, 'max_leaf_nodes': 2, 'min_samples_split': 5, 'n_estimators': 100}, 'config_hash': {'algorithm': 'e13eb05fd9a62d2f63bbb1c1deff0cd620d5e6ab', 'config': '4db6fb84d85f52659f780e682ffac5712c3d8a94', 'pipeline': '64c9a1ca9d53ae67244bdd942f4db36a3c05218c'}, 'duration': 1.7678282260894775, 'iteration': 1, 'loss': 0.18000000000000005, 'max_history_score': 0.9533333333333334, 'max_history_score_std': 0.059999999999999984, 'max_history_step': 'joint', 'pipeline': {'features': ('features_NoneType', {}), 'normalizer': ('normalizer_PowerTransformer', {}), 'rebalance': ('rebalance_NearMiss', {'rebalance__n_neighbors': 1})}, 'score': 0.82, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': 1, 'max_features': None, 'max_leaf_nodes': None, 'min_samples_split': 5, 'n_estimators': 75}, 'config_hash': {'algorithm': '94b0d7a654c508cc63643f78fe4f0f07e6f07c1e', 'config': '4403c5a85e951938d3c454e961d3a412780722f6', 'pipeline': '3e47444880d8367fbac2faaba2e52a917274aa58'}, 'duration': 0.8397619724273682, 'iteration': 2, 'loss': 0.03333333333333344, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_PCA', {'features__n_components': 3}), 'normalizer': ('normalizer_MinMaxScaler', {}), 'rebalance': ('rebalance_NoneType', {})}, 'score': 0.9666666666666666, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': None, 'max_features': None, 'max_leaf_nodes': 3, 'min_samples_split': 3, 'n_estimators': 75}, 'config_hash': {'algorithm': 'e8332f0a8902bda03bf70e7978cc5d52affb29d3', 'config': 'a064e2df18ab98d44dabcefbc7bed94913f1d0be', 'pipeline': '7eea819c2a8c103c4b1e9e9c1e224aebba95081f'}, 'duration': 0.8501448631286621, 'iteration': 3, 'loss': 0.053333333333333344, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 2, 'features__selectkbest__k': 4}), 'normalizer': ('normalizer_NoneType', {}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 7})}, 'score': 0.9466666666666667, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'entropy', 'max_depth': 3, 'max_features': 3, 'max_leaf_nodes': None, 'min_samples_split': 5, 'n_estimators': 75}, 'config_hash': {'algorithm': '7a4491035bc6bd737fe9a8cda8a79a02d02d5c74', 'config': '0ddb6f5cab3db4dddd7682966a57205f3e329ad4', 'pipeline': 'a9ae03fe38334f6868cbf84cdd3d629d4bbe3fb0'}, 'duration': 1.1026010513305664, 'iteration': 4, 'loss': 0.05999999999999994, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 2, 'features__selectkbest__k': 1}), 'normalizer': ('normalizer_NoneType', {}), 'rebalance': ('rebalance_NoneType', {})}, 'score': 0.9400000000000001, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'gini', 'max_depth': 3, 'max_features': 1, 'max_leaf_nodes': 5, 'min_samples_split': 2, 'n_estimators': 25}, 'config_hash': {'algorithm': '9826d20b2d6a0f559cf7f16450ce7526f07e8434', 'config': '49f25751bca61cdd461a8cbd2923689b642f98ed', 'pipeline': '19b249664c5bf067de1fed4334a296f947ce774a'}, 'duration': 0.35647010803222656, 'iteration': 5, 'loss': 0.046666666666666634, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_NoneType', {}), 'normalizer': ('normalizer_NoneType', {}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 6})}, 'score': 0.9533333333333334, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'gini', 'max_depth': 2, 'max_features': 1, 'max_leaf_nodes': 2, 'min_samples_split': 2, 'n_estimators': 50}, 'config_hash': {'algorithm': '0a4f6fbb07e0f32c6f675489a0fc82eee05bd8e1', 'config': '5c3a2b6f5e63fb45f10e41e0318b354912ec44f6', 'pipeline': 'dc3b9f176f090005e38b142f11d80e93a7dc5d5e'}, 'duration': 0.7213859558105469, 'iteration': 6, 'loss': 0.31333333333333324, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 1, 'features__selectkbest__k': 4}), 'normalizer': ('normalizer_PowerTransformer', {}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 7})}, 'score': 0.6866666666666668, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'entropy', 'max_depth': 4, 'max_features': 3, 'max_leaf_nodes': 5, 'min_samples_split': 5, 'n_estimators': 10}, 'config_hash': {'algorithm': 'b8112b97ecfc10f00a195af661dcc861cac21289', 'config': 'd3b129b397350f1b6572651c67c01de49b4b174c', 'pipeline': '5b0357ed7072c37b3d6f458bb5d49ff7d825f603'}, 'duration': 0.8299109935760498, 'iteration': 7, 'loss': 1.0, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_PCA', {'features__n_components': 2}), 'normalizer': ('normalizer_StandardScaler', {'normalizer__with_mean': True, 'normalizer__with_std': False}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 6})}, 'score': 0.0, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'gini', 'max_depth': 4, 'max_features': None, 'max_leaf_nodes': 2, 'min_samples_split': 5, 'n_estimators': 100}, 'config_hash': {'algorithm': '40ca24df19b8d164d9d098a6bed1ce056fbbb961', 'config': '813bde1108cc3c4b9bfb3a22cbb421bda7eac671', 'pipeline': '74a7b8705a1c22f7dea5e44e4ebda8f1e48add71'}, 'duration': 2.2111589908599854, 'iteration': 8, 'loss': 0.33333333333333326, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_PCA', {'features__n_components': 2}), 'normalizer': ('normalizer_StandardScaler', {'normalizer__with_mean': False, 'normalizer__with_std': True}), 'rebalance': ('rebalance_NearMiss', {'rebalance__n_neighbors': 2})}, 'score': 0.6666666666666667, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'entropy', 'max_depth': 2, 'max_features': 1, 'max_leaf_nodes': 5, 'min_samples_split': 2, 'n_estimators': 100}, 'config_hash': {'algorithm': '331418a5c12cf1453876eef85e9d98fc8e54fa11', 'config': '31930b6860ed406d59bf7e59ba1925d94704bd3b', 'pipeline': '054bef356f90ec6f644ef3ffc688766744db51c2'}, 'duration': 1.0501940250396729, 'iteration': 9, 'loss': 0.053333333333333344, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_SelectKBest', {'features__k': 1}), 'normalizer': ('normalizer_RobustScaler', {'normalizer__quantile_range': (...), 'normalizer__with_centering': True, 'normalizer__with_scaling': True}), 'rebalance': ('rebalance_NearMiss', {'rebalance__n_neighbors': 2})}, 'score': 0.9466666666666667, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'entropy', 'max_depth': 3, 'max_features': None, 'max_leaf_nodes': 3, 'min_samples_split': 2, 'n_estimators': 100}, 'config_hash': {'algorithm': 'dbc1b8126649fe93dce5fbb37e4015b0acfb179e', 'config': '9913cd550615a9d0946ab4a755a8b9f619e442fd', 'pipeline': 'dd626121cea079ebb32e184ca65483ec7a6d7f59'}, 'duration': 1.120617151260376, 'iteration': 10, 'loss': 0.046666666666666634, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 2, 'features__selectkbest__k': 1}), 'normalizer': ('normalizer_MinMaxScaler', {}), 'rebalance': ('rebalance_NoneType', {})}, 'score': 0.9533333333333334, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'gini', 'max_depth': 3, 'max_features': 3, 'max_leaf_nodes': None, 'min_samples_split': 3, 'n_estimators': 75}, 'config_hash': {'algorithm': '34917a130df5a975f78bd7ec1a0c7b1ffdc787a9', 'config': '95fc8cadc088141290b7de9c388977e4685f0108', 'pipeline': '550d10faf2f08db48516cc3501558816d6a99bc0'}, 'duration': 1.4287099838256836, 'iteration': 11, 'loss': 0.19333333333333313, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 3, 'features__selectkbest__k': 4}), 'normalizer': ('normalizer_StandardScaler', {'normalizer__with_mean': False, 'normalizer__with_std': False}), 'rebalance': ('rebalance_CondensedNearestNeighbour', {'rebalance__n_neighbors': 1})}, 'score': 0.8066666666666669, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'entropy', 'max_depth': 1, 'max_features': 2, 'max_leaf_nodes': 5, 'min_samples_split': 2, 'n_estimators': 75}, 'config_hash': {'algorithm': '33f9abb4aee44a395a9f3b3ffa9ce80a8cdaed7c', 'config': '40fa726f0360cf6af55f9b5902d399d02f61f157', 'pipeline': 'cfd1d20841fe2153da762c95e79f95a3fb1e426a'}, 'duration': 1.2978079319000244, 'iteration': 12, 'loss': 0.053333333333333344, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_PCA', {'features__n_components': 4}), 'normalizer': ('normalizer_MinMaxScaler', {}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 7})}, 'score': 0.9466666666666667, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'entropy', 'max_depth': 4, 'max_features': 2, 'max_leaf_nodes': 5, 'min_samples_split': 3, 'n_estimators': 25}, 'config_hash': {'algorithm': '210111ec6562d09eb093e98ed69ef1c662e11a50', 'config': '0fb8e77c7bd9a58b72f1b33c21a59a09a8c676ba', 'pipeline': '5d269d759e0c7926a685a14b263ace8ae0071e4b'}, 'duration': 0.36649012565612793, 'iteration': 13, 'loss': 0.040000000000000036, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 2, 'features__selectkbest__k': 2}), 'normalizer': ('normalizer_NoneType', {}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 7})}, 'score': 0.96, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'entropy', 'max_depth': 3, 'max_features': 1, 'max_leaf_nodes': 5, 'min_samples_split': 2, 'n_estimators': 25}, 'config_hash': {'algorithm': '0e989a03980101fabf79eda3326ed2870e11d690', 'config': 'f4bffd5d8c67a9c5321a9943c4a99678f59a02b7', 'pipeline': '865ee1e3fe8334c3d5ecb2038d5a5d1b3ba50e75'}, 'duration': 0.35639500617980957, 'iteration': 14, 'loss': 0.046666666666666634, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_NoneType', {}), 'normalizer': ('normalizer_RobustScaler', {'normalizer__quantile_range': (...), 'normalizer__with_centering': True, 'normalizer__with_scaling': False}), 'rebalance': ('rebalance_NoneType', {})}, 'score': 0.9533333333333334, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'entropy', 'max_depth': None, 'max_features': 3, 'max_leaf_nodes': 3, 'min_samples_split': 5, 'n_estimators': 10}, 'config_hash': {'algorithm': '9c592e876c13de5e23e6de5b868e01755d63e72e', 'config': '1e6a68cd1eeac886d90724d78b1cb5fb76a3cde4', 'pipeline': '5a1ca4d82f21b7de0d2c918630a42510673fa36e'}, 'duration': 0.18141412734985352, 'iteration': 15, 'loss': 0.046666666666666634, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_SelectKBest', {'features__k': 3}), 'normalizer': ('normalizer_RobustScaler', {'normalizer__quantile_range': (...), 'normalizer__with_centering': True, 'normalizer__with_scaling': True}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 6})}, 'score': 0.9533333333333334, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': 1, 'max_features': None, 'max_leaf_nodes': None, 'min_samples_split': 5, 'n_estimators': 10}, 'config_hash': {'algorithm': '8bed77aef289bfd453b2858bd288ae5ba7160f2b', 'config': '781185bcb8999045de8d489f253a1a1ba4247932', 'pipeline': '1ece7eabedc2be9e5b0a1be65c570d08ffa3eb54'}, 'duration': 0.1636829376220703, 'iteration': 16, 'loss': 0.053333333333333344, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_NoneType', {}), 'normalizer': ('normalizer_NoneType', {}), 'rebalance': ('rebalance_NearMiss', {'rebalance__n_neighbors': 1})}, 'score': 0.9466666666666667, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'gini', 'max_depth': 3, 'max_features': 2, 'max_leaf_nodes': 2, 'min_samples_split': 5, 'n_estimators': 75}, 'config_hash': {'algorithm': '617b97d9ba21d3373bc51ffa9cccf9c6f91a77b3', 'config': '99fb425b4e8c5d80228cab94202252aa25cdf77c', 'pipeline': 'd6242929c3b515c7719e60423023ac604311afc3'}, 'duration': 0.8468999862670898, 'iteration': 17, 'loss': 0.24, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_PCA', {'features__n_components': 4}), 'normalizer': ('normalizer_PowerTransformer', {}), 'rebalance': ('rebalance_NearMiss', {'rebalance__n_neighbors': 2})}, 'score': 0.76, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': 1, 'max_features': 1, 'max_leaf_nodes': 2, 'min_samples_split': 5, 'n_estimators': 50}, 'config_hash': {'algorithm': 'b92d2697cdd4979da443369d6596229ec091626a', 'config': 'c513a3e13281206ad76187dd817b1fff93d54fe1', 'pipeline': 'c4b4f914a3ca8df967cade997a90366d85a371b9'}, 'duration': 0.6724588871002197, 'iteration': 18, 'loss': 0.23333333333333328, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 1, 'features__selectkbest__k': 3}), 'normalizer': ('normalizer_StandardScaler', {'normalizer__with_mean': True, 'normalizer__with_std': True}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 5})}, 'score': 0.7666666666666667, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'entropy', 'max_depth': None, 'max_features': None, 'max_leaf_nodes': 5, 'min_samples_split': 5, 'n_estimators': 10}, 'config_hash': {'algorithm': 'a0115de695e6cca2e81cbfb54df79bf4b43608b1', 'config': 'ba194015e20b5d67770e8c67342c3d8d0d01dc41', 'pipeline': '8d45fabfeb85ffdcabf7076bd0e65fffe97ce928'}, 'duration': 0.19424200057983398, 'iteration': 19, 'loss': 0.08666666666666667, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_PCA', {'features__n_components': 3}), 'normalizer': ('normalizer_NoneType', {}), 'rebalance': ('rebalance_NoneType', {})}, 'score': 0.9133333333333333, ...}, ...], 'history_hash': ['db6ac7e6d348155757e4794bb5f88fe2b4f63d50', '4db6fb84d85f52659f780e682ffac5712c3d8a94', '4403c5a85e951938d3c454e961d3a412780722f6', 'a064e2df18ab98d44dabcefbc7bed94913f1d0be', '0ddb6f5cab3db4dddd7682966a57205f3e329ad4', '49f25751bca61cdd461a8cbd2923689b642f98ed', '5c3a2b6f5e63fb45f10e41e0318b354912ec44f6', 'd3b129b397350f1b6572651c67c01de49b4b174c', '813bde1108cc3c4b9bfb3a22cbb421bda7eac671', '31930b6860ed406d59bf7e59ba1925d94704bd3b', '9913cd550615a9d0946ab4a755a8b9f619e442fd', '95fc8cadc088141290b7de9c388977e4685f0108', '40fa726f0360cf6af55f9b5902d399d02f61f157', '0fb8e77c7bd9a58b72f1b33c21a59a09a8c676ba', 'f4bffd5d8c67a9c5321a9943c4a99678f59a02b7', '1e6a68cd1eeac886d90724d78b1cb5fb76a3cde4', '781185bcb8999045de8d489f253a1a1ba4247932', '99fb425b4e8c5d80228cab94202252aa25cdf77c', 'c513a3e13281206ad76187dd817b1fff93d54fe1', 'ba194015e20b5d67770e8c67342c3d8d0d01dc41', ...], 'history_index': {'013329309d510b94f19d930320402d65f953a847': 39, '038a0f515e2ec894ee8e34f9caa2889eb3ebd5ce': 66, '052ae4bf232b316187b078abae42c2be19e16a00': 111, '0659afebf316aafeb75612fb07081a04c28545ed': 74, '06e7cde9f3556cd01332ce389ad1d8925cd4b4a4': 120, '0b6551ecfd6f83a15704a9db68f1599c99c6d3ef': 58, '0ddb6f5cab3db4dddd7682966a57205f3e329ad4': 4, '0fb8e77c7bd9a58b72f1b33c21a59a09a8c676ba': 13, '111e2fd99e871044225b8638df965b2a16868e35': 110, '111ffc790caf02104464bfa2f448cba7c56c71dc': 46, ...}, 'iteration': 158, 'max_history_score': 0.9666666666666668, 'max_history_score_std': 0.033333333333333326, 'max_history_step': 'joint'}, config={'algorithm': 'RandomForest', 'seed': 42, 'time': 300})
    108 
    109 def objective_algo(algo_config, current_pipeline_config, algorithm, X, y, context, config):
    110     return objective(current_pipeline_config, algo_config, algorithm, X, y, context, config, step='algorithm')
    111 
    112 def objective_joint(wconfig, algorithm, X, y, context, config):
--> 113     return objective(wconfig['pipeline'], wconfig['algorithm'], algorithm, X, y, context, config, step='joint')
        wconfig = {'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': 4, 'max_features': 3, 'max_leaf_nodes': 3, 'min_samples_split': 5, 'n_estimators': 10}, 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 1, 'features__selectkbest__k': 1}), 'normalizer': ('normalizer_PowerTransformer', {}), 'rebalance': ('rebalance_CondensedNearestNeighbour', {'rebalance__n_neighbors': 1})}}
        algorithm = 'RandomForest'
        X = array([[5.1, 3.5, 1.4, 0.2],
       [4.9, 3. , 1....2, 3.4, 5.4, 2.3],
       [5.9, 3. , 5.1, 1.8]])
        y = array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,... 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2])
        context = {'baseline_score': 0.9466666666666667, 'baseline_score_std': 0.04988876515698587, 'best_config': {'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': 4, 'max_features': 3, 'max_leaf_nodes': 3, 'min_samples_split': 3, 'n_estimators': 10}, 'config_hash': {'algorithm': 'ffb7ff225ce3d3712c96cf87fe42202988ee2eb0', 'config': 'bae32f426be9cd6243523c023944a8c148fe4aeb', 'pipeline': 'd2a68bfda6fcdec4ae0ffc7d7b6a2122bc1cd673'}, 'duration': 0.7115809917449951, 'iteration': 113, 'loss': 0.033333333333333215, 'max_history_score': 0.9666666666666668, 'max_history_score_std': 0.033333333333333326, 'max_history_step': 'joint', 'pipeline': {'features': ('features_NoneType', {}), 'normalizer': ('normalizer_PowerTransformer', {}), 'rebalance': ('rebalance_CondensedNearestNeighbour', {'rebalance__n_neighbors': 2})}, 'score': 0.9666666666666668, ...}, 'history': [{'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': 2, 'max_features': None, 'max_leaf_nodes': 5, 'min_samples_split': 2, 'n_estimators': 75}, 'config_hash': {'algorithm': '3af5b0cce71c8fe2545246ca24ff5bc3dd516e06', 'config': 'db6ac7e6d348155757e4794bb5f88fe2b4f63d50', 'pipeline': '8d59f4b94cef6be9306ed86a22a9570fa670d567'}, 'duration': 1.149928092956543, 'iteration': 0, 'loss': 0.046666666666666634, 'max_history_score': 0.9533333333333334, 'max_history_score_std': 0.059999999999999984, 'max_history_step': 'joint', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 4, 'features__selectkbest__k': 3}), 'normalizer': ('normalizer_StandardScaler', {'normalizer__with_mean': True, 'normalizer__with_std': True}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 6})}, 'score': 0.9533333333333334, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': 1, 'max_features': 2, 'max_leaf_nodes': 2, 'min_samples_split': 5, 'n_estimators': 100}, 'config_hash': {'algorithm': 'e13eb05fd9a62d2f63bbb1c1deff0cd620d5e6ab', 'config': '4db6fb84d85f52659f780e682ffac5712c3d8a94', 'pipeline': '64c9a1ca9d53ae67244bdd942f4db36a3c05218c'}, 'duration': 1.7678282260894775, 'iteration': 1, 'loss': 0.18000000000000005, 'max_history_score': 0.9533333333333334, 'max_history_score_std': 0.059999999999999984, 'max_history_step': 'joint', 'pipeline': {'features': ('features_NoneType', {}), 'normalizer': ('normalizer_PowerTransformer', {}), 'rebalance': ('rebalance_NearMiss', {'rebalance__n_neighbors': 1})}, 'score': 0.82, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': 1, 'max_features': None, 'max_leaf_nodes': None, 'min_samples_split': 5, 'n_estimators': 75}, 'config_hash': {'algorithm': '94b0d7a654c508cc63643f78fe4f0f07e6f07c1e', 'config': '4403c5a85e951938d3c454e961d3a412780722f6', 'pipeline': '3e47444880d8367fbac2faaba2e52a917274aa58'}, 'duration': 0.8397619724273682, 'iteration': 2, 'loss': 0.03333333333333344, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_PCA', {'features__n_components': 3}), 'normalizer': ('normalizer_MinMaxScaler', {}), 'rebalance': ('rebalance_NoneType', {})}, 'score': 0.9666666666666666, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': None, 'max_features': None, 'max_leaf_nodes': 3, 'min_samples_split': 3, 'n_estimators': 75}, 'config_hash': {'algorithm': 'e8332f0a8902bda03bf70e7978cc5d52affb29d3', 'config': 'a064e2df18ab98d44dabcefbc7bed94913f1d0be', 'pipeline': '7eea819c2a8c103c4b1e9e9c1e224aebba95081f'}, 'duration': 0.8501448631286621, 'iteration': 3, 'loss': 0.053333333333333344, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 2, 'features__selectkbest__k': 4}), 'normalizer': ('normalizer_NoneType', {}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 7})}, 'score': 0.9466666666666667, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'entropy', 'max_depth': 3, 'max_features': 3, 'max_leaf_nodes': None, 'min_samples_split': 5, 'n_estimators': 75}, 'config_hash': {'algorithm': '7a4491035bc6bd737fe9a8cda8a79a02d02d5c74', 'config': '0ddb6f5cab3db4dddd7682966a57205f3e329ad4', 'pipeline': 'a9ae03fe38334f6868cbf84cdd3d629d4bbe3fb0'}, 'duration': 1.1026010513305664, 'iteration': 4, 'loss': 0.05999999999999994, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 2, 'features__selectkbest__k': 1}), 'normalizer': ('normalizer_NoneType', {}), 'rebalance': ('rebalance_NoneType', {})}, 'score': 0.9400000000000001, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'gini', 'max_depth': 3, 'max_features': 1, 'max_leaf_nodes': 5, 'min_samples_split': 2, 'n_estimators': 25}, 'config_hash': {'algorithm': '9826d20b2d6a0f559cf7f16450ce7526f07e8434', 'config': '49f25751bca61cdd461a8cbd2923689b642f98ed', 'pipeline': '19b249664c5bf067de1fed4334a296f947ce774a'}, 'duration': 0.35647010803222656, 'iteration': 5, 'loss': 0.046666666666666634, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_NoneType', {}), 'normalizer': ('normalizer_NoneType', {}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 6})}, 'score': 0.9533333333333334, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'gini', 'max_depth': 2, 'max_features': 1, 'max_leaf_nodes': 2, 'min_samples_split': 2, 'n_estimators': 50}, 'config_hash': {'algorithm': '0a4f6fbb07e0f32c6f675489a0fc82eee05bd8e1', 'config': '5c3a2b6f5e63fb45f10e41e0318b354912ec44f6', 'pipeline': 'dc3b9f176f090005e38b142f11d80e93a7dc5d5e'}, 'duration': 0.7213859558105469, 'iteration': 6, 'loss': 0.31333333333333324, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 1, 'features__selectkbest__k': 4}), 'normalizer': ('normalizer_PowerTransformer', {}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 7})}, 'score': 0.6866666666666668, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'entropy', 'max_depth': 4, 'max_features': 3, 'max_leaf_nodes': 5, 'min_samples_split': 5, 'n_estimators': 10}, 'config_hash': {'algorithm': 'b8112b97ecfc10f00a195af661dcc861cac21289', 'config': 'd3b129b397350f1b6572651c67c01de49b4b174c', 'pipeline': '5b0357ed7072c37b3d6f458bb5d49ff7d825f603'}, 'duration': 0.8299109935760498, 'iteration': 7, 'loss': 1.0, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_PCA', {'features__n_components': 2}), 'normalizer': ('normalizer_StandardScaler', {'normalizer__with_mean': True, 'normalizer__with_std': False}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 6})}, 'score': 0.0, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'gini', 'max_depth': 4, 'max_features': None, 'max_leaf_nodes': 2, 'min_samples_split': 5, 'n_estimators': 100}, 'config_hash': {'algorithm': '40ca24df19b8d164d9d098a6bed1ce056fbbb961', 'config': '813bde1108cc3c4b9bfb3a22cbb421bda7eac671', 'pipeline': '74a7b8705a1c22f7dea5e44e4ebda8f1e48add71'}, 'duration': 2.2111589908599854, 'iteration': 8, 'loss': 0.33333333333333326, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_PCA', {'features__n_components': 2}), 'normalizer': ('normalizer_StandardScaler', {'normalizer__with_mean': False, 'normalizer__with_std': True}), 'rebalance': ('rebalance_NearMiss', {'rebalance__n_neighbors': 2})}, 'score': 0.6666666666666667, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'entropy', 'max_depth': 2, 'max_features': 1, 'max_leaf_nodes': 5, 'min_samples_split': 2, 'n_estimators': 100}, 'config_hash': {'algorithm': '331418a5c12cf1453876eef85e9d98fc8e54fa11', 'config': '31930b6860ed406d59bf7e59ba1925d94704bd3b', 'pipeline': '054bef356f90ec6f644ef3ffc688766744db51c2'}, 'duration': 1.0501940250396729, 'iteration': 9, 'loss': 0.053333333333333344, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_SelectKBest', {'features__k': 1}), 'normalizer': ('normalizer_RobustScaler', {'normalizer__quantile_range': (...), 'normalizer__with_centering': True, 'normalizer__with_scaling': True}), 'rebalance': ('rebalance_NearMiss', {'rebalance__n_neighbors': 2})}, 'score': 0.9466666666666667, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'entropy', 'max_depth': 3, 'max_features': None, 'max_leaf_nodes': 3, 'min_samples_split': 2, 'n_estimators': 100}, 'config_hash': {'algorithm': 'dbc1b8126649fe93dce5fbb37e4015b0acfb179e', 'config': '9913cd550615a9d0946ab4a755a8b9f619e442fd', 'pipeline': 'dd626121cea079ebb32e184ca65483ec7a6d7f59'}, 'duration': 1.120617151260376, 'iteration': 10, 'loss': 0.046666666666666634, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 2, 'features__selectkbest__k': 1}), 'normalizer': ('normalizer_MinMaxScaler', {}), 'rebalance': ('rebalance_NoneType', {})}, 'score': 0.9533333333333334, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'gini', 'max_depth': 3, 'max_features': 3, 'max_leaf_nodes': None, 'min_samples_split': 3, 'n_estimators': 75}, 'config_hash': {'algorithm': '34917a130df5a975f78bd7ec1a0c7b1ffdc787a9', 'config': '95fc8cadc088141290b7de9c388977e4685f0108', 'pipeline': '550d10faf2f08db48516cc3501558816d6a99bc0'}, 'duration': 1.4287099838256836, 'iteration': 11, 'loss': 0.19333333333333313, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 3, 'features__selectkbest__k': 4}), 'normalizer': ('normalizer_StandardScaler', {'normalizer__with_mean': False, 'normalizer__with_std': False}), 'rebalance': ('rebalance_CondensedNearestNeighbour', {'rebalance__n_neighbors': 1})}, 'score': 0.8066666666666669, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'entropy', 'max_depth': 1, 'max_features': 2, 'max_leaf_nodes': 5, 'min_samples_split': 2, 'n_estimators': 75}, 'config_hash': {'algorithm': '33f9abb4aee44a395a9f3b3ffa9ce80a8cdaed7c', 'config': '40fa726f0360cf6af55f9b5902d399d02f61f157', 'pipeline': 'cfd1d20841fe2153da762c95e79f95a3fb1e426a'}, 'duration': 1.2978079319000244, 'iteration': 12, 'loss': 0.053333333333333344, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_PCA', {'features__n_components': 4}), 'normalizer': ('normalizer_MinMaxScaler', {}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 7})}, 'score': 0.9466666666666667, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'entropy', 'max_depth': 4, 'max_features': 2, 'max_leaf_nodes': 5, 'min_samples_split': 3, 'n_estimators': 25}, 'config_hash': {'algorithm': '210111ec6562d09eb093e98ed69ef1c662e11a50', 'config': '0fb8e77c7bd9a58b72f1b33c21a59a09a8c676ba', 'pipeline': '5d269d759e0c7926a685a14b263ace8ae0071e4b'}, 'duration': 0.36649012565612793, 'iteration': 13, 'loss': 0.040000000000000036, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 2, 'features__selectkbest__k': 2}), 'normalizer': ('normalizer_NoneType', {}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 7})}, 'score': 0.96, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'entropy', 'max_depth': 3, 'max_features': 1, 'max_leaf_nodes': 5, 'min_samples_split': 2, 'n_estimators': 25}, 'config_hash': {'algorithm': '0e989a03980101fabf79eda3326ed2870e11d690', 'config': 'f4bffd5d8c67a9c5321a9943c4a99678f59a02b7', 'pipeline': '865ee1e3fe8334c3d5ecb2038d5a5d1b3ba50e75'}, 'duration': 0.35639500617980957, 'iteration': 14, 'loss': 0.046666666666666634, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_NoneType', {}), 'normalizer': ('normalizer_RobustScaler', {'normalizer__quantile_range': (...), 'normalizer__with_centering': True, 'normalizer__with_scaling': False}), 'rebalance': ('rebalance_NoneType', {})}, 'score': 0.9533333333333334, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'entropy', 'max_depth': None, 'max_features': 3, 'max_leaf_nodes': 3, 'min_samples_split': 5, 'n_estimators': 10}, 'config_hash': {'algorithm': '9c592e876c13de5e23e6de5b868e01755d63e72e', 'config': '1e6a68cd1eeac886d90724d78b1cb5fb76a3cde4', 'pipeline': '5a1ca4d82f21b7de0d2c918630a42510673fa36e'}, 'duration': 0.18141412734985352, 'iteration': 15, 'loss': 0.046666666666666634, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_SelectKBest', {'features__k': 3}), 'normalizer': ('normalizer_RobustScaler', {'normalizer__quantile_range': (...), 'normalizer__with_centering': True, 'normalizer__with_scaling': True}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 6})}, 'score': 0.9533333333333334, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': 1, 'max_features': None, 'max_leaf_nodes': None, 'min_samples_split': 5, 'n_estimators': 10}, 'config_hash': {'algorithm': '8bed77aef289bfd453b2858bd288ae5ba7160f2b', 'config': '781185bcb8999045de8d489f253a1a1ba4247932', 'pipeline': '1ece7eabedc2be9e5b0a1be65c570d08ffa3eb54'}, 'duration': 0.1636829376220703, 'iteration': 16, 'loss': 0.053333333333333344, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_NoneType', {}), 'normalizer': ('normalizer_NoneType', {}), 'rebalance': ('rebalance_NearMiss', {'rebalance__n_neighbors': 1})}, 'score': 0.9466666666666667, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'gini', 'max_depth': 3, 'max_features': 2, 'max_leaf_nodes': 2, 'min_samples_split': 5, 'n_estimators': 75}, 'config_hash': {'algorithm': '617b97d9ba21d3373bc51ffa9cccf9c6f91a77b3', 'config': '99fb425b4e8c5d80228cab94202252aa25cdf77c', 'pipeline': 'd6242929c3b515c7719e60423023ac604311afc3'}, 'duration': 0.8468999862670898, 'iteration': 17, 'loss': 0.24, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_PCA', {'features__n_components': 4}), 'normalizer': ('normalizer_PowerTransformer', {}), 'rebalance': ('rebalance_NearMiss', {'rebalance__n_neighbors': 2})}, 'score': 0.76, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': 1, 'max_features': 1, 'max_leaf_nodes': 2, 'min_samples_split': 5, 'n_estimators': 50}, 'config_hash': {'algorithm': 'b92d2697cdd4979da443369d6596229ec091626a', 'config': 'c513a3e13281206ad76187dd817b1fff93d54fe1', 'pipeline': 'c4b4f914a3ca8df967cade997a90366d85a371b9'}, 'duration': 0.6724588871002197, 'iteration': 18, 'loss': 0.23333333333333328, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 1, 'features__selectkbest__k': 3}), 'normalizer': ('normalizer_StandardScaler', {'normalizer__with_mean': True, 'normalizer__with_std': True}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 5})}, 'score': 0.7666666666666667, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'entropy', 'max_depth': None, 'max_features': None, 'max_leaf_nodes': 5, 'min_samples_split': 5, 'n_estimators': 10}, 'config_hash': {'algorithm': 'a0115de695e6cca2e81cbfb54df79bf4b43608b1', 'config': 'ba194015e20b5d67770e8c67342c3d8d0d01dc41', 'pipeline': '8d45fabfeb85ffdcabf7076bd0e65fffe97ce928'}, 'duration': 0.19424200057983398, 'iteration': 19, 'loss': 0.08666666666666667, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_PCA', {'features__n_components': 3}), 'normalizer': ('normalizer_NoneType', {}), 'rebalance': ('rebalance_NoneType', {})}, 'score': 0.9133333333333333, ...}, ...], 'history_hash': ['db6ac7e6d348155757e4794bb5f88fe2b4f63d50', '4db6fb84d85f52659f780e682ffac5712c3d8a94', '4403c5a85e951938d3c454e961d3a412780722f6', 'a064e2df18ab98d44dabcefbc7bed94913f1d0be', '0ddb6f5cab3db4dddd7682966a57205f3e329ad4', '49f25751bca61cdd461a8cbd2923689b642f98ed', '5c3a2b6f5e63fb45f10e41e0318b354912ec44f6', 'd3b129b397350f1b6572651c67c01de49b4b174c', '813bde1108cc3c4b9bfb3a22cbb421bda7eac671', '31930b6860ed406d59bf7e59ba1925d94704bd3b', '9913cd550615a9d0946ab4a755a8b9f619e442fd', '95fc8cadc088141290b7de9c388977e4685f0108', '40fa726f0360cf6af55f9b5902d399d02f61f157', '0fb8e77c7bd9a58b72f1b33c21a59a09a8c676ba', 'f4bffd5d8c67a9c5321a9943c4a99678f59a02b7', '1e6a68cd1eeac886d90724d78b1cb5fb76a3cde4', '781185bcb8999045de8d489f253a1a1ba4247932', '99fb425b4e8c5d80228cab94202252aa25cdf77c', 'c513a3e13281206ad76187dd817b1fff93d54fe1', 'ba194015e20b5d67770e8c67342c3d8d0d01dc41', ...], 'history_index': {'013329309d510b94f19d930320402d65f953a847': 39, '038a0f515e2ec894ee8e34f9caa2889eb3ebd5ce': 66, '052ae4bf232b316187b078abae42c2be19e16a00': 111, '0659afebf316aafeb75612fb07081a04c28545ed': 74, '06e7cde9f3556cd01332ce389ad1d8925cd4b4a4': 120, '0b6551ecfd6f83a15704a9db68f1599c99c6d3ef': 58, '0ddb6f5cab3db4dddd7682966a57205f3e329ad4': 4, '0fb8e77c7bd9a58b72f1b33c21a59a09a8c676ba': 13, '111e2fd99e871044225b8638df965b2a16868e35': 110, '111ffc790caf02104464bfa2f448cba7c56c71dc': 46, ...}, 'iteration': 158, 'max_history_score': 0.9666666666666668, 'max_history_score_std': 0.033333333333333326, 'max_history_step': 'joint'}
        config = {'algorithm': 'RandomForest', 'seed': 42, 'time': 300}
    114 
    115 
    116 def get_baseline_score(algorithm, X, y, seed):
    117     pipeline, _ = pipeline_conf_to_full_pipeline(

...........................................................................
/home/aquemy/dev/dp_hyperparameters/extension/experiment/objective.py in objective(pipeline_config={'features': ('features_FeatureUnion', {'features__pca__n_components': 1, 'features__selectkbest__k': 1}), 'normalizer': ('normalizer_PowerTransformer', {}), 'rebalance': ('rebalance_CondensedNearestNeighbour', {'rebalance__n_neighbors': 1})}, algo_config={'bootstrap': True, 'criterion': 'gini', 'max_depth': 4, 'max_features': 3, 'max_leaf_nodes': 3, 'min_samples_split': 5, 'n_estimators': 10}, algorithm='RandomForest', X=array([[5.1, 3.5, 1.4, 0.2],
       [4.9, 3. , 1....2, 3.4, 5.4, 2.3],
       [5.9, 3. , 5.1, 1.8]]), y=array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,... 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]), context={'baseline_score': 0.9466666666666667, 'baseline_score_std': 0.04988876515698587, 'best_config': {'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': 4, 'max_features': 3, 'max_leaf_nodes': 3, 'min_samples_split': 3, 'n_estimators': 10}, 'config_hash': {'algorithm': 'ffb7ff225ce3d3712c96cf87fe42202988ee2eb0', 'config': 'bae32f426be9cd6243523c023944a8c148fe4aeb', 'pipeline': 'd2a68bfda6fcdec4ae0ffc7d7b6a2122bc1cd673'}, 'duration': 0.7115809917449951, 'iteration': 113, 'loss': 0.033333333333333215, 'max_history_score': 0.9666666666666668, 'max_history_score_std': 0.033333333333333326, 'max_history_step': 'joint', 'pipeline': {'features': ('features_NoneType', {}), 'normalizer': ('normalizer_PowerTransformer', {}), 'rebalance': ('rebalance_CondensedNearestNeighbour', {'rebalance__n_neighbors': 2})}, 'score': 0.9666666666666668, ...}, 'history': [{'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': 2, 'max_features': None, 'max_leaf_nodes': 5, 'min_samples_split': 2, 'n_estimators': 75}, 'config_hash': {'algorithm': '3af5b0cce71c8fe2545246ca24ff5bc3dd516e06', 'config': 'db6ac7e6d348155757e4794bb5f88fe2b4f63d50', 'pipeline': '8d59f4b94cef6be9306ed86a22a9570fa670d567'}, 'duration': 1.149928092956543, 'iteration': 0, 'loss': 0.046666666666666634, 'max_history_score': 0.9533333333333334, 'max_history_score_std': 0.059999999999999984, 'max_history_step': 'joint', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 4, 'features__selectkbest__k': 3}), 'normalizer': ('normalizer_StandardScaler', {'normalizer__with_mean': True, 'normalizer__with_std': True}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 6})}, 'score': 0.9533333333333334, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': 1, 'max_features': 2, 'max_leaf_nodes': 2, 'min_samples_split': 5, 'n_estimators': 100}, 'config_hash': {'algorithm': 'e13eb05fd9a62d2f63bbb1c1deff0cd620d5e6ab', 'config': '4db6fb84d85f52659f780e682ffac5712c3d8a94', 'pipeline': '64c9a1ca9d53ae67244bdd942f4db36a3c05218c'}, 'duration': 1.7678282260894775, 'iteration': 1, 'loss': 0.18000000000000005, 'max_history_score': 0.9533333333333334, 'max_history_score_std': 0.059999999999999984, 'max_history_step': 'joint', 'pipeline': {'features': ('features_NoneType', {}), 'normalizer': ('normalizer_PowerTransformer', {}), 'rebalance': ('rebalance_NearMiss', {'rebalance__n_neighbors': 1})}, 'score': 0.82, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': 1, 'max_features': None, 'max_leaf_nodes': None, 'min_samples_split': 5, 'n_estimators': 75}, 'config_hash': {'algorithm': '94b0d7a654c508cc63643f78fe4f0f07e6f07c1e', 'config': '4403c5a85e951938d3c454e961d3a412780722f6', 'pipeline': '3e47444880d8367fbac2faaba2e52a917274aa58'}, 'duration': 0.8397619724273682, 'iteration': 2, 'loss': 0.03333333333333344, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_PCA', {'features__n_components': 3}), 'normalizer': ('normalizer_MinMaxScaler', {}), 'rebalance': ('rebalance_NoneType', {})}, 'score': 0.9666666666666666, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': None, 'max_features': None, 'max_leaf_nodes': 3, 'min_samples_split': 3, 'n_estimators': 75}, 'config_hash': {'algorithm': 'e8332f0a8902bda03bf70e7978cc5d52affb29d3', 'config': 'a064e2df18ab98d44dabcefbc7bed94913f1d0be', 'pipeline': '7eea819c2a8c103c4b1e9e9c1e224aebba95081f'}, 'duration': 0.8501448631286621, 'iteration': 3, 'loss': 0.053333333333333344, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 2, 'features__selectkbest__k': 4}), 'normalizer': ('normalizer_NoneType', {}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 7})}, 'score': 0.9466666666666667, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'entropy', 'max_depth': 3, 'max_features': 3, 'max_leaf_nodes': None, 'min_samples_split': 5, 'n_estimators': 75}, 'config_hash': {'algorithm': '7a4491035bc6bd737fe9a8cda8a79a02d02d5c74', 'config': '0ddb6f5cab3db4dddd7682966a57205f3e329ad4', 'pipeline': 'a9ae03fe38334f6868cbf84cdd3d629d4bbe3fb0'}, 'duration': 1.1026010513305664, 'iteration': 4, 'loss': 0.05999999999999994, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 2, 'features__selectkbest__k': 1}), 'normalizer': ('normalizer_NoneType', {}), 'rebalance': ('rebalance_NoneType', {})}, 'score': 0.9400000000000001, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'gini', 'max_depth': 3, 'max_features': 1, 'max_leaf_nodes': 5, 'min_samples_split': 2, 'n_estimators': 25}, 'config_hash': {'algorithm': '9826d20b2d6a0f559cf7f16450ce7526f07e8434', 'config': '49f25751bca61cdd461a8cbd2923689b642f98ed', 'pipeline': '19b249664c5bf067de1fed4334a296f947ce774a'}, 'duration': 0.35647010803222656, 'iteration': 5, 'loss': 0.046666666666666634, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_NoneType', {}), 'normalizer': ('normalizer_NoneType', {}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 6})}, 'score': 0.9533333333333334, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'gini', 'max_depth': 2, 'max_features': 1, 'max_leaf_nodes': 2, 'min_samples_split': 2, 'n_estimators': 50}, 'config_hash': {'algorithm': '0a4f6fbb07e0f32c6f675489a0fc82eee05bd8e1', 'config': '5c3a2b6f5e63fb45f10e41e0318b354912ec44f6', 'pipeline': 'dc3b9f176f090005e38b142f11d80e93a7dc5d5e'}, 'duration': 0.7213859558105469, 'iteration': 6, 'loss': 0.31333333333333324, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 1, 'features__selectkbest__k': 4}), 'normalizer': ('normalizer_PowerTransformer', {}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 7})}, 'score': 0.6866666666666668, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'entropy', 'max_depth': 4, 'max_features': 3, 'max_leaf_nodes': 5, 'min_samples_split': 5, 'n_estimators': 10}, 'config_hash': {'algorithm': 'b8112b97ecfc10f00a195af661dcc861cac21289', 'config': 'd3b129b397350f1b6572651c67c01de49b4b174c', 'pipeline': '5b0357ed7072c37b3d6f458bb5d49ff7d825f603'}, 'duration': 0.8299109935760498, 'iteration': 7, 'loss': 1.0, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_PCA', {'features__n_components': 2}), 'normalizer': ('normalizer_StandardScaler', {'normalizer__with_mean': True, 'normalizer__with_std': False}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 6})}, 'score': 0.0, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'gini', 'max_depth': 4, 'max_features': None, 'max_leaf_nodes': 2, 'min_samples_split': 5, 'n_estimators': 100}, 'config_hash': {'algorithm': '40ca24df19b8d164d9d098a6bed1ce056fbbb961', 'config': '813bde1108cc3c4b9bfb3a22cbb421bda7eac671', 'pipeline': '74a7b8705a1c22f7dea5e44e4ebda8f1e48add71'}, 'duration': 2.2111589908599854, 'iteration': 8, 'loss': 0.33333333333333326, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_PCA', {'features__n_components': 2}), 'normalizer': ('normalizer_StandardScaler', {'normalizer__with_mean': False, 'normalizer__with_std': True}), 'rebalance': ('rebalance_NearMiss', {'rebalance__n_neighbors': 2})}, 'score': 0.6666666666666667, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'entropy', 'max_depth': 2, 'max_features': 1, 'max_leaf_nodes': 5, 'min_samples_split': 2, 'n_estimators': 100}, 'config_hash': {'algorithm': '331418a5c12cf1453876eef85e9d98fc8e54fa11', 'config': '31930b6860ed406d59bf7e59ba1925d94704bd3b', 'pipeline': '054bef356f90ec6f644ef3ffc688766744db51c2'}, 'duration': 1.0501940250396729, 'iteration': 9, 'loss': 0.053333333333333344, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_SelectKBest', {'features__k': 1}), 'normalizer': ('normalizer_RobustScaler', {'normalizer__quantile_range': (...), 'normalizer__with_centering': True, 'normalizer__with_scaling': True}), 'rebalance': ('rebalance_NearMiss', {'rebalance__n_neighbors': 2})}, 'score': 0.9466666666666667, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'entropy', 'max_depth': 3, 'max_features': None, 'max_leaf_nodes': 3, 'min_samples_split': 2, 'n_estimators': 100}, 'config_hash': {'algorithm': 'dbc1b8126649fe93dce5fbb37e4015b0acfb179e', 'config': '9913cd550615a9d0946ab4a755a8b9f619e442fd', 'pipeline': 'dd626121cea079ebb32e184ca65483ec7a6d7f59'}, 'duration': 1.120617151260376, 'iteration': 10, 'loss': 0.046666666666666634, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 2, 'features__selectkbest__k': 1}), 'normalizer': ('normalizer_MinMaxScaler', {}), 'rebalance': ('rebalance_NoneType', {})}, 'score': 0.9533333333333334, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'gini', 'max_depth': 3, 'max_features': 3, 'max_leaf_nodes': None, 'min_samples_split': 3, 'n_estimators': 75}, 'config_hash': {'algorithm': '34917a130df5a975f78bd7ec1a0c7b1ffdc787a9', 'config': '95fc8cadc088141290b7de9c388977e4685f0108', 'pipeline': '550d10faf2f08db48516cc3501558816d6a99bc0'}, 'duration': 1.4287099838256836, 'iteration': 11, 'loss': 0.19333333333333313, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 3, 'features__selectkbest__k': 4}), 'normalizer': ('normalizer_StandardScaler', {'normalizer__with_mean': False, 'normalizer__with_std': False}), 'rebalance': ('rebalance_CondensedNearestNeighbour', {'rebalance__n_neighbors': 1})}, 'score': 0.8066666666666669, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'entropy', 'max_depth': 1, 'max_features': 2, 'max_leaf_nodes': 5, 'min_samples_split': 2, 'n_estimators': 75}, 'config_hash': {'algorithm': '33f9abb4aee44a395a9f3b3ffa9ce80a8cdaed7c', 'config': '40fa726f0360cf6af55f9b5902d399d02f61f157', 'pipeline': 'cfd1d20841fe2153da762c95e79f95a3fb1e426a'}, 'duration': 1.2978079319000244, 'iteration': 12, 'loss': 0.053333333333333344, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_PCA', {'features__n_components': 4}), 'normalizer': ('normalizer_MinMaxScaler', {}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 7})}, 'score': 0.9466666666666667, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'entropy', 'max_depth': 4, 'max_features': 2, 'max_leaf_nodes': 5, 'min_samples_split': 3, 'n_estimators': 25}, 'config_hash': {'algorithm': '210111ec6562d09eb093e98ed69ef1c662e11a50', 'config': '0fb8e77c7bd9a58b72f1b33c21a59a09a8c676ba', 'pipeline': '5d269d759e0c7926a685a14b263ace8ae0071e4b'}, 'duration': 0.36649012565612793, 'iteration': 13, 'loss': 0.040000000000000036, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 2, 'features__selectkbest__k': 2}), 'normalizer': ('normalizer_NoneType', {}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 7})}, 'score': 0.96, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'entropy', 'max_depth': 3, 'max_features': 1, 'max_leaf_nodes': 5, 'min_samples_split': 2, 'n_estimators': 25}, 'config_hash': {'algorithm': '0e989a03980101fabf79eda3326ed2870e11d690', 'config': 'f4bffd5d8c67a9c5321a9943c4a99678f59a02b7', 'pipeline': '865ee1e3fe8334c3d5ecb2038d5a5d1b3ba50e75'}, 'duration': 0.35639500617980957, 'iteration': 14, 'loss': 0.046666666666666634, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_NoneType', {}), 'normalizer': ('normalizer_RobustScaler', {'normalizer__quantile_range': (...), 'normalizer__with_centering': True, 'normalizer__with_scaling': False}), 'rebalance': ('rebalance_NoneType', {})}, 'score': 0.9533333333333334, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'entropy', 'max_depth': None, 'max_features': 3, 'max_leaf_nodes': 3, 'min_samples_split': 5, 'n_estimators': 10}, 'config_hash': {'algorithm': '9c592e876c13de5e23e6de5b868e01755d63e72e', 'config': '1e6a68cd1eeac886d90724d78b1cb5fb76a3cde4', 'pipeline': '5a1ca4d82f21b7de0d2c918630a42510673fa36e'}, 'duration': 0.18141412734985352, 'iteration': 15, 'loss': 0.046666666666666634, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_SelectKBest', {'features__k': 3}), 'normalizer': ('normalizer_RobustScaler', {'normalizer__quantile_range': (...), 'normalizer__with_centering': True, 'normalizer__with_scaling': True}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 6})}, 'score': 0.9533333333333334, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': 1, 'max_features': None, 'max_leaf_nodes': None, 'min_samples_split': 5, 'n_estimators': 10}, 'config_hash': {'algorithm': '8bed77aef289bfd453b2858bd288ae5ba7160f2b', 'config': '781185bcb8999045de8d489f253a1a1ba4247932', 'pipeline': '1ece7eabedc2be9e5b0a1be65c570d08ffa3eb54'}, 'duration': 0.1636829376220703, 'iteration': 16, 'loss': 0.053333333333333344, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_NoneType', {}), 'normalizer': ('normalizer_NoneType', {}), 'rebalance': ('rebalance_NearMiss', {'rebalance__n_neighbors': 1})}, 'score': 0.9466666666666667, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'gini', 'max_depth': 3, 'max_features': 2, 'max_leaf_nodes': 2, 'min_samples_split': 5, 'n_estimators': 75}, 'config_hash': {'algorithm': '617b97d9ba21d3373bc51ffa9cccf9c6f91a77b3', 'config': '99fb425b4e8c5d80228cab94202252aa25cdf77c', 'pipeline': 'd6242929c3b515c7719e60423023ac604311afc3'}, 'duration': 0.8468999862670898, 'iteration': 17, 'loss': 0.24, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_PCA', {'features__n_components': 4}), 'normalizer': ('normalizer_PowerTransformer', {}), 'rebalance': ('rebalance_NearMiss', {'rebalance__n_neighbors': 2})}, 'score': 0.76, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': 1, 'max_features': 1, 'max_leaf_nodes': 2, 'min_samples_split': 5, 'n_estimators': 50}, 'config_hash': {'algorithm': 'b92d2697cdd4979da443369d6596229ec091626a', 'config': 'c513a3e13281206ad76187dd817b1fff93d54fe1', 'pipeline': 'c4b4f914a3ca8df967cade997a90366d85a371b9'}, 'duration': 0.6724588871002197, 'iteration': 18, 'loss': 0.23333333333333328, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 1, 'features__selectkbest__k': 3}), 'normalizer': ('normalizer_StandardScaler', {'normalizer__with_mean': True, 'normalizer__with_std': True}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 5})}, 'score': 0.7666666666666667, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'entropy', 'max_depth': None, 'max_features': None, 'max_leaf_nodes': 5, 'min_samples_split': 5, 'n_estimators': 10}, 'config_hash': {'algorithm': 'a0115de695e6cca2e81cbfb54df79bf4b43608b1', 'config': 'ba194015e20b5d67770e8c67342c3d8d0d01dc41', 'pipeline': '8d45fabfeb85ffdcabf7076bd0e65fffe97ce928'}, 'duration': 0.19424200057983398, 'iteration': 19, 'loss': 0.08666666666666667, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_PCA', {'features__n_components': 3}), 'normalizer': ('normalizer_NoneType', {}), 'rebalance': ('rebalance_NoneType', {})}, 'score': 0.9133333333333333, ...}, ...], 'history_hash': ['db6ac7e6d348155757e4794bb5f88fe2b4f63d50', '4db6fb84d85f52659f780e682ffac5712c3d8a94', '4403c5a85e951938d3c454e961d3a412780722f6', 'a064e2df18ab98d44dabcefbc7bed94913f1d0be', '0ddb6f5cab3db4dddd7682966a57205f3e329ad4', '49f25751bca61cdd461a8cbd2923689b642f98ed', '5c3a2b6f5e63fb45f10e41e0318b354912ec44f6', 'd3b129b397350f1b6572651c67c01de49b4b174c', '813bde1108cc3c4b9bfb3a22cbb421bda7eac671', '31930b6860ed406d59bf7e59ba1925d94704bd3b', '9913cd550615a9d0946ab4a755a8b9f619e442fd', '95fc8cadc088141290b7de9c388977e4685f0108', '40fa726f0360cf6af55f9b5902d399d02f61f157', '0fb8e77c7bd9a58b72f1b33c21a59a09a8c676ba', 'f4bffd5d8c67a9c5321a9943c4a99678f59a02b7', '1e6a68cd1eeac886d90724d78b1cb5fb76a3cde4', '781185bcb8999045de8d489f253a1a1ba4247932', '99fb425b4e8c5d80228cab94202252aa25cdf77c', 'c513a3e13281206ad76187dd817b1fff93d54fe1', 'ba194015e20b5d67770e8c67342c3d8d0d01dc41', ...], 'history_index': {'013329309d510b94f19d930320402d65f953a847': 39, '038a0f515e2ec894ee8e34f9caa2889eb3ebd5ce': 66, '052ae4bf232b316187b078abae42c2be19e16a00': 111, '0659afebf316aafeb75612fb07081a04c28545ed': 74, '06e7cde9f3556cd01332ce389ad1d8925cd4b4a4': 120, '0b6551ecfd6f83a15704a9db68f1599c99c6d3ef': 58, '0ddb6f5cab3db4dddd7682966a57205f3e329ad4': 4, '0fb8e77c7bd9a58b72f1b33c21a59a09a8c676ba': 13, '111e2fd99e871044225b8638df965b2a16868e35': 110, '111ffc790caf02104464bfa2f448cba7c56c71dc': 46, ...}, 'iteration': 158, 'max_history_score': 0.9666666666666668, 'max_history_score_std': 0.033333333333333326, 'max_history_step': 'joint'}, config={'algorithm': 'RandomForest', 'seed': 42, 'time': 300}, step='joint')
     45                 y,
     46                 cv=10,
     47                 n_jobs=-1,
     48                 return_estimator=False,
     49                 return_train_score=False,
---> 50                 verbose=0)
     51         score = np.mean(scores['test_score'])
     52         std = np.std(scores['test_score'])
     53         status = STATUS_OK
     54     except Exception as e:

...........................................................................
/home/aquemy/.local/lib/python2.7/site-packages/sklearn/model_selection/_validation.py in cross_validate(estimator=Pipeline(memory=None,
     steps=[('rebalance', ... random_state=42, verbose=0, warm_start=False))]), X=array([[5.1, 3.5, 1.4, 0.2],
       [4.9, 3. , 1....2, 3.4, 5.4, 2.3],
       [5.9, 3. , 5.1, 1.8]]), y=array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,... 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]), groups=None, scoring=None, cv=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1, verbose=0, fit_params=None, pre_dispatch='2*n_jobs', return_train_score=False, return_estimator=False, error_score='raise-deprecating')
    235         delayed(_fit_and_score)(
    236             clone(estimator), X, y, scorers, train, test, verbose, None,
    237             fit_params, return_train_score=return_train_score,
    238             return_times=True, return_estimator=return_estimator,
    239             error_score=error_score)
--> 240         for train, test in cv.split(X, y, groups))
        cv.split = <bound method StratifiedKFold.split of Stratifie...d(n_splits=10, random_state=None, shuffle=False)>
        X = array([[5.1, 3.5, 1.4, 0.2],
       [4.9, 3. , 1....2, 3.4, 5.4, 2.3],
       [5.9, 3. , 5.1, 1.8]])
        y = array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,... 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2])
        groups = None
    241 
    242     zipped_scores = list(zip(*scores))
    243     if return_train_score:
    244         train_scores = zipped_scores.pop(0)

...........................................................................
/home/aquemy/.local/lib/python2.7/site-packages/sklearn/externals/joblib/parallel.py in __call__(self=Parallel(n_jobs=-1), iterable=<generator object <genexpr>>)
    925                 # No need to wait for async callbacks to trigger to
    926                 # consumption.
    927                 self._iterating = False
    928 
    929             with self._backend.retrieval_context():
--> 930                 self.retrieve()
        self.retrieve = <bound method Parallel.retrieve of Parallel(n_jobs=-1)>
    931             # Make sure that we get a last message telling us we are done
    932             elapsed_time = time.time() - self._start_time
    933             self._print('Done %3i out of %3i | elapsed: %s finished',
    934                         (len(self._output), len(self._output),

---------------------------------------------------------------------------
Joblib worker traceback:
---------------------------------------------------------------------------
ValueError                                         Mon Jun 17 13:12:47 2019
PID: 21176                                  Python 2.7.15+: /usr/bin/python
...........................................................................
/home/aquemy/.local/lib/python2.7/site-packages/sklearn/externals/joblib/parallel.py in __call__(self=<sklearn.externals.joblib.parallel.BatchedCalls object>)
    220     def __call__(self):
    221         # Set the default nested backend to self._backend but do not set the
    222         # change the default number of processes to -1
    223         with parallel_backend(self._backend, n_jobs=self._n_jobs):
    224             return [func(*args, **kwargs)
--> 225                     for func, args, kwargs in self.items]
        func = <function _fit_and_score>
        args = (Pipeline(memory=None,
     steps=[('rebalance', ... random_state=42, verbose=0, warm_start=False))]), array([[5.1, 3.5, 1.4, 0.2],
       [4.9, 3. , 1....2, 3.4, 5.4, 2.3],
       [5.9, 3. , 5.1, 1.8]]), array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,... 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]), {'score': <function _passthrough_scorer>}, array([  5,   6,   7,   8,   9,  10,  11,  12,  ..., 142, 143, 144,
       145, 146, 147, 148, 149]), array([  0,   1,   2,   3,   4,  50,  51,  52,  53,  54, 100, 101, 102,
       103, 104]), 0, None, None)
        kwargs = {'error_score': 'raise-deprecating', 'return_estimator': False, 'return_times': True, 'return_train_score': False}
        self.items = [(<function _fit_and_score>, (Pipeline(memory=None,
     steps=[('rebalance', ... random_state=42, verbose=0, warm_start=False))]), array([[5.1, 3.5, 1.4, 0.2],
       [4.9, 3. , 1....2, 3.4, 5.4, 2.3],
       [5.9, 3. , 5.1, 1.8]]), array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,... 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]), {'score': <function _passthrough_scorer>}, array([  5,   6,   7,   8,   9,  10,  11,  12,  ..., 142, 143, 144,
       145, 146, 147, 148, 149]), array([  0,   1,   2,   3,   4,  50,  51,  52,  53,  54, 100, 101, 102,
       103, 104]), 0, None, None), {'error_score': 'raise-deprecating', 'return_estimator': False, 'return_times': True, 'return_train_score': False})]
    226 
    227     def __len__(self):
    228         return self._size
    229 

...........................................................................
/home/aquemy/.local/lib/python2.7/site-packages/sklearn/model_selection/_validation.py in _fit_and_score(estimator=Pipeline(memory=None,
     steps=[('rebalance', ... random_state=42, verbose=0, warm_start=False))]), X=array([[5.1, 3.5, 1.4, 0.2],
       [4.9, 3. , 1....2, 3.4, 5.4, 2.3],
       [5.9, 3. , 5.1, 1.8]]), y=array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,... 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]), scorer={'score': <function _passthrough_scorer>}, train=array([  5,   6,   7,   8,   9,  10,  11,  12,  ..., 142, 143, 144,
       145, 146, 147, 148, 149]), test=array([  0,   1,   2,   3,   4,  50,  51,  52,  53,  54, 100, 101, 102,
       103, 104]), verbose=0, parameters=None, fit_params={}, return_train_score=False, return_parameters=False, return_n_test_samples=False, return_times=True, return_estimator=False, error_score='raise-deprecating')
    523 
    524     try:
    525         if y_train is None:
    526             estimator.fit(X_train, **fit_params)
    527         else:
--> 528             estimator.fit(X_train, y_train, **fit_params)
        estimator.fit = <bound method Pipeline.fit of Pipeline(memory=No...random_state=42, verbose=0, warm_start=False))])>
        X_train = array([[5.4, 3.9, 1.7, 0.4],
       [4.6, 3.4, 1....2, 3.4, 5.4, 2.3],
       [5.9, 3. , 5.1, 1.8]])
        y_train = array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,
       2, 2, 2])
        fit_params = {}
    529 
    530     except Exception as e:
    531         # Note fit time as time until error
    532         fit_time = time.time() - start_time

...........................................................................
/usr/local/lib/python2.7/dist-packages/imblearn/pipeline.py in fit(self=Pipeline(memory=None,
     steps=[('rebalance', ... random_state=42, verbose=0, warm_start=False))]), X=array([[5.4, 3.9, 1.7, 0.4],
       [4.6, 3.4, 1....2, 3.4, 5.4, 2.3],
       [5.9, 3. , 5.1, 1.8]]), y=array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,
       2, 2, 2]), **fit_params={})
    234             This estimator
    235 
    236         """
    237         Xt, yt, fit_params = self._fit(X, y, **fit_params)
    238         if self._final_estimator is not None:
--> 239             self._final_estimator.fit(Xt, yt, **fit_params)
        self._final_estimator.fit = <bound method RandomForestClassifier.fit of Rand...e, random_state=42, verbose=0, warm_start=False)>
        Xt = array([[ 0.79920252,  1.89792759],
       [-0.29... 2.08116345],
       [ 2.77323041,  4.13173219]])
        yt = array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
       0, 1, 2])
        fit_params = {}
    240         return self
    241 
    242     def fit_transform(self, X, y=None, **fit_params):
    243         """Fit the model and transform with the final estimator

...........................................................................
/home/aquemy/.local/lib/python2.7/site-packages/sklearn/ensemble/forest.py in fit(self=RandomForestClassifier(bootstrap=True, class_wei...se, random_state=42, verbose=0, warm_start=False), X=array([[ 0.7992025 ,  1.8979276 ],
       [-0.29...      [ 2.7732303 ,  4.131732  ]], dtype=float32), y=array([[0.],
       [0.],
       [0.],
       [0...    [0.],
       [0.],
       [1.],
       [2.]]), sample_weight=None)
    328             trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,
    329                              **_joblib_parallel_args(prefer='threads'))(
    330                 delayed(_parallel_build_trees)(
    331                     t, self, X, y, sample_weight, i, len(trees),
    332                     verbose=self.verbose, class_weight=self.class_weight)
--> 333                 for i, t in enumerate(trees))
        i = 9
    334 
    335             # Collect newly grown trees
    336             self.estimators_.extend(trees)
    337 

...........................................................................
/home/aquemy/.local/lib/python2.7/site-packages/sklearn/externals/joblib/parallel.py in __call__(self=Parallel(n_jobs=1), iterable=<generator object <genexpr>>)
    912             # self._original_iterator is None, then this means either
    913             # that pre_dispatch == "all", n_jobs == 1 or that the first batch
    914             # was very quick and its callback already dispatched all the
    915             # remaining jobs.
    916             self._iterating = False
--> 917             if self.dispatch_one_batch(iterator):
        self.dispatch_one_batch = <bound method Parallel.dispatch_one_batch of Parallel(n_jobs=1)>
        iterator = <generator object <genexpr>>
    918                 self._iterating = self._original_iterator is not None
    919 
    920             while self.dispatch_one_batch(iterator):
    921                 pass

...........................................................................
/home/aquemy/.local/lib/python2.7/site-packages/sklearn/externals/joblib/parallel.py in dispatch_one_batch(self=Parallel(n_jobs=1), iterator=<generator object <genexpr>>)
    754                                  self._pickle_cache)
    755             if len(tasks) == 0:
    756                 # No more tasks available in the iterator: tell caller to stop.
    757                 return False
    758             else:
--> 759                 self._dispatch(tasks)
        self._dispatch = <bound method Parallel._dispatch of Parallel(n_jobs=1)>
        tasks = <sklearn.externals.joblib.parallel.BatchedCalls object>
    760                 return True
    761 
    762     def _print(self, msg, msg_args):
    763         """Display the message on stout or stderr depending on verbosity"""

...........................................................................
/home/aquemy/.local/lib/python2.7/site-packages/sklearn/externals/joblib/parallel.py in _dispatch(self=Parallel(n_jobs=1), batch=<sklearn.externals.joblib.parallel.BatchedCalls object>)
    711 
    712         dispatch_timestamp = time.time()
    713         cb = BatchCompletionCallBack(dispatch_timestamp, len(batch), self)
    714         with self._lock:
    715             job_idx = len(self._jobs)
--> 716             job = self._backend.apply_async(batch, callback=cb)
        job = undefined
        self._backend.apply_async = <bound method SequentialBackend.apply_async of <...lib._parallel_backends.SequentialBackend object>>
        batch = <sklearn.externals.joblib.parallel.BatchedCalls object>
        cb = <sklearn.externals.joblib.parallel.BatchCompletionCallBack object>
    717             # A job can complete so quickly than its callback is
    718             # called before we get here, causing self._jobs to
    719             # grow. To ensure correct results ordering, .insert is
    720             # used (rather than .append) in the following line

...........................................................................
/home/aquemy/.local/lib/python2.7/site-packages/sklearn/externals/joblib/_parallel_backends.py in apply_async(self=<sklearn.externals.joblib._parallel_backends.SequentialBackend object>, func=<sklearn.externals.joblib.parallel.BatchedCalls object>, callback=<sklearn.externals.joblib.parallel.BatchCompletionCallBack object>)
    177             raise ValueError('n_jobs == 0 in Parallel has no meaning')
    178         return 1
    179 
    180     def apply_async(self, func, callback=None):
    181         """Schedule a func to be run"""
--> 182         result = ImmediateResult(func)
        result = undefined
        func = <sklearn.externals.joblib.parallel.BatchedCalls object>
    183         if callback:
    184             callback(result)
    185         return result
    186 

...........................................................................
/home/aquemy/.local/lib/python2.7/site-packages/sklearn/externals/joblib/_parallel_backends.py in __init__(self=<sklearn.externals.joblib._parallel_backends.ImmediateResult object>, batch=<sklearn.externals.joblib.parallel.BatchedCalls object>)
    544 
    545 class ImmediateResult(object):
    546     def __init__(self, batch):
    547         # Don't delay the application, to avoid keeping the input
    548         # arguments in memory
--> 549         self.results = batch()
        self.results = undefined
        batch = <sklearn.externals.joblib.parallel.BatchedCalls object>
    550 
    551     def get(self):
    552         return self.results
    553 

...........................................................................
/home/aquemy/.local/lib/python2.7/site-packages/sklearn/externals/joblib/parallel.py in __call__(self=<sklearn.externals.joblib.parallel.BatchedCalls object>)
    220     def __call__(self):
    221         # Set the default nested backend to self._backend but do not set the
    222         # change the default number of processes to -1
    223         with parallel_backend(self._backend, n_jobs=self._n_jobs):
    224             return [func(*args, **kwargs)
--> 225                     for func, args, kwargs in self.items]
        func = <function _parallel_build_trees>
        args = (DecisionTreeClassifier(class_weight=None, criter...=False, random_state=1608637542, splitter='best'), RandomForestClassifier(bootstrap=True, class_wei...se, random_state=42, verbose=0, warm_start=False), array([[ 0.7992025 ,  1.8979276 ],
       [-0.29...      [ 2.7732303 ,  4.131732  ]], dtype=float32), array([[0.],
       [0.],
       [0.],
       [0...    [0.],
       [0.],
       [1.],
       [2.]]), None, 0, 10)
        kwargs = {'class_weight': None, 'verbose': 0}
        self.items = [(<function _parallel_build_trees>, (DecisionTreeClassifier(class_weight=None, criter...=False, random_state=1608637542, splitter='best'), RandomForestClassifier(bootstrap=True, class_wei...se, random_state=42, verbose=0, warm_start=False), array([[ 0.7992025 ,  1.8979276 ],
       [-0.29...      [ 2.7732303 ,  4.131732  ]], dtype=float32), array([[0.],
       [0.],
       [0.],
       [0...    [0.],
       [0.],
       [1.],
       [2.]]), None, 0, 10), {'class_weight': None, 'verbose': 0})]
    226 
    227     def __len__(self):
    228         return self._size
    229 

...........................................................................
/home/aquemy/.local/lib/python2.7/site-packages/sklearn/ensemble/forest.py in _parallel_build_trees(tree=DecisionTreeClassifier(class_weight=None, criter...=False, random_state=1608637542, splitter='best'), forest=RandomForestClassifier(bootstrap=True, class_wei...se, random_state=42, verbose=0, warm_start=False), X=array([[ 0.7992025 ,  1.8979276 ],
       [-0.29...      [ 2.7732303 ,  4.131732  ]], dtype=float32), y=array([[0.],
       [0.],
       [0.],
       [0...    [0.],
       [0.],
       [1.],
       [2.]]), sample_weight=None, tree_idx=0, n_trees=10, verbose=0, class_weight=None)
    114                 simplefilter('ignore', DeprecationWarning)
    115                 curr_sample_weight *= compute_sample_weight('auto', y, indices)
    116         elif class_weight == 'balanced_subsample':
    117             curr_sample_weight *= compute_sample_weight('balanced', y, indices)
    118 
--> 119         tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)
        tree.fit = <bound method DecisionTreeClassifier.fit of Deci...False, random_state=1608637542, splitter='best')>
        X = array([[ 0.7992025 ,  1.8979276 ],
       [-0.29...      [ 2.7732303 ,  4.131732  ]], dtype=float32)
        y = array([[0.],
       [0.],
       [0.],
       [0...    [0.],
       [0.],
       [1.],
       [2.]])
        sample_weight = None
        curr_sample_weight = array([2., 0., 2., 1., 2., 0., 1., 2., 1., 1., 2... 0., 0., 0., 0., 2., 0., 5., 0., 2., 0., 0., 1.])
    120     else:
    121         tree.fit(X, y, sample_weight=sample_weight, check_input=False)
    122 
    123     return tree

...........................................................................
/home/aquemy/.local/lib/python2.7/site-packages/sklearn/tree/tree.py in fit(self=DecisionTreeClassifier(class_weight=None, criter...=False, random_state=1608637542, splitter='best'), X=array([[ 0.7992025 ,  1.8979276 ],
       [-0.29...      [ 2.7732303 ,  4.131732  ]], dtype=float32), y=array([[0.],
       [0.],
       [0.],
       [0...    [0.],
       [0.],
       [1.],
       [2.]]), sample_weight=array([2., 0., 2., 1., 2., 0., 1., 2., 1., 1., 2... 0., 0., 0., 0., 2., 0., 5., 0., 2., 0., 0., 1.]), check_input=False, X_idx_sorted=None)
    796 
    797         super(DecisionTreeClassifier, self).fit(
    798             X, y,
    799             sample_weight=sample_weight,
    800             check_input=check_input,
--> 801             X_idx_sorted=X_idx_sorted)
        X_idx_sorted = None
    802         return self
    803 
    804     def predict_proba(self, X, check_input=True):
    805         """Predict class probabilities of the input samples X.

...........................................................................
/home/aquemy/.local/lib/python2.7/site-packages/sklearn/tree/tree.py in fit(self=DecisionTreeClassifier(class_weight=None, criter...=False, random_state=1608637542, splitter='best'), X=array([[ 0.7992025 ,  1.8979276 ],
       [-0.29...      [ 2.7732303 ,  4.131732  ]], dtype=float32), y=array([[0.],
       [0.],
       [0.],
       [0...    [0.],
       [0.],
       [1.],
       [2.]]), sample_weight=array([2., 0., 2., 1., 2., 0., 1., 2., 1., 1., 2... 0., 0., 0., 0., 2., 0., 5., 0., 2., 0., 0., 1.]), check_input=False, X_idx_sorted=None)
    237         if not 0 <= self.min_weight_fraction_leaf <= 0.5:
    238             raise ValueError("min_weight_fraction_leaf must in [0, 0.5]")
    239         if max_depth <= 0:
    240             raise ValueError("max_depth must be greater than zero. ")
    241         if not (0 < max_features <= self.n_features_):
--> 242             raise ValueError("max_features must be in (0, n_features]")
    243         if not isinstance(max_leaf_nodes, (numbers.Integral, np.integer)):
    244             raise ValueError("max_leaf_nodes must be integral number but was "
    245                              "%r" % max_leaf_nodes)
    246         if -1 < max_leaf_nodes < 2:

ValueError: max_features must be in (0, n_features]
___________________________________________________________________________
Best score: 0.966666666667 (0.0333333333333) [J] | Score: 0.0 (0.0) [J]
Best score: 0.966666666667 (0.0333333333333) [J] | Score: 0.853333333333 (0.0581186525805) [J]
Best score: 0.966666666667 (0.0333333333333) [J] | Score: 0.933333333333 (0.0596284794) [J]
Best score: 0.966666666667 (0.0333333333333) [J] | Score: 0.953333333333 (0.0520683311727) [J]
Best score: 0.966666666667 (0.0333333333333) [J] | Score: 0.9 (0.108525470641) [J]
JoblibValueError
___________________________________________________________________________
...........................................................................
/home/aquemy/dev/dp_hyperparameters/extension/main.py in <module>()
     27 
     28     serializer.serialize_results(scenario, policy)
     29 
     30 if __name__ == "__main__":
     31     args = cli.parse_args()
---> 32     main(args)

...........................................................................
/home/aquemy/dev/dp_hyperparameters/extension/main.py in main(args=Namespace(customize=[(['control', 'seed'], '42')...io='./scenarios/rf_iris_joint.yaml', verbosity=0))
     21         test_size=0.4, 
     22         random_state=scenario['control']['seed']
     23     )
     24 
     25     policy = policies.initiate(scenario['setup']['policy'], config)
---> 26     policy.run(X,y)
        policy.run = <bound method Joint.run of <experiment.policies.joint.Joint object>>
        X = array([[5.1, 3.5, 1.4, 0.2],
       [4.9, 3. , 1....2, 3.4, 5.4, 2.3],
       [5.9, 3. , 5.1, 1.8]])
        y = array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,... 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2])
     27 
     28     serializer.serialize_results(scenario, policy)
     29 
     30 if __name__ == "__main__":

...........................................................................
/home/aquemy/dev/dp_hyperparameters/extension/experiment/policies/joint.py in run(self=<experiment.policies.joint.Joint object>, X=array([[5.1, 3.5, 1.4, 0.2],
       [4.9, 3. , 1....2, 3.4, 5.4, 2.3],
       [5.9, 3. , 5.1, 1.8]]), y=array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,... 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]))
     32             algo=tpe.suggest, 
     33             max_evals=None,
     34             max_time=self.config['time'],     
     35             trials=trials,
     36             show_progressbar=False,
---> 37             verbose=0
     38         )
     39 
     40         best_config = self.context['best_config']
     41         super(Joint, self).display_step_results(best_config)

...........................................................................
/home/aquemy/dev/dp_hyperparameters/extension/hyperopt/fmin.py in fmin(fn=<functools.partial object>, space={'algorithm': {'bootstrap': <hyperopt.pyll.base.Apply object>, 'criterion': <hyperopt.pyll.base.Apply object>, 'max_depth': <hyperopt.pyll.base.Apply object>, 'max_features': <hyperopt.pyll.base.Apply object>, 'max_leaf_nodes': <hyperopt.pyll.base.Apply object>, 'min_samples_split': <hyperopt.pyll.base.Apply object>, 'n_estimators': <hyperopt.pyll.base.Apply object>}, 'pipeline': {'features': <hyperopt.pyll.base.Apply object>, 'normalizer': <hyperopt.pyll.base.Apply object>, 'rebalance': <hyperopt.pyll.base.Apply object>}}, algo=<function suggest>, max_evals=9223372036854775807, max_time=300, trials=<hyperopt.base.Trials object>, rstate=<mtrand.RandomState object>, allow_trials_fmin=True, pass_expr_memo_ctrl=None, catch_eval_exceptions=False, verbose=0, return_argmin=True, points_to_evaluate=None, max_queue_len=1, show_progressbar=False)
    406             pass_expr_memo_ctrl=pass_expr_memo_ctrl,
    407             verbose=verbose,
    408             catch_eval_exceptions=catch_eval_exceptions,
    409             return_argmin=return_argmin,
    410             show_progressbar=show_progressbar,
--> 411             max_time=max_time
        max_time = 300
    412         )
    413 
    414     if trials is None:
    415         if points_to_evaluate is None:

...........................................................................
/home/aquemy/dev/dp_hyperparameters/extension/hyperopt/base.py in fmin(self=<hyperopt.base.Trials object>, fn=<functools.partial object>, space={'algorithm': {'bootstrap': <hyperopt.pyll.base.Apply object>, 'criterion': <hyperopt.pyll.base.Apply object>, 'max_depth': <hyperopt.pyll.base.Apply object>, 'max_features': <hyperopt.pyll.base.Apply object>, 'max_leaf_nodes': <hyperopt.pyll.base.Apply object>, 'min_samples_split': <hyperopt.pyll.base.Apply object>, 'n_estimators': <hyperopt.pyll.base.Apply object>}, 'pipeline': {'features': <hyperopt.pyll.base.Apply object>, 'normalizer': <hyperopt.pyll.base.Apply object>, 'rebalance': <hyperopt.pyll.base.Apply object>}}, algo=<function suggest>, max_evals=9223372036854775807, max_time=300, rstate=<mtrand.RandomState object>, verbose=0, pass_expr_memo_ctrl=None, catch_eval_exceptions=False, return_argmin=True, show_progressbar=False)
    636             verbose=verbose,
    637             allow_trials_fmin=False,  # -- prevent recursion
    638             pass_expr_memo_ctrl=pass_expr_memo_ctrl,
    639             catch_eval_exceptions=catch_eval_exceptions,
    640             return_argmin=return_argmin,
--> 641             show_progressbar=show_progressbar)
        show_progressbar = False
    642 
    643 
    644 def trials_from_docs(docs, validate=True, **kwargs):
    645     """Construct a Trials base class instance from a list of trials documents

...........................................................................
/home/aquemy/dev/dp_hyperparameters/extension/hyperopt/fmin.py in fmin(fn=<functools.partial object>, space={'algorithm': {'bootstrap': <hyperopt.pyll.base.Apply object>, 'criterion': <hyperopt.pyll.base.Apply object>, 'max_depth': <hyperopt.pyll.base.Apply object>, 'max_features': <hyperopt.pyll.base.Apply object>, 'max_leaf_nodes': <hyperopt.pyll.base.Apply object>, 'min_samples_split': <hyperopt.pyll.base.Apply object>, 'n_estimators': <hyperopt.pyll.base.Apply object>}, 'pipeline': {'features': <hyperopt.pyll.base.Apply object>, 'normalizer': <hyperopt.pyll.base.Apply object>, 'rebalance': <hyperopt.pyll.base.Apply object>}}, algo=<function suggest>, max_evals=9223372036854775807, max_time=300, trials=<hyperopt.base.Trials object>, rstate=<mtrand.RandomState object>, allow_trials_fmin=False, pass_expr_memo_ctrl=None, catch_eval_exceptions=False, verbose=0, return_argmin=True, points_to_evaluate=None, max_queue_len=1, show_progressbar=False)
    426                     verbose=verbose,
    427                     max_queue_len=max_queue_len,
    428                     show_progressbar=show_progressbar,
    429                     max_time=max_time)
    430     rval.catch_eval_exceptions = catch_eval_exceptions
--> 431     rval.exhaust()
        rval.exhaust = <bound method FMinIter.exhaust of <hyperopt.fmin.FMinIter object>>
    432     if return_argmin:
    433         return trials.argmin
    434     elif len(trials) > 0:
    435         # Only if there are some succesfull trail runs, return the best point in the evaluation space

...........................................................................
/home/aquemy/dev/dp_hyperparameters/extension/hyperopt/fmin.py in exhaust(self=<hyperopt.fmin.FMinIter object>)
    273             raise StopIteration()
    274         return self.trials
    275 
    276     def exhaust(self):
    277         n_done = len(self.trials)
--> 278         self.run(self.max_evals - n_done, block_until_done=self.asynchronous)
        self.run = <bound method FMinIter.run of <hyperopt.fmin.FMinIter object>>
        self.max_evals = 9223372036854775807
        n_done = 0
        self.asynchronous = False
    279         self.trials.refresh()
    280         return self
    281 
    282 

...........................................................................
/home/aquemy/dev/dp_hyperparameters/extension/hyperopt/fmin.py in run(self=<hyperopt.fmin.FMinIter object>, N=9223372036854775807, block_until_done=False)
    232                     if self.asynchronous:
    233                         # -- wait for workers to fill in the trials
    234                         time.sleep(self.poll_interval_secs)
    235                     else:
    236                         # -- loop over trials and do the jobs directly
--> 237                         self.serial_evaluate()
        self.serial_evaluate = <bound method FMinIter.serial_evaluate of <hyperopt.fmin.FMinIter object>>
    238                     try:
    239                         res = [d['result']['loss'] for d in
    240                                          self.trials.trials if
    241                                          d['result']['status'] == 'ok']

...........................................................................
/home/aquemy/dev/dp_hyperparameters/extension/hyperopt/fmin.py in serial_evaluate(self=<hyperopt.fmin.FMinIter object>, N=-1)
    138                 trial['book_time'] = now
    139                 trial['refresh_time'] = now
    140                 spec = base.spec_from_misc(trial['misc'])
    141                 ctrl = base.Ctrl(self.trials, current_trial=trial)
    142                 try:
--> 143                     result = self.domain.evaluate(spec, ctrl)
        result = undefined
        self.domain.evaluate = <bound method Domain.evaluate of <hyperopt.base.Domain object>>
        spec = {'bootstrap': 0, 'criterion': 0, 'features': 2, 'features_SelectKBest_features__k': 0, 'max_depth': 1, 'max_features': 2, 'max_leaf_nodes': 0, 'min_samples_split': 1, 'n_estimators': 3, 'normalizer': 0, ...}
        ctrl = <hyperopt.base.Ctrl object>
    144                 except Exception as e:
    145                     logger.info('job exception: %s' % str(e))
    146                     trial['state'] = base.JOB_STATE_ERROR
    147                     trial['misc']['error'] = (str(type(e)), str(e))

...........................................................................
/home/aquemy/dev/dp_hyperparameters/extension/hyperopt/base.py in evaluate(self=<hyperopt.base.Domain object>, config={'bootstrap': 0, 'criterion': 0, 'features': 2, 'features_SelectKBest_features__k': 0, 'max_depth': 1, 'max_features': 2, 'max_leaf_nodes': 0, 'min_samples_split': 1, 'n_estimators': 3, 'normalizer': 0, ...}, ctrl=<hyperopt.base.Ctrl object>, attach_attachments=True)
    841             #    or the normal Python part (self.fn)
    842             pyll_rval = pyll.rec_eval(
    843                 self.expr,
    844                 memo=memo,
    845                 print_node_on_error=self.rec_eval_print_node_on_error)
--> 846             rval = self.fn(pyll_rval)
        rval = undefined
        self.fn = <functools.partial object>
        pyll_rval = {'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': 2, 'max_features': 3, 'max_leaf_nodes': 2, 'min_samples_split': 3, 'n_estimators': 75}, 'pipeline': {'features': ('features_SelectKBest', {'features__k': 1}), 'normalizer': ('normalizer_NoneType', {}), 'rebalance': ('rebalance_CondensedNearestNeighbour', {'rebalance__n_neighbors': 3})}}
    847 
    848         if isinstance(rval, (float, int, np.number)):
    849             dict_rval = {'loss': float(rval), 'status': STATUS_OK}
    850         else:

...........................................................................
/home/aquemy/dev/dp_hyperparameters/extension/experiment/objective.py in objective_joint(wconfig={'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': 2, 'max_features': 3, 'max_leaf_nodes': 2, 'min_samples_split': 3, 'n_estimators': 75}, 'pipeline': {'features': ('features_SelectKBest', {'features__k': 1}), 'normalizer': ('normalizer_NoneType', {}), 'rebalance': ('rebalance_CondensedNearestNeighbour', {'rebalance__n_neighbors': 3})}}, algorithm='RandomForest', X=array([[5.1, 3.5, 1.4, 0.2],
       [4.9, 3. , 1....2, 3.4, 5.4, 2.3],
       [5.9, 3. , 5.1, 1.8]]), y=array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,... 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]), context={'baseline_score': 0.9466666666666667, 'baseline_score_std': 0.04988876515698587, 'best_config': {'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': 4, 'max_features': 3, 'max_leaf_nodes': 3, 'min_samples_split': 3, 'n_estimators': 10}, 'config_hash': {'algorithm': 'ffb7ff225ce3d3712c96cf87fe42202988ee2eb0', 'config': 'bae32f426be9cd6243523c023944a8c148fe4aeb', 'pipeline': 'd2a68bfda6fcdec4ae0ffc7d7b6a2122bc1cd673'}, 'duration': 0.7115809917449951, 'iteration': 113, 'loss': 0.033333333333333215, 'max_history_score': 0.9666666666666668, 'max_history_score_std': 0.033333333333333326, 'max_history_step': 'joint', 'pipeline': {'features': ('features_NoneType', {}), 'normalizer': ('normalizer_PowerTransformer', {}), 'rebalance': ('rebalance_CondensedNearestNeighbour', {'rebalance__n_neighbors': 2})}, 'score': 0.9666666666666668, ...}, 'history': [{'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': 2, 'max_features': None, 'max_leaf_nodes': 5, 'min_samples_split': 2, 'n_estimators': 75}, 'config_hash': {'algorithm': '3af5b0cce71c8fe2545246ca24ff5bc3dd516e06', 'config': 'db6ac7e6d348155757e4794bb5f88fe2b4f63d50', 'pipeline': '8d59f4b94cef6be9306ed86a22a9570fa670d567'}, 'duration': 1.149928092956543, 'iteration': 0, 'loss': 0.046666666666666634, 'max_history_score': 0.9533333333333334, 'max_history_score_std': 0.059999999999999984, 'max_history_step': 'joint', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 4, 'features__selectkbest__k': 3}), 'normalizer': ('normalizer_StandardScaler', {'normalizer__with_mean': True, 'normalizer__with_std': True}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 6})}, 'score': 0.9533333333333334, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': 1, 'max_features': 2, 'max_leaf_nodes': 2, 'min_samples_split': 5, 'n_estimators': 100}, 'config_hash': {'algorithm': 'e13eb05fd9a62d2f63bbb1c1deff0cd620d5e6ab', 'config': '4db6fb84d85f52659f780e682ffac5712c3d8a94', 'pipeline': '64c9a1ca9d53ae67244bdd942f4db36a3c05218c'}, 'duration': 1.7678282260894775, 'iteration': 1, 'loss': 0.18000000000000005, 'max_history_score': 0.9533333333333334, 'max_history_score_std': 0.059999999999999984, 'max_history_step': 'joint', 'pipeline': {'features': ('features_NoneType', {}), 'normalizer': ('normalizer_PowerTransformer', {}), 'rebalance': ('rebalance_NearMiss', {'rebalance__n_neighbors': 1})}, 'score': 0.82, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': 1, 'max_features': None, 'max_leaf_nodes': None, 'min_samples_split': 5, 'n_estimators': 75}, 'config_hash': {'algorithm': '94b0d7a654c508cc63643f78fe4f0f07e6f07c1e', 'config': '4403c5a85e951938d3c454e961d3a412780722f6', 'pipeline': '3e47444880d8367fbac2faaba2e52a917274aa58'}, 'duration': 0.8397619724273682, 'iteration': 2, 'loss': 0.03333333333333344, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_PCA', {'features__n_components': 3}), 'normalizer': ('normalizer_MinMaxScaler', {}), 'rebalance': ('rebalance_NoneType', {})}, 'score': 0.9666666666666666, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': None, 'max_features': None, 'max_leaf_nodes': 3, 'min_samples_split': 3, 'n_estimators': 75}, 'config_hash': {'algorithm': 'e8332f0a8902bda03bf70e7978cc5d52affb29d3', 'config': 'a064e2df18ab98d44dabcefbc7bed94913f1d0be', 'pipeline': '7eea819c2a8c103c4b1e9e9c1e224aebba95081f'}, 'duration': 0.8501448631286621, 'iteration': 3, 'loss': 0.053333333333333344, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 2, 'features__selectkbest__k': 4}), 'normalizer': ('normalizer_NoneType', {}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 7})}, 'score': 0.9466666666666667, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'entropy', 'max_depth': 3, 'max_features': 3, 'max_leaf_nodes': None, 'min_samples_split': 5, 'n_estimators': 75}, 'config_hash': {'algorithm': '7a4491035bc6bd737fe9a8cda8a79a02d02d5c74', 'config': '0ddb6f5cab3db4dddd7682966a57205f3e329ad4', 'pipeline': 'a9ae03fe38334f6868cbf84cdd3d629d4bbe3fb0'}, 'duration': 1.1026010513305664, 'iteration': 4, 'loss': 0.05999999999999994, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 2, 'features__selectkbest__k': 1}), 'normalizer': ('normalizer_NoneType', {}), 'rebalance': ('rebalance_NoneType', {})}, 'score': 0.9400000000000001, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'gini', 'max_depth': 3, 'max_features': 1, 'max_leaf_nodes': 5, 'min_samples_split': 2, 'n_estimators': 25}, 'config_hash': {'algorithm': '9826d20b2d6a0f559cf7f16450ce7526f07e8434', 'config': '49f25751bca61cdd461a8cbd2923689b642f98ed', 'pipeline': '19b249664c5bf067de1fed4334a296f947ce774a'}, 'duration': 0.35647010803222656, 'iteration': 5, 'loss': 0.046666666666666634, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_NoneType', {}), 'normalizer': ('normalizer_NoneType', {}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 6})}, 'score': 0.9533333333333334, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'gini', 'max_depth': 2, 'max_features': 1, 'max_leaf_nodes': 2, 'min_samples_split': 2, 'n_estimators': 50}, 'config_hash': {'algorithm': '0a4f6fbb07e0f32c6f675489a0fc82eee05bd8e1', 'config': '5c3a2b6f5e63fb45f10e41e0318b354912ec44f6', 'pipeline': 'dc3b9f176f090005e38b142f11d80e93a7dc5d5e'}, 'duration': 0.7213859558105469, 'iteration': 6, 'loss': 0.31333333333333324, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 1, 'features__selectkbest__k': 4}), 'normalizer': ('normalizer_PowerTransformer', {}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 7})}, 'score': 0.6866666666666668, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'entropy', 'max_depth': 4, 'max_features': 3, 'max_leaf_nodes': 5, 'min_samples_split': 5, 'n_estimators': 10}, 'config_hash': {'algorithm': 'b8112b97ecfc10f00a195af661dcc861cac21289', 'config': 'd3b129b397350f1b6572651c67c01de49b4b174c', 'pipeline': '5b0357ed7072c37b3d6f458bb5d49ff7d825f603'}, 'duration': 0.8299109935760498, 'iteration': 7, 'loss': 1.0, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_PCA', {'features__n_components': 2}), 'normalizer': ('normalizer_StandardScaler', {'normalizer__with_mean': True, 'normalizer__with_std': False}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 6})}, 'score': 0.0, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'gini', 'max_depth': 4, 'max_features': None, 'max_leaf_nodes': 2, 'min_samples_split': 5, 'n_estimators': 100}, 'config_hash': {'algorithm': '40ca24df19b8d164d9d098a6bed1ce056fbbb961', 'config': '813bde1108cc3c4b9bfb3a22cbb421bda7eac671', 'pipeline': '74a7b8705a1c22f7dea5e44e4ebda8f1e48add71'}, 'duration': 2.2111589908599854, 'iteration': 8, 'loss': 0.33333333333333326, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_PCA', {'features__n_components': 2}), 'normalizer': ('normalizer_StandardScaler', {'normalizer__with_mean': False, 'normalizer__with_std': True}), 'rebalance': ('rebalance_NearMiss', {'rebalance__n_neighbors': 2})}, 'score': 0.6666666666666667, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'entropy', 'max_depth': 2, 'max_features': 1, 'max_leaf_nodes': 5, 'min_samples_split': 2, 'n_estimators': 100}, 'config_hash': {'algorithm': '331418a5c12cf1453876eef85e9d98fc8e54fa11', 'config': '31930b6860ed406d59bf7e59ba1925d94704bd3b', 'pipeline': '054bef356f90ec6f644ef3ffc688766744db51c2'}, 'duration': 1.0501940250396729, 'iteration': 9, 'loss': 0.053333333333333344, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_SelectKBest', {'features__k': 1}), 'normalizer': ('normalizer_RobustScaler', {'normalizer__quantile_range': (...), 'normalizer__with_centering': True, 'normalizer__with_scaling': True}), 'rebalance': ('rebalance_NearMiss', {'rebalance__n_neighbors': 2})}, 'score': 0.9466666666666667, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'entropy', 'max_depth': 3, 'max_features': None, 'max_leaf_nodes': 3, 'min_samples_split': 2, 'n_estimators': 100}, 'config_hash': {'algorithm': 'dbc1b8126649fe93dce5fbb37e4015b0acfb179e', 'config': '9913cd550615a9d0946ab4a755a8b9f619e442fd', 'pipeline': 'dd626121cea079ebb32e184ca65483ec7a6d7f59'}, 'duration': 1.120617151260376, 'iteration': 10, 'loss': 0.046666666666666634, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 2, 'features__selectkbest__k': 1}), 'normalizer': ('normalizer_MinMaxScaler', {}), 'rebalance': ('rebalance_NoneType', {})}, 'score': 0.9533333333333334, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'gini', 'max_depth': 3, 'max_features': 3, 'max_leaf_nodes': None, 'min_samples_split': 3, 'n_estimators': 75}, 'config_hash': {'algorithm': '34917a130df5a975f78bd7ec1a0c7b1ffdc787a9', 'config': '95fc8cadc088141290b7de9c388977e4685f0108', 'pipeline': '550d10faf2f08db48516cc3501558816d6a99bc0'}, 'duration': 1.4287099838256836, 'iteration': 11, 'loss': 0.19333333333333313, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 3, 'features__selectkbest__k': 4}), 'normalizer': ('normalizer_StandardScaler', {'normalizer__with_mean': False, 'normalizer__with_std': False}), 'rebalance': ('rebalance_CondensedNearestNeighbour', {'rebalance__n_neighbors': 1})}, 'score': 0.8066666666666669, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'entropy', 'max_depth': 1, 'max_features': 2, 'max_leaf_nodes': 5, 'min_samples_split': 2, 'n_estimators': 75}, 'config_hash': {'algorithm': '33f9abb4aee44a395a9f3b3ffa9ce80a8cdaed7c', 'config': '40fa726f0360cf6af55f9b5902d399d02f61f157', 'pipeline': 'cfd1d20841fe2153da762c95e79f95a3fb1e426a'}, 'duration': 1.2978079319000244, 'iteration': 12, 'loss': 0.053333333333333344, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_PCA', {'features__n_components': 4}), 'normalizer': ('normalizer_MinMaxScaler', {}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 7})}, 'score': 0.9466666666666667, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'entropy', 'max_depth': 4, 'max_features': 2, 'max_leaf_nodes': 5, 'min_samples_split': 3, 'n_estimators': 25}, 'config_hash': {'algorithm': '210111ec6562d09eb093e98ed69ef1c662e11a50', 'config': '0fb8e77c7bd9a58b72f1b33c21a59a09a8c676ba', 'pipeline': '5d269d759e0c7926a685a14b263ace8ae0071e4b'}, 'duration': 0.36649012565612793, 'iteration': 13, 'loss': 0.040000000000000036, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 2, 'features__selectkbest__k': 2}), 'normalizer': ('normalizer_NoneType', {}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 7})}, 'score': 0.96, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'entropy', 'max_depth': 3, 'max_features': 1, 'max_leaf_nodes': 5, 'min_samples_split': 2, 'n_estimators': 25}, 'config_hash': {'algorithm': '0e989a03980101fabf79eda3326ed2870e11d690', 'config': 'f4bffd5d8c67a9c5321a9943c4a99678f59a02b7', 'pipeline': '865ee1e3fe8334c3d5ecb2038d5a5d1b3ba50e75'}, 'duration': 0.35639500617980957, 'iteration': 14, 'loss': 0.046666666666666634, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_NoneType', {}), 'normalizer': ('normalizer_RobustScaler', {'normalizer__quantile_range': (...), 'normalizer__with_centering': True, 'normalizer__with_scaling': False}), 'rebalance': ('rebalance_NoneType', {})}, 'score': 0.9533333333333334, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'entropy', 'max_depth': None, 'max_features': 3, 'max_leaf_nodes': 3, 'min_samples_split': 5, 'n_estimators': 10}, 'config_hash': {'algorithm': '9c592e876c13de5e23e6de5b868e01755d63e72e', 'config': '1e6a68cd1eeac886d90724d78b1cb5fb76a3cde4', 'pipeline': '5a1ca4d82f21b7de0d2c918630a42510673fa36e'}, 'duration': 0.18141412734985352, 'iteration': 15, 'loss': 0.046666666666666634, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_SelectKBest', {'features__k': 3}), 'normalizer': ('normalizer_RobustScaler', {'normalizer__quantile_range': (...), 'normalizer__with_centering': True, 'normalizer__with_scaling': True}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 6})}, 'score': 0.9533333333333334, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': 1, 'max_features': None, 'max_leaf_nodes': None, 'min_samples_split': 5, 'n_estimators': 10}, 'config_hash': {'algorithm': '8bed77aef289bfd453b2858bd288ae5ba7160f2b', 'config': '781185bcb8999045de8d489f253a1a1ba4247932', 'pipeline': '1ece7eabedc2be9e5b0a1be65c570d08ffa3eb54'}, 'duration': 0.1636829376220703, 'iteration': 16, 'loss': 0.053333333333333344, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_NoneType', {}), 'normalizer': ('normalizer_NoneType', {}), 'rebalance': ('rebalance_NearMiss', {'rebalance__n_neighbors': 1})}, 'score': 0.9466666666666667, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'gini', 'max_depth': 3, 'max_features': 2, 'max_leaf_nodes': 2, 'min_samples_split': 5, 'n_estimators': 75}, 'config_hash': {'algorithm': '617b97d9ba21d3373bc51ffa9cccf9c6f91a77b3', 'config': '99fb425b4e8c5d80228cab94202252aa25cdf77c', 'pipeline': 'd6242929c3b515c7719e60423023ac604311afc3'}, 'duration': 0.8468999862670898, 'iteration': 17, 'loss': 0.24, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_PCA', {'features__n_components': 4}), 'normalizer': ('normalizer_PowerTransformer', {}), 'rebalance': ('rebalance_NearMiss', {'rebalance__n_neighbors': 2})}, 'score': 0.76, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': 1, 'max_features': 1, 'max_leaf_nodes': 2, 'min_samples_split': 5, 'n_estimators': 50}, 'config_hash': {'algorithm': 'b92d2697cdd4979da443369d6596229ec091626a', 'config': 'c513a3e13281206ad76187dd817b1fff93d54fe1', 'pipeline': 'c4b4f914a3ca8df967cade997a90366d85a371b9'}, 'duration': 0.6724588871002197, 'iteration': 18, 'loss': 0.23333333333333328, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 1, 'features__selectkbest__k': 3}), 'normalizer': ('normalizer_StandardScaler', {'normalizer__with_mean': True, 'normalizer__with_std': True}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 5})}, 'score': 0.7666666666666667, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'entropy', 'max_depth': None, 'max_features': None, 'max_leaf_nodes': 5, 'min_samples_split': 5, 'n_estimators': 10}, 'config_hash': {'algorithm': 'a0115de695e6cca2e81cbfb54df79bf4b43608b1', 'config': 'ba194015e20b5d67770e8c67342c3d8d0d01dc41', 'pipeline': '8d45fabfeb85ffdcabf7076bd0e65fffe97ce928'}, 'duration': 0.19424200057983398, 'iteration': 19, 'loss': 0.08666666666666667, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_PCA', {'features__n_components': 3}), 'normalizer': ('normalizer_NoneType', {}), 'rebalance': ('rebalance_NoneType', {})}, 'score': 0.9133333333333333, ...}, ...], 'history_hash': ['db6ac7e6d348155757e4794bb5f88fe2b4f63d50', '4db6fb84d85f52659f780e682ffac5712c3d8a94', '4403c5a85e951938d3c454e961d3a412780722f6', 'a064e2df18ab98d44dabcefbc7bed94913f1d0be', '0ddb6f5cab3db4dddd7682966a57205f3e329ad4', '49f25751bca61cdd461a8cbd2923689b642f98ed', '5c3a2b6f5e63fb45f10e41e0318b354912ec44f6', 'd3b129b397350f1b6572651c67c01de49b4b174c', '813bde1108cc3c4b9bfb3a22cbb421bda7eac671', '31930b6860ed406d59bf7e59ba1925d94704bd3b', '9913cd550615a9d0946ab4a755a8b9f619e442fd', '95fc8cadc088141290b7de9c388977e4685f0108', '40fa726f0360cf6af55f9b5902d399d02f61f157', '0fb8e77c7bd9a58b72f1b33c21a59a09a8c676ba', 'f4bffd5d8c67a9c5321a9943c4a99678f59a02b7', '1e6a68cd1eeac886d90724d78b1cb5fb76a3cde4', '781185bcb8999045de8d489f253a1a1ba4247932', '99fb425b4e8c5d80228cab94202252aa25cdf77c', 'c513a3e13281206ad76187dd817b1fff93d54fe1', 'ba194015e20b5d67770e8c67342c3d8d0d01dc41', ...], 'history_index': {'013329309d510b94f19d930320402d65f953a847': 39, '038a0f515e2ec894ee8e34f9caa2889eb3ebd5ce': 66, '052ae4bf232b316187b078abae42c2be19e16a00': 111, '0659afebf316aafeb75612fb07081a04c28545ed': 74, '06e7cde9f3556cd01332ce389ad1d8925cd4b4a4': 120, '0b6551ecfd6f83a15704a9db68f1599c99c6d3ef': 58, '0ddb6f5cab3db4dddd7682966a57205f3e329ad4': 4, '0fb8e77c7bd9a58b72f1b33c21a59a09a8c676ba': 13, '111e2fd99e871044225b8638df965b2a16868e35': 110, '111ffc790caf02104464bfa2f448cba7c56c71dc': 46, ...}, 'iteration': 163, 'max_history_score': 0.9666666666666668, 'max_history_score_std': 0.033333333333333326, 'max_history_step': 'joint'}, config={'algorithm': 'RandomForest', 'seed': 42, 'time': 300})
    108 
    109 def objective_algo(algo_config, current_pipeline_config, algorithm, X, y, context, config):
    110     return objective(current_pipeline_config, algo_config, algorithm, X, y, context, config, step='algorithm')
    111 
    112 def objective_joint(wconfig, algorithm, X, y, context, config):
--> 113     return objective(wconfig['pipeline'], wconfig['algorithm'], algorithm, X, y, context, config, step='joint')
        wconfig = {'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': 2, 'max_features': 3, 'max_leaf_nodes': 2, 'min_samples_split': 3, 'n_estimators': 75}, 'pipeline': {'features': ('features_SelectKBest', {'features__k': 1}), 'normalizer': ('normalizer_NoneType', {}), 'rebalance': ('rebalance_CondensedNearestNeighbour', {'rebalance__n_neighbors': 3})}}
        algorithm = 'RandomForest'
        X = array([[5.1, 3.5, 1.4, 0.2],
       [4.9, 3. , 1....2, 3.4, 5.4, 2.3],
       [5.9, 3. , 5.1, 1.8]])
        y = array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,... 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2])
        context = {'baseline_score': 0.9466666666666667, 'baseline_score_std': 0.04988876515698587, 'best_config': {'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': 4, 'max_features': 3, 'max_leaf_nodes': 3, 'min_samples_split': 3, 'n_estimators': 10}, 'config_hash': {'algorithm': 'ffb7ff225ce3d3712c96cf87fe42202988ee2eb0', 'config': 'bae32f426be9cd6243523c023944a8c148fe4aeb', 'pipeline': 'd2a68bfda6fcdec4ae0ffc7d7b6a2122bc1cd673'}, 'duration': 0.7115809917449951, 'iteration': 113, 'loss': 0.033333333333333215, 'max_history_score': 0.9666666666666668, 'max_history_score_std': 0.033333333333333326, 'max_history_step': 'joint', 'pipeline': {'features': ('features_NoneType', {}), 'normalizer': ('normalizer_PowerTransformer', {}), 'rebalance': ('rebalance_CondensedNearestNeighbour', {'rebalance__n_neighbors': 2})}, 'score': 0.9666666666666668, ...}, 'history': [{'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': 2, 'max_features': None, 'max_leaf_nodes': 5, 'min_samples_split': 2, 'n_estimators': 75}, 'config_hash': {'algorithm': '3af5b0cce71c8fe2545246ca24ff5bc3dd516e06', 'config': 'db6ac7e6d348155757e4794bb5f88fe2b4f63d50', 'pipeline': '8d59f4b94cef6be9306ed86a22a9570fa670d567'}, 'duration': 1.149928092956543, 'iteration': 0, 'loss': 0.046666666666666634, 'max_history_score': 0.9533333333333334, 'max_history_score_std': 0.059999999999999984, 'max_history_step': 'joint', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 4, 'features__selectkbest__k': 3}), 'normalizer': ('normalizer_StandardScaler', {'normalizer__with_mean': True, 'normalizer__with_std': True}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 6})}, 'score': 0.9533333333333334, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': 1, 'max_features': 2, 'max_leaf_nodes': 2, 'min_samples_split': 5, 'n_estimators': 100}, 'config_hash': {'algorithm': 'e13eb05fd9a62d2f63bbb1c1deff0cd620d5e6ab', 'config': '4db6fb84d85f52659f780e682ffac5712c3d8a94', 'pipeline': '64c9a1ca9d53ae67244bdd942f4db36a3c05218c'}, 'duration': 1.7678282260894775, 'iteration': 1, 'loss': 0.18000000000000005, 'max_history_score': 0.9533333333333334, 'max_history_score_std': 0.059999999999999984, 'max_history_step': 'joint', 'pipeline': {'features': ('features_NoneType', {}), 'normalizer': ('normalizer_PowerTransformer', {}), 'rebalance': ('rebalance_NearMiss', {'rebalance__n_neighbors': 1})}, 'score': 0.82, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': 1, 'max_features': None, 'max_leaf_nodes': None, 'min_samples_split': 5, 'n_estimators': 75}, 'config_hash': {'algorithm': '94b0d7a654c508cc63643f78fe4f0f07e6f07c1e', 'config': '4403c5a85e951938d3c454e961d3a412780722f6', 'pipeline': '3e47444880d8367fbac2faaba2e52a917274aa58'}, 'duration': 0.8397619724273682, 'iteration': 2, 'loss': 0.03333333333333344, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_PCA', {'features__n_components': 3}), 'normalizer': ('normalizer_MinMaxScaler', {}), 'rebalance': ('rebalance_NoneType', {})}, 'score': 0.9666666666666666, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': None, 'max_features': None, 'max_leaf_nodes': 3, 'min_samples_split': 3, 'n_estimators': 75}, 'config_hash': {'algorithm': 'e8332f0a8902bda03bf70e7978cc5d52affb29d3', 'config': 'a064e2df18ab98d44dabcefbc7bed94913f1d0be', 'pipeline': '7eea819c2a8c103c4b1e9e9c1e224aebba95081f'}, 'duration': 0.8501448631286621, 'iteration': 3, 'loss': 0.053333333333333344, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 2, 'features__selectkbest__k': 4}), 'normalizer': ('normalizer_NoneType', {}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 7})}, 'score': 0.9466666666666667, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'entropy', 'max_depth': 3, 'max_features': 3, 'max_leaf_nodes': None, 'min_samples_split': 5, 'n_estimators': 75}, 'config_hash': {'algorithm': '7a4491035bc6bd737fe9a8cda8a79a02d02d5c74', 'config': '0ddb6f5cab3db4dddd7682966a57205f3e329ad4', 'pipeline': 'a9ae03fe38334f6868cbf84cdd3d629d4bbe3fb0'}, 'duration': 1.1026010513305664, 'iteration': 4, 'loss': 0.05999999999999994, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 2, 'features__selectkbest__k': 1}), 'normalizer': ('normalizer_NoneType', {}), 'rebalance': ('rebalance_NoneType', {})}, 'score': 0.9400000000000001, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'gini', 'max_depth': 3, 'max_features': 1, 'max_leaf_nodes': 5, 'min_samples_split': 2, 'n_estimators': 25}, 'config_hash': {'algorithm': '9826d20b2d6a0f559cf7f16450ce7526f07e8434', 'config': '49f25751bca61cdd461a8cbd2923689b642f98ed', 'pipeline': '19b249664c5bf067de1fed4334a296f947ce774a'}, 'duration': 0.35647010803222656, 'iteration': 5, 'loss': 0.046666666666666634, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_NoneType', {}), 'normalizer': ('normalizer_NoneType', {}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 6})}, 'score': 0.9533333333333334, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'gini', 'max_depth': 2, 'max_features': 1, 'max_leaf_nodes': 2, 'min_samples_split': 2, 'n_estimators': 50}, 'config_hash': {'algorithm': '0a4f6fbb07e0f32c6f675489a0fc82eee05bd8e1', 'config': '5c3a2b6f5e63fb45f10e41e0318b354912ec44f6', 'pipeline': 'dc3b9f176f090005e38b142f11d80e93a7dc5d5e'}, 'duration': 0.7213859558105469, 'iteration': 6, 'loss': 0.31333333333333324, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 1, 'features__selectkbest__k': 4}), 'normalizer': ('normalizer_PowerTransformer', {}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 7})}, 'score': 0.6866666666666668, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'entropy', 'max_depth': 4, 'max_features': 3, 'max_leaf_nodes': 5, 'min_samples_split': 5, 'n_estimators': 10}, 'config_hash': {'algorithm': 'b8112b97ecfc10f00a195af661dcc861cac21289', 'config': 'd3b129b397350f1b6572651c67c01de49b4b174c', 'pipeline': '5b0357ed7072c37b3d6f458bb5d49ff7d825f603'}, 'duration': 0.8299109935760498, 'iteration': 7, 'loss': 1.0, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_PCA', {'features__n_components': 2}), 'normalizer': ('normalizer_StandardScaler', {'normalizer__with_mean': True, 'normalizer__with_std': False}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 6})}, 'score': 0.0, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'gini', 'max_depth': 4, 'max_features': None, 'max_leaf_nodes': 2, 'min_samples_split': 5, 'n_estimators': 100}, 'config_hash': {'algorithm': '40ca24df19b8d164d9d098a6bed1ce056fbbb961', 'config': '813bde1108cc3c4b9bfb3a22cbb421bda7eac671', 'pipeline': '74a7b8705a1c22f7dea5e44e4ebda8f1e48add71'}, 'duration': 2.2111589908599854, 'iteration': 8, 'loss': 0.33333333333333326, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_PCA', {'features__n_components': 2}), 'normalizer': ('normalizer_StandardScaler', {'normalizer__with_mean': False, 'normalizer__with_std': True}), 'rebalance': ('rebalance_NearMiss', {'rebalance__n_neighbors': 2})}, 'score': 0.6666666666666667, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'entropy', 'max_depth': 2, 'max_features': 1, 'max_leaf_nodes': 5, 'min_samples_split': 2, 'n_estimators': 100}, 'config_hash': {'algorithm': '331418a5c12cf1453876eef85e9d98fc8e54fa11', 'config': '31930b6860ed406d59bf7e59ba1925d94704bd3b', 'pipeline': '054bef356f90ec6f644ef3ffc688766744db51c2'}, 'duration': 1.0501940250396729, 'iteration': 9, 'loss': 0.053333333333333344, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_SelectKBest', {'features__k': 1}), 'normalizer': ('normalizer_RobustScaler', {'normalizer__quantile_range': (...), 'normalizer__with_centering': True, 'normalizer__with_scaling': True}), 'rebalance': ('rebalance_NearMiss', {'rebalance__n_neighbors': 2})}, 'score': 0.9466666666666667, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'entropy', 'max_depth': 3, 'max_features': None, 'max_leaf_nodes': 3, 'min_samples_split': 2, 'n_estimators': 100}, 'config_hash': {'algorithm': 'dbc1b8126649fe93dce5fbb37e4015b0acfb179e', 'config': '9913cd550615a9d0946ab4a755a8b9f619e442fd', 'pipeline': 'dd626121cea079ebb32e184ca65483ec7a6d7f59'}, 'duration': 1.120617151260376, 'iteration': 10, 'loss': 0.046666666666666634, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 2, 'features__selectkbest__k': 1}), 'normalizer': ('normalizer_MinMaxScaler', {}), 'rebalance': ('rebalance_NoneType', {})}, 'score': 0.9533333333333334, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'gini', 'max_depth': 3, 'max_features': 3, 'max_leaf_nodes': None, 'min_samples_split': 3, 'n_estimators': 75}, 'config_hash': {'algorithm': '34917a130df5a975f78bd7ec1a0c7b1ffdc787a9', 'config': '95fc8cadc088141290b7de9c388977e4685f0108', 'pipeline': '550d10faf2f08db48516cc3501558816d6a99bc0'}, 'duration': 1.4287099838256836, 'iteration': 11, 'loss': 0.19333333333333313, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 3, 'features__selectkbest__k': 4}), 'normalizer': ('normalizer_StandardScaler', {'normalizer__with_mean': False, 'normalizer__with_std': False}), 'rebalance': ('rebalance_CondensedNearestNeighbour', {'rebalance__n_neighbors': 1})}, 'score': 0.8066666666666669, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'entropy', 'max_depth': 1, 'max_features': 2, 'max_leaf_nodes': 5, 'min_samples_split': 2, 'n_estimators': 75}, 'config_hash': {'algorithm': '33f9abb4aee44a395a9f3b3ffa9ce80a8cdaed7c', 'config': '40fa726f0360cf6af55f9b5902d399d02f61f157', 'pipeline': 'cfd1d20841fe2153da762c95e79f95a3fb1e426a'}, 'duration': 1.2978079319000244, 'iteration': 12, 'loss': 0.053333333333333344, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_PCA', {'features__n_components': 4}), 'normalizer': ('normalizer_MinMaxScaler', {}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 7})}, 'score': 0.9466666666666667, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'entropy', 'max_depth': 4, 'max_features': 2, 'max_leaf_nodes': 5, 'min_samples_split': 3, 'n_estimators': 25}, 'config_hash': {'algorithm': '210111ec6562d09eb093e98ed69ef1c662e11a50', 'config': '0fb8e77c7bd9a58b72f1b33c21a59a09a8c676ba', 'pipeline': '5d269d759e0c7926a685a14b263ace8ae0071e4b'}, 'duration': 0.36649012565612793, 'iteration': 13, 'loss': 0.040000000000000036, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 2, 'features__selectkbest__k': 2}), 'normalizer': ('normalizer_NoneType', {}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 7})}, 'score': 0.96, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'entropy', 'max_depth': 3, 'max_features': 1, 'max_leaf_nodes': 5, 'min_samples_split': 2, 'n_estimators': 25}, 'config_hash': {'algorithm': '0e989a03980101fabf79eda3326ed2870e11d690', 'config': 'f4bffd5d8c67a9c5321a9943c4a99678f59a02b7', 'pipeline': '865ee1e3fe8334c3d5ecb2038d5a5d1b3ba50e75'}, 'duration': 0.35639500617980957, 'iteration': 14, 'loss': 0.046666666666666634, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_NoneType', {}), 'normalizer': ('normalizer_RobustScaler', {'normalizer__quantile_range': (...), 'normalizer__with_centering': True, 'normalizer__with_scaling': False}), 'rebalance': ('rebalance_NoneType', {})}, 'score': 0.9533333333333334, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'entropy', 'max_depth': None, 'max_features': 3, 'max_leaf_nodes': 3, 'min_samples_split': 5, 'n_estimators': 10}, 'config_hash': {'algorithm': '9c592e876c13de5e23e6de5b868e01755d63e72e', 'config': '1e6a68cd1eeac886d90724d78b1cb5fb76a3cde4', 'pipeline': '5a1ca4d82f21b7de0d2c918630a42510673fa36e'}, 'duration': 0.18141412734985352, 'iteration': 15, 'loss': 0.046666666666666634, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_SelectKBest', {'features__k': 3}), 'normalizer': ('normalizer_RobustScaler', {'normalizer__quantile_range': (...), 'normalizer__with_centering': True, 'normalizer__with_scaling': True}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 6})}, 'score': 0.9533333333333334, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': 1, 'max_features': None, 'max_leaf_nodes': None, 'min_samples_split': 5, 'n_estimators': 10}, 'config_hash': {'algorithm': '8bed77aef289bfd453b2858bd288ae5ba7160f2b', 'config': '781185bcb8999045de8d489f253a1a1ba4247932', 'pipeline': '1ece7eabedc2be9e5b0a1be65c570d08ffa3eb54'}, 'duration': 0.1636829376220703, 'iteration': 16, 'loss': 0.053333333333333344, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_NoneType', {}), 'normalizer': ('normalizer_NoneType', {}), 'rebalance': ('rebalance_NearMiss', {'rebalance__n_neighbors': 1})}, 'score': 0.9466666666666667, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'gini', 'max_depth': 3, 'max_features': 2, 'max_leaf_nodes': 2, 'min_samples_split': 5, 'n_estimators': 75}, 'config_hash': {'algorithm': '617b97d9ba21d3373bc51ffa9cccf9c6f91a77b3', 'config': '99fb425b4e8c5d80228cab94202252aa25cdf77c', 'pipeline': 'd6242929c3b515c7719e60423023ac604311afc3'}, 'duration': 0.8468999862670898, 'iteration': 17, 'loss': 0.24, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_PCA', {'features__n_components': 4}), 'normalizer': ('normalizer_PowerTransformer', {}), 'rebalance': ('rebalance_NearMiss', {'rebalance__n_neighbors': 2})}, 'score': 0.76, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': 1, 'max_features': 1, 'max_leaf_nodes': 2, 'min_samples_split': 5, 'n_estimators': 50}, 'config_hash': {'algorithm': 'b92d2697cdd4979da443369d6596229ec091626a', 'config': 'c513a3e13281206ad76187dd817b1fff93d54fe1', 'pipeline': 'c4b4f914a3ca8df967cade997a90366d85a371b9'}, 'duration': 0.6724588871002197, 'iteration': 18, 'loss': 0.23333333333333328, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 1, 'features__selectkbest__k': 3}), 'normalizer': ('normalizer_StandardScaler', {'normalizer__with_mean': True, 'normalizer__with_std': True}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 5})}, 'score': 0.7666666666666667, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'entropy', 'max_depth': None, 'max_features': None, 'max_leaf_nodes': 5, 'min_samples_split': 5, 'n_estimators': 10}, 'config_hash': {'algorithm': 'a0115de695e6cca2e81cbfb54df79bf4b43608b1', 'config': 'ba194015e20b5d67770e8c67342c3d8d0d01dc41', 'pipeline': '8d45fabfeb85ffdcabf7076bd0e65fffe97ce928'}, 'duration': 0.19424200057983398, 'iteration': 19, 'loss': 0.08666666666666667, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_PCA', {'features__n_components': 3}), 'normalizer': ('normalizer_NoneType', {}), 'rebalance': ('rebalance_NoneType', {})}, 'score': 0.9133333333333333, ...}, ...], 'history_hash': ['db6ac7e6d348155757e4794bb5f88fe2b4f63d50', '4db6fb84d85f52659f780e682ffac5712c3d8a94', '4403c5a85e951938d3c454e961d3a412780722f6', 'a064e2df18ab98d44dabcefbc7bed94913f1d0be', '0ddb6f5cab3db4dddd7682966a57205f3e329ad4', '49f25751bca61cdd461a8cbd2923689b642f98ed', '5c3a2b6f5e63fb45f10e41e0318b354912ec44f6', 'd3b129b397350f1b6572651c67c01de49b4b174c', '813bde1108cc3c4b9bfb3a22cbb421bda7eac671', '31930b6860ed406d59bf7e59ba1925d94704bd3b', '9913cd550615a9d0946ab4a755a8b9f619e442fd', '95fc8cadc088141290b7de9c388977e4685f0108', '40fa726f0360cf6af55f9b5902d399d02f61f157', '0fb8e77c7bd9a58b72f1b33c21a59a09a8c676ba', 'f4bffd5d8c67a9c5321a9943c4a99678f59a02b7', '1e6a68cd1eeac886d90724d78b1cb5fb76a3cde4', '781185bcb8999045de8d489f253a1a1ba4247932', '99fb425b4e8c5d80228cab94202252aa25cdf77c', 'c513a3e13281206ad76187dd817b1fff93d54fe1', 'ba194015e20b5d67770e8c67342c3d8d0d01dc41', ...], 'history_index': {'013329309d510b94f19d930320402d65f953a847': 39, '038a0f515e2ec894ee8e34f9caa2889eb3ebd5ce': 66, '052ae4bf232b316187b078abae42c2be19e16a00': 111, '0659afebf316aafeb75612fb07081a04c28545ed': 74, '06e7cde9f3556cd01332ce389ad1d8925cd4b4a4': 120, '0b6551ecfd6f83a15704a9db68f1599c99c6d3ef': 58, '0ddb6f5cab3db4dddd7682966a57205f3e329ad4': 4, '0fb8e77c7bd9a58b72f1b33c21a59a09a8c676ba': 13, '111e2fd99e871044225b8638df965b2a16868e35': 110, '111ffc790caf02104464bfa2f448cba7c56c71dc': 46, ...}, 'iteration': 163, 'max_history_score': 0.9666666666666668, 'max_history_score_std': 0.033333333333333326, 'max_history_step': 'joint'}
        config = {'algorithm': 'RandomForest', 'seed': 42, 'time': 300}
    114 
    115 
    116 def get_baseline_score(algorithm, X, y, seed):
    117     pipeline, _ = pipeline_conf_to_full_pipeline(

...........................................................................
/home/aquemy/dev/dp_hyperparameters/extension/experiment/objective.py in objective(pipeline_config={'features': ('features_SelectKBest', {'features__k': 1}), 'normalizer': ('normalizer_NoneType', {}), 'rebalance': ('rebalance_CondensedNearestNeighbour', {'rebalance__n_neighbors': 3})}, algo_config={'bootstrap': True, 'criterion': 'gini', 'max_depth': 2, 'max_features': 3, 'max_leaf_nodes': 2, 'min_samples_split': 3, 'n_estimators': 75}, algorithm='RandomForest', X=array([[5.1, 3.5, 1.4, 0.2],
       [4.9, 3. , 1....2, 3.4, 5.4, 2.3],
       [5.9, 3. , 5.1, 1.8]]), y=array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,... 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]), context={'baseline_score': 0.9466666666666667, 'baseline_score_std': 0.04988876515698587, 'best_config': {'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': 4, 'max_features': 3, 'max_leaf_nodes': 3, 'min_samples_split': 3, 'n_estimators': 10}, 'config_hash': {'algorithm': 'ffb7ff225ce3d3712c96cf87fe42202988ee2eb0', 'config': 'bae32f426be9cd6243523c023944a8c148fe4aeb', 'pipeline': 'd2a68bfda6fcdec4ae0ffc7d7b6a2122bc1cd673'}, 'duration': 0.7115809917449951, 'iteration': 113, 'loss': 0.033333333333333215, 'max_history_score': 0.9666666666666668, 'max_history_score_std': 0.033333333333333326, 'max_history_step': 'joint', 'pipeline': {'features': ('features_NoneType', {}), 'normalizer': ('normalizer_PowerTransformer', {}), 'rebalance': ('rebalance_CondensedNearestNeighbour', {'rebalance__n_neighbors': 2})}, 'score': 0.9666666666666668, ...}, 'history': [{'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': 2, 'max_features': None, 'max_leaf_nodes': 5, 'min_samples_split': 2, 'n_estimators': 75}, 'config_hash': {'algorithm': '3af5b0cce71c8fe2545246ca24ff5bc3dd516e06', 'config': 'db6ac7e6d348155757e4794bb5f88fe2b4f63d50', 'pipeline': '8d59f4b94cef6be9306ed86a22a9570fa670d567'}, 'duration': 1.149928092956543, 'iteration': 0, 'loss': 0.046666666666666634, 'max_history_score': 0.9533333333333334, 'max_history_score_std': 0.059999999999999984, 'max_history_step': 'joint', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 4, 'features__selectkbest__k': 3}), 'normalizer': ('normalizer_StandardScaler', {'normalizer__with_mean': True, 'normalizer__with_std': True}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 6})}, 'score': 0.9533333333333334, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': 1, 'max_features': 2, 'max_leaf_nodes': 2, 'min_samples_split': 5, 'n_estimators': 100}, 'config_hash': {'algorithm': 'e13eb05fd9a62d2f63bbb1c1deff0cd620d5e6ab', 'config': '4db6fb84d85f52659f780e682ffac5712c3d8a94', 'pipeline': '64c9a1ca9d53ae67244bdd942f4db36a3c05218c'}, 'duration': 1.7678282260894775, 'iteration': 1, 'loss': 0.18000000000000005, 'max_history_score': 0.9533333333333334, 'max_history_score_std': 0.059999999999999984, 'max_history_step': 'joint', 'pipeline': {'features': ('features_NoneType', {}), 'normalizer': ('normalizer_PowerTransformer', {}), 'rebalance': ('rebalance_NearMiss', {'rebalance__n_neighbors': 1})}, 'score': 0.82, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': 1, 'max_features': None, 'max_leaf_nodes': None, 'min_samples_split': 5, 'n_estimators': 75}, 'config_hash': {'algorithm': '94b0d7a654c508cc63643f78fe4f0f07e6f07c1e', 'config': '4403c5a85e951938d3c454e961d3a412780722f6', 'pipeline': '3e47444880d8367fbac2faaba2e52a917274aa58'}, 'duration': 0.8397619724273682, 'iteration': 2, 'loss': 0.03333333333333344, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_PCA', {'features__n_components': 3}), 'normalizer': ('normalizer_MinMaxScaler', {}), 'rebalance': ('rebalance_NoneType', {})}, 'score': 0.9666666666666666, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': None, 'max_features': None, 'max_leaf_nodes': 3, 'min_samples_split': 3, 'n_estimators': 75}, 'config_hash': {'algorithm': 'e8332f0a8902bda03bf70e7978cc5d52affb29d3', 'config': 'a064e2df18ab98d44dabcefbc7bed94913f1d0be', 'pipeline': '7eea819c2a8c103c4b1e9e9c1e224aebba95081f'}, 'duration': 0.8501448631286621, 'iteration': 3, 'loss': 0.053333333333333344, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 2, 'features__selectkbest__k': 4}), 'normalizer': ('normalizer_NoneType', {}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 7})}, 'score': 0.9466666666666667, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'entropy', 'max_depth': 3, 'max_features': 3, 'max_leaf_nodes': None, 'min_samples_split': 5, 'n_estimators': 75}, 'config_hash': {'algorithm': '7a4491035bc6bd737fe9a8cda8a79a02d02d5c74', 'config': '0ddb6f5cab3db4dddd7682966a57205f3e329ad4', 'pipeline': 'a9ae03fe38334f6868cbf84cdd3d629d4bbe3fb0'}, 'duration': 1.1026010513305664, 'iteration': 4, 'loss': 0.05999999999999994, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 2, 'features__selectkbest__k': 1}), 'normalizer': ('normalizer_NoneType', {}), 'rebalance': ('rebalance_NoneType', {})}, 'score': 0.9400000000000001, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'gini', 'max_depth': 3, 'max_features': 1, 'max_leaf_nodes': 5, 'min_samples_split': 2, 'n_estimators': 25}, 'config_hash': {'algorithm': '9826d20b2d6a0f559cf7f16450ce7526f07e8434', 'config': '49f25751bca61cdd461a8cbd2923689b642f98ed', 'pipeline': '19b249664c5bf067de1fed4334a296f947ce774a'}, 'duration': 0.35647010803222656, 'iteration': 5, 'loss': 0.046666666666666634, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_NoneType', {}), 'normalizer': ('normalizer_NoneType', {}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 6})}, 'score': 0.9533333333333334, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'gini', 'max_depth': 2, 'max_features': 1, 'max_leaf_nodes': 2, 'min_samples_split': 2, 'n_estimators': 50}, 'config_hash': {'algorithm': '0a4f6fbb07e0f32c6f675489a0fc82eee05bd8e1', 'config': '5c3a2b6f5e63fb45f10e41e0318b354912ec44f6', 'pipeline': 'dc3b9f176f090005e38b142f11d80e93a7dc5d5e'}, 'duration': 0.7213859558105469, 'iteration': 6, 'loss': 0.31333333333333324, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 1, 'features__selectkbest__k': 4}), 'normalizer': ('normalizer_PowerTransformer', {}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 7})}, 'score': 0.6866666666666668, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'entropy', 'max_depth': 4, 'max_features': 3, 'max_leaf_nodes': 5, 'min_samples_split': 5, 'n_estimators': 10}, 'config_hash': {'algorithm': 'b8112b97ecfc10f00a195af661dcc861cac21289', 'config': 'd3b129b397350f1b6572651c67c01de49b4b174c', 'pipeline': '5b0357ed7072c37b3d6f458bb5d49ff7d825f603'}, 'duration': 0.8299109935760498, 'iteration': 7, 'loss': 1.0, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_PCA', {'features__n_components': 2}), 'normalizer': ('normalizer_StandardScaler', {'normalizer__with_mean': True, 'normalizer__with_std': False}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 6})}, 'score': 0.0, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'gini', 'max_depth': 4, 'max_features': None, 'max_leaf_nodes': 2, 'min_samples_split': 5, 'n_estimators': 100}, 'config_hash': {'algorithm': '40ca24df19b8d164d9d098a6bed1ce056fbbb961', 'config': '813bde1108cc3c4b9bfb3a22cbb421bda7eac671', 'pipeline': '74a7b8705a1c22f7dea5e44e4ebda8f1e48add71'}, 'duration': 2.2111589908599854, 'iteration': 8, 'loss': 0.33333333333333326, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_PCA', {'features__n_components': 2}), 'normalizer': ('normalizer_StandardScaler', {'normalizer__with_mean': False, 'normalizer__with_std': True}), 'rebalance': ('rebalance_NearMiss', {'rebalance__n_neighbors': 2})}, 'score': 0.6666666666666667, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'entropy', 'max_depth': 2, 'max_features': 1, 'max_leaf_nodes': 5, 'min_samples_split': 2, 'n_estimators': 100}, 'config_hash': {'algorithm': '331418a5c12cf1453876eef85e9d98fc8e54fa11', 'config': '31930b6860ed406d59bf7e59ba1925d94704bd3b', 'pipeline': '054bef356f90ec6f644ef3ffc688766744db51c2'}, 'duration': 1.0501940250396729, 'iteration': 9, 'loss': 0.053333333333333344, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_SelectKBest', {'features__k': 1}), 'normalizer': ('normalizer_RobustScaler', {'normalizer__quantile_range': (...), 'normalizer__with_centering': True, 'normalizer__with_scaling': True}), 'rebalance': ('rebalance_NearMiss', {'rebalance__n_neighbors': 2})}, 'score': 0.9466666666666667, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'entropy', 'max_depth': 3, 'max_features': None, 'max_leaf_nodes': 3, 'min_samples_split': 2, 'n_estimators': 100}, 'config_hash': {'algorithm': 'dbc1b8126649fe93dce5fbb37e4015b0acfb179e', 'config': '9913cd550615a9d0946ab4a755a8b9f619e442fd', 'pipeline': 'dd626121cea079ebb32e184ca65483ec7a6d7f59'}, 'duration': 1.120617151260376, 'iteration': 10, 'loss': 0.046666666666666634, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 2, 'features__selectkbest__k': 1}), 'normalizer': ('normalizer_MinMaxScaler', {}), 'rebalance': ('rebalance_NoneType', {})}, 'score': 0.9533333333333334, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'gini', 'max_depth': 3, 'max_features': 3, 'max_leaf_nodes': None, 'min_samples_split': 3, 'n_estimators': 75}, 'config_hash': {'algorithm': '34917a130df5a975f78bd7ec1a0c7b1ffdc787a9', 'config': '95fc8cadc088141290b7de9c388977e4685f0108', 'pipeline': '550d10faf2f08db48516cc3501558816d6a99bc0'}, 'duration': 1.4287099838256836, 'iteration': 11, 'loss': 0.19333333333333313, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 3, 'features__selectkbest__k': 4}), 'normalizer': ('normalizer_StandardScaler', {'normalizer__with_mean': False, 'normalizer__with_std': False}), 'rebalance': ('rebalance_CondensedNearestNeighbour', {'rebalance__n_neighbors': 1})}, 'score': 0.8066666666666669, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'entropy', 'max_depth': 1, 'max_features': 2, 'max_leaf_nodes': 5, 'min_samples_split': 2, 'n_estimators': 75}, 'config_hash': {'algorithm': '33f9abb4aee44a395a9f3b3ffa9ce80a8cdaed7c', 'config': '40fa726f0360cf6af55f9b5902d399d02f61f157', 'pipeline': 'cfd1d20841fe2153da762c95e79f95a3fb1e426a'}, 'duration': 1.2978079319000244, 'iteration': 12, 'loss': 0.053333333333333344, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_PCA', {'features__n_components': 4}), 'normalizer': ('normalizer_MinMaxScaler', {}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 7})}, 'score': 0.9466666666666667, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'entropy', 'max_depth': 4, 'max_features': 2, 'max_leaf_nodes': 5, 'min_samples_split': 3, 'n_estimators': 25}, 'config_hash': {'algorithm': '210111ec6562d09eb093e98ed69ef1c662e11a50', 'config': '0fb8e77c7bd9a58b72f1b33c21a59a09a8c676ba', 'pipeline': '5d269d759e0c7926a685a14b263ace8ae0071e4b'}, 'duration': 0.36649012565612793, 'iteration': 13, 'loss': 0.040000000000000036, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 2, 'features__selectkbest__k': 2}), 'normalizer': ('normalizer_NoneType', {}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 7})}, 'score': 0.96, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'entropy', 'max_depth': 3, 'max_features': 1, 'max_leaf_nodes': 5, 'min_samples_split': 2, 'n_estimators': 25}, 'config_hash': {'algorithm': '0e989a03980101fabf79eda3326ed2870e11d690', 'config': 'f4bffd5d8c67a9c5321a9943c4a99678f59a02b7', 'pipeline': '865ee1e3fe8334c3d5ecb2038d5a5d1b3ba50e75'}, 'duration': 0.35639500617980957, 'iteration': 14, 'loss': 0.046666666666666634, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_NoneType', {}), 'normalizer': ('normalizer_RobustScaler', {'normalizer__quantile_range': (...), 'normalizer__with_centering': True, 'normalizer__with_scaling': False}), 'rebalance': ('rebalance_NoneType', {})}, 'score': 0.9533333333333334, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'entropy', 'max_depth': None, 'max_features': 3, 'max_leaf_nodes': 3, 'min_samples_split': 5, 'n_estimators': 10}, 'config_hash': {'algorithm': '9c592e876c13de5e23e6de5b868e01755d63e72e', 'config': '1e6a68cd1eeac886d90724d78b1cb5fb76a3cde4', 'pipeline': '5a1ca4d82f21b7de0d2c918630a42510673fa36e'}, 'duration': 0.18141412734985352, 'iteration': 15, 'loss': 0.046666666666666634, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_SelectKBest', {'features__k': 3}), 'normalizer': ('normalizer_RobustScaler', {'normalizer__quantile_range': (...), 'normalizer__with_centering': True, 'normalizer__with_scaling': True}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 6})}, 'score': 0.9533333333333334, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': 1, 'max_features': None, 'max_leaf_nodes': None, 'min_samples_split': 5, 'n_estimators': 10}, 'config_hash': {'algorithm': '8bed77aef289bfd453b2858bd288ae5ba7160f2b', 'config': '781185bcb8999045de8d489f253a1a1ba4247932', 'pipeline': '1ece7eabedc2be9e5b0a1be65c570d08ffa3eb54'}, 'duration': 0.1636829376220703, 'iteration': 16, 'loss': 0.053333333333333344, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_NoneType', {}), 'normalizer': ('normalizer_NoneType', {}), 'rebalance': ('rebalance_NearMiss', {'rebalance__n_neighbors': 1})}, 'score': 0.9466666666666667, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'gini', 'max_depth': 3, 'max_features': 2, 'max_leaf_nodes': 2, 'min_samples_split': 5, 'n_estimators': 75}, 'config_hash': {'algorithm': '617b97d9ba21d3373bc51ffa9cccf9c6f91a77b3', 'config': '99fb425b4e8c5d80228cab94202252aa25cdf77c', 'pipeline': 'd6242929c3b515c7719e60423023ac604311afc3'}, 'duration': 0.8468999862670898, 'iteration': 17, 'loss': 0.24, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_PCA', {'features__n_components': 4}), 'normalizer': ('normalizer_PowerTransformer', {}), 'rebalance': ('rebalance_NearMiss', {'rebalance__n_neighbors': 2})}, 'score': 0.76, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': 1, 'max_features': 1, 'max_leaf_nodes': 2, 'min_samples_split': 5, 'n_estimators': 50}, 'config_hash': {'algorithm': 'b92d2697cdd4979da443369d6596229ec091626a', 'config': 'c513a3e13281206ad76187dd817b1fff93d54fe1', 'pipeline': 'c4b4f914a3ca8df967cade997a90366d85a371b9'}, 'duration': 0.6724588871002197, 'iteration': 18, 'loss': 0.23333333333333328, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 1, 'features__selectkbest__k': 3}), 'normalizer': ('normalizer_StandardScaler', {'normalizer__with_mean': True, 'normalizer__with_std': True}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 5})}, 'score': 0.7666666666666667, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'entropy', 'max_depth': None, 'max_features': None, 'max_leaf_nodes': 5, 'min_samples_split': 5, 'n_estimators': 10}, 'config_hash': {'algorithm': 'a0115de695e6cca2e81cbfb54df79bf4b43608b1', 'config': 'ba194015e20b5d67770e8c67342c3d8d0d01dc41', 'pipeline': '8d45fabfeb85ffdcabf7076bd0e65fffe97ce928'}, 'duration': 0.19424200057983398, 'iteration': 19, 'loss': 0.08666666666666667, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_PCA', {'features__n_components': 3}), 'normalizer': ('normalizer_NoneType', {}), 'rebalance': ('rebalance_NoneType', {})}, 'score': 0.9133333333333333, ...}, ...], 'history_hash': ['db6ac7e6d348155757e4794bb5f88fe2b4f63d50', '4db6fb84d85f52659f780e682ffac5712c3d8a94', '4403c5a85e951938d3c454e961d3a412780722f6', 'a064e2df18ab98d44dabcefbc7bed94913f1d0be', '0ddb6f5cab3db4dddd7682966a57205f3e329ad4', '49f25751bca61cdd461a8cbd2923689b642f98ed', '5c3a2b6f5e63fb45f10e41e0318b354912ec44f6', 'd3b129b397350f1b6572651c67c01de49b4b174c', '813bde1108cc3c4b9bfb3a22cbb421bda7eac671', '31930b6860ed406d59bf7e59ba1925d94704bd3b', '9913cd550615a9d0946ab4a755a8b9f619e442fd', '95fc8cadc088141290b7de9c388977e4685f0108', '40fa726f0360cf6af55f9b5902d399d02f61f157', '0fb8e77c7bd9a58b72f1b33c21a59a09a8c676ba', 'f4bffd5d8c67a9c5321a9943c4a99678f59a02b7', '1e6a68cd1eeac886d90724d78b1cb5fb76a3cde4', '781185bcb8999045de8d489f253a1a1ba4247932', '99fb425b4e8c5d80228cab94202252aa25cdf77c', 'c513a3e13281206ad76187dd817b1fff93d54fe1', 'ba194015e20b5d67770e8c67342c3d8d0d01dc41', ...], 'history_index': {'013329309d510b94f19d930320402d65f953a847': 39, '038a0f515e2ec894ee8e34f9caa2889eb3ebd5ce': 66, '052ae4bf232b316187b078abae42c2be19e16a00': 111, '0659afebf316aafeb75612fb07081a04c28545ed': 74, '06e7cde9f3556cd01332ce389ad1d8925cd4b4a4': 120, '0b6551ecfd6f83a15704a9db68f1599c99c6d3ef': 58, '0ddb6f5cab3db4dddd7682966a57205f3e329ad4': 4, '0fb8e77c7bd9a58b72f1b33c21a59a09a8c676ba': 13, '111e2fd99e871044225b8638df965b2a16868e35': 110, '111ffc790caf02104464bfa2f448cba7c56c71dc': 46, ...}, 'iteration': 163, 'max_history_score': 0.9666666666666668, 'max_history_score_std': 0.033333333333333326, 'max_history_step': 'joint'}, config={'algorithm': 'RandomForest', 'seed': 42, 'time': 300}, step='joint')
     45                 y,
     46                 cv=10,
     47                 n_jobs=-1,
     48                 return_estimator=False,
     49                 return_train_score=False,
---> 50                 verbose=0)
     51         score = np.mean(scores['test_score'])
     52         std = np.std(scores['test_score'])
     53         status = STATUS_OK
     54     except Exception as e:

...........................................................................
/home/aquemy/.local/lib/python2.7/site-packages/sklearn/model_selection/_validation.py in cross_validate(estimator=Pipeline(memory=None,
     steps=[('rebalance', ... random_state=42, verbose=0, warm_start=False))]), X=array([[5.1, 3.5, 1.4, 0.2],
       [4.9, 3. , 1....2, 3.4, 5.4, 2.3],
       [5.9, 3. , 5.1, 1.8]]), y=array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,... 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]), groups=None, scoring=None, cv=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1, verbose=0, fit_params=None, pre_dispatch='2*n_jobs', return_train_score=False, return_estimator=False, error_score='raise-deprecating')
    235         delayed(_fit_and_score)(
    236             clone(estimator), X, y, scorers, train, test, verbose, None,
    237             fit_params, return_train_score=return_train_score,
    238             return_times=True, return_estimator=return_estimator,
    239             error_score=error_score)
--> 240         for train, test in cv.split(X, y, groups))
        cv.split = <bound method StratifiedKFold.split of Stratifie...d(n_splits=10, random_state=None, shuffle=False)>
        X = array([[5.1, 3.5, 1.4, 0.2],
       [4.9, 3. , 1....2, 3.4, 5.4, 2.3],
       [5.9, 3. , 5.1, 1.8]])
        y = array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,... 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2])
        groups = None
    241 
    242     zipped_scores = list(zip(*scores))
    243     if return_train_score:
    244         train_scores = zipped_scores.pop(0)

...........................................................................
/home/aquemy/.local/lib/python2.7/site-packages/sklearn/externals/joblib/parallel.py in __call__(self=Parallel(n_jobs=-1), iterable=<generator object <genexpr>>)
    925                 # No need to wait for async callbacks to trigger to
    926                 # consumption.
    927                 self._iterating = False
    928 
    929             with self._backend.retrieval_context():
--> 930                 self.retrieve()
        self.retrieve = <bound method Parallel.retrieve of Parallel(n_jobs=-1)>
    931             # Make sure that we get a last message telling us we are done
    932             elapsed_time = time.time() - self._start_time
    933             self._print('Done %3i out of %3i | elapsed: %s finished',
    934                         (len(self._output), len(self._output),

---------------------------------------------------------------------------
Joblib worker traceback:
---------------------------------------------------------------------------
ValueError                                         Mon Jun 17 13:12:51 2019
PID: 21219                                  Python 2.7.15+: /usr/bin/python
...........................................................................
/home/aquemy/.local/lib/python2.7/site-packages/sklearn/externals/joblib/parallel.py in __call__(self=<sklearn.externals.joblib.parallel.BatchedCalls object>)
    220     def __call__(self):
    221         # Set the default nested backend to self._backend but do not set the
    222         # change the default number of processes to -1
    223         with parallel_backend(self._backend, n_jobs=self._n_jobs):
    224             return [func(*args, **kwargs)
--> 225                     for func, args, kwargs in self.items]
        func = <function _fit_and_score>
        args = (Pipeline(memory=None,
     steps=[('rebalance', ... random_state=42, verbose=0, warm_start=False))]), array([[5.1, 3.5, 1.4, 0.2],
       [4.9, 3. , 1....2, 3.4, 5.4, 2.3],
       [5.9, 3. , 5.1, 1.8]]), array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,... 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]), {'score': <function _passthrough_scorer>}, array([  5,   6,   7,   8,   9,  10,  11,  12,  ..., 142, 143, 144,
       145, 146, 147, 148, 149]), array([  0,   1,   2,   3,   4,  50,  51,  52,  53,  54, 100, 101, 102,
       103, 104]), 0, None, None)
        kwargs = {'error_score': 'raise-deprecating', 'return_estimator': False, 'return_times': True, 'return_train_score': False}
        self.items = [(<function _fit_and_score>, (Pipeline(memory=None,
     steps=[('rebalance', ... random_state=42, verbose=0, warm_start=False))]), array([[5.1, 3.5, 1.4, 0.2],
       [4.9, 3. , 1....2, 3.4, 5.4, 2.3],
       [5.9, 3. , 5.1, 1.8]]), array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,... 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]), {'score': <function _passthrough_scorer>}, array([  5,   6,   7,   8,   9,  10,  11,  12,  ..., 142, 143, 144,
       145, 146, 147, 148, 149]), array([  0,   1,   2,   3,   4,  50,  51,  52,  53,  54, 100, 101, 102,
       103, 104]), 0, None, None), {'error_score': 'raise-deprecating', 'return_estimator': False, 'return_times': True, 'return_train_score': False})]
    226 
    227     def __len__(self):
    228         return self._size
    229 

...........................................................................
/home/aquemy/.local/lib/python2.7/site-packages/sklearn/model_selection/_validation.py in _fit_and_score(estimator=Pipeline(memory=None,
     steps=[('rebalance', ... random_state=42, verbose=0, warm_start=False))]), X=array([[5.1, 3.5, 1.4, 0.2],
       [4.9, 3. , 1....2, 3.4, 5.4, 2.3],
       [5.9, 3. , 5.1, 1.8]]), y=array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,... 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]), scorer={'score': <function _passthrough_scorer>}, train=array([  5,   6,   7,   8,   9,  10,  11,  12,  ..., 142, 143, 144,
       145, 146, 147, 148, 149]), test=array([  0,   1,   2,   3,   4,  50,  51,  52,  53,  54, 100, 101, 102,
       103, 104]), verbose=0, parameters=None, fit_params={}, return_train_score=False, return_parameters=False, return_n_test_samples=False, return_times=True, return_estimator=False, error_score='raise-deprecating')
    523 
    524     try:
    525         if y_train is None:
    526             estimator.fit(X_train, **fit_params)
    527         else:
--> 528             estimator.fit(X_train, y_train, **fit_params)
        estimator.fit = <bound method Pipeline.fit of Pipeline(memory=No...random_state=42, verbose=0, warm_start=False))])>
        X_train = array([[5.4, 3.9, 1.7, 0.4],
       [4.6, 3.4, 1....2, 3.4, 5.4, 2.3],
       [5.9, 3. , 5.1, 1.8]])
        y_train = array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,
       2, 2, 2])
        fit_params = {}
    529 
    530     except Exception as e:
    531         # Note fit time as time until error
    532         fit_time = time.time() - start_time

...........................................................................
/usr/local/lib/python2.7/dist-packages/imblearn/pipeline.py in fit(self=Pipeline(memory=None,
     steps=[('rebalance', ... random_state=42, verbose=0, warm_start=False))]), X=array([[5.4, 3.9, 1.7, 0.4],
       [4.6, 3.4, 1....2, 3.4, 5.4, 2.3],
       [5.9, 3. , 5.1, 1.8]]), y=array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,
       2, 2, 2]), **fit_params={})
    234             This estimator
    235 
    236         """
    237         Xt, yt, fit_params = self._fit(X, y, **fit_params)
    238         if self._final_estimator is not None:
--> 239             self._final_estimator.fit(Xt, yt, **fit_params)
        self._final_estimator.fit = <bound method RandomForestClassifier.fit of Rand...e, random_state=42, verbose=0, warm_start=False)>
        Xt = array([[0.4],
       [0.3],
       [0.2],
      ...[1.3],
       [2. ],
       [2.1],
       [1.7]])
        yt = array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...0, 0, 0, 0, 0, 0, 0, 0,
       0, 1, 1, 2, 2, 2])
        fit_params = {}
    240         return self
    241 
    242     def fit_transform(self, X, y=None, **fit_params):
    243         """Fit the model and transform with the final estimator

...........................................................................
/home/aquemy/.local/lib/python2.7/site-packages/sklearn/ensemble/forest.py in fit(self=RandomForestClassifier(bootstrap=True, class_wei...se, random_state=42, verbose=0, warm_start=False), X=array([[0.4],
       [0.3],
       [0.2],
      ...2. ],
       [2.1],
       [1.7]], dtype=float32), y=array([[0.],
       [0.],
       [0.],
       [0...    [1.],
       [2.],
       [2.],
       [2.]]), sample_weight=None)
    328             trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,
    329                              **_joblib_parallel_args(prefer='threads'))(
    330                 delayed(_parallel_build_trees)(
    331                     t, self, X, y, sample_weight, i, len(trees),
    332                     verbose=self.verbose, class_weight=self.class_weight)
--> 333                 for i, t in enumerate(trees))
        i = 74
    334 
    335             # Collect newly grown trees
    336             self.estimators_.extend(trees)
    337 

...........................................................................
/home/aquemy/.local/lib/python2.7/site-packages/sklearn/externals/joblib/parallel.py in __call__(self=Parallel(n_jobs=1), iterable=<generator object <genexpr>>)
    912             # self._original_iterator is None, then this means either
    913             # that pre_dispatch == "all", n_jobs == 1 or that the first batch
    914             # was very quick and its callback already dispatched all the
    915             # remaining jobs.
    916             self._iterating = False
--> 917             if self.dispatch_one_batch(iterator):
        self.dispatch_one_batch = <bound method Parallel.dispatch_one_batch of Parallel(n_jobs=1)>
        iterator = <generator object <genexpr>>
    918                 self._iterating = self._original_iterator is not None
    919 
    920             while self.dispatch_one_batch(iterator):
    921                 pass

...........................................................................
/home/aquemy/.local/lib/python2.7/site-packages/sklearn/externals/joblib/parallel.py in dispatch_one_batch(self=Parallel(n_jobs=1), iterator=<generator object <genexpr>>)
    754                                  self._pickle_cache)
    755             if len(tasks) == 0:
    756                 # No more tasks available in the iterator: tell caller to stop.
    757                 return False
    758             else:
--> 759                 self._dispatch(tasks)
        self._dispatch = <bound method Parallel._dispatch of Parallel(n_jobs=1)>
        tasks = <sklearn.externals.joblib.parallel.BatchedCalls object>
    760                 return True
    761 
    762     def _print(self, msg, msg_args):
    763         """Display the message on stout or stderr depending on verbosity"""

...........................................................................
/home/aquemy/.local/lib/python2.7/site-packages/sklearn/externals/joblib/parallel.py in _dispatch(self=Parallel(n_jobs=1), batch=<sklearn.externals.joblib.parallel.BatchedCalls object>)
    711 
    712         dispatch_timestamp = time.time()
    713         cb = BatchCompletionCallBack(dispatch_timestamp, len(batch), self)
    714         with self._lock:
    715             job_idx = len(self._jobs)
--> 716             job = self._backend.apply_async(batch, callback=cb)
        job = undefined
        self._backend.apply_async = <bound method SequentialBackend.apply_async of <...lib._parallel_backends.SequentialBackend object>>
        batch = <sklearn.externals.joblib.parallel.BatchedCalls object>
        cb = <sklearn.externals.joblib.parallel.BatchCompletionCallBack object>
    717             # A job can complete so quickly than its callback is
    718             # called before we get here, causing self._jobs to
    719             # grow. To ensure correct results ordering, .insert is
    720             # used (rather than .append) in the following line

...........................................................................
/home/aquemy/.local/lib/python2.7/site-packages/sklearn/externals/joblib/_parallel_backends.py in apply_async(self=<sklearn.externals.joblib._parallel_backends.SequentialBackend object>, func=<sklearn.externals.joblib.parallel.BatchedCalls object>, callback=<sklearn.externals.joblib.parallel.BatchCompletionCallBack object>)
    177             raise ValueError('n_jobs == 0 in Parallel has no meaning')
    178         return 1
    179 
    180     def apply_async(self, func, callback=None):
    181         """Schedule a func to be run"""
--> 182         result = ImmediateResult(func)
        result = undefined
        func = <sklearn.externals.joblib.parallel.BatchedCalls object>
    183         if callback:
    184             callback(result)
    185         return result
    186 

...........................................................................
/home/aquemy/.local/lib/python2.7/site-packages/sklearn/externals/joblib/_parallel_backends.py in __init__(self=<sklearn.externals.joblib._parallel_backends.ImmediateResult object>, batch=<sklearn.externals.joblib.parallel.BatchedCalls object>)
    544 
    545 class ImmediateResult(object):
    546     def __init__(self, batch):
    547         # Don't delay the application, to avoid keeping the input
    548         # arguments in memory
--> 549         self.results = batch()
        self.results = undefined
        batch = <sklearn.externals.joblib.parallel.BatchedCalls object>
    550 
    551     def get(self):
    552         return self.results
    553 

...........................................................................
/home/aquemy/.local/lib/python2.7/site-packages/sklearn/externals/joblib/parallel.py in __call__(self=<sklearn.externals.joblib.parallel.BatchedCalls object>)
    220     def __call__(self):
    221         # Set the default nested backend to self._backend but do not set the
    222         # change the default number of processes to -1
    223         with parallel_backend(self._backend, n_jobs=self._n_jobs):
    224             return [func(*args, **kwargs)
--> 225                     for func, args, kwargs in self.items]
        func = <function _parallel_build_trees>
        args = (DecisionTreeClassifier(class_weight=None, criter...=False, random_state=1608637542, splitter='best'), RandomForestClassifier(bootstrap=True, class_wei...se, random_state=42, verbose=0, warm_start=False), array([[0.4],
       [0.3],
       [0.2],
      ...2. ],
       [2.1],
       [1.7]], dtype=float32), array([[0.],
       [0.],
       [0.],
       [0...    [1.],
       [2.],
       [2.],
       [2.]]), None, 0, 75)
        kwargs = {'class_weight': None, 'verbose': 0}
        self.items = [(<function _parallel_build_trees>, (DecisionTreeClassifier(class_weight=None, criter...=False, random_state=1608637542, splitter='best'), RandomForestClassifier(bootstrap=True, class_wei...se, random_state=42, verbose=0, warm_start=False), array([[0.4],
       [0.3],
       [0.2],
      ...2. ],
       [2.1],
       [1.7]], dtype=float32), array([[0.],
       [0.],
       [0.],
       [0...    [1.],
       [2.],
       [2.],
       [2.]]), None, 0, 75), {'class_weight': None, 'verbose': 0})]
    226 
    227     def __len__(self):
    228         return self._size
    229 

...........................................................................
/home/aquemy/.local/lib/python2.7/site-packages/sklearn/ensemble/forest.py in _parallel_build_trees(tree=DecisionTreeClassifier(class_weight=None, criter...=False, random_state=1608637542, splitter='best'), forest=RandomForestClassifier(bootstrap=True, class_wei...se, random_state=42, verbose=0, warm_start=False), X=array([[0.4],
       [0.3],
       [0.2],
      ...2. ],
       [2.1],
       [1.7]], dtype=float32), y=array([[0.],
       [0.],
       [0.],
       [0...    [1.],
       [2.],
       [2.],
       [2.]]), sample_weight=None, tree_idx=0, n_trees=75, verbose=0, class_weight=None)
    114                 simplefilter('ignore', DeprecationWarning)
    115                 curr_sample_weight *= compute_sample_weight('auto', y, indices)
    116         elif class_weight == 'balanced_subsample':
    117             curr_sample_weight *= compute_sample_weight('balanced', y, indices)
    118 
--> 119         tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)
        tree.fit = <bound method DecisionTreeClassifier.fit of Deci...False, random_state=1608637542, splitter='best')>
        X = array([[0.4],
       [0.3],
       [0.2],
      ...2. ],
       [2.1],
       [1.7]], dtype=float32)
        y = array([[0.],
       [0.],
       [0.],
       [0...    [1.],
       [2.],
       [2.],
       [2.]])
        sample_weight = None
        curr_sample_weight = array([2., 0., 2., 1., 2., 0., 1., 2., 1., 1., 2... 0., 2., 0., 5., 0., 2., 0., 0., 1., 0., 0., 3.])
    120     else:
    121         tree.fit(X, y, sample_weight=sample_weight, check_input=False)
    122 
    123     return tree

...........................................................................
/home/aquemy/.local/lib/python2.7/site-packages/sklearn/tree/tree.py in fit(self=DecisionTreeClassifier(class_weight=None, criter...=False, random_state=1608637542, splitter='best'), X=array([[0.4],
       [0.3],
       [0.2],
      ...2. ],
       [2.1],
       [1.7]], dtype=float32), y=array([[0.],
       [0.],
       [0.],
       [0...    [1.],
       [2.],
       [2.],
       [2.]]), sample_weight=array([2., 0., 2., 1., 2., 0., 1., 2., 1., 1., 2... 0., 2., 0., 5., 0., 2., 0., 0., 1., 0., 0., 3.]), check_input=False, X_idx_sorted=None)
    796 
    797         super(DecisionTreeClassifier, self).fit(
    798             X, y,
    799             sample_weight=sample_weight,
    800             check_input=check_input,
--> 801             X_idx_sorted=X_idx_sorted)
        X_idx_sorted = None
    802         return self
    803 
    804     def predict_proba(self, X, check_input=True):
    805         """Predict class probabilities of the input samples X.

...........................................................................
/home/aquemy/.local/lib/python2.7/site-packages/sklearn/tree/tree.py in fit(self=DecisionTreeClassifier(class_weight=None, criter...=False, random_state=1608637542, splitter='best'), X=array([[0.4],
       [0.3],
       [0.2],
      ...2. ],
       [2.1],
       [1.7]], dtype=float32), y=array([[0.],
       [0.],
       [0.],
       [0...    [1.],
       [2.],
       [2.],
       [2.]]), sample_weight=array([2., 0., 2., 1., 2., 0., 1., 2., 1., 1., 2... 0., 2., 0., 5., 0., 2., 0., 0., 1., 0., 0., 3.]), check_input=False, X_idx_sorted=None)
    237         if not 0 <= self.min_weight_fraction_leaf <= 0.5:
    238             raise ValueError("min_weight_fraction_leaf must in [0, 0.5]")
    239         if max_depth <= 0:
    240             raise ValueError("max_depth must be greater than zero. ")
    241         if not (0 < max_features <= self.n_features_):
--> 242             raise ValueError("max_features must be in (0, n_features]")
    243         if not isinstance(max_leaf_nodes, (numbers.Integral, np.integer)):
    244             raise ValueError("max_leaf_nodes must be integral number but was "
    245                              "%r" % max_leaf_nodes)
    246         if -1 < max_leaf_nodes < 2:

ValueError: max_features must be in (0, n_features]
___________________________________________________________________________
Best score: 0.966666666667 (0.0333333333333) [J] | Score: 0.0 (0.0) [J]
Best score: 0.966666666667 (0.0333333333333) [J] | Score: 0.68 (0.04) [J]
Best score: 0.966666666667 (0.0333333333333) [J] | Score: 0.78 (0.0845905169363) [J]
Best score: 0.966666666667 (0.0333333333333) [J] | Score: 0.933333333333 (0.0666666666667) [J]
Best score: 0.966666666667 (0.0333333333333) [J] | Score: 0.953333333333 (0.0520683311727) [J]
Best score: 0.966666666667 (0.0333333333333) [J] | Score: 0.946666666667 (0.0581186525805) [J]
Best score: 0.966666666667 (0.0333333333333) [J] | Score: 0.693333333333 (0.0611010092661) [J]
Best score: 0.966666666667 (0.0333333333333) [J] | Score: 0.966666666667 (0.04472135955) [J]
Best score: 0.966666666667 (0.0333333333333) [J] | Score: 0.966666666667 (0.04472135955) [J]
Best score: 0.966666666667 (0.0333333333333) [J] | Score: 0.953333333333 (0.0520683311727) [J]
Best score: 0.966666666667 (0.0333333333333) [J] | Score: 0.853333333333 (0.0832666399786) [J]
Best score: 0.966666666667 (0.0333333333333) [J] | Score: 0.9 (0.0802772971919) [J]
Best score: 0.966666666667 (0.0333333333333) [J] | Score: 0.713333333333 (0.0669991708075) [J]
Best score: 0.966666666667 (0.0333333333333) [J] | Score: 0.96 (0.0442216638714) [J]
Best score: 0.966666666667 (0.0333333333333) [J] | Score: 0.946666666667 (0.049888765157) [J]
Best score: 0.966666666667 (0.0333333333333) [J] | Score: 0.88 (0.0653197264742) [J]
Best score: 0.966666666667 (0.0333333333333) [J] | Score: 0.773333333333 (0.133998341615) [J]
Best score: 0.966666666667 (0.0333333333333) [J] | Score: 0.58 (0.119443152448) [J]
Best score: 0.966666666667 (0.0333333333333) [J] | Score: 0.666666666667 (1.11022302463e-16) [J]
Best score: 0.966666666667 (0.0333333333333) [J] | Score: 0.96 (0.0442216638714) [J]
Best score: 0.966666666667 (0.0333333333333) [J] | Score: 0.866666666667 (0.0843274042712) [J]
Best score: 0.966666666667 (0.0333333333333) [J] | Score: 0.946666666667 (0.0581186525805) [J]
Best score: 0.966666666667 (0.0333333333333) [J] | Score: 0.853333333333 (0.0777460252646) [J]
Best score: 0.966666666667 (0.0333333333333) [J] | Score: 0.906666666667 (0.0853749898324) [J]
JoblibValueError
___________________________________________________________________________
...........................................................................
/home/aquemy/dev/dp_hyperparameters/extension/main.py in <module>()
     27 
     28     serializer.serialize_results(scenario, policy)
     29 
     30 if __name__ == "__main__":
     31     args = cli.parse_args()
---> 32     main(args)

...........................................................................
/home/aquemy/dev/dp_hyperparameters/extension/main.py in main(args=Namespace(customize=[(['control', 'seed'], '42')...io='./scenarios/rf_iris_joint.yaml', verbosity=0))
     21         test_size=0.4, 
     22         random_state=scenario['control']['seed']
     23     )
     24 
     25     policy = policies.initiate(scenario['setup']['policy'], config)
---> 26     policy.run(X,y)
        policy.run = <bound method Joint.run of <experiment.policies.joint.Joint object>>
        X = array([[5.1, 3.5, 1.4, 0.2],
       [4.9, 3. , 1....2, 3.4, 5.4, 2.3],
       [5.9, 3. , 5.1, 1.8]])
        y = array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,... 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2])
     27 
     28     serializer.serialize_results(scenario, policy)
     29 
     30 if __name__ == "__main__":

...........................................................................
/home/aquemy/dev/dp_hyperparameters/extension/experiment/policies/joint.py in run(self=<experiment.policies.joint.Joint object>, X=array([[5.1, 3.5, 1.4, 0.2],
       [4.9, 3. , 1....2, 3.4, 5.4, 2.3],
       [5.9, 3. , 5.1, 1.8]]), y=array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,... 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]))
     32             algo=tpe.suggest, 
     33             max_evals=None,
     34             max_time=self.config['time'],     
     35             trials=trials,
     36             show_progressbar=False,
---> 37             verbose=0
     38         )
     39 
     40         best_config = self.context['best_config']
     41         super(Joint, self).display_step_results(best_config)

...........................................................................
/home/aquemy/dev/dp_hyperparameters/extension/hyperopt/fmin.py in fmin(fn=<functools.partial object>, space={'algorithm': {'bootstrap': <hyperopt.pyll.base.Apply object>, 'criterion': <hyperopt.pyll.base.Apply object>, 'max_depth': <hyperopt.pyll.base.Apply object>, 'max_features': <hyperopt.pyll.base.Apply object>, 'max_leaf_nodes': <hyperopt.pyll.base.Apply object>, 'min_samples_split': <hyperopt.pyll.base.Apply object>, 'n_estimators': <hyperopt.pyll.base.Apply object>}, 'pipeline': {'features': <hyperopt.pyll.base.Apply object>, 'normalizer': <hyperopt.pyll.base.Apply object>, 'rebalance': <hyperopt.pyll.base.Apply object>}}, algo=<function suggest>, max_evals=9223372036854775807, max_time=300, trials=<hyperopt.base.Trials object>, rstate=<mtrand.RandomState object>, allow_trials_fmin=True, pass_expr_memo_ctrl=None, catch_eval_exceptions=False, verbose=0, return_argmin=True, points_to_evaluate=None, max_queue_len=1, show_progressbar=False)
    406             pass_expr_memo_ctrl=pass_expr_memo_ctrl,
    407             verbose=verbose,
    408             catch_eval_exceptions=catch_eval_exceptions,
    409             return_argmin=return_argmin,
    410             show_progressbar=show_progressbar,
--> 411             max_time=max_time
        max_time = 300
    412         )
    413 
    414     if trials is None:
    415         if points_to_evaluate is None:

...........................................................................
/home/aquemy/dev/dp_hyperparameters/extension/hyperopt/base.py in fmin(self=<hyperopt.base.Trials object>, fn=<functools.partial object>, space={'algorithm': {'bootstrap': <hyperopt.pyll.base.Apply object>, 'criterion': <hyperopt.pyll.base.Apply object>, 'max_depth': <hyperopt.pyll.base.Apply object>, 'max_features': <hyperopt.pyll.base.Apply object>, 'max_leaf_nodes': <hyperopt.pyll.base.Apply object>, 'min_samples_split': <hyperopt.pyll.base.Apply object>, 'n_estimators': <hyperopt.pyll.base.Apply object>}, 'pipeline': {'features': <hyperopt.pyll.base.Apply object>, 'normalizer': <hyperopt.pyll.base.Apply object>, 'rebalance': <hyperopt.pyll.base.Apply object>}}, algo=<function suggest>, max_evals=9223372036854775807, max_time=300, rstate=<mtrand.RandomState object>, verbose=0, pass_expr_memo_ctrl=None, catch_eval_exceptions=False, return_argmin=True, show_progressbar=False)
    636             verbose=verbose,
    637             allow_trials_fmin=False,  # -- prevent recursion
    638             pass_expr_memo_ctrl=pass_expr_memo_ctrl,
    639             catch_eval_exceptions=catch_eval_exceptions,
    640             return_argmin=return_argmin,
--> 641             show_progressbar=show_progressbar)
        show_progressbar = False
    642 
    643 
    644 def trials_from_docs(docs, validate=True, **kwargs):
    645     """Construct a Trials base class instance from a list of trials documents

...........................................................................
/home/aquemy/dev/dp_hyperparameters/extension/hyperopt/fmin.py in fmin(fn=<functools.partial object>, space={'algorithm': {'bootstrap': <hyperopt.pyll.base.Apply object>, 'criterion': <hyperopt.pyll.base.Apply object>, 'max_depth': <hyperopt.pyll.base.Apply object>, 'max_features': <hyperopt.pyll.base.Apply object>, 'max_leaf_nodes': <hyperopt.pyll.base.Apply object>, 'min_samples_split': <hyperopt.pyll.base.Apply object>, 'n_estimators': <hyperopt.pyll.base.Apply object>}, 'pipeline': {'features': <hyperopt.pyll.base.Apply object>, 'normalizer': <hyperopt.pyll.base.Apply object>, 'rebalance': <hyperopt.pyll.base.Apply object>}}, algo=<function suggest>, max_evals=9223372036854775807, max_time=300, trials=<hyperopt.base.Trials object>, rstate=<mtrand.RandomState object>, allow_trials_fmin=False, pass_expr_memo_ctrl=None, catch_eval_exceptions=False, verbose=0, return_argmin=True, points_to_evaluate=None, max_queue_len=1, show_progressbar=False)
    426                     verbose=verbose,
    427                     max_queue_len=max_queue_len,
    428                     show_progressbar=show_progressbar,
    429                     max_time=max_time)
    430     rval.catch_eval_exceptions = catch_eval_exceptions
--> 431     rval.exhaust()
        rval.exhaust = <bound method FMinIter.exhaust of <hyperopt.fmin.FMinIter object>>
    432     if return_argmin:
    433         return trials.argmin
    434     elif len(trials) > 0:
    435         # Only if there are some succesfull trail runs, return the best point in the evaluation space

...........................................................................
/home/aquemy/dev/dp_hyperparameters/extension/hyperopt/fmin.py in exhaust(self=<hyperopt.fmin.FMinIter object>)
    273             raise StopIteration()
    274         return self.trials
    275 
    276     def exhaust(self):
    277         n_done = len(self.trials)
--> 278         self.run(self.max_evals - n_done, block_until_done=self.asynchronous)
        self.run = <bound method FMinIter.run of <hyperopt.fmin.FMinIter object>>
        self.max_evals = 9223372036854775807
        n_done = 0
        self.asynchronous = False
    279         self.trials.refresh()
    280         return self
    281 
    282 

...........................................................................
/home/aquemy/dev/dp_hyperparameters/extension/hyperopt/fmin.py in run(self=<hyperopt.fmin.FMinIter object>, N=9223372036854775807, block_until_done=False)
    232                     if self.asynchronous:
    233                         # -- wait for workers to fill in the trials
    234                         time.sleep(self.poll_interval_secs)
    235                     else:
    236                         # -- loop over trials and do the jobs directly
--> 237                         self.serial_evaluate()
        self.serial_evaluate = <bound method FMinIter.serial_evaluate of <hyperopt.fmin.FMinIter object>>
    238                     try:
    239                         res = [d['result']['loss'] for d in
    240                                          self.trials.trials if
    241                                          d['result']['status'] == 'ok']

...........................................................................
/home/aquemy/dev/dp_hyperparameters/extension/hyperopt/fmin.py in serial_evaluate(self=<hyperopt.fmin.FMinIter object>, N=-1)
    138                 trial['book_time'] = now
    139                 trial['refresh_time'] = now
    140                 spec = base.spec_from_misc(trial['misc'])
    141                 ctrl = base.Ctrl(self.trials, current_trial=trial)
    142                 try:
--> 143                     result = self.domain.evaluate(spec, ctrl)
        result = undefined
        self.domain.evaluate = <bound method Domain.evaluate of <hyperopt.base.Domain object>>
        spec = {'bootstrap': 0, 'criterion': 0, 'features': 1, 'features_PCA_features__n_components': 0, 'max_depth': 3, 'max_features': 2, 'max_leaf_nodes': 2, 'min_samples_split': 0, 'n_estimators': 2, 'normalizer': 2, ...}
        ctrl = <hyperopt.base.Ctrl object>
    144                 except Exception as e:
    145                     logger.info('job exception: %s' % str(e))
    146                     trial['state'] = base.JOB_STATE_ERROR
    147                     trial['misc']['error'] = (str(type(e)), str(e))

...........................................................................
/home/aquemy/dev/dp_hyperparameters/extension/hyperopt/base.py in evaluate(self=<hyperopt.base.Domain object>, config={'bootstrap': 0, 'criterion': 0, 'features': 1, 'features_PCA_features__n_components': 0, 'max_depth': 3, 'max_features': 2, 'max_leaf_nodes': 2, 'min_samples_split': 0, 'n_estimators': 2, 'normalizer': 2, ...}, ctrl=<hyperopt.base.Ctrl object>, attach_attachments=True)
    841             #    or the normal Python part (self.fn)
    842             pyll_rval = pyll.rec_eval(
    843                 self.expr,
    844                 memo=memo,
    845                 print_node_on_error=self.rec_eval_print_node_on_error)
--> 846             rval = self.fn(pyll_rval)
        rval = undefined
        self.fn = <functools.partial object>
        pyll_rval = {'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': 4, 'max_features': 3, 'max_leaf_nodes': 5, 'min_samples_split': 2, 'n_estimators': 50}, 'pipeline': {'features': ('features_PCA', {'features__n_components': 1}), 'normalizer': ('normalizer_PowerTransformer', {}), 'rebalance': ('rebalance_CondensedNearestNeighbour', {'rebalance__n_neighbors': 2})}}
    847 
    848         if isinstance(rval, (float, int, np.number)):
    849             dict_rval = {'loss': float(rval), 'status': STATUS_OK}
    850         else:

...........................................................................
/home/aquemy/dev/dp_hyperparameters/extension/experiment/objective.py in objective_joint(wconfig={'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': 4, 'max_features': 3, 'max_leaf_nodes': 5, 'min_samples_split': 2, 'n_estimators': 50}, 'pipeline': {'features': ('features_PCA', {'features__n_components': 1}), 'normalizer': ('normalizer_PowerTransformer', {}), 'rebalance': ('rebalance_CondensedNearestNeighbour', {'rebalance__n_neighbors': 2})}}, algorithm='RandomForest', X=array([[5.1, 3.5, 1.4, 0.2],
       [4.9, 3. , 1....2, 3.4, 5.4, 2.3],
       [5.9, 3. , 5.1, 1.8]]), y=array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,... 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]), context={'baseline_score': 0.9466666666666667, 'baseline_score_std': 0.04988876515698587, 'best_config': {'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': 4, 'max_features': 3, 'max_leaf_nodes': 3, 'min_samples_split': 3, 'n_estimators': 10}, 'config_hash': {'algorithm': 'ffb7ff225ce3d3712c96cf87fe42202988ee2eb0', 'config': 'bae32f426be9cd6243523c023944a8c148fe4aeb', 'pipeline': 'd2a68bfda6fcdec4ae0ffc7d7b6a2122bc1cd673'}, 'duration': 0.7115809917449951, 'iteration': 113, 'loss': 0.033333333333333215, 'max_history_score': 0.9666666666666668, 'max_history_score_std': 0.033333333333333326, 'max_history_step': 'joint', 'pipeline': {'features': ('features_NoneType', {}), 'normalizer': ('normalizer_PowerTransformer', {}), 'rebalance': ('rebalance_CondensedNearestNeighbour', {'rebalance__n_neighbors': 2})}, 'score': 0.9666666666666668, ...}, 'history': [{'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': 2, 'max_features': None, 'max_leaf_nodes': 5, 'min_samples_split': 2, 'n_estimators': 75}, 'config_hash': {'algorithm': '3af5b0cce71c8fe2545246ca24ff5bc3dd516e06', 'config': 'db6ac7e6d348155757e4794bb5f88fe2b4f63d50', 'pipeline': '8d59f4b94cef6be9306ed86a22a9570fa670d567'}, 'duration': 1.149928092956543, 'iteration': 0, 'loss': 0.046666666666666634, 'max_history_score': 0.9533333333333334, 'max_history_score_std': 0.059999999999999984, 'max_history_step': 'joint', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 4, 'features__selectkbest__k': 3}), 'normalizer': ('normalizer_StandardScaler', {'normalizer__with_mean': True, 'normalizer__with_std': True}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 6})}, 'score': 0.9533333333333334, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': 1, 'max_features': 2, 'max_leaf_nodes': 2, 'min_samples_split': 5, 'n_estimators': 100}, 'config_hash': {'algorithm': 'e13eb05fd9a62d2f63bbb1c1deff0cd620d5e6ab', 'config': '4db6fb84d85f52659f780e682ffac5712c3d8a94', 'pipeline': '64c9a1ca9d53ae67244bdd942f4db36a3c05218c'}, 'duration': 1.7678282260894775, 'iteration': 1, 'loss': 0.18000000000000005, 'max_history_score': 0.9533333333333334, 'max_history_score_std': 0.059999999999999984, 'max_history_step': 'joint', 'pipeline': {'features': ('features_NoneType', {}), 'normalizer': ('normalizer_PowerTransformer', {}), 'rebalance': ('rebalance_NearMiss', {'rebalance__n_neighbors': 1})}, 'score': 0.82, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': 1, 'max_features': None, 'max_leaf_nodes': None, 'min_samples_split': 5, 'n_estimators': 75}, 'config_hash': {'algorithm': '94b0d7a654c508cc63643f78fe4f0f07e6f07c1e', 'config': '4403c5a85e951938d3c454e961d3a412780722f6', 'pipeline': '3e47444880d8367fbac2faaba2e52a917274aa58'}, 'duration': 0.8397619724273682, 'iteration': 2, 'loss': 0.03333333333333344, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_PCA', {'features__n_components': 3}), 'normalizer': ('normalizer_MinMaxScaler', {}), 'rebalance': ('rebalance_NoneType', {})}, 'score': 0.9666666666666666, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': None, 'max_features': None, 'max_leaf_nodes': 3, 'min_samples_split': 3, 'n_estimators': 75}, 'config_hash': {'algorithm': 'e8332f0a8902bda03bf70e7978cc5d52affb29d3', 'config': 'a064e2df18ab98d44dabcefbc7bed94913f1d0be', 'pipeline': '7eea819c2a8c103c4b1e9e9c1e224aebba95081f'}, 'duration': 0.8501448631286621, 'iteration': 3, 'loss': 0.053333333333333344, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 2, 'features__selectkbest__k': 4}), 'normalizer': ('normalizer_NoneType', {}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 7})}, 'score': 0.9466666666666667, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'entropy', 'max_depth': 3, 'max_features': 3, 'max_leaf_nodes': None, 'min_samples_split': 5, 'n_estimators': 75}, 'config_hash': {'algorithm': '7a4491035bc6bd737fe9a8cda8a79a02d02d5c74', 'config': '0ddb6f5cab3db4dddd7682966a57205f3e329ad4', 'pipeline': 'a9ae03fe38334f6868cbf84cdd3d629d4bbe3fb0'}, 'duration': 1.1026010513305664, 'iteration': 4, 'loss': 0.05999999999999994, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 2, 'features__selectkbest__k': 1}), 'normalizer': ('normalizer_NoneType', {}), 'rebalance': ('rebalance_NoneType', {})}, 'score': 0.9400000000000001, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'gini', 'max_depth': 3, 'max_features': 1, 'max_leaf_nodes': 5, 'min_samples_split': 2, 'n_estimators': 25}, 'config_hash': {'algorithm': '9826d20b2d6a0f559cf7f16450ce7526f07e8434', 'config': '49f25751bca61cdd461a8cbd2923689b642f98ed', 'pipeline': '19b249664c5bf067de1fed4334a296f947ce774a'}, 'duration': 0.35647010803222656, 'iteration': 5, 'loss': 0.046666666666666634, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_NoneType', {}), 'normalizer': ('normalizer_NoneType', {}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 6})}, 'score': 0.9533333333333334, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'gini', 'max_depth': 2, 'max_features': 1, 'max_leaf_nodes': 2, 'min_samples_split': 2, 'n_estimators': 50}, 'config_hash': {'algorithm': '0a4f6fbb07e0f32c6f675489a0fc82eee05bd8e1', 'config': '5c3a2b6f5e63fb45f10e41e0318b354912ec44f6', 'pipeline': 'dc3b9f176f090005e38b142f11d80e93a7dc5d5e'}, 'duration': 0.7213859558105469, 'iteration': 6, 'loss': 0.31333333333333324, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 1, 'features__selectkbest__k': 4}), 'normalizer': ('normalizer_PowerTransformer', {}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 7})}, 'score': 0.6866666666666668, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'entropy', 'max_depth': 4, 'max_features': 3, 'max_leaf_nodes': 5, 'min_samples_split': 5, 'n_estimators': 10}, 'config_hash': {'algorithm': 'b8112b97ecfc10f00a195af661dcc861cac21289', 'config': 'd3b129b397350f1b6572651c67c01de49b4b174c', 'pipeline': '5b0357ed7072c37b3d6f458bb5d49ff7d825f603'}, 'duration': 0.8299109935760498, 'iteration': 7, 'loss': 1.0, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_PCA', {'features__n_components': 2}), 'normalizer': ('normalizer_StandardScaler', {'normalizer__with_mean': True, 'normalizer__with_std': False}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 6})}, 'score': 0.0, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'gini', 'max_depth': 4, 'max_features': None, 'max_leaf_nodes': 2, 'min_samples_split': 5, 'n_estimators': 100}, 'config_hash': {'algorithm': '40ca24df19b8d164d9d098a6bed1ce056fbbb961', 'config': '813bde1108cc3c4b9bfb3a22cbb421bda7eac671', 'pipeline': '74a7b8705a1c22f7dea5e44e4ebda8f1e48add71'}, 'duration': 2.2111589908599854, 'iteration': 8, 'loss': 0.33333333333333326, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_PCA', {'features__n_components': 2}), 'normalizer': ('normalizer_StandardScaler', {'normalizer__with_mean': False, 'normalizer__with_std': True}), 'rebalance': ('rebalance_NearMiss', {'rebalance__n_neighbors': 2})}, 'score': 0.6666666666666667, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'entropy', 'max_depth': 2, 'max_features': 1, 'max_leaf_nodes': 5, 'min_samples_split': 2, 'n_estimators': 100}, 'config_hash': {'algorithm': '331418a5c12cf1453876eef85e9d98fc8e54fa11', 'config': '31930b6860ed406d59bf7e59ba1925d94704bd3b', 'pipeline': '054bef356f90ec6f644ef3ffc688766744db51c2'}, 'duration': 1.0501940250396729, 'iteration': 9, 'loss': 0.053333333333333344, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_SelectKBest', {'features__k': 1}), 'normalizer': ('normalizer_RobustScaler', {'normalizer__quantile_range': (...), 'normalizer__with_centering': True, 'normalizer__with_scaling': True}), 'rebalance': ('rebalance_NearMiss', {'rebalance__n_neighbors': 2})}, 'score': 0.9466666666666667, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'entropy', 'max_depth': 3, 'max_features': None, 'max_leaf_nodes': 3, 'min_samples_split': 2, 'n_estimators': 100}, 'config_hash': {'algorithm': 'dbc1b8126649fe93dce5fbb37e4015b0acfb179e', 'config': '9913cd550615a9d0946ab4a755a8b9f619e442fd', 'pipeline': 'dd626121cea079ebb32e184ca65483ec7a6d7f59'}, 'duration': 1.120617151260376, 'iteration': 10, 'loss': 0.046666666666666634, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 2, 'features__selectkbest__k': 1}), 'normalizer': ('normalizer_MinMaxScaler', {}), 'rebalance': ('rebalance_NoneType', {})}, 'score': 0.9533333333333334, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'gini', 'max_depth': 3, 'max_features': 3, 'max_leaf_nodes': None, 'min_samples_split': 3, 'n_estimators': 75}, 'config_hash': {'algorithm': '34917a130df5a975f78bd7ec1a0c7b1ffdc787a9', 'config': '95fc8cadc088141290b7de9c388977e4685f0108', 'pipeline': '550d10faf2f08db48516cc3501558816d6a99bc0'}, 'duration': 1.4287099838256836, 'iteration': 11, 'loss': 0.19333333333333313, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 3, 'features__selectkbest__k': 4}), 'normalizer': ('normalizer_StandardScaler', {'normalizer__with_mean': False, 'normalizer__with_std': False}), 'rebalance': ('rebalance_CondensedNearestNeighbour', {'rebalance__n_neighbors': 1})}, 'score': 0.8066666666666669, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'entropy', 'max_depth': 1, 'max_features': 2, 'max_leaf_nodes': 5, 'min_samples_split': 2, 'n_estimators': 75}, 'config_hash': {'algorithm': '33f9abb4aee44a395a9f3b3ffa9ce80a8cdaed7c', 'config': '40fa726f0360cf6af55f9b5902d399d02f61f157', 'pipeline': 'cfd1d20841fe2153da762c95e79f95a3fb1e426a'}, 'duration': 1.2978079319000244, 'iteration': 12, 'loss': 0.053333333333333344, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_PCA', {'features__n_components': 4}), 'normalizer': ('normalizer_MinMaxScaler', {}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 7})}, 'score': 0.9466666666666667, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'entropy', 'max_depth': 4, 'max_features': 2, 'max_leaf_nodes': 5, 'min_samples_split': 3, 'n_estimators': 25}, 'config_hash': {'algorithm': '210111ec6562d09eb093e98ed69ef1c662e11a50', 'config': '0fb8e77c7bd9a58b72f1b33c21a59a09a8c676ba', 'pipeline': '5d269d759e0c7926a685a14b263ace8ae0071e4b'}, 'duration': 0.36649012565612793, 'iteration': 13, 'loss': 0.040000000000000036, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 2, 'features__selectkbest__k': 2}), 'normalizer': ('normalizer_NoneType', {}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 7})}, 'score': 0.96, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'entropy', 'max_depth': 3, 'max_features': 1, 'max_leaf_nodes': 5, 'min_samples_split': 2, 'n_estimators': 25}, 'config_hash': {'algorithm': '0e989a03980101fabf79eda3326ed2870e11d690', 'config': 'f4bffd5d8c67a9c5321a9943c4a99678f59a02b7', 'pipeline': '865ee1e3fe8334c3d5ecb2038d5a5d1b3ba50e75'}, 'duration': 0.35639500617980957, 'iteration': 14, 'loss': 0.046666666666666634, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_NoneType', {}), 'normalizer': ('normalizer_RobustScaler', {'normalizer__quantile_range': (...), 'normalizer__with_centering': True, 'normalizer__with_scaling': False}), 'rebalance': ('rebalance_NoneType', {})}, 'score': 0.9533333333333334, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'entropy', 'max_depth': None, 'max_features': 3, 'max_leaf_nodes': 3, 'min_samples_split': 5, 'n_estimators': 10}, 'config_hash': {'algorithm': '9c592e876c13de5e23e6de5b868e01755d63e72e', 'config': '1e6a68cd1eeac886d90724d78b1cb5fb76a3cde4', 'pipeline': '5a1ca4d82f21b7de0d2c918630a42510673fa36e'}, 'duration': 0.18141412734985352, 'iteration': 15, 'loss': 0.046666666666666634, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_SelectKBest', {'features__k': 3}), 'normalizer': ('normalizer_RobustScaler', {'normalizer__quantile_range': (...), 'normalizer__with_centering': True, 'normalizer__with_scaling': True}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 6})}, 'score': 0.9533333333333334, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': 1, 'max_features': None, 'max_leaf_nodes': None, 'min_samples_split': 5, 'n_estimators': 10}, 'config_hash': {'algorithm': '8bed77aef289bfd453b2858bd288ae5ba7160f2b', 'config': '781185bcb8999045de8d489f253a1a1ba4247932', 'pipeline': '1ece7eabedc2be9e5b0a1be65c570d08ffa3eb54'}, 'duration': 0.1636829376220703, 'iteration': 16, 'loss': 0.053333333333333344, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_NoneType', {}), 'normalizer': ('normalizer_NoneType', {}), 'rebalance': ('rebalance_NearMiss', {'rebalance__n_neighbors': 1})}, 'score': 0.9466666666666667, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'gini', 'max_depth': 3, 'max_features': 2, 'max_leaf_nodes': 2, 'min_samples_split': 5, 'n_estimators': 75}, 'config_hash': {'algorithm': '617b97d9ba21d3373bc51ffa9cccf9c6f91a77b3', 'config': '99fb425b4e8c5d80228cab94202252aa25cdf77c', 'pipeline': 'd6242929c3b515c7719e60423023ac604311afc3'}, 'duration': 0.8468999862670898, 'iteration': 17, 'loss': 0.24, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_PCA', {'features__n_components': 4}), 'normalizer': ('normalizer_PowerTransformer', {}), 'rebalance': ('rebalance_NearMiss', {'rebalance__n_neighbors': 2})}, 'score': 0.76, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': 1, 'max_features': 1, 'max_leaf_nodes': 2, 'min_samples_split': 5, 'n_estimators': 50}, 'config_hash': {'algorithm': 'b92d2697cdd4979da443369d6596229ec091626a', 'config': 'c513a3e13281206ad76187dd817b1fff93d54fe1', 'pipeline': 'c4b4f914a3ca8df967cade997a90366d85a371b9'}, 'duration': 0.6724588871002197, 'iteration': 18, 'loss': 0.23333333333333328, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 1, 'features__selectkbest__k': 3}), 'normalizer': ('normalizer_StandardScaler', {'normalizer__with_mean': True, 'normalizer__with_std': True}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 5})}, 'score': 0.7666666666666667, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'entropy', 'max_depth': None, 'max_features': None, 'max_leaf_nodes': 5, 'min_samples_split': 5, 'n_estimators': 10}, 'config_hash': {'algorithm': 'a0115de695e6cca2e81cbfb54df79bf4b43608b1', 'config': 'ba194015e20b5d67770e8c67342c3d8d0d01dc41', 'pipeline': '8d45fabfeb85ffdcabf7076bd0e65fffe97ce928'}, 'duration': 0.19424200057983398, 'iteration': 19, 'loss': 0.08666666666666667, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_PCA', {'features__n_components': 3}), 'normalizer': ('normalizer_NoneType', {}), 'rebalance': ('rebalance_NoneType', {})}, 'score': 0.9133333333333333, ...}, ...], 'history_hash': ['db6ac7e6d348155757e4794bb5f88fe2b4f63d50', '4db6fb84d85f52659f780e682ffac5712c3d8a94', '4403c5a85e951938d3c454e961d3a412780722f6', 'a064e2df18ab98d44dabcefbc7bed94913f1d0be', '0ddb6f5cab3db4dddd7682966a57205f3e329ad4', '49f25751bca61cdd461a8cbd2923689b642f98ed', '5c3a2b6f5e63fb45f10e41e0318b354912ec44f6', 'd3b129b397350f1b6572651c67c01de49b4b174c', '813bde1108cc3c4b9bfb3a22cbb421bda7eac671', '31930b6860ed406d59bf7e59ba1925d94704bd3b', '9913cd550615a9d0946ab4a755a8b9f619e442fd', '95fc8cadc088141290b7de9c388977e4685f0108', '40fa726f0360cf6af55f9b5902d399d02f61f157', '0fb8e77c7bd9a58b72f1b33c21a59a09a8c676ba', 'f4bffd5d8c67a9c5321a9943c4a99678f59a02b7', '1e6a68cd1eeac886d90724d78b1cb5fb76a3cde4', '781185bcb8999045de8d489f253a1a1ba4247932', '99fb425b4e8c5d80228cab94202252aa25cdf77c', 'c513a3e13281206ad76187dd817b1fff93d54fe1', 'ba194015e20b5d67770e8c67342c3d8d0d01dc41', ...], 'history_index': {'013329309d510b94f19d930320402d65f953a847': 39, '038a0f515e2ec894ee8e34f9caa2889eb3ebd5ce': 66, '052ae4bf232b316187b078abae42c2be19e16a00': 111, '0659afebf316aafeb75612fb07081a04c28545ed': 74, '06e7cde9f3556cd01332ce389ad1d8925cd4b4a4': 120, '08606f2a0f0a6c9de204020b4632e09fcee0ae56': 168, '0b6551ecfd6f83a15704a9db68f1599c99c6d3ef': 58, '0ddb6f5cab3db4dddd7682966a57205f3e329ad4': 4, '0fb8e77c7bd9a58b72f1b33c21a59a09a8c676ba': 13, '111e2fd99e871044225b8638df965b2a16868e35': 110, ...}, 'iteration': 187, 'max_history_score': 0.9666666666666668, 'max_history_score_std': 0.033333333333333326, 'max_history_step': 'joint'}, config={'algorithm': 'RandomForest', 'seed': 42, 'time': 300})
    108 
    109 def objective_algo(algo_config, current_pipeline_config, algorithm, X, y, context, config):
    110     return objective(current_pipeline_config, algo_config, algorithm, X, y, context, config, step='algorithm')
    111 
    112 def objective_joint(wconfig, algorithm, X, y, context, config):
--> 113     return objective(wconfig['pipeline'], wconfig['algorithm'], algorithm, X, y, context, config, step='joint')
        wconfig = {'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': 4, 'max_features': 3, 'max_leaf_nodes': 5, 'min_samples_split': 2, 'n_estimators': 50}, 'pipeline': {'features': ('features_PCA', {'features__n_components': 1}), 'normalizer': ('normalizer_PowerTransformer', {}), 'rebalance': ('rebalance_CondensedNearestNeighbour', {'rebalance__n_neighbors': 2})}}
        algorithm = 'RandomForest'
        X = array([[5.1, 3.5, 1.4, 0.2],
       [4.9, 3. , 1....2, 3.4, 5.4, 2.3],
       [5.9, 3. , 5.1, 1.8]])
        y = array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,... 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2])
        context = {'baseline_score': 0.9466666666666667, 'baseline_score_std': 0.04988876515698587, 'best_config': {'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': 4, 'max_features': 3, 'max_leaf_nodes': 3, 'min_samples_split': 3, 'n_estimators': 10}, 'config_hash': {'algorithm': 'ffb7ff225ce3d3712c96cf87fe42202988ee2eb0', 'config': 'bae32f426be9cd6243523c023944a8c148fe4aeb', 'pipeline': 'd2a68bfda6fcdec4ae0ffc7d7b6a2122bc1cd673'}, 'duration': 0.7115809917449951, 'iteration': 113, 'loss': 0.033333333333333215, 'max_history_score': 0.9666666666666668, 'max_history_score_std': 0.033333333333333326, 'max_history_step': 'joint', 'pipeline': {'features': ('features_NoneType', {}), 'normalizer': ('normalizer_PowerTransformer', {}), 'rebalance': ('rebalance_CondensedNearestNeighbour', {'rebalance__n_neighbors': 2})}, 'score': 0.9666666666666668, ...}, 'history': [{'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': 2, 'max_features': None, 'max_leaf_nodes': 5, 'min_samples_split': 2, 'n_estimators': 75}, 'config_hash': {'algorithm': '3af5b0cce71c8fe2545246ca24ff5bc3dd516e06', 'config': 'db6ac7e6d348155757e4794bb5f88fe2b4f63d50', 'pipeline': '8d59f4b94cef6be9306ed86a22a9570fa670d567'}, 'duration': 1.149928092956543, 'iteration': 0, 'loss': 0.046666666666666634, 'max_history_score': 0.9533333333333334, 'max_history_score_std': 0.059999999999999984, 'max_history_step': 'joint', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 4, 'features__selectkbest__k': 3}), 'normalizer': ('normalizer_StandardScaler', {'normalizer__with_mean': True, 'normalizer__with_std': True}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 6})}, 'score': 0.9533333333333334, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': 1, 'max_features': 2, 'max_leaf_nodes': 2, 'min_samples_split': 5, 'n_estimators': 100}, 'config_hash': {'algorithm': 'e13eb05fd9a62d2f63bbb1c1deff0cd620d5e6ab', 'config': '4db6fb84d85f52659f780e682ffac5712c3d8a94', 'pipeline': '64c9a1ca9d53ae67244bdd942f4db36a3c05218c'}, 'duration': 1.7678282260894775, 'iteration': 1, 'loss': 0.18000000000000005, 'max_history_score': 0.9533333333333334, 'max_history_score_std': 0.059999999999999984, 'max_history_step': 'joint', 'pipeline': {'features': ('features_NoneType', {}), 'normalizer': ('normalizer_PowerTransformer', {}), 'rebalance': ('rebalance_NearMiss', {'rebalance__n_neighbors': 1})}, 'score': 0.82, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': 1, 'max_features': None, 'max_leaf_nodes': None, 'min_samples_split': 5, 'n_estimators': 75}, 'config_hash': {'algorithm': '94b0d7a654c508cc63643f78fe4f0f07e6f07c1e', 'config': '4403c5a85e951938d3c454e961d3a412780722f6', 'pipeline': '3e47444880d8367fbac2faaba2e52a917274aa58'}, 'duration': 0.8397619724273682, 'iteration': 2, 'loss': 0.03333333333333344, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_PCA', {'features__n_components': 3}), 'normalizer': ('normalizer_MinMaxScaler', {}), 'rebalance': ('rebalance_NoneType', {})}, 'score': 0.9666666666666666, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': None, 'max_features': None, 'max_leaf_nodes': 3, 'min_samples_split': 3, 'n_estimators': 75}, 'config_hash': {'algorithm': 'e8332f0a8902bda03bf70e7978cc5d52affb29d3', 'config': 'a064e2df18ab98d44dabcefbc7bed94913f1d0be', 'pipeline': '7eea819c2a8c103c4b1e9e9c1e224aebba95081f'}, 'duration': 0.8501448631286621, 'iteration': 3, 'loss': 0.053333333333333344, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 2, 'features__selectkbest__k': 4}), 'normalizer': ('normalizer_NoneType', {}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 7})}, 'score': 0.9466666666666667, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'entropy', 'max_depth': 3, 'max_features': 3, 'max_leaf_nodes': None, 'min_samples_split': 5, 'n_estimators': 75}, 'config_hash': {'algorithm': '7a4491035bc6bd737fe9a8cda8a79a02d02d5c74', 'config': '0ddb6f5cab3db4dddd7682966a57205f3e329ad4', 'pipeline': 'a9ae03fe38334f6868cbf84cdd3d629d4bbe3fb0'}, 'duration': 1.1026010513305664, 'iteration': 4, 'loss': 0.05999999999999994, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 2, 'features__selectkbest__k': 1}), 'normalizer': ('normalizer_NoneType', {}), 'rebalance': ('rebalance_NoneType', {})}, 'score': 0.9400000000000001, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'gini', 'max_depth': 3, 'max_features': 1, 'max_leaf_nodes': 5, 'min_samples_split': 2, 'n_estimators': 25}, 'config_hash': {'algorithm': '9826d20b2d6a0f559cf7f16450ce7526f07e8434', 'config': '49f25751bca61cdd461a8cbd2923689b642f98ed', 'pipeline': '19b249664c5bf067de1fed4334a296f947ce774a'}, 'duration': 0.35647010803222656, 'iteration': 5, 'loss': 0.046666666666666634, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_NoneType', {}), 'normalizer': ('normalizer_NoneType', {}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 6})}, 'score': 0.9533333333333334, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'gini', 'max_depth': 2, 'max_features': 1, 'max_leaf_nodes': 2, 'min_samples_split': 2, 'n_estimators': 50}, 'config_hash': {'algorithm': '0a4f6fbb07e0f32c6f675489a0fc82eee05bd8e1', 'config': '5c3a2b6f5e63fb45f10e41e0318b354912ec44f6', 'pipeline': 'dc3b9f176f090005e38b142f11d80e93a7dc5d5e'}, 'duration': 0.7213859558105469, 'iteration': 6, 'loss': 0.31333333333333324, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 1, 'features__selectkbest__k': 4}), 'normalizer': ('normalizer_PowerTransformer', {}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 7})}, 'score': 0.6866666666666668, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'entropy', 'max_depth': 4, 'max_features': 3, 'max_leaf_nodes': 5, 'min_samples_split': 5, 'n_estimators': 10}, 'config_hash': {'algorithm': 'b8112b97ecfc10f00a195af661dcc861cac21289', 'config': 'd3b129b397350f1b6572651c67c01de49b4b174c', 'pipeline': '5b0357ed7072c37b3d6f458bb5d49ff7d825f603'}, 'duration': 0.8299109935760498, 'iteration': 7, 'loss': 1.0, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_PCA', {'features__n_components': 2}), 'normalizer': ('normalizer_StandardScaler', {'normalizer__with_mean': True, 'normalizer__with_std': False}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 6})}, 'score': 0.0, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'gini', 'max_depth': 4, 'max_features': None, 'max_leaf_nodes': 2, 'min_samples_split': 5, 'n_estimators': 100}, 'config_hash': {'algorithm': '40ca24df19b8d164d9d098a6bed1ce056fbbb961', 'config': '813bde1108cc3c4b9bfb3a22cbb421bda7eac671', 'pipeline': '74a7b8705a1c22f7dea5e44e4ebda8f1e48add71'}, 'duration': 2.2111589908599854, 'iteration': 8, 'loss': 0.33333333333333326, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_PCA', {'features__n_components': 2}), 'normalizer': ('normalizer_StandardScaler', {'normalizer__with_mean': False, 'normalizer__with_std': True}), 'rebalance': ('rebalance_NearMiss', {'rebalance__n_neighbors': 2})}, 'score': 0.6666666666666667, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'entropy', 'max_depth': 2, 'max_features': 1, 'max_leaf_nodes': 5, 'min_samples_split': 2, 'n_estimators': 100}, 'config_hash': {'algorithm': '331418a5c12cf1453876eef85e9d98fc8e54fa11', 'config': '31930b6860ed406d59bf7e59ba1925d94704bd3b', 'pipeline': '054bef356f90ec6f644ef3ffc688766744db51c2'}, 'duration': 1.0501940250396729, 'iteration': 9, 'loss': 0.053333333333333344, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_SelectKBest', {'features__k': 1}), 'normalizer': ('normalizer_RobustScaler', {'normalizer__quantile_range': (...), 'normalizer__with_centering': True, 'normalizer__with_scaling': True}), 'rebalance': ('rebalance_NearMiss', {'rebalance__n_neighbors': 2})}, 'score': 0.9466666666666667, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'entropy', 'max_depth': 3, 'max_features': None, 'max_leaf_nodes': 3, 'min_samples_split': 2, 'n_estimators': 100}, 'config_hash': {'algorithm': 'dbc1b8126649fe93dce5fbb37e4015b0acfb179e', 'config': '9913cd550615a9d0946ab4a755a8b9f619e442fd', 'pipeline': 'dd626121cea079ebb32e184ca65483ec7a6d7f59'}, 'duration': 1.120617151260376, 'iteration': 10, 'loss': 0.046666666666666634, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 2, 'features__selectkbest__k': 1}), 'normalizer': ('normalizer_MinMaxScaler', {}), 'rebalance': ('rebalance_NoneType', {})}, 'score': 0.9533333333333334, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'gini', 'max_depth': 3, 'max_features': 3, 'max_leaf_nodes': None, 'min_samples_split': 3, 'n_estimators': 75}, 'config_hash': {'algorithm': '34917a130df5a975f78bd7ec1a0c7b1ffdc787a9', 'config': '95fc8cadc088141290b7de9c388977e4685f0108', 'pipeline': '550d10faf2f08db48516cc3501558816d6a99bc0'}, 'duration': 1.4287099838256836, 'iteration': 11, 'loss': 0.19333333333333313, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 3, 'features__selectkbest__k': 4}), 'normalizer': ('normalizer_StandardScaler', {'normalizer__with_mean': False, 'normalizer__with_std': False}), 'rebalance': ('rebalance_CondensedNearestNeighbour', {'rebalance__n_neighbors': 1})}, 'score': 0.8066666666666669, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'entropy', 'max_depth': 1, 'max_features': 2, 'max_leaf_nodes': 5, 'min_samples_split': 2, 'n_estimators': 75}, 'config_hash': {'algorithm': '33f9abb4aee44a395a9f3b3ffa9ce80a8cdaed7c', 'config': '40fa726f0360cf6af55f9b5902d399d02f61f157', 'pipeline': 'cfd1d20841fe2153da762c95e79f95a3fb1e426a'}, 'duration': 1.2978079319000244, 'iteration': 12, 'loss': 0.053333333333333344, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_PCA', {'features__n_components': 4}), 'normalizer': ('normalizer_MinMaxScaler', {}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 7})}, 'score': 0.9466666666666667, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'entropy', 'max_depth': 4, 'max_features': 2, 'max_leaf_nodes': 5, 'min_samples_split': 3, 'n_estimators': 25}, 'config_hash': {'algorithm': '210111ec6562d09eb093e98ed69ef1c662e11a50', 'config': '0fb8e77c7bd9a58b72f1b33c21a59a09a8c676ba', 'pipeline': '5d269d759e0c7926a685a14b263ace8ae0071e4b'}, 'duration': 0.36649012565612793, 'iteration': 13, 'loss': 0.040000000000000036, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 2, 'features__selectkbest__k': 2}), 'normalizer': ('normalizer_NoneType', {}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 7})}, 'score': 0.96, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'entropy', 'max_depth': 3, 'max_features': 1, 'max_leaf_nodes': 5, 'min_samples_split': 2, 'n_estimators': 25}, 'config_hash': {'algorithm': '0e989a03980101fabf79eda3326ed2870e11d690', 'config': 'f4bffd5d8c67a9c5321a9943c4a99678f59a02b7', 'pipeline': '865ee1e3fe8334c3d5ecb2038d5a5d1b3ba50e75'}, 'duration': 0.35639500617980957, 'iteration': 14, 'loss': 0.046666666666666634, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_NoneType', {}), 'normalizer': ('normalizer_RobustScaler', {'normalizer__quantile_range': (...), 'normalizer__with_centering': True, 'normalizer__with_scaling': False}), 'rebalance': ('rebalance_NoneType', {})}, 'score': 0.9533333333333334, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'entropy', 'max_depth': None, 'max_features': 3, 'max_leaf_nodes': 3, 'min_samples_split': 5, 'n_estimators': 10}, 'config_hash': {'algorithm': '9c592e876c13de5e23e6de5b868e01755d63e72e', 'config': '1e6a68cd1eeac886d90724d78b1cb5fb76a3cde4', 'pipeline': '5a1ca4d82f21b7de0d2c918630a42510673fa36e'}, 'duration': 0.18141412734985352, 'iteration': 15, 'loss': 0.046666666666666634, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_SelectKBest', {'features__k': 3}), 'normalizer': ('normalizer_RobustScaler', {'normalizer__quantile_range': (...), 'normalizer__with_centering': True, 'normalizer__with_scaling': True}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 6})}, 'score': 0.9533333333333334, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': 1, 'max_features': None, 'max_leaf_nodes': None, 'min_samples_split': 5, 'n_estimators': 10}, 'config_hash': {'algorithm': '8bed77aef289bfd453b2858bd288ae5ba7160f2b', 'config': '781185bcb8999045de8d489f253a1a1ba4247932', 'pipeline': '1ece7eabedc2be9e5b0a1be65c570d08ffa3eb54'}, 'duration': 0.1636829376220703, 'iteration': 16, 'loss': 0.053333333333333344, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_NoneType', {}), 'normalizer': ('normalizer_NoneType', {}), 'rebalance': ('rebalance_NearMiss', {'rebalance__n_neighbors': 1})}, 'score': 0.9466666666666667, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'gini', 'max_depth': 3, 'max_features': 2, 'max_leaf_nodes': 2, 'min_samples_split': 5, 'n_estimators': 75}, 'config_hash': {'algorithm': '617b97d9ba21d3373bc51ffa9cccf9c6f91a77b3', 'config': '99fb425b4e8c5d80228cab94202252aa25cdf77c', 'pipeline': 'd6242929c3b515c7719e60423023ac604311afc3'}, 'duration': 0.8468999862670898, 'iteration': 17, 'loss': 0.24, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_PCA', {'features__n_components': 4}), 'normalizer': ('normalizer_PowerTransformer', {}), 'rebalance': ('rebalance_NearMiss', {'rebalance__n_neighbors': 2})}, 'score': 0.76, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': 1, 'max_features': 1, 'max_leaf_nodes': 2, 'min_samples_split': 5, 'n_estimators': 50}, 'config_hash': {'algorithm': 'b92d2697cdd4979da443369d6596229ec091626a', 'config': 'c513a3e13281206ad76187dd817b1fff93d54fe1', 'pipeline': 'c4b4f914a3ca8df967cade997a90366d85a371b9'}, 'duration': 0.6724588871002197, 'iteration': 18, 'loss': 0.23333333333333328, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 1, 'features__selectkbest__k': 3}), 'normalizer': ('normalizer_StandardScaler', {'normalizer__with_mean': True, 'normalizer__with_std': True}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 5})}, 'score': 0.7666666666666667, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'entropy', 'max_depth': None, 'max_features': None, 'max_leaf_nodes': 5, 'min_samples_split': 5, 'n_estimators': 10}, 'config_hash': {'algorithm': 'a0115de695e6cca2e81cbfb54df79bf4b43608b1', 'config': 'ba194015e20b5d67770e8c67342c3d8d0d01dc41', 'pipeline': '8d45fabfeb85ffdcabf7076bd0e65fffe97ce928'}, 'duration': 0.19424200057983398, 'iteration': 19, 'loss': 0.08666666666666667, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_PCA', {'features__n_components': 3}), 'normalizer': ('normalizer_NoneType', {}), 'rebalance': ('rebalance_NoneType', {})}, 'score': 0.9133333333333333, ...}, ...], 'history_hash': ['db6ac7e6d348155757e4794bb5f88fe2b4f63d50', '4db6fb84d85f52659f780e682ffac5712c3d8a94', '4403c5a85e951938d3c454e961d3a412780722f6', 'a064e2df18ab98d44dabcefbc7bed94913f1d0be', '0ddb6f5cab3db4dddd7682966a57205f3e329ad4', '49f25751bca61cdd461a8cbd2923689b642f98ed', '5c3a2b6f5e63fb45f10e41e0318b354912ec44f6', 'd3b129b397350f1b6572651c67c01de49b4b174c', '813bde1108cc3c4b9bfb3a22cbb421bda7eac671', '31930b6860ed406d59bf7e59ba1925d94704bd3b', '9913cd550615a9d0946ab4a755a8b9f619e442fd', '95fc8cadc088141290b7de9c388977e4685f0108', '40fa726f0360cf6af55f9b5902d399d02f61f157', '0fb8e77c7bd9a58b72f1b33c21a59a09a8c676ba', 'f4bffd5d8c67a9c5321a9943c4a99678f59a02b7', '1e6a68cd1eeac886d90724d78b1cb5fb76a3cde4', '781185bcb8999045de8d489f253a1a1ba4247932', '99fb425b4e8c5d80228cab94202252aa25cdf77c', 'c513a3e13281206ad76187dd817b1fff93d54fe1', 'ba194015e20b5d67770e8c67342c3d8d0d01dc41', ...], 'history_index': {'013329309d510b94f19d930320402d65f953a847': 39, '038a0f515e2ec894ee8e34f9caa2889eb3ebd5ce': 66, '052ae4bf232b316187b078abae42c2be19e16a00': 111, '0659afebf316aafeb75612fb07081a04c28545ed': 74, '06e7cde9f3556cd01332ce389ad1d8925cd4b4a4': 120, '08606f2a0f0a6c9de204020b4632e09fcee0ae56': 168, '0b6551ecfd6f83a15704a9db68f1599c99c6d3ef': 58, '0ddb6f5cab3db4dddd7682966a57205f3e329ad4': 4, '0fb8e77c7bd9a58b72f1b33c21a59a09a8c676ba': 13, '111e2fd99e871044225b8638df965b2a16868e35': 110, ...}, 'iteration': 187, 'max_history_score': 0.9666666666666668, 'max_history_score_std': 0.033333333333333326, 'max_history_step': 'joint'}
        config = {'algorithm': 'RandomForest', 'seed': 42, 'time': 300}
    114 
    115 
    116 def get_baseline_score(algorithm, X, y, seed):
    117     pipeline, _ = pipeline_conf_to_full_pipeline(

...........................................................................
/home/aquemy/dev/dp_hyperparameters/extension/experiment/objective.py in objective(pipeline_config={'features': ('features_PCA', {'features__n_components': 1}), 'normalizer': ('normalizer_PowerTransformer', {}), 'rebalance': ('rebalance_CondensedNearestNeighbour', {'rebalance__n_neighbors': 2})}, algo_config={'bootstrap': True, 'criterion': 'gini', 'max_depth': 4, 'max_features': 3, 'max_leaf_nodes': 5, 'min_samples_split': 2, 'n_estimators': 50}, algorithm='RandomForest', X=array([[5.1, 3.5, 1.4, 0.2],
       [4.9, 3. , 1....2, 3.4, 5.4, 2.3],
       [5.9, 3. , 5.1, 1.8]]), y=array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,... 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]), context={'baseline_score': 0.9466666666666667, 'baseline_score_std': 0.04988876515698587, 'best_config': {'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': 4, 'max_features': 3, 'max_leaf_nodes': 3, 'min_samples_split': 3, 'n_estimators': 10}, 'config_hash': {'algorithm': 'ffb7ff225ce3d3712c96cf87fe42202988ee2eb0', 'config': 'bae32f426be9cd6243523c023944a8c148fe4aeb', 'pipeline': 'd2a68bfda6fcdec4ae0ffc7d7b6a2122bc1cd673'}, 'duration': 0.7115809917449951, 'iteration': 113, 'loss': 0.033333333333333215, 'max_history_score': 0.9666666666666668, 'max_history_score_std': 0.033333333333333326, 'max_history_step': 'joint', 'pipeline': {'features': ('features_NoneType', {}), 'normalizer': ('normalizer_PowerTransformer', {}), 'rebalance': ('rebalance_CondensedNearestNeighbour', {'rebalance__n_neighbors': 2})}, 'score': 0.9666666666666668, ...}, 'history': [{'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': 2, 'max_features': None, 'max_leaf_nodes': 5, 'min_samples_split': 2, 'n_estimators': 75}, 'config_hash': {'algorithm': '3af5b0cce71c8fe2545246ca24ff5bc3dd516e06', 'config': 'db6ac7e6d348155757e4794bb5f88fe2b4f63d50', 'pipeline': '8d59f4b94cef6be9306ed86a22a9570fa670d567'}, 'duration': 1.149928092956543, 'iteration': 0, 'loss': 0.046666666666666634, 'max_history_score': 0.9533333333333334, 'max_history_score_std': 0.059999999999999984, 'max_history_step': 'joint', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 4, 'features__selectkbest__k': 3}), 'normalizer': ('normalizer_StandardScaler', {'normalizer__with_mean': True, 'normalizer__with_std': True}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 6})}, 'score': 0.9533333333333334, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': 1, 'max_features': 2, 'max_leaf_nodes': 2, 'min_samples_split': 5, 'n_estimators': 100}, 'config_hash': {'algorithm': 'e13eb05fd9a62d2f63bbb1c1deff0cd620d5e6ab', 'config': '4db6fb84d85f52659f780e682ffac5712c3d8a94', 'pipeline': '64c9a1ca9d53ae67244bdd942f4db36a3c05218c'}, 'duration': 1.7678282260894775, 'iteration': 1, 'loss': 0.18000000000000005, 'max_history_score': 0.9533333333333334, 'max_history_score_std': 0.059999999999999984, 'max_history_step': 'joint', 'pipeline': {'features': ('features_NoneType', {}), 'normalizer': ('normalizer_PowerTransformer', {}), 'rebalance': ('rebalance_NearMiss', {'rebalance__n_neighbors': 1})}, 'score': 0.82, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': 1, 'max_features': None, 'max_leaf_nodes': None, 'min_samples_split': 5, 'n_estimators': 75}, 'config_hash': {'algorithm': '94b0d7a654c508cc63643f78fe4f0f07e6f07c1e', 'config': '4403c5a85e951938d3c454e961d3a412780722f6', 'pipeline': '3e47444880d8367fbac2faaba2e52a917274aa58'}, 'duration': 0.8397619724273682, 'iteration': 2, 'loss': 0.03333333333333344, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_PCA', {'features__n_components': 3}), 'normalizer': ('normalizer_MinMaxScaler', {}), 'rebalance': ('rebalance_NoneType', {})}, 'score': 0.9666666666666666, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': None, 'max_features': None, 'max_leaf_nodes': 3, 'min_samples_split': 3, 'n_estimators': 75}, 'config_hash': {'algorithm': 'e8332f0a8902bda03bf70e7978cc5d52affb29d3', 'config': 'a064e2df18ab98d44dabcefbc7bed94913f1d0be', 'pipeline': '7eea819c2a8c103c4b1e9e9c1e224aebba95081f'}, 'duration': 0.8501448631286621, 'iteration': 3, 'loss': 0.053333333333333344, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 2, 'features__selectkbest__k': 4}), 'normalizer': ('normalizer_NoneType', {}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 7})}, 'score': 0.9466666666666667, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'entropy', 'max_depth': 3, 'max_features': 3, 'max_leaf_nodes': None, 'min_samples_split': 5, 'n_estimators': 75}, 'config_hash': {'algorithm': '7a4491035bc6bd737fe9a8cda8a79a02d02d5c74', 'config': '0ddb6f5cab3db4dddd7682966a57205f3e329ad4', 'pipeline': 'a9ae03fe38334f6868cbf84cdd3d629d4bbe3fb0'}, 'duration': 1.1026010513305664, 'iteration': 4, 'loss': 0.05999999999999994, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 2, 'features__selectkbest__k': 1}), 'normalizer': ('normalizer_NoneType', {}), 'rebalance': ('rebalance_NoneType', {})}, 'score': 0.9400000000000001, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'gini', 'max_depth': 3, 'max_features': 1, 'max_leaf_nodes': 5, 'min_samples_split': 2, 'n_estimators': 25}, 'config_hash': {'algorithm': '9826d20b2d6a0f559cf7f16450ce7526f07e8434', 'config': '49f25751bca61cdd461a8cbd2923689b642f98ed', 'pipeline': '19b249664c5bf067de1fed4334a296f947ce774a'}, 'duration': 0.35647010803222656, 'iteration': 5, 'loss': 0.046666666666666634, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_NoneType', {}), 'normalizer': ('normalizer_NoneType', {}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 6})}, 'score': 0.9533333333333334, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'gini', 'max_depth': 2, 'max_features': 1, 'max_leaf_nodes': 2, 'min_samples_split': 2, 'n_estimators': 50}, 'config_hash': {'algorithm': '0a4f6fbb07e0f32c6f675489a0fc82eee05bd8e1', 'config': '5c3a2b6f5e63fb45f10e41e0318b354912ec44f6', 'pipeline': 'dc3b9f176f090005e38b142f11d80e93a7dc5d5e'}, 'duration': 0.7213859558105469, 'iteration': 6, 'loss': 0.31333333333333324, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 1, 'features__selectkbest__k': 4}), 'normalizer': ('normalizer_PowerTransformer', {}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 7})}, 'score': 0.6866666666666668, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'entropy', 'max_depth': 4, 'max_features': 3, 'max_leaf_nodes': 5, 'min_samples_split': 5, 'n_estimators': 10}, 'config_hash': {'algorithm': 'b8112b97ecfc10f00a195af661dcc861cac21289', 'config': 'd3b129b397350f1b6572651c67c01de49b4b174c', 'pipeline': '5b0357ed7072c37b3d6f458bb5d49ff7d825f603'}, 'duration': 0.8299109935760498, 'iteration': 7, 'loss': 1.0, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_PCA', {'features__n_components': 2}), 'normalizer': ('normalizer_StandardScaler', {'normalizer__with_mean': True, 'normalizer__with_std': False}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 6})}, 'score': 0.0, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'gini', 'max_depth': 4, 'max_features': None, 'max_leaf_nodes': 2, 'min_samples_split': 5, 'n_estimators': 100}, 'config_hash': {'algorithm': '40ca24df19b8d164d9d098a6bed1ce056fbbb961', 'config': '813bde1108cc3c4b9bfb3a22cbb421bda7eac671', 'pipeline': '74a7b8705a1c22f7dea5e44e4ebda8f1e48add71'}, 'duration': 2.2111589908599854, 'iteration': 8, 'loss': 0.33333333333333326, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_PCA', {'features__n_components': 2}), 'normalizer': ('normalizer_StandardScaler', {'normalizer__with_mean': False, 'normalizer__with_std': True}), 'rebalance': ('rebalance_NearMiss', {'rebalance__n_neighbors': 2})}, 'score': 0.6666666666666667, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'entropy', 'max_depth': 2, 'max_features': 1, 'max_leaf_nodes': 5, 'min_samples_split': 2, 'n_estimators': 100}, 'config_hash': {'algorithm': '331418a5c12cf1453876eef85e9d98fc8e54fa11', 'config': '31930b6860ed406d59bf7e59ba1925d94704bd3b', 'pipeline': '054bef356f90ec6f644ef3ffc688766744db51c2'}, 'duration': 1.0501940250396729, 'iteration': 9, 'loss': 0.053333333333333344, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_SelectKBest', {'features__k': 1}), 'normalizer': ('normalizer_RobustScaler', {'normalizer__quantile_range': (...), 'normalizer__with_centering': True, 'normalizer__with_scaling': True}), 'rebalance': ('rebalance_NearMiss', {'rebalance__n_neighbors': 2})}, 'score': 0.9466666666666667, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'entropy', 'max_depth': 3, 'max_features': None, 'max_leaf_nodes': 3, 'min_samples_split': 2, 'n_estimators': 100}, 'config_hash': {'algorithm': 'dbc1b8126649fe93dce5fbb37e4015b0acfb179e', 'config': '9913cd550615a9d0946ab4a755a8b9f619e442fd', 'pipeline': 'dd626121cea079ebb32e184ca65483ec7a6d7f59'}, 'duration': 1.120617151260376, 'iteration': 10, 'loss': 0.046666666666666634, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 2, 'features__selectkbest__k': 1}), 'normalizer': ('normalizer_MinMaxScaler', {}), 'rebalance': ('rebalance_NoneType', {})}, 'score': 0.9533333333333334, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'gini', 'max_depth': 3, 'max_features': 3, 'max_leaf_nodes': None, 'min_samples_split': 3, 'n_estimators': 75}, 'config_hash': {'algorithm': '34917a130df5a975f78bd7ec1a0c7b1ffdc787a9', 'config': '95fc8cadc088141290b7de9c388977e4685f0108', 'pipeline': '550d10faf2f08db48516cc3501558816d6a99bc0'}, 'duration': 1.4287099838256836, 'iteration': 11, 'loss': 0.19333333333333313, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 3, 'features__selectkbest__k': 4}), 'normalizer': ('normalizer_StandardScaler', {'normalizer__with_mean': False, 'normalizer__with_std': False}), 'rebalance': ('rebalance_CondensedNearestNeighbour', {'rebalance__n_neighbors': 1})}, 'score': 0.8066666666666669, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'entropy', 'max_depth': 1, 'max_features': 2, 'max_leaf_nodes': 5, 'min_samples_split': 2, 'n_estimators': 75}, 'config_hash': {'algorithm': '33f9abb4aee44a395a9f3b3ffa9ce80a8cdaed7c', 'config': '40fa726f0360cf6af55f9b5902d399d02f61f157', 'pipeline': 'cfd1d20841fe2153da762c95e79f95a3fb1e426a'}, 'duration': 1.2978079319000244, 'iteration': 12, 'loss': 0.053333333333333344, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_PCA', {'features__n_components': 4}), 'normalizer': ('normalizer_MinMaxScaler', {}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 7})}, 'score': 0.9466666666666667, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'entropy', 'max_depth': 4, 'max_features': 2, 'max_leaf_nodes': 5, 'min_samples_split': 3, 'n_estimators': 25}, 'config_hash': {'algorithm': '210111ec6562d09eb093e98ed69ef1c662e11a50', 'config': '0fb8e77c7bd9a58b72f1b33c21a59a09a8c676ba', 'pipeline': '5d269d759e0c7926a685a14b263ace8ae0071e4b'}, 'duration': 0.36649012565612793, 'iteration': 13, 'loss': 0.040000000000000036, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 2, 'features__selectkbest__k': 2}), 'normalizer': ('normalizer_NoneType', {}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 7})}, 'score': 0.96, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'entropy', 'max_depth': 3, 'max_features': 1, 'max_leaf_nodes': 5, 'min_samples_split': 2, 'n_estimators': 25}, 'config_hash': {'algorithm': '0e989a03980101fabf79eda3326ed2870e11d690', 'config': 'f4bffd5d8c67a9c5321a9943c4a99678f59a02b7', 'pipeline': '865ee1e3fe8334c3d5ecb2038d5a5d1b3ba50e75'}, 'duration': 0.35639500617980957, 'iteration': 14, 'loss': 0.046666666666666634, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_NoneType', {}), 'normalizer': ('normalizer_RobustScaler', {'normalizer__quantile_range': (...), 'normalizer__with_centering': True, 'normalizer__with_scaling': False}), 'rebalance': ('rebalance_NoneType', {})}, 'score': 0.9533333333333334, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'entropy', 'max_depth': None, 'max_features': 3, 'max_leaf_nodes': 3, 'min_samples_split': 5, 'n_estimators': 10}, 'config_hash': {'algorithm': '9c592e876c13de5e23e6de5b868e01755d63e72e', 'config': '1e6a68cd1eeac886d90724d78b1cb5fb76a3cde4', 'pipeline': '5a1ca4d82f21b7de0d2c918630a42510673fa36e'}, 'duration': 0.18141412734985352, 'iteration': 15, 'loss': 0.046666666666666634, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_SelectKBest', {'features__k': 3}), 'normalizer': ('normalizer_RobustScaler', {'normalizer__quantile_range': (...), 'normalizer__with_centering': True, 'normalizer__with_scaling': True}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 6})}, 'score': 0.9533333333333334, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': 1, 'max_features': None, 'max_leaf_nodes': None, 'min_samples_split': 5, 'n_estimators': 10}, 'config_hash': {'algorithm': '8bed77aef289bfd453b2858bd288ae5ba7160f2b', 'config': '781185bcb8999045de8d489f253a1a1ba4247932', 'pipeline': '1ece7eabedc2be9e5b0a1be65c570d08ffa3eb54'}, 'duration': 0.1636829376220703, 'iteration': 16, 'loss': 0.053333333333333344, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_NoneType', {}), 'normalizer': ('normalizer_NoneType', {}), 'rebalance': ('rebalance_NearMiss', {'rebalance__n_neighbors': 1})}, 'score': 0.9466666666666667, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'gini', 'max_depth': 3, 'max_features': 2, 'max_leaf_nodes': 2, 'min_samples_split': 5, 'n_estimators': 75}, 'config_hash': {'algorithm': '617b97d9ba21d3373bc51ffa9cccf9c6f91a77b3', 'config': '99fb425b4e8c5d80228cab94202252aa25cdf77c', 'pipeline': 'd6242929c3b515c7719e60423023ac604311afc3'}, 'duration': 0.8468999862670898, 'iteration': 17, 'loss': 0.24, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_PCA', {'features__n_components': 4}), 'normalizer': ('normalizer_PowerTransformer', {}), 'rebalance': ('rebalance_NearMiss', {'rebalance__n_neighbors': 2})}, 'score': 0.76, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': 1, 'max_features': 1, 'max_leaf_nodes': 2, 'min_samples_split': 5, 'n_estimators': 50}, 'config_hash': {'algorithm': 'b92d2697cdd4979da443369d6596229ec091626a', 'config': 'c513a3e13281206ad76187dd817b1fff93d54fe1', 'pipeline': 'c4b4f914a3ca8df967cade997a90366d85a371b9'}, 'duration': 0.6724588871002197, 'iteration': 18, 'loss': 0.23333333333333328, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 1, 'features__selectkbest__k': 3}), 'normalizer': ('normalizer_StandardScaler', {'normalizer__with_mean': True, 'normalizer__with_std': True}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 5})}, 'score': 0.7666666666666667, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'entropy', 'max_depth': None, 'max_features': None, 'max_leaf_nodes': 5, 'min_samples_split': 5, 'n_estimators': 10}, 'config_hash': {'algorithm': 'a0115de695e6cca2e81cbfb54df79bf4b43608b1', 'config': 'ba194015e20b5d67770e8c67342c3d8d0d01dc41', 'pipeline': '8d45fabfeb85ffdcabf7076bd0e65fffe97ce928'}, 'duration': 0.19424200057983398, 'iteration': 19, 'loss': 0.08666666666666667, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_PCA', {'features__n_components': 3}), 'normalizer': ('normalizer_NoneType', {}), 'rebalance': ('rebalance_NoneType', {})}, 'score': 0.9133333333333333, ...}, ...], 'history_hash': ['db6ac7e6d348155757e4794bb5f88fe2b4f63d50', '4db6fb84d85f52659f780e682ffac5712c3d8a94', '4403c5a85e951938d3c454e961d3a412780722f6', 'a064e2df18ab98d44dabcefbc7bed94913f1d0be', '0ddb6f5cab3db4dddd7682966a57205f3e329ad4', '49f25751bca61cdd461a8cbd2923689b642f98ed', '5c3a2b6f5e63fb45f10e41e0318b354912ec44f6', 'd3b129b397350f1b6572651c67c01de49b4b174c', '813bde1108cc3c4b9bfb3a22cbb421bda7eac671', '31930b6860ed406d59bf7e59ba1925d94704bd3b', '9913cd550615a9d0946ab4a755a8b9f619e442fd', '95fc8cadc088141290b7de9c388977e4685f0108', '40fa726f0360cf6af55f9b5902d399d02f61f157', '0fb8e77c7bd9a58b72f1b33c21a59a09a8c676ba', 'f4bffd5d8c67a9c5321a9943c4a99678f59a02b7', '1e6a68cd1eeac886d90724d78b1cb5fb76a3cde4', '781185bcb8999045de8d489f253a1a1ba4247932', '99fb425b4e8c5d80228cab94202252aa25cdf77c', 'c513a3e13281206ad76187dd817b1fff93d54fe1', 'ba194015e20b5d67770e8c67342c3d8d0d01dc41', ...], 'history_index': {'013329309d510b94f19d930320402d65f953a847': 39, '038a0f515e2ec894ee8e34f9caa2889eb3ebd5ce': 66, '052ae4bf232b316187b078abae42c2be19e16a00': 111, '0659afebf316aafeb75612fb07081a04c28545ed': 74, '06e7cde9f3556cd01332ce389ad1d8925cd4b4a4': 120, '08606f2a0f0a6c9de204020b4632e09fcee0ae56': 168, '0b6551ecfd6f83a15704a9db68f1599c99c6d3ef': 58, '0ddb6f5cab3db4dddd7682966a57205f3e329ad4': 4, '0fb8e77c7bd9a58b72f1b33c21a59a09a8c676ba': 13, '111e2fd99e871044225b8638df965b2a16868e35': 110, ...}, 'iteration': 187, 'max_history_score': 0.9666666666666668, 'max_history_score_std': 0.033333333333333326, 'max_history_step': 'joint'}, config={'algorithm': 'RandomForest', 'seed': 42, 'time': 300}, step='joint')
     45                 y,
     46                 cv=10,
     47                 n_jobs=-1,
     48                 return_estimator=False,
     49                 return_train_score=False,
---> 50                 verbose=0)
     51         score = np.mean(scores['test_score'])
     52         std = np.std(scores['test_score'])
     53         status = STATUS_OK
     54     except Exception as e:

...........................................................................
/home/aquemy/.local/lib/python2.7/site-packages/sklearn/model_selection/_validation.py in cross_validate(estimator=Pipeline(memory=None,
     steps=[('rebalance', ... random_state=42, verbose=0, warm_start=False))]), X=array([[5.1, 3.5, 1.4, 0.2],
       [4.9, 3. , 1....2, 3.4, 5.4, 2.3],
       [5.9, 3. , 5.1, 1.8]]), y=array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,... 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]), groups=None, scoring=None, cv=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1, verbose=0, fit_params=None, pre_dispatch='2*n_jobs', return_train_score=False, return_estimator=False, error_score='raise-deprecating')
    235         delayed(_fit_and_score)(
    236             clone(estimator), X, y, scorers, train, test, verbose, None,
    237             fit_params, return_train_score=return_train_score,
    238             return_times=True, return_estimator=return_estimator,
    239             error_score=error_score)
--> 240         for train, test in cv.split(X, y, groups))
        cv.split = <bound method StratifiedKFold.split of Stratifie...d(n_splits=10, random_state=None, shuffle=False)>
        X = array([[5.1, 3.5, 1.4, 0.2],
       [4.9, 3. , 1....2, 3.4, 5.4, 2.3],
       [5.9, 3. , 5.1, 1.8]])
        y = array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,... 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2])
        groups = None
    241 
    242     zipped_scores = list(zip(*scores))
    243     if return_train_score:
    244         train_scores = zipped_scores.pop(0)

...........................................................................
/home/aquemy/.local/lib/python2.7/site-packages/sklearn/externals/joblib/parallel.py in __call__(self=Parallel(n_jobs=-1), iterable=<generator object <genexpr>>)
    925                 # No need to wait for async callbacks to trigger to
    926                 # consumption.
    927                 self._iterating = False
    928 
    929             with self._backend.retrieval_context():
--> 930                 self.retrieve()
        self.retrieve = <bound method Parallel.retrieve of Parallel(n_jobs=-1)>
    931             # Make sure that we get a last message telling us we are done
    932             elapsed_time = time.time() - self._start_time
    933             self._print('Done %3i out of %3i | elapsed: %s finished',
    934                         (len(self._output), len(self._output),

---------------------------------------------------------------------------
Joblib worker traceback:
---------------------------------------------------------------------------
ValueError                                         Mon Jun 17 13:13:10 2019
PID: 21264                                  Python 2.7.15+: /usr/bin/python
...........................................................................
/home/aquemy/.local/lib/python2.7/site-packages/sklearn/externals/joblib/parallel.py in __call__(self=<sklearn.externals.joblib.parallel.BatchedCalls object>)
    220     def __call__(self):
    221         # Set the default nested backend to self._backend but do not set the
    222         # change the default number of processes to -1
    223         with parallel_backend(self._backend, n_jobs=self._n_jobs):
    224             return [func(*args, **kwargs)
--> 225                     for func, args, kwargs in self.items]
        func = <function _fit_and_score>
        args = (Pipeline(memory=None,
     steps=[('rebalance', ... random_state=42, verbose=0, warm_start=False))]), array([[5.1, 3.5, 1.4, 0.2],
       [4.9, 3. , 1....2, 3.4, 5.4, 2.3],
       [5.9, 3. , 5.1, 1.8]]), array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,... 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]), {'score': <function _passthrough_scorer>}, array([  5,   6,   7,   8,   9,  10,  11,  12,  ..., 142, 143, 144,
       145, 146, 147, 148, 149]), array([  0,   1,   2,   3,   4,  50,  51,  52,  53,  54, 100, 101, 102,
       103, 104]), 0, None, None)
        kwargs = {'error_score': 'raise-deprecating', 'return_estimator': False, 'return_times': True, 'return_train_score': False}
        self.items = [(<function _fit_and_score>, (Pipeline(memory=None,
     steps=[('rebalance', ... random_state=42, verbose=0, warm_start=False))]), array([[5.1, 3.5, 1.4, 0.2],
       [4.9, 3. , 1....2, 3.4, 5.4, 2.3],
       [5.9, 3. , 5.1, 1.8]]), array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,... 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]), {'score': <function _passthrough_scorer>}, array([  5,   6,   7,   8,   9,  10,  11,  12,  ..., 142, 143, 144,
       145, 146, 147, 148, 149]), array([  0,   1,   2,   3,   4,  50,  51,  52,  53,  54, 100, 101, 102,
       103, 104]), 0, None, None), {'error_score': 'raise-deprecating', 'return_estimator': False, 'return_times': True, 'return_train_score': False})]
    226 
    227     def __len__(self):
    228         return self._size
    229 

...........................................................................
/home/aquemy/.local/lib/python2.7/site-packages/sklearn/model_selection/_validation.py in _fit_and_score(estimator=Pipeline(memory=None,
     steps=[('rebalance', ... random_state=42, verbose=0, warm_start=False))]), X=array([[5.1, 3.5, 1.4, 0.2],
       [4.9, 3. , 1....2, 3.4, 5.4, 2.3],
       [5.9, 3. , 5.1, 1.8]]), y=array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,... 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]), scorer={'score': <function _passthrough_scorer>}, train=array([  5,   6,   7,   8,   9,  10,  11,  12,  ..., 142, 143, 144,
       145, 146, 147, 148, 149]), test=array([  0,   1,   2,   3,   4,  50,  51,  52,  53,  54, 100, 101, 102,
       103, 104]), verbose=0, parameters=None, fit_params={}, return_train_score=False, return_parameters=False, return_n_test_samples=False, return_times=True, return_estimator=False, error_score='raise-deprecating')
    523 
    524     try:
    525         if y_train is None:
    526             estimator.fit(X_train, **fit_params)
    527         else:
--> 528             estimator.fit(X_train, y_train, **fit_params)
        estimator.fit = <bound method Pipeline.fit of Pipeline(memory=No...random_state=42, verbose=0, warm_start=False))])>
        X_train = array([[5.4, 3.9, 1.7, 0.4],
       [4.6, 3.4, 1....2, 3.4, 5.4, 2.3],
       [5.9, 3. , 5.1, 1.8]])
        y_train = array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,
       2, 2, 2])
        fit_params = {}
    529 
    530     except Exception as e:
    531         # Note fit time as time until error
    532         fit_time = time.time() - start_time

...........................................................................
/usr/local/lib/python2.7/dist-packages/imblearn/pipeline.py in fit(self=Pipeline(memory=None,
     steps=[('rebalance', ... random_state=42, verbose=0, warm_start=False))]), X=array([[5.4, 3.9, 1.7, 0.4],
       [4.6, 3.4, 1....2, 3.4, 5.4, 2.3],
       [5.9, 3. , 5.1, 1.8]]), y=array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,
       2, 2, 2]), **fit_params={})
    234             This estimator
    235 
    236         """
    237         Xt, yt, fit_params = self._fit(X, y, **fit_params)
    238         if self._final_estimator is not None:
--> 239             self._final_estimator.fit(Xt, yt, **fit_params)
        self._final_estimator.fit = <bound method RandomForestClassifier.fit of Rand...e, random_state=42, verbose=0, warm_start=False)>
        Xt = array([[ 0.92244484],
       [-0.71663156],
    ...23],
       [ 4.07227182],
       [ 2.61605905]])
        yt = array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...0, 0, 0, 0, 0, 0, 0,
       0, 1, 1, 1, 2, 2, 2])
        fit_params = {}
    240         return self
    241 
    242     def fit_transform(self, X, y=None, **fit_params):
    243         """Fit the model and transform with the final estimator

...........................................................................
/home/aquemy/.local/lib/python2.7/site-packages/sklearn/ensemble/forest.py in fit(self=RandomForestClassifier(bootstrap=True, class_wei...se, random_state=42, verbose=0, warm_start=False), X=array([[ 0.9224448 ],
       [-0.71663153],
    ....072272  ],
       [ 2.616059  ]], dtype=float32), y=array([[0.],
       [0.],
       [0.],
       [0...    [1.],
       [2.],
       [2.],
       [2.]]), sample_weight=None)
    328             trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,
    329                              **_joblib_parallel_args(prefer='threads'))(
    330                 delayed(_parallel_build_trees)(
    331                     t, self, X, y, sample_weight, i, len(trees),
    332                     verbose=self.verbose, class_weight=self.class_weight)
--> 333                 for i, t in enumerate(trees))
        i = 49
    334 
    335             # Collect newly grown trees
    336             self.estimators_.extend(trees)
    337 

...........................................................................
/home/aquemy/.local/lib/python2.7/site-packages/sklearn/externals/joblib/parallel.py in __call__(self=Parallel(n_jobs=1), iterable=<generator object <genexpr>>)
    912             # self._original_iterator is None, then this means either
    913             # that pre_dispatch == "all", n_jobs == 1 or that the first batch
    914             # was very quick and its callback already dispatched all the
    915             # remaining jobs.
    916             self._iterating = False
--> 917             if self.dispatch_one_batch(iterator):
        self.dispatch_one_batch = <bound method Parallel.dispatch_one_batch of Parallel(n_jobs=1)>
        iterator = <generator object <genexpr>>
    918                 self._iterating = self._original_iterator is not None
    919 
    920             while self.dispatch_one_batch(iterator):
    921                 pass

...........................................................................
/home/aquemy/.local/lib/python2.7/site-packages/sklearn/externals/joblib/parallel.py in dispatch_one_batch(self=Parallel(n_jobs=1), iterator=<generator object <genexpr>>)
    754                                  self._pickle_cache)
    755             if len(tasks) == 0:
    756                 # No more tasks available in the iterator: tell caller to stop.
    757                 return False
    758             else:
--> 759                 self._dispatch(tasks)
        self._dispatch = <bound method Parallel._dispatch of Parallel(n_jobs=1)>
        tasks = <sklearn.externals.joblib.parallel.BatchedCalls object>
    760                 return True
    761 
    762     def _print(self, msg, msg_args):
    763         """Display the message on stout or stderr depending on verbosity"""

...........................................................................
/home/aquemy/.local/lib/python2.7/site-packages/sklearn/externals/joblib/parallel.py in _dispatch(self=Parallel(n_jobs=1), batch=<sklearn.externals.joblib.parallel.BatchedCalls object>)
    711 
    712         dispatch_timestamp = time.time()
    713         cb = BatchCompletionCallBack(dispatch_timestamp, len(batch), self)
    714         with self._lock:
    715             job_idx = len(self._jobs)
--> 716             job = self._backend.apply_async(batch, callback=cb)
        job = undefined
        self._backend.apply_async = <bound method SequentialBackend.apply_async of <...lib._parallel_backends.SequentialBackend object>>
        batch = <sklearn.externals.joblib.parallel.BatchedCalls object>
        cb = <sklearn.externals.joblib.parallel.BatchCompletionCallBack object>
    717             # A job can complete so quickly than its callback is
    718             # called before we get here, causing self._jobs to
    719             # grow. To ensure correct results ordering, .insert is
    720             # used (rather than .append) in the following line

...........................................................................
/home/aquemy/.local/lib/python2.7/site-packages/sklearn/externals/joblib/_parallel_backends.py in apply_async(self=<sklearn.externals.joblib._parallel_backends.SequentialBackend object>, func=<sklearn.externals.joblib.parallel.BatchedCalls object>, callback=<sklearn.externals.joblib.parallel.BatchCompletionCallBack object>)
    177             raise ValueError('n_jobs == 0 in Parallel has no meaning')
    178         return 1
    179 
    180     def apply_async(self, func, callback=None):
    181         """Schedule a func to be run"""
--> 182         result = ImmediateResult(func)
        result = undefined
        func = <sklearn.externals.joblib.parallel.BatchedCalls object>
    183         if callback:
    184             callback(result)
    185         return result
    186 

...........................................................................
/home/aquemy/.local/lib/python2.7/site-packages/sklearn/externals/joblib/_parallel_backends.py in __init__(self=<sklearn.externals.joblib._parallel_backends.ImmediateResult object>, batch=<sklearn.externals.joblib.parallel.BatchedCalls object>)
    544 
    545 class ImmediateResult(object):
    546     def __init__(self, batch):
    547         # Don't delay the application, to avoid keeping the input
    548         # arguments in memory
--> 549         self.results = batch()
        self.results = undefined
        batch = <sklearn.externals.joblib.parallel.BatchedCalls object>
    550 
    551     def get(self):
    552         return self.results
    553 

...........................................................................
/home/aquemy/.local/lib/python2.7/site-packages/sklearn/externals/joblib/parallel.py in __call__(self=<sklearn.externals.joblib.parallel.BatchedCalls object>)
    220     def __call__(self):
    221         # Set the default nested backend to self._backend but do not set the
    222         # change the default number of processes to -1
    223         with parallel_backend(self._backend, n_jobs=self._n_jobs):
    224             return [func(*args, **kwargs)
--> 225                     for func, args, kwargs in self.items]
        func = <function _parallel_build_trees>
        args = (DecisionTreeClassifier(class_weight=None, criter...=False, random_state=1608637542, splitter='best'), RandomForestClassifier(bootstrap=True, class_wei...se, random_state=42, verbose=0, warm_start=False), array([[ 0.9224448 ],
       [-0.71663153],
    ....072272  ],
       [ 2.616059  ]], dtype=float32), array([[0.],
       [0.],
       [0.],
       [0...    [1.],
       [2.],
       [2.],
       [2.]]), None, 0, 50)
        kwargs = {'class_weight': None, 'verbose': 0}
        self.items = [(<function _parallel_build_trees>, (DecisionTreeClassifier(class_weight=None, criter...=False, random_state=1608637542, splitter='best'), RandomForestClassifier(bootstrap=True, class_wei...se, random_state=42, verbose=0, warm_start=False), array([[ 0.9224448 ],
       [-0.71663153],
    ....072272  ],
       [ 2.616059  ]], dtype=float32), array([[0.],
       [0.],
       [0.],
       [0...    [1.],
       [2.],
       [2.],
       [2.]]), None, 0, 50), {'class_weight': None, 'verbose': 0})]
    226 
    227     def __len__(self):
    228         return self._size
    229 

...........................................................................
/home/aquemy/.local/lib/python2.7/site-packages/sklearn/ensemble/forest.py in _parallel_build_trees(tree=DecisionTreeClassifier(class_weight=None, criter...=False, random_state=1608637542, splitter='best'), forest=RandomForestClassifier(bootstrap=True, class_wei...se, random_state=42, verbose=0, warm_start=False), X=array([[ 0.9224448 ],
       [-0.71663153],
    ....072272  ],
       [ 2.616059  ]], dtype=float32), y=array([[0.],
       [0.],
       [0.],
       [0...    [1.],
       [2.],
       [2.],
       [2.]]), sample_weight=None, tree_idx=0, n_trees=50, verbose=0, class_weight=None)
    114                 simplefilter('ignore', DeprecationWarning)
    115                 curr_sample_weight *= compute_sample_weight('auto', y, indices)
    116         elif class_weight == 'balanced_subsample':
    117             curr_sample_weight *= compute_sample_weight('balanced', y, indices)
    118 
--> 119         tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)
        tree.fit = <bound method DecisionTreeClassifier.fit of Deci...False, random_state=1608637542, splitter='best')>
        X = array([[ 0.9224448 ],
       [-0.71663153],
    ....072272  ],
       [ 2.616059  ]], dtype=float32)
        y = array([[0.],
       [0.],
       [0.],
       [0...    [1.],
       [2.],
       [2.],
       [2.]])
        sample_weight = None
        curr_sample_weight = array([2., 0., 2., 1., 2., 0., 1., 2., 1., 1., 2... 2., 0., 4., 0., 2., 0., 0., 1., 0., 0., 3., 2.])
    120     else:
    121         tree.fit(X, y, sample_weight=sample_weight, check_input=False)
    122 
    123     return tree

...........................................................................
/home/aquemy/.local/lib/python2.7/site-packages/sklearn/tree/tree.py in fit(self=DecisionTreeClassifier(class_weight=None, criter...=False, random_state=1608637542, splitter='best'), X=array([[ 0.9224448 ],
       [-0.71663153],
    ....072272  ],
       [ 2.616059  ]], dtype=float32), y=array([[0.],
       [0.],
       [0.],
       [0...    [1.],
       [2.],
       [2.],
       [2.]]), sample_weight=array([2., 0., 2., 1., 2., 0., 1., 2., 1., 1., 2... 2., 0., 4., 0., 2., 0., 0., 1., 0., 0., 3., 2.]), check_input=False, X_idx_sorted=None)
    796 
    797         super(DecisionTreeClassifier, self).fit(
    798             X, y,
    799             sample_weight=sample_weight,
    800             check_input=check_input,
--> 801             X_idx_sorted=X_idx_sorted)
        X_idx_sorted = None
    802         return self
    803 
    804     def predict_proba(self, X, check_input=True):
    805         """Predict class probabilities of the input samples X.

...........................................................................
/home/aquemy/.local/lib/python2.7/site-packages/sklearn/tree/tree.py in fit(self=DecisionTreeClassifier(class_weight=None, criter...=False, random_state=1608637542, splitter='best'), X=array([[ 0.9224448 ],
       [-0.71663153],
    ....072272  ],
       [ 2.616059  ]], dtype=float32), y=array([[0.],
       [0.],
       [0.],
       [0...    [1.],
       [2.],
       [2.],
       [2.]]), sample_weight=array([2., 0., 2., 1., 2., 0., 1., 2., 1., 1., 2... 2., 0., 4., 0., 2., 0., 0., 1., 0., 0., 3., 2.]), check_input=False, X_idx_sorted=None)
    237         if not 0 <= self.min_weight_fraction_leaf <= 0.5:
    238             raise ValueError("min_weight_fraction_leaf must in [0, 0.5]")
    239         if max_depth <= 0:
    240             raise ValueError("max_depth must be greater than zero. ")
    241         if not (0 < max_features <= self.n_features_):
--> 242             raise ValueError("max_features must be in (0, n_features]")
    243         if not isinstance(max_leaf_nodes, (numbers.Integral, np.integer)):
    244             raise ValueError("max_leaf_nodes must be integral number but was "
    245                              "%r" % max_leaf_nodes)
    246         if -1 < max_leaf_nodes < 2:

ValueError: max_features must be in (0, n_features]
___________________________________________________________________________
Best score: 0.966666666667 (0.0333333333333) [J] | Score: 0.0 (0.0) [J]
Best score: 0.966666666667 (0.0333333333333) [J] | Score: 0.94 (0.0466666666667) [J]
Best score: 0.966666666667 (0.0333333333333) [J] | Score: 0.933333333333 (0.0516397779494) [J]
Best score: 0.966666666667 (0.0333333333333) [J] | Score: 0.96 (0.0442216638714) [J]
Best score: 0.966666666667 (0.0333333333333) [J] | Score: 0.906666666667 (0.0952190457139) [J]
Best score: 0.966666666667 (0.0333333333333) [J] | Score: 0.94 (0.0553774924195) [J]
Best score: 0.966666666667 (0.0333333333333) [J] | Score: 0.893333333333 (0.0853749898324) [J]
Best score: 0.966666666667 (0.0333333333333) [J] | Score: 0.633333333333 (0.0906764700582) [J]
Best score: 0.966666666667 (0.0333333333333) [J] | Score: 0.926666666667 (0.0553774924195) [J]
Best score: 0.966666666667 (0.0333333333333) [J] | Score: 0.88 (0.0653197264742) [J]
Best score: 0.966666666667 (0.0333333333333) [J] | Score: 0.96 (0.0442216638714) [J]
Best score: 0.966666666667 (0.0333333333333) [J] | Score: 0.646666666667 (0.06) [J]
Best score: 0.966666666667 (0.0333333333333) [J] | Score: 0.94 (0.062893207547) [J]
Best score: 0.966666666667 (0.0333333333333) [J] | Score: 0.953333333333 (0.0520683311727) [J]
Best score: 0.966666666667 (0.0333333333333) [J] | Score: 0.946666666667 (0.0653197264742) [J]
Best score: 0.966666666667 (0.0333333333333) [J] | Score: 0.92 (0.0777460252646) [J]
Best score: 0.966666666667 (0.0333333333333) [J] | Score: 0.92 (0.0718021974285) [J]
JoblibValueError
___________________________________________________________________________
...........................................................................
/home/aquemy/dev/dp_hyperparameters/extension/main.py in <module>()
     27 
     28     serializer.serialize_results(scenario, policy)
     29 
     30 if __name__ == "__main__":
     31     args = cli.parse_args()
---> 32     main(args)

...........................................................................
/home/aquemy/dev/dp_hyperparameters/extension/main.py in main(args=Namespace(customize=[(['control', 'seed'], '42')...io='./scenarios/rf_iris_joint.yaml', verbosity=0))
     21         test_size=0.4, 
     22         random_state=scenario['control']['seed']
     23     )
     24 
     25     policy = policies.initiate(scenario['setup']['policy'], config)
---> 26     policy.run(X,y)
        policy.run = <bound method Joint.run of <experiment.policies.joint.Joint object>>
        X = array([[5.1, 3.5, 1.4, 0.2],
       [4.9, 3. , 1....2, 3.4, 5.4, 2.3],
       [5.9, 3. , 5.1, 1.8]])
        y = array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,... 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2])
     27 
     28     serializer.serialize_results(scenario, policy)
     29 
     30 if __name__ == "__main__":

...........................................................................
/home/aquemy/dev/dp_hyperparameters/extension/experiment/policies/joint.py in run(self=<experiment.policies.joint.Joint object>, X=array([[5.1, 3.5, 1.4, 0.2],
       [4.9, 3. , 1....2, 3.4, 5.4, 2.3],
       [5.9, 3. , 5.1, 1.8]]), y=array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,... 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]))
     32             algo=tpe.suggest, 
     33             max_evals=None,
     34             max_time=self.config['time'],     
     35             trials=trials,
     36             show_progressbar=False,
---> 37             verbose=0
     38         )
     39 
     40         best_config = self.context['best_config']
     41         super(Joint, self).display_step_results(best_config)

...........................................................................
/home/aquemy/dev/dp_hyperparameters/extension/hyperopt/fmin.py in fmin(fn=<functools.partial object>, space={'algorithm': {'bootstrap': <hyperopt.pyll.base.Apply object>, 'criterion': <hyperopt.pyll.base.Apply object>, 'max_depth': <hyperopt.pyll.base.Apply object>, 'max_features': <hyperopt.pyll.base.Apply object>, 'max_leaf_nodes': <hyperopt.pyll.base.Apply object>, 'min_samples_split': <hyperopt.pyll.base.Apply object>, 'n_estimators': <hyperopt.pyll.base.Apply object>}, 'pipeline': {'features': <hyperopt.pyll.base.Apply object>, 'normalizer': <hyperopt.pyll.base.Apply object>, 'rebalance': <hyperopt.pyll.base.Apply object>}}, algo=<function suggest>, max_evals=9223372036854775807, max_time=300, trials=<hyperopt.base.Trials object>, rstate=<mtrand.RandomState object>, allow_trials_fmin=True, pass_expr_memo_ctrl=None, catch_eval_exceptions=False, verbose=0, return_argmin=True, points_to_evaluate=None, max_queue_len=1, show_progressbar=False)
    406             pass_expr_memo_ctrl=pass_expr_memo_ctrl,
    407             verbose=verbose,
    408             catch_eval_exceptions=catch_eval_exceptions,
    409             return_argmin=return_argmin,
    410             show_progressbar=show_progressbar,
--> 411             max_time=max_time
        max_time = 300
    412         )
    413 
    414     if trials is None:
    415         if points_to_evaluate is None:

...........................................................................
/home/aquemy/dev/dp_hyperparameters/extension/hyperopt/base.py in fmin(self=<hyperopt.base.Trials object>, fn=<functools.partial object>, space={'algorithm': {'bootstrap': <hyperopt.pyll.base.Apply object>, 'criterion': <hyperopt.pyll.base.Apply object>, 'max_depth': <hyperopt.pyll.base.Apply object>, 'max_features': <hyperopt.pyll.base.Apply object>, 'max_leaf_nodes': <hyperopt.pyll.base.Apply object>, 'min_samples_split': <hyperopt.pyll.base.Apply object>, 'n_estimators': <hyperopt.pyll.base.Apply object>}, 'pipeline': {'features': <hyperopt.pyll.base.Apply object>, 'normalizer': <hyperopt.pyll.base.Apply object>, 'rebalance': <hyperopt.pyll.base.Apply object>}}, algo=<function suggest>, max_evals=9223372036854775807, max_time=300, rstate=<mtrand.RandomState object>, verbose=0, pass_expr_memo_ctrl=None, catch_eval_exceptions=False, return_argmin=True, show_progressbar=False)
    636             verbose=verbose,
    637             allow_trials_fmin=False,  # -- prevent recursion
    638             pass_expr_memo_ctrl=pass_expr_memo_ctrl,
    639             catch_eval_exceptions=catch_eval_exceptions,
    640             return_argmin=return_argmin,
--> 641             show_progressbar=show_progressbar)
        show_progressbar = False
    642 
    643 
    644 def trials_from_docs(docs, validate=True, **kwargs):
    645     """Construct a Trials base class instance from a list of trials documents

...........................................................................
/home/aquemy/dev/dp_hyperparameters/extension/hyperopt/fmin.py in fmin(fn=<functools.partial object>, space={'algorithm': {'bootstrap': <hyperopt.pyll.base.Apply object>, 'criterion': <hyperopt.pyll.base.Apply object>, 'max_depth': <hyperopt.pyll.base.Apply object>, 'max_features': <hyperopt.pyll.base.Apply object>, 'max_leaf_nodes': <hyperopt.pyll.base.Apply object>, 'min_samples_split': <hyperopt.pyll.base.Apply object>, 'n_estimators': <hyperopt.pyll.base.Apply object>}, 'pipeline': {'features': <hyperopt.pyll.base.Apply object>, 'normalizer': <hyperopt.pyll.base.Apply object>, 'rebalance': <hyperopt.pyll.base.Apply object>}}, algo=<function suggest>, max_evals=9223372036854775807, max_time=300, trials=<hyperopt.base.Trials object>, rstate=<mtrand.RandomState object>, allow_trials_fmin=False, pass_expr_memo_ctrl=None, catch_eval_exceptions=False, verbose=0, return_argmin=True, points_to_evaluate=None, max_queue_len=1, show_progressbar=False)
    426                     verbose=verbose,
    427                     max_queue_len=max_queue_len,
    428                     show_progressbar=show_progressbar,
    429                     max_time=max_time)
    430     rval.catch_eval_exceptions = catch_eval_exceptions
--> 431     rval.exhaust()
        rval.exhaust = <bound method FMinIter.exhaust of <hyperopt.fmin.FMinIter object>>
    432     if return_argmin:
    433         return trials.argmin
    434     elif len(trials) > 0:
    435         # Only if there are some succesfull trail runs, return the best point in the evaluation space

...........................................................................
/home/aquemy/dev/dp_hyperparameters/extension/hyperopt/fmin.py in exhaust(self=<hyperopt.fmin.FMinIter object>)
    273             raise StopIteration()
    274         return self.trials
    275 
    276     def exhaust(self):
    277         n_done = len(self.trials)
--> 278         self.run(self.max_evals - n_done, block_until_done=self.asynchronous)
        self.run = <bound method FMinIter.run of <hyperopt.fmin.FMinIter object>>
        self.max_evals = 9223372036854775807
        n_done = 0
        self.asynchronous = False
    279         self.trials.refresh()
    280         return self
    281 
    282 

...........................................................................
/home/aquemy/dev/dp_hyperparameters/extension/hyperopt/fmin.py in run(self=<hyperopt.fmin.FMinIter object>, N=9223372036854775807, block_until_done=False)
    232                     if self.asynchronous:
    233                         # -- wait for workers to fill in the trials
    234                         time.sleep(self.poll_interval_secs)
    235                     else:
    236                         # -- loop over trials and do the jobs directly
--> 237                         self.serial_evaluate()
        self.serial_evaluate = <bound method FMinIter.serial_evaluate of <hyperopt.fmin.FMinIter object>>
    238                     try:
    239                         res = [d['result']['loss'] for d in
    240                                          self.trials.trials if
    241                                          d['result']['status'] == 'ok']

...........................................................................
/home/aquemy/dev/dp_hyperparameters/extension/hyperopt/fmin.py in serial_evaluate(self=<hyperopt.fmin.FMinIter object>, N=-1)
    138                 trial['book_time'] = now
    139                 trial['refresh_time'] = now
    140                 spec = base.spec_from_misc(trial['misc'])
    141                 ctrl = base.Ctrl(self.trials, current_trial=trial)
    142                 try:
--> 143                     result = self.domain.evaluate(spec, ctrl)
        result = undefined
        self.domain.evaluate = <bound method Domain.evaluate of <hyperopt.base.Domain object>>
        spec = {'bootstrap': 0, 'criterion': 0, 'features': 1, 'features_PCA_features__n_components': 0, 'max_depth': 3, 'max_features': 2, 'max_leaf_nodes': 1, 'min_samples_split': 1, 'n_estimators': 0, 'normalizer': 2, ...}
        ctrl = <hyperopt.base.Ctrl object>
    144                 except Exception as e:
    145                     logger.info('job exception: %s' % str(e))
    146                     trial['state'] = base.JOB_STATE_ERROR
    147                     trial['misc']['error'] = (str(type(e)), str(e))

...........................................................................
/home/aquemy/dev/dp_hyperparameters/extension/hyperopt/base.py in evaluate(self=<hyperopt.base.Domain object>, config={'bootstrap': 0, 'criterion': 0, 'features': 1, 'features_PCA_features__n_components': 0, 'max_depth': 3, 'max_features': 2, 'max_leaf_nodes': 1, 'min_samples_split': 1, 'n_estimators': 0, 'normalizer': 2, ...}, ctrl=<hyperopt.base.Ctrl object>, attach_attachments=True)
    841             #    or the normal Python part (self.fn)
    842             pyll_rval = pyll.rec_eval(
    843                 self.expr,
    844                 memo=memo,
    845                 print_node_on_error=self.rec_eval_print_node_on_error)
--> 846             rval = self.fn(pyll_rval)
        rval = undefined
        self.fn = <functools.partial object>
        pyll_rval = {'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': 4, 'max_features': 3, 'max_leaf_nodes': 3, 'min_samples_split': 3, 'n_estimators': 10}, 'pipeline': {'features': ('features_PCA', {'features__n_components': 1}), 'normalizer': ('normalizer_PowerTransformer', {}), 'rebalance': ('rebalance_CondensedNearestNeighbour', {'rebalance__n_neighbors': 1})}}
    847 
    848         if isinstance(rval, (float, int, np.number)):
    849             dict_rval = {'loss': float(rval), 'status': STATUS_OK}
    850         else:

...........................................................................
/home/aquemy/dev/dp_hyperparameters/extension/experiment/objective.py in objective_joint(wconfig={'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': 4, 'max_features': 3, 'max_leaf_nodes': 3, 'min_samples_split': 3, 'n_estimators': 10}, 'pipeline': {'features': ('features_PCA', {'features__n_components': 1}), 'normalizer': ('normalizer_PowerTransformer', {}), 'rebalance': ('rebalance_CondensedNearestNeighbour', {'rebalance__n_neighbors': 1})}}, algorithm='RandomForest', X=array([[5.1, 3.5, 1.4, 0.2],
       [4.9, 3. , 1....2, 3.4, 5.4, 2.3],
       [5.9, 3. , 5.1, 1.8]]), y=array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,... 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]), context={'baseline_score': 0.9466666666666667, 'baseline_score_std': 0.04988876515698587, 'best_config': {'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': 4, 'max_features': 3, 'max_leaf_nodes': 3, 'min_samples_split': 3, 'n_estimators': 10}, 'config_hash': {'algorithm': 'ffb7ff225ce3d3712c96cf87fe42202988ee2eb0', 'config': 'bae32f426be9cd6243523c023944a8c148fe4aeb', 'pipeline': 'd2a68bfda6fcdec4ae0ffc7d7b6a2122bc1cd673'}, 'duration': 0.7115809917449951, 'iteration': 113, 'loss': 0.033333333333333215, 'max_history_score': 0.9666666666666668, 'max_history_score_std': 0.033333333333333326, 'max_history_step': 'joint', 'pipeline': {'features': ('features_NoneType', {}), 'normalizer': ('normalizer_PowerTransformer', {}), 'rebalance': ('rebalance_CondensedNearestNeighbour', {'rebalance__n_neighbors': 2})}, 'score': 0.9666666666666668, ...}, 'history': [{'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': 2, 'max_features': None, 'max_leaf_nodes': 5, 'min_samples_split': 2, 'n_estimators': 75}, 'config_hash': {'algorithm': '3af5b0cce71c8fe2545246ca24ff5bc3dd516e06', 'config': 'db6ac7e6d348155757e4794bb5f88fe2b4f63d50', 'pipeline': '8d59f4b94cef6be9306ed86a22a9570fa670d567'}, 'duration': 1.149928092956543, 'iteration': 0, 'loss': 0.046666666666666634, 'max_history_score': 0.9533333333333334, 'max_history_score_std': 0.059999999999999984, 'max_history_step': 'joint', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 4, 'features__selectkbest__k': 3}), 'normalizer': ('normalizer_StandardScaler', {'normalizer__with_mean': True, 'normalizer__with_std': True}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 6})}, 'score': 0.9533333333333334, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': 1, 'max_features': 2, 'max_leaf_nodes': 2, 'min_samples_split': 5, 'n_estimators': 100}, 'config_hash': {'algorithm': 'e13eb05fd9a62d2f63bbb1c1deff0cd620d5e6ab', 'config': '4db6fb84d85f52659f780e682ffac5712c3d8a94', 'pipeline': '64c9a1ca9d53ae67244bdd942f4db36a3c05218c'}, 'duration': 1.7678282260894775, 'iteration': 1, 'loss': 0.18000000000000005, 'max_history_score': 0.9533333333333334, 'max_history_score_std': 0.059999999999999984, 'max_history_step': 'joint', 'pipeline': {'features': ('features_NoneType', {}), 'normalizer': ('normalizer_PowerTransformer', {}), 'rebalance': ('rebalance_NearMiss', {'rebalance__n_neighbors': 1})}, 'score': 0.82, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': 1, 'max_features': None, 'max_leaf_nodes': None, 'min_samples_split': 5, 'n_estimators': 75}, 'config_hash': {'algorithm': '94b0d7a654c508cc63643f78fe4f0f07e6f07c1e', 'config': '4403c5a85e951938d3c454e961d3a412780722f6', 'pipeline': '3e47444880d8367fbac2faaba2e52a917274aa58'}, 'duration': 0.8397619724273682, 'iteration': 2, 'loss': 0.03333333333333344, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_PCA', {'features__n_components': 3}), 'normalizer': ('normalizer_MinMaxScaler', {}), 'rebalance': ('rebalance_NoneType', {})}, 'score': 0.9666666666666666, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': None, 'max_features': None, 'max_leaf_nodes': 3, 'min_samples_split': 3, 'n_estimators': 75}, 'config_hash': {'algorithm': 'e8332f0a8902bda03bf70e7978cc5d52affb29d3', 'config': 'a064e2df18ab98d44dabcefbc7bed94913f1d0be', 'pipeline': '7eea819c2a8c103c4b1e9e9c1e224aebba95081f'}, 'duration': 0.8501448631286621, 'iteration': 3, 'loss': 0.053333333333333344, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 2, 'features__selectkbest__k': 4}), 'normalizer': ('normalizer_NoneType', {}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 7})}, 'score': 0.9466666666666667, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'entropy', 'max_depth': 3, 'max_features': 3, 'max_leaf_nodes': None, 'min_samples_split': 5, 'n_estimators': 75}, 'config_hash': {'algorithm': '7a4491035bc6bd737fe9a8cda8a79a02d02d5c74', 'config': '0ddb6f5cab3db4dddd7682966a57205f3e329ad4', 'pipeline': 'a9ae03fe38334f6868cbf84cdd3d629d4bbe3fb0'}, 'duration': 1.1026010513305664, 'iteration': 4, 'loss': 0.05999999999999994, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 2, 'features__selectkbest__k': 1}), 'normalizer': ('normalizer_NoneType', {}), 'rebalance': ('rebalance_NoneType', {})}, 'score': 0.9400000000000001, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'gini', 'max_depth': 3, 'max_features': 1, 'max_leaf_nodes': 5, 'min_samples_split': 2, 'n_estimators': 25}, 'config_hash': {'algorithm': '9826d20b2d6a0f559cf7f16450ce7526f07e8434', 'config': '49f25751bca61cdd461a8cbd2923689b642f98ed', 'pipeline': '19b249664c5bf067de1fed4334a296f947ce774a'}, 'duration': 0.35647010803222656, 'iteration': 5, 'loss': 0.046666666666666634, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_NoneType', {}), 'normalizer': ('normalizer_NoneType', {}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 6})}, 'score': 0.9533333333333334, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'gini', 'max_depth': 2, 'max_features': 1, 'max_leaf_nodes': 2, 'min_samples_split': 2, 'n_estimators': 50}, 'config_hash': {'algorithm': '0a4f6fbb07e0f32c6f675489a0fc82eee05bd8e1', 'config': '5c3a2b6f5e63fb45f10e41e0318b354912ec44f6', 'pipeline': 'dc3b9f176f090005e38b142f11d80e93a7dc5d5e'}, 'duration': 0.7213859558105469, 'iteration': 6, 'loss': 0.31333333333333324, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 1, 'features__selectkbest__k': 4}), 'normalizer': ('normalizer_PowerTransformer', {}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 7})}, 'score': 0.6866666666666668, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'entropy', 'max_depth': 4, 'max_features': 3, 'max_leaf_nodes': 5, 'min_samples_split': 5, 'n_estimators': 10}, 'config_hash': {'algorithm': 'b8112b97ecfc10f00a195af661dcc861cac21289', 'config': 'd3b129b397350f1b6572651c67c01de49b4b174c', 'pipeline': '5b0357ed7072c37b3d6f458bb5d49ff7d825f603'}, 'duration': 0.8299109935760498, 'iteration': 7, 'loss': 1.0, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_PCA', {'features__n_components': 2}), 'normalizer': ('normalizer_StandardScaler', {'normalizer__with_mean': True, 'normalizer__with_std': False}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 6})}, 'score': 0.0, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'gini', 'max_depth': 4, 'max_features': None, 'max_leaf_nodes': 2, 'min_samples_split': 5, 'n_estimators': 100}, 'config_hash': {'algorithm': '40ca24df19b8d164d9d098a6bed1ce056fbbb961', 'config': '813bde1108cc3c4b9bfb3a22cbb421bda7eac671', 'pipeline': '74a7b8705a1c22f7dea5e44e4ebda8f1e48add71'}, 'duration': 2.2111589908599854, 'iteration': 8, 'loss': 0.33333333333333326, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_PCA', {'features__n_components': 2}), 'normalizer': ('normalizer_StandardScaler', {'normalizer__with_mean': False, 'normalizer__with_std': True}), 'rebalance': ('rebalance_NearMiss', {'rebalance__n_neighbors': 2})}, 'score': 0.6666666666666667, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'entropy', 'max_depth': 2, 'max_features': 1, 'max_leaf_nodes': 5, 'min_samples_split': 2, 'n_estimators': 100}, 'config_hash': {'algorithm': '331418a5c12cf1453876eef85e9d98fc8e54fa11', 'config': '31930b6860ed406d59bf7e59ba1925d94704bd3b', 'pipeline': '054bef356f90ec6f644ef3ffc688766744db51c2'}, 'duration': 1.0501940250396729, 'iteration': 9, 'loss': 0.053333333333333344, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_SelectKBest', {'features__k': 1}), 'normalizer': ('normalizer_RobustScaler', {'normalizer__quantile_range': (...), 'normalizer__with_centering': True, 'normalizer__with_scaling': True}), 'rebalance': ('rebalance_NearMiss', {'rebalance__n_neighbors': 2})}, 'score': 0.9466666666666667, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'entropy', 'max_depth': 3, 'max_features': None, 'max_leaf_nodes': 3, 'min_samples_split': 2, 'n_estimators': 100}, 'config_hash': {'algorithm': 'dbc1b8126649fe93dce5fbb37e4015b0acfb179e', 'config': '9913cd550615a9d0946ab4a755a8b9f619e442fd', 'pipeline': 'dd626121cea079ebb32e184ca65483ec7a6d7f59'}, 'duration': 1.120617151260376, 'iteration': 10, 'loss': 0.046666666666666634, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 2, 'features__selectkbest__k': 1}), 'normalizer': ('normalizer_MinMaxScaler', {}), 'rebalance': ('rebalance_NoneType', {})}, 'score': 0.9533333333333334, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'gini', 'max_depth': 3, 'max_features': 3, 'max_leaf_nodes': None, 'min_samples_split': 3, 'n_estimators': 75}, 'config_hash': {'algorithm': '34917a130df5a975f78bd7ec1a0c7b1ffdc787a9', 'config': '95fc8cadc088141290b7de9c388977e4685f0108', 'pipeline': '550d10faf2f08db48516cc3501558816d6a99bc0'}, 'duration': 1.4287099838256836, 'iteration': 11, 'loss': 0.19333333333333313, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 3, 'features__selectkbest__k': 4}), 'normalizer': ('normalizer_StandardScaler', {'normalizer__with_mean': False, 'normalizer__with_std': False}), 'rebalance': ('rebalance_CondensedNearestNeighbour', {'rebalance__n_neighbors': 1})}, 'score': 0.8066666666666669, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'entropy', 'max_depth': 1, 'max_features': 2, 'max_leaf_nodes': 5, 'min_samples_split': 2, 'n_estimators': 75}, 'config_hash': {'algorithm': '33f9abb4aee44a395a9f3b3ffa9ce80a8cdaed7c', 'config': '40fa726f0360cf6af55f9b5902d399d02f61f157', 'pipeline': 'cfd1d20841fe2153da762c95e79f95a3fb1e426a'}, 'duration': 1.2978079319000244, 'iteration': 12, 'loss': 0.053333333333333344, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_PCA', {'features__n_components': 4}), 'normalizer': ('normalizer_MinMaxScaler', {}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 7})}, 'score': 0.9466666666666667, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'entropy', 'max_depth': 4, 'max_features': 2, 'max_leaf_nodes': 5, 'min_samples_split': 3, 'n_estimators': 25}, 'config_hash': {'algorithm': '210111ec6562d09eb093e98ed69ef1c662e11a50', 'config': '0fb8e77c7bd9a58b72f1b33c21a59a09a8c676ba', 'pipeline': '5d269d759e0c7926a685a14b263ace8ae0071e4b'}, 'duration': 0.36649012565612793, 'iteration': 13, 'loss': 0.040000000000000036, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 2, 'features__selectkbest__k': 2}), 'normalizer': ('normalizer_NoneType', {}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 7})}, 'score': 0.96, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'entropy', 'max_depth': 3, 'max_features': 1, 'max_leaf_nodes': 5, 'min_samples_split': 2, 'n_estimators': 25}, 'config_hash': {'algorithm': '0e989a03980101fabf79eda3326ed2870e11d690', 'config': 'f4bffd5d8c67a9c5321a9943c4a99678f59a02b7', 'pipeline': '865ee1e3fe8334c3d5ecb2038d5a5d1b3ba50e75'}, 'duration': 0.35639500617980957, 'iteration': 14, 'loss': 0.046666666666666634, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_NoneType', {}), 'normalizer': ('normalizer_RobustScaler', {'normalizer__quantile_range': (...), 'normalizer__with_centering': True, 'normalizer__with_scaling': False}), 'rebalance': ('rebalance_NoneType', {})}, 'score': 0.9533333333333334, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'entropy', 'max_depth': None, 'max_features': 3, 'max_leaf_nodes': 3, 'min_samples_split': 5, 'n_estimators': 10}, 'config_hash': {'algorithm': '9c592e876c13de5e23e6de5b868e01755d63e72e', 'config': '1e6a68cd1eeac886d90724d78b1cb5fb76a3cde4', 'pipeline': '5a1ca4d82f21b7de0d2c918630a42510673fa36e'}, 'duration': 0.18141412734985352, 'iteration': 15, 'loss': 0.046666666666666634, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_SelectKBest', {'features__k': 3}), 'normalizer': ('normalizer_RobustScaler', {'normalizer__quantile_range': (...), 'normalizer__with_centering': True, 'normalizer__with_scaling': True}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 6})}, 'score': 0.9533333333333334, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': 1, 'max_features': None, 'max_leaf_nodes': None, 'min_samples_split': 5, 'n_estimators': 10}, 'config_hash': {'algorithm': '8bed77aef289bfd453b2858bd288ae5ba7160f2b', 'config': '781185bcb8999045de8d489f253a1a1ba4247932', 'pipeline': '1ece7eabedc2be9e5b0a1be65c570d08ffa3eb54'}, 'duration': 0.1636829376220703, 'iteration': 16, 'loss': 0.053333333333333344, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_NoneType', {}), 'normalizer': ('normalizer_NoneType', {}), 'rebalance': ('rebalance_NearMiss', {'rebalance__n_neighbors': 1})}, 'score': 0.9466666666666667, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'gini', 'max_depth': 3, 'max_features': 2, 'max_leaf_nodes': 2, 'min_samples_split': 5, 'n_estimators': 75}, 'config_hash': {'algorithm': '617b97d9ba21d3373bc51ffa9cccf9c6f91a77b3', 'config': '99fb425b4e8c5d80228cab94202252aa25cdf77c', 'pipeline': 'd6242929c3b515c7719e60423023ac604311afc3'}, 'duration': 0.8468999862670898, 'iteration': 17, 'loss': 0.24, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_PCA', {'features__n_components': 4}), 'normalizer': ('normalizer_PowerTransformer', {}), 'rebalance': ('rebalance_NearMiss', {'rebalance__n_neighbors': 2})}, 'score': 0.76, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': 1, 'max_features': 1, 'max_leaf_nodes': 2, 'min_samples_split': 5, 'n_estimators': 50}, 'config_hash': {'algorithm': 'b92d2697cdd4979da443369d6596229ec091626a', 'config': 'c513a3e13281206ad76187dd817b1fff93d54fe1', 'pipeline': 'c4b4f914a3ca8df967cade997a90366d85a371b9'}, 'duration': 0.6724588871002197, 'iteration': 18, 'loss': 0.23333333333333328, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 1, 'features__selectkbest__k': 3}), 'normalizer': ('normalizer_StandardScaler', {'normalizer__with_mean': True, 'normalizer__with_std': True}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 5})}, 'score': 0.7666666666666667, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'entropy', 'max_depth': None, 'max_features': None, 'max_leaf_nodes': 5, 'min_samples_split': 5, 'n_estimators': 10}, 'config_hash': {'algorithm': 'a0115de695e6cca2e81cbfb54df79bf4b43608b1', 'config': 'ba194015e20b5d67770e8c67342c3d8d0d01dc41', 'pipeline': '8d45fabfeb85ffdcabf7076bd0e65fffe97ce928'}, 'duration': 0.19424200057983398, 'iteration': 19, 'loss': 0.08666666666666667, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_PCA', {'features__n_components': 3}), 'normalizer': ('normalizer_NoneType', {}), 'rebalance': ('rebalance_NoneType', {})}, 'score': 0.9133333333333333, ...}, ...], 'history_hash': ['db6ac7e6d348155757e4794bb5f88fe2b4f63d50', '4db6fb84d85f52659f780e682ffac5712c3d8a94', '4403c5a85e951938d3c454e961d3a412780722f6', 'a064e2df18ab98d44dabcefbc7bed94913f1d0be', '0ddb6f5cab3db4dddd7682966a57205f3e329ad4', '49f25751bca61cdd461a8cbd2923689b642f98ed', '5c3a2b6f5e63fb45f10e41e0318b354912ec44f6', 'd3b129b397350f1b6572651c67c01de49b4b174c', '813bde1108cc3c4b9bfb3a22cbb421bda7eac671', '31930b6860ed406d59bf7e59ba1925d94704bd3b', '9913cd550615a9d0946ab4a755a8b9f619e442fd', '95fc8cadc088141290b7de9c388977e4685f0108', '40fa726f0360cf6af55f9b5902d399d02f61f157', '0fb8e77c7bd9a58b72f1b33c21a59a09a8c676ba', 'f4bffd5d8c67a9c5321a9943c4a99678f59a02b7', '1e6a68cd1eeac886d90724d78b1cb5fb76a3cde4', '781185bcb8999045de8d489f253a1a1ba4247932', '99fb425b4e8c5d80228cab94202252aa25cdf77c', 'c513a3e13281206ad76187dd817b1fff93d54fe1', 'ba194015e20b5d67770e8c67342c3d8d0d01dc41', ...], 'history_index': {'013329309d510b94f19d930320402d65f953a847': 39, '038a0f515e2ec894ee8e34f9caa2889eb3ebd5ce': 66, '052ae4bf232b316187b078abae42c2be19e16a00': 111, '0659afebf316aafeb75612fb07081a04c28545ed': 74, '06e7cde9f3556cd01332ce389ad1d8925cd4b4a4': 120, '08606f2a0f0a6c9de204020b4632e09fcee0ae56': 168, '0a05b5b0a70971a5e347aaab7a4d4a07a92222fd': 191, '0b6551ecfd6f83a15704a9db68f1599c99c6d3ef': 58, '0cfb4698cbf2d986bcd5e0c2ef0f974da60b205e': 194, '0ddb6f5cab3db4dddd7682966a57205f3e329ad4': 4, ...}, 'iteration': 204, 'max_history_score': 0.9666666666666668, 'max_history_score_std': 0.033333333333333326, 'max_history_step': 'joint'}, config={'algorithm': 'RandomForest', 'seed': 42, 'time': 300})
    108 
    109 def objective_algo(algo_config, current_pipeline_config, algorithm, X, y, context, config):
    110     return objective(current_pipeline_config, algo_config, algorithm, X, y, context, config, step='algorithm')
    111 
    112 def objective_joint(wconfig, algorithm, X, y, context, config):
--> 113     return objective(wconfig['pipeline'], wconfig['algorithm'], algorithm, X, y, context, config, step='joint')
        wconfig = {'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': 4, 'max_features': 3, 'max_leaf_nodes': 3, 'min_samples_split': 3, 'n_estimators': 10}, 'pipeline': {'features': ('features_PCA', {'features__n_components': 1}), 'normalizer': ('normalizer_PowerTransformer', {}), 'rebalance': ('rebalance_CondensedNearestNeighbour', {'rebalance__n_neighbors': 1})}}
        algorithm = 'RandomForest'
        X = array([[5.1, 3.5, 1.4, 0.2],
       [4.9, 3. , 1....2, 3.4, 5.4, 2.3],
       [5.9, 3. , 5.1, 1.8]])
        y = array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,... 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2])
        context = {'baseline_score': 0.9466666666666667, 'baseline_score_std': 0.04988876515698587, 'best_config': {'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': 4, 'max_features': 3, 'max_leaf_nodes': 3, 'min_samples_split': 3, 'n_estimators': 10}, 'config_hash': {'algorithm': 'ffb7ff225ce3d3712c96cf87fe42202988ee2eb0', 'config': 'bae32f426be9cd6243523c023944a8c148fe4aeb', 'pipeline': 'd2a68bfda6fcdec4ae0ffc7d7b6a2122bc1cd673'}, 'duration': 0.7115809917449951, 'iteration': 113, 'loss': 0.033333333333333215, 'max_history_score': 0.9666666666666668, 'max_history_score_std': 0.033333333333333326, 'max_history_step': 'joint', 'pipeline': {'features': ('features_NoneType', {}), 'normalizer': ('normalizer_PowerTransformer', {}), 'rebalance': ('rebalance_CondensedNearestNeighbour', {'rebalance__n_neighbors': 2})}, 'score': 0.9666666666666668, ...}, 'history': [{'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': 2, 'max_features': None, 'max_leaf_nodes': 5, 'min_samples_split': 2, 'n_estimators': 75}, 'config_hash': {'algorithm': '3af5b0cce71c8fe2545246ca24ff5bc3dd516e06', 'config': 'db6ac7e6d348155757e4794bb5f88fe2b4f63d50', 'pipeline': '8d59f4b94cef6be9306ed86a22a9570fa670d567'}, 'duration': 1.149928092956543, 'iteration': 0, 'loss': 0.046666666666666634, 'max_history_score': 0.9533333333333334, 'max_history_score_std': 0.059999999999999984, 'max_history_step': 'joint', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 4, 'features__selectkbest__k': 3}), 'normalizer': ('normalizer_StandardScaler', {'normalizer__with_mean': True, 'normalizer__with_std': True}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 6})}, 'score': 0.9533333333333334, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': 1, 'max_features': 2, 'max_leaf_nodes': 2, 'min_samples_split': 5, 'n_estimators': 100}, 'config_hash': {'algorithm': 'e13eb05fd9a62d2f63bbb1c1deff0cd620d5e6ab', 'config': '4db6fb84d85f52659f780e682ffac5712c3d8a94', 'pipeline': '64c9a1ca9d53ae67244bdd942f4db36a3c05218c'}, 'duration': 1.7678282260894775, 'iteration': 1, 'loss': 0.18000000000000005, 'max_history_score': 0.9533333333333334, 'max_history_score_std': 0.059999999999999984, 'max_history_step': 'joint', 'pipeline': {'features': ('features_NoneType', {}), 'normalizer': ('normalizer_PowerTransformer', {}), 'rebalance': ('rebalance_NearMiss', {'rebalance__n_neighbors': 1})}, 'score': 0.82, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': 1, 'max_features': None, 'max_leaf_nodes': None, 'min_samples_split': 5, 'n_estimators': 75}, 'config_hash': {'algorithm': '94b0d7a654c508cc63643f78fe4f0f07e6f07c1e', 'config': '4403c5a85e951938d3c454e961d3a412780722f6', 'pipeline': '3e47444880d8367fbac2faaba2e52a917274aa58'}, 'duration': 0.8397619724273682, 'iteration': 2, 'loss': 0.03333333333333344, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_PCA', {'features__n_components': 3}), 'normalizer': ('normalizer_MinMaxScaler', {}), 'rebalance': ('rebalance_NoneType', {})}, 'score': 0.9666666666666666, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': None, 'max_features': None, 'max_leaf_nodes': 3, 'min_samples_split': 3, 'n_estimators': 75}, 'config_hash': {'algorithm': 'e8332f0a8902bda03bf70e7978cc5d52affb29d3', 'config': 'a064e2df18ab98d44dabcefbc7bed94913f1d0be', 'pipeline': '7eea819c2a8c103c4b1e9e9c1e224aebba95081f'}, 'duration': 0.8501448631286621, 'iteration': 3, 'loss': 0.053333333333333344, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 2, 'features__selectkbest__k': 4}), 'normalizer': ('normalizer_NoneType', {}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 7})}, 'score': 0.9466666666666667, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'entropy', 'max_depth': 3, 'max_features': 3, 'max_leaf_nodes': None, 'min_samples_split': 5, 'n_estimators': 75}, 'config_hash': {'algorithm': '7a4491035bc6bd737fe9a8cda8a79a02d02d5c74', 'config': '0ddb6f5cab3db4dddd7682966a57205f3e329ad4', 'pipeline': 'a9ae03fe38334f6868cbf84cdd3d629d4bbe3fb0'}, 'duration': 1.1026010513305664, 'iteration': 4, 'loss': 0.05999999999999994, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 2, 'features__selectkbest__k': 1}), 'normalizer': ('normalizer_NoneType', {}), 'rebalance': ('rebalance_NoneType', {})}, 'score': 0.9400000000000001, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'gini', 'max_depth': 3, 'max_features': 1, 'max_leaf_nodes': 5, 'min_samples_split': 2, 'n_estimators': 25}, 'config_hash': {'algorithm': '9826d20b2d6a0f559cf7f16450ce7526f07e8434', 'config': '49f25751bca61cdd461a8cbd2923689b642f98ed', 'pipeline': '19b249664c5bf067de1fed4334a296f947ce774a'}, 'duration': 0.35647010803222656, 'iteration': 5, 'loss': 0.046666666666666634, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_NoneType', {}), 'normalizer': ('normalizer_NoneType', {}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 6})}, 'score': 0.9533333333333334, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'gini', 'max_depth': 2, 'max_features': 1, 'max_leaf_nodes': 2, 'min_samples_split': 2, 'n_estimators': 50}, 'config_hash': {'algorithm': '0a4f6fbb07e0f32c6f675489a0fc82eee05bd8e1', 'config': '5c3a2b6f5e63fb45f10e41e0318b354912ec44f6', 'pipeline': 'dc3b9f176f090005e38b142f11d80e93a7dc5d5e'}, 'duration': 0.7213859558105469, 'iteration': 6, 'loss': 0.31333333333333324, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 1, 'features__selectkbest__k': 4}), 'normalizer': ('normalizer_PowerTransformer', {}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 7})}, 'score': 0.6866666666666668, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'entropy', 'max_depth': 4, 'max_features': 3, 'max_leaf_nodes': 5, 'min_samples_split': 5, 'n_estimators': 10}, 'config_hash': {'algorithm': 'b8112b97ecfc10f00a195af661dcc861cac21289', 'config': 'd3b129b397350f1b6572651c67c01de49b4b174c', 'pipeline': '5b0357ed7072c37b3d6f458bb5d49ff7d825f603'}, 'duration': 0.8299109935760498, 'iteration': 7, 'loss': 1.0, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_PCA', {'features__n_components': 2}), 'normalizer': ('normalizer_StandardScaler', {'normalizer__with_mean': True, 'normalizer__with_std': False}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 6})}, 'score': 0.0, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'gini', 'max_depth': 4, 'max_features': None, 'max_leaf_nodes': 2, 'min_samples_split': 5, 'n_estimators': 100}, 'config_hash': {'algorithm': '40ca24df19b8d164d9d098a6bed1ce056fbbb961', 'config': '813bde1108cc3c4b9bfb3a22cbb421bda7eac671', 'pipeline': '74a7b8705a1c22f7dea5e44e4ebda8f1e48add71'}, 'duration': 2.2111589908599854, 'iteration': 8, 'loss': 0.33333333333333326, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_PCA', {'features__n_components': 2}), 'normalizer': ('normalizer_StandardScaler', {'normalizer__with_mean': False, 'normalizer__with_std': True}), 'rebalance': ('rebalance_NearMiss', {'rebalance__n_neighbors': 2})}, 'score': 0.6666666666666667, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'entropy', 'max_depth': 2, 'max_features': 1, 'max_leaf_nodes': 5, 'min_samples_split': 2, 'n_estimators': 100}, 'config_hash': {'algorithm': '331418a5c12cf1453876eef85e9d98fc8e54fa11', 'config': '31930b6860ed406d59bf7e59ba1925d94704bd3b', 'pipeline': '054bef356f90ec6f644ef3ffc688766744db51c2'}, 'duration': 1.0501940250396729, 'iteration': 9, 'loss': 0.053333333333333344, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_SelectKBest', {'features__k': 1}), 'normalizer': ('normalizer_RobustScaler', {'normalizer__quantile_range': (...), 'normalizer__with_centering': True, 'normalizer__with_scaling': True}), 'rebalance': ('rebalance_NearMiss', {'rebalance__n_neighbors': 2})}, 'score': 0.9466666666666667, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'entropy', 'max_depth': 3, 'max_features': None, 'max_leaf_nodes': 3, 'min_samples_split': 2, 'n_estimators': 100}, 'config_hash': {'algorithm': 'dbc1b8126649fe93dce5fbb37e4015b0acfb179e', 'config': '9913cd550615a9d0946ab4a755a8b9f619e442fd', 'pipeline': 'dd626121cea079ebb32e184ca65483ec7a6d7f59'}, 'duration': 1.120617151260376, 'iteration': 10, 'loss': 0.046666666666666634, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 2, 'features__selectkbest__k': 1}), 'normalizer': ('normalizer_MinMaxScaler', {}), 'rebalance': ('rebalance_NoneType', {})}, 'score': 0.9533333333333334, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'gini', 'max_depth': 3, 'max_features': 3, 'max_leaf_nodes': None, 'min_samples_split': 3, 'n_estimators': 75}, 'config_hash': {'algorithm': '34917a130df5a975f78bd7ec1a0c7b1ffdc787a9', 'config': '95fc8cadc088141290b7de9c388977e4685f0108', 'pipeline': '550d10faf2f08db48516cc3501558816d6a99bc0'}, 'duration': 1.4287099838256836, 'iteration': 11, 'loss': 0.19333333333333313, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 3, 'features__selectkbest__k': 4}), 'normalizer': ('normalizer_StandardScaler', {'normalizer__with_mean': False, 'normalizer__with_std': False}), 'rebalance': ('rebalance_CondensedNearestNeighbour', {'rebalance__n_neighbors': 1})}, 'score': 0.8066666666666669, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'entropy', 'max_depth': 1, 'max_features': 2, 'max_leaf_nodes': 5, 'min_samples_split': 2, 'n_estimators': 75}, 'config_hash': {'algorithm': '33f9abb4aee44a395a9f3b3ffa9ce80a8cdaed7c', 'config': '40fa726f0360cf6af55f9b5902d399d02f61f157', 'pipeline': 'cfd1d20841fe2153da762c95e79f95a3fb1e426a'}, 'duration': 1.2978079319000244, 'iteration': 12, 'loss': 0.053333333333333344, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_PCA', {'features__n_components': 4}), 'normalizer': ('normalizer_MinMaxScaler', {}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 7})}, 'score': 0.9466666666666667, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'entropy', 'max_depth': 4, 'max_features': 2, 'max_leaf_nodes': 5, 'min_samples_split': 3, 'n_estimators': 25}, 'config_hash': {'algorithm': '210111ec6562d09eb093e98ed69ef1c662e11a50', 'config': '0fb8e77c7bd9a58b72f1b33c21a59a09a8c676ba', 'pipeline': '5d269d759e0c7926a685a14b263ace8ae0071e4b'}, 'duration': 0.36649012565612793, 'iteration': 13, 'loss': 0.040000000000000036, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 2, 'features__selectkbest__k': 2}), 'normalizer': ('normalizer_NoneType', {}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 7})}, 'score': 0.96, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'entropy', 'max_depth': 3, 'max_features': 1, 'max_leaf_nodes': 5, 'min_samples_split': 2, 'n_estimators': 25}, 'config_hash': {'algorithm': '0e989a03980101fabf79eda3326ed2870e11d690', 'config': 'f4bffd5d8c67a9c5321a9943c4a99678f59a02b7', 'pipeline': '865ee1e3fe8334c3d5ecb2038d5a5d1b3ba50e75'}, 'duration': 0.35639500617980957, 'iteration': 14, 'loss': 0.046666666666666634, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_NoneType', {}), 'normalizer': ('normalizer_RobustScaler', {'normalizer__quantile_range': (...), 'normalizer__with_centering': True, 'normalizer__with_scaling': False}), 'rebalance': ('rebalance_NoneType', {})}, 'score': 0.9533333333333334, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'entropy', 'max_depth': None, 'max_features': 3, 'max_leaf_nodes': 3, 'min_samples_split': 5, 'n_estimators': 10}, 'config_hash': {'algorithm': '9c592e876c13de5e23e6de5b868e01755d63e72e', 'config': '1e6a68cd1eeac886d90724d78b1cb5fb76a3cde4', 'pipeline': '5a1ca4d82f21b7de0d2c918630a42510673fa36e'}, 'duration': 0.18141412734985352, 'iteration': 15, 'loss': 0.046666666666666634, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_SelectKBest', {'features__k': 3}), 'normalizer': ('normalizer_RobustScaler', {'normalizer__quantile_range': (...), 'normalizer__with_centering': True, 'normalizer__with_scaling': True}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 6})}, 'score': 0.9533333333333334, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': 1, 'max_features': None, 'max_leaf_nodes': None, 'min_samples_split': 5, 'n_estimators': 10}, 'config_hash': {'algorithm': '8bed77aef289bfd453b2858bd288ae5ba7160f2b', 'config': '781185bcb8999045de8d489f253a1a1ba4247932', 'pipeline': '1ece7eabedc2be9e5b0a1be65c570d08ffa3eb54'}, 'duration': 0.1636829376220703, 'iteration': 16, 'loss': 0.053333333333333344, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_NoneType', {}), 'normalizer': ('normalizer_NoneType', {}), 'rebalance': ('rebalance_NearMiss', {'rebalance__n_neighbors': 1})}, 'score': 0.9466666666666667, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'gini', 'max_depth': 3, 'max_features': 2, 'max_leaf_nodes': 2, 'min_samples_split': 5, 'n_estimators': 75}, 'config_hash': {'algorithm': '617b97d9ba21d3373bc51ffa9cccf9c6f91a77b3', 'config': '99fb425b4e8c5d80228cab94202252aa25cdf77c', 'pipeline': 'd6242929c3b515c7719e60423023ac604311afc3'}, 'duration': 0.8468999862670898, 'iteration': 17, 'loss': 0.24, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_PCA', {'features__n_components': 4}), 'normalizer': ('normalizer_PowerTransformer', {}), 'rebalance': ('rebalance_NearMiss', {'rebalance__n_neighbors': 2})}, 'score': 0.76, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': 1, 'max_features': 1, 'max_leaf_nodes': 2, 'min_samples_split': 5, 'n_estimators': 50}, 'config_hash': {'algorithm': 'b92d2697cdd4979da443369d6596229ec091626a', 'config': 'c513a3e13281206ad76187dd817b1fff93d54fe1', 'pipeline': 'c4b4f914a3ca8df967cade997a90366d85a371b9'}, 'duration': 0.6724588871002197, 'iteration': 18, 'loss': 0.23333333333333328, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 1, 'features__selectkbest__k': 3}), 'normalizer': ('normalizer_StandardScaler', {'normalizer__with_mean': True, 'normalizer__with_std': True}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 5})}, 'score': 0.7666666666666667, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'entropy', 'max_depth': None, 'max_features': None, 'max_leaf_nodes': 5, 'min_samples_split': 5, 'n_estimators': 10}, 'config_hash': {'algorithm': 'a0115de695e6cca2e81cbfb54df79bf4b43608b1', 'config': 'ba194015e20b5d67770e8c67342c3d8d0d01dc41', 'pipeline': '8d45fabfeb85ffdcabf7076bd0e65fffe97ce928'}, 'duration': 0.19424200057983398, 'iteration': 19, 'loss': 0.08666666666666667, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_PCA', {'features__n_components': 3}), 'normalizer': ('normalizer_NoneType', {}), 'rebalance': ('rebalance_NoneType', {})}, 'score': 0.9133333333333333, ...}, ...], 'history_hash': ['db6ac7e6d348155757e4794bb5f88fe2b4f63d50', '4db6fb84d85f52659f780e682ffac5712c3d8a94', '4403c5a85e951938d3c454e961d3a412780722f6', 'a064e2df18ab98d44dabcefbc7bed94913f1d0be', '0ddb6f5cab3db4dddd7682966a57205f3e329ad4', '49f25751bca61cdd461a8cbd2923689b642f98ed', '5c3a2b6f5e63fb45f10e41e0318b354912ec44f6', 'd3b129b397350f1b6572651c67c01de49b4b174c', '813bde1108cc3c4b9bfb3a22cbb421bda7eac671', '31930b6860ed406d59bf7e59ba1925d94704bd3b', '9913cd550615a9d0946ab4a755a8b9f619e442fd', '95fc8cadc088141290b7de9c388977e4685f0108', '40fa726f0360cf6af55f9b5902d399d02f61f157', '0fb8e77c7bd9a58b72f1b33c21a59a09a8c676ba', 'f4bffd5d8c67a9c5321a9943c4a99678f59a02b7', '1e6a68cd1eeac886d90724d78b1cb5fb76a3cde4', '781185bcb8999045de8d489f253a1a1ba4247932', '99fb425b4e8c5d80228cab94202252aa25cdf77c', 'c513a3e13281206ad76187dd817b1fff93d54fe1', 'ba194015e20b5d67770e8c67342c3d8d0d01dc41', ...], 'history_index': {'013329309d510b94f19d930320402d65f953a847': 39, '038a0f515e2ec894ee8e34f9caa2889eb3ebd5ce': 66, '052ae4bf232b316187b078abae42c2be19e16a00': 111, '0659afebf316aafeb75612fb07081a04c28545ed': 74, '06e7cde9f3556cd01332ce389ad1d8925cd4b4a4': 120, '08606f2a0f0a6c9de204020b4632e09fcee0ae56': 168, '0a05b5b0a70971a5e347aaab7a4d4a07a92222fd': 191, '0b6551ecfd6f83a15704a9db68f1599c99c6d3ef': 58, '0cfb4698cbf2d986bcd5e0c2ef0f974da60b205e': 194, '0ddb6f5cab3db4dddd7682966a57205f3e329ad4': 4, ...}, 'iteration': 204, 'max_history_score': 0.9666666666666668, 'max_history_score_std': 0.033333333333333326, 'max_history_step': 'joint'}
        config = {'algorithm': 'RandomForest', 'seed': 42, 'time': 300}
    114 
    115 
    116 def get_baseline_score(algorithm, X, y, seed):
    117     pipeline, _ = pipeline_conf_to_full_pipeline(

...........................................................................
/home/aquemy/dev/dp_hyperparameters/extension/experiment/objective.py in objective(pipeline_config={'features': ('features_PCA', {'features__n_components': 1}), 'normalizer': ('normalizer_PowerTransformer', {}), 'rebalance': ('rebalance_CondensedNearestNeighbour', {'rebalance__n_neighbors': 1})}, algo_config={'bootstrap': True, 'criterion': 'gini', 'max_depth': 4, 'max_features': 3, 'max_leaf_nodes': 3, 'min_samples_split': 3, 'n_estimators': 10}, algorithm='RandomForest', X=array([[5.1, 3.5, 1.4, 0.2],
       [4.9, 3. , 1....2, 3.4, 5.4, 2.3],
       [5.9, 3. , 5.1, 1.8]]), y=array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,... 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]), context={'baseline_score': 0.9466666666666667, 'baseline_score_std': 0.04988876515698587, 'best_config': {'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': 4, 'max_features': 3, 'max_leaf_nodes': 3, 'min_samples_split': 3, 'n_estimators': 10}, 'config_hash': {'algorithm': 'ffb7ff225ce3d3712c96cf87fe42202988ee2eb0', 'config': 'bae32f426be9cd6243523c023944a8c148fe4aeb', 'pipeline': 'd2a68bfda6fcdec4ae0ffc7d7b6a2122bc1cd673'}, 'duration': 0.7115809917449951, 'iteration': 113, 'loss': 0.033333333333333215, 'max_history_score': 0.9666666666666668, 'max_history_score_std': 0.033333333333333326, 'max_history_step': 'joint', 'pipeline': {'features': ('features_NoneType', {}), 'normalizer': ('normalizer_PowerTransformer', {}), 'rebalance': ('rebalance_CondensedNearestNeighbour', {'rebalance__n_neighbors': 2})}, 'score': 0.9666666666666668, ...}, 'history': [{'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': 2, 'max_features': None, 'max_leaf_nodes': 5, 'min_samples_split': 2, 'n_estimators': 75}, 'config_hash': {'algorithm': '3af5b0cce71c8fe2545246ca24ff5bc3dd516e06', 'config': 'db6ac7e6d348155757e4794bb5f88fe2b4f63d50', 'pipeline': '8d59f4b94cef6be9306ed86a22a9570fa670d567'}, 'duration': 1.149928092956543, 'iteration': 0, 'loss': 0.046666666666666634, 'max_history_score': 0.9533333333333334, 'max_history_score_std': 0.059999999999999984, 'max_history_step': 'joint', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 4, 'features__selectkbest__k': 3}), 'normalizer': ('normalizer_StandardScaler', {'normalizer__with_mean': True, 'normalizer__with_std': True}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 6})}, 'score': 0.9533333333333334, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': 1, 'max_features': 2, 'max_leaf_nodes': 2, 'min_samples_split': 5, 'n_estimators': 100}, 'config_hash': {'algorithm': 'e13eb05fd9a62d2f63bbb1c1deff0cd620d5e6ab', 'config': '4db6fb84d85f52659f780e682ffac5712c3d8a94', 'pipeline': '64c9a1ca9d53ae67244bdd942f4db36a3c05218c'}, 'duration': 1.7678282260894775, 'iteration': 1, 'loss': 0.18000000000000005, 'max_history_score': 0.9533333333333334, 'max_history_score_std': 0.059999999999999984, 'max_history_step': 'joint', 'pipeline': {'features': ('features_NoneType', {}), 'normalizer': ('normalizer_PowerTransformer', {}), 'rebalance': ('rebalance_NearMiss', {'rebalance__n_neighbors': 1})}, 'score': 0.82, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': 1, 'max_features': None, 'max_leaf_nodes': None, 'min_samples_split': 5, 'n_estimators': 75}, 'config_hash': {'algorithm': '94b0d7a654c508cc63643f78fe4f0f07e6f07c1e', 'config': '4403c5a85e951938d3c454e961d3a412780722f6', 'pipeline': '3e47444880d8367fbac2faaba2e52a917274aa58'}, 'duration': 0.8397619724273682, 'iteration': 2, 'loss': 0.03333333333333344, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_PCA', {'features__n_components': 3}), 'normalizer': ('normalizer_MinMaxScaler', {}), 'rebalance': ('rebalance_NoneType', {})}, 'score': 0.9666666666666666, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': None, 'max_features': None, 'max_leaf_nodes': 3, 'min_samples_split': 3, 'n_estimators': 75}, 'config_hash': {'algorithm': 'e8332f0a8902bda03bf70e7978cc5d52affb29d3', 'config': 'a064e2df18ab98d44dabcefbc7bed94913f1d0be', 'pipeline': '7eea819c2a8c103c4b1e9e9c1e224aebba95081f'}, 'duration': 0.8501448631286621, 'iteration': 3, 'loss': 0.053333333333333344, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 2, 'features__selectkbest__k': 4}), 'normalizer': ('normalizer_NoneType', {}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 7})}, 'score': 0.9466666666666667, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'entropy', 'max_depth': 3, 'max_features': 3, 'max_leaf_nodes': None, 'min_samples_split': 5, 'n_estimators': 75}, 'config_hash': {'algorithm': '7a4491035bc6bd737fe9a8cda8a79a02d02d5c74', 'config': '0ddb6f5cab3db4dddd7682966a57205f3e329ad4', 'pipeline': 'a9ae03fe38334f6868cbf84cdd3d629d4bbe3fb0'}, 'duration': 1.1026010513305664, 'iteration': 4, 'loss': 0.05999999999999994, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 2, 'features__selectkbest__k': 1}), 'normalizer': ('normalizer_NoneType', {}), 'rebalance': ('rebalance_NoneType', {})}, 'score': 0.9400000000000001, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'gini', 'max_depth': 3, 'max_features': 1, 'max_leaf_nodes': 5, 'min_samples_split': 2, 'n_estimators': 25}, 'config_hash': {'algorithm': '9826d20b2d6a0f559cf7f16450ce7526f07e8434', 'config': '49f25751bca61cdd461a8cbd2923689b642f98ed', 'pipeline': '19b249664c5bf067de1fed4334a296f947ce774a'}, 'duration': 0.35647010803222656, 'iteration': 5, 'loss': 0.046666666666666634, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_NoneType', {}), 'normalizer': ('normalizer_NoneType', {}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 6})}, 'score': 0.9533333333333334, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'gini', 'max_depth': 2, 'max_features': 1, 'max_leaf_nodes': 2, 'min_samples_split': 2, 'n_estimators': 50}, 'config_hash': {'algorithm': '0a4f6fbb07e0f32c6f675489a0fc82eee05bd8e1', 'config': '5c3a2b6f5e63fb45f10e41e0318b354912ec44f6', 'pipeline': 'dc3b9f176f090005e38b142f11d80e93a7dc5d5e'}, 'duration': 0.7213859558105469, 'iteration': 6, 'loss': 0.31333333333333324, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 1, 'features__selectkbest__k': 4}), 'normalizer': ('normalizer_PowerTransformer', {}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 7})}, 'score': 0.6866666666666668, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'entropy', 'max_depth': 4, 'max_features': 3, 'max_leaf_nodes': 5, 'min_samples_split': 5, 'n_estimators': 10}, 'config_hash': {'algorithm': 'b8112b97ecfc10f00a195af661dcc861cac21289', 'config': 'd3b129b397350f1b6572651c67c01de49b4b174c', 'pipeline': '5b0357ed7072c37b3d6f458bb5d49ff7d825f603'}, 'duration': 0.8299109935760498, 'iteration': 7, 'loss': 1.0, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_PCA', {'features__n_components': 2}), 'normalizer': ('normalizer_StandardScaler', {'normalizer__with_mean': True, 'normalizer__with_std': False}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 6})}, 'score': 0.0, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'gini', 'max_depth': 4, 'max_features': None, 'max_leaf_nodes': 2, 'min_samples_split': 5, 'n_estimators': 100}, 'config_hash': {'algorithm': '40ca24df19b8d164d9d098a6bed1ce056fbbb961', 'config': '813bde1108cc3c4b9bfb3a22cbb421bda7eac671', 'pipeline': '74a7b8705a1c22f7dea5e44e4ebda8f1e48add71'}, 'duration': 2.2111589908599854, 'iteration': 8, 'loss': 0.33333333333333326, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_PCA', {'features__n_components': 2}), 'normalizer': ('normalizer_StandardScaler', {'normalizer__with_mean': False, 'normalizer__with_std': True}), 'rebalance': ('rebalance_NearMiss', {'rebalance__n_neighbors': 2})}, 'score': 0.6666666666666667, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'entropy', 'max_depth': 2, 'max_features': 1, 'max_leaf_nodes': 5, 'min_samples_split': 2, 'n_estimators': 100}, 'config_hash': {'algorithm': '331418a5c12cf1453876eef85e9d98fc8e54fa11', 'config': '31930b6860ed406d59bf7e59ba1925d94704bd3b', 'pipeline': '054bef356f90ec6f644ef3ffc688766744db51c2'}, 'duration': 1.0501940250396729, 'iteration': 9, 'loss': 0.053333333333333344, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_SelectKBest', {'features__k': 1}), 'normalizer': ('normalizer_RobustScaler', {'normalizer__quantile_range': (...), 'normalizer__with_centering': True, 'normalizer__with_scaling': True}), 'rebalance': ('rebalance_NearMiss', {'rebalance__n_neighbors': 2})}, 'score': 0.9466666666666667, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'entropy', 'max_depth': 3, 'max_features': None, 'max_leaf_nodes': 3, 'min_samples_split': 2, 'n_estimators': 100}, 'config_hash': {'algorithm': 'dbc1b8126649fe93dce5fbb37e4015b0acfb179e', 'config': '9913cd550615a9d0946ab4a755a8b9f619e442fd', 'pipeline': 'dd626121cea079ebb32e184ca65483ec7a6d7f59'}, 'duration': 1.120617151260376, 'iteration': 10, 'loss': 0.046666666666666634, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 2, 'features__selectkbest__k': 1}), 'normalizer': ('normalizer_MinMaxScaler', {}), 'rebalance': ('rebalance_NoneType', {})}, 'score': 0.9533333333333334, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'gini', 'max_depth': 3, 'max_features': 3, 'max_leaf_nodes': None, 'min_samples_split': 3, 'n_estimators': 75}, 'config_hash': {'algorithm': '34917a130df5a975f78bd7ec1a0c7b1ffdc787a9', 'config': '95fc8cadc088141290b7de9c388977e4685f0108', 'pipeline': '550d10faf2f08db48516cc3501558816d6a99bc0'}, 'duration': 1.4287099838256836, 'iteration': 11, 'loss': 0.19333333333333313, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 3, 'features__selectkbest__k': 4}), 'normalizer': ('normalizer_StandardScaler', {'normalizer__with_mean': False, 'normalizer__with_std': False}), 'rebalance': ('rebalance_CondensedNearestNeighbour', {'rebalance__n_neighbors': 1})}, 'score': 0.8066666666666669, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'entropy', 'max_depth': 1, 'max_features': 2, 'max_leaf_nodes': 5, 'min_samples_split': 2, 'n_estimators': 75}, 'config_hash': {'algorithm': '33f9abb4aee44a395a9f3b3ffa9ce80a8cdaed7c', 'config': '40fa726f0360cf6af55f9b5902d399d02f61f157', 'pipeline': 'cfd1d20841fe2153da762c95e79f95a3fb1e426a'}, 'duration': 1.2978079319000244, 'iteration': 12, 'loss': 0.053333333333333344, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_PCA', {'features__n_components': 4}), 'normalizer': ('normalizer_MinMaxScaler', {}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 7})}, 'score': 0.9466666666666667, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'entropy', 'max_depth': 4, 'max_features': 2, 'max_leaf_nodes': 5, 'min_samples_split': 3, 'n_estimators': 25}, 'config_hash': {'algorithm': '210111ec6562d09eb093e98ed69ef1c662e11a50', 'config': '0fb8e77c7bd9a58b72f1b33c21a59a09a8c676ba', 'pipeline': '5d269d759e0c7926a685a14b263ace8ae0071e4b'}, 'duration': 0.36649012565612793, 'iteration': 13, 'loss': 0.040000000000000036, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 2, 'features__selectkbest__k': 2}), 'normalizer': ('normalizer_NoneType', {}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 7})}, 'score': 0.96, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'entropy', 'max_depth': 3, 'max_features': 1, 'max_leaf_nodes': 5, 'min_samples_split': 2, 'n_estimators': 25}, 'config_hash': {'algorithm': '0e989a03980101fabf79eda3326ed2870e11d690', 'config': 'f4bffd5d8c67a9c5321a9943c4a99678f59a02b7', 'pipeline': '865ee1e3fe8334c3d5ecb2038d5a5d1b3ba50e75'}, 'duration': 0.35639500617980957, 'iteration': 14, 'loss': 0.046666666666666634, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_NoneType', {}), 'normalizer': ('normalizer_RobustScaler', {'normalizer__quantile_range': (...), 'normalizer__with_centering': True, 'normalizer__with_scaling': False}), 'rebalance': ('rebalance_NoneType', {})}, 'score': 0.9533333333333334, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'entropy', 'max_depth': None, 'max_features': 3, 'max_leaf_nodes': 3, 'min_samples_split': 5, 'n_estimators': 10}, 'config_hash': {'algorithm': '9c592e876c13de5e23e6de5b868e01755d63e72e', 'config': '1e6a68cd1eeac886d90724d78b1cb5fb76a3cde4', 'pipeline': '5a1ca4d82f21b7de0d2c918630a42510673fa36e'}, 'duration': 0.18141412734985352, 'iteration': 15, 'loss': 0.046666666666666634, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_SelectKBest', {'features__k': 3}), 'normalizer': ('normalizer_RobustScaler', {'normalizer__quantile_range': (...), 'normalizer__with_centering': True, 'normalizer__with_scaling': True}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 6})}, 'score': 0.9533333333333334, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': 1, 'max_features': None, 'max_leaf_nodes': None, 'min_samples_split': 5, 'n_estimators': 10}, 'config_hash': {'algorithm': '8bed77aef289bfd453b2858bd288ae5ba7160f2b', 'config': '781185bcb8999045de8d489f253a1a1ba4247932', 'pipeline': '1ece7eabedc2be9e5b0a1be65c570d08ffa3eb54'}, 'duration': 0.1636829376220703, 'iteration': 16, 'loss': 0.053333333333333344, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_NoneType', {}), 'normalizer': ('normalizer_NoneType', {}), 'rebalance': ('rebalance_NearMiss', {'rebalance__n_neighbors': 1})}, 'score': 0.9466666666666667, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'gini', 'max_depth': 3, 'max_features': 2, 'max_leaf_nodes': 2, 'min_samples_split': 5, 'n_estimators': 75}, 'config_hash': {'algorithm': '617b97d9ba21d3373bc51ffa9cccf9c6f91a77b3', 'config': '99fb425b4e8c5d80228cab94202252aa25cdf77c', 'pipeline': 'd6242929c3b515c7719e60423023ac604311afc3'}, 'duration': 0.8468999862670898, 'iteration': 17, 'loss': 0.24, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_PCA', {'features__n_components': 4}), 'normalizer': ('normalizer_PowerTransformer', {}), 'rebalance': ('rebalance_NearMiss', {'rebalance__n_neighbors': 2})}, 'score': 0.76, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': 1, 'max_features': 1, 'max_leaf_nodes': 2, 'min_samples_split': 5, 'n_estimators': 50}, 'config_hash': {'algorithm': 'b92d2697cdd4979da443369d6596229ec091626a', 'config': 'c513a3e13281206ad76187dd817b1fff93d54fe1', 'pipeline': 'c4b4f914a3ca8df967cade997a90366d85a371b9'}, 'duration': 0.6724588871002197, 'iteration': 18, 'loss': 0.23333333333333328, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 1, 'features__selectkbest__k': 3}), 'normalizer': ('normalizer_StandardScaler', {'normalizer__with_mean': True, 'normalizer__with_std': True}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 5})}, 'score': 0.7666666666666667, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'entropy', 'max_depth': None, 'max_features': None, 'max_leaf_nodes': 5, 'min_samples_split': 5, 'n_estimators': 10}, 'config_hash': {'algorithm': 'a0115de695e6cca2e81cbfb54df79bf4b43608b1', 'config': 'ba194015e20b5d67770e8c67342c3d8d0d01dc41', 'pipeline': '8d45fabfeb85ffdcabf7076bd0e65fffe97ce928'}, 'duration': 0.19424200057983398, 'iteration': 19, 'loss': 0.08666666666666667, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_PCA', {'features__n_components': 3}), 'normalizer': ('normalizer_NoneType', {}), 'rebalance': ('rebalance_NoneType', {})}, 'score': 0.9133333333333333, ...}, ...], 'history_hash': ['db6ac7e6d348155757e4794bb5f88fe2b4f63d50', '4db6fb84d85f52659f780e682ffac5712c3d8a94', '4403c5a85e951938d3c454e961d3a412780722f6', 'a064e2df18ab98d44dabcefbc7bed94913f1d0be', '0ddb6f5cab3db4dddd7682966a57205f3e329ad4', '49f25751bca61cdd461a8cbd2923689b642f98ed', '5c3a2b6f5e63fb45f10e41e0318b354912ec44f6', 'd3b129b397350f1b6572651c67c01de49b4b174c', '813bde1108cc3c4b9bfb3a22cbb421bda7eac671', '31930b6860ed406d59bf7e59ba1925d94704bd3b', '9913cd550615a9d0946ab4a755a8b9f619e442fd', '95fc8cadc088141290b7de9c388977e4685f0108', '40fa726f0360cf6af55f9b5902d399d02f61f157', '0fb8e77c7bd9a58b72f1b33c21a59a09a8c676ba', 'f4bffd5d8c67a9c5321a9943c4a99678f59a02b7', '1e6a68cd1eeac886d90724d78b1cb5fb76a3cde4', '781185bcb8999045de8d489f253a1a1ba4247932', '99fb425b4e8c5d80228cab94202252aa25cdf77c', 'c513a3e13281206ad76187dd817b1fff93d54fe1', 'ba194015e20b5d67770e8c67342c3d8d0d01dc41', ...], 'history_index': {'013329309d510b94f19d930320402d65f953a847': 39, '038a0f515e2ec894ee8e34f9caa2889eb3ebd5ce': 66, '052ae4bf232b316187b078abae42c2be19e16a00': 111, '0659afebf316aafeb75612fb07081a04c28545ed': 74, '06e7cde9f3556cd01332ce389ad1d8925cd4b4a4': 120, '08606f2a0f0a6c9de204020b4632e09fcee0ae56': 168, '0a05b5b0a70971a5e347aaab7a4d4a07a92222fd': 191, '0b6551ecfd6f83a15704a9db68f1599c99c6d3ef': 58, '0cfb4698cbf2d986bcd5e0c2ef0f974da60b205e': 194, '0ddb6f5cab3db4dddd7682966a57205f3e329ad4': 4, ...}, 'iteration': 204, 'max_history_score': 0.9666666666666668, 'max_history_score_std': 0.033333333333333326, 'max_history_step': 'joint'}, config={'algorithm': 'RandomForest', 'seed': 42, 'time': 300}, step='joint')
     45                 y,
     46                 cv=10,
     47                 n_jobs=-1,
     48                 return_estimator=False,
     49                 return_train_score=False,
---> 50                 verbose=0)
     51         score = np.mean(scores['test_score'])
     52         std = np.std(scores['test_score'])
     53         status = STATUS_OK
     54     except Exception as e:

...........................................................................
/home/aquemy/.local/lib/python2.7/site-packages/sklearn/model_selection/_validation.py in cross_validate(estimator=Pipeline(memory=None,
     steps=[('rebalance', ... random_state=42, verbose=0, warm_start=False))]), X=array([[5.1, 3.5, 1.4, 0.2],
       [4.9, 3. , 1....2, 3.4, 5.4, 2.3],
       [5.9, 3. , 5.1, 1.8]]), y=array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,... 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]), groups=None, scoring=None, cv=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1, verbose=0, fit_params=None, pre_dispatch='2*n_jobs', return_train_score=False, return_estimator=False, error_score='raise-deprecating')
    235         delayed(_fit_and_score)(
    236             clone(estimator), X, y, scorers, train, test, verbose, None,
    237             fit_params, return_train_score=return_train_score,
    238             return_times=True, return_estimator=return_estimator,
    239             error_score=error_score)
--> 240         for train, test in cv.split(X, y, groups))
        cv.split = <bound method StratifiedKFold.split of Stratifie...d(n_splits=10, random_state=None, shuffle=False)>
        X = array([[5.1, 3.5, 1.4, 0.2],
       [4.9, 3. , 1....2, 3.4, 5.4, 2.3],
       [5.9, 3. , 5.1, 1.8]])
        y = array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,... 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2])
        groups = None
    241 
    242     zipped_scores = list(zip(*scores))
    243     if return_train_score:
    244         train_scores = zipped_scores.pop(0)

...........................................................................
/home/aquemy/.local/lib/python2.7/site-packages/sklearn/externals/joblib/parallel.py in __call__(self=Parallel(n_jobs=-1), iterable=<generator object <genexpr>>)
    925                 # No need to wait for async callbacks to trigger to
    926                 # consumption.
    927                 self._iterating = False
    928 
    929             with self._backend.retrieval_context():
--> 930                 self.retrieve()
        self.retrieve = <bound method Parallel.retrieve of Parallel(n_jobs=-1)>
    931             # Make sure that we get a last message telling us we are done
    932             elapsed_time = time.time() - self._start_time
    933             self._print('Done %3i out of %3i | elapsed: %s finished',
    934                         (len(self._output), len(self._output),

---------------------------------------------------------------------------
Joblib worker traceback:
---------------------------------------------------------------------------
ValueError                                         Mon Jun 17 13:13:22 2019
PID: 21309                                  Python 2.7.15+: /usr/bin/python
...........................................................................
/home/aquemy/.local/lib/python2.7/site-packages/sklearn/externals/joblib/parallel.py in __call__(self=<sklearn.externals.joblib.parallel.BatchedCalls object>)
    220     def __call__(self):
    221         # Set the default nested backend to self._backend but do not set the
    222         # change the default number of processes to -1
    223         with parallel_backend(self._backend, n_jobs=self._n_jobs):
    224             return [func(*args, **kwargs)
--> 225                     for func, args, kwargs in self.items]
        func = <function _fit_and_score>
        args = (Pipeline(memory=None,
     steps=[('rebalance', ... random_state=42, verbose=0, warm_start=False))]), array([[5.1, 3.5, 1.4, 0.2],
       [4.9, 3. , 1....2, 3.4, 5.4, 2.3],
       [5.9, 3. , 5.1, 1.8]]), array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,... 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]), {'score': <function _passthrough_scorer>}, array([  5,   6,   7,   8,   9,  10,  11,  12,  ..., 142, 143, 144,
       145, 146, 147, 148, 149]), array([  0,   1,   2,   3,   4,  50,  51,  52,  53,  54, 100, 101, 102,
       103, 104]), 0, None, None)
        kwargs = {'error_score': 'raise-deprecating', 'return_estimator': False, 'return_times': True, 'return_train_score': False}
        self.items = [(<function _fit_and_score>, (Pipeline(memory=None,
     steps=[('rebalance', ... random_state=42, verbose=0, warm_start=False))]), array([[5.1, 3.5, 1.4, 0.2],
       [4.9, 3. , 1....2, 3.4, 5.4, 2.3],
       [5.9, 3. , 5.1, 1.8]]), array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,... 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]), {'score': <function _passthrough_scorer>}, array([  5,   6,   7,   8,   9,  10,  11,  12,  ..., 142, 143, 144,
       145, 146, 147, 148, 149]), array([  0,   1,   2,   3,   4,  50,  51,  52,  53,  54, 100, 101, 102,
       103, 104]), 0, None, None), {'error_score': 'raise-deprecating', 'return_estimator': False, 'return_times': True, 'return_train_score': False})]
    226 
    227     def __len__(self):
    228         return self._size
    229 

...........................................................................
/home/aquemy/.local/lib/python2.7/site-packages/sklearn/model_selection/_validation.py in _fit_and_score(estimator=Pipeline(memory=None,
     steps=[('rebalance', ... random_state=42, verbose=0, warm_start=False))]), X=array([[5.1, 3.5, 1.4, 0.2],
       [4.9, 3. , 1....2, 3.4, 5.4, 2.3],
       [5.9, 3. , 5.1, 1.8]]), y=array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,... 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]), scorer={'score': <function _passthrough_scorer>}, train=array([  5,   6,   7,   8,   9,  10,  11,  12,  ..., 142, 143, 144,
       145, 146, 147, 148, 149]), test=array([  0,   1,   2,   3,   4,  50,  51,  52,  53,  54, 100, 101, 102,
       103, 104]), verbose=0, parameters=None, fit_params={}, return_train_score=False, return_parameters=False, return_n_test_samples=False, return_times=True, return_estimator=False, error_score='raise-deprecating')
    523 
    524     try:
    525         if y_train is None:
    526             estimator.fit(X_train, **fit_params)
    527         else:
--> 528             estimator.fit(X_train, y_train, **fit_params)
        estimator.fit = <bound method Pipeline.fit of Pipeline(memory=No...random_state=42, verbose=0, warm_start=False))])>
        X_train = array([[5.4, 3.9, 1.7, 0.4],
       [4.6, 3.4, 1....2, 3.4, 5.4, 2.3],
       [5.9, 3. , 5.1, 1.8]])
        y_train = array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,
       2, 2, 2])
        fit_params = {}
    529 
    530     except Exception as e:
    531         # Note fit time as time until error
    532         fit_time = time.time() - start_time

...........................................................................
/usr/local/lib/python2.7/dist-packages/imblearn/pipeline.py in fit(self=Pipeline(memory=None,
     steps=[('rebalance', ... random_state=42, verbose=0, warm_start=False))]), X=array([[5.4, 3.9, 1.7, 0.4],
       [4.6, 3.4, 1....2, 3.4, 5.4, 2.3],
       [5.9, 3. , 5.1, 1.8]]), y=array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,
       2, 2, 2]), **fit_params={})
    234             This estimator
    235 
    236         """
    237         Xt, yt, fit_params = self._fit(X, y, **fit_params)
    238         if self._final_estimator is not None:
--> 239             self._final_estimator.fit(Xt, yt, **fit_params)
        self._final_estimator.fit = <bound method RandomForestClassifier.fit of Rand...e, random_state=42, verbose=0, warm_start=False)>
        Xt = array([[ 1.86139763],
       [-0.62290846],
    ...53],
       [ 1.86314038],
       [ 3.9988138 ]])
        yt = array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
       0, 1, 2])
        fit_params = {}
    240         return self
    241 
    242     def fit_transform(self, X, y=None, **fit_params):
    243         """Fit the model and transform with the final estimator

...........................................................................
/home/aquemy/.local/lib/python2.7/site-packages/sklearn/ensemble/forest.py in fit(self=RandomForestClassifier(bootstrap=True, class_wei...se, random_state=42, verbose=0, warm_start=False), X=array([[ 1.8613976 ],
       [-0.6229085 ],
    ....8631403 ],
       [ 3.9988139 ]], dtype=float32), y=array([[0.],
       [0.],
       [0.],
       [0...    [0.],
       [0.],
       [1.],
       [2.]]), sample_weight=None)
    328             trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,
    329                              **_joblib_parallel_args(prefer='threads'))(
    330                 delayed(_parallel_build_trees)(
    331                     t, self, X, y, sample_weight, i, len(trees),
    332                     verbose=self.verbose, class_weight=self.class_weight)
--> 333                 for i, t in enumerate(trees))
        i = 9
    334 
    335             # Collect newly grown trees
    336             self.estimators_.extend(trees)
    337 

...........................................................................
/home/aquemy/.local/lib/python2.7/site-packages/sklearn/externals/joblib/parallel.py in __call__(self=Parallel(n_jobs=1), iterable=<generator object <genexpr>>)
    912             # self._original_iterator is None, then this means either
    913             # that pre_dispatch == "all", n_jobs == 1 or that the first batch
    914             # was very quick and its callback already dispatched all the
    915             # remaining jobs.
    916             self._iterating = False
--> 917             if self.dispatch_one_batch(iterator):
        self.dispatch_one_batch = <bound method Parallel.dispatch_one_batch of Parallel(n_jobs=1)>
        iterator = <generator object <genexpr>>
    918                 self._iterating = self._original_iterator is not None
    919 
    920             while self.dispatch_one_batch(iterator):
    921                 pass

...........................................................................
/home/aquemy/.local/lib/python2.7/site-packages/sklearn/externals/joblib/parallel.py in dispatch_one_batch(self=Parallel(n_jobs=1), iterator=<generator object <genexpr>>)
    754                                  self._pickle_cache)
    755             if len(tasks) == 0:
    756                 # No more tasks available in the iterator: tell caller to stop.
    757                 return False
    758             else:
--> 759                 self._dispatch(tasks)
        self._dispatch = <bound method Parallel._dispatch of Parallel(n_jobs=1)>
        tasks = <sklearn.externals.joblib.parallel.BatchedCalls object>
    760                 return True
    761 
    762     def _print(self, msg, msg_args):
    763         """Display the message on stout or stderr depending on verbosity"""

...........................................................................
/home/aquemy/.local/lib/python2.7/site-packages/sklearn/externals/joblib/parallel.py in _dispatch(self=Parallel(n_jobs=1), batch=<sklearn.externals.joblib.parallel.BatchedCalls object>)
    711 
    712         dispatch_timestamp = time.time()
    713         cb = BatchCompletionCallBack(dispatch_timestamp, len(batch), self)
    714         with self._lock:
    715             job_idx = len(self._jobs)
--> 716             job = self._backend.apply_async(batch, callback=cb)
        job = undefined
        self._backend.apply_async = <bound method SequentialBackend.apply_async of <...lib._parallel_backends.SequentialBackend object>>
        batch = <sklearn.externals.joblib.parallel.BatchedCalls object>
        cb = <sklearn.externals.joblib.parallel.BatchCompletionCallBack object>
    717             # A job can complete so quickly than its callback is
    718             # called before we get here, causing self._jobs to
    719             # grow. To ensure correct results ordering, .insert is
    720             # used (rather than .append) in the following line

...........................................................................
/home/aquemy/.local/lib/python2.7/site-packages/sklearn/externals/joblib/_parallel_backends.py in apply_async(self=<sklearn.externals.joblib._parallel_backends.SequentialBackend object>, func=<sklearn.externals.joblib.parallel.BatchedCalls object>, callback=<sklearn.externals.joblib.parallel.BatchCompletionCallBack object>)
    177             raise ValueError('n_jobs == 0 in Parallel has no meaning')
    178         return 1
    179 
    180     def apply_async(self, func, callback=None):
    181         """Schedule a func to be run"""
--> 182         result = ImmediateResult(func)
        result = undefined
        func = <sklearn.externals.joblib.parallel.BatchedCalls object>
    183         if callback:
    184             callback(result)
    185         return result
    186 

...........................................................................
/home/aquemy/.local/lib/python2.7/site-packages/sklearn/externals/joblib/_parallel_backends.py in __init__(self=<sklearn.externals.joblib._parallel_backends.ImmediateResult object>, batch=<sklearn.externals.joblib.parallel.BatchedCalls object>)
    544 
    545 class ImmediateResult(object):
    546     def __init__(self, batch):
    547         # Don't delay the application, to avoid keeping the input
    548         # arguments in memory
--> 549         self.results = batch()
        self.results = undefined
        batch = <sklearn.externals.joblib.parallel.BatchedCalls object>
    550 
    551     def get(self):
    552         return self.results
    553 

...........................................................................
/home/aquemy/.local/lib/python2.7/site-packages/sklearn/externals/joblib/parallel.py in __call__(self=<sklearn.externals.joblib.parallel.BatchedCalls object>)
    220     def __call__(self):
    221         # Set the default nested backend to self._backend but do not set the
    222         # change the default number of processes to -1
    223         with parallel_backend(self._backend, n_jobs=self._n_jobs):
    224             return [func(*args, **kwargs)
--> 225                     for func, args, kwargs in self.items]
        func = <function _parallel_build_trees>
        args = (DecisionTreeClassifier(class_weight=None, criter...=False, random_state=1608637542, splitter='best'), RandomForestClassifier(bootstrap=True, class_wei...se, random_state=42, verbose=0, warm_start=False), array([[ 1.8613976 ],
       [-0.6229085 ],
    ....8631403 ],
       [ 3.9988139 ]], dtype=float32), array([[0.],
       [0.],
       [0.],
       [0...    [0.],
       [0.],
       [1.],
       [2.]]), None, 0, 10)
        kwargs = {'class_weight': None, 'verbose': 0}
        self.items = [(<function _parallel_build_trees>, (DecisionTreeClassifier(class_weight=None, criter...=False, random_state=1608637542, splitter='best'), RandomForestClassifier(bootstrap=True, class_wei...se, random_state=42, verbose=0, warm_start=False), array([[ 1.8613976 ],
       [-0.6229085 ],
    ....8631403 ],
       [ 3.9988139 ]], dtype=float32), array([[0.],
       [0.],
       [0.],
       [0...    [0.],
       [0.],
       [1.],
       [2.]]), None, 0, 10), {'class_weight': None, 'verbose': 0})]
    226 
    227     def __len__(self):
    228         return self._size
    229 

...........................................................................
/home/aquemy/.local/lib/python2.7/site-packages/sklearn/ensemble/forest.py in _parallel_build_trees(tree=DecisionTreeClassifier(class_weight=None, criter...=False, random_state=1608637542, splitter='best'), forest=RandomForestClassifier(bootstrap=True, class_wei...se, random_state=42, verbose=0, warm_start=False), X=array([[ 1.8613976 ],
       [-0.6229085 ],
    ....8631403 ],
       [ 3.9988139 ]], dtype=float32), y=array([[0.],
       [0.],
       [0.],
       [0...    [0.],
       [0.],
       [1.],
       [2.]]), sample_weight=None, tree_idx=0, n_trees=10, verbose=0, class_weight=None)
    114                 simplefilter('ignore', DeprecationWarning)
    115                 curr_sample_weight *= compute_sample_weight('auto', y, indices)
    116         elif class_weight == 'balanced_subsample':
    117             curr_sample_weight *= compute_sample_weight('balanced', y, indices)
    118 
--> 119         tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)
        tree.fit = <bound method DecisionTreeClassifier.fit of Deci...False, random_state=1608637542, splitter='best')>
        X = array([[ 1.8613976 ],
       [-0.6229085 ],
    ....8631403 ],
       [ 3.9988139 ]], dtype=float32)
        y = array([[0.],
       [0.],
       [0.],
       [0...    [0.],
       [0.],
       [1.],
       [2.]])
        sample_weight = None
        curr_sample_weight = array([2., 0., 2., 1., 2., 0., 1., 2., 1., 1., 2... 0., 0., 0., 0., 2., 0., 5., 0., 2., 0., 0., 1.])
    120     else:
    121         tree.fit(X, y, sample_weight=sample_weight, check_input=False)
    122 
    123     return tree

...........................................................................
/home/aquemy/.local/lib/python2.7/site-packages/sklearn/tree/tree.py in fit(self=DecisionTreeClassifier(class_weight=None, criter...=False, random_state=1608637542, splitter='best'), X=array([[ 1.8613976 ],
       [-0.6229085 ],
    ....8631403 ],
       [ 3.9988139 ]], dtype=float32), y=array([[0.],
       [0.],
       [0.],
       [0...    [0.],
       [0.],
       [1.],
       [2.]]), sample_weight=array([2., 0., 2., 1., 2., 0., 1., 2., 1., 1., 2... 0., 0., 0., 0., 2., 0., 5., 0., 2., 0., 0., 1.]), check_input=False, X_idx_sorted=None)
    796 
    797         super(DecisionTreeClassifier, self).fit(
    798             X, y,
    799             sample_weight=sample_weight,
    800             check_input=check_input,
--> 801             X_idx_sorted=X_idx_sorted)
        X_idx_sorted = None
    802         return self
    803 
    804     def predict_proba(self, X, check_input=True):
    805         """Predict class probabilities of the input samples X.

...........................................................................
/home/aquemy/.local/lib/python2.7/site-packages/sklearn/tree/tree.py in fit(self=DecisionTreeClassifier(class_weight=None, criter...=False, random_state=1608637542, splitter='best'), X=array([[ 1.8613976 ],
       [-0.6229085 ],
    ....8631403 ],
       [ 3.9988139 ]], dtype=float32), y=array([[0.],
       [0.],
       [0.],
       [0...    [0.],
       [0.],
       [1.],
       [2.]]), sample_weight=array([2., 0., 2., 1., 2., 0., 1., 2., 1., 1., 2... 0., 0., 0., 0., 2., 0., 5., 0., 2., 0., 0., 1.]), check_input=False, X_idx_sorted=None)
    237         if not 0 <= self.min_weight_fraction_leaf <= 0.5:
    238             raise ValueError("min_weight_fraction_leaf must in [0, 0.5]")
    239         if max_depth <= 0:
    240             raise ValueError("max_depth must be greater than zero. ")
    241         if not (0 < max_features <= self.n_features_):
--> 242             raise ValueError("max_features must be in (0, n_features]")
    243         if not isinstance(max_leaf_nodes, (numbers.Integral, np.integer)):
    244             raise ValueError("max_leaf_nodes must be integral number but was "
    245                              "%r" % max_leaf_nodes)
    246         if -1 < max_leaf_nodes < 2:

ValueError: max_features must be in (0, n_features]
___________________________________________________________________________
Best score: 0.966666666667 (0.0333333333333) [J] | Score: 0.0 (0.0) [J]
Best score: 0.966666666667 (0.0333333333333) [J] | Score: 0.866666666667 (0.0666666666667) [J]
Best score: 0.966666666667 (0.0333333333333) [J] | Score: 0.666666666667 (1.11022302463e-16) [J]
Best score: 0.966666666667 (0.0333333333333) [J] | Score: 0.866666666667 (0.0666666666667) [J]
Best score: 0.966666666667 (0.0333333333333) [J] | Score: 0.96 (0.0442216638714) [J]
Best score: 0.966666666667 (0.0333333333333) [J] | Score: 0.966666666667 (0.04472135955) [J]
Best score: 0.966666666667 (0.0333333333333) [J] | Score: 0.906666666667 (0.0533333333333) [J]
Best score: 0.966666666667 (0.0333333333333) [J] | Score: 0.953333333333 (0.0520683311727) [J]
Best score: 0.966666666667 (0.0333333333333) [J] | Score: 0.953333333333 (0.0520683311727) [J]
Best score: 0.966666666667 (0.0333333333333) [J] | Score: 0.666666666667 (1.11022302463e-16) [J]
Best score: 0.966666666667 (0.0333333333333) [J] | Score: 0.933333333333 (0.0596284794) [J]
Best score: 0.966666666667 (0.0333333333333) [J] | Score: 0.873333333333 (0.0963788819653) [J]
Best score: 0.966666666667 (0.0333333333333) [J] | Score: 0.686666666667 (0.0426874949162) [J]
Best score: 0.966666666667 (0.0333333333333) [J] | Score: 0.953333333333 (0.0520683311727) [J]
Best score: 0.966666666667 (0.0333333333333) [J] | Score: 0.933333333333 (0.0666666666667) [J]
Best score: 0.966666666667 (0.0333333333333) [J] | Score: 0.953333333333 (0.0520683311727) [J]
Best score: 0.966666666667 (0.0333333333333) [J] | Score: 0.926666666667 (0.075718777944) [J]
JoblibValueError
___________________________________________________________________________
...........................................................................
/home/aquemy/dev/dp_hyperparameters/extension/main.py in <module>()
     27 
     28     serializer.serialize_results(scenario, policy)
     29 
     30 if __name__ == "__main__":
     31     args = cli.parse_args()
---> 32     main(args)

...........................................................................
/home/aquemy/dev/dp_hyperparameters/extension/main.py in main(args=Namespace(customize=[(['control', 'seed'], '42')...io='./scenarios/rf_iris_joint.yaml', verbosity=0))
     21         test_size=0.4, 
     22         random_state=scenario['control']['seed']
     23     )
     24 
     25     policy = policies.initiate(scenario['setup']['policy'], config)
---> 26     policy.run(X,y)
        policy.run = <bound method Joint.run of <experiment.policies.joint.Joint object>>
        X = array([[5.1, 3.5, 1.4, 0.2],
       [4.9, 3. , 1....2, 3.4, 5.4, 2.3],
       [5.9, 3. , 5.1, 1.8]])
        y = array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,... 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2])
     27 
     28     serializer.serialize_results(scenario, policy)
     29 
     30 if __name__ == "__main__":

...........................................................................
/home/aquemy/dev/dp_hyperparameters/extension/experiment/policies/joint.py in run(self=<experiment.policies.joint.Joint object>, X=array([[5.1, 3.5, 1.4, 0.2],
       [4.9, 3. , 1....2, 3.4, 5.4, 2.3],
       [5.9, 3. , 5.1, 1.8]]), y=array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,... 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]))
     32             algo=tpe.suggest, 
     33             max_evals=None,
     34             max_time=self.config['time'],     
     35             trials=trials,
     36             show_progressbar=False,
---> 37             verbose=0
     38         )
     39 
     40         best_config = self.context['best_config']
     41         super(Joint, self).display_step_results(best_config)

...........................................................................
/home/aquemy/dev/dp_hyperparameters/extension/hyperopt/fmin.py in fmin(fn=<functools.partial object>, space={'algorithm': {'bootstrap': <hyperopt.pyll.base.Apply object>, 'criterion': <hyperopt.pyll.base.Apply object>, 'max_depth': <hyperopt.pyll.base.Apply object>, 'max_features': <hyperopt.pyll.base.Apply object>, 'max_leaf_nodes': <hyperopt.pyll.base.Apply object>, 'min_samples_split': <hyperopt.pyll.base.Apply object>, 'n_estimators': <hyperopt.pyll.base.Apply object>}, 'pipeline': {'features': <hyperopt.pyll.base.Apply object>, 'normalizer': <hyperopt.pyll.base.Apply object>, 'rebalance': <hyperopt.pyll.base.Apply object>}}, algo=<function suggest>, max_evals=9223372036854775807, max_time=300, trials=<hyperopt.base.Trials object>, rstate=<mtrand.RandomState object>, allow_trials_fmin=True, pass_expr_memo_ctrl=None, catch_eval_exceptions=False, verbose=0, return_argmin=True, points_to_evaluate=None, max_queue_len=1, show_progressbar=False)
    406             pass_expr_memo_ctrl=pass_expr_memo_ctrl,
    407             verbose=verbose,
    408             catch_eval_exceptions=catch_eval_exceptions,
    409             return_argmin=return_argmin,
    410             show_progressbar=show_progressbar,
--> 411             max_time=max_time
        max_time = 300
    412         )
    413 
    414     if trials is None:
    415         if points_to_evaluate is None:

...........................................................................
/home/aquemy/dev/dp_hyperparameters/extension/hyperopt/base.py in fmin(self=<hyperopt.base.Trials object>, fn=<functools.partial object>, space={'algorithm': {'bootstrap': <hyperopt.pyll.base.Apply object>, 'criterion': <hyperopt.pyll.base.Apply object>, 'max_depth': <hyperopt.pyll.base.Apply object>, 'max_features': <hyperopt.pyll.base.Apply object>, 'max_leaf_nodes': <hyperopt.pyll.base.Apply object>, 'min_samples_split': <hyperopt.pyll.base.Apply object>, 'n_estimators': <hyperopt.pyll.base.Apply object>}, 'pipeline': {'features': <hyperopt.pyll.base.Apply object>, 'normalizer': <hyperopt.pyll.base.Apply object>, 'rebalance': <hyperopt.pyll.base.Apply object>}}, algo=<function suggest>, max_evals=9223372036854775807, max_time=300, rstate=<mtrand.RandomState object>, verbose=0, pass_expr_memo_ctrl=None, catch_eval_exceptions=False, return_argmin=True, show_progressbar=False)
    636             verbose=verbose,
    637             allow_trials_fmin=False,  # -- prevent recursion
    638             pass_expr_memo_ctrl=pass_expr_memo_ctrl,
    639             catch_eval_exceptions=catch_eval_exceptions,
    640             return_argmin=return_argmin,
--> 641             show_progressbar=show_progressbar)
        show_progressbar = False
    642 
    643 
    644 def trials_from_docs(docs, validate=True, **kwargs):
    645     """Construct a Trials base class instance from a list of trials documents

...........................................................................
/home/aquemy/dev/dp_hyperparameters/extension/hyperopt/fmin.py in fmin(fn=<functools.partial object>, space={'algorithm': {'bootstrap': <hyperopt.pyll.base.Apply object>, 'criterion': <hyperopt.pyll.base.Apply object>, 'max_depth': <hyperopt.pyll.base.Apply object>, 'max_features': <hyperopt.pyll.base.Apply object>, 'max_leaf_nodes': <hyperopt.pyll.base.Apply object>, 'min_samples_split': <hyperopt.pyll.base.Apply object>, 'n_estimators': <hyperopt.pyll.base.Apply object>}, 'pipeline': {'features': <hyperopt.pyll.base.Apply object>, 'normalizer': <hyperopt.pyll.base.Apply object>, 'rebalance': <hyperopt.pyll.base.Apply object>}}, algo=<function suggest>, max_evals=9223372036854775807, max_time=300, trials=<hyperopt.base.Trials object>, rstate=<mtrand.RandomState object>, allow_trials_fmin=False, pass_expr_memo_ctrl=None, catch_eval_exceptions=False, verbose=0, return_argmin=True, points_to_evaluate=None, max_queue_len=1, show_progressbar=False)
    426                     verbose=verbose,
    427                     max_queue_len=max_queue_len,
    428                     show_progressbar=show_progressbar,
    429                     max_time=max_time)
    430     rval.catch_eval_exceptions = catch_eval_exceptions
--> 431     rval.exhaust()
        rval.exhaust = <bound method FMinIter.exhaust of <hyperopt.fmin.FMinIter object>>
    432     if return_argmin:
    433         return trials.argmin
    434     elif len(trials) > 0:
    435         # Only if there are some succesfull trail runs, return the best point in the evaluation space

...........................................................................
/home/aquemy/dev/dp_hyperparameters/extension/hyperopt/fmin.py in exhaust(self=<hyperopt.fmin.FMinIter object>)
    273             raise StopIteration()
    274         return self.trials
    275 
    276     def exhaust(self):
    277         n_done = len(self.trials)
--> 278         self.run(self.max_evals - n_done, block_until_done=self.asynchronous)
        self.run = <bound method FMinIter.run of <hyperopt.fmin.FMinIter object>>
        self.max_evals = 9223372036854775807
        n_done = 0
        self.asynchronous = False
    279         self.trials.refresh()
    280         return self
    281 
    282 

...........................................................................
/home/aquemy/dev/dp_hyperparameters/extension/hyperopt/fmin.py in run(self=<hyperopt.fmin.FMinIter object>, N=9223372036854775807, block_until_done=False)
    232                     if self.asynchronous:
    233                         # -- wait for workers to fill in the trials
    234                         time.sleep(self.poll_interval_secs)
    235                     else:
    236                         # -- loop over trials and do the jobs directly
--> 237                         self.serial_evaluate()
        self.serial_evaluate = <bound method FMinIter.serial_evaluate of <hyperopt.fmin.FMinIter object>>
    238                     try:
    239                         res = [d['result']['loss'] for d in
    240                                          self.trials.trials if
    241                                          d['result']['status'] == 'ok']

...........................................................................
/home/aquemy/dev/dp_hyperparameters/extension/hyperopt/fmin.py in serial_evaluate(self=<hyperopt.fmin.FMinIter object>, N=-1)
    138                 trial['book_time'] = now
    139                 trial['refresh_time'] = now
    140                 spec = base.spec_from_misc(trial['misc'])
    141                 ctrl = base.Ctrl(self.trials, current_trial=trial)
    142                 try:
--> 143                     result = self.domain.evaluate(spec, ctrl)
        result = undefined
        self.domain.evaluate = <bound method Domain.evaluate of <hyperopt.base.Domain object>>
        spec = {'bootstrap': 0, 'criterion': 0, 'features': 1, 'features_PCA_features__n_components': 0, 'max_depth': 3, 'max_features': 2, 'max_leaf_nodes': 1, 'min_samples_split': 1, 'n_estimators': 4, 'normalizer': 4, ...}
        ctrl = <hyperopt.base.Ctrl object>
    144                 except Exception as e:
    145                     logger.info('job exception: %s' % str(e))
    146                     trial['state'] = base.JOB_STATE_ERROR
    147                     trial['misc']['error'] = (str(type(e)), str(e))

...........................................................................
/home/aquemy/dev/dp_hyperparameters/extension/hyperopt/base.py in evaluate(self=<hyperopt.base.Domain object>, config={'bootstrap': 0, 'criterion': 0, 'features': 1, 'features_PCA_features__n_components': 0, 'max_depth': 3, 'max_features': 2, 'max_leaf_nodes': 1, 'min_samples_split': 1, 'n_estimators': 4, 'normalizer': 4, ...}, ctrl=<hyperopt.base.Ctrl object>, attach_attachments=True)
    841             #    or the normal Python part (self.fn)
    842             pyll_rval = pyll.rec_eval(
    843                 self.expr,
    844                 memo=memo,
    845                 print_node_on_error=self.rec_eval_print_node_on_error)
--> 846             rval = self.fn(pyll_rval)
        rval = undefined
        self.fn = <functools.partial object>
        pyll_rval = {'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': 4, 'max_features': 3, 'max_leaf_nodes': 3, 'min_samples_split': 3, 'n_estimators': 100}, 'pipeline': {'features': ('features_PCA', {'features__n_components': 1}), 'normalizer': ('normalizer_RobustScaler', {'normalizer__quantile_range': (25.0, 75.0), 'normalizer__with_centering': True, 'normalizer__with_scaling': True}), 'rebalance': ('rebalance_CondensedNearestNeighbour', {'rebalance__n_neighbors': 3})}}
    847 
    848         if isinstance(rval, (float, int, np.number)):
    849             dict_rval = {'loss': float(rval), 'status': STATUS_OK}
    850         else:

...........................................................................
/home/aquemy/dev/dp_hyperparameters/extension/experiment/objective.py in objective_joint(wconfig={'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': 4, 'max_features': 3, 'max_leaf_nodes': 3, 'min_samples_split': 3, 'n_estimators': 100}, 'pipeline': {'features': ('features_PCA', {'features__n_components': 1}), 'normalizer': ('normalizer_RobustScaler', {'normalizer__quantile_range': (25.0, 75.0), 'normalizer__with_centering': True, 'normalizer__with_scaling': True}), 'rebalance': ('rebalance_CondensedNearestNeighbour', {'rebalance__n_neighbors': 3})}}, algorithm='RandomForest', X=array([[5.1, 3.5, 1.4, 0.2],
       [4.9, 3. , 1....2, 3.4, 5.4, 2.3],
       [5.9, 3. , 5.1, 1.8]]), y=array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,... 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]), context={'baseline_score': 0.9466666666666667, 'baseline_score_std': 0.04988876515698587, 'best_config': {'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': 4, 'max_features': 3, 'max_leaf_nodes': 3, 'min_samples_split': 3, 'n_estimators': 10}, 'config_hash': {'algorithm': 'ffb7ff225ce3d3712c96cf87fe42202988ee2eb0', 'config': 'bae32f426be9cd6243523c023944a8c148fe4aeb', 'pipeline': 'd2a68bfda6fcdec4ae0ffc7d7b6a2122bc1cd673'}, 'duration': 0.7115809917449951, 'iteration': 113, 'loss': 0.033333333333333215, 'max_history_score': 0.9666666666666668, 'max_history_score_std': 0.033333333333333326, 'max_history_step': 'joint', 'pipeline': {'features': ('features_NoneType', {}), 'normalizer': ('normalizer_PowerTransformer', {}), 'rebalance': ('rebalance_CondensedNearestNeighbour', {'rebalance__n_neighbors': 2})}, 'score': 0.9666666666666668, ...}, 'history': [{'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': 2, 'max_features': None, 'max_leaf_nodes': 5, 'min_samples_split': 2, 'n_estimators': 75}, 'config_hash': {'algorithm': '3af5b0cce71c8fe2545246ca24ff5bc3dd516e06', 'config': 'db6ac7e6d348155757e4794bb5f88fe2b4f63d50', 'pipeline': '8d59f4b94cef6be9306ed86a22a9570fa670d567'}, 'duration': 1.149928092956543, 'iteration': 0, 'loss': 0.046666666666666634, 'max_history_score': 0.9533333333333334, 'max_history_score_std': 0.059999999999999984, 'max_history_step': 'joint', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 4, 'features__selectkbest__k': 3}), 'normalizer': ('normalizer_StandardScaler', {'normalizer__with_mean': True, 'normalizer__with_std': True}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 6})}, 'score': 0.9533333333333334, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': 1, 'max_features': 2, 'max_leaf_nodes': 2, 'min_samples_split': 5, 'n_estimators': 100}, 'config_hash': {'algorithm': 'e13eb05fd9a62d2f63bbb1c1deff0cd620d5e6ab', 'config': '4db6fb84d85f52659f780e682ffac5712c3d8a94', 'pipeline': '64c9a1ca9d53ae67244bdd942f4db36a3c05218c'}, 'duration': 1.7678282260894775, 'iteration': 1, 'loss': 0.18000000000000005, 'max_history_score': 0.9533333333333334, 'max_history_score_std': 0.059999999999999984, 'max_history_step': 'joint', 'pipeline': {'features': ('features_NoneType', {}), 'normalizer': ('normalizer_PowerTransformer', {}), 'rebalance': ('rebalance_NearMiss', {'rebalance__n_neighbors': 1})}, 'score': 0.82, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': 1, 'max_features': None, 'max_leaf_nodes': None, 'min_samples_split': 5, 'n_estimators': 75}, 'config_hash': {'algorithm': '94b0d7a654c508cc63643f78fe4f0f07e6f07c1e', 'config': '4403c5a85e951938d3c454e961d3a412780722f6', 'pipeline': '3e47444880d8367fbac2faaba2e52a917274aa58'}, 'duration': 0.8397619724273682, 'iteration': 2, 'loss': 0.03333333333333344, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_PCA', {'features__n_components': 3}), 'normalizer': ('normalizer_MinMaxScaler', {}), 'rebalance': ('rebalance_NoneType', {})}, 'score': 0.9666666666666666, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': None, 'max_features': None, 'max_leaf_nodes': 3, 'min_samples_split': 3, 'n_estimators': 75}, 'config_hash': {'algorithm': 'e8332f0a8902bda03bf70e7978cc5d52affb29d3', 'config': 'a064e2df18ab98d44dabcefbc7bed94913f1d0be', 'pipeline': '7eea819c2a8c103c4b1e9e9c1e224aebba95081f'}, 'duration': 0.8501448631286621, 'iteration': 3, 'loss': 0.053333333333333344, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 2, 'features__selectkbest__k': 4}), 'normalizer': ('normalizer_NoneType', {}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 7})}, 'score': 0.9466666666666667, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'entropy', 'max_depth': 3, 'max_features': 3, 'max_leaf_nodes': None, 'min_samples_split': 5, 'n_estimators': 75}, 'config_hash': {'algorithm': '7a4491035bc6bd737fe9a8cda8a79a02d02d5c74', 'config': '0ddb6f5cab3db4dddd7682966a57205f3e329ad4', 'pipeline': 'a9ae03fe38334f6868cbf84cdd3d629d4bbe3fb0'}, 'duration': 1.1026010513305664, 'iteration': 4, 'loss': 0.05999999999999994, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 2, 'features__selectkbest__k': 1}), 'normalizer': ('normalizer_NoneType', {}), 'rebalance': ('rebalance_NoneType', {})}, 'score': 0.9400000000000001, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'gini', 'max_depth': 3, 'max_features': 1, 'max_leaf_nodes': 5, 'min_samples_split': 2, 'n_estimators': 25}, 'config_hash': {'algorithm': '9826d20b2d6a0f559cf7f16450ce7526f07e8434', 'config': '49f25751bca61cdd461a8cbd2923689b642f98ed', 'pipeline': '19b249664c5bf067de1fed4334a296f947ce774a'}, 'duration': 0.35647010803222656, 'iteration': 5, 'loss': 0.046666666666666634, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_NoneType', {}), 'normalizer': ('normalizer_NoneType', {}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 6})}, 'score': 0.9533333333333334, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'gini', 'max_depth': 2, 'max_features': 1, 'max_leaf_nodes': 2, 'min_samples_split': 2, 'n_estimators': 50}, 'config_hash': {'algorithm': '0a4f6fbb07e0f32c6f675489a0fc82eee05bd8e1', 'config': '5c3a2b6f5e63fb45f10e41e0318b354912ec44f6', 'pipeline': 'dc3b9f176f090005e38b142f11d80e93a7dc5d5e'}, 'duration': 0.7213859558105469, 'iteration': 6, 'loss': 0.31333333333333324, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 1, 'features__selectkbest__k': 4}), 'normalizer': ('normalizer_PowerTransformer', {}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 7})}, 'score': 0.6866666666666668, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'entropy', 'max_depth': 4, 'max_features': 3, 'max_leaf_nodes': 5, 'min_samples_split': 5, 'n_estimators': 10}, 'config_hash': {'algorithm': 'b8112b97ecfc10f00a195af661dcc861cac21289', 'config': 'd3b129b397350f1b6572651c67c01de49b4b174c', 'pipeline': '5b0357ed7072c37b3d6f458bb5d49ff7d825f603'}, 'duration': 0.8299109935760498, 'iteration': 7, 'loss': 1.0, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_PCA', {'features__n_components': 2}), 'normalizer': ('normalizer_StandardScaler', {'normalizer__with_mean': True, 'normalizer__with_std': False}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 6})}, 'score': 0.0, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'gini', 'max_depth': 4, 'max_features': None, 'max_leaf_nodes': 2, 'min_samples_split': 5, 'n_estimators': 100}, 'config_hash': {'algorithm': '40ca24df19b8d164d9d098a6bed1ce056fbbb961', 'config': '813bde1108cc3c4b9bfb3a22cbb421bda7eac671', 'pipeline': '74a7b8705a1c22f7dea5e44e4ebda8f1e48add71'}, 'duration': 2.2111589908599854, 'iteration': 8, 'loss': 0.33333333333333326, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_PCA', {'features__n_components': 2}), 'normalizer': ('normalizer_StandardScaler', {'normalizer__with_mean': False, 'normalizer__with_std': True}), 'rebalance': ('rebalance_NearMiss', {'rebalance__n_neighbors': 2})}, 'score': 0.6666666666666667, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'entropy', 'max_depth': 2, 'max_features': 1, 'max_leaf_nodes': 5, 'min_samples_split': 2, 'n_estimators': 100}, 'config_hash': {'algorithm': '331418a5c12cf1453876eef85e9d98fc8e54fa11', 'config': '31930b6860ed406d59bf7e59ba1925d94704bd3b', 'pipeline': '054bef356f90ec6f644ef3ffc688766744db51c2'}, 'duration': 1.0501940250396729, 'iteration': 9, 'loss': 0.053333333333333344, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_SelectKBest', {'features__k': 1}), 'normalizer': ('normalizer_RobustScaler', {'normalizer__quantile_range': (...), 'normalizer__with_centering': True, 'normalizer__with_scaling': True}), 'rebalance': ('rebalance_NearMiss', {'rebalance__n_neighbors': 2})}, 'score': 0.9466666666666667, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'entropy', 'max_depth': 3, 'max_features': None, 'max_leaf_nodes': 3, 'min_samples_split': 2, 'n_estimators': 100}, 'config_hash': {'algorithm': 'dbc1b8126649fe93dce5fbb37e4015b0acfb179e', 'config': '9913cd550615a9d0946ab4a755a8b9f619e442fd', 'pipeline': 'dd626121cea079ebb32e184ca65483ec7a6d7f59'}, 'duration': 1.120617151260376, 'iteration': 10, 'loss': 0.046666666666666634, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 2, 'features__selectkbest__k': 1}), 'normalizer': ('normalizer_MinMaxScaler', {}), 'rebalance': ('rebalance_NoneType', {})}, 'score': 0.9533333333333334, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'gini', 'max_depth': 3, 'max_features': 3, 'max_leaf_nodes': None, 'min_samples_split': 3, 'n_estimators': 75}, 'config_hash': {'algorithm': '34917a130df5a975f78bd7ec1a0c7b1ffdc787a9', 'config': '95fc8cadc088141290b7de9c388977e4685f0108', 'pipeline': '550d10faf2f08db48516cc3501558816d6a99bc0'}, 'duration': 1.4287099838256836, 'iteration': 11, 'loss': 0.19333333333333313, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 3, 'features__selectkbest__k': 4}), 'normalizer': ('normalizer_StandardScaler', {'normalizer__with_mean': False, 'normalizer__with_std': False}), 'rebalance': ('rebalance_CondensedNearestNeighbour', {'rebalance__n_neighbors': 1})}, 'score': 0.8066666666666669, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'entropy', 'max_depth': 1, 'max_features': 2, 'max_leaf_nodes': 5, 'min_samples_split': 2, 'n_estimators': 75}, 'config_hash': {'algorithm': '33f9abb4aee44a395a9f3b3ffa9ce80a8cdaed7c', 'config': '40fa726f0360cf6af55f9b5902d399d02f61f157', 'pipeline': 'cfd1d20841fe2153da762c95e79f95a3fb1e426a'}, 'duration': 1.2978079319000244, 'iteration': 12, 'loss': 0.053333333333333344, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_PCA', {'features__n_components': 4}), 'normalizer': ('normalizer_MinMaxScaler', {}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 7})}, 'score': 0.9466666666666667, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'entropy', 'max_depth': 4, 'max_features': 2, 'max_leaf_nodes': 5, 'min_samples_split': 3, 'n_estimators': 25}, 'config_hash': {'algorithm': '210111ec6562d09eb093e98ed69ef1c662e11a50', 'config': '0fb8e77c7bd9a58b72f1b33c21a59a09a8c676ba', 'pipeline': '5d269d759e0c7926a685a14b263ace8ae0071e4b'}, 'duration': 0.36649012565612793, 'iteration': 13, 'loss': 0.040000000000000036, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 2, 'features__selectkbest__k': 2}), 'normalizer': ('normalizer_NoneType', {}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 7})}, 'score': 0.96, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'entropy', 'max_depth': 3, 'max_features': 1, 'max_leaf_nodes': 5, 'min_samples_split': 2, 'n_estimators': 25}, 'config_hash': {'algorithm': '0e989a03980101fabf79eda3326ed2870e11d690', 'config': 'f4bffd5d8c67a9c5321a9943c4a99678f59a02b7', 'pipeline': '865ee1e3fe8334c3d5ecb2038d5a5d1b3ba50e75'}, 'duration': 0.35639500617980957, 'iteration': 14, 'loss': 0.046666666666666634, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_NoneType', {}), 'normalizer': ('normalizer_RobustScaler', {'normalizer__quantile_range': (...), 'normalizer__with_centering': True, 'normalizer__with_scaling': False}), 'rebalance': ('rebalance_NoneType', {})}, 'score': 0.9533333333333334, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'entropy', 'max_depth': None, 'max_features': 3, 'max_leaf_nodes': 3, 'min_samples_split': 5, 'n_estimators': 10}, 'config_hash': {'algorithm': '9c592e876c13de5e23e6de5b868e01755d63e72e', 'config': '1e6a68cd1eeac886d90724d78b1cb5fb76a3cde4', 'pipeline': '5a1ca4d82f21b7de0d2c918630a42510673fa36e'}, 'duration': 0.18141412734985352, 'iteration': 15, 'loss': 0.046666666666666634, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_SelectKBest', {'features__k': 3}), 'normalizer': ('normalizer_RobustScaler', {'normalizer__quantile_range': (...), 'normalizer__with_centering': True, 'normalizer__with_scaling': True}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 6})}, 'score': 0.9533333333333334, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': 1, 'max_features': None, 'max_leaf_nodes': None, 'min_samples_split': 5, 'n_estimators': 10}, 'config_hash': {'algorithm': '8bed77aef289bfd453b2858bd288ae5ba7160f2b', 'config': '781185bcb8999045de8d489f253a1a1ba4247932', 'pipeline': '1ece7eabedc2be9e5b0a1be65c570d08ffa3eb54'}, 'duration': 0.1636829376220703, 'iteration': 16, 'loss': 0.053333333333333344, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_NoneType', {}), 'normalizer': ('normalizer_NoneType', {}), 'rebalance': ('rebalance_NearMiss', {'rebalance__n_neighbors': 1})}, 'score': 0.9466666666666667, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'gini', 'max_depth': 3, 'max_features': 2, 'max_leaf_nodes': 2, 'min_samples_split': 5, 'n_estimators': 75}, 'config_hash': {'algorithm': '617b97d9ba21d3373bc51ffa9cccf9c6f91a77b3', 'config': '99fb425b4e8c5d80228cab94202252aa25cdf77c', 'pipeline': 'd6242929c3b515c7719e60423023ac604311afc3'}, 'duration': 0.8468999862670898, 'iteration': 17, 'loss': 0.24, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_PCA', {'features__n_components': 4}), 'normalizer': ('normalizer_PowerTransformer', {}), 'rebalance': ('rebalance_NearMiss', {'rebalance__n_neighbors': 2})}, 'score': 0.76, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': 1, 'max_features': 1, 'max_leaf_nodes': 2, 'min_samples_split': 5, 'n_estimators': 50}, 'config_hash': {'algorithm': 'b92d2697cdd4979da443369d6596229ec091626a', 'config': 'c513a3e13281206ad76187dd817b1fff93d54fe1', 'pipeline': 'c4b4f914a3ca8df967cade997a90366d85a371b9'}, 'duration': 0.6724588871002197, 'iteration': 18, 'loss': 0.23333333333333328, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 1, 'features__selectkbest__k': 3}), 'normalizer': ('normalizer_StandardScaler', {'normalizer__with_mean': True, 'normalizer__with_std': True}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 5})}, 'score': 0.7666666666666667, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'entropy', 'max_depth': None, 'max_features': None, 'max_leaf_nodes': 5, 'min_samples_split': 5, 'n_estimators': 10}, 'config_hash': {'algorithm': 'a0115de695e6cca2e81cbfb54df79bf4b43608b1', 'config': 'ba194015e20b5d67770e8c67342c3d8d0d01dc41', 'pipeline': '8d45fabfeb85ffdcabf7076bd0e65fffe97ce928'}, 'duration': 0.19424200057983398, 'iteration': 19, 'loss': 0.08666666666666667, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_PCA', {'features__n_components': 3}), 'normalizer': ('normalizer_NoneType', {}), 'rebalance': ('rebalance_NoneType', {})}, 'score': 0.9133333333333333, ...}, ...], 'history_hash': ['db6ac7e6d348155757e4794bb5f88fe2b4f63d50', '4db6fb84d85f52659f780e682ffac5712c3d8a94', '4403c5a85e951938d3c454e961d3a412780722f6', 'a064e2df18ab98d44dabcefbc7bed94913f1d0be', '0ddb6f5cab3db4dddd7682966a57205f3e329ad4', '49f25751bca61cdd461a8cbd2923689b642f98ed', '5c3a2b6f5e63fb45f10e41e0318b354912ec44f6', 'd3b129b397350f1b6572651c67c01de49b4b174c', '813bde1108cc3c4b9bfb3a22cbb421bda7eac671', '31930b6860ed406d59bf7e59ba1925d94704bd3b', '9913cd550615a9d0946ab4a755a8b9f619e442fd', '95fc8cadc088141290b7de9c388977e4685f0108', '40fa726f0360cf6af55f9b5902d399d02f61f157', '0fb8e77c7bd9a58b72f1b33c21a59a09a8c676ba', 'f4bffd5d8c67a9c5321a9943c4a99678f59a02b7', '1e6a68cd1eeac886d90724d78b1cb5fb76a3cde4', '781185bcb8999045de8d489f253a1a1ba4247932', '99fb425b4e8c5d80228cab94202252aa25cdf77c', 'c513a3e13281206ad76187dd817b1fff93d54fe1', 'ba194015e20b5d67770e8c67342c3d8d0d01dc41', ...], 'history_index': {'00f0493590a2cb5e98a35b29816f8cd9f87f96ec': 208, '013329309d510b94f19d930320402d65f953a847': 39, '038a0f515e2ec894ee8e34f9caa2889eb3ebd5ce': 66, '052ae4bf232b316187b078abae42c2be19e16a00': 111, '0659afebf316aafeb75612fb07081a04c28545ed': 74, '06e7cde9f3556cd01332ce389ad1d8925cd4b4a4': 120, '08606f2a0f0a6c9de204020b4632e09fcee0ae56': 168, '0a05b5b0a70971a5e347aaab7a4d4a07a92222fd': 191, '0b6551ecfd6f83a15704a9db68f1599c99c6d3ef': 58, '0cfb4698cbf2d986bcd5e0c2ef0f974da60b205e': 194, ...}, 'iteration': 221, 'max_history_score': 0.9666666666666668, 'max_history_score_std': 0.033333333333333326, 'max_history_step': 'joint'}, config={'algorithm': 'RandomForest', 'seed': 42, 'time': 300})
    108 
    109 def objective_algo(algo_config, current_pipeline_config, algorithm, X, y, context, config):
    110     return objective(current_pipeline_config, algo_config, algorithm, X, y, context, config, step='algorithm')
    111 
    112 def objective_joint(wconfig, algorithm, X, y, context, config):
--> 113     return objective(wconfig['pipeline'], wconfig['algorithm'], algorithm, X, y, context, config, step='joint')
        wconfig = {'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': 4, 'max_features': 3, 'max_leaf_nodes': 3, 'min_samples_split': 3, 'n_estimators': 100}, 'pipeline': {'features': ('features_PCA', {'features__n_components': 1}), 'normalizer': ('normalizer_RobustScaler', {'normalizer__quantile_range': (25.0, 75.0), 'normalizer__with_centering': True, 'normalizer__with_scaling': True}), 'rebalance': ('rebalance_CondensedNearestNeighbour', {'rebalance__n_neighbors': 3})}}
        algorithm = 'RandomForest'
        X = array([[5.1, 3.5, 1.4, 0.2],
       [4.9, 3. , 1....2, 3.4, 5.4, 2.3],
       [5.9, 3. , 5.1, 1.8]])
        y = array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,... 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2])
        context = {'baseline_score': 0.9466666666666667, 'baseline_score_std': 0.04988876515698587, 'best_config': {'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': 4, 'max_features': 3, 'max_leaf_nodes': 3, 'min_samples_split': 3, 'n_estimators': 10}, 'config_hash': {'algorithm': 'ffb7ff225ce3d3712c96cf87fe42202988ee2eb0', 'config': 'bae32f426be9cd6243523c023944a8c148fe4aeb', 'pipeline': 'd2a68bfda6fcdec4ae0ffc7d7b6a2122bc1cd673'}, 'duration': 0.7115809917449951, 'iteration': 113, 'loss': 0.033333333333333215, 'max_history_score': 0.9666666666666668, 'max_history_score_std': 0.033333333333333326, 'max_history_step': 'joint', 'pipeline': {'features': ('features_NoneType', {}), 'normalizer': ('normalizer_PowerTransformer', {}), 'rebalance': ('rebalance_CondensedNearestNeighbour', {'rebalance__n_neighbors': 2})}, 'score': 0.9666666666666668, ...}, 'history': [{'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': 2, 'max_features': None, 'max_leaf_nodes': 5, 'min_samples_split': 2, 'n_estimators': 75}, 'config_hash': {'algorithm': '3af5b0cce71c8fe2545246ca24ff5bc3dd516e06', 'config': 'db6ac7e6d348155757e4794bb5f88fe2b4f63d50', 'pipeline': '8d59f4b94cef6be9306ed86a22a9570fa670d567'}, 'duration': 1.149928092956543, 'iteration': 0, 'loss': 0.046666666666666634, 'max_history_score': 0.9533333333333334, 'max_history_score_std': 0.059999999999999984, 'max_history_step': 'joint', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 4, 'features__selectkbest__k': 3}), 'normalizer': ('normalizer_StandardScaler', {'normalizer__with_mean': True, 'normalizer__with_std': True}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 6})}, 'score': 0.9533333333333334, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': 1, 'max_features': 2, 'max_leaf_nodes': 2, 'min_samples_split': 5, 'n_estimators': 100}, 'config_hash': {'algorithm': 'e13eb05fd9a62d2f63bbb1c1deff0cd620d5e6ab', 'config': '4db6fb84d85f52659f780e682ffac5712c3d8a94', 'pipeline': '64c9a1ca9d53ae67244bdd942f4db36a3c05218c'}, 'duration': 1.7678282260894775, 'iteration': 1, 'loss': 0.18000000000000005, 'max_history_score': 0.9533333333333334, 'max_history_score_std': 0.059999999999999984, 'max_history_step': 'joint', 'pipeline': {'features': ('features_NoneType', {}), 'normalizer': ('normalizer_PowerTransformer', {}), 'rebalance': ('rebalance_NearMiss', {'rebalance__n_neighbors': 1})}, 'score': 0.82, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': 1, 'max_features': None, 'max_leaf_nodes': None, 'min_samples_split': 5, 'n_estimators': 75}, 'config_hash': {'algorithm': '94b0d7a654c508cc63643f78fe4f0f07e6f07c1e', 'config': '4403c5a85e951938d3c454e961d3a412780722f6', 'pipeline': '3e47444880d8367fbac2faaba2e52a917274aa58'}, 'duration': 0.8397619724273682, 'iteration': 2, 'loss': 0.03333333333333344, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_PCA', {'features__n_components': 3}), 'normalizer': ('normalizer_MinMaxScaler', {}), 'rebalance': ('rebalance_NoneType', {})}, 'score': 0.9666666666666666, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': None, 'max_features': None, 'max_leaf_nodes': 3, 'min_samples_split': 3, 'n_estimators': 75}, 'config_hash': {'algorithm': 'e8332f0a8902bda03bf70e7978cc5d52affb29d3', 'config': 'a064e2df18ab98d44dabcefbc7bed94913f1d0be', 'pipeline': '7eea819c2a8c103c4b1e9e9c1e224aebba95081f'}, 'duration': 0.8501448631286621, 'iteration': 3, 'loss': 0.053333333333333344, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 2, 'features__selectkbest__k': 4}), 'normalizer': ('normalizer_NoneType', {}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 7})}, 'score': 0.9466666666666667, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'entropy', 'max_depth': 3, 'max_features': 3, 'max_leaf_nodes': None, 'min_samples_split': 5, 'n_estimators': 75}, 'config_hash': {'algorithm': '7a4491035bc6bd737fe9a8cda8a79a02d02d5c74', 'config': '0ddb6f5cab3db4dddd7682966a57205f3e329ad4', 'pipeline': 'a9ae03fe38334f6868cbf84cdd3d629d4bbe3fb0'}, 'duration': 1.1026010513305664, 'iteration': 4, 'loss': 0.05999999999999994, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 2, 'features__selectkbest__k': 1}), 'normalizer': ('normalizer_NoneType', {}), 'rebalance': ('rebalance_NoneType', {})}, 'score': 0.9400000000000001, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'gini', 'max_depth': 3, 'max_features': 1, 'max_leaf_nodes': 5, 'min_samples_split': 2, 'n_estimators': 25}, 'config_hash': {'algorithm': '9826d20b2d6a0f559cf7f16450ce7526f07e8434', 'config': '49f25751bca61cdd461a8cbd2923689b642f98ed', 'pipeline': '19b249664c5bf067de1fed4334a296f947ce774a'}, 'duration': 0.35647010803222656, 'iteration': 5, 'loss': 0.046666666666666634, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_NoneType', {}), 'normalizer': ('normalizer_NoneType', {}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 6})}, 'score': 0.9533333333333334, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'gini', 'max_depth': 2, 'max_features': 1, 'max_leaf_nodes': 2, 'min_samples_split': 2, 'n_estimators': 50}, 'config_hash': {'algorithm': '0a4f6fbb07e0f32c6f675489a0fc82eee05bd8e1', 'config': '5c3a2b6f5e63fb45f10e41e0318b354912ec44f6', 'pipeline': 'dc3b9f176f090005e38b142f11d80e93a7dc5d5e'}, 'duration': 0.7213859558105469, 'iteration': 6, 'loss': 0.31333333333333324, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 1, 'features__selectkbest__k': 4}), 'normalizer': ('normalizer_PowerTransformer', {}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 7})}, 'score': 0.6866666666666668, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'entropy', 'max_depth': 4, 'max_features': 3, 'max_leaf_nodes': 5, 'min_samples_split': 5, 'n_estimators': 10}, 'config_hash': {'algorithm': 'b8112b97ecfc10f00a195af661dcc861cac21289', 'config': 'd3b129b397350f1b6572651c67c01de49b4b174c', 'pipeline': '5b0357ed7072c37b3d6f458bb5d49ff7d825f603'}, 'duration': 0.8299109935760498, 'iteration': 7, 'loss': 1.0, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_PCA', {'features__n_components': 2}), 'normalizer': ('normalizer_StandardScaler', {'normalizer__with_mean': True, 'normalizer__with_std': False}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 6})}, 'score': 0.0, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'gini', 'max_depth': 4, 'max_features': None, 'max_leaf_nodes': 2, 'min_samples_split': 5, 'n_estimators': 100}, 'config_hash': {'algorithm': '40ca24df19b8d164d9d098a6bed1ce056fbbb961', 'config': '813bde1108cc3c4b9bfb3a22cbb421bda7eac671', 'pipeline': '74a7b8705a1c22f7dea5e44e4ebda8f1e48add71'}, 'duration': 2.2111589908599854, 'iteration': 8, 'loss': 0.33333333333333326, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_PCA', {'features__n_components': 2}), 'normalizer': ('normalizer_StandardScaler', {'normalizer__with_mean': False, 'normalizer__with_std': True}), 'rebalance': ('rebalance_NearMiss', {'rebalance__n_neighbors': 2})}, 'score': 0.6666666666666667, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'entropy', 'max_depth': 2, 'max_features': 1, 'max_leaf_nodes': 5, 'min_samples_split': 2, 'n_estimators': 100}, 'config_hash': {'algorithm': '331418a5c12cf1453876eef85e9d98fc8e54fa11', 'config': '31930b6860ed406d59bf7e59ba1925d94704bd3b', 'pipeline': '054bef356f90ec6f644ef3ffc688766744db51c2'}, 'duration': 1.0501940250396729, 'iteration': 9, 'loss': 0.053333333333333344, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_SelectKBest', {'features__k': 1}), 'normalizer': ('normalizer_RobustScaler', {'normalizer__quantile_range': (...), 'normalizer__with_centering': True, 'normalizer__with_scaling': True}), 'rebalance': ('rebalance_NearMiss', {'rebalance__n_neighbors': 2})}, 'score': 0.9466666666666667, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'entropy', 'max_depth': 3, 'max_features': None, 'max_leaf_nodes': 3, 'min_samples_split': 2, 'n_estimators': 100}, 'config_hash': {'algorithm': 'dbc1b8126649fe93dce5fbb37e4015b0acfb179e', 'config': '9913cd550615a9d0946ab4a755a8b9f619e442fd', 'pipeline': 'dd626121cea079ebb32e184ca65483ec7a6d7f59'}, 'duration': 1.120617151260376, 'iteration': 10, 'loss': 0.046666666666666634, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 2, 'features__selectkbest__k': 1}), 'normalizer': ('normalizer_MinMaxScaler', {}), 'rebalance': ('rebalance_NoneType', {})}, 'score': 0.9533333333333334, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'gini', 'max_depth': 3, 'max_features': 3, 'max_leaf_nodes': None, 'min_samples_split': 3, 'n_estimators': 75}, 'config_hash': {'algorithm': '34917a130df5a975f78bd7ec1a0c7b1ffdc787a9', 'config': '95fc8cadc088141290b7de9c388977e4685f0108', 'pipeline': '550d10faf2f08db48516cc3501558816d6a99bc0'}, 'duration': 1.4287099838256836, 'iteration': 11, 'loss': 0.19333333333333313, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 3, 'features__selectkbest__k': 4}), 'normalizer': ('normalizer_StandardScaler', {'normalizer__with_mean': False, 'normalizer__with_std': False}), 'rebalance': ('rebalance_CondensedNearestNeighbour', {'rebalance__n_neighbors': 1})}, 'score': 0.8066666666666669, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'entropy', 'max_depth': 1, 'max_features': 2, 'max_leaf_nodes': 5, 'min_samples_split': 2, 'n_estimators': 75}, 'config_hash': {'algorithm': '33f9abb4aee44a395a9f3b3ffa9ce80a8cdaed7c', 'config': '40fa726f0360cf6af55f9b5902d399d02f61f157', 'pipeline': 'cfd1d20841fe2153da762c95e79f95a3fb1e426a'}, 'duration': 1.2978079319000244, 'iteration': 12, 'loss': 0.053333333333333344, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_PCA', {'features__n_components': 4}), 'normalizer': ('normalizer_MinMaxScaler', {}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 7})}, 'score': 0.9466666666666667, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'entropy', 'max_depth': 4, 'max_features': 2, 'max_leaf_nodes': 5, 'min_samples_split': 3, 'n_estimators': 25}, 'config_hash': {'algorithm': '210111ec6562d09eb093e98ed69ef1c662e11a50', 'config': '0fb8e77c7bd9a58b72f1b33c21a59a09a8c676ba', 'pipeline': '5d269d759e0c7926a685a14b263ace8ae0071e4b'}, 'duration': 0.36649012565612793, 'iteration': 13, 'loss': 0.040000000000000036, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 2, 'features__selectkbest__k': 2}), 'normalizer': ('normalizer_NoneType', {}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 7})}, 'score': 0.96, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'entropy', 'max_depth': 3, 'max_features': 1, 'max_leaf_nodes': 5, 'min_samples_split': 2, 'n_estimators': 25}, 'config_hash': {'algorithm': '0e989a03980101fabf79eda3326ed2870e11d690', 'config': 'f4bffd5d8c67a9c5321a9943c4a99678f59a02b7', 'pipeline': '865ee1e3fe8334c3d5ecb2038d5a5d1b3ba50e75'}, 'duration': 0.35639500617980957, 'iteration': 14, 'loss': 0.046666666666666634, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_NoneType', {}), 'normalizer': ('normalizer_RobustScaler', {'normalizer__quantile_range': (...), 'normalizer__with_centering': True, 'normalizer__with_scaling': False}), 'rebalance': ('rebalance_NoneType', {})}, 'score': 0.9533333333333334, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'entropy', 'max_depth': None, 'max_features': 3, 'max_leaf_nodes': 3, 'min_samples_split': 5, 'n_estimators': 10}, 'config_hash': {'algorithm': '9c592e876c13de5e23e6de5b868e01755d63e72e', 'config': '1e6a68cd1eeac886d90724d78b1cb5fb76a3cde4', 'pipeline': '5a1ca4d82f21b7de0d2c918630a42510673fa36e'}, 'duration': 0.18141412734985352, 'iteration': 15, 'loss': 0.046666666666666634, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_SelectKBest', {'features__k': 3}), 'normalizer': ('normalizer_RobustScaler', {'normalizer__quantile_range': (...), 'normalizer__with_centering': True, 'normalizer__with_scaling': True}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 6})}, 'score': 0.9533333333333334, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': 1, 'max_features': None, 'max_leaf_nodes': None, 'min_samples_split': 5, 'n_estimators': 10}, 'config_hash': {'algorithm': '8bed77aef289bfd453b2858bd288ae5ba7160f2b', 'config': '781185bcb8999045de8d489f253a1a1ba4247932', 'pipeline': '1ece7eabedc2be9e5b0a1be65c570d08ffa3eb54'}, 'duration': 0.1636829376220703, 'iteration': 16, 'loss': 0.053333333333333344, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_NoneType', {}), 'normalizer': ('normalizer_NoneType', {}), 'rebalance': ('rebalance_NearMiss', {'rebalance__n_neighbors': 1})}, 'score': 0.9466666666666667, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'gini', 'max_depth': 3, 'max_features': 2, 'max_leaf_nodes': 2, 'min_samples_split': 5, 'n_estimators': 75}, 'config_hash': {'algorithm': '617b97d9ba21d3373bc51ffa9cccf9c6f91a77b3', 'config': '99fb425b4e8c5d80228cab94202252aa25cdf77c', 'pipeline': 'd6242929c3b515c7719e60423023ac604311afc3'}, 'duration': 0.8468999862670898, 'iteration': 17, 'loss': 0.24, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_PCA', {'features__n_components': 4}), 'normalizer': ('normalizer_PowerTransformer', {}), 'rebalance': ('rebalance_NearMiss', {'rebalance__n_neighbors': 2})}, 'score': 0.76, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': 1, 'max_features': 1, 'max_leaf_nodes': 2, 'min_samples_split': 5, 'n_estimators': 50}, 'config_hash': {'algorithm': 'b92d2697cdd4979da443369d6596229ec091626a', 'config': 'c513a3e13281206ad76187dd817b1fff93d54fe1', 'pipeline': 'c4b4f914a3ca8df967cade997a90366d85a371b9'}, 'duration': 0.6724588871002197, 'iteration': 18, 'loss': 0.23333333333333328, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 1, 'features__selectkbest__k': 3}), 'normalizer': ('normalizer_StandardScaler', {'normalizer__with_mean': True, 'normalizer__with_std': True}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 5})}, 'score': 0.7666666666666667, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'entropy', 'max_depth': None, 'max_features': None, 'max_leaf_nodes': 5, 'min_samples_split': 5, 'n_estimators': 10}, 'config_hash': {'algorithm': 'a0115de695e6cca2e81cbfb54df79bf4b43608b1', 'config': 'ba194015e20b5d67770e8c67342c3d8d0d01dc41', 'pipeline': '8d45fabfeb85ffdcabf7076bd0e65fffe97ce928'}, 'duration': 0.19424200057983398, 'iteration': 19, 'loss': 0.08666666666666667, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_PCA', {'features__n_components': 3}), 'normalizer': ('normalizer_NoneType', {}), 'rebalance': ('rebalance_NoneType', {})}, 'score': 0.9133333333333333, ...}, ...], 'history_hash': ['db6ac7e6d348155757e4794bb5f88fe2b4f63d50', '4db6fb84d85f52659f780e682ffac5712c3d8a94', '4403c5a85e951938d3c454e961d3a412780722f6', 'a064e2df18ab98d44dabcefbc7bed94913f1d0be', '0ddb6f5cab3db4dddd7682966a57205f3e329ad4', '49f25751bca61cdd461a8cbd2923689b642f98ed', '5c3a2b6f5e63fb45f10e41e0318b354912ec44f6', 'd3b129b397350f1b6572651c67c01de49b4b174c', '813bde1108cc3c4b9bfb3a22cbb421bda7eac671', '31930b6860ed406d59bf7e59ba1925d94704bd3b', '9913cd550615a9d0946ab4a755a8b9f619e442fd', '95fc8cadc088141290b7de9c388977e4685f0108', '40fa726f0360cf6af55f9b5902d399d02f61f157', '0fb8e77c7bd9a58b72f1b33c21a59a09a8c676ba', 'f4bffd5d8c67a9c5321a9943c4a99678f59a02b7', '1e6a68cd1eeac886d90724d78b1cb5fb76a3cde4', '781185bcb8999045de8d489f253a1a1ba4247932', '99fb425b4e8c5d80228cab94202252aa25cdf77c', 'c513a3e13281206ad76187dd817b1fff93d54fe1', 'ba194015e20b5d67770e8c67342c3d8d0d01dc41', ...], 'history_index': {'00f0493590a2cb5e98a35b29816f8cd9f87f96ec': 208, '013329309d510b94f19d930320402d65f953a847': 39, '038a0f515e2ec894ee8e34f9caa2889eb3ebd5ce': 66, '052ae4bf232b316187b078abae42c2be19e16a00': 111, '0659afebf316aafeb75612fb07081a04c28545ed': 74, '06e7cde9f3556cd01332ce389ad1d8925cd4b4a4': 120, '08606f2a0f0a6c9de204020b4632e09fcee0ae56': 168, '0a05b5b0a70971a5e347aaab7a4d4a07a92222fd': 191, '0b6551ecfd6f83a15704a9db68f1599c99c6d3ef': 58, '0cfb4698cbf2d986bcd5e0c2ef0f974da60b205e': 194, ...}, 'iteration': 221, 'max_history_score': 0.9666666666666668, 'max_history_score_std': 0.033333333333333326, 'max_history_step': 'joint'}
        config = {'algorithm': 'RandomForest', 'seed': 42, 'time': 300}
    114 
    115 
    116 def get_baseline_score(algorithm, X, y, seed):
    117     pipeline, _ = pipeline_conf_to_full_pipeline(

...........................................................................
/home/aquemy/dev/dp_hyperparameters/extension/experiment/objective.py in objective(pipeline_config={'features': ('features_PCA', {'features__n_components': 1}), 'normalizer': ('normalizer_RobustScaler', {'normalizer__quantile_range': (25.0, 75.0), 'normalizer__with_centering': True, 'normalizer__with_scaling': True}), 'rebalance': ('rebalance_CondensedNearestNeighbour', {'rebalance__n_neighbors': 3})}, algo_config={'bootstrap': True, 'criterion': 'gini', 'max_depth': 4, 'max_features': 3, 'max_leaf_nodes': 3, 'min_samples_split': 3, 'n_estimators': 100}, algorithm='RandomForest', X=array([[5.1, 3.5, 1.4, 0.2],
       [4.9, 3. , 1....2, 3.4, 5.4, 2.3],
       [5.9, 3. , 5.1, 1.8]]), y=array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,... 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]), context={'baseline_score': 0.9466666666666667, 'baseline_score_std': 0.04988876515698587, 'best_config': {'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': 4, 'max_features': 3, 'max_leaf_nodes': 3, 'min_samples_split': 3, 'n_estimators': 10}, 'config_hash': {'algorithm': 'ffb7ff225ce3d3712c96cf87fe42202988ee2eb0', 'config': 'bae32f426be9cd6243523c023944a8c148fe4aeb', 'pipeline': 'd2a68bfda6fcdec4ae0ffc7d7b6a2122bc1cd673'}, 'duration': 0.7115809917449951, 'iteration': 113, 'loss': 0.033333333333333215, 'max_history_score': 0.9666666666666668, 'max_history_score_std': 0.033333333333333326, 'max_history_step': 'joint', 'pipeline': {'features': ('features_NoneType', {}), 'normalizer': ('normalizer_PowerTransformer', {}), 'rebalance': ('rebalance_CondensedNearestNeighbour', {'rebalance__n_neighbors': 2})}, 'score': 0.9666666666666668, ...}, 'history': [{'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': 2, 'max_features': None, 'max_leaf_nodes': 5, 'min_samples_split': 2, 'n_estimators': 75}, 'config_hash': {'algorithm': '3af5b0cce71c8fe2545246ca24ff5bc3dd516e06', 'config': 'db6ac7e6d348155757e4794bb5f88fe2b4f63d50', 'pipeline': '8d59f4b94cef6be9306ed86a22a9570fa670d567'}, 'duration': 1.149928092956543, 'iteration': 0, 'loss': 0.046666666666666634, 'max_history_score': 0.9533333333333334, 'max_history_score_std': 0.059999999999999984, 'max_history_step': 'joint', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 4, 'features__selectkbest__k': 3}), 'normalizer': ('normalizer_StandardScaler', {'normalizer__with_mean': True, 'normalizer__with_std': True}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 6})}, 'score': 0.9533333333333334, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': 1, 'max_features': 2, 'max_leaf_nodes': 2, 'min_samples_split': 5, 'n_estimators': 100}, 'config_hash': {'algorithm': 'e13eb05fd9a62d2f63bbb1c1deff0cd620d5e6ab', 'config': '4db6fb84d85f52659f780e682ffac5712c3d8a94', 'pipeline': '64c9a1ca9d53ae67244bdd942f4db36a3c05218c'}, 'duration': 1.7678282260894775, 'iteration': 1, 'loss': 0.18000000000000005, 'max_history_score': 0.9533333333333334, 'max_history_score_std': 0.059999999999999984, 'max_history_step': 'joint', 'pipeline': {'features': ('features_NoneType', {}), 'normalizer': ('normalizer_PowerTransformer', {}), 'rebalance': ('rebalance_NearMiss', {'rebalance__n_neighbors': 1})}, 'score': 0.82, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': 1, 'max_features': None, 'max_leaf_nodes': None, 'min_samples_split': 5, 'n_estimators': 75}, 'config_hash': {'algorithm': '94b0d7a654c508cc63643f78fe4f0f07e6f07c1e', 'config': '4403c5a85e951938d3c454e961d3a412780722f6', 'pipeline': '3e47444880d8367fbac2faaba2e52a917274aa58'}, 'duration': 0.8397619724273682, 'iteration': 2, 'loss': 0.03333333333333344, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_PCA', {'features__n_components': 3}), 'normalizer': ('normalizer_MinMaxScaler', {}), 'rebalance': ('rebalance_NoneType', {})}, 'score': 0.9666666666666666, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': None, 'max_features': None, 'max_leaf_nodes': 3, 'min_samples_split': 3, 'n_estimators': 75}, 'config_hash': {'algorithm': 'e8332f0a8902bda03bf70e7978cc5d52affb29d3', 'config': 'a064e2df18ab98d44dabcefbc7bed94913f1d0be', 'pipeline': '7eea819c2a8c103c4b1e9e9c1e224aebba95081f'}, 'duration': 0.8501448631286621, 'iteration': 3, 'loss': 0.053333333333333344, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 2, 'features__selectkbest__k': 4}), 'normalizer': ('normalizer_NoneType', {}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 7})}, 'score': 0.9466666666666667, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'entropy', 'max_depth': 3, 'max_features': 3, 'max_leaf_nodes': None, 'min_samples_split': 5, 'n_estimators': 75}, 'config_hash': {'algorithm': '7a4491035bc6bd737fe9a8cda8a79a02d02d5c74', 'config': '0ddb6f5cab3db4dddd7682966a57205f3e329ad4', 'pipeline': 'a9ae03fe38334f6868cbf84cdd3d629d4bbe3fb0'}, 'duration': 1.1026010513305664, 'iteration': 4, 'loss': 0.05999999999999994, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 2, 'features__selectkbest__k': 1}), 'normalizer': ('normalizer_NoneType', {}), 'rebalance': ('rebalance_NoneType', {})}, 'score': 0.9400000000000001, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'gini', 'max_depth': 3, 'max_features': 1, 'max_leaf_nodes': 5, 'min_samples_split': 2, 'n_estimators': 25}, 'config_hash': {'algorithm': '9826d20b2d6a0f559cf7f16450ce7526f07e8434', 'config': '49f25751bca61cdd461a8cbd2923689b642f98ed', 'pipeline': '19b249664c5bf067de1fed4334a296f947ce774a'}, 'duration': 0.35647010803222656, 'iteration': 5, 'loss': 0.046666666666666634, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_NoneType', {}), 'normalizer': ('normalizer_NoneType', {}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 6})}, 'score': 0.9533333333333334, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'gini', 'max_depth': 2, 'max_features': 1, 'max_leaf_nodes': 2, 'min_samples_split': 2, 'n_estimators': 50}, 'config_hash': {'algorithm': '0a4f6fbb07e0f32c6f675489a0fc82eee05bd8e1', 'config': '5c3a2b6f5e63fb45f10e41e0318b354912ec44f6', 'pipeline': 'dc3b9f176f090005e38b142f11d80e93a7dc5d5e'}, 'duration': 0.7213859558105469, 'iteration': 6, 'loss': 0.31333333333333324, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 1, 'features__selectkbest__k': 4}), 'normalizer': ('normalizer_PowerTransformer', {}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 7})}, 'score': 0.6866666666666668, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'entropy', 'max_depth': 4, 'max_features': 3, 'max_leaf_nodes': 5, 'min_samples_split': 5, 'n_estimators': 10}, 'config_hash': {'algorithm': 'b8112b97ecfc10f00a195af661dcc861cac21289', 'config': 'd3b129b397350f1b6572651c67c01de49b4b174c', 'pipeline': '5b0357ed7072c37b3d6f458bb5d49ff7d825f603'}, 'duration': 0.8299109935760498, 'iteration': 7, 'loss': 1.0, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_PCA', {'features__n_components': 2}), 'normalizer': ('normalizer_StandardScaler', {'normalizer__with_mean': True, 'normalizer__with_std': False}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 6})}, 'score': 0.0, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'gini', 'max_depth': 4, 'max_features': None, 'max_leaf_nodes': 2, 'min_samples_split': 5, 'n_estimators': 100}, 'config_hash': {'algorithm': '40ca24df19b8d164d9d098a6bed1ce056fbbb961', 'config': '813bde1108cc3c4b9bfb3a22cbb421bda7eac671', 'pipeline': '74a7b8705a1c22f7dea5e44e4ebda8f1e48add71'}, 'duration': 2.2111589908599854, 'iteration': 8, 'loss': 0.33333333333333326, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_PCA', {'features__n_components': 2}), 'normalizer': ('normalizer_StandardScaler', {'normalizer__with_mean': False, 'normalizer__with_std': True}), 'rebalance': ('rebalance_NearMiss', {'rebalance__n_neighbors': 2})}, 'score': 0.6666666666666667, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'entropy', 'max_depth': 2, 'max_features': 1, 'max_leaf_nodes': 5, 'min_samples_split': 2, 'n_estimators': 100}, 'config_hash': {'algorithm': '331418a5c12cf1453876eef85e9d98fc8e54fa11', 'config': '31930b6860ed406d59bf7e59ba1925d94704bd3b', 'pipeline': '054bef356f90ec6f644ef3ffc688766744db51c2'}, 'duration': 1.0501940250396729, 'iteration': 9, 'loss': 0.053333333333333344, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_SelectKBest', {'features__k': 1}), 'normalizer': ('normalizer_RobustScaler', {'normalizer__quantile_range': (...), 'normalizer__with_centering': True, 'normalizer__with_scaling': True}), 'rebalance': ('rebalance_NearMiss', {'rebalance__n_neighbors': 2})}, 'score': 0.9466666666666667, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'entropy', 'max_depth': 3, 'max_features': None, 'max_leaf_nodes': 3, 'min_samples_split': 2, 'n_estimators': 100}, 'config_hash': {'algorithm': 'dbc1b8126649fe93dce5fbb37e4015b0acfb179e', 'config': '9913cd550615a9d0946ab4a755a8b9f619e442fd', 'pipeline': 'dd626121cea079ebb32e184ca65483ec7a6d7f59'}, 'duration': 1.120617151260376, 'iteration': 10, 'loss': 0.046666666666666634, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 2, 'features__selectkbest__k': 1}), 'normalizer': ('normalizer_MinMaxScaler', {}), 'rebalance': ('rebalance_NoneType', {})}, 'score': 0.9533333333333334, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'gini', 'max_depth': 3, 'max_features': 3, 'max_leaf_nodes': None, 'min_samples_split': 3, 'n_estimators': 75}, 'config_hash': {'algorithm': '34917a130df5a975f78bd7ec1a0c7b1ffdc787a9', 'config': '95fc8cadc088141290b7de9c388977e4685f0108', 'pipeline': '550d10faf2f08db48516cc3501558816d6a99bc0'}, 'duration': 1.4287099838256836, 'iteration': 11, 'loss': 0.19333333333333313, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 3, 'features__selectkbest__k': 4}), 'normalizer': ('normalizer_StandardScaler', {'normalizer__with_mean': False, 'normalizer__with_std': False}), 'rebalance': ('rebalance_CondensedNearestNeighbour', {'rebalance__n_neighbors': 1})}, 'score': 0.8066666666666669, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'entropy', 'max_depth': 1, 'max_features': 2, 'max_leaf_nodes': 5, 'min_samples_split': 2, 'n_estimators': 75}, 'config_hash': {'algorithm': '33f9abb4aee44a395a9f3b3ffa9ce80a8cdaed7c', 'config': '40fa726f0360cf6af55f9b5902d399d02f61f157', 'pipeline': 'cfd1d20841fe2153da762c95e79f95a3fb1e426a'}, 'duration': 1.2978079319000244, 'iteration': 12, 'loss': 0.053333333333333344, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_PCA', {'features__n_components': 4}), 'normalizer': ('normalizer_MinMaxScaler', {}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 7})}, 'score': 0.9466666666666667, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'entropy', 'max_depth': 4, 'max_features': 2, 'max_leaf_nodes': 5, 'min_samples_split': 3, 'n_estimators': 25}, 'config_hash': {'algorithm': '210111ec6562d09eb093e98ed69ef1c662e11a50', 'config': '0fb8e77c7bd9a58b72f1b33c21a59a09a8c676ba', 'pipeline': '5d269d759e0c7926a685a14b263ace8ae0071e4b'}, 'duration': 0.36649012565612793, 'iteration': 13, 'loss': 0.040000000000000036, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 2, 'features__selectkbest__k': 2}), 'normalizer': ('normalizer_NoneType', {}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 7})}, 'score': 0.96, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'entropy', 'max_depth': 3, 'max_features': 1, 'max_leaf_nodes': 5, 'min_samples_split': 2, 'n_estimators': 25}, 'config_hash': {'algorithm': '0e989a03980101fabf79eda3326ed2870e11d690', 'config': 'f4bffd5d8c67a9c5321a9943c4a99678f59a02b7', 'pipeline': '865ee1e3fe8334c3d5ecb2038d5a5d1b3ba50e75'}, 'duration': 0.35639500617980957, 'iteration': 14, 'loss': 0.046666666666666634, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_NoneType', {}), 'normalizer': ('normalizer_RobustScaler', {'normalizer__quantile_range': (...), 'normalizer__with_centering': True, 'normalizer__with_scaling': False}), 'rebalance': ('rebalance_NoneType', {})}, 'score': 0.9533333333333334, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'entropy', 'max_depth': None, 'max_features': 3, 'max_leaf_nodes': 3, 'min_samples_split': 5, 'n_estimators': 10}, 'config_hash': {'algorithm': '9c592e876c13de5e23e6de5b868e01755d63e72e', 'config': '1e6a68cd1eeac886d90724d78b1cb5fb76a3cde4', 'pipeline': '5a1ca4d82f21b7de0d2c918630a42510673fa36e'}, 'duration': 0.18141412734985352, 'iteration': 15, 'loss': 0.046666666666666634, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_SelectKBest', {'features__k': 3}), 'normalizer': ('normalizer_RobustScaler', {'normalizer__quantile_range': (...), 'normalizer__with_centering': True, 'normalizer__with_scaling': True}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 6})}, 'score': 0.9533333333333334, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': 1, 'max_features': None, 'max_leaf_nodes': None, 'min_samples_split': 5, 'n_estimators': 10}, 'config_hash': {'algorithm': '8bed77aef289bfd453b2858bd288ae5ba7160f2b', 'config': '781185bcb8999045de8d489f253a1a1ba4247932', 'pipeline': '1ece7eabedc2be9e5b0a1be65c570d08ffa3eb54'}, 'duration': 0.1636829376220703, 'iteration': 16, 'loss': 0.053333333333333344, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_NoneType', {}), 'normalizer': ('normalizer_NoneType', {}), 'rebalance': ('rebalance_NearMiss', {'rebalance__n_neighbors': 1})}, 'score': 0.9466666666666667, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'gini', 'max_depth': 3, 'max_features': 2, 'max_leaf_nodes': 2, 'min_samples_split': 5, 'n_estimators': 75}, 'config_hash': {'algorithm': '617b97d9ba21d3373bc51ffa9cccf9c6f91a77b3', 'config': '99fb425b4e8c5d80228cab94202252aa25cdf77c', 'pipeline': 'd6242929c3b515c7719e60423023ac604311afc3'}, 'duration': 0.8468999862670898, 'iteration': 17, 'loss': 0.24, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_PCA', {'features__n_components': 4}), 'normalizer': ('normalizer_PowerTransformer', {}), 'rebalance': ('rebalance_NearMiss', {'rebalance__n_neighbors': 2})}, 'score': 0.76, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': 1, 'max_features': 1, 'max_leaf_nodes': 2, 'min_samples_split': 5, 'n_estimators': 50}, 'config_hash': {'algorithm': 'b92d2697cdd4979da443369d6596229ec091626a', 'config': 'c513a3e13281206ad76187dd817b1fff93d54fe1', 'pipeline': 'c4b4f914a3ca8df967cade997a90366d85a371b9'}, 'duration': 0.6724588871002197, 'iteration': 18, 'loss': 0.23333333333333328, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 1, 'features__selectkbest__k': 3}), 'normalizer': ('normalizer_StandardScaler', {'normalizer__with_mean': True, 'normalizer__with_std': True}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 5})}, 'score': 0.7666666666666667, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'entropy', 'max_depth': None, 'max_features': None, 'max_leaf_nodes': 5, 'min_samples_split': 5, 'n_estimators': 10}, 'config_hash': {'algorithm': 'a0115de695e6cca2e81cbfb54df79bf4b43608b1', 'config': 'ba194015e20b5d67770e8c67342c3d8d0d01dc41', 'pipeline': '8d45fabfeb85ffdcabf7076bd0e65fffe97ce928'}, 'duration': 0.19424200057983398, 'iteration': 19, 'loss': 0.08666666666666667, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_PCA', {'features__n_components': 3}), 'normalizer': ('normalizer_NoneType', {}), 'rebalance': ('rebalance_NoneType', {})}, 'score': 0.9133333333333333, ...}, ...], 'history_hash': ['db6ac7e6d348155757e4794bb5f88fe2b4f63d50', '4db6fb84d85f52659f780e682ffac5712c3d8a94', '4403c5a85e951938d3c454e961d3a412780722f6', 'a064e2df18ab98d44dabcefbc7bed94913f1d0be', '0ddb6f5cab3db4dddd7682966a57205f3e329ad4', '49f25751bca61cdd461a8cbd2923689b642f98ed', '5c3a2b6f5e63fb45f10e41e0318b354912ec44f6', 'd3b129b397350f1b6572651c67c01de49b4b174c', '813bde1108cc3c4b9bfb3a22cbb421bda7eac671', '31930b6860ed406d59bf7e59ba1925d94704bd3b', '9913cd550615a9d0946ab4a755a8b9f619e442fd', '95fc8cadc088141290b7de9c388977e4685f0108', '40fa726f0360cf6af55f9b5902d399d02f61f157', '0fb8e77c7bd9a58b72f1b33c21a59a09a8c676ba', 'f4bffd5d8c67a9c5321a9943c4a99678f59a02b7', '1e6a68cd1eeac886d90724d78b1cb5fb76a3cde4', '781185bcb8999045de8d489f253a1a1ba4247932', '99fb425b4e8c5d80228cab94202252aa25cdf77c', 'c513a3e13281206ad76187dd817b1fff93d54fe1', 'ba194015e20b5d67770e8c67342c3d8d0d01dc41', ...], 'history_index': {'00f0493590a2cb5e98a35b29816f8cd9f87f96ec': 208, '013329309d510b94f19d930320402d65f953a847': 39, '038a0f515e2ec894ee8e34f9caa2889eb3ebd5ce': 66, '052ae4bf232b316187b078abae42c2be19e16a00': 111, '0659afebf316aafeb75612fb07081a04c28545ed': 74, '06e7cde9f3556cd01332ce389ad1d8925cd4b4a4': 120, '08606f2a0f0a6c9de204020b4632e09fcee0ae56': 168, '0a05b5b0a70971a5e347aaab7a4d4a07a92222fd': 191, '0b6551ecfd6f83a15704a9db68f1599c99c6d3ef': 58, '0cfb4698cbf2d986bcd5e0c2ef0f974da60b205e': 194, ...}, 'iteration': 221, 'max_history_score': 0.9666666666666668, 'max_history_score_std': 0.033333333333333326, 'max_history_step': 'joint'}, config={'algorithm': 'RandomForest', 'seed': 42, 'time': 300}, step='joint')
     45                 y,
     46                 cv=10,
     47                 n_jobs=-1,
     48                 return_estimator=False,
     49                 return_train_score=False,
---> 50                 verbose=0)
     51         score = np.mean(scores['test_score'])
     52         std = np.std(scores['test_score'])
     53         status = STATUS_OK
     54     except Exception as e:

...........................................................................
/home/aquemy/.local/lib/python2.7/site-packages/sklearn/model_selection/_validation.py in cross_validate(estimator=Pipeline(memory=None,
     steps=[('rebalance', ... random_state=42, verbose=0, warm_start=False))]), X=array([[5.1, 3.5, 1.4, 0.2],
       [4.9, 3. , 1....2, 3.4, 5.4, 2.3],
       [5.9, 3. , 5.1, 1.8]]), y=array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,... 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]), groups=None, scoring=None, cv=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1, verbose=0, fit_params=None, pre_dispatch='2*n_jobs', return_train_score=False, return_estimator=False, error_score='raise-deprecating')
    235         delayed(_fit_and_score)(
    236             clone(estimator), X, y, scorers, train, test, verbose, None,
    237             fit_params, return_train_score=return_train_score,
    238             return_times=True, return_estimator=return_estimator,
    239             error_score=error_score)
--> 240         for train, test in cv.split(X, y, groups))
        cv.split = <bound method StratifiedKFold.split of Stratifie...d(n_splits=10, random_state=None, shuffle=False)>
        X = array([[5.1, 3.5, 1.4, 0.2],
       [4.9, 3. , 1....2, 3.4, 5.4, 2.3],
       [5.9, 3. , 5.1, 1.8]])
        y = array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,... 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2])
        groups = None
    241 
    242     zipped_scores = list(zip(*scores))
    243     if return_train_score:
    244         train_scores = zipped_scores.pop(0)

...........................................................................
/home/aquemy/.local/lib/python2.7/site-packages/sklearn/externals/joblib/parallel.py in __call__(self=Parallel(n_jobs=-1), iterable=<generator object <genexpr>>)
    925                 # No need to wait for async callbacks to trigger to
    926                 # consumption.
    927                 self._iterating = False
    928 
    929             with self._backend.retrieval_context():
--> 930                 self.retrieve()
        self.retrieve = <bound method Parallel.retrieve of Parallel(n_jobs=-1)>
    931             # Make sure that we get a last message telling us we are done
    932             elapsed_time = time.time() - self._start_time
    933             self._print('Done %3i out of %3i | elapsed: %s finished',
    934                         (len(self._output), len(self._output),

---------------------------------------------------------------------------
Joblib worker traceback:
---------------------------------------------------------------------------
ValueError                                         Mon Jun 17 13:13:35 2019
PID: 21355                                  Python 2.7.15+: /usr/bin/python
...........................................................................
/home/aquemy/.local/lib/python2.7/site-packages/sklearn/externals/joblib/parallel.py in __call__(self=<sklearn.externals.joblib.parallel.BatchedCalls object>)
    220     def __call__(self):
    221         # Set the default nested backend to self._backend but do not set the
    222         # change the default number of processes to -1
    223         with parallel_backend(self._backend, n_jobs=self._n_jobs):
    224             return [func(*args, **kwargs)
--> 225                     for func, args, kwargs in self.items]
        func = <function _fit_and_score>
        args = (Pipeline(memory=None,
     steps=[('rebalance', ... random_state=42, verbose=0, warm_start=False))]), array([[5.1, 3.5, 1.4, 0.2],
       [4.9, 3. , 1....2, 3.4, 5.4, 2.3],
       [5.9, 3. , 5.1, 1.8]]), array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,... 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]), {'score': <function _passthrough_scorer>}, array([  5,   6,   7,   8,   9,  10,  11,  12,  ..., 142, 143, 144,
       145, 146, 147, 148, 149]), array([  0,   1,   2,   3,   4,  50,  51,  52,  53,  54, 100, 101, 102,
       103, 104]), 0, None, None)
        kwargs = {'error_score': 'raise-deprecating', 'return_estimator': False, 'return_times': True, 'return_train_score': False}
        self.items = [(<function _fit_and_score>, (Pipeline(memory=None,
     steps=[('rebalance', ... random_state=42, verbose=0, warm_start=False))]), array([[5.1, 3.5, 1.4, 0.2],
       [4.9, 3. , 1....2, 3.4, 5.4, 2.3],
       [5.9, 3. , 5.1, 1.8]]), array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,... 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]), {'score': <function _passthrough_scorer>}, array([  5,   6,   7,   8,   9,  10,  11,  12,  ..., 142, 143, 144,
       145, 146, 147, 148, 149]), array([  0,   1,   2,   3,   4,  50,  51,  52,  53,  54, 100, 101, 102,
       103, 104]), 0, None, None), {'error_score': 'raise-deprecating', 'return_estimator': False, 'return_times': True, 'return_train_score': False})]
    226 
    227     def __len__(self):
    228         return self._size
    229 

...........................................................................
/home/aquemy/.local/lib/python2.7/site-packages/sklearn/model_selection/_validation.py in _fit_and_score(estimator=Pipeline(memory=None,
     steps=[('rebalance', ... random_state=42, verbose=0, warm_start=False))]), X=array([[5.1, 3.5, 1.4, 0.2],
       [4.9, 3. , 1....2, 3.4, 5.4, 2.3],
       [5.9, 3. , 5.1, 1.8]]), y=array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,... 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]), scorer={'score': <function _passthrough_scorer>}, train=array([  5,   6,   7,   8,   9,  10,  11,  12,  ..., 142, 143, 144,
       145, 146, 147, 148, 149]), test=array([  0,   1,   2,   3,   4,  50,  51,  52,  53,  54, 100, 101, 102,
       103, 104]), verbose=0, parameters=None, fit_params={}, return_train_score=False, return_parameters=False, return_n_test_samples=False, return_times=True, return_estimator=False, error_score='raise-deprecating')
    523 
    524     try:
    525         if y_train is None:
    526             estimator.fit(X_train, **fit_params)
    527         else:
--> 528             estimator.fit(X_train, y_train, **fit_params)
        estimator.fit = <bound method Pipeline.fit of Pipeline(memory=No...random_state=42, verbose=0, warm_start=False))])>
        X_train = array([[5.4, 3.9, 1.7, 0.4],
       [4.6, 3.4, 1....2, 3.4, 5.4, 2.3],
       [5.9, 3. , 5.1, 1.8]])
        y_train = array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,
       2, 2, 2])
        fit_params = {}
    529 
    530     except Exception as e:
    531         # Note fit time as time until error
    532         fit_time = time.time() - start_time

...........................................................................
/usr/local/lib/python2.7/dist-packages/imblearn/pipeline.py in fit(self=Pipeline(memory=None,
     steps=[('rebalance', ... random_state=42, verbose=0, warm_start=False))]), X=array([[5.4, 3.9, 1.7, 0.4],
       [4.6, 3.4, 1....2, 3.4, 5.4, 2.3],
       [5.9, 3. , 5.1, 1.8]]), y=array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,
       2, 2, 2]), **fit_params={})
    234             This estimator
    235 
    236         """
    237         Xt, yt, fit_params = self._fit(X, y, **fit_params)
    238         if self._final_estimator is not None:
--> 239             self._final_estimator.fit(Xt, yt, **fit_params)
        self._final_estimator.fit = <bound method RandomForestClassifier.fit of Rand...e, random_state=42, verbose=0, warm_start=False)>
        Xt = array([[-0.58705445],
       [-2.25245798],
    ...52],
       [25.60235462],
       [14.75364619]])
        yt = array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...0, 0, 0, 0, 0, 0, 0, 0,
       0, 1, 1, 2, 2, 2])
        fit_params = {}
    240         return self
    241 
    242     def fit_transform(self, X, y=None, **fit_params):
    243         """Fit the model and transform with the final estimator

...........................................................................
/home/aquemy/.local/lib/python2.7/site-packages/sklearn/ensemble/forest.py in fit(self=RandomForestClassifier(bootstrap=True, class_wei...se, random_state=42, verbose=0, warm_start=False), X=array([[-0.58705443],
       [-2.252458  ],
    ....602354  ],
       [14.753646  ]], dtype=float32), y=array([[0.],
       [0.],
       [0.],
       [0...    [1.],
       [2.],
       [2.],
       [2.]]), sample_weight=None)
    328             trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,
    329                              **_joblib_parallel_args(prefer='threads'))(
    330                 delayed(_parallel_build_trees)(
    331                     t, self, X, y, sample_weight, i, len(trees),
    332                     verbose=self.verbose, class_weight=self.class_weight)
--> 333                 for i, t in enumerate(trees))
        i = 99
    334 
    335             # Collect newly grown trees
    336             self.estimators_.extend(trees)
    337 

...........................................................................
/home/aquemy/.local/lib/python2.7/site-packages/sklearn/externals/joblib/parallel.py in __call__(self=Parallel(n_jobs=1), iterable=<generator object <genexpr>>)
    912             # self._original_iterator is None, then this means either
    913             # that pre_dispatch == "all", n_jobs == 1 or that the first batch
    914             # was very quick and its callback already dispatched all the
    915             # remaining jobs.
    916             self._iterating = False
--> 917             if self.dispatch_one_batch(iterator):
        self.dispatch_one_batch = <bound method Parallel.dispatch_one_batch of Parallel(n_jobs=1)>
        iterator = <generator object <genexpr>>
    918                 self._iterating = self._original_iterator is not None
    919 
    920             while self.dispatch_one_batch(iterator):
    921                 pass

...........................................................................
/home/aquemy/.local/lib/python2.7/site-packages/sklearn/externals/joblib/parallel.py in dispatch_one_batch(self=Parallel(n_jobs=1), iterator=<generator object <genexpr>>)
    754                                  self._pickle_cache)
    755             if len(tasks) == 0:
    756                 # No more tasks available in the iterator: tell caller to stop.
    757                 return False
    758             else:
--> 759                 self._dispatch(tasks)
        self._dispatch = <bound method Parallel._dispatch of Parallel(n_jobs=1)>
        tasks = <sklearn.externals.joblib.parallel.BatchedCalls object>
    760                 return True
    761 
    762     def _print(self, msg, msg_args):
    763         """Display the message on stout or stderr depending on verbosity"""

...........................................................................
/home/aquemy/.local/lib/python2.7/site-packages/sklearn/externals/joblib/parallel.py in _dispatch(self=Parallel(n_jobs=1), batch=<sklearn.externals.joblib.parallel.BatchedCalls object>)
    711 
    712         dispatch_timestamp = time.time()
    713         cb = BatchCompletionCallBack(dispatch_timestamp, len(batch), self)
    714         with self._lock:
    715             job_idx = len(self._jobs)
--> 716             job = self._backend.apply_async(batch, callback=cb)
        job = undefined
        self._backend.apply_async = <bound method SequentialBackend.apply_async of <...lib._parallel_backends.SequentialBackend object>>
        batch = <sklearn.externals.joblib.parallel.BatchedCalls object>
        cb = <sklearn.externals.joblib.parallel.BatchCompletionCallBack object>
    717             # A job can complete so quickly than its callback is
    718             # called before we get here, causing self._jobs to
    719             # grow. To ensure correct results ordering, .insert is
    720             # used (rather than .append) in the following line

...........................................................................
/home/aquemy/.local/lib/python2.7/site-packages/sklearn/externals/joblib/_parallel_backends.py in apply_async(self=<sklearn.externals.joblib._parallel_backends.SequentialBackend object>, func=<sklearn.externals.joblib.parallel.BatchedCalls object>, callback=<sklearn.externals.joblib.parallel.BatchCompletionCallBack object>)
    177             raise ValueError('n_jobs == 0 in Parallel has no meaning')
    178         return 1
    179 
    180     def apply_async(self, func, callback=None):
    181         """Schedule a func to be run"""
--> 182         result = ImmediateResult(func)
        result = undefined
        func = <sklearn.externals.joblib.parallel.BatchedCalls object>
    183         if callback:
    184             callback(result)
    185         return result
    186 

...........................................................................
/home/aquemy/.local/lib/python2.7/site-packages/sklearn/externals/joblib/_parallel_backends.py in __init__(self=<sklearn.externals.joblib._parallel_backends.ImmediateResult object>, batch=<sklearn.externals.joblib.parallel.BatchedCalls object>)
    544 
    545 class ImmediateResult(object):
    546     def __init__(self, batch):
    547         # Don't delay the application, to avoid keeping the input
    548         # arguments in memory
--> 549         self.results = batch()
        self.results = undefined
        batch = <sklearn.externals.joblib.parallel.BatchedCalls object>
    550 
    551     def get(self):
    552         return self.results
    553 

...........................................................................
/home/aquemy/.local/lib/python2.7/site-packages/sklearn/externals/joblib/parallel.py in __call__(self=<sklearn.externals.joblib.parallel.BatchedCalls object>)
    220     def __call__(self):
    221         # Set the default nested backend to self._backend but do not set the
    222         # change the default number of processes to -1
    223         with parallel_backend(self._backend, n_jobs=self._n_jobs):
    224             return [func(*args, **kwargs)
--> 225                     for func, args, kwargs in self.items]
        func = <function _parallel_build_trees>
        args = (DecisionTreeClassifier(class_weight=None, criter...=False, random_state=1608637542, splitter='best'), RandomForestClassifier(bootstrap=True, class_wei...se, random_state=42, verbose=0, warm_start=False), array([[-0.58705443],
       [-2.252458  ],
    ....602354  ],
       [14.753646  ]], dtype=float32), array([[0.],
       [0.],
       [0.],
       [0...    [1.],
       [2.],
       [2.],
       [2.]]), None, 0, 100)
        kwargs = {'class_weight': None, 'verbose': 0}
        self.items = [(<function _parallel_build_trees>, (DecisionTreeClassifier(class_weight=None, criter...=False, random_state=1608637542, splitter='best'), RandomForestClassifier(bootstrap=True, class_wei...se, random_state=42, verbose=0, warm_start=False), array([[-0.58705443],
       [-2.252458  ],
    ....602354  ],
       [14.753646  ]], dtype=float32), array([[0.],
       [0.],
       [0.],
       [0...    [1.],
       [2.],
       [2.],
       [2.]]), None, 0, 100), {'class_weight': None, 'verbose': 0})]
    226 
    227     def __len__(self):
    228         return self._size
    229 

...........................................................................
/home/aquemy/.local/lib/python2.7/site-packages/sklearn/ensemble/forest.py in _parallel_build_trees(tree=DecisionTreeClassifier(class_weight=None, criter...=False, random_state=1608637542, splitter='best'), forest=RandomForestClassifier(bootstrap=True, class_wei...se, random_state=42, verbose=0, warm_start=False), X=array([[-0.58705443],
       [-2.252458  ],
    ....602354  ],
       [14.753646  ]], dtype=float32), y=array([[0.],
       [0.],
       [0.],
       [0...    [1.],
       [2.],
       [2.],
       [2.]]), sample_weight=None, tree_idx=0, n_trees=100, verbose=0, class_weight=None)
    114                 simplefilter('ignore', DeprecationWarning)
    115                 curr_sample_weight *= compute_sample_weight('auto', y, indices)
    116         elif class_weight == 'balanced_subsample':
    117             curr_sample_weight *= compute_sample_weight('balanced', y, indices)
    118 
--> 119         tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)
        tree.fit = <bound method DecisionTreeClassifier.fit of Deci...False, random_state=1608637542, splitter='best')>
        X = array([[-0.58705443],
       [-2.252458  ],
    ....602354  ],
       [14.753646  ]], dtype=float32)
        y = array([[0.],
       [0.],
       [0.],
       [0...    [1.],
       [2.],
       [2.],
       [2.]])
        sample_weight = None
        curr_sample_weight = array([2., 0., 2., 1., 2., 0., 1., 2., 1., 1., 2... 0., 2., 0., 5., 0., 2., 0., 0., 1., 0., 0., 3.])
    120     else:
    121         tree.fit(X, y, sample_weight=sample_weight, check_input=False)
    122 
    123     return tree

...........................................................................
/home/aquemy/.local/lib/python2.7/site-packages/sklearn/tree/tree.py in fit(self=DecisionTreeClassifier(class_weight=None, criter...=False, random_state=1608637542, splitter='best'), X=array([[-0.58705443],
       [-2.252458  ],
    ....602354  ],
       [14.753646  ]], dtype=float32), y=array([[0.],
       [0.],
       [0.],
       [0...    [1.],
       [2.],
       [2.],
       [2.]]), sample_weight=array([2., 0., 2., 1., 2., 0., 1., 2., 1., 1., 2... 0., 2., 0., 5., 0., 2., 0., 0., 1., 0., 0., 3.]), check_input=False, X_idx_sorted=None)
    796 
    797         super(DecisionTreeClassifier, self).fit(
    798             X, y,
    799             sample_weight=sample_weight,
    800             check_input=check_input,
--> 801             X_idx_sorted=X_idx_sorted)
        X_idx_sorted = None
    802         return self
    803 
    804     def predict_proba(self, X, check_input=True):
    805         """Predict class probabilities of the input samples X.

...........................................................................
/home/aquemy/.local/lib/python2.7/site-packages/sklearn/tree/tree.py in fit(self=DecisionTreeClassifier(class_weight=None, criter...=False, random_state=1608637542, splitter='best'), X=array([[-0.58705443],
       [-2.252458  ],
    ....602354  ],
       [14.753646  ]], dtype=float32), y=array([[0.],
       [0.],
       [0.],
       [0...    [1.],
       [2.],
       [2.],
       [2.]]), sample_weight=array([2., 0., 2., 1., 2., 0., 1., 2., 1., 1., 2... 0., 2., 0., 5., 0., 2., 0., 0., 1., 0., 0., 3.]), check_input=False, X_idx_sorted=None)
    237         if not 0 <= self.min_weight_fraction_leaf <= 0.5:
    238             raise ValueError("min_weight_fraction_leaf must in [0, 0.5]")
    239         if max_depth <= 0:
    240             raise ValueError("max_depth must be greater than zero. ")
    241         if not (0 < max_features <= self.n_features_):
--> 242             raise ValueError("max_features must be in (0, n_features]")
    243         if not isinstance(max_leaf_nodes, (numbers.Integral, np.integer)):
    244             raise ValueError("max_leaf_nodes must be integral number but was "
    245                              "%r" % max_leaf_nodes)
    246         if -1 < max_leaf_nodes < 2:

ValueError: max_features must be in (0, n_features]
___________________________________________________________________________
Best score: 0.966666666667 (0.0333333333333) [J] | Score: 0.0 (0.0) [J]
Best score: 0.966666666667 (0.0333333333333) [J] | Score: 0.913333333333 (0.0991071249821) [J]
Best score: 0.966666666667 (0.0333333333333) [J] | Score: 0.873333333333 (0.0553774924195) [J]
Best score: 0.966666666667 (0.0333333333333) [J] | Score: 0.946666666667 (0.0581186525805) [J]
Best score: 0.966666666667 (0.0333333333333) [J] | Score: 0.733333333333 (0.171269767716) [J]
Best score: 0.966666666667 (0.0333333333333) [J] | Score: 0.96 (0.0442216638714) [J]
Best score: 0.966666666667 (0.0333333333333) [J] | Score: 0.64 (0.0742368581711) [J]
Best score: 0.966666666667 (0.0333333333333) [J] | Score: 0.886666666667 (0.06) [J]
Best score: 0.966666666667 (0.0333333333333) [J] | Score: 0.933333333333 (0.0596284794) [J]
Best score: 0.966666666667 (0.0333333333333) [J] | Score: 0.88 (0.0884433277428) [J]
Best score: 0.966666666667 (0.0333333333333) [J] | Score: 0.68 (0.04) [J]
Best score: 0.966666666667 (0.0333333333333) [J] | Score: 0.946666666667 (0.049888765157) [J]
Best score: 0.966666666667 (0.0333333333333) [J] | Score: 0.946666666667 (0.0581186525805) [J]
JoblibValueError
___________________________________________________________________________
...........................................................................
/home/aquemy/dev/dp_hyperparameters/extension/main.py in <module>()
     27 
     28     serializer.serialize_results(scenario, policy)
     29 
     30 if __name__ == "__main__":
     31     args = cli.parse_args()
---> 32     main(args)

...........................................................................
/home/aquemy/dev/dp_hyperparameters/extension/main.py in main(args=Namespace(customize=[(['control', 'seed'], '42')...io='./scenarios/rf_iris_joint.yaml', verbosity=0))
     21         test_size=0.4, 
     22         random_state=scenario['control']['seed']
     23     )
     24 
     25     policy = policies.initiate(scenario['setup']['policy'], config)
---> 26     policy.run(X,y)
        policy.run = <bound method Joint.run of <experiment.policies.joint.Joint object>>
        X = array([[5.1, 3.5, 1.4, 0.2],
       [4.9, 3. , 1....2, 3.4, 5.4, 2.3],
       [5.9, 3. , 5.1, 1.8]])
        y = array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,... 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2])
     27 
     28     serializer.serialize_results(scenario, policy)
     29 
     30 if __name__ == "__main__":

...........................................................................
/home/aquemy/dev/dp_hyperparameters/extension/experiment/policies/joint.py in run(self=<experiment.policies.joint.Joint object>, X=array([[5.1, 3.5, 1.4, 0.2],
       [4.9, 3. , 1....2, 3.4, 5.4, 2.3],
       [5.9, 3. , 5.1, 1.8]]), y=array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,... 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]))
     32             algo=tpe.suggest, 
     33             max_evals=None,
     34             max_time=self.config['time'],     
     35             trials=trials,
     36             show_progressbar=False,
---> 37             verbose=0
     38         )
     39 
     40         best_config = self.context['best_config']
     41         super(Joint, self).display_step_results(best_config)

...........................................................................
/home/aquemy/dev/dp_hyperparameters/extension/hyperopt/fmin.py in fmin(fn=<functools.partial object>, space={'algorithm': {'bootstrap': <hyperopt.pyll.base.Apply object>, 'criterion': <hyperopt.pyll.base.Apply object>, 'max_depth': <hyperopt.pyll.base.Apply object>, 'max_features': <hyperopt.pyll.base.Apply object>, 'max_leaf_nodes': <hyperopt.pyll.base.Apply object>, 'min_samples_split': <hyperopt.pyll.base.Apply object>, 'n_estimators': <hyperopt.pyll.base.Apply object>}, 'pipeline': {'features': <hyperopt.pyll.base.Apply object>, 'normalizer': <hyperopt.pyll.base.Apply object>, 'rebalance': <hyperopt.pyll.base.Apply object>}}, algo=<function suggest>, max_evals=9223372036854775807, max_time=300, trials=<hyperopt.base.Trials object>, rstate=<mtrand.RandomState object>, allow_trials_fmin=True, pass_expr_memo_ctrl=None, catch_eval_exceptions=False, verbose=0, return_argmin=True, points_to_evaluate=None, max_queue_len=1, show_progressbar=False)
    406             pass_expr_memo_ctrl=pass_expr_memo_ctrl,
    407             verbose=verbose,
    408             catch_eval_exceptions=catch_eval_exceptions,
    409             return_argmin=return_argmin,
    410             show_progressbar=show_progressbar,
--> 411             max_time=max_time
        max_time = 300
    412         )
    413 
    414     if trials is None:
    415         if points_to_evaluate is None:

...........................................................................
/home/aquemy/dev/dp_hyperparameters/extension/hyperopt/base.py in fmin(self=<hyperopt.base.Trials object>, fn=<functools.partial object>, space={'algorithm': {'bootstrap': <hyperopt.pyll.base.Apply object>, 'criterion': <hyperopt.pyll.base.Apply object>, 'max_depth': <hyperopt.pyll.base.Apply object>, 'max_features': <hyperopt.pyll.base.Apply object>, 'max_leaf_nodes': <hyperopt.pyll.base.Apply object>, 'min_samples_split': <hyperopt.pyll.base.Apply object>, 'n_estimators': <hyperopt.pyll.base.Apply object>}, 'pipeline': {'features': <hyperopt.pyll.base.Apply object>, 'normalizer': <hyperopt.pyll.base.Apply object>, 'rebalance': <hyperopt.pyll.base.Apply object>}}, algo=<function suggest>, max_evals=9223372036854775807, max_time=300, rstate=<mtrand.RandomState object>, verbose=0, pass_expr_memo_ctrl=None, catch_eval_exceptions=False, return_argmin=True, show_progressbar=False)
    636             verbose=verbose,
    637             allow_trials_fmin=False,  # -- prevent recursion
    638             pass_expr_memo_ctrl=pass_expr_memo_ctrl,
    639             catch_eval_exceptions=catch_eval_exceptions,
    640             return_argmin=return_argmin,
--> 641             show_progressbar=show_progressbar)
        show_progressbar = False
    642 
    643 
    644 def trials_from_docs(docs, validate=True, **kwargs):
    645     """Construct a Trials base class instance from a list of trials documents

...........................................................................
/home/aquemy/dev/dp_hyperparameters/extension/hyperopt/fmin.py in fmin(fn=<functools.partial object>, space={'algorithm': {'bootstrap': <hyperopt.pyll.base.Apply object>, 'criterion': <hyperopt.pyll.base.Apply object>, 'max_depth': <hyperopt.pyll.base.Apply object>, 'max_features': <hyperopt.pyll.base.Apply object>, 'max_leaf_nodes': <hyperopt.pyll.base.Apply object>, 'min_samples_split': <hyperopt.pyll.base.Apply object>, 'n_estimators': <hyperopt.pyll.base.Apply object>}, 'pipeline': {'features': <hyperopt.pyll.base.Apply object>, 'normalizer': <hyperopt.pyll.base.Apply object>, 'rebalance': <hyperopt.pyll.base.Apply object>}}, algo=<function suggest>, max_evals=9223372036854775807, max_time=300, trials=<hyperopt.base.Trials object>, rstate=<mtrand.RandomState object>, allow_trials_fmin=False, pass_expr_memo_ctrl=None, catch_eval_exceptions=False, verbose=0, return_argmin=True, points_to_evaluate=None, max_queue_len=1, show_progressbar=False)
    426                     verbose=verbose,
    427                     max_queue_len=max_queue_len,
    428                     show_progressbar=show_progressbar,
    429                     max_time=max_time)
    430     rval.catch_eval_exceptions = catch_eval_exceptions
--> 431     rval.exhaust()
        rval.exhaust = <bound method FMinIter.exhaust of <hyperopt.fmin.FMinIter object>>
    432     if return_argmin:
    433         return trials.argmin
    434     elif len(trials) > 0:
    435         # Only if there are some succesfull trail runs, return the best point in the evaluation space

...........................................................................
/home/aquemy/dev/dp_hyperparameters/extension/hyperopt/fmin.py in exhaust(self=<hyperopt.fmin.FMinIter object>)
    273             raise StopIteration()
    274         return self.trials
    275 
    276     def exhaust(self):
    277         n_done = len(self.trials)
--> 278         self.run(self.max_evals - n_done, block_until_done=self.asynchronous)
        self.run = <bound method FMinIter.run of <hyperopt.fmin.FMinIter object>>
        self.max_evals = 9223372036854775807
        n_done = 0
        self.asynchronous = False
    279         self.trials.refresh()
    280         return self
    281 
    282 

...........................................................................
/home/aquemy/dev/dp_hyperparameters/extension/hyperopt/fmin.py in run(self=<hyperopt.fmin.FMinIter object>, N=9223372036854775807, block_until_done=False)
    232                     if self.asynchronous:
    233                         # -- wait for workers to fill in the trials
    234                         time.sleep(self.poll_interval_secs)
    235                     else:
    236                         # -- loop over trials and do the jobs directly
--> 237                         self.serial_evaluate()
        self.serial_evaluate = <bound method FMinIter.serial_evaluate of <hyperopt.fmin.FMinIter object>>
    238                     try:
    239                         res = [d['result']['loss'] for d in
    240                                          self.trials.trials if
    241                                          d['result']['status'] == 'ok']

...........................................................................
/home/aquemy/dev/dp_hyperparameters/extension/hyperopt/fmin.py in serial_evaluate(self=<hyperopt.fmin.FMinIter object>, N=-1)
    138                 trial['book_time'] = now
    139                 trial['refresh_time'] = now
    140                 spec = base.spec_from_misc(trial['misc'])
    141                 ctrl = base.Ctrl(self.trials, current_trial=trial)
    142                 try:
--> 143                     result = self.domain.evaluate(spec, ctrl)
        result = undefined
        self.domain.evaluate = <bound method Domain.evaluate of <hyperopt.base.Domain object>>
        spec = {'bootstrap': 0, 'criterion': 0, 'features': 1, 'features_PCA_features__n_components': 0, 'max_depth': 3, 'max_features': 2, 'max_leaf_nodes': 2, 'min_samples_split': 1, 'n_estimators': 0, 'normalizer': 2, ...}
        ctrl = <hyperopt.base.Ctrl object>
    144                 except Exception as e:
    145                     logger.info('job exception: %s' % str(e))
    146                     trial['state'] = base.JOB_STATE_ERROR
    147                     trial['misc']['error'] = (str(type(e)), str(e))

...........................................................................
/home/aquemy/dev/dp_hyperparameters/extension/hyperopt/base.py in evaluate(self=<hyperopt.base.Domain object>, config={'bootstrap': 0, 'criterion': 0, 'features': 1, 'features_PCA_features__n_components': 0, 'max_depth': 3, 'max_features': 2, 'max_leaf_nodes': 2, 'min_samples_split': 1, 'n_estimators': 0, 'normalizer': 2, ...}, ctrl=<hyperopt.base.Ctrl object>, attach_attachments=True)
    841             #    or the normal Python part (self.fn)
    842             pyll_rval = pyll.rec_eval(
    843                 self.expr,
    844                 memo=memo,
    845                 print_node_on_error=self.rec_eval_print_node_on_error)
--> 846             rval = self.fn(pyll_rval)
        rval = undefined
        self.fn = <functools.partial object>
        pyll_rval = {'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': 4, 'max_features': 3, 'max_leaf_nodes': 5, 'min_samples_split': 3, 'n_estimators': 10}, 'pipeline': {'features': ('features_PCA', {'features__n_components': 1}), 'normalizer': ('normalizer_PowerTransformer', {}), 'rebalance': ('rebalance_CondensedNearestNeighbour', {'rebalance__n_neighbors': 1})}}
    847 
    848         if isinstance(rval, (float, int, np.number)):
    849             dict_rval = {'loss': float(rval), 'status': STATUS_OK}
    850         else:

...........................................................................
/home/aquemy/dev/dp_hyperparameters/extension/experiment/objective.py in objective_joint(wconfig={'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': 4, 'max_features': 3, 'max_leaf_nodes': 5, 'min_samples_split': 3, 'n_estimators': 10}, 'pipeline': {'features': ('features_PCA', {'features__n_components': 1}), 'normalizer': ('normalizer_PowerTransformer', {}), 'rebalance': ('rebalance_CondensedNearestNeighbour', {'rebalance__n_neighbors': 1})}}, algorithm='RandomForest', X=array([[5.1, 3.5, 1.4, 0.2],
       [4.9, 3. , 1....2, 3.4, 5.4, 2.3],
       [5.9, 3. , 5.1, 1.8]]), y=array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,... 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]), context={'baseline_score': 0.9466666666666667, 'baseline_score_std': 0.04988876515698587, 'best_config': {'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': 4, 'max_features': 3, 'max_leaf_nodes': 3, 'min_samples_split': 3, 'n_estimators': 10}, 'config_hash': {'algorithm': 'ffb7ff225ce3d3712c96cf87fe42202988ee2eb0', 'config': 'bae32f426be9cd6243523c023944a8c148fe4aeb', 'pipeline': 'd2a68bfda6fcdec4ae0ffc7d7b6a2122bc1cd673'}, 'duration': 0.7115809917449951, 'iteration': 113, 'loss': 0.033333333333333215, 'max_history_score': 0.9666666666666668, 'max_history_score_std': 0.033333333333333326, 'max_history_step': 'joint', 'pipeline': {'features': ('features_NoneType', {}), 'normalizer': ('normalizer_PowerTransformer', {}), 'rebalance': ('rebalance_CondensedNearestNeighbour', {'rebalance__n_neighbors': 2})}, 'score': 0.9666666666666668, ...}, 'history': [{'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': 2, 'max_features': None, 'max_leaf_nodes': 5, 'min_samples_split': 2, 'n_estimators': 75}, 'config_hash': {'algorithm': '3af5b0cce71c8fe2545246ca24ff5bc3dd516e06', 'config': 'db6ac7e6d348155757e4794bb5f88fe2b4f63d50', 'pipeline': '8d59f4b94cef6be9306ed86a22a9570fa670d567'}, 'duration': 1.149928092956543, 'iteration': 0, 'loss': 0.046666666666666634, 'max_history_score': 0.9533333333333334, 'max_history_score_std': 0.059999999999999984, 'max_history_step': 'joint', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 4, 'features__selectkbest__k': 3}), 'normalizer': ('normalizer_StandardScaler', {'normalizer__with_mean': True, 'normalizer__with_std': True}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 6})}, 'score': 0.9533333333333334, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': 1, 'max_features': 2, 'max_leaf_nodes': 2, 'min_samples_split': 5, 'n_estimators': 100}, 'config_hash': {'algorithm': 'e13eb05fd9a62d2f63bbb1c1deff0cd620d5e6ab', 'config': '4db6fb84d85f52659f780e682ffac5712c3d8a94', 'pipeline': '64c9a1ca9d53ae67244bdd942f4db36a3c05218c'}, 'duration': 1.7678282260894775, 'iteration': 1, 'loss': 0.18000000000000005, 'max_history_score': 0.9533333333333334, 'max_history_score_std': 0.059999999999999984, 'max_history_step': 'joint', 'pipeline': {'features': ('features_NoneType', {}), 'normalizer': ('normalizer_PowerTransformer', {}), 'rebalance': ('rebalance_NearMiss', {'rebalance__n_neighbors': 1})}, 'score': 0.82, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': 1, 'max_features': None, 'max_leaf_nodes': None, 'min_samples_split': 5, 'n_estimators': 75}, 'config_hash': {'algorithm': '94b0d7a654c508cc63643f78fe4f0f07e6f07c1e', 'config': '4403c5a85e951938d3c454e961d3a412780722f6', 'pipeline': '3e47444880d8367fbac2faaba2e52a917274aa58'}, 'duration': 0.8397619724273682, 'iteration': 2, 'loss': 0.03333333333333344, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_PCA', {'features__n_components': 3}), 'normalizer': ('normalizer_MinMaxScaler', {}), 'rebalance': ('rebalance_NoneType', {})}, 'score': 0.9666666666666666, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': None, 'max_features': None, 'max_leaf_nodes': 3, 'min_samples_split': 3, 'n_estimators': 75}, 'config_hash': {'algorithm': 'e8332f0a8902bda03bf70e7978cc5d52affb29d3', 'config': 'a064e2df18ab98d44dabcefbc7bed94913f1d0be', 'pipeline': '7eea819c2a8c103c4b1e9e9c1e224aebba95081f'}, 'duration': 0.8501448631286621, 'iteration': 3, 'loss': 0.053333333333333344, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 2, 'features__selectkbest__k': 4}), 'normalizer': ('normalizer_NoneType', {}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 7})}, 'score': 0.9466666666666667, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'entropy', 'max_depth': 3, 'max_features': 3, 'max_leaf_nodes': None, 'min_samples_split': 5, 'n_estimators': 75}, 'config_hash': {'algorithm': '7a4491035bc6bd737fe9a8cda8a79a02d02d5c74', 'config': '0ddb6f5cab3db4dddd7682966a57205f3e329ad4', 'pipeline': 'a9ae03fe38334f6868cbf84cdd3d629d4bbe3fb0'}, 'duration': 1.1026010513305664, 'iteration': 4, 'loss': 0.05999999999999994, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 2, 'features__selectkbest__k': 1}), 'normalizer': ('normalizer_NoneType', {}), 'rebalance': ('rebalance_NoneType', {})}, 'score': 0.9400000000000001, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'gini', 'max_depth': 3, 'max_features': 1, 'max_leaf_nodes': 5, 'min_samples_split': 2, 'n_estimators': 25}, 'config_hash': {'algorithm': '9826d20b2d6a0f559cf7f16450ce7526f07e8434', 'config': '49f25751bca61cdd461a8cbd2923689b642f98ed', 'pipeline': '19b249664c5bf067de1fed4334a296f947ce774a'}, 'duration': 0.35647010803222656, 'iteration': 5, 'loss': 0.046666666666666634, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_NoneType', {}), 'normalizer': ('normalizer_NoneType', {}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 6})}, 'score': 0.9533333333333334, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'gini', 'max_depth': 2, 'max_features': 1, 'max_leaf_nodes': 2, 'min_samples_split': 2, 'n_estimators': 50}, 'config_hash': {'algorithm': '0a4f6fbb07e0f32c6f675489a0fc82eee05bd8e1', 'config': '5c3a2b6f5e63fb45f10e41e0318b354912ec44f6', 'pipeline': 'dc3b9f176f090005e38b142f11d80e93a7dc5d5e'}, 'duration': 0.7213859558105469, 'iteration': 6, 'loss': 0.31333333333333324, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 1, 'features__selectkbest__k': 4}), 'normalizer': ('normalizer_PowerTransformer', {}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 7})}, 'score': 0.6866666666666668, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'entropy', 'max_depth': 4, 'max_features': 3, 'max_leaf_nodes': 5, 'min_samples_split': 5, 'n_estimators': 10}, 'config_hash': {'algorithm': 'b8112b97ecfc10f00a195af661dcc861cac21289', 'config': 'd3b129b397350f1b6572651c67c01de49b4b174c', 'pipeline': '5b0357ed7072c37b3d6f458bb5d49ff7d825f603'}, 'duration': 0.8299109935760498, 'iteration': 7, 'loss': 1.0, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_PCA', {'features__n_components': 2}), 'normalizer': ('normalizer_StandardScaler', {'normalizer__with_mean': True, 'normalizer__with_std': False}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 6})}, 'score': 0.0, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'gini', 'max_depth': 4, 'max_features': None, 'max_leaf_nodes': 2, 'min_samples_split': 5, 'n_estimators': 100}, 'config_hash': {'algorithm': '40ca24df19b8d164d9d098a6bed1ce056fbbb961', 'config': '813bde1108cc3c4b9bfb3a22cbb421bda7eac671', 'pipeline': '74a7b8705a1c22f7dea5e44e4ebda8f1e48add71'}, 'duration': 2.2111589908599854, 'iteration': 8, 'loss': 0.33333333333333326, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_PCA', {'features__n_components': 2}), 'normalizer': ('normalizer_StandardScaler', {'normalizer__with_mean': False, 'normalizer__with_std': True}), 'rebalance': ('rebalance_NearMiss', {'rebalance__n_neighbors': 2})}, 'score': 0.6666666666666667, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'entropy', 'max_depth': 2, 'max_features': 1, 'max_leaf_nodes': 5, 'min_samples_split': 2, 'n_estimators': 100}, 'config_hash': {'algorithm': '331418a5c12cf1453876eef85e9d98fc8e54fa11', 'config': '31930b6860ed406d59bf7e59ba1925d94704bd3b', 'pipeline': '054bef356f90ec6f644ef3ffc688766744db51c2'}, 'duration': 1.0501940250396729, 'iteration': 9, 'loss': 0.053333333333333344, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_SelectKBest', {'features__k': 1}), 'normalizer': ('normalizer_RobustScaler', {'normalizer__quantile_range': (...), 'normalizer__with_centering': True, 'normalizer__with_scaling': True}), 'rebalance': ('rebalance_NearMiss', {'rebalance__n_neighbors': 2})}, 'score': 0.9466666666666667, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'entropy', 'max_depth': 3, 'max_features': None, 'max_leaf_nodes': 3, 'min_samples_split': 2, 'n_estimators': 100}, 'config_hash': {'algorithm': 'dbc1b8126649fe93dce5fbb37e4015b0acfb179e', 'config': '9913cd550615a9d0946ab4a755a8b9f619e442fd', 'pipeline': 'dd626121cea079ebb32e184ca65483ec7a6d7f59'}, 'duration': 1.120617151260376, 'iteration': 10, 'loss': 0.046666666666666634, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 2, 'features__selectkbest__k': 1}), 'normalizer': ('normalizer_MinMaxScaler', {}), 'rebalance': ('rebalance_NoneType', {})}, 'score': 0.9533333333333334, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'gini', 'max_depth': 3, 'max_features': 3, 'max_leaf_nodes': None, 'min_samples_split': 3, 'n_estimators': 75}, 'config_hash': {'algorithm': '34917a130df5a975f78bd7ec1a0c7b1ffdc787a9', 'config': '95fc8cadc088141290b7de9c388977e4685f0108', 'pipeline': '550d10faf2f08db48516cc3501558816d6a99bc0'}, 'duration': 1.4287099838256836, 'iteration': 11, 'loss': 0.19333333333333313, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 3, 'features__selectkbest__k': 4}), 'normalizer': ('normalizer_StandardScaler', {'normalizer__with_mean': False, 'normalizer__with_std': False}), 'rebalance': ('rebalance_CondensedNearestNeighbour', {'rebalance__n_neighbors': 1})}, 'score': 0.8066666666666669, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'entropy', 'max_depth': 1, 'max_features': 2, 'max_leaf_nodes': 5, 'min_samples_split': 2, 'n_estimators': 75}, 'config_hash': {'algorithm': '33f9abb4aee44a395a9f3b3ffa9ce80a8cdaed7c', 'config': '40fa726f0360cf6af55f9b5902d399d02f61f157', 'pipeline': 'cfd1d20841fe2153da762c95e79f95a3fb1e426a'}, 'duration': 1.2978079319000244, 'iteration': 12, 'loss': 0.053333333333333344, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_PCA', {'features__n_components': 4}), 'normalizer': ('normalizer_MinMaxScaler', {}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 7})}, 'score': 0.9466666666666667, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'entropy', 'max_depth': 4, 'max_features': 2, 'max_leaf_nodes': 5, 'min_samples_split': 3, 'n_estimators': 25}, 'config_hash': {'algorithm': '210111ec6562d09eb093e98ed69ef1c662e11a50', 'config': '0fb8e77c7bd9a58b72f1b33c21a59a09a8c676ba', 'pipeline': '5d269d759e0c7926a685a14b263ace8ae0071e4b'}, 'duration': 0.36649012565612793, 'iteration': 13, 'loss': 0.040000000000000036, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 2, 'features__selectkbest__k': 2}), 'normalizer': ('normalizer_NoneType', {}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 7})}, 'score': 0.96, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'entropy', 'max_depth': 3, 'max_features': 1, 'max_leaf_nodes': 5, 'min_samples_split': 2, 'n_estimators': 25}, 'config_hash': {'algorithm': '0e989a03980101fabf79eda3326ed2870e11d690', 'config': 'f4bffd5d8c67a9c5321a9943c4a99678f59a02b7', 'pipeline': '865ee1e3fe8334c3d5ecb2038d5a5d1b3ba50e75'}, 'duration': 0.35639500617980957, 'iteration': 14, 'loss': 0.046666666666666634, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_NoneType', {}), 'normalizer': ('normalizer_RobustScaler', {'normalizer__quantile_range': (...), 'normalizer__with_centering': True, 'normalizer__with_scaling': False}), 'rebalance': ('rebalance_NoneType', {})}, 'score': 0.9533333333333334, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'entropy', 'max_depth': None, 'max_features': 3, 'max_leaf_nodes': 3, 'min_samples_split': 5, 'n_estimators': 10}, 'config_hash': {'algorithm': '9c592e876c13de5e23e6de5b868e01755d63e72e', 'config': '1e6a68cd1eeac886d90724d78b1cb5fb76a3cde4', 'pipeline': '5a1ca4d82f21b7de0d2c918630a42510673fa36e'}, 'duration': 0.18141412734985352, 'iteration': 15, 'loss': 0.046666666666666634, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_SelectKBest', {'features__k': 3}), 'normalizer': ('normalizer_RobustScaler', {'normalizer__quantile_range': (...), 'normalizer__with_centering': True, 'normalizer__with_scaling': True}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 6})}, 'score': 0.9533333333333334, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': 1, 'max_features': None, 'max_leaf_nodes': None, 'min_samples_split': 5, 'n_estimators': 10}, 'config_hash': {'algorithm': '8bed77aef289bfd453b2858bd288ae5ba7160f2b', 'config': '781185bcb8999045de8d489f253a1a1ba4247932', 'pipeline': '1ece7eabedc2be9e5b0a1be65c570d08ffa3eb54'}, 'duration': 0.1636829376220703, 'iteration': 16, 'loss': 0.053333333333333344, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_NoneType', {}), 'normalizer': ('normalizer_NoneType', {}), 'rebalance': ('rebalance_NearMiss', {'rebalance__n_neighbors': 1})}, 'score': 0.9466666666666667, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'gini', 'max_depth': 3, 'max_features': 2, 'max_leaf_nodes': 2, 'min_samples_split': 5, 'n_estimators': 75}, 'config_hash': {'algorithm': '617b97d9ba21d3373bc51ffa9cccf9c6f91a77b3', 'config': '99fb425b4e8c5d80228cab94202252aa25cdf77c', 'pipeline': 'd6242929c3b515c7719e60423023ac604311afc3'}, 'duration': 0.8468999862670898, 'iteration': 17, 'loss': 0.24, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_PCA', {'features__n_components': 4}), 'normalizer': ('normalizer_PowerTransformer', {}), 'rebalance': ('rebalance_NearMiss', {'rebalance__n_neighbors': 2})}, 'score': 0.76, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': 1, 'max_features': 1, 'max_leaf_nodes': 2, 'min_samples_split': 5, 'n_estimators': 50}, 'config_hash': {'algorithm': 'b92d2697cdd4979da443369d6596229ec091626a', 'config': 'c513a3e13281206ad76187dd817b1fff93d54fe1', 'pipeline': 'c4b4f914a3ca8df967cade997a90366d85a371b9'}, 'duration': 0.6724588871002197, 'iteration': 18, 'loss': 0.23333333333333328, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 1, 'features__selectkbest__k': 3}), 'normalizer': ('normalizer_StandardScaler', {'normalizer__with_mean': True, 'normalizer__with_std': True}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 5})}, 'score': 0.7666666666666667, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'entropy', 'max_depth': None, 'max_features': None, 'max_leaf_nodes': 5, 'min_samples_split': 5, 'n_estimators': 10}, 'config_hash': {'algorithm': 'a0115de695e6cca2e81cbfb54df79bf4b43608b1', 'config': 'ba194015e20b5d67770e8c67342c3d8d0d01dc41', 'pipeline': '8d45fabfeb85ffdcabf7076bd0e65fffe97ce928'}, 'duration': 0.19424200057983398, 'iteration': 19, 'loss': 0.08666666666666667, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_PCA', {'features__n_components': 3}), 'normalizer': ('normalizer_NoneType', {}), 'rebalance': ('rebalance_NoneType', {})}, 'score': 0.9133333333333333, ...}, ...], 'history_hash': ['db6ac7e6d348155757e4794bb5f88fe2b4f63d50', '4db6fb84d85f52659f780e682ffac5712c3d8a94', '4403c5a85e951938d3c454e961d3a412780722f6', 'a064e2df18ab98d44dabcefbc7bed94913f1d0be', '0ddb6f5cab3db4dddd7682966a57205f3e329ad4', '49f25751bca61cdd461a8cbd2923689b642f98ed', '5c3a2b6f5e63fb45f10e41e0318b354912ec44f6', 'd3b129b397350f1b6572651c67c01de49b4b174c', '813bde1108cc3c4b9bfb3a22cbb421bda7eac671', '31930b6860ed406d59bf7e59ba1925d94704bd3b', '9913cd550615a9d0946ab4a755a8b9f619e442fd', '95fc8cadc088141290b7de9c388977e4685f0108', '40fa726f0360cf6af55f9b5902d399d02f61f157', '0fb8e77c7bd9a58b72f1b33c21a59a09a8c676ba', 'f4bffd5d8c67a9c5321a9943c4a99678f59a02b7', '1e6a68cd1eeac886d90724d78b1cb5fb76a3cde4', '781185bcb8999045de8d489f253a1a1ba4247932', '99fb425b4e8c5d80228cab94202252aa25cdf77c', 'c513a3e13281206ad76187dd817b1fff93d54fe1', 'ba194015e20b5d67770e8c67342c3d8d0d01dc41', ...], 'history_index': {'00f0493590a2cb5e98a35b29816f8cd9f87f96ec': 208, '013329309d510b94f19d930320402d65f953a847': 39, '038a0f515e2ec894ee8e34f9caa2889eb3ebd5ce': 66, '052ae4bf232b316187b078abae42c2be19e16a00': 111, '0659afebf316aafeb75612fb07081a04c28545ed': 74, '06e7cde9f3556cd01332ce389ad1d8925cd4b4a4': 120, '08606f2a0f0a6c9de204020b4632e09fcee0ae56': 168, '0a05b5b0a70971a5e347aaab7a4d4a07a92222fd': 191, '0b6551ecfd6f83a15704a9db68f1599c99c6d3ef': 58, '0cfb4698cbf2d986bcd5e0c2ef0f974da60b205e': 194, ...}, 'iteration': 234, 'max_history_score': 0.9666666666666668, 'max_history_score_std': 0.033333333333333326, 'max_history_step': 'joint'}, config={'algorithm': 'RandomForest', 'seed': 42, 'time': 300})
    108 
    109 def objective_algo(algo_config, current_pipeline_config, algorithm, X, y, context, config):
    110     return objective(current_pipeline_config, algo_config, algorithm, X, y, context, config, step='algorithm')
    111 
    112 def objective_joint(wconfig, algorithm, X, y, context, config):
--> 113     return objective(wconfig['pipeline'], wconfig['algorithm'], algorithm, X, y, context, config, step='joint')
        wconfig = {'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': 4, 'max_features': 3, 'max_leaf_nodes': 5, 'min_samples_split': 3, 'n_estimators': 10}, 'pipeline': {'features': ('features_PCA', {'features__n_components': 1}), 'normalizer': ('normalizer_PowerTransformer', {}), 'rebalance': ('rebalance_CondensedNearestNeighbour', {'rebalance__n_neighbors': 1})}}
        algorithm = 'RandomForest'
        X = array([[5.1, 3.5, 1.4, 0.2],
       [4.9, 3. , 1....2, 3.4, 5.4, 2.3],
       [5.9, 3. , 5.1, 1.8]])
        y = array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,... 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2])
        context = {'baseline_score': 0.9466666666666667, 'baseline_score_std': 0.04988876515698587, 'best_config': {'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': 4, 'max_features': 3, 'max_leaf_nodes': 3, 'min_samples_split': 3, 'n_estimators': 10}, 'config_hash': {'algorithm': 'ffb7ff225ce3d3712c96cf87fe42202988ee2eb0', 'config': 'bae32f426be9cd6243523c023944a8c148fe4aeb', 'pipeline': 'd2a68bfda6fcdec4ae0ffc7d7b6a2122bc1cd673'}, 'duration': 0.7115809917449951, 'iteration': 113, 'loss': 0.033333333333333215, 'max_history_score': 0.9666666666666668, 'max_history_score_std': 0.033333333333333326, 'max_history_step': 'joint', 'pipeline': {'features': ('features_NoneType', {}), 'normalizer': ('normalizer_PowerTransformer', {}), 'rebalance': ('rebalance_CondensedNearestNeighbour', {'rebalance__n_neighbors': 2})}, 'score': 0.9666666666666668, ...}, 'history': [{'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': 2, 'max_features': None, 'max_leaf_nodes': 5, 'min_samples_split': 2, 'n_estimators': 75}, 'config_hash': {'algorithm': '3af5b0cce71c8fe2545246ca24ff5bc3dd516e06', 'config': 'db6ac7e6d348155757e4794bb5f88fe2b4f63d50', 'pipeline': '8d59f4b94cef6be9306ed86a22a9570fa670d567'}, 'duration': 1.149928092956543, 'iteration': 0, 'loss': 0.046666666666666634, 'max_history_score': 0.9533333333333334, 'max_history_score_std': 0.059999999999999984, 'max_history_step': 'joint', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 4, 'features__selectkbest__k': 3}), 'normalizer': ('normalizer_StandardScaler', {'normalizer__with_mean': True, 'normalizer__with_std': True}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 6})}, 'score': 0.9533333333333334, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': 1, 'max_features': 2, 'max_leaf_nodes': 2, 'min_samples_split': 5, 'n_estimators': 100}, 'config_hash': {'algorithm': 'e13eb05fd9a62d2f63bbb1c1deff0cd620d5e6ab', 'config': '4db6fb84d85f52659f780e682ffac5712c3d8a94', 'pipeline': '64c9a1ca9d53ae67244bdd942f4db36a3c05218c'}, 'duration': 1.7678282260894775, 'iteration': 1, 'loss': 0.18000000000000005, 'max_history_score': 0.9533333333333334, 'max_history_score_std': 0.059999999999999984, 'max_history_step': 'joint', 'pipeline': {'features': ('features_NoneType', {}), 'normalizer': ('normalizer_PowerTransformer', {}), 'rebalance': ('rebalance_NearMiss', {'rebalance__n_neighbors': 1})}, 'score': 0.82, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': 1, 'max_features': None, 'max_leaf_nodes': None, 'min_samples_split': 5, 'n_estimators': 75}, 'config_hash': {'algorithm': '94b0d7a654c508cc63643f78fe4f0f07e6f07c1e', 'config': '4403c5a85e951938d3c454e961d3a412780722f6', 'pipeline': '3e47444880d8367fbac2faaba2e52a917274aa58'}, 'duration': 0.8397619724273682, 'iteration': 2, 'loss': 0.03333333333333344, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_PCA', {'features__n_components': 3}), 'normalizer': ('normalizer_MinMaxScaler', {}), 'rebalance': ('rebalance_NoneType', {})}, 'score': 0.9666666666666666, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': None, 'max_features': None, 'max_leaf_nodes': 3, 'min_samples_split': 3, 'n_estimators': 75}, 'config_hash': {'algorithm': 'e8332f0a8902bda03bf70e7978cc5d52affb29d3', 'config': 'a064e2df18ab98d44dabcefbc7bed94913f1d0be', 'pipeline': '7eea819c2a8c103c4b1e9e9c1e224aebba95081f'}, 'duration': 0.8501448631286621, 'iteration': 3, 'loss': 0.053333333333333344, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 2, 'features__selectkbest__k': 4}), 'normalizer': ('normalizer_NoneType', {}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 7})}, 'score': 0.9466666666666667, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'entropy', 'max_depth': 3, 'max_features': 3, 'max_leaf_nodes': None, 'min_samples_split': 5, 'n_estimators': 75}, 'config_hash': {'algorithm': '7a4491035bc6bd737fe9a8cda8a79a02d02d5c74', 'config': '0ddb6f5cab3db4dddd7682966a57205f3e329ad4', 'pipeline': 'a9ae03fe38334f6868cbf84cdd3d629d4bbe3fb0'}, 'duration': 1.1026010513305664, 'iteration': 4, 'loss': 0.05999999999999994, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 2, 'features__selectkbest__k': 1}), 'normalizer': ('normalizer_NoneType', {}), 'rebalance': ('rebalance_NoneType', {})}, 'score': 0.9400000000000001, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'gini', 'max_depth': 3, 'max_features': 1, 'max_leaf_nodes': 5, 'min_samples_split': 2, 'n_estimators': 25}, 'config_hash': {'algorithm': '9826d20b2d6a0f559cf7f16450ce7526f07e8434', 'config': '49f25751bca61cdd461a8cbd2923689b642f98ed', 'pipeline': '19b249664c5bf067de1fed4334a296f947ce774a'}, 'duration': 0.35647010803222656, 'iteration': 5, 'loss': 0.046666666666666634, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_NoneType', {}), 'normalizer': ('normalizer_NoneType', {}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 6})}, 'score': 0.9533333333333334, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'gini', 'max_depth': 2, 'max_features': 1, 'max_leaf_nodes': 2, 'min_samples_split': 2, 'n_estimators': 50}, 'config_hash': {'algorithm': '0a4f6fbb07e0f32c6f675489a0fc82eee05bd8e1', 'config': '5c3a2b6f5e63fb45f10e41e0318b354912ec44f6', 'pipeline': 'dc3b9f176f090005e38b142f11d80e93a7dc5d5e'}, 'duration': 0.7213859558105469, 'iteration': 6, 'loss': 0.31333333333333324, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 1, 'features__selectkbest__k': 4}), 'normalizer': ('normalizer_PowerTransformer', {}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 7})}, 'score': 0.6866666666666668, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'entropy', 'max_depth': 4, 'max_features': 3, 'max_leaf_nodes': 5, 'min_samples_split': 5, 'n_estimators': 10}, 'config_hash': {'algorithm': 'b8112b97ecfc10f00a195af661dcc861cac21289', 'config': 'd3b129b397350f1b6572651c67c01de49b4b174c', 'pipeline': '5b0357ed7072c37b3d6f458bb5d49ff7d825f603'}, 'duration': 0.8299109935760498, 'iteration': 7, 'loss': 1.0, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_PCA', {'features__n_components': 2}), 'normalizer': ('normalizer_StandardScaler', {'normalizer__with_mean': True, 'normalizer__with_std': False}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 6})}, 'score': 0.0, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'gini', 'max_depth': 4, 'max_features': None, 'max_leaf_nodes': 2, 'min_samples_split': 5, 'n_estimators': 100}, 'config_hash': {'algorithm': '40ca24df19b8d164d9d098a6bed1ce056fbbb961', 'config': '813bde1108cc3c4b9bfb3a22cbb421bda7eac671', 'pipeline': '74a7b8705a1c22f7dea5e44e4ebda8f1e48add71'}, 'duration': 2.2111589908599854, 'iteration': 8, 'loss': 0.33333333333333326, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_PCA', {'features__n_components': 2}), 'normalizer': ('normalizer_StandardScaler', {'normalizer__with_mean': False, 'normalizer__with_std': True}), 'rebalance': ('rebalance_NearMiss', {'rebalance__n_neighbors': 2})}, 'score': 0.6666666666666667, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'entropy', 'max_depth': 2, 'max_features': 1, 'max_leaf_nodes': 5, 'min_samples_split': 2, 'n_estimators': 100}, 'config_hash': {'algorithm': '331418a5c12cf1453876eef85e9d98fc8e54fa11', 'config': '31930b6860ed406d59bf7e59ba1925d94704bd3b', 'pipeline': '054bef356f90ec6f644ef3ffc688766744db51c2'}, 'duration': 1.0501940250396729, 'iteration': 9, 'loss': 0.053333333333333344, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_SelectKBest', {'features__k': 1}), 'normalizer': ('normalizer_RobustScaler', {'normalizer__quantile_range': (...), 'normalizer__with_centering': True, 'normalizer__with_scaling': True}), 'rebalance': ('rebalance_NearMiss', {'rebalance__n_neighbors': 2})}, 'score': 0.9466666666666667, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'entropy', 'max_depth': 3, 'max_features': None, 'max_leaf_nodes': 3, 'min_samples_split': 2, 'n_estimators': 100}, 'config_hash': {'algorithm': 'dbc1b8126649fe93dce5fbb37e4015b0acfb179e', 'config': '9913cd550615a9d0946ab4a755a8b9f619e442fd', 'pipeline': 'dd626121cea079ebb32e184ca65483ec7a6d7f59'}, 'duration': 1.120617151260376, 'iteration': 10, 'loss': 0.046666666666666634, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 2, 'features__selectkbest__k': 1}), 'normalizer': ('normalizer_MinMaxScaler', {}), 'rebalance': ('rebalance_NoneType', {})}, 'score': 0.9533333333333334, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'gini', 'max_depth': 3, 'max_features': 3, 'max_leaf_nodes': None, 'min_samples_split': 3, 'n_estimators': 75}, 'config_hash': {'algorithm': '34917a130df5a975f78bd7ec1a0c7b1ffdc787a9', 'config': '95fc8cadc088141290b7de9c388977e4685f0108', 'pipeline': '550d10faf2f08db48516cc3501558816d6a99bc0'}, 'duration': 1.4287099838256836, 'iteration': 11, 'loss': 0.19333333333333313, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 3, 'features__selectkbest__k': 4}), 'normalizer': ('normalizer_StandardScaler', {'normalizer__with_mean': False, 'normalizer__with_std': False}), 'rebalance': ('rebalance_CondensedNearestNeighbour', {'rebalance__n_neighbors': 1})}, 'score': 0.8066666666666669, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'entropy', 'max_depth': 1, 'max_features': 2, 'max_leaf_nodes': 5, 'min_samples_split': 2, 'n_estimators': 75}, 'config_hash': {'algorithm': '33f9abb4aee44a395a9f3b3ffa9ce80a8cdaed7c', 'config': '40fa726f0360cf6af55f9b5902d399d02f61f157', 'pipeline': 'cfd1d20841fe2153da762c95e79f95a3fb1e426a'}, 'duration': 1.2978079319000244, 'iteration': 12, 'loss': 0.053333333333333344, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_PCA', {'features__n_components': 4}), 'normalizer': ('normalizer_MinMaxScaler', {}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 7})}, 'score': 0.9466666666666667, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'entropy', 'max_depth': 4, 'max_features': 2, 'max_leaf_nodes': 5, 'min_samples_split': 3, 'n_estimators': 25}, 'config_hash': {'algorithm': '210111ec6562d09eb093e98ed69ef1c662e11a50', 'config': '0fb8e77c7bd9a58b72f1b33c21a59a09a8c676ba', 'pipeline': '5d269d759e0c7926a685a14b263ace8ae0071e4b'}, 'duration': 0.36649012565612793, 'iteration': 13, 'loss': 0.040000000000000036, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 2, 'features__selectkbest__k': 2}), 'normalizer': ('normalizer_NoneType', {}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 7})}, 'score': 0.96, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'entropy', 'max_depth': 3, 'max_features': 1, 'max_leaf_nodes': 5, 'min_samples_split': 2, 'n_estimators': 25}, 'config_hash': {'algorithm': '0e989a03980101fabf79eda3326ed2870e11d690', 'config': 'f4bffd5d8c67a9c5321a9943c4a99678f59a02b7', 'pipeline': '865ee1e3fe8334c3d5ecb2038d5a5d1b3ba50e75'}, 'duration': 0.35639500617980957, 'iteration': 14, 'loss': 0.046666666666666634, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_NoneType', {}), 'normalizer': ('normalizer_RobustScaler', {'normalizer__quantile_range': (...), 'normalizer__with_centering': True, 'normalizer__with_scaling': False}), 'rebalance': ('rebalance_NoneType', {})}, 'score': 0.9533333333333334, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'entropy', 'max_depth': None, 'max_features': 3, 'max_leaf_nodes': 3, 'min_samples_split': 5, 'n_estimators': 10}, 'config_hash': {'algorithm': '9c592e876c13de5e23e6de5b868e01755d63e72e', 'config': '1e6a68cd1eeac886d90724d78b1cb5fb76a3cde4', 'pipeline': '5a1ca4d82f21b7de0d2c918630a42510673fa36e'}, 'duration': 0.18141412734985352, 'iteration': 15, 'loss': 0.046666666666666634, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_SelectKBest', {'features__k': 3}), 'normalizer': ('normalizer_RobustScaler', {'normalizer__quantile_range': (...), 'normalizer__with_centering': True, 'normalizer__with_scaling': True}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 6})}, 'score': 0.9533333333333334, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': 1, 'max_features': None, 'max_leaf_nodes': None, 'min_samples_split': 5, 'n_estimators': 10}, 'config_hash': {'algorithm': '8bed77aef289bfd453b2858bd288ae5ba7160f2b', 'config': '781185bcb8999045de8d489f253a1a1ba4247932', 'pipeline': '1ece7eabedc2be9e5b0a1be65c570d08ffa3eb54'}, 'duration': 0.1636829376220703, 'iteration': 16, 'loss': 0.053333333333333344, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_NoneType', {}), 'normalizer': ('normalizer_NoneType', {}), 'rebalance': ('rebalance_NearMiss', {'rebalance__n_neighbors': 1})}, 'score': 0.9466666666666667, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'gini', 'max_depth': 3, 'max_features': 2, 'max_leaf_nodes': 2, 'min_samples_split': 5, 'n_estimators': 75}, 'config_hash': {'algorithm': '617b97d9ba21d3373bc51ffa9cccf9c6f91a77b3', 'config': '99fb425b4e8c5d80228cab94202252aa25cdf77c', 'pipeline': 'd6242929c3b515c7719e60423023ac604311afc3'}, 'duration': 0.8468999862670898, 'iteration': 17, 'loss': 0.24, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_PCA', {'features__n_components': 4}), 'normalizer': ('normalizer_PowerTransformer', {}), 'rebalance': ('rebalance_NearMiss', {'rebalance__n_neighbors': 2})}, 'score': 0.76, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': 1, 'max_features': 1, 'max_leaf_nodes': 2, 'min_samples_split': 5, 'n_estimators': 50}, 'config_hash': {'algorithm': 'b92d2697cdd4979da443369d6596229ec091626a', 'config': 'c513a3e13281206ad76187dd817b1fff93d54fe1', 'pipeline': 'c4b4f914a3ca8df967cade997a90366d85a371b9'}, 'duration': 0.6724588871002197, 'iteration': 18, 'loss': 0.23333333333333328, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 1, 'features__selectkbest__k': 3}), 'normalizer': ('normalizer_StandardScaler', {'normalizer__with_mean': True, 'normalizer__with_std': True}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 5})}, 'score': 0.7666666666666667, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'entropy', 'max_depth': None, 'max_features': None, 'max_leaf_nodes': 5, 'min_samples_split': 5, 'n_estimators': 10}, 'config_hash': {'algorithm': 'a0115de695e6cca2e81cbfb54df79bf4b43608b1', 'config': 'ba194015e20b5d67770e8c67342c3d8d0d01dc41', 'pipeline': '8d45fabfeb85ffdcabf7076bd0e65fffe97ce928'}, 'duration': 0.19424200057983398, 'iteration': 19, 'loss': 0.08666666666666667, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_PCA', {'features__n_components': 3}), 'normalizer': ('normalizer_NoneType', {}), 'rebalance': ('rebalance_NoneType', {})}, 'score': 0.9133333333333333, ...}, ...], 'history_hash': ['db6ac7e6d348155757e4794bb5f88fe2b4f63d50', '4db6fb84d85f52659f780e682ffac5712c3d8a94', '4403c5a85e951938d3c454e961d3a412780722f6', 'a064e2df18ab98d44dabcefbc7bed94913f1d0be', '0ddb6f5cab3db4dddd7682966a57205f3e329ad4', '49f25751bca61cdd461a8cbd2923689b642f98ed', '5c3a2b6f5e63fb45f10e41e0318b354912ec44f6', 'd3b129b397350f1b6572651c67c01de49b4b174c', '813bde1108cc3c4b9bfb3a22cbb421bda7eac671', '31930b6860ed406d59bf7e59ba1925d94704bd3b', '9913cd550615a9d0946ab4a755a8b9f619e442fd', '95fc8cadc088141290b7de9c388977e4685f0108', '40fa726f0360cf6af55f9b5902d399d02f61f157', '0fb8e77c7bd9a58b72f1b33c21a59a09a8c676ba', 'f4bffd5d8c67a9c5321a9943c4a99678f59a02b7', '1e6a68cd1eeac886d90724d78b1cb5fb76a3cde4', '781185bcb8999045de8d489f253a1a1ba4247932', '99fb425b4e8c5d80228cab94202252aa25cdf77c', 'c513a3e13281206ad76187dd817b1fff93d54fe1', 'ba194015e20b5d67770e8c67342c3d8d0d01dc41', ...], 'history_index': {'00f0493590a2cb5e98a35b29816f8cd9f87f96ec': 208, '013329309d510b94f19d930320402d65f953a847': 39, '038a0f515e2ec894ee8e34f9caa2889eb3ebd5ce': 66, '052ae4bf232b316187b078abae42c2be19e16a00': 111, '0659afebf316aafeb75612fb07081a04c28545ed': 74, '06e7cde9f3556cd01332ce389ad1d8925cd4b4a4': 120, '08606f2a0f0a6c9de204020b4632e09fcee0ae56': 168, '0a05b5b0a70971a5e347aaab7a4d4a07a92222fd': 191, '0b6551ecfd6f83a15704a9db68f1599c99c6d3ef': 58, '0cfb4698cbf2d986bcd5e0c2ef0f974da60b205e': 194, ...}, 'iteration': 234, 'max_history_score': 0.9666666666666668, 'max_history_score_std': 0.033333333333333326, 'max_history_step': 'joint'}
        config = {'algorithm': 'RandomForest', 'seed': 42, 'time': 300}
    114 
    115 
    116 def get_baseline_score(algorithm, X, y, seed):
    117     pipeline, _ = pipeline_conf_to_full_pipeline(

...........................................................................
/home/aquemy/dev/dp_hyperparameters/extension/experiment/objective.py in objective(pipeline_config={'features': ('features_PCA', {'features__n_components': 1}), 'normalizer': ('normalizer_PowerTransformer', {}), 'rebalance': ('rebalance_CondensedNearestNeighbour', {'rebalance__n_neighbors': 1})}, algo_config={'bootstrap': True, 'criterion': 'gini', 'max_depth': 4, 'max_features': 3, 'max_leaf_nodes': 5, 'min_samples_split': 3, 'n_estimators': 10}, algorithm='RandomForest', X=array([[5.1, 3.5, 1.4, 0.2],
       [4.9, 3. , 1....2, 3.4, 5.4, 2.3],
       [5.9, 3. , 5.1, 1.8]]), y=array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,... 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]), context={'baseline_score': 0.9466666666666667, 'baseline_score_std': 0.04988876515698587, 'best_config': {'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': 4, 'max_features': 3, 'max_leaf_nodes': 3, 'min_samples_split': 3, 'n_estimators': 10}, 'config_hash': {'algorithm': 'ffb7ff225ce3d3712c96cf87fe42202988ee2eb0', 'config': 'bae32f426be9cd6243523c023944a8c148fe4aeb', 'pipeline': 'd2a68bfda6fcdec4ae0ffc7d7b6a2122bc1cd673'}, 'duration': 0.7115809917449951, 'iteration': 113, 'loss': 0.033333333333333215, 'max_history_score': 0.9666666666666668, 'max_history_score_std': 0.033333333333333326, 'max_history_step': 'joint', 'pipeline': {'features': ('features_NoneType', {}), 'normalizer': ('normalizer_PowerTransformer', {}), 'rebalance': ('rebalance_CondensedNearestNeighbour', {'rebalance__n_neighbors': 2})}, 'score': 0.9666666666666668, ...}, 'history': [{'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': 2, 'max_features': None, 'max_leaf_nodes': 5, 'min_samples_split': 2, 'n_estimators': 75}, 'config_hash': {'algorithm': '3af5b0cce71c8fe2545246ca24ff5bc3dd516e06', 'config': 'db6ac7e6d348155757e4794bb5f88fe2b4f63d50', 'pipeline': '8d59f4b94cef6be9306ed86a22a9570fa670d567'}, 'duration': 1.149928092956543, 'iteration': 0, 'loss': 0.046666666666666634, 'max_history_score': 0.9533333333333334, 'max_history_score_std': 0.059999999999999984, 'max_history_step': 'joint', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 4, 'features__selectkbest__k': 3}), 'normalizer': ('normalizer_StandardScaler', {'normalizer__with_mean': True, 'normalizer__with_std': True}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 6})}, 'score': 0.9533333333333334, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': 1, 'max_features': 2, 'max_leaf_nodes': 2, 'min_samples_split': 5, 'n_estimators': 100}, 'config_hash': {'algorithm': 'e13eb05fd9a62d2f63bbb1c1deff0cd620d5e6ab', 'config': '4db6fb84d85f52659f780e682ffac5712c3d8a94', 'pipeline': '64c9a1ca9d53ae67244bdd942f4db36a3c05218c'}, 'duration': 1.7678282260894775, 'iteration': 1, 'loss': 0.18000000000000005, 'max_history_score': 0.9533333333333334, 'max_history_score_std': 0.059999999999999984, 'max_history_step': 'joint', 'pipeline': {'features': ('features_NoneType', {}), 'normalizer': ('normalizer_PowerTransformer', {}), 'rebalance': ('rebalance_NearMiss', {'rebalance__n_neighbors': 1})}, 'score': 0.82, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': 1, 'max_features': None, 'max_leaf_nodes': None, 'min_samples_split': 5, 'n_estimators': 75}, 'config_hash': {'algorithm': '94b0d7a654c508cc63643f78fe4f0f07e6f07c1e', 'config': '4403c5a85e951938d3c454e961d3a412780722f6', 'pipeline': '3e47444880d8367fbac2faaba2e52a917274aa58'}, 'duration': 0.8397619724273682, 'iteration': 2, 'loss': 0.03333333333333344, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_PCA', {'features__n_components': 3}), 'normalizer': ('normalizer_MinMaxScaler', {}), 'rebalance': ('rebalance_NoneType', {})}, 'score': 0.9666666666666666, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': None, 'max_features': None, 'max_leaf_nodes': 3, 'min_samples_split': 3, 'n_estimators': 75}, 'config_hash': {'algorithm': 'e8332f0a8902bda03bf70e7978cc5d52affb29d3', 'config': 'a064e2df18ab98d44dabcefbc7bed94913f1d0be', 'pipeline': '7eea819c2a8c103c4b1e9e9c1e224aebba95081f'}, 'duration': 0.8501448631286621, 'iteration': 3, 'loss': 0.053333333333333344, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 2, 'features__selectkbest__k': 4}), 'normalizer': ('normalizer_NoneType', {}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 7})}, 'score': 0.9466666666666667, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'entropy', 'max_depth': 3, 'max_features': 3, 'max_leaf_nodes': None, 'min_samples_split': 5, 'n_estimators': 75}, 'config_hash': {'algorithm': '7a4491035bc6bd737fe9a8cda8a79a02d02d5c74', 'config': '0ddb6f5cab3db4dddd7682966a57205f3e329ad4', 'pipeline': 'a9ae03fe38334f6868cbf84cdd3d629d4bbe3fb0'}, 'duration': 1.1026010513305664, 'iteration': 4, 'loss': 0.05999999999999994, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 2, 'features__selectkbest__k': 1}), 'normalizer': ('normalizer_NoneType', {}), 'rebalance': ('rebalance_NoneType', {})}, 'score': 0.9400000000000001, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'gini', 'max_depth': 3, 'max_features': 1, 'max_leaf_nodes': 5, 'min_samples_split': 2, 'n_estimators': 25}, 'config_hash': {'algorithm': '9826d20b2d6a0f559cf7f16450ce7526f07e8434', 'config': '49f25751bca61cdd461a8cbd2923689b642f98ed', 'pipeline': '19b249664c5bf067de1fed4334a296f947ce774a'}, 'duration': 0.35647010803222656, 'iteration': 5, 'loss': 0.046666666666666634, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_NoneType', {}), 'normalizer': ('normalizer_NoneType', {}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 6})}, 'score': 0.9533333333333334, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'gini', 'max_depth': 2, 'max_features': 1, 'max_leaf_nodes': 2, 'min_samples_split': 2, 'n_estimators': 50}, 'config_hash': {'algorithm': '0a4f6fbb07e0f32c6f675489a0fc82eee05bd8e1', 'config': '5c3a2b6f5e63fb45f10e41e0318b354912ec44f6', 'pipeline': 'dc3b9f176f090005e38b142f11d80e93a7dc5d5e'}, 'duration': 0.7213859558105469, 'iteration': 6, 'loss': 0.31333333333333324, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 1, 'features__selectkbest__k': 4}), 'normalizer': ('normalizer_PowerTransformer', {}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 7})}, 'score': 0.6866666666666668, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'entropy', 'max_depth': 4, 'max_features': 3, 'max_leaf_nodes': 5, 'min_samples_split': 5, 'n_estimators': 10}, 'config_hash': {'algorithm': 'b8112b97ecfc10f00a195af661dcc861cac21289', 'config': 'd3b129b397350f1b6572651c67c01de49b4b174c', 'pipeline': '5b0357ed7072c37b3d6f458bb5d49ff7d825f603'}, 'duration': 0.8299109935760498, 'iteration': 7, 'loss': 1.0, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_PCA', {'features__n_components': 2}), 'normalizer': ('normalizer_StandardScaler', {'normalizer__with_mean': True, 'normalizer__with_std': False}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 6})}, 'score': 0.0, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'gini', 'max_depth': 4, 'max_features': None, 'max_leaf_nodes': 2, 'min_samples_split': 5, 'n_estimators': 100}, 'config_hash': {'algorithm': '40ca24df19b8d164d9d098a6bed1ce056fbbb961', 'config': '813bde1108cc3c4b9bfb3a22cbb421bda7eac671', 'pipeline': '74a7b8705a1c22f7dea5e44e4ebda8f1e48add71'}, 'duration': 2.2111589908599854, 'iteration': 8, 'loss': 0.33333333333333326, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_PCA', {'features__n_components': 2}), 'normalizer': ('normalizer_StandardScaler', {'normalizer__with_mean': False, 'normalizer__with_std': True}), 'rebalance': ('rebalance_NearMiss', {'rebalance__n_neighbors': 2})}, 'score': 0.6666666666666667, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'entropy', 'max_depth': 2, 'max_features': 1, 'max_leaf_nodes': 5, 'min_samples_split': 2, 'n_estimators': 100}, 'config_hash': {'algorithm': '331418a5c12cf1453876eef85e9d98fc8e54fa11', 'config': '31930b6860ed406d59bf7e59ba1925d94704bd3b', 'pipeline': '054bef356f90ec6f644ef3ffc688766744db51c2'}, 'duration': 1.0501940250396729, 'iteration': 9, 'loss': 0.053333333333333344, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_SelectKBest', {'features__k': 1}), 'normalizer': ('normalizer_RobustScaler', {'normalizer__quantile_range': (...), 'normalizer__with_centering': True, 'normalizer__with_scaling': True}), 'rebalance': ('rebalance_NearMiss', {'rebalance__n_neighbors': 2})}, 'score': 0.9466666666666667, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'entropy', 'max_depth': 3, 'max_features': None, 'max_leaf_nodes': 3, 'min_samples_split': 2, 'n_estimators': 100}, 'config_hash': {'algorithm': 'dbc1b8126649fe93dce5fbb37e4015b0acfb179e', 'config': '9913cd550615a9d0946ab4a755a8b9f619e442fd', 'pipeline': 'dd626121cea079ebb32e184ca65483ec7a6d7f59'}, 'duration': 1.120617151260376, 'iteration': 10, 'loss': 0.046666666666666634, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 2, 'features__selectkbest__k': 1}), 'normalizer': ('normalizer_MinMaxScaler', {}), 'rebalance': ('rebalance_NoneType', {})}, 'score': 0.9533333333333334, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'gini', 'max_depth': 3, 'max_features': 3, 'max_leaf_nodes': None, 'min_samples_split': 3, 'n_estimators': 75}, 'config_hash': {'algorithm': '34917a130df5a975f78bd7ec1a0c7b1ffdc787a9', 'config': '95fc8cadc088141290b7de9c388977e4685f0108', 'pipeline': '550d10faf2f08db48516cc3501558816d6a99bc0'}, 'duration': 1.4287099838256836, 'iteration': 11, 'loss': 0.19333333333333313, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 3, 'features__selectkbest__k': 4}), 'normalizer': ('normalizer_StandardScaler', {'normalizer__with_mean': False, 'normalizer__with_std': False}), 'rebalance': ('rebalance_CondensedNearestNeighbour', {'rebalance__n_neighbors': 1})}, 'score': 0.8066666666666669, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'entropy', 'max_depth': 1, 'max_features': 2, 'max_leaf_nodes': 5, 'min_samples_split': 2, 'n_estimators': 75}, 'config_hash': {'algorithm': '33f9abb4aee44a395a9f3b3ffa9ce80a8cdaed7c', 'config': '40fa726f0360cf6af55f9b5902d399d02f61f157', 'pipeline': 'cfd1d20841fe2153da762c95e79f95a3fb1e426a'}, 'duration': 1.2978079319000244, 'iteration': 12, 'loss': 0.053333333333333344, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_PCA', {'features__n_components': 4}), 'normalizer': ('normalizer_MinMaxScaler', {}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 7})}, 'score': 0.9466666666666667, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'entropy', 'max_depth': 4, 'max_features': 2, 'max_leaf_nodes': 5, 'min_samples_split': 3, 'n_estimators': 25}, 'config_hash': {'algorithm': '210111ec6562d09eb093e98ed69ef1c662e11a50', 'config': '0fb8e77c7bd9a58b72f1b33c21a59a09a8c676ba', 'pipeline': '5d269d759e0c7926a685a14b263ace8ae0071e4b'}, 'duration': 0.36649012565612793, 'iteration': 13, 'loss': 0.040000000000000036, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 2, 'features__selectkbest__k': 2}), 'normalizer': ('normalizer_NoneType', {}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 7})}, 'score': 0.96, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'entropy', 'max_depth': 3, 'max_features': 1, 'max_leaf_nodes': 5, 'min_samples_split': 2, 'n_estimators': 25}, 'config_hash': {'algorithm': '0e989a03980101fabf79eda3326ed2870e11d690', 'config': 'f4bffd5d8c67a9c5321a9943c4a99678f59a02b7', 'pipeline': '865ee1e3fe8334c3d5ecb2038d5a5d1b3ba50e75'}, 'duration': 0.35639500617980957, 'iteration': 14, 'loss': 0.046666666666666634, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_NoneType', {}), 'normalizer': ('normalizer_RobustScaler', {'normalizer__quantile_range': (...), 'normalizer__with_centering': True, 'normalizer__with_scaling': False}), 'rebalance': ('rebalance_NoneType', {})}, 'score': 0.9533333333333334, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'entropy', 'max_depth': None, 'max_features': 3, 'max_leaf_nodes': 3, 'min_samples_split': 5, 'n_estimators': 10}, 'config_hash': {'algorithm': '9c592e876c13de5e23e6de5b868e01755d63e72e', 'config': '1e6a68cd1eeac886d90724d78b1cb5fb76a3cde4', 'pipeline': '5a1ca4d82f21b7de0d2c918630a42510673fa36e'}, 'duration': 0.18141412734985352, 'iteration': 15, 'loss': 0.046666666666666634, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_SelectKBest', {'features__k': 3}), 'normalizer': ('normalizer_RobustScaler', {'normalizer__quantile_range': (...), 'normalizer__with_centering': True, 'normalizer__with_scaling': True}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 6})}, 'score': 0.9533333333333334, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': 1, 'max_features': None, 'max_leaf_nodes': None, 'min_samples_split': 5, 'n_estimators': 10}, 'config_hash': {'algorithm': '8bed77aef289bfd453b2858bd288ae5ba7160f2b', 'config': '781185bcb8999045de8d489f253a1a1ba4247932', 'pipeline': '1ece7eabedc2be9e5b0a1be65c570d08ffa3eb54'}, 'duration': 0.1636829376220703, 'iteration': 16, 'loss': 0.053333333333333344, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_NoneType', {}), 'normalizer': ('normalizer_NoneType', {}), 'rebalance': ('rebalance_NearMiss', {'rebalance__n_neighbors': 1})}, 'score': 0.9466666666666667, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'gini', 'max_depth': 3, 'max_features': 2, 'max_leaf_nodes': 2, 'min_samples_split': 5, 'n_estimators': 75}, 'config_hash': {'algorithm': '617b97d9ba21d3373bc51ffa9cccf9c6f91a77b3', 'config': '99fb425b4e8c5d80228cab94202252aa25cdf77c', 'pipeline': 'd6242929c3b515c7719e60423023ac604311afc3'}, 'duration': 0.8468999862670898, 'iteration': 17, 'loss': 0.24, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_PCA', {'features__n_components': 4}), 'normalizer': ('normalizer_PowerTransformer', {}), 'rebalance': ('rebalance_NearMiss', {'rebalance__n_neighbors': 2})}, 'score': 0.76, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': 1, 'max_features': 1, 'max_leaf_nodes': 2, 'min_samples_split': 5, 'n_estimators': 50}, 'config_hash': {'algorithm': 'b92d2697cdd4979da443369d6596229ec091626a', 'config': 'c513a3e13281206ad76187dd817b1fff93d54fe1', 'pipeline': 'c4b4f914a3ca8df967cade997a90366d85a371b9'}, 'duration': 0.6724588871002197, 'iteration': 18, 'loss': 0.23333333333333328, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 1, 'features__selectkbest__k': 3}), 'normalizer': ('normalizer_StandardScaler', {'normalizer__with_mean': True, 'normalizer__with_std': True}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 5})}, 'score': 0.7666666666666667, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'entropy', 'max_depth': None, 'max_features': None, 'max_leaf_nodes': 5, 'min_samples_split': 5, 'n_estimators': 10}, 'config_hash': {'algorithm': 'a0115de695e6cca2e81cbfb54df79bf4b43608b1', 'config': 'ba194015e20b5d67770e8c67342c3d8d0d01dc41', 'pipeline': '8d45fabfeb85ffdcabf7076bd0e65fffe97ce928'}, 'duration': 0.19424200057983398, 'iteration': 19, 'loss': 0.08666666666666667, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_PCA', {'features__n_components': 3}), 'normalizer': ('normalizer_NoneType', {}), 'rebalance': ('rebalance_NoneType', {})}, 'score': 0.9133333333333333, ...}, ...], 'history_hash': ['db6ac7e6d348155757e4794bb5f88fe2b4f63d50', '4db6fb84d85f52659f780e682ffac5712c3d8a94', '4403c5a85e951938d3c454e961d3a412780722f6', 'a064e2df18ab98d44dabcefbc7bed94913f1d0be', '0ddb6f5cab3db4dddd7682966a57205f3e329ad4', '49f25751bca61cdd461a8cbd2923689b642f98ed', '5c3a2b6f5e63fb45f10e41e0318b354912ec44f6', 'd3b129b397350f1b6572651c67c01de49b4b174c', '813bde1108cc3c4b9bfb3a22cbb421bda7eac671', '31930b6860ed406d59bf7e59ba1925d94704bd3b', '9913cd550615a9d0946ab4a755a8b9f619e442fd', '95fc8cadc088141290b7de9c388977e4685f0108', '40fa726f0360cf6af55f9b5902d399d02f61f157', '0fb8e77c7bd9a58b72f1b33c21a59a09a8c676ba', 'f4bffd5d8c67a9c5321a9943c4a99678f59a02b7', '1e6a68cd1eeac886d90724d78b1cb5fb76a3cde4', '781185bcb8999045de8d489f253a1a1ba4247932', '99fb425b4e8c5d80228cab94202252aa25cdf77c', 'c513a3e13281206ad76187dd817b1fff93d54fe1', 'ba194015e20b5d67770e8c67342c3d8d0d01dc41', ...], 'history_index': {'00f0493590a2cb5e98a35b29816f8cd9f87f96ec': 208, '013329309d510b94f19d930320402d65f953a847': 39, '038a0f515e2ec894ee8e34f9caa2889eb3ebd5ce': 66, '052ae4bf232b316187b078abae42c2be19e16a00': 111, '0659afebf316aafeb75612fb07081a04c28545ed': 74, '06e7cde9f3556cd01332ce389ad1d8925cd4b4a4': 120, '08606f2a0f0a6c9de204020b4632e09fcee0ae56': 168, '0a05b5b0a70971a5e347aaab7a4d4a07a92222fd': 191, '0b6551ecfd6f83a15704a9db68f1599c99c6d3ef': 58, '0cfb4698cbf2d986bcd5e0c2ef0f974da60b205e': 194, ...}, 'iteration': 234, 'max_history_score': 0.9666666666666668, 'max_history_score_std': 0.033333333333333326, 'max_history_step': 'joint'}, config={'algorithm': 'RandomForest', 'seed': 42, 'time': 300}, step='joint')
     45                 y,
     46                 cv=10,
     47                 n_jobs=-1,
     48                 return_estimator=False,
     49                 return_train_score=False,
---> 50                 verbose=0)
     51         score = np.mean(scores['test_score'])
     52         std = np.std(scores['test_score'])
     53         status = STATUS_OK
     54     except Exception as e:

...........................................................................
/home/aquemy/.local/lib/python2.7/site-packages/sklearn/model_selection/_validation.py in cross_validate(estimator=Pipeline(memory=None,
     steps=[('rebalance', ... random_state=42, verbose=0, warm_start=False))]), X=array([[5.1, 3.5, 1.4, 0.2],
       [4.9, 3. , 1....2, 3.4, 5.4, 2.3],
       [5.9, 3. , 5.1, 1.8]]), y=array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,... 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]), groups=None, scoring=None, cv=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1, verbose=0, fit_params=None, pre_dispatch='2*n_jobs', return_train_score=False, return_estimator=False, error_score='raise-deprecating')
    235         delayed(_fit_and_score)(
    236             clone(estimator), X, y, scorers, train, test, verbose, None,
    237             fit_params, return_train_score=return_train_score,
    238             return_times=True, return_estimator=return_estimator,
    239             error_score=error_score)
--> 240         for train, test in cv.split(X, y, groups))
        cv.split = <bound method StratifiedKFold.split of Stratifie...d(n_splits=10, random_state=None, shuffle=False)>
        X = array([[5.1, 3.5, 1.4, 0.2],
       [4.9, 3. , 1....2, 3.4, 5.4, 2.3],
       [5.9, 3. , 5.1, 1.8]])
        y = array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,... 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2])
        groups = None
    241 
    242     zipped_scores = list(zip(*scores))
    243     if return_train_score:
    244         train_scores = zipped_scores.pop(0)

...........................................................................
/home/aquemy/.local/lib/python2.7/site-packages/sklearn/externals/joblib/parallel.py in __call__(self=Parallel(n_jobs=-1), iterable=<generator object <genexpr>>)
    925                 # No need to wait for async callbacks to trigger to
    926                 # consumption.
    927                 self._iterating = False
    928 
    929             with self._backend.retrieval_context():
--> 930                 self.retrieve()
        self.retrieve = <bound method Parallel.retrieve of Parallel(n_jobs=-1)>
    931             # Make sure that we get a last message telling us we are done
    932             elapsed_time = time.time() - self._start_time
    933             self._print('Done %3i out of %3i | elapsed: %s finished',
    934                         (len(self._output), len(self._output),

---------------------------------------------------------------------------
Joblib worker traceback:
---------------------------------------------------------------------------
ValueError                                         Mon Jun 17 13:13:45 2019
PID: 21398                                  Python 2.7.15+: /usr/bin/python
...........................................................................
/home/aquemy/.local/lib/python2.7/site-packages/sklearn/externals/joblib/parallel.py in __call__(self=<sklearn.externals.joblib.parallel.BatchedCalls object>)
    220     def __call__(self):
    221         # Set the default nested backend to self._backend but do not set the
    222         # change the default number of processes to -1
    223         with parallel_backend(self._backend, n_jobs=self._n_jobs):
    224             return [func(*args, **kwargs)
--> 225                     for func, args, kwargs in self.items]
        func = <function _fit_and_score>
        args = (Pipeline(memory=None,
     steps=[('rebalance', ... random_state=42, verbose=0, warm_start=False))]), array([[5.1, 3.5, 1.4, 0.2],
       [4.9, 3. , 1....2, 3.4, 5.4, 2.3],
       [5.9, 3. , 5.1, 1.8]]), array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,... 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]), {'score': <function _passthrough_scorer>}, array([  5,   6,   7,   8,   9,  10,  11,  12,  ..., 142, 143, 144,
       145, 146, 147, 148, 149]), array([  0,   1,   2,   3,   4,  50,  51,  52,  53,  54, 100, 101, 102,
       103, 104]), 0, None, None)
        kwargs = {'error_score': 'raise-deprecating', 'return_estimator': False, 'return_times': True, 'return_train_score': False}
        self.items = [(<function _fit_and_score>, (Pipeline(memory=None,
     steps=[('rebalance', ... random_state=42, verbose=0, warm_start=False))]), array([[5.1, 3.5, 1.4, 0.2],
       [4.9, 3. , 1....2, 3.4, 5.4, 2.3],
       [5.9, 3. , 5.1, 1.8]]), array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,... 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]), {'score': <function _passthrough_scorer>}, array([  5,   6,   7,   8,   9,  10,  11,  12,  ..., 142, 143, 144,
       145, 146, 147, 148, 149]), array([  0,   1,   2,   3,   4,  50,  51,  52,  53,  54, 100, 101, 102,
       103, 104]), 0, None, None), {'error_score': 'raise-deprecating', 'return_estimator': False, 'return_times': True, 'return_train_score': False})]
    226 
    227     def __len__(self):
    228         return self._size
    229 

...........................................................................
/home/aquemy/.local/lib/python2.7/site-packages/sklearn/model_selection/_validation.py in _fit_and_score(estimator=Pipeline(memory=None,
     steps=[('rebalance', ... random_state=42, verbose=0, warm_start=False))]), X=array([[5.1, 3.5, 1.4, 0.2],
       [4.9, 3. , 1....2, 3.4, 5.4, 2.3],
       [5.9, 3. , 5.1, 1.8]]), y=array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,... 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]), scorer={'score': <function _passthrough_scorer>}, train=array([  5,   6,   7,   8,   9,  10,  11,  12,  ..., 142, 143, 144,
       145, 146, 147, 148, 149]), test=array([  0,   1,   2,   3,   4,  50,  51,  52,  53,  54, 100, 101, 102,
       103, 104]), verbose=0, parameters=None, fit_params={}, return_train_score=False, return_parameters=False, return_n_test_samples=False, return_times=True, return_estimator=False, error_score='raise-deprecating')
    523 
    524     try:
    525         if y_train is None:
    526             estimator.fit(X_train, **fit_params)
    527         else:
--> 528             estimator.fit(X_train, y_train, **fit_params)
        estimator.fit = <bound method Pipeline.fit of Pipeline(memory=No...random_state=42, verbose=0, warm_start=False))])>
        X_train = array([[5.4, 3.9, 1.7, 0.4],
       [4.6, 3.4, 1....2, 3.4, 5.4, 2.3],
       [5.9, 3. , 5.1, 1.8]])
        y_train = array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,
       2, 2, 2])
        fit_params = {}
    529 
    530     except Exception as e:
    531         # Note fit time as time until error
    532         fit_time = time.time() - start_time

...........................................................................
/usr/local/lib/python2.7/dist-packages/imblearn/pipeline.py in fit(self=Pipeline(memory=None,
     steps=[('rebalance', ... random_state=42, verbose=0, warm_start=False))]), X=array([[5.4, 3.9, 1.7, 0.4],
       [4.6, 3.4, 1....2, 3.4, 5.4, 2.3],
       [5.9, 3. , 5.1, 1.8]]), y=array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,
       2, 2, 2]), **fit_params={})
    234             This estimator
    235 
    236         """
    237         Xt, yt, fit_params = self._fit(X, y, **fit_params)
    238         if self._final_estimator is not None:
--> 239             self._final_estimator.fit(Xt, yt, **fit_params)
        self._final_estimator.fit = <bound method RandomForestClassifier.fit of Rand...e, random_state=42, verbose=0, warm_start=False)>
        Xt = array([[ 1.56032816],
       [-0.61362439],
    ...72],
       [ 2.1804035 ],
       [ 3.64505887]])
        yt = array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
       0, 1, 1, 2])
        fit_params = {}
    240         return self
    241 
    242     def fit_transform(self, X, y=None, **fit_params):
    243         """Fit the model and transform with the final estimator

...........................................................................
/home/aquemy/.local/lib/python2.7/site-packages/sklearn/ensemble/forest.py in fit(self=RandomForestClassifier(bootstrap=True, class_wei...se, random_state=42, verbose=0, warm_start=False), X=array([[ 1.5603281 ],
       [-0.6136244 ],
    ....1804035 ],
       [ 3.6450589 ]], dtype=float32), y=array([[0.],
       [0.],
       [0.],
       [0...    [0.],
       [1.],
       [1.],
       [2.]]), sample_weight=None)
    328             trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,
    329                              **_joblib_parallel_args(prefer='threads'))(
    330                 delayed(_parallel_build_trees)(
    331                     t, self, X, y, sample_weight, i, len(trees),
    332                     verbose=self.verbose, class_weight=self.class_weight)
--> 333                 for i, t in enumerate(trees))
        i = 9
    334 
    335             # Collect newly grown trees
    336             self.estimators_.extend(trees)
    337 

...........................................................................
/home/aquemy/.local/lib/python2.7/site-packages/sklearn/externals/joblib/parallel.py in __call__(self=Parallel(n_jobs=1), iterable=<generator object <genexpr>>)
    912             # self._original_iterator is None, then this means either
    913             # that pre_dispatch == "all", n_jobs == 1 or that the first batch
    914             # was very quick and its callback already dispatched all the
    915             # remaining jobs.
    916             self._iterating = False
--> 917             if self.dispatch_one_batch(iterator):
        self.dispatch_one_batch = <bound method Parallel.dispatch_one_batch of Parallel(n_jobs=1)>
        iterator = <generator object <genexpr>>
    918                 self._iterating = self._original_iterator is not None
    919 
    920             while self.dispatch_one_batch(iterator):
    921                 pass

...........................................................................
/home/aquemy/.local/lib/python2.7/site-packages/sklearn/externals/joblib/parallel.py in dispatch_one_batch(self=Parallel(n_jobs=1), iterator=<generator object <genexpr>>)
    754                                  self._pickle_cache)
    755             if len(tasks) == 0:
    756                 # No more tasks available in the iterator: tell caller to stop.
    757                 return False
    758             else:
--> 759                 self._dispatch(tasks)
        self._dispatch = <bound method Parallel._dispatch of Parallel(n_jobs=1)>
        tasks = <sklearn.externals.joblib.parallel.BatchedCalls object>
    760                 return True
    761 
    762     def _print(self, msg, msg_args):
    763         """Display the message on stout or stderr depending on verbosity"""

...........................................................................
/home/aquemy/.local/lib/python2.7/site-packages/sklearn/externals/joblib/parallel.py in _dispatch(self=Parallel(n_jobs=1), batch=<sklearn.externals.joblib.parallel.BatchedCalls object>)
    711 
    712         dispatch_timestamp = time.time()
    713         cb = BatchCompletionCallBack(dispatch_timestamp, len(batch), self)
    714         with self._lock:
    715             job_idx = len(self._jobs)
--> 716             job = self._backend.apply_async(batch, callback=cb)
        job = undefined
        self._backend.apply_async = <bound method SequentialBackend.apply_async of <...lib._parallel_backends.SequentialBackend object>>
        batch = <sklearn.externals.joblib.parallel.BatchedCalls object>
        cb = <sklearn.externals.joblib.parallel.BatchCompletionCallBack object>
    717             # A job can complete so quickly than its callback is
    718             # called before we get here, causing self._jobs to
    719             # grow. To ensure correct results ordering, .insert is
    720             # used (rather than .append) in the following line

...........................................................................
/home/aquemy/.local/lib/python2.7/site-packages/sklearn/externals/joblib/_parallel_backends.py in apply_async(self=<sklearn.externals.joblib._parallel_backends.SequentialBackend object>, func=<sklearn.externals.joblib.parallel.BatchedCalls object>, callback=<sklearn.externals.joblib.parallel.BatchCompletionCallBack object>)
    177             raise ValueError('n_jobs == 0 in Parallel has no meaning')
    178         return 1
    179 
    180     def apply_async(self, func, callback=None):
    181         """Schedule a func to be run"""
--> 182         result = ImmediateResult(func)
        result = undefined
        func = <sklearn.externals.joblib.parallel.BatchedCalls object>
    183         if callback:
    184             callback(result)
    185         return result
    186 

...........................................................................
/home/aquemy/.local/lib/python2.7/site-packages/sklearn/externals/joblib/_parallel_backends.py in __init__(self=<sklearn.externals.joblib._parallel_backends.ImmediateResult object>, batch=<sklearn.externals.joblib.parallel.BatchedCalls object>)
    544 
    545 class ImmediateResult(object):
    546     def __init__(self, batch):
    547         # Don't delay the application, to avoid keeping the input
    548         # arguments in memory
--> 549         self.results = batch()
        self.results = undefined
        batch = <sklearn.externals.joblib.parallel.BatchedCalls object>
    550 
    551     def get(self):
    552         return self.results
    553 

...........................................................................
/home/aquemy/.local/lib/python2.7/site-packages/sklearn/externals/joblib/parallel.py in __call__(self=<sklearn.externals.joblib.parallel.BatchedCalls object>)
    220     def __call__(self):
    221         # Set the default nested backend to self._backend but do not set the
    222         # change the default number of processes to -1
    223         with parallel_backend(self._backend, n_jobs=self._n_jobs):
    224             return [func(*args, **kwargs)
--> 225                     for func, args, kwargs in self.items]
        func = <function _parallel_build_trees>
        args = (DecisionTreeClassifier(class_weight=None, criter...=False, random_state=1608637542, splitter='best'), RandomForestClassifier(bootstrap=True, class_wei...se, random_state=42, verbose=0, warm_start=False), array([[ 1.5603281 ],
       [-0.6136244 ],
    ....1804035 ],
       [ 3.6450589 ]], dtype=float32), array([[0.],
       [0.],
       [0.],
       [0...    [0.],
       [1.],
       [1.],
       [2.]]), None, 0, 10)
        kwargs = {'class_weight': None, 'verbose': 0}
        self.items = [(<function _parallel_build_trees>, (DecisionTreeClassifier(class_weight=None, criter...=False, random_state=1608637542, splitter='best'), RandomForestClassifier(bootstrap=True, class_wei...se, random_state=42, verbose=0, warm_start=False), array([[ 1.5603281 ],
       [-0.6136244 ],
    ....1804035 ],
       [ 3.6450589 ]], dtype=float32), array([[0.],
       [0.],
       [0.],
       [0...    [0.],
       [1.],
       [1.],
       [2.]]), None, 0, 10), {'class_weight': None, 'verbose': 0})]
    226 
    227     def __len__(self):
    228         return self._size
    229 

...........................................................................
/home/aquemy/.local/lib/python2.7/site-packages/sklearn/ensemble/forest.py in _parallel_build_trees(tree=DecisionTreeClassifier(class_weight=None, criter...=False, random_state=1608637542, splitter='best'), forest=RandomForestClassifier(bootstrap=True, class_wei...se, random_state=42, verbose=0, warm_start=False), X=array([[ 1.5603281 ],
       [-0.6136244 ],
    ....1804035 ],
       [ 3.6450589 ]], dtype=float32), y=array([[0.],
       [0.],
       [0.],
       [0...    [0.],
       [1.],
       [1.],
       [2.]]), sample_weight=None, tree_idx=0, n_trees=10, verbose=0, class_weight=None)
    114                 simplefilter('ignore', DeprecationWarning)
    115                 curr_sample_weight *= compute_sample_weight('auto', y, indices)
    116         elif class_weight == 'balanced_subsample':
    117             curr_sample_weight *= compute_sample_weight('balanced', y, indices)
    118 
--> 119         tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)
        tree.fit = <bound method DecisionTreeClassifier.fit of Deci...False, random_state=1608637542, splitter='best')>
        X = array([[ 1.5603281 ],
       [-0.6136244 ],
    ....1804035 ],
       [ 3.6450589 ]], dtype=float32)
        y = array([[0.],
       [0.],
       [0.],
       [0...    [0.],
       [1.],
       [1.],
       [2.]])
        sample_weight = None
        curr_sample_weight = array([2., 0., 2., 1., 2., 0., 1., 2., 1., 1., 2... 0., 0., 0., 2., 0., 5., 0., 2., 0., 0., 1., 0.])
    120     else:
    121         tree.fit(X, y, sample_weight=sample_weight, check_input=False)
    122 
    123     return tree

...........................................................................
/home/aquemy/.local/lib/python2.7/site-packages/sklearn/tree/tree.py in fit(self=DecisionTreeClassifier(class_weight=None, criter...=False, random_state=1608637542, splitter='best'), X=array([[ 1.5603281 ],
       [-0.6136244 ],
    ....1804035 ],
       [ 3.6450589 ]], dtype=float32), y=array([[0.],
       [0.],
       [0.],
       [0...    [0.],
       [1.],
       [1.],
       [2.]]), sample_weight=array([2., 0., 2., 1., 2., 0., 1., 2., 1., 1., 2... 0., 0., 0., 2., 0., 5., 0., 2., 0., 0., 1., 0.]), check_input=False, X_idx_sorted=None)
    796 
    797         super(DecisionTreeClassifier, self).fit(
    798             X, y,
    799             sample_weight=sample_weight,
    800             check_input=check_input,
--> 801             X_idx_sorted=X_idx_sorted)
        X_idx_sorted = None
    802         return self
    803 
    804     def predict_proba(self, X, check_input=True):
    805         """Predict class probabilities of the input samples X.

...........................................................................
/home/aquemy/.local/lib/python2.7/site-packages/sklearn/tree/tree.py in fit(self=DecisionTreeClassifier(class_weight=None, criter...=False, random_state=1608637542, splitter='best'), X=array([[ 1.5603281 ],
       [-0.6136244 ],
    ....1804035 ],
       [ 3.6450589 ]], dtype=float32), y=array([[0.],
       [0.],
       [0.],
       [0...    [0.],
       [1.],
       [1.],
       [2.]]), sample_weight=array([2., 0., 2., 1., 2., 0., 1., 2., 1., 1., 2... 0., 0., 0., 2., 0., 5., 0., 2., 0., 0., 1., 0.]), check_input=False, X_idx_sorted=None)
    237         if not 0 <= self.min_weight_fraction_leaf <= 0.5:
    238             raise ValueError("min_weight_fraction_leaf must in [0, 0.5]")
    239         if max_depth <= 0:
    240             raise ValueError("max_depth must be greater than zero. ")
    241         if not (0 < max_features <= self.n_features_):
--> 242             raise ValueError("max_features must be in (0, n_features]")
    243         if not isinstance(max_leaf_nodes, (numbers.Integral, np.integer)):
    244             raise ValueError("max_leaf_nodes must be integral number but was "
    245                              "%r" % max_leaf_nodes)
    246         if -1 < max_leaf_nodes < 2:

ValueError: max_features must be in (0, n_features]
___________________________________________________________________________
Best score: 0.966666666667 (0.0333333333333) [J] | Score: 0.0 (0.0) [J]
Best score: 0.966666666667 (0.0333333333333) [J] | Score: 0.92 (0.0581186525805) [J]
Best score: 0.966666666667 (0.0333333333333) [J] | Score: 0.866666666667 (0.0942809041582) [J]
Best score: 0.966666666667 (0.0333333333333) [J] | Score: 0.666666666667 (1.11022302463e-16) [J]
Best score: 0.966666666667 (0.0333333333333) [J] | Score: 0.913333333333 (0.0669991708075) [J]
JoblibValueError
___________________________________________________________________________
...........................................................................
/home/aquemy/dev/dp_hyperparameters/extension/main.py in <module>()
     27 
     28     serializer.serialize_results(scenario, policy)
     29 
     30 if __name__ == "__main__":
     31     args = cli.parse_args()
---> 32     main(args)

...........................................................................
/home/aquemy/dev/dp_hyperparameters/extension/main.py in main(args=Namespace(customize=[(['control', 'seed'], '42')...io='./scenarios/rf_iris_joint.yaml', verbosity=0))
     21         test_size=0.4, 
     22         random_state=scenario['control']['seed']
     23     )
     24 
     25     policy = policies.initiate(scenario['setup']['policy'], config)
---> 26     policy.run(X,y)
        policy.run = <bound method Joint.run of <experiment.policies.joint.Joint object>>
        X = array([[5.1, 3.5, 1.4, 0.2],
       [4.9, 3. , 1....2, 3.4, 5.4, 2.3],
       [5.9, 3. , 5.1, 1.8]])
        y = array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,... 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2])
     27 
     28     serializer.serialize_results(scenario, policy)
     29 
     30 if __name__ == "__main__":

...........................................................................
/home/aquemy/dev/dp_hyperparameters/extension/experiment/policies/joint.py in run(self=<experiment.policies.joint.Joint object>, X=array([[5.1, 3.5, 1.4, 0.2],
       [4.9, 3. , 1....2, 3.4, 5.4, 2.3],
       [5.9, 3. , 5.1, 1.8]]), y=array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,... 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]))
     32             algo=tpe.suggest, 
     33             max_evals=None,
     34             max_time=self.config['time'],     
     35             trials=trials,
     36             show_progressbar=False,
---> 37             verbose=0
     38         )
     39 
     40         best_config = self.context['best_config']
     41         super(Joint, self).display_step_results(best_config)

...........................................................................
/home/aquemy/dev/dp_hyperparameters/extension/hyperopt/fmin.py in fmin(fn=<functools.partial object>, space={'algorithm': {'bootstrap': <hyperopt.pyll.base.Apply object>, 'criterion': <hyperopt.pyll.base.Apply object>, 'max_depth': <hyperopt.pyll.base.Apply object>, 'max_features': <hyperopt.pyll.base.Apply object>, 'max_leaf_nodes': <hyperopt.pyll.base.Apply object>, 'min_samples_split': <hyperopt.pyll.base.Apply object>, 'n_estimators': <hyperopt.pyll.base.Apply object>}, 'pipeline': {'features': <hyperopt.pyll.base.Apply object>, 'normalizer': <hyperopt.pyll.base.Apply object>, 'rebalance': <hyperopt.pyll.base.Apply object>}}, algo=<function suggest>, max_evals=9223372036854775807, max_time=300, trials=<hyperopt.base.Trials object>, rstate=<mtrand.RandomState object>, allow_trials_fmin=True, pass_expr_memo_ctrl=None, catch_eval_exceptions=False, verbose=0, return_argmin=True, points_to_evaluate=None, max_queue_len=1, show_progressbar=False)
    406             pass_expr_memo_ctrl=pass_expr_memo_ctrl,
    407             verbose=verbose,
    408             catch_eval_exceptions=catch_eval_exceptions,
    409             return_argmin=return_argmin,
    410             show_progressbar=show_progressbar,
--> 411             max_time=max_time
        max_time = 300
    412         )
    413 
    414     if trials is None:
    415         if points_to_evaluate is None:

...........................................................................
/home/aquemy/dev/dp_hyperparameters/extension/hyperopt/base.py in fmin(self=<hyperopt.base.Trials object>, fn=<functools.partial object>, space={'algorithm': {'bootstrap': <hyperopt.pyll.base.Apply object>, 'criterion': <hyperopt.pyll.base.Apply object>, 'max_depth': <hyperopt.pyll.base.Apply object>, 'max_features': <hyperopt.pyll.base.Apply object>, 'max_leaf_nodes': <hyperopt.pyll.base.Apply object>, 'min_samples_split': <hyperopt.pyll.base.Apply object>, 'n_estimators': <hyperopt.pyll.base.Apply object>}, 'pipeline': {'features': <hyperopt.pyll.base.Apply object>, 'normalizer': <hyperopt.pyll.base.Apply object>, 'rebalance': <hyperopt.pyll.base.Apply object>}}, algo=<function suggest>, max_evals=9223372036854775807, max_time=300, rstate=<mtrand.RandomState object>, verbose=0, pass_expr_memo_ctrl=None, catch_eval_exceptions=False, return_argmin=True, show_progressbar=False)
    636             verbose=verbose,
    637             allow_trials_fmin=False,  # -- prevent recursion
    638             pass_expr_memo_ctrl=pass_expr_memo_ctrl,
    639             catch_eval_exceptions=catch_eval_exceptions,
    640             return_argmin=return_argmin,
--> 641             show_progressbar=show_progressbar)
        show_progressbar = False
    642 
    643 
    644 def trials_from_docs(docs, validate=True, **kwargs):
    645     """Construct a Trials base class instance from a list of trials documents

...........................................................................
/home/aquemy/dev/dp_hyperparameters/extension/hyperopt/fmin.py in fmin(fn=<functools.partial object>, space={'algorithm': {'bootstrap': <hyperopt.pyll.base.Apply object>, 'criterion': <hyperopt.pyll.base.Apply object>, 'max_depth': <hyperopt.pyll.base.Apply object>, 'max_features': <hyperopt.pyll.base.Apply object>, 'max_leaf_nodes': <hyperopt.pyll.base.Apply object>, 'min_samples_split': <hyperopt.pyll.base.Apply object>, 'n_estimators': <hyperopt.pyll.base.Apply object>}, 'pipeline': {'features': <hyperopt.pyll.base.Apply object>, 'normalizer': <hyperopt.pyll.base.Apply object>, 'rebalance': <hyperopt.pyll.base.Apply object>}}, algo=<function suggest>, max_evals=9223372036854775807, max_time=300, trials=<hyperopt.base.Trials object>, rstate=<mtrand.RandomState object>, allow_trials_fmin=False, pass_expr_memo_ctrl=None, catch_eval_exceptions=False, verbose=0, return_argmin=True, points_to_evaluate=None, max_queue_len=1, show_progressbar=False)
    426                     verbose=verbose,
    427                     max_queue_len=max_queue_len,
    428                     show_progressbar=show_progressbar,
    429                     max_time=max_time)
    430     rval.catch_eval_exceptions = catch_eval_exceptions
--> 431     rval.exhaust()
        rval.exhaust = <bound method FMinIter.exhaust of <hyperopt.fmin.FMinIter object>>
    432     if return_argmin:
    433         return trials.argmin
    434     elif len(trials) > 0:
    435         # Only if there are some succesfull trail runs, return the best point in the evaluation space

...........................................................................
/home/aquemy/dev/dp_hyperparameters/extension/hyperopt/fmin.py in exhaust(self=<hyperopt.fmin.FMinIter object>)
    273             raise StopIteration()
    274         return self.trials
    275 
    276     def exhaust(self):
    277         n_done = len(self.trials)
--> 278         self.run(self.max_evals - n_done, block_until_done=self.asynchronous)
        self.run = <bound method FMinIter.run of <hyperopt.fmin.FMinIter object>>
        self.max_evals = 9223372036854775807
        n_done = 0
        self.asynchronous = False
    279         self.trials.refresh()
    280         return self
    281 
    282 

...........................................................................
/home/aquemy/dev/dp_hyperparameters/extension/hyperopt/fmin.py in run(self=<hyperopt.fmin.FMinIter object>, N=9223372036854775807, block_until_done=False)
    232                     if self.asynchronous:
    233                         # -- wait for workers to fill in the trials
    234                         time.sleep(self.poll_interval_secs)
    235                     else:
    236                         # -- loop over trials and do the jobs directly
--> 237                         self.serial_evaluate()
        self.serial_evaluate = <bound method FMinIter.serial_evaluate of <hyperopt.fmin.FMinIter object>>
    238                     try:
    239                         res = [d['result']['loss'] for d in
    240                                          self.trials.trials if
    241                                          d['result']['status'] == 'ok']

...........................................................................
/home/aquemy/dev/dp_hyperparameters/extension/hyperopt/fmin.py in serial_evaluate(self=<hyperopt.fmin.FMinIter object>, N=-1)
    138                 trial['book_time'] = now
    139                 trial['refresh_time'] = now
    140                 spec = base.spec_from_misc(trial['misc'])
    141                 ctrl = base.Ctrl(self.trials, current_trial=trial)
    142                 try:
--> 143                     result = self.domain.evaluate(spec, ctrl)
        result = undefined
        self.domain.evaluate = <bound method Domain.evaluate of <hyperopt.base.Domain object>>
        spec = {'bootstrap': 0, 'criterion': 0, 'features': 2, 'features_SelectKBest_features__k': 0, 'max_depth': 4, 'max_features': 2, 'max_leaf_nodes': 1, 'min_samples_split': 1, 'n_estimators': 0, 'normalizer': 3, ...}
        ctrl = <hyperopt.base.Ctrl object>
    144                 except Exception as e:
    145                     logger.info('job exception: %s' % str(e))
    146                     trial['state'] = base.JOB_STATE_ERROR
    147                     trial['misc']['error'] = (str(type(e)), str(e))

...........................................................................
/home/aquemy/dev/dp_hyperparameters/extension/hyperopt/base.py in evaluate(self=<hyperopt.base.Domain object>, config={'bootstrap': 0, 'criterion': 0, 'features': 2, 'features_SelectKBest_features__k': 0, 'max_depth': 4, 'max_features': 2, 'max_leaf_nodes': 1, 'min_samples_split': 1, 'n_estimators': 0, 'normalizer': 3, ...}, ctrl=<hyperopt.base.Ctrl object>, attach_attachments=True)
    841             #    or the normal Python part (self.fn)
    842             pyll_rval = pyll.rec_eval(
    843                 self.expr,
    844                 memo=memo,
    845                 print_node_on_error=self.rec_eval_print_node_on_error)
--> 846             rval = self.fn(pyll_rval)
        rval = undefined
        self.fn = <functools.partial object>
        pyll_rval = {'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': None, 'max_features': 3, 'max_leaf_nodes': 3, 'min_samples_split': 3, 'n_estimators': 10}, 'pipeline': {'features': ('features_SelectKBest', {'features__k': 1}), 'normalizer': ('normalizer_MinMaxScaler', {}), 'rebalance': ('rebalance_CondensedNearestNeighbour', {'rebalance__n_neighbors': 3})}}
    847 
    848         if isinstance(rval, (float, int, np.number)):
    849             dict_rval = {'loss': float(rval), 'status': STATUS_OK}
    850         else:

...........................................................................
/home/aquemy/dev/dp_hyperparameters/extension/experiment/objective.py in objective_joint(wconfig={'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': None, 'max_features': 3, 'max_leaf_nodes': 3, 'min_samples_split': 3, 'n_estimators': 10}, 'pipeline': {'features': ('features_SelectKBest', {'features__k': 1}), 'normalizer': ('normalizer_MinMaxScaler', {}), 'rebalance': ('rebalance_CondensedNearestNeighbour', {'rebalance__n_neighbors': 3})}}, algorithm='RandomForest', X=array([[5.1, 3.5, 1.4, 0.2],
       [4.9, 3. , 1....2, 3.4, 5.4, 2.3],
       [5.9, 3. , 5.1, 1.8]]), y=array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,... 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]), context={'baseline_score': 0.9466666666666667, 'baseline_score_std': 0.04988876515698587, 'best_config': {'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': 4, 'max_features': 3, 'max_leaf_nodes': 3, 'min_samples_split': 3, 'n_estimators': 10}, 'config_hash': {'algorithm': 'ffb7ff225ce3d3712c96cf87fe42202988ee2eb0', 'config': 'bae32f426be9cd6243523c023944a8c148fe4aeb', 'pipeline': 'd2a68bfda6fcdec4ae0ffc7d7b6a2122bc1cd673'}, 'duration': 0.7115809917449951, 'iteration': 113, 'loss': 0.033333333333333215, 'max_history_score': 0.9666666666666668, 'max_history_score_std': 0.033333333333333326, 'max_history_step': 'joint', 'pipeline': {'features': ('features_NoneType', {}), 'normalizer': ('normalizer_PowerTransformer', {}), 'rebalance': ('rebalance_CondensedNearestNeighbour', {'rebalance__n_neighbors': 2})}, 'score': 0.9666666666666668, ...}, 'history': [{'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': 2, 'max_features': None, 'max_leaf_nodes': 5, 'min_samples_split': 2, 'n_estimators': 75}, 'config_hash': {'algorithm': '3af5b0cce71c8fe2545246ca24ff5bc3dd516e06', 'config': 'db6ac7e6d348155757e4794bb5f88fe2b4f63d50', 'pipeline': '8d59f4b94cef6be9306ed86a22a9570fa670d567'}, 'duration': 1.149928092956543, 'iteration': 0, 'loss': 0.046666666666666634, 'max_history_score': 0.9533333333333334, 'max_history_score_std': 0.059999999999999984, 'max_history_step': 'joint', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 4, 'features__selectkbest__k': 3}), 'normalizer': ('normalizer_StandardScaler', {'normalizer__with_mean': True, 'normalizer__with_std': True}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 6})}, 'score': 0.9533333333333334, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': 1, 'max_features': 2, 'max_leaf_nodes': 2, 'min_samples_split': 5, 'n_estimators': 100}, 'config_hash': {'algorithm': 'e13eb05fd9a62d2f63bbb1c1deff0cd620d5e6ab', 'config': '4db6fb84d85f52659f780e682ffac5712c3d8a94', 'pipeline': '64c9a1ca9d53ae67244bdd942f4db36a3c05218c'}, 'duration': 1.7678282260894775, 'iteration': 1, 'loss': 0.18000000000000005, 'max_history_score': 0.9533333333333334, 'max_history_score_std': 0.059999999999999984, 'max_history_step': 'joint', 'pipeline': {'features': ('features_NoneType', {}), 'normalizer': ('normalizer_PowerTransformer', {}), 'rebalance': ('rebalance_NearMiss', {'rebalance__n_neighbors': 1})}, 'score': 0.82, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': 1, 'max_features': None, 'max_leaf_nodes': None, 'min_samples_split': 5, 'n_estimators': 75}, 'config_hash': {'algorithm': '94b0d7a654c508cc63643f78fe4f0f07e6f07c1e', 'config': '4403c5a85e951938d3c454e961d3a412780722f6', 'pipeline': '3e47444880d8367fbac2faaba2e52a917274aa58'}, 'duration': 0.8397619724273682, 'iteration': 2, 'loss': 0.03333333333333344, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_PCA', {'features__n_components': 3}), 'normalizer': ('normalizer_MinMaxScaler', {}), 'rebalance': ('rebalance_NoneType', {})}, 'score': 0.9666666666666666, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': None, 'max_features': None, 'max_leaf_nodes': 3, 'min_samples_split': 3, 'n_estimators': 75}, 'config_hash': {'algorithm': 'e8332f0a8902bda03bf70e7978cc5d52affb29d3', 'config': 'a064e2df18ab98d44dabcefbc7bed94913f1d0be', 'pipeline': '7eea819c2a8c103c4b1e9e9c1e224aebba95081f'}, 'duration': 0.8501448631286621, 'iteration': 3, 'loss': 0.053333333333333344, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 2, 'features__selectkbest__k': 4}), 'normalizer': ('normalizer_NoneType', {}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 7})}, 'score': 0.9466666666666667, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'entropy', 'max_depth': 3, 'max_features': 3, 'max_leaf_nodes': None, 'min_samples_split': 5, 'n_estimators': 75}, 'config_hash': {'algorithm': '7a4491035bc6bd737fe9a8cda8a79a02d02d5c74', 'config': '0ddb6f5cab3db4dddd7682966a57205f3e329ad4', 'pipeline': 'a9ae03fe38334f6868cbf84cdd3d629d4bbe3fb0'}, 'duration': 1.1026010513305664, 'iteration': 4, 'loss': 0.05999999999999994, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 2, 'features__selectkbest__k': 1}), 'normalizer': ('normalizer_NoneType', {}), 'rebalance': ('rebalance_NoneType', {})}, 'score': 0.9400000000000001, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'gini', 'max_depth': 3, 'max_features': 1, 'max_leaf_nodes': 5, 'min_samples_split': 2, 'n_estimators': 25}, 'config_hash': {'algorithm': '9826d20b2d6a0f559cf7f16450ce7526f07e8434', 'config': '49f25751bca61cdd461a8cbd2923689b642f98ed', 'pipeline': '19b249664c5bf067de1fed4334a296f947ce774a'}, 'duration': 0.35647010803222656, 'iteration': 5, 'loss': 0.046666666666666634, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_NoneType', {}), 'normalizer': ('normalizer_NoneType', {}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 6})}, 'score': 0.9533333333333334, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'gini', 'max_depth': 2, 'max_features': 1, 'max_leaf_nodes': 2, 'min_samples_split': 2, 'n_estimators': 50}, 'config_hash': {'algorithm': '0a4f6fbb07e0f32c6f675489a0fc82eee05bd8e1', 'config': '5c3a2b6f5e63fb45f10e41e0318b354912ec44f6', 'pipeline': 'dc3b9f176f090005e38b142f11d80e93a7dc5d5e'}, 'duration': 0.7213859558105469, 'iteration': 6, 'loss': 0.31333333333333324, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 1, 'features__selectkbest__k': 4}), 'normalizer': ('normalizer_PowerTransformer', {}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 7})}, 'score': 0.6866666666666668, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'entropy', 'max_depth': 4, 'max_features': 3, 'max_leaf_nodes': 5, 'min_samples_split': 5, 'n_estimators': 10}, 'config_hash': {'algorithm': 'b8112b97ecfc10f00a195af661dcc861cac21289', 'config': 'd3b129b397350f1b6572651c67c01de49b4b174c', 'pipeline': '5b0357ed7072c37b3d6f458bb5d49ff7d825f603'}, 'duration': 0.8299109935760498, 'iteration': 7, 'loss': 1.0, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_PCA', {'features__n_components': 2}), 'normalizer': ('normalizer_StandardScaler', {'normalizer__with_mean': True, 'normalizer__with_std': False}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 6})}, 'score': 0.0, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'gini', 'max_depth': 4, 'max_features': None, 'max_leaf_nodes': 2, 'min_samples_split': 5, 'n_estimators': 100}, 'config_hash': {'algorithm': '40ca24df19b8d164d9d098a6bed1ce056fbbb961', 'config': '813bde1108cc3c4b9bfb3a22cbb421bda7eac671', 'pipeline': '74a7b8705a1c22f7dea5e44e4ebda8f1e48add71'}, 'duration': 2.2111589908599854, 'iteration': 8, 'loss': 0.33333333333333326, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_PCA', {'features__n_components': 2}), 'normalizer': ('normalizer_StandardScaler', {'normalizer__with_mean': False, 'normalizer__with_std': True}), 'rebalance': ('rebalance_NearMiss', {'rebalance__n_neighbors': 2})}, 'score': 0.6666666666666667, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'entropy', 'max_depth': 2, 'max_features': 1, 'max_leaf_nodes': 5, 'min_samples_split': 2, 'n_estimators': 100}, 'config_hash': {'algorithm': '331418a5c12cf1453876eef85e9d98fc8e54fa11', 'config': '31930b6860ed406d59bf7e59ba1925d94704bd3b', 'pipeline': '054bef356f90ec6f644ef3ffc688766744db51c2'}, 'duration': 1.0501940250396729, 'iteration': 9, 'loss': 0.053333333333333344, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_SelectKBest', {'features__k': 1}), 'normalizer': ('normalizer_RobustScaler', {'normalizer__quantile_range': (...), 'normalizer__with_centering': True, 'normalizer__with_scaling': True}), 'rebalance': ('rebalance_NearMiss', {'rebalance__n_neighbors': 2})}, 'score': 0.9466666666666667, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'entropy', 'max_depth': 3, 'max_features': None, 'max_leaf_nodes': 3, 'min_samples_split': 2, 'n_estimators': 100}, 'config_hash': {'algorithm': 'dbc1b8126649fe93dce5fbb37e4015b0acfb179e', 'config': '9913cd550615a9d0946ab4a755a8b9f619e442fd', 'pipeline': 'dd626121cea079ebb32e184ca65483ec7a6d7f59'}, 'duration': 1.120617151260376, 'iteration': 10, 'loss': 0.046666666666666634, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 2, 'features__selectkbest__k': 1}), 'normalizer': ('normalizer_MinMaxScaler', {}), 'rebalance': ('rebalance_NoneType', {})}, 'score': 0.9533333333333334, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'gini', 'max_depth': 3, 'max_features': 3, 'max_leaf_nodes': None, 'min_samples_split': 3, 'n_estimators': 75}, 'config_hash': {'algorithm': '34917a130df5a975f78bd7ec1a0c7b1ffdc787a9', 'config': '95fc8cadc088141290b7de9c388977e4685f0108', 'pipeline': '550d10faf2f08db48516cc3501558816d6a99bc0'}, 'duration': 1.4287099838256836, 'iteration': 11, 'loss': 0.19333333333333313, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 3, 'features__selectkbest__k': 4}), 'normalizer': ('normalizer_StandardScaler', {'normalizer__with_mean': False, 'normalizer__with_std': False}), 'rebalance': ('rebalance_CondensedNearestNeighbour', {'rebalance__n_neighbors': 1})}, 'score': 0.8066666666666669, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'entropy', 'max_depth': 1, 'max_features': 2, 'max_leaf_nodes': 5, 'min_samples_split': 2, 'n_estimators': 75}, 'config_hash': {'algorithm': '33f9abb4aee44a395a9f3b3ffa9ce80a8cdaed7c', 'config': '40fa726f0360cf6af55f9b5902d399d02f61f157', 'pipeline': 'cfd1d20841fe2153da762c95e79f95a3fb1e426a'}, 'duration': 1.2978079319000244, 'iteration': 12, 'loss': 0.053333333333333344, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_PCA', {'features__n_components': 4}), 'normalizer': ('normalizer_MinMaxScaler', {}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 7})}, 'score': 0.9466666666666667, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'entropy', 'max_depth': 4, 'max_features': 2, 'max_leaf_nodes': 5, 'min_samples_split': 3, 'n_estimators': 25}, 'config_hash': {'algorithm': '210111ec6562d09eb093e98ed69ef1c662e11a50', 'config': '0fb8e77c7bd9a58b72f1b33c21a59a09a8c676ba', 'pipeline': '5d269d759e0c7926a685a14b263ace8ae0071e4b'}, 'duration': 0.36649012565612793, 'iteration': 13, 'loss': 0.040000000000000036, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 2, 'features__selectkbest__k': 2}), 'normalizer': ('normalizer_NoneType', {}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 7})}, 'score': 0.96, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'entropy', 'max_depth': 3, 'max_features': 1, 'max_leaf_nodes': 5, 'min_samples_split': 2, 'n_estimators': 25}, 'config_hash': {'algorithm': '0e989a03980101fabf79eda3326ed2870e11d690', 'config': 'f4bffd5d8c67a9c5321a9943c4a99678f59a02b7', 'pipeline': '865ee1e3fe8334c3d5ecb2038d5a5d1b3ba50e75'}, 'duration': 0.35639500617980957, 'iteration': 14, 'loss': 0.046666666666666634, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_NoneType', {}), 'normalizer': ('normalizer_RobustScaler', {'normalizer__quantile_range': (...), 'normalizer__with_centering': True, 'normalizer__with_scaling': False}), 'rebalance': ('rebalance_NoneType', {})}, 'score': 0.9533333333333334, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'entropy', 'max_depth': None, 'max_features': 3, 'max_leaf_nodes': 3, 'min_samples_split': 5, 'n_estimators': 10}, 'config_hash': {'algorithm': '9c592e876c13de5e23e6de5b868e01755d63e72e', 'config': '1e6a68cd1eeac886d90724d78b1cb5fb76a3cde4', 'pipeline': '5a1ca4d82f21b7de0d2c918630a42510673fa36e'}, 'duration': 0.18141412734985352, 'iteration': 15, 'loss': 0.046666666666666634, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_SelectKBest', {'features__k': 3}), 'normalizer': ('normalizer_RobustScaler', {'normalizer__quantile_range': (...), 'normalizer__with_centering': True, 'normalizer__with_scaling': True}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 6})}, 'score': 0.9533333333333334, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': 1, 'max_features': None, 'max_leaf_nodes': None, 'min_samples_split': 5, 'n_estimators': 10}, 'config_hash': {'algorithm': '8bed77aef289bfd453b2858bd288ae5ba7160f2b', 'config': '781185bcb8999045de8d489f253a1a1ba4247932', 'pipeline': '1ece7eabedc2be9e5b0a1be65c570d08ffa3eb54'}, 'duration': 0.1636829376220703, 'iteration': 16, 'loss': 0.053333333333333344, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_NoneType', {}), 'normalizer': ('normalizer_NoneType', {}), 'rebalance': ('rebalance_NearMiss', {'rebalance__n_neighbors': 1})}, 'score': 0.9466666666666667, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'gini', 'max_depth': 3, 'max_features': 2, 'max_leaf_nodes': 2, 'min_samples_split': 5, 'n_estimators': 75}, 'config_hash': {'algorithm': '617b97d9ba21d3373bc51ffa9cccf9c6f91a77b3', 'config': '99fb425b4e8c5d80228cab94202252aa25cdf77c', 'pipeline': 'd6242929c3b515c7719e60423023ac604311afc3'}, 'duration': 0.8468999862670898, 'iteration': 17, 'loss': 0.24, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_PCA', {'features__n_components': 4}), 'normalizer': ('normalizer_PowerTransformer', {}), 'rebalance': ('rebalance_NearMiss', {'rebalance__n_neighbors': 2})}, 'score': 0.76, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': 1, 'max_features': 1, 'max_leaf_nodes': 2, 'min_samples_split': 5, 'n_estimators': 50}, 'config_hash': {'algorithm': 'b92d2697cdd4979da443369d6596229ec091626a', 'config': 'c513a3e13281206ad76187dd817b1fff93d54fe1', 'pipeline': 'c4b4f914a3ca8df967cade997a90366d85a371b9'}, 'duration': 0.6724588871002197, 'iteration': 18, 'loss': 0.23333333333333328, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 1, 'features__selectkbest__k': 3}), 'normalizer': ('normalizer_StandardScaler', {'normalizer__with_mean': True, 'normalizer__with_std': True}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 5})}, 'score': 0.7666666666666667, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'entropy', 'max_depth': None, 'max_features': None, 'max_leaf_nodes': 5, 'min_samples_split': 5, 'n_estimators': 10}, 'config_hash': {'algorithm': 'a0115de695e6cca2e81cbfb54df79bf4b43608b1', 'config': 'ba194015e20b5d67770e8c67342c3d8d0d01dc41', 'pipeline': '8d45fabfeb85ffdcabf7076bd0e65fffe97ce928'}, 'duration': 0.19424200057983398, 'iteration': 19, 'loss': 0.08666666666666667, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_PCA', {'features__n_components': 3}), 'normalizer': ('normalizer_NoneType', {}), 'rebalance': ('rebalance_NoneType', {})}, 'score': 0.9133333333333333, ...}, ...], 'history_hash': ['db6ac7e6d348155757e4794bb5f88fe2b4f63d50', '4db6fb84d85f52659f780e682ffac5712c3d8a94', '4403c5a85e951938d3c454e961d3a412780722f6', 'a064e2df18ab98d44dabcefbc7bed94913f1d0be', '0ddb6f5cab3db4dddd7682966a57205f3e329ad4', '49f25751bca61cdd461a8cbd2923689b642f98ed', '5c3a2b6f5e63fb45f10e41e0318b354912ec44f6', 'd3b129b397350f1b6572651c67c01de49b4b174c', '813bde1108cc3c4b9bfb3a22cbb421bda7eac671', '31930b6860ed406d59bf7e59ba1925d94704bd3b', '9913cd550615a9d0946ab4a755a8b9f619e442fd', '95fc8cadc088141290b7de9c388977e4685f0108', '40fa726f0360cf6af55f9b5902d399d02f61f157', '0fb8e77c7bd9a58b72f1b33c21a59a09a8c676ba', 'f4bffd5d8c67a9c5321a9943c4a99678f59a02b7', '1e6a68cd1eeac886d90724d78b1cb5fb76a3cde4', '781185bcb8999045de8d489f253a1a1ba4247932', '99fb425b4e8c5d80228cab94202252aa25cdf77c', 'c513a3e13281206ad76187dd817b1fff93d54fe1', 'ba194015e20b5d67770e8c67342c3d8d0d01dc41', ...], 'history_index': {'00f0493590a2cb5e98a35b29816f8cd9f87f96ec': 208, '013329309d510b94f19d930320402d65f953a847': 39, '038a0f515e2ec894ee8e34f9caa2889eb3ebd5ce': 66, '052ae4bf232b316187b078abae42c2be19e16a00': 111, '0659afebf316aafeb75612fb07081a04c28545ed': 74, '06e7cde9f3556cd01332ce389ad1d8925cd4b4a4': 120, '08606f2a0f0a6c9de204020b4632e09fcee0ae56': 168, '0a05b5b0a70971a5e347aaab7a4d4a07a92222fd': 191, '0b6551ecfd6f83a15704a9db68f1599c99c6d3ef': 58, '0cfb4698cbf2d986bcd5e0c2ef0f974da60b205e': 194, ...}, 'iteration': 239, 'max_history_score': 0.9666666666666668, 'max_history_score_std': 0.033333333333333326, 'max_history_step': 'joint'}, config={'algorithm': 'RandomForest', 'seed': 42, 'time': 300})
    108 
    109 def objective_algo(algo_config, current_pipeline_config, algorithm, X, y, context, config):
    110     return objective(current_pipeline_config, algo_config, algorithm, X, y, context, config, step='algorithm')
    111 
    112 def objective_joint(wconfig, algorithm, X, y, context, config):
--> 113     return objective(wconfig['pipeline'], wconfig['algorithm'], algorithm, X, y, context, config, step='joint')
        wconfig = {'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': None, 'max_features': 3, 'max_leaf_nodes': 3, 'min_samples_split': 3, 'n_estimators': 10}, 'pipeline': {'features': ('features_SelectKBest', {'features__k': 1}), 'normalizer': ('normalizer_MinMaxScaler', {}), 'rebalance': ('rebalance_CondensedNearestNeighbour', {'rebalance__n_neighbors': 3})}}
        algorithm = 'RandomForest'
        X = array([[5.1, 3.5, 1.4, 0.2],
       [4.9, 3. , 1....2, 3.4, 5.4, 2.3],
       [5.9, 3. , 5.1, 1.8]])
        y = array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,... 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2])
        context = {'baseline_score': 0.9466666666666667, 'baseline_score_std': 0.04988876515698587, 'best_config': {'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': 4, 'max_features': 3, 'max_leaf_nodes': 3, 'min_samples_split': 3, 'n_estimators': 10}, 'config_hash': {'algorithm': 'ffb7ff225ce3d3712c96cf87fe42202988ee2eb0', 'config': 'bae32f426be9cd6243523c023944a8c148fe4aeb', 'pipeline': 'd2a68bfda6fcdec4ae0ffc7d7b6a2122bc1cd673'}, 'duration': 0.7115809917449951, 'iteration': 113, 'loss': 0.033333333333333215, 'max_history_score': 0.9666666666666668, 'max_history_score_std': 0.033333333333333326, 'max_history_step': 'joint', 'pipeline': {'features': ('features_NoneType', {}), 'normalizer': ('normalizer_PowerTransformer', {}), 'rebalance': ('rebalance_CondensedNearestNeighbour', {'rebalance__n_neighbors': 2})}, 'score': 0.9666666666666668, ...}, 'history': [{'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': 2, 'max_features': None, 'max_leaf_nodes': 5, 'min_samples_split': 2, 'n_estimators': 75}, 'config_hash': {'algorithm': '3af5b0cce71c8fe2545246ca24ff5bc3dd516e06', 'config': 'db6ac7e6d348155757e4794bb5f88fe2b4f63d50', 'pipeline': '8d59f4b94cef6be9306ed86a22a9570fa670d567'}, 'duration': 1.149928092956543, 'iteration': 0, 'loss': 0.046666666666666634, 'max_history_score': 0.9533333333333334, 'max_history_score_std': 0.059999999999999984, 'max_history_step': 'joint', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 4, 'features__selectkbest__k': 3}), 'normalizer': ('normalizer_StandardScaler', {'normalizer__with_mean': True, 'normalizer__with_std': True}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 6})}, 'score': 0.9533333333333334, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': 1, 'max_features': 2, 'max_leaf_nodes': 2, 'min_samples_split': 5, 'n_estimators': 100}, 'config_hash': {'algorithm': 'e13eb05fd9a62d2f63bbb1c1deff0cd620d5e6ab', 'config': '4db6fb84d85f52659f780e682ffac5712c3d8a94', 'pipeline': '64c9a1ca9d53ae67244bdd942f4db36a3c05218c'}, 'duration': 1.7678282260894775, 'iteration': 1, 'loss': 0.18000000000000005, 'max_history_score': 0.9533333333333334, 'max_history_score_std': 0.059999999999999984, 'max_history_step': 'joint', 'pipeline': {'features': ('features_NoneType', {}), 'normalizer': ('normalizer_PowerTransformer', {}), 'rebalance': ('rebalance_NearMiss', {'rebalance__n_neighbors': 1})}, 'score': 0.82, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': 1, 'max_features': None, 'max_leaf_nodes': None, 'min_samples_split': 5, 'n_estimators': 75}, 'config_hash': {'algorithm': '94b0d7a654c508cc63643f78fe4f0f07e6f07c1e', 'config': '4403c5a85e951938d3c454e961d3a412780722f6', 'pipeline': '3e47444880d8367fbac2faaba2e52a917274aa58'}, 'duration': 0.8397619724273682, 'iteration': 2, 'loss': 0.03333333333333344, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_PCA', {'features__n_components': 3}), 'normalizer': ('normalizer_MinMaxScaler', {}), 'rebalance': ('rebalance_NoneType', {})}, 'score': 0.9666666666666666, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': None, 'max_features': None, 'max_leaf_nodes': 3, 'min_samples_split': 3, 'n_estimators': 75}, 'config_hash': {'algorithm': 'e8332f0a8902bda03bf70e7978cc5d52affb29d3', 'config': 'a064e2df18ab98d44dabcefbc7bed94913f1d0be', 'pipeline': '7eea819c2a8c103c4b1e9e9c1e224aebba95081f'}, 'duration': 0.8501448631286621, 'iteration': 3, 'loss': 0.053333333333333344, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 2, 'features__selectkbest__k': 4}), 'normalizer': ('normalizer_NoneType', {}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 7})}, 'score': 0.9466666666666667, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'entropy', 'max_depth': 3, 'max_features': 3, 'max_leaf_nodes': None, 'min_samples_split': 5, 'n_estimators': 75}, 'config_hash': {'algorithm': '7a4491035bc6bd737fe9a8cda8a79a02d02d5c74', 'config': '0ddb6f5cab3db4dddd7682966a57205f3e329ad4', 'pipeline': 'a9ae03fe38334f6868cbf84cdd3d629d4bbe3fb0'}, 'duration': 1.1026010513305664, 'iteration': 4, 'loss': 0.05999999999999994, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 2, 'features__selectkbest__k': 1}), 'normalizer': ('normalizer_NoneType', {}), 'rebalance': ('rebalance_NoneType', {})}, 'score': 0.9400000000000001, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'gini', 'max_depth': 3, 'max_features': 1, 'max_leaf_nodes': 5, 'min_samples_split': 2, 'n_estimators': 25}, 'config_hash': {'algorithm': '9826d20b2d6a0f559cf7f16450ce7526f07e8434', 'config': '49f25751bca61cdd461a8cbd2923689b642f98ed', 'pipeline': '19b249664c5bf067de1fed4334a296f947ce774a'}, 'duration': 0.35647010803222656, 'iteration': 5, 'loss': 0.046666666666666634, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_NoneType', {}), 'normalizer': ('normalizer_NoneType', {}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 6})}, 'score': 0.9533333333333334, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'gini', 'max_depth': 2, 'max_features': 1, 'max_leaf_nodes': 2, 'min_samples_split': 2, 'n_estimators': 50}, 'config_hash': {'algorithm': '0a4f6fbb07e0f32c6f675489a0fc82eee05bd8e1', 'config': '5c3a2b6f5e63fb45f10e41e0318b354912ec44f6', 'pipeline': 'dc3b9f176f090005e38b142f11d80e93a7dc5d5e'}, 'duration': 0.7213859558105469, 'iteration': 6, 'loss': 0.31333333333333324, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 1, 'features__selectkbest__k': 4}), 'normalizer': ('normalizer_PowerTransformer', {}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 7})}, 'score': 0.6866666666666668, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'entropy', 'max_depth': 4, 'max_features': 3, 'max_leaf_nodes': 5, 'min_samples_split': 5, 'n_estimators': 10}, 'config_hash': {'algorithm': 'b8112b97ecfc10f00a195af661dcc861cac21289', 'config': 'd3b129b397350f1b6572651c67c01de49b4b174c', 'pipeline': '5b0357ed7072c37b3d6f458bb5d49ff7d825f603'}, 'duration': 0.8299109935760498, 'iteration': 7, 'loss': 1.0, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_PCA', {'features__n_components': 2}), 'normalizer': ('normalizer_StandardScaler', {'normalizer__with_mean': True, 'normalizer__with_std': False}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 6})}, 'score': 0.0, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'gini', 'max_depth': 4, 'max_features': None, 'max_leaf_nodes': 2, 'min_samples_split': 5, 'n_estimators': 100}, 'config_hash': {'algorithm': '40ca24df19b8d164d9d098a6bed1ce056fbbb961', 'config': '813bde1108cc3c4b9bfb3a22cbb421bda7eac671', 'pipeline': '74a7b8705a1c22f7dea5e44e4ebda8f1e48add71'}, 'duration': 2.2111589908599854, 'iteration': 8, 'loss': 0.33333333333333326, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_PCA', {'features__n_components': 2}), 'normalizer': ('normalizer_StandardScaler', {'normalizer__with_mean': False, 'normalizer__with_std': True}), 'rebalance': ('rebalance_NearMiss', {'rebalance__n_neighbors': 2})}, 'score': 0.6666666666666667, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'entropy', 'max_depth': 2, 'max_features': 1, 'max_leaf_nodes': 5, 'min_samples_split': 2, 'n_estimators': 100}, 'config_hash': {'algorithm': '331418a5c12cf1453876eef85e9d98fc8e54fa11', 'config': '31930b6860ed406d59bf7e59ba1925d94704bd3b', 'pipeline': '054bef356f90ec6f644ef3ffc688766744db51c2'}, 'duration': 1.0501940250396729, 'iteration': 9, 'loss': 0.053333333333333344, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_SelectKBest', {'features__k': 1}), 'normalizer': ('normalizer_RobustScaler', {'normalizer__quantile_range': (...), 'normalizer__with_centering': True, 'normalizer__with_scaling': True}), 'rebalance': ('rebalance_NearMiss', {'rebalance__n_neighbors': 2})}, 'score': 0.9466666666666667, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'entropy', 'max_depth': 3, 'max_features': None, 'max_leaf_nodes': 3, 'min_samples_split': 2, 'n_estimators': 100}, 'config_hash': {'algorithm': 'dbc1b8126649fe93dce5fbb37e4015b0acfb179e', 'config': '9913cd550615a9d0946ab4a755a8b9f619e442fd', 'pipeline': 'dd626121cea079ebb32e184ca65483ec7a6d7f59'}, 'duration': 1.120617151260376, 'iteration': 10, 'loss': 0.046666666666666634, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 2, 'features__selectkbest__k': 1}), 'normalizer': ('normalizer_MinMaxScaler', {}), 'rebalance': ('rebalance_NoneType', {})}, 'score': 0.9533333333333334, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'gini', 'max_depth': 3, 'max_features': 3, 'max_leaf_nodes': None, 'min_samples_split': 3, 'n_estimators': 75}, 'config_hash': {'algorithm': '34917a130df5a975f78bd7ec1a0c7b1ffdc787a9', 'config': '95fc8cadc088141290b7de9c388977e4685f0108', 'pipeline': '550d10faf2f08db48516cc3501558816d6a99bc0'}, 'duration': 1.4287099838256836, 'iteration': 11, 'loss': 0.19333333333333313, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 3, 'features__selectkbest__k': 4}), 'normalizer': ('normalizer_StandardScaler', {'normalizer__with_mean': False, 'normalizer__with_std': False}), 'rebalance': ('rebalance_CondensedNearestNeighbour', {'rebalance__n_neighbors': 1})}, 'score': 0.8066666666666669, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'entropy', 'max_depth': 1, 'max_features': 2, 'max_leaf_nodes': 5, 'min_samples_split': 2, 'n_estimators': 75}, 'config_hash': {'algorithm': '33f9abb4aee44a395a9f3b3ffa9ce80a8cdaed7c', 'config': '40fa726f0360cf6af55f9b5902d399d02f61f157', 'pipeline': 'cfd1d20841fe2153da762c95e79f95a3fb1e426a'}, 'duration': 1.2978079319000244, 'iteration': 12, 'loss': 0.053333333333333344, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_PCA', {'features__n_components': 4}), 'normalizer': ('normalizer_MinMaxScaler', {}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 7})}, 'score': 0.9466666666666667, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'entropy', 'max_depth': 4, 'max_features': 2, 'max_leaf_nodes': 5, 'min_samples_split': 3, 'n_estimators': 25}, 'config_hash': {'algorithm': '210111ec6562d09eb093e98ed69ef1c662e11a50', 'config': '0fb8e77c7bd9a58b72f1b33c21a59a09a8c676ba', 'pipeline': '5d269d759e0c7926a685a14b263ace8ae0071e4b'}, 'duration': 0.36649012565612793, 'iteration': 13, 'loss': 0.040000000000000036, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 2, 'features__selectkbest__k': 2}), 'normalizer': ('normalizer_NoneType', {}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 7})}, 'score': 0.96, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'entropy', 'max_depth': 3, 'max_features': 1, 'max_leaf_nodes': 5, 'min_samples_split': 2, 'n_estimators': 25}, 'config_hash': {'algorithm': '0e989a03980101fabf79eda3326ed2870e11d690', 'config': 'f4bffd5d8c67a9c5321a9943c4a99678f59a02b7', 'pipeline': '865ee1e3fe8334c3d5ecb2038d5a5d1b3ba50e75'}, 'duration': 0.35639500617980957, 'iteration': 14, 'loss': 0.046666666666666634, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_NoneType', {}), 'normalizer': ('normalizer_RobustScaler', {'normalizer__quantile_range': (...), 'normalizer__with_centering': True, 'normalizer__with_scaling': False}), 'rebalance': ('rebalance_NoneType', {})}, 'score': 0.9533333333333334, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'entropy', 'max_depth': None, 'max_features': 3, 'max_leaf_nodes': 3, 'min_samples_split': 5, 'n_estimators': 10}, 'config_hash': {'algorithm': '9c592e876c13de5e23e6de5b868e01755d63e72e', 'config': '1e6a68cd1eeac886d90724d78b1cb5fb76a3cde4', 'pipeline': '5a1ca4d82f21b7de0d2c918630a42510673fa36e'}, 'duration': 0.18141412734985352, 'iteration': 15, 'loss': 0.046666666666666634, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_SelectKBest', {'features__k': 3}), 'normalizer': ('normalizer_RobustScaler', {'normalizer__quantile_range': (...), 'normalizer__with_centering': True, 'normalizer__with_scaling': True}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 6})}, 'score': 0.9533333333333334, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': 1, 'max_features': None, 'max_leaf_nodes': None, 'min_samples_split': 5, 'n_estimators': 10}, 'config_hash': {'algorithm': '8bed77aef289bfd453b2858bd288ae5ba7160f2b', 'config': '781185bcb8999045de8d489f253a1a1ba4247932', 'pipeline': '1ece7eabedc2be9e5b0a1be65c570d08ffa3eb54'}, 'duration': 0.1636829376220703, 'iteration': 16, 'loss': 0.053333333333333344, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_NoneType', {}), 'normalizer': ('normalizer_NoneType', {}), 'rebalance': ('rebalance_NearMiss', {'rebalance__n_neighbors': 1})}, 'score': 0.9466666666666667, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'gini', 'max_depth': 3, 'max_features': 2, 'max_leaf_nodes': 2, 'min_samples_split': 5, 'n_estimators': 75}, 'config_hash': {'algorithm': '617b97d9ba21d3373bc51ffa9cccf9c6f91a77b3', 'config': '99fb425b4e8c5d80228cab94202252aa25cdf77c', 'pipeline': 'd6242929c3b515c7719e60423023ac604311afc3'}, 'duration': 0.8468999862670898, 'iteration': 17, 'loss': 0.24, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_PCA', {'features__n_components': 4}), 'normalizer': ('normalizer_PowerTransformer', {}), 'rebalance': ('rebalance_NearMiss', {'rebalance__n_neighbors': 2})}, 'score': 0.76, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': 1, 'max_features': 1, 'max_leaf_nodes': 2, 'min_samples_split': 5, 'n_estimators': 50}, 'config_hash': {'algorithm': 'b92d2697cdd4979da443369d6596229ec091626a', 'config': 'c513a3e13281206ad76187dd817b1fff93d54fe1', 'pipeline': 'c4b4f914a3ca8df967cade997a90366d85a371b9'}, 'duration': 0.6724588871002197, 'iteration': 18, 'loss': 0.23333333333333328, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 1, 'features__selectkbest__k': 3}), 'normalizer': ('normalizer_StandardScaler', {'normalizer__with_mean': True, 'normalizer__with_std': True}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 5})}, 'score': 0.7666666666666667, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'entropy', 'max_depth': None, 'max_features': None, 'max_leaf_nodes': 5, 'min_samples_split': 5, 'n_estimators': 10}, 'config_hash': {'algorithm': 'a0115de695e6cca2e81cbfb54df79bf4b43608b1', 'config': 'ba194015e20b5d67770e8c67342c3d8d0d01dc41', 'pipeline': '8d45fabfeb85ffdcabf7076bd0e65fffe97ce928'}, 'duration': 0.19424200057983398, 'iteration': 19, 'loss': 0.08666666666666667, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_PCA', {'features__n_components': 3}), 'normalizer': ('normalizer_NoneType', {}), 'rebalance': ('rebalance_NoneType', {})}, 'score': 0.9133333333333333, ...}, ...], 'history_hash': ['db6ac7e6d348155757e4794bb5f88fe2b4f63d50', '4db6fb84d85f52659f780e682ffac5712c3d8a94', '4403c5a85e951938d3c454e961d3a412780722f6', 'a064e2df18ab98d44dabcefbc7bed94913f1d0be', '0ddb6f5cab3db4dddd7682966a57205f3e329ad4', '49f25751bca61cdd461a8cbd2923689b642f98ed', '5c3a2b6f5e63fb45f10e41e0318b354912ec44f6', 'd3b129b397350f1b6572651c67c01de49b4b174c', '813bde1108cc3c4b9bfb3a22cbb421bda7eac671', '31930b6860ed406d59bf7e59ba1925d94704bd3b', '9913cd550615a9d0946ab4a755a8b9f619e442fd', '95fc8cadc088141290b7de9c388977e4685f0108', '40fa726f0360cf6af55f9b5902d399d02f61f157', '0fb8e77c7bd9a58b72f1b33c21a59a09a8c676ba', 'f4bffd5d8c67a9c5321a9943c4a99678f59a02b7', '1e6a68cd1eeac886d90724d78b1cb5fb76a3cde4', '781185bcb8999045de8d489f253a1a1ba4247932', '99fb425b4e8c5d80228cab94202252aa25cdf77c', 'c513a3e13281206ad76187dd817b1fff93d54fe1', 'ba194015e20b5d67770e8c67342c3d8d0d01dc41', ...], 'history_index': {'00f0493590a2cb5e98a35b29816f8cd9f87f96ec': 208, '013329309d510b94f19d930320402d65f953a847': 39, '038a0f515e2ec894ee8e34f9caa2889eb3ebd5ce': 66, '052ae4bf232b316187b078abae42c2be19e16a00': 111, '0659afebf316aafeb75612fb07081a04c28545ed': 74, '06e7cde9f3556cd01332ce389ad1d8925cd4b4a4': 120, '08606f2a0f0a6c9de204020b4632e09fcee0ae56': 168, '0a05b5b0a70971a5e347aaab7a4d4a07a92222fd': 191, '0b6551ecfd6f83a15704a9db68f1599c99c6d3ef': 58, '0cfb4698cbf2d986bcd5e0c2ef0f974da60b205e': 194, ...}, 'iteration': 239, 'max_history_score': 0.9666666666666668, 'max_history_score_std': 0.033333333333333326, 'max_history_step': 'joint'}
        config = {'algorithm': 'RandomForest', 'seed': 42, 'time': 300}
    114 
    115 
    116 def get_baseline_score(algorithm, X, y, seed):
    117     pipeline, _ = pipeline_conf_to_full_pipeline(

...........................................................................
/home/aquemy/dev/dp_hyperparameters/extension/experiment/objective.py in objective(pipeline_config={'features': ('features_SelectKBest', {'features__k': 1}), 'normalizer': ('normalizer_MinMaxScaler', {}), 'rebalance': ('rebalance_CondensedNearestNeighbour', {'rebalance__n_neighbors': 3})}, algo_config={'bootstrap': True, 'criterion': 'gini', 'max_depth': None, 'max_features': 3, 'max_leaf_nodes': 3, 'min_samples_split': 3, 'n_estimators': 10}, algorithm='RandomForest', X=array([[5.1, 3.5, 1.4, 0.2],
       [4.9, 3. , 1....2, 3.4, 5.4, 2.3],
       [5.9, 3. , 5.1, 1.8]]), y=array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,... 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]), context={'baseline_score': 0.9466666666666667, 'baseline_score_std': 0.04988876515698587, 'best_config': {'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': 4, 'max_features': 3, 'max_leaf_nodes': 3, 'min_samples_split': 3, 'n_estimators': 10}, 'config_hash': {'algorithm': 'ffb7ff225ce3d3712c96cf87fe42202988ee2eb0', 'config': 'bae32f426be9cd6243523c023944a8c148fe4aeb', 'pipeline': 'd2a68bfda6fcdec4ae0ffc7d7b6a2122bc1cd673'}, 'duration': 0.7115809917449951, 'iteration': 113, 'loss': 0.033333333333333215, 'max_history_score': 0.9666666666666668, 'max_history_score_std': 0.033333333333333326, 'max_history_step': 'joint', 'pipeline': {'features': ('features_NoneType', {}), 'normalizer': ('normalizer_PowerTransformer', {}), 'rebalance': ('rebalance_CondensedNearestNeighbour', {'rebalance__n_neighbors': 2})}, 'score': 0.9666666666666668, ...}, 'history': [{'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': 2, 'max_features': None, 'max_leaf_nodes': 5, 'min_samples_split': 2, 'n_estimators': 75}, 'config_hash': {'algorithm': '3af5b0cce71c8fe2545246ca24ff5bc3dd516e06', 'config': 'db6ac7e6d348155757e4794bb5f88fe2b4f63d50', 'pipeline': '8d59f4b94cef6be9306ed86a22a9570fa670d567'}, 'duration': 1.149928092956543, 'iteration': 0, 'loss': 0.046666666666666634, 'max_history_score': 0.9533333333333334, 'max_history_score_std': 0.059999999999999984, 'max_history_step': 'joint', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 4, 'features__selectkbest__k': 3}), 'normalizer': ('normalizer_StandardScaler', {'normalizer__with_mean': True, 'normalizer__with_std': True}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 6})}, 'score': 0.9533333333333334, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': 1, 'max_features': 2, 'max_leaf_nodes': 2, 'min_samples_split': 5, 'n_estimators': 100}, 'config_hash': {'algorithm': 'e13eb05fd9a62d2f63bbb1c1deff0cd620d5e6ab', 'config': '4db6fb84d85f52659f780e682ffac5712c3d8a94', 'pipeline': '64c9a1ca9d53ae67244bdd942f4db36a3c05218c'}, 'duration': 1.7678282260894775, 'iteration': 1, 'loss': 0.18000000000000005, 'max_history_score': 0.9533333333333334, 'max_history_score_std': 0.059999999999999984, 'max_history_step': 'joint', 'pipeline': {'features': ('features_NoneType', {}), 'normalizer': ('normalizer_PowerTransformer', {}), 'rebalance': ('rebalance_NearMiss', {'rebalance__n_neighbors': 1})}, 'score': 0.82, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': 1, 'max_features': None, 'max_leaf_nodes': None, 'min_samples_split': 5, 'n_estimators': 75}, 'config_hash': {'algorithm': '94b0d7a654c508cc63643f78fe4f0f07e6f07c1e', 'config': '4403c5a85e951938d3c454e961d3a412780722f6', 'pipeline': '3e47444880d8367fbac2faaba2e52a917274aa58'}, 'duration': 0.8397619724273682, 'iteration': 2, 'loss': 0.03333333333333344, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_PCA', {'features__n_components': 3}), 'normalizer': ('normalizer_MinMaxScaler', {}), 'rebalance': ('rebalance_NoneType', {})}, 'score': 0.9666666666666666, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': None, 'max_features': None, 'max_leaf_nodes': 3, 'min_samples_split': 3, 'n_estimators': 75}, 'config_hash': {'algorithm': 'e8332f0a8902bda03bf70e7978cc5d52affb29d3', 'config': 'a064e2df18ab98d44dabcefbc7bed94913f1d0be', 'pipeline': '7eea819c2a8c103c4b1e9e9c1e224aebba95081f'}, 'duration': 0.8501448631286621, 'iteration': 3, 'loss': 0.053333333333333344, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 2, 'features__selectkbest__k': 4}), 'normalizer': ('normalizer_NoneType', {}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 7})}, 'score': 0.9466666666666667, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'entropy', 'max_depth': 3, 'max_features': 3, 'max_leaf_nodes': None, 'min_samples_split': 5, 'n_estimators': 75}, 'config_hash': {'algorithm': '7a4491035bc6bd737fe9a8cda8a79a02d02d5c74', 'config': '0ddb6f5cab3db4dddd7682966a57205f3e329ad4', 'pipeline': 'a9ae03fe38334f6868cbf84cdd3d629d4bbe3fb0'}, 'duration': 1.1026010513305664, 'iteration': 4, 'loss': 0.05999999999999994, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 2, 'features__selectkbest__k': 1}), 'normalizer': ('normalizer_NoneType', {}), 'rebalance': ('rebalance_NoneType', {})}, 'score': 0.9400000000000001, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'gini', 'max_depth': 3, 'max_features': 1, 'max_leaf_nodes': 5, 'min_samples_split': 2, 'n_estimators': 25}, 'config_hash': {'algorithm': '9826d20b2d6a0f559cf7f16450ce7526f07e8434', 'config': '49f25751bca61cdd461a8cbd2923689b642f98ed', 'pipeline': '19b249664c5bf067de1fed4334a296f947ce774a'}, 'duration': 0.35647010803222656, 'iteration': 5, 'loss': 0.046666666666666634, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_NoneType', {}), 'normalizer': ('normalizer_NoneType', {}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 6})}, 'score': 0.9533333333333334, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'gini', 'max_depth': 2, 'max_features': 1, 'max_leaf_nodes': 2, 'min_samples_split': 2, 'n_estimators': 50}, 'config_hash': {'algorithm': '0a4f6fbb07e0f32c6f675489a0fc82eee05bd8e1', 'config': '5c3a2b6f5e63fb45f10e41e0318b354912ec44f6', 'pipeline': 'dc3b9f176f090005e38b142f11d80e93a7dc5d5e'}, 'duration': 0.7213859558105469, 'iteration': 6, 'loss': 0.31333333333333324, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 1, 'features__selectkbest__k': 4}), 'normalizer': ('normalizer_PowerTransformer', {}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 7})}, 'score': 0.6866666666666668, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'entropy', 'max_depth': 4, 'max_features': 3, 'max_leaf_nodes': 5, 'min_samples_split': 5, 'n_estimators': 10}, 'config_hash': {'algorithm': 'b8112b97ecfc10f00a195af661dcc861cac21289', 'config': 'd3b129b397350f1b6572651c67c01de49b4b174c', 'pipeline': '5b0357ed7072c37b3d6f458bb5d49ff7d825f603'}, 'duration': 0.8299109935760498, 'iteration': 7, 'loss': 1.0, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_PCA', {'features__n_components': 2}), 'normalizer': ('normalizer_StandardScaler', {'normalizer__with_mean': True, 'normalizer__with_std': False}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 6})}, 'score': 0.0, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'gini', 'max_depth': 4, 'max_features': None, 'max_leaf_nodes': 2, 'min_samples_split': 5, 'n_estimators': 100}, 'config_hash': {'algorithm': '40ca24df19b8d164d9d098a6bed1ce056fbbb961', 'config': '813bde1108cc3c4b9bfb3a22cbb421bda7eac671', 'pipeline': '74a7b8705a1c22f7dea5e44e4ebda8f1e48add71'}, 'duration': 2.2111589908599854, 'iteration': 8, 'loss': 0.33333333333333326, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_PCA', {'features__n_components': 2}), 'normalizer': ('normalizer_StandardScaler', {'normalizer__with_mean': False, 'normalizer__with_std': True}), 'rebalance': ('rebalance_NearMiss', {'rebalance__n_neighbors': 2})}, 'score': 0.6666666666666667, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'entropy', 'max_depth': 2, 'max_features': 1, 'max_leaf_nodes': 5, 'min_samples_split': 2, 'n_estimators': 100}, 'config_hash': {'algorithm': '331418a5c12cf1453876eef85e9d98fc8e54fa11', 'config': '31930b6860ed406d59bf7e59ba1925d94704bd3b', 'pipeline': '054bef356f90ec6f644ef3ffc688766744db51c2'}, 'duration': 1.0501940250396729, 'iteration': 9, 'loss': 0.053333333333333344, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_SelectKBest', {'features__k': 1}), 'normalizer': ('normalizer_RobustScaler', {'normalizer__quantile_range': (...), 'normalizer__with_centering': True, 'normalizer__with_scaling': True}), 'rebalance': ('rebalance_NearMiss', {'rebalance__n_neighbors': 2})}, 'score': 0.9466666666666667, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'entropy', 'max_depth': 3, 'max_features': None, 'max_leaf_nodes': 3, 'min_samples_split': 2, 'n_estimators': 100}, 'config_hash': {'algorithm': 'dbc1b8126649fe93dce5fbb37e4015b0acfb179e', 'config': '9913cd550615a9d0946ab4a755a8b9f619e442fd', 'pipeline': 'dd626121cea079ebb32e184ca65483ec7a6d7f59'}, 'duration': 1.120617151260376, 'iteration': 10, 'loss': 0.046666666666666634, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 2, 'features__selectkbest__k': 1}), 'normalizer': ('normalizer_MinMaxScaler', {}), 'rebalance': ('rebalance_NoneType', {})}, 'score': 0.9533333333333334, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'gini', 'max_depth': 3, 'max_features': 3, 'max_leaf_nodes': None, 'min_samples_split': 3, 'n_estimators': 75}, 'config_hash': {'algorithm': '34917a130df5a975f78bd7ec1a0c7b1ffdc787a9', 'config': '95fc8cadc088141290b7de9c388977e4685f0108', 'pipeline': '550d10faf2f08db48516cc3501558816d6a99bc0'}, 'duration': 1.4287099838256836, 'iteration': 11, 'loss': 0.19333333333333313, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 3, 'features__selectkbest__k': 4}), 'normalizer': ('normalizer_StandardScaler', {'normalizer__with_mean': False, 'normalizer__with_std': False}), 'rebalance': ('rebalance_CondensedNearestNeighbour', {'rebalance__n_neighbors': 1})}, 'score': 0.8066666666666669, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'entropy', 'max_depth': 1, 'max_features': 2, 'max_leaf_nodes': 5, 'min_samples_split': 2, 'n_estimators': 75}, 'config_hash': {'algorithm': '33f9abb4aee44a395a9f3b3ffa9ce80a8cdaed7c', 'config': '40fa726f0360cf6af55f9b5902d399d02f61f157', 'pipeline': 'cfd1d20841fe2153da762c95e79f95a3fb1e426a'}, 'duration': 1.2978079319000244, 'iteration': 12, 'loss': 0.053333333333333344, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_PCA', {'features__n_components': 4}), 'normalizer': ('normalizer_MinMaxScaler', {}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 7})}, 'score': 0.9466666666666667, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'entropy', 'max_depth': 4, 'max_features': 2, 'max_leaf_nodes': 5, 'min_samples_split': 3, 'n_estimators': 25}, 'config_hash': {'algorithm': '210111ec6562d09eb093e98ed69ef1c662e11a50', 'config': '0fb8e77c7bd9a58b72f1b33c21a59a09a8c676ba', 'pipeline': '5d269d759e0c7926a685a14b263ace8ae0071e4b'}, 'duration': 0.36649012565612793, 'iteration': 13, 'loss': 0.040000000000000036, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 2, 'features__selectkbest__k': 2}), 'normalizer': ('normalizer_NoneType', {}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 7})}, 'score': 0.96, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'entropy', 'max_depth': 3, 'max_features': 1, 'max_leaf_nodes': 5, 'min_samples_split': 2, 'n_estimators': 25}, 'config_hash': {'algorithm': '0e989a03980101fabf79eda3326ed2870e11d690', 'config': 'f4bffd5d8c67a9c5321a9943c4a99678f59a02b7', 'pipeline': '865ee1e3fe8334c3d5ecb2038d5a5d1b3ba50e75'}, 'duration': 0.35639500617980957, 'iteration': 14, 'loss': 0.046666666666666634, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_NoneType', {}), 'normalizer': ('normalizer_RobustScaler', {'normalizer__quantile_range': (...), 'normalizer__with_centering': True, 'normalizer__with_scaling': False}), 'rebalance': ('rebalance_NoneType', {})}, 'score': 0.9533333333333334, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'entropy', 'max_depth': None, 'max_features': 3, 'max_leaf_nodes': 3, 'min_samples_split': 5, 'n_estimators': 10}, 'config_hash': {'algorithm': '9c592e876c13de5e23e6de5b868e01755d63e72e', 'config': '1e6a68cd1eeac886d90724d78b1cb5fb76a3cde4', 'pipeline': '5a1ca4d82f21b7de0d2c918630a42510673fa36e'}, 'duration': 0.18141412734985352, 'iteration': 15, 'loss': 0.046666666666666634, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_SelectKBest', {'features__k': 3}), 'normalizer': ('normalizer_RobustScaler', {'normalizer__quantile_range': (...), 'normalizer__with_centering': True, 'normalizer__with_scaling': True}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 6})}, 'score': 0.9533333333333334, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': 1, 'max_features': None, 'max_leaf_nodes': None, 'min_samples_split': 5, 'n_estimators': 10}, 'config_hash': {'algorithm': '8bed77aef289bfd453b2858bd288ae5ba7160f2b', 'config': '781185bcb8999045de8d489f253a1a1ba4247932', 'pipeline': '1ece7eabedc2be9e5b0a1be65c570d08ffa3eb54'}, 'duration': 0.1636829376220703, 'iteration': 16, 'loss': 0.053333333333333344, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_NoneType', {}), 'normalizer': ('normalizer_NoneType', {}), 'rebalance': ('rebalance_NearMiss', {'rebalance__n_neighbors': 1})}, 'score': 0.9466666666666667, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'gini', 'max_depth': 3, 'max_features': 2, 'max_leaf_nodes': 2, 'min_samples_split': 5, 'n_estimators': 75}, 'config_hash': {'algorithm': '617b97d9ba21d3373bc51ffa9cccf9c6f91a77b3', 'config': '99fb425b4e8c5d80228cab94202252aa25cdf77c', 'pipeline': 'd6242929c3b515c7719e60423023ac604311afc3'}, 'duration': 0.8468999862670898, 'iteration': 17, 'loss': 0.24, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_PCA', {'features__n_components': 4}), 'normalizer': ('normalizer_PowerTransformer', {}), 'rebalance': ('rebalance_NearMiss', {'rebalance__n_neighbors': 2})}, 'score': 0.76, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': 1, 'max_features': 1, 'max_leaf_nodes': 2, 'min_samples_split': 5, 'n_estimators': 50}, 'config_hash': {'algorithm': 'b92d2697cdd4979da443369d6596229ec091626a', 'config': 'c513a3e13281206ad76187dd817b1fff93d54fe1', 'pipeline': 'c4b4f914a3ca8df967cade997a90366d85a371b9'}, 'duration': 0.6724588871002197, 'iteration': 18, 'loss': 0.23333333333333328, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 1, 'features__selectkbest__k': 3}), 'normalizer': ('normalizer_StandardScaler', {'normalizer__with_mean': True, 'normalizer__with_std': True}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 5})}, 'score': 0.7666666666666667, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'entropy', 'max_depth': None, 'max_features': None, 'max_leaf_nodes': 5, 'min_samples_split': 5, 'n_estimators': 10}, 'config_hash': {'algorithm': 'a0115de695e6cca2e81cbfb54df79bf4b43608b1', 'config': 'ba194015e20b5d67770e8c67342c3d8d0d01dc41', 'pipeline': '8d45fabfeb85ffdcabf7076bd0e65fffe97ce928'}, 'duration': 0.19424200057983398, 'iteration': 19, 'loss': 0.08666666666666667, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_PCA', {'features__n_components': 3}), 'normalizer': ('normalizer_NoneType', {}), 'rebalance': ('rebalance_NoneType', {})}, 'score': 0.9133333333333333, ...}, ...], 'history_hash': ['db6ac7e6d348155757e4794bb5f88fe2b4f63d50', '4db6fb84d85f52659f780e682ffac5712c3d8a94', '4403c5a85e951938d3c454e961d3a412780722f6', 'a064e2df18ab98d44dabcefbc7bed94913f1d0be', '0ddb6f5cab3db4dddd7682966a57205f3e329ad4', '49f25751bca61cdd461a8cbd2923689b642f98ed', '5c3a2b6f5e63fb45f10e41e0318b354912ec44f6', 'd3b129b397350f1b6572651c67c01de49b4b174c', '813bde1108cc3c4b9bfb3a22cbb421bda7eac671', '31930b6860ed406d59bf7e59ba1925d94704bd3b', '9913cd550615a9d0946ab4a755a8b9f619e442fd', '95fc8cadc088141290b7de9c388977e4685f0108', '40fa726f0360cf6af55f9b5902d399d02f61f157', '0fb8e77c7bd9a58b72f1b33c21a59a09a8c676ba', 'f4bffd5d8c67a9c5321a9943c4a99678f59a02b7', '1e6a68cd1eeac886d90724d78b1cb5fb76a3cde4', '781185bcb8999045de8d489f253a1a1ba4247932', '99fb425b4e8c5d80228cab94202252aa25cdf77c', 'c513a3e13281206ad76187dd817b1fff93d54fe1', 'ba194015e20b5d67770e8c67342c3d8d0d01dc41', ...], 'history_index': {'00f0493590a2cb5e98a35b29816f8cd9f87f96ec': 208, '013329309d510b94f19d930320402d65f953a847': 39, '038a0f515e2ec894ee8e34f9caa2889eb3ebd5ce': 66, '052ae4bf232b316187b078abae42c2be19e16a00': 111, '0659afebf316aafeb75612fb07081a04c28545ed': 74, '06e7cde9f3556cd01332ce389ad1d8925cd4b4a4': 120, '08606f2a0f0a6c9de204020b4632e09fcee0ae56': 168, '0a05b5b0a70971a5e347aaab7a4d4a07a92222fd': 191, '0b6551ecfd6f83a15704a9db68f1599c99c6d3ef': 58, '0cfb4698cbf2d986bcd5e0c2ef0f974da60b205e': 194, ...}, 'iteration': 239, 'max_history_score': 0.9666666666666668, 'max_history_score_std': 0.033333333333333326, 'max_history_step': 'joint'}, config={'algorithm': 'RandomForest', 'seed': 42, 'time': 300}, step='joint')
     45                 y,
     46                 cv=10,
     47                 n_jobs=-1,
     48                 return_estimator=False,
     49                 return_train_score=False,
---> 50                 verbose=0)
     51         score = np.mean(scores['test_score'])
     52         std = np.std(scores['test_score'])
     53         status = STATUS_OK
     54     except Exception as e:

...........................................................................
/home/aquemy/.local/lib/python2.7/site-packages/sklearn/model_selection/_validation.py in cross_validate(estimator=Pipeline(memory=None,
     steps=[('rebalance', ... random_state=42, verbose=0, warm_start=False))]), X=array([[5.1, 3.5, 1.4, 0.2],
       [4.9, 3. , 1....2, 3.4, 5.4, 2.3],
       [5.9, 3. , 5.1, 1.8]]), y=array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,... 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]), groups=None, scoring=None, cv=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1, verbose=0, fit_params=None, pre_dispatch='2*n_jobs', return_train_score=False, return_estimator=False, error_score='raise-deprecating')
    235         delayed(_fit_and_score)(
    236             clone(estimator), X, y, scorers, train, test, verbose, None,
    237             fit_params, return_train_score=return_train_score,
    238             return_times=True, return_estimator=return_estimator,
    239             error_score=error_score)
--> 240         for train, test in cv.split(X, y, groups))
        cv.split = <bound method StratifiedKFold.split of Stratifie...d(n_splits=10, random_state=None, shuffle=False)>
        X = array([[5.1, 3.5, 1.4, 0.2],
       [4.9, 3. , 1....2, 3.4, 5.4, 2.3],
       [5.9, 3. , 5.1, 1.8]])
        y = array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,... 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2])
        groups = None
    241 
    242     zipped_scores = list(zip(*scores))
    243     if return_train_score:
    244         train_scores = zipped_scores.pop(0)

...........................................................................
/home/aquemy/.local/lib/python2.7/site-packages/sklearn/externals/joblib/parallel.py in __call__(self=Parallel(n_jobs=-1), iterable=<generator object <genexpr>>)
    925                 # No need to wait for async callbacks to trigger to
    926                 # consumption.
    927                 self._iterating = False
    928 
    929             with self._backend.retrieval_context():
--> 930                 self.retrieve()
        self.retrieve = <bound method Parallel.retrieve of Parallel(n_jobs=-1)>
    931             # Make sure that we get a last message telling us we are done
    932             elapsed_time = time.time() - self._start_time
    933             self._print('Done %3i out of %3i | elapsed: %s finished',
    934                         (len(self._output), len(self._output),

---------------------------------------------------------------------------
Joblib worker traceback:
---------------------------------------------------------------------------
ValueError                                         Mon Jun 17 13:13:49 2019
PID: 21458                                  Python 2.7.15+: /usr/bin/python
...........................................................................
/home/aquemy/.local/lib/python2.7/site-packages/sklearn/externals/joblib/parallel.py in __call__(self=<sklearn.externals.joblib.parallel.BatchedCalls object>)
    220     def __call__(self):
    221         # Set the default nested backend to self._backend but do not set the
    222         # change the default number of processes to -1
    223         with parallel_backend(self._backend, n_jobs=self._n_jobs):
    224             return [func(*args, **kwargs)
--> 225                     for func, args, kwargs in self.items]
        func = <function _fit_and_score>
        args = (Pipeline(memory=None,
     steps=[('rebalance', ... random_state=42, verbose=0, warm_start=False))]), array([[5.1, 3.5, 1.4, 0.2],
       [4.9, 3. , 1....2, 3.4, 5.4, 2.3],
       [5.9, 3. , 5.1, 1.8]]), array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,... 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]), {'score': <function _passthrough_scorer>}, array([  5,   6,   7,   8,   9,  10,  11,  12,  ..., 142, 143, 144,
       145, 146, 147, 148, 149]), array([  0,   1,   2,   3,   4,  50,  51,  52,  53,  54, 100, 101, 102,
       103, 104]), 0, None, None)
        kwargs = {'error_score': 'raise-deprecating', 'return_estimator': False, 'return_times': True, 'return_train_score': False}
        self.items = [(<function _fit_and_score>, (Pipeline(memory=None,
     steps=[('rebalance', ... random_state=42, verbose=0, warm_start=False))]), array([[5.1, 3.5, 1.4, 0.2],
       [4.9, 3. , 1....2, 3.4, 5.4, 2.3],
       [5.9, 3. , 5.1, 1.8]]), array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,... 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]), {'score': <function _passthrough_scorer>}, array([  5,   6,   7,   8,   9,  10,  11,  12,  ..., 142, 143, 144,
       145, 146, 147, 148, 149]), array([  0,   1,   2,   3,   4,  50,  51,  52,  53,  54, 100, 101, 102,
       103, 104]), 0, None, None), {'error_score': 'raise-deprecating', 'return_estimator': False, 'return_times': True, 'return_train_score': False})]
    226 
    227     def __len__(self):
    228         return self._size
    229 

...........................................................................
/home/aquemy/.local/lib/python2.7/site-packages/sklearn/model_selection/_validation.py in _fit_and_score(estimator=Pipeline(memory=None,
     steps=[('rebalance', ... random_state=42, verbose=0, warm_start=False))]), X=array([[5.1, 3.5, 1.4, 0.2],
       [4.9, 3. , 1....2, 3.4, 5.4, 2.3],
       [5.9, 3. , 5.1, 1.8]]), y=array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,... 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]), scorer={'score': <function _passthrough_scorer>}, train=array([  5,   6,   7,   8,   9,  10,  11,  12,  ..., 142, 143, 144,
       145, 146, 147, 148, 149]), test=array([  0,   1,   2,   3,   4,  50,  51,  52,  53,  54, 100, 101, 102,
       103, 104]), verbose=0, parameters=None, fit_params={}, return_train_score=False, return_parameters=False, return_n_test_samples=False, return_times=True, return_estimator=False, error_score='raise-deprecating')
    523 
    524     try:
    525         if y_train is None:
    526             estimator.fit(X_train, **fit_params)
    527         else:
--> 528             estimator.fit(X_train, y_train, **fit_params)
        estimator.fit = <bound method Pipeline.fit of Pipeline(memory=No...random_state=42, verbose=0, warm_start=False))])>
        X_train = array([[5.4, 3.9, 1.7, 0.4],
       [4.6, 3.4, 1....2, 3.4, 5.4, 2.3],
       [5.9, 3. , 5.1, 1.8]])
        y_train = array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,
       2, 2, 2])
        fit_params = {}
    529 
    530     except Exception as e:
    531         # Note fit time as time until error
    532         fit_time = time.time() - start_time

...........................................................................
/usr/local/lib/python2.7/dist-packages/imblearn/pipeline.py in fit(self=Pipeline(memory=None,
     steps=[('rebalance', ... random_state=42, verbose=0, warm_start=False))]), X=array([[5.4, 3.9, 1.7, 0.4],
       [4.6, 3.4, 1....2, 3.4, 5.4, 2.3],
       [5.9, 3. , 5.1, 1.8]]), y=array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,
       2, 2, 2]), **fit_params={})
    234             This estimator
    235 
    236         """
    237         Xt, yt, fit_params = self._fit(X, y, **fit_params)
    238         if self._final_estimator is not None:
--> 239             self._final_estimator.fit(Xt, yt, **fit_params)
        self._final_estimator.fit = <bound method RandomForestClassifier.fit of Rand...e, random_state=42, verbose=0, warm_start=False)>
        Xt = array([[0.13636364],
       [0.09090909],
      ...    ],
       [0.90909091],
       [0.72727273]])
        yt = array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...0, 0, 0, 0, 0, 0, 0,
       0, 1, 1, 1, 2, 2, 2])
        fit_params = {}
    240         return self
    241 
    242     def fit_transform(self, X, y=None, **fit_params):
    243         """Fit the model and transform with the final estimator

...........................................................................
/home/aquemy/.local/lib/python2.7/site-packages/sklearn/ensemble/forest.py in fit(self=RandomForestClassifier(bootstrap=True, class_wei...se, random_state=42, verbose=0, warm_start=False), X=array([[0.13636364],
       [0.09090909],
      ...0.90909094],
       [0.72727275]], dtype=float32), y=array([[0.],
       [0.],
       [0.],
       [0...    [1.],
       [2.],
       [2.],
       [2.]]), sample_weight=None)
    328             trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,
    329                              **_joblib_parallel_args(prefer='threads'))(
    330                 delayed(_parallel_build_trees)(
    331                     t, self, X, y, sample_weight, i, len(trees),
    332                     verbose=self.verbose, class_weight=self.class_weight)
--> 333                 for i, t in enumerate(trees))
        i = 9
    334 
    335             # Collect newly grown trees
    336             self.estimators_.extend(trees)
    337 

...........................................................................
/home/aquemy/.local/lib/python2.7/site-packages/sklearn/externals/joblib/parallel.py in __call__(self=Parallel(n_jobs=1), iterable=<generator object <genexpr>>)
    912             # self._original_iterator is None, then this means either
    913             # that pre_dispatch == "all", n_jobs == 1 or that the first batch
    914             # was very quick and its callback already dispatched all the
    915             # remaining jobs.
    916             self._iterating = False
--> 917             if self.dispatch_one_batch(iterator):
        self.dispatch_one_batch = <bound method Parallel.dispatch_one_batch of Parallel(n_jobs=1)>
        iterator = <generator object <genexpr>>
    918                 self._iterating = self._original_iterator is not None
    919 
    920             while self.dispatch_one_batch(iterator):
    921                 pass

...........................................................................
/home/aquemy/.local/lib/python2.7/site-packages/sklearn/externals/joblib/parallel.py in dispatch_one_batch(self=Parallel(n_jobs=1), iterator=<generator object <genexpr>>)
    754                                  self._pickle_cache)
    755             if len(tasks) == 0:
    756                 # No more tasks available in the iterator: tell caller to stop.
    757                 return False
    758             else:
--> 759                 self._dispatch(tasks)
        self._dispatch = <bound method Parallel._dispatch of Parallel(n_jobs=1)>
        tasks = <sklearn.externals.joblib.parallel.BatchedCalls object>
    760                 return True
    761 
    762     def _print(self, msg, msg_args):
    763         """Display the message on stout or stderr depending on verbosity"""

...........................................................................
/home/aquemy/.local/lib/python2.7/site-packages/sklearn/externals/joblib/parallel.py in _dispatch(self=Parallel(n_jobs=1), batch=<sklearn.externals.joblib.parallel.BatchedCalls object>)
    711 
    712         dispatch_timestamp = time.time()
    713         cb = BatchCompletionCallBack(dispatch_timestamp, len(batch), self)
    714         with self._lock:
    715             job_idx = len(self._jobs)
--> 716             job = self._backend.apply_async(batch, callback=cb)
        job = undefined
        self._backend.apply_async = <bound method SequentialBackend.apply_async of <...lib._parallel_backends.SequentialBackend object>>
        batch = <sklearn.externals.joblib.parallel.BatchedCalls object>
        cb = <sklearn.externals.joblib.parallel.BatchCompletionCallBack object>
    717             # A job can complete so quickly than its callback is
    718             # called before we get here, causing self._jobs to
    719             # grow. To ensure correct results ordering, .insert is
    720             # used (rather than .append) in the following line

...........................................................................
/home/aquemy/.local/lib/python2.7/site-packages/sklearn/externals/joblib/_parallel_backends.py in apply_async(self=<sklearn.externals.joblib._parallel_backends.SequentialBackend object>, func=<sklearn.externals.joblib.parallel.BatchedCalls object>, callback=<sklearn.externals.joblib.parallel.BatchCompletionCallBack object>)
    177             raise ValueError('n_jobs == 0 in Parallel has no meaning')
    178         return 1
    179 
    180     def apply_async(self, func, callback=None):
    181         """Schedule a func to be run"""
--> 182         result = ImmediateResult(func)
        result = undefined
        func = <sklearn.externals.joblib.parallel.BatchedCalls object>
    183         if callback:
    184             callback(result)
    185         return result
    186 

...........................................................................
/home/aquemy/.local/lib/python2.7/site-packages/sklearn/externals/joblib/_parallel_backends.py in __init__(self=<sklearn.externals.joblib._parallel_backends.ImmediateResult object>, batch=<sklearn.externals.joblib.parallel.BatchedCalls object>)
    544 
    545 class ImmediateResult(object):
    546     def __init__(self, batch):
    547         # Don't delay the application, to avoid keeping the input
    548         # arguments in memory
--> 549         self.results = batch()
        self.results = undefined
        batch = <sklearn.externals.joblib.parallel.BatchedCalls object>
    550 
    551     def get(self):
    552         return self.results
    553 

...........................................................................
/home/aquemy/.local/lib/python2.7/site-packages/sklearn/externals/joblib/parallel.py in __call__(self=<sklearn.externals.joblib.parallel.BatchedCalls object>)
    220     def __call__(self):
    221         # Set the default nested backend to self._backend but do not set the
    222         # change the default number of processes to -1
    223         with parallel_backend(self._backend, n_jobs=self._n_jobs):
    224             return [func(*args, **kwargs)
--> 225                     for func, args, kwargs in self.items]
        func = <function _parallel_build_trees>
        args = (DecisionTreeClassifier(class_weight=None, criter...=False, random_state=1608637542, splitter='best'), RandomForestClassifier(bootstrap=True, class_wei...se, random_state=42, verbose=0, warm_start=False), array([[0.13636364],
       [0.09090909],
      ...0.90909094],
       [0.72727275]], dtype=float32), array([[0.],
       [0.],
       [0.],
       [0...    [1.],
       [2.],
       [2.],
       [2.]]), None, 0, 10)
        kwargs = {'class_weight': None, 'verbose': 0}
        self.items = [(<function _parallel_build_trees>, (DecisionTreeClassifier(class_weight=None, criter...=False, random_state=1608637542, splitter='best'), RandomForestClassifier(bootstrap=True, class_wei...se, random_state=42, verbose=0, warm_start=False), array([[0.13636364],
       [0.09090909],
      ...0.90909094],
       [0.72727275]], dtype=float32), array([[0.],
       [0.],
       [0.],
       [0...    [1.],
       [2.],
       [2.],
       [2.]]), None, 0, 10), {'class_weight': None, 'verbose': 0})]
    226 
    227     def __len__(self):
    228         return self._size
    229 

...........................................................................
/home/aquemy/.local/lib/python2.7/site-packages/sklearn/ensemble/forest.py in _parallel_build_trees(tree=DecisionTreeClassifier(class_weight=None, criter...=False, random_state=1608637542, splitter='best'), forest=RandomForestClassifier(bootstrap=True, class_wei...se, random_state=42, verbose=0, warm_start=False), X=array([[0.13636364],
       [0.09090909],
      ...0.90909094],
       [0.72727275]], dtype=float32), y=array([[0.],
       [0.],
       [0.],
       [0...    [1.],
       [2.],
       [2.],
       [2.]]), sample_weight=None, tree_idx=0, n_trees=10, verbose=0, class_weight=None)
    114                 simplefilter('ignore', DeprecationWarning)
    115                 curr_sample_weight *= compute_sample_weight('auto', y, indices)
    116         elif class_weight == 'balanced_subsample':
    117             curr_sample_weight *= compute_sample_weight('balanced', y, indices)
    118 
--> 119         tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)
        tree.fit = <bound method DecisionTreeClassifier.fit of Deci...False, random_state=1608637542, splitter='best')>
        X = array([[0.13636364],
       [0.09090909],
      ...0.90909094],
       [0.72727275]], dtype=float32)
        y = array([[0.],
       [0.],
       [0.],
       [0...    [1.],
       [2.],
       [2.],
       [2.]])
        sample_weight = None
        curr_sample_weight = array([2., 0., 2., 1., 2., 0., 1., 2., 1., 1., 2... 2., 0., 4., 0., 2., 0., 0., 1., 0., 0., 3., 2.])
    120     else:
    121         tree.fit(X, y, sample_weight=sample_weight, check_input=False)
    122 
    123     return tree

...........................................................................
/home/aquemy/.local/lib/python2.7/site-packages/sklearn/tree/tree.py in fit(self=DecisionTreeClassifier(class_weight=None, criter...=False, random_state=1608637542, splitter='best'), X=array([[0.13636364],
       [0.09090909],
      ...0.90909094],
       [0.72727275]], dtype=float32), y=array([[0.],
       [0.],
       [0.],
       [0...    [1.],
       [2.],
       [2.],
       [2.]]), sample_weight=array([2., 0., 2., 1., 2., 0., 1., 2., 1., 1., 2... 2., 0., 4., 0., 2., 0., 0., 1., 0., 0., 3., 2.]), check_input=False, X_idx_sorted=None)
    796 
    797         super(DecisionTreeClassifier, self).fit(
    798             X, y,
    799             sample_weight=sample_weight,
    800             check_input=check_input,
--> 801             X_idx_sorted=X_idx_sorted)
        X_idx_sorted = None
    802         return self
    803 
    804     def predict_proba(self, X, check_input=True):
    805         """Predict class probabilities of the input samples X.

...........................................................................
/home/aquemy/.local/lib/python2.7/site-packages/sklearn/tree/tree.py in fit(self=DecisionTreeClassifier(class_weight=None, criter...=False, random_state=1608637542, splitter='best'), X=array([[0.13636364],
       [0.09090909],
      ...0.90909094],
       [0.72727275]], dtype=float32), y=array([[0.],
       [0.],
       [0.],
       [0...    [1.],
       [2.],
       [2.],
       [2.]]), sample_weight=array([2., 0., 2., 1., 2., 0., 1., 2., 1., 1., 2... 2., 0., 4., 0., 2., 0., 0., 1., 0., 0., 3., 2.]), check_input=False, X_idx_sorted=None)
    237         if not 0 <= self.min_weight_fraction_leaf <= 0.5:
    238             raise ValueError("min_weight_fraction_leaf must in [0, 0.5]")
    239         if max_depth <= 0:
    240             raise ValueError("max_depth must be greater than zero. ")
    241         if not (0 < max_features <= self.n_features_):
--> 242             raise ValueError("max_features must be in (0, n_features]")
    243         if not isinstance(max_leaf_nodes, (numbers.Integral, np.integer)):
    244             raise ValueError("max_leaf_nodes must be integral number but was "
    245                              "%r" % max_leaf_nodes)
    246         if -1 < max_leaf_nodes < 2:

ValueError: max_features must be in (0, n_features]
___________________________________________________________________________
Best score: 0.966666666667 (0.0333333333333) [J] | Score: 0.0 (0.0) [J]
Best score: 0.966666666667 (0.0333333333333) [J] | Score: 0.953333333333 (0.0520683311727) [J]
Best score: 0.966666666667 (0.0333333333333) [J] | Score: 0.713333333333 (0.0991071249821) [J]
JoblibValueError
___________________________________________________________________________
...........................................................................
/home/aquemy/dev/dp_hyperparameters/extension/main.py in <module>()
     27 
     28     serializer.serialize_results(scenario, policy)
     29 
     30 if __name__ == "__main__":
     31     args = cli.parse_args()
---> 32     main(args)

...........................................................................
/home/aquemy/dev/dp_hyperparameters/extension/main.py in main(args=Namespace(customize=[(['control', 'seed'], '42')...io='./scenarios/rf_iris_joint.yaml', verbosity=0))
     21         test_size=0.4, 
     22         random_state=scenario['control']['seed']
     23     )
     24 
     25     policy = policies.initiate(scenario['setup']['policy'], config)
---> 26     policy.run(X,y)
        policy.run = <bound method Joint.run of <experiment.policies.joint.Joint object>>
        X = array([[5.1, 3.5, 1.4, 0.2],
       [4.9, 3. , 1....2, 3.4, 5.4, 2.3],
       [5.9, 3. , 5.1, 1.8]])
        y = array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,... 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2])
     27 
     28     serializer.serialize_results(scenario, policy)
     29 
     30 if __name__ == "__main__":

...........................................................................
/home/aquemy/dev/dp_hyperparameters/extension/experiment/policies/joint.py in run(self=<experiment.policies.joint.Joint object>, X=array([[5.1, 3.5, 1.4, 0.2],
       [4.9, 3. , 1....2, 3.4, 5.4, 2.3],
       [5.9, 3. , 5.1, 1.8]]), y=array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,... 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]))
     32             algo=tpe.suggest, 
     33             max_evals=None,
     34             max_time=self.config['time'],     
     35             trials=trials,
     36             show_progressbar=False,
---> 37             verbose=0
     38         )
     39 
     40         best_config = self.context['best_config']
     41         super(Joint, self).display_step_results(best_config)

...........................................................................
/home/aquemy/dev/dp_hyperparameters/extension/hyperopt/fmin.py in fmin(fn=<functools.partial object>, space={'algorithm': {'bootstrap': <hyperopt.pyll.base.Apply object>, 'criterion': <hyperopt.pyll.base.Apply object>, 'max_depth': <hyperopt.pyll.base.Apply object>, 'max_features': <hyperopt.pyll.base.Apply object>, 'max_leaf_nodes': <hyperopt.pyll.base.Apply object>, 'min_samples_split': <hyperopt.pyll.base.Apply object>, 'n_estimators': <hyperopt.pyll.base.Apply object>}, 'pipeline': {'features': <hyperopt.pyll.base.Apply object>, 'normalizer': <hyperopt.pyll.base.Apply object>, 'rebalance': <hyperopt.pyll.base.Apply object>}}, algo=<function suggest>, max_evals=9223372036854775807, max_time=300, trials=<hyperopt.base.Trials object>, rstate=<mtrand.RandomState object>, allow_trials_fmin=True, pass_expr_memo_ctrl=None, catch_eval_exceptions=False, verbose=0, return_argmin=True, points_to_evaluate=None, max_queue_len=1, show_progressbar=False)
    406             pass_expr_memo_ctrl=pass_expr_memo_ctrl,
    407             verbose=verbose,
    408             catch_eval_exceptions=catch_eval_exceptions,
    409             return_argmin=return_argmin,
    410             show_progressbar=show_progressbar,
--> 411             max_time=max_time
        max_time = 300
    412         )
    413 
    414     if trials is None:
    415         if points_to_evaluate is None:

...........................................................................
/home/aquemy/dev/dp_hyperparameters/extension/hyperopt/base.py in fmin(self=<hyperopt.base.Trials object>, fn=<functools.partial object>, space={'algorithm': {'bootstrap': <hyperopt.pyll.base.Apply object>, 'criterion': <hyperopt.pyll.base.Apply object>, 'max_depth': <hyperopt.pyll.base.Apply object>, 'max_features': <hyperopt.pyll.base.Apply object>, 'max_leaf_nodes': <hyperopt.pyll.base.Apply object>, 'min_samples_split': <hyperopt.pyll.base.Apply object>, 'n_estimators': <hyperopt.pyll.base.Apply object>}, 'pipeline': {'features': <hyperopt.pyll.base.Apply object>, 'normalizer': <hyperopt.pyll.base.Apply object>, 'rebalance': <hyperopt.pyll.base.Apply object>}}, algo=<function suggest>, max_evals=9223372036854775807, max_time=300, rstate=<mtrand.RandomState object>, verbose=0, pass_expr_memo_ctrl=None, catch_eval_exceptions=False, return_argmin=True, show_progressbar=False)
    636             verbose=verbose,
    637             allow_trials_fmin=False,  # -- prevent recursion
    638             pass_expr_memo_ctrl=pass_expr_memo_ctrl,
    639             catch_eval_exceptions=catch_eval_exceptions,
    640             return_argmin=return_argmin,
--> 641             show_progressbar=show_progressbar)
        show_progressbar = False
    642 
    643 
    644 def trials_from_docs(docs, validate=True, **kwargs):
    645     """Construct a Trials base class instance from a list of trials documents

...........................................................................
/home/aquemy/dev/dp_hyperparameters/extension/hyperopt/fmin.py in fmin(fn=<functools.partial object>, space={'algorithm': {'bootstrap': <hyperopt.pyll.base.Apply object>, 'criterion': <hyperopt.pyll.base.Apply object>, 'max_depth': <hyperopt.pyll.base.Apply object>, 'max_features': <hyperopt.pyll.base.Apply object>, 'max_leaf_nodes': <hyperopt.pyll.base.Apply object>, 'min_samples_split': <hyperopt.pyll.base.Apply object>, 'n_estimators': <hyperopt.pyll.base.Apply object>}, 'pipeline': {'features': <hyperopt.pyll.base.Apply object>, 'normalizer': <hyperopt.pyll.base.Apply object>, 'rebalance': <hyperopt.pyll.base.Apply object>}}, algo=<function suggest>, max_evals=9223372036854775807, max_time=300, trials=<hyperopt.base.Trials object>, rstate=<mtrand.RandomState object>, allow_trials_fmin=False, pass_expr_memo_ctrl=None, catch_eval_exceptions=False, verbose=0, return_argmin=True, points_to_evaluate=None, max_queue_len=1, show_progressbar=False)
    426                     verbose=verbose,
    427                     max_queue_len=max_queue_len,
    428                     show_progressbar=show_progressbar,
    429                     max_time=max_time)
    430     rval.catch_eval_exceptions = catch_eval_exceptions
--> 431     rval.exhaust()
        rval.exhaust = <bound method FMinIter.exhaust of <hyperopt.fmin.FMinIter object>>
    432     if return_argmin:
    433         return trials.argmin
    434     elif len(trials) > 0:
    435         # Only if there are some succesfull trail runs, return the best point in the evaluation space

...........................................................................
/home/aquemy/dev/dp_hyperparameters/extension/hyperopt/fmin.py in exhaust(self=<hyperopt.fmin.FMinIter object>)
    273             raise StopIteration()
    274         return self.trials
    275 
    276     def exhaust(self):
    277         n_done = len(self.trials)
--> 278         self.run(self.max_evals - n_done, block_until_done=self.asynchronous)
        self.run = <bound method FMinIter.run of <hyperopt.fmin.FMinIter object>>
        self.max_evals = 9223372036854775807
        n_done = 0
        self.asynchronous = False
    279         self.trials.refresh()
    280         return self
    281 
    282 

...........................................................................
/home/aquemy/dev/dp_hyperparameters/extension/hyperopt/fmin.py in run(self=<hyperopt.fmin.FMinIter object>, N=9223372036854775807, block_until_done=False)
    232                     if self.asynchronous:
    233                         # -- wait for workers to fill in the trials
    234                         time.sleep(self.poll_interval_secs)
    235                     else:
    236                         # -- loop over trials and do the jobs directly
--> 237                         self.serial_evaluate()
        self.serial_evaluate = <bound method FMinIter.serial_evaluate of <hyperopt.fmin.FMinIter object>>
    238                     try:
    239                         res = [d['result']['loss'] for d in
    240                                          self.trials.trials if
    241                                          d['result']['status'] == 'ok']

...........................................................................
/home/aquemy/dev/dp_hyperparameters/extension/hyperopt/fmin.py in serial_evaluate(self=<hyperopt.fmin.FMinIter object>, N=-1)
    138                 trial['book_time'] = now
    139                 trial['refresh_time'] = now
    140                 spec = base.spec_from_misc(trial['misc'])
    141                 ctrl = base.Ctrl(self.trials, current_trial=trial)
    142                 try:
--> 143                     result = self.domain.evaluate(spec, ctrl)
        result = undefined
        self.domain.evaluate = <bound method Domain.evaluate of <hyperopt.base.Domain object>>
        spec = {'bootstrap': 1, 'criterion': 1, 'features': 1, 'features_PCA_features__n_components': 1, 'max_depth': 3, 'max_features': 2, 'max_leaf_nodes': 1, 'min_samples_split': 1, 'n_estimators': 0, 'normalizer': 2, ...}
        ctrl = <hyperopt.base.Ctrl object>
    144                 except Exception as e:
    145                     logger.info('job exception: %s' % str(e))
    146                     trial['state'] = base.JOB_STATE_ERROR
    147                     trial['misc']['error'] = (str(type(e)), str(e))

...........................................................................
/home/aquemy/dev/dp_hyperparameters/extension/hyperopt/base.py in evaluate(self=<hyperopt.base.Domain object>, config={'bootstrap': 1, 'criterion': 1, 'features': 1, 'features_PCA_features__n_components': 1, 'max_depth': 3, 'max_features': 2, 'max_leaf_nodes': 1, 'min_samples_split': 1, 'n_estimators': 0, 'normalizer': 2, ...}, ctrl=<hyperopt.base.Ctrl object>, attach_attachments=True)
    841             #    or the normal Python part (self.fn)
    842             pyll_rval = pyll.rec_eval(
    843                 self.expr,
    844                 memo=memo,
    845                 print_node_on_error=self.rec_eval_print_node_on_error)
--> 846             rval = self.fn(pyll_rval)
        rval = undefined
        self.fn = <functools.partial object>
        pyll_rval = {'algorithm': {'bootstrap': False, 'criterion': 'entropy', 'max_depth': 4, 'max_features': 3, 'max_leaf_nodes': 3, 'min_samples_split': 3, 'n_estimators': 10}, 'pipeline': {'features': ('features_PCA', {'features__n_components': 2}), 'normalizer': ('normalizer_PowerTransformer', {}), 'rebalance': ('rebalance_CondensedNearestNeighbour', {'rebalance__n_neighbors': 2})}}
    847 
    848         if isinstance(rval, (float, int, np.number)):
    849             dict_rval = {'loss': float(rval), 'status': STATUS_OK}
    850         else:

...........................................................................
/home/aquemy/dev/dp_hyperparameters/extension/experiment/objective.py in objective_joint(wconfig={'algorithm': {'bootstrap': False, 'criterion': 'entropy', 'max_depth': 4, 'max_features': 3, 'max_leaf_nodes': 3, 'min_samples_split': 3, 'n_estimators': 10}, 'pipeline': {'features': ('features_PCA', {'features__n_components': 2}), 'normalizer': ('normalizer_PowerTransformer', {}), 'rebalance': ('rebalance_CondensedNearestNeighbour', {'rebalance__n_neighbors': 2})}}, algorithm='RandomForest', X=array([[5.1, 3.5, 1.4, 0.2],
       [4.9, 3. , 1....2, 3.4, 5.4, 2.3],
       [5.9, 3. , 5.1, 1.8]]), y=array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,... 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]), context={'baseline_score': 0.9466666666666667, 'baseline_score_std': 0.04988876515698587, 'best_config': {'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': 4, 'max_features': 3, 'max_leaf_nodes': 3, 'min_samples_split': 3, 'n_estimators': 10}, 'config_hash': {'algorithm': 'ffb7ff225ce3d3712c96cf87fe42202988ee2eb0', 'config': 'bae32f426be9cd6243523c023944a8c148fe4aeb', 'pipeline': 'd2a68bfda6fcdec4ae0ffc7d7b6a2122bc1cd673'}, 'duration': 0.7115809917449951, 'iteration': 113, 'loss': 0.033333333333333215, 'max_history_score': 0.9666666666666668, 'max_history_score_std': 0.033333333333333326, 'max_history_step': 'joint', 'pipeline': {'features': ('features_NoneType', {}), 'normalizer': ('normalizer_PowerTransformer', {}), 'rebalance': ('rebalance_CondensedNearestNeighbour', {'rebalance__n_neighbors': 2})}, 'score': 0.9666666666666668, ...}, 'history': [{'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': 2, 'max_features': None, 'max_leaf_nodes': 5, 'min_samples_split': 2, 'n_estimators': 75}, 'config_hash': {'algorithm': '3af5b0cce71c8fe2545246ca24ff5bc3dd516e06', 'config': 'db6ac7e6d348155757e4794bb5f88fe2b4f63d50', 'pipeline': '8d59f4b94cef6be9306ed86a22a9570fa670d567'}, 'duration': 1.149928092956543, 'iteration': 0, 'loss': 0.046666666666666634, 'max_history_score': 0.9533333333333334, 'max_history_score_std': 0.059999999999999984, 'max_history_step': 'joint', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 4, 'features__selectkbest__k': 3}), 'normalizer': ('normalizer_StandardScaler', {'normalizer__with_mean': True, 'normalizer__with_std': True}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 6})}, 'score': 0.9533333333333334, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': 1, 'max_features': 2, 'max_leaf_nodes': 2, 'min_samples_split': 5, 'n_estimators': 100}, 'config_hash': {'algorithm': 'e13eb05fd9a62d2f63bbb1c1deff0cd620d5e6ab', 'config': '4db6fb84d85f52659f780e682ffac5712c3d8a94', 'pipeline': '64c9a1ca9d53ae67244bdd942f4db36a3c05218c'}, 'duration': 1.7678282260894775, 'iteration': 1, 'loss': 0.18000000000000005, 'max_history_score': 0.9533333333333334, 'max_history_score_std': 0.059999999999999984, 'max_history_step': 'joint', 'pipeline': {'features': ('features_NoneType', {}), 'normalizer': ('normalizer_PowerTransformer', {}), 'rebalance': ('rebalance_NearMiss', {'rebalance__n_neighbors': 1})}, 'score': 0.82, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': 1, 'max_features': None, 'max_leaf_nodes': None, 'min_samples_split': 5, 'n_estimators': 75}, 'config_hash': {'algorithm': '94b0d7a654c508cc63643f78fe4f0f07e6f07c1e', 'config': '4403c5a85e951938d3c454e961d3a412780722f6', 'pipeline': '3e47444880d8367fbac2faaba2e52a917274aa58'}, 'duration': 0.8397619724273682, 'iteration': 2, 'loss': 0.03333333333333344, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_PCA', {'features__n_components': 3}), 'normalizer': ('normalizer_MinMaxScaler', {}), 'rebalance': ('rebalance_NoneType', {})}, 'score': 0.9666666666666666, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': None, 'max_features': None, 'max_leaf_nodes': 3, 'min_samples_split': 3, 'n_estimators': 75}, 'config_hash': {'algorithm': 'e8332f0a8902bda03bf70e7978cc5d52affb29d3', 'config': 'a064e2df18ab98d44dabcefbc7bed94913f1d0be', 'pipeline': '7eea819c2a8c103c4b1e9e9c1e224aebba95081f'}, 'duration': 0.8501448631286621, 'iteration': 3, 'loss': 0.053333333333333344, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 2, 'features__selectkbest__k': 4}), 'normalizer': ('normalizer_NoneType', {}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 7})}, 'score': 0.9466666666666667, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'entropy', 'max_depth': 3, 'max_features': 3, 'max_leaf_nodes': None, 'min_samples_split': 5, 'n_estimators': 75}, 'config_hash': {'algorithm': '7a4491035bc6bd737fe9a8cda8a79a02d02d5c74', 'config': '0ddb6f5cab3db4dddd7682966a57205f3e329ad4', 'pipeline': 'a9ae03fe38334f6868cbf84cdd3d629d4bbe3fb0'}, 'duration': 1.1026010513305664, 'iteration': 4, 'loss': 0.05999999999999994, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 2, 'features__selectkbest__k': 1}), 'normalizer': ('normalizer_NoneType', {}), 'rebalance': ('rebalance_NoneType', {})}, 'score': 0.9400000000000001, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'gini', 'max_depth': 3, 'max_features': 1, 'max_leaf_nodes': 5, 'min_samples_split': 2, 'n_estimators': 25}, 'config_hash': {'algorithm': '9826d20b2d6a0f559cf7f16450ce7526f07e8434', 'config': '49f25751bca61cdd461a8cbd2923689b642f98ed', 'pipeline': '19b249664c5bf067de1fed4334a296f947ce774a'}, 'duration': 0.35647010803222656, 'iteration': 5, 'loss': 0.046666666666666634, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_NoneType', {}), 'normalizer': ('normalizer_NoneType', {}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 6})}, 'score': 0.9533333333333334, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'gini', 'max_depth': 2, 'max_features': 1, 'max_leaf_nodes': 2, 'min_samples_split': 2, 'n_estimators': 50}, 'config_hash': {'algorithm': '0a4f6fbb07e0f32c6f675489a0fc82eee05bd8e1', 'config': '5c3a2b6f5e63fb45f10e41e0318b354912ec44f6', 'pipeline': 'dc3b9f176f090005e38b142f11d80e93a7dc5d5e'}, 'duration': 0.7213859558105469, 'iteration': 6, 'loss': 0.31333333333333324, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 1, 'features__selectkbest__k': 4}), 'normalizer': ('normalizer_PowerTransformer', {}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 7})}, 'score': 0.6866666666666668, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'entropy', 'max_depth': 4, 'max_features': 3, 'max_leaf_nodes': 5, 'min_samples_split': 5, 'n_estimators': 10}, 'config_hash': {'algorithm': 'b8112b97ecfc10f00a195af661dcc861cac21289', 'config': 'd3b129b397350f1b6572651c67c01de49b4b174c', 'pipeline': '5b0357ed7072c37b3d6f458bb5d49ff7d825f603'}, 'duration': 0.8299109935760498, 'iteration': 7, 'loss': 1.0, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_PCA', {'features__n_components': 2}), 'normalizer': ('normalizer_StandardScaler', {'normalizer__with_mean': True, 'normalizer__with_std': False}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 6})}, 'score': 0.0, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'gini', 'max_depth': 4, 'max_features': None, 'max_leaf_nodes': 2, 'min_samples_split': 5, 'n_estimators': 100}, 'config_hash': {'algorithm': '40ca24df19b8d164d9d098a6bed1ce056fbbb961', 'config': '813bde1108cc3c4b9bfb3a22cbb421bda7eac671', 'pipeline': '74a7b8705a1c22f7dea5e44e4ebda8f1e48add71'}, 'duration': 2.2111589908599854, 'iteration': 8, 'loss': 0.33333333333333326, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_PCA', {'features__n_components': 2}), 'normalizer': ('normalizer_StandardScaler', {'normalizer__with_mean': False, 'normalizer__with_std': True}), 'rebalance': ('rebalance_NearMiss', {'rebalance__n_neighbors': 2})}, 'score': 0.6666666666666667, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'entropy', 'max_depth': 2, 'max_features': 1, 'max_leaf_nodes': 5, 'min_samples_split': 2, 'n_estimators': 100}, 'config_hash': {'algorithm': '331418a5c12cf1453876eef85e9d98fc8e54fa11', 'config': '31930b6860ed406d59bf7e59ba1925d94704bd3b', 'pipeline': '054bef356f90ec6f644ef3ffc688766744db51c2'}, 'duration': 1.0501940250396729, 'iteration': 9, 'loss': 0.053333333333333344, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_SelectKBest', {'features__k': 1}), 'normalizer': ('normalizer_RobustScaler', {'normalizer__quantile_range': (...), 'normalizer__with_centering': True, 'normalizer__with_scaling': True}), 'rebalance': ('rebalance_NearMiss', {'rebalance__n_neighbors': 2})}, 'score': 0.9466666666666667, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'entropy', 'max_depth': 3, 'max_features': None, 'max_leaf_nodes': 3, 'min_samples_split': 2, 'n_estimators': 100}, 'config_hash': {'algorithm': 'dbc1b8126649fe93dce5fbb37e4015b0acfb179e', 'config': '9913cd550615a9d0946ab4a755a8b9f619e442fd', 'pipeline': 'dd626121cea079ebb32e184ca65483ec7a6d7f59'}, 'duration': 1.120617151260376, 'iteration': 10, 'loss': 0.046666666666666634, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 2, 'features__selectkbest__k': 1}), 'normalizer': ('normalizer_MinMaxScaler', {}), 'rebalance': ('rebalance_NoneType', {})}, 'score': 0.9533333333333334, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'gini', 'max_depth': 3, 'max_features': 3, 'max_leaf_nodes': None, 'min_samples_split': 3, 'n_estimators': 75}, 'config_hash': {'algorithm': '34917a130df5a975f78bd7ec1a0c7b1ffdc787a9', 'config': '95fc8cadc088141290b7de9c388977e4685f0108', 'pipeline': '550d10faf2f08db48516cc3501558816d6a99bc0'}, 'duration': 1.4287099838256836, 'iteration': 11, 'loss': 0.19333333333333313, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 3, 'features__selectkbest__k': 4}), 'normalizer': ('normalizer_StandardScaler', {'normalizer__with_mean': False, 'normalizer__with_std': False}), 'rebalance': ('rebalance_CondensedNearestNeighbour', {'rebalance__n_neighbors': 1})}, 'score': 0.8066666666666669, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'entropy', 'max_depth': 1, 'max_features': 2, 'max_leaf_nodes': 5, 'min_samples_split': 2, 'n_estimators': 75}, 'config_hash': {'algorithm': '33f9abb4aee44a395a9f3b3ffa9ce80a8cdaed7c', 'config': '40fa726f0360cf6af55f9b5902d399d02f61f157', 'pipeline': 'cfd1d20841fe2153da762c95e79f95a3fb1e426a'}, 'duration': 1.2978079319000244, 'iteration': 12, 'loss': 0.053333333333333344, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_PCA', {'features__n_components': 4}), 'normalizer': ('normalizer_MinMaxScaler', {}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 7})}, 'score': 0.9466666666666667, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'entropy', 'max_depth': 4, 'max_features': 2, 'max_leaf_nodes': 5, 'min_samples_split': 3, 'n_estimators': 25}, 'config_hash': {'algorithm': '210111ec6562d09eb093e98ed69ef1c662e11a50', 'config': '0fb8e77c7bd9a58b72f1b33c21a59a09a8c676ba', 'pipeline': '5d269d759e0c7926a685a14b263ace8ae0071e4b'}, 'duration': 0.36649012565612793, 'iteration': 13, 'loss': 0.040000000000000036, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 2, 'features__selectkbest__k': 2}), 'normalizer': ('normalizer_NoneType', {}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 7})}, 'score': 0.96, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'entropy', 'max_depth': 3, 'max_features': 1, 'max_leaf_nodes': 5, 'min_samples_split': 2, 'n_estimators': 25}, 'config_hash': {'algorithm': '0e989a03980101fabf79eda3326ed2870e11d690', 'config': 'f4bffd5d8c67a9c5321a9943c4a99678f59a02b7', 'pipeline': '865ee1e3fe8334c3d5ecb2038d5a5d1b3ba50e75'}, 'duration': 0.35639500617980957, 'iteration': 14, 'loss': 0.046666666666666634, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_NoneType', {}), 'normalizer': ('normalizer_RobustScaler', {'normalizer__quantile_range': (...), 'normalizer__with_centering': True, 'normalizer__with_scaling': False}), 'rebalance': ('rebalance_NoneType', {})}, 'score': 0.9533333333333334, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'entropy', 'max_depth': None, 'max_features': 3, 'max_leaf_nodes': 3, 'min_samples_split': 5, 'n_estimators': 10}, 'config_hash': {'algorithm': '9c592e876c13de5e23e6de5b868e01755d63e72e', 'config': '1e6a68cd1eeac886d90724d78b1cb5fb76a3cde4', 'pipeline': '5a1ca4d82f21b7de0d2c918630a42510673fa36e'}, 'duration': 0.18141412734985352, 'iteration': 15, 'loss': 0.046666666666666634, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_SelectKBest', {'features__k': 3}), 'normalizer': ('normalizer_RobustScaler', {'normalizer__quantile_range': (...), 'normalizer__with_centering': True, 'normalizer__with_scaling': True}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 6})}, 'score': 0.9533333333333334, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': 1, 'max_features': None, 'max_leaf_nodes': None, 'min_samples_split': 5, 'n_estimators': 10}, 'config_hash': {'algorithm': '8bed77aef289bfd453b2858bd288ae5ba7160f2b', 'config': '781185bcb8999045de8d489f253a1a1ba4247932', 'pipeline': '1ece7eabedc2be9e5b0a1be65c570d08ffa3eb54'}, 'duration': 0.1636829376220703, 'iteration': 16, 'loss': 0.053333333333333344, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_NoneType', {}), 'normalizer': ('normalizer_NoneType', {}), 'rebalance': ('rebalance_NearMiss', {'rebalance__n_neighbors': 1})}, 'score': 0.9466666666666667, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'gini', 'max_depth': 3, 'max_features': 2, 'max_leaf_nodes': 2, 'min_samples_split': 5, 'n_estimators': 75}, 'config_hash': {'algorithm': '617b97d9ba21d3373bc51ffa9cccf9c6f91a77b3', 'config': '99fb425b4e8c5d80228cab94202252aa25cdf77c', 'pipeline': 'd6242929c3b515c7719e60423023ac604311afc3'}, 'duration': 0.8468999862670898, 'iteration': 17, 'loss': 0.24, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_PCA', {'features__n_components': 4}), 'normalizer': ('normalizer_PowerTransformer', {}), 'rebalance': ('rebalance_NearMiss', {'rebalance__n_neighbors': 2})}, 'score': 0.76, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': 1, 'max_features': 1, 'max_leaf_nodes': 2, 'min_samples_split': 5, 'n_estimators': 50}, 'config_hash': {'algorithm': 'b92d2697cdd4979da443369d6596229ec091626a', 'config': 'c513a3e13281206ad76187dd817b1fff93d54fe1', 'pipeline': 'c4b4f914a3ca8df967cade997a90366d85a371b9'}, 'duration': 0.6724588871002197, 'iteration': 18, 'loss': 0.23333333333333328, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 1, 'features__selectkbest__k': 3}), 'normalizer': ('normalizer_StandardScaler', {'normalizer__with_mean': True, 'normalizer__with_std': True}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 5})}, 'score': 0.7666666666666667, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'entropy', 'max_depth': None, 'max_features': None, 'max_leaf_nodes': 5, 'min_samples_split': 5, 'n_estimators': 10}, 'config_hash': {'algorithm': 'a0115de695e6cca2e81cbfb54df79bf4b43608b1', 'config': 'ba194015e20b5d67770e8c67342c3d8d0d01dc41', 'pipeline': '8d45fabfeb85ffdcabf7076bd0e65fffe97ce928'}, 'duration': 0.19424200057983398, 'iteration': 19, 'loss': 0.08666666666666667, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_PCA', {'features__n_components': 3}), 'normalizer': ('normalizer_NoneType', {}), 'rebalance': ('rebalance_NoneType', {})}, 'score': 0.9133333333333333, ...}, ...], 'history_hash': ['db6ac7e6d348155757e4794bb5f88fe2b4f63d50', '4db6fb84d85f52659f780e682ffac5712c3d8a94', '4403c5a85e951938d3c454e961d3a412780722f6', 'a064e2df18ab98d44dabcefbc7bed94913f1d0be', '0ddb6f5cab3db4dddd7682966a57205f3e329ad4', '49f25751bca61cdd461a8cbd2923689b642f98ed', '5c3a2b6f5e63fb45f10e41e0318b354912ec44f6', 'd3b129b397350f1b6572651c67c01de49b4b174c', '813bde1108cc3c4b9bfb3a22cbb421bda7eac671', '31930b6860ed406d59bf7e59ba1925d94704bd3b', '9913cd550615a9d0946ab4a755a8b9f619e442fd', '95fc8cadc088141290b7de9c388977e4685f0108', '40fa726f0360cf6af55f9b5902d399d02f61f157', '0fb8e77c7bd9a58b72f1b33c21a59a09a8c676ba', 'f4bffd5d8c67a9c5321a9943c4a99678f59a02b7', '1e6a68cd1eeac886d90724d78b1cb5fb76a3cde4', '781185bcb8999045de8d489f253a1a1ba4247932', '99fb425b4e8c5d80228cab94202252aa25cdf77c', 'c513a3e13281206ad76187dd817b1fff93d54fe1', 'ba194015e20b5d67770e8c67342c3d8d0d01dc41', ...], 'history_index': {'00f0493590a2cb5e98a35b29816f8cd9f87f96ec': 208, '013329309d510b94f19d930320402d65f953a847': 39, '038a0f515e2ec894ee8e34f9caa2889eb3ebd5ce': 66, '052ae4bf232b316187b078abae42c2be19e16a00': 111, '05e9258ebf99dd97202167ef1563fa834b0568f1': 242, '0659afebf316aafeb75612fb07081a04c28545ed': 74, '06e7cde9f3556cd01332ce389ad1d8925cd4b4a4': 120, '08606f2a0f0a6c9de204020b4632e09fcee0ae56': 168, '0a05b5b0a70971a5e347aaab7a4d4a07a92222fd': 191, '0b6551ecfd6f83a15704a9db68f1599c99c6d3ef': 58, ...}, 'iteration': 242, 'max_history_score': 0.9666666666666668, 'max_history_score_std': 0.033333333333333326, 'max_history_step': 'joint'}, config={'algorithm': 'RandomForest', 'seed': 42, 'time': 300})
    108 
    109 def objective_algo(algo_config, current_pipeline_config, algorithm, X, y, context, config):
    110     return objective(current_pipeline_config, algo_config, algorithm, X, y, context, config, step='algorithm')
    111 
    112 def objective_joint(wconfig, algorithm, X, y, context, config):
--> 113     return objective(wconfig['pipeline'], wconfig['algorithm'], algorithm, X, y, context, config, step='joint')
        wconfig = {'algorithm': {'bootstrap': False, 'criterion': 'entropy', 'max_depth': 4, 'max_features': 3, 'max_leaf_nodes': 3, 'min_samples_split': 3, 'n_estimators': 10}, 'pipeline': {'features': ('features_PCA', {'features__n_components': 2}), 'normalizer': ('normalizer_PowerTransformer', {}), 'rebalance': ('rebalance_CondensedNearestNeighbour', {'rebalance__n_neighbors': 2})}}
        algorithm = 'RandomForest'
        X = array([[5.1, 3.5, 1.4, 0.2],
       [4.9, 3. , 1....2, 3.4, 5.4, 2.3],
       [5.9, 3. , 5.1, 1.8]])
        y = array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,... 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2])
        context = {'baseline_score': 0.9466666666666667, 'baseline_score_std': 0.04988876515698587, 'best_config': {'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': 4, 'max_features': 3, 'max_leaf_nodes': 3, 'min_samples_split': 3, 'n_estimators': 10}, 'config_hash': {'algorithm': 'ffb7ff225ce3d3712c96cf87fe42202988ee2eb0', 'config': 'bae32f426be9cd6243523c023944a8c148fe4aeb', 'pipeline': 'd2a68bfda6fcdec4ae0ffc7d7b6a2122bc1cd673'}, 'duration': 0.7115809917449951, 'iteration': 113, 'loss': 0.033333333333333215, 'max_history_score': 0.9666666666666668, 'max_history_score_std': 0.033333333333333326, 'max_history_step': 'joint', 'pipeline': {'features': ('features_NoneType', {}), 'normalizer': ('normalizer_PowerTransformer', {}), 'rebalance': ('rebalance_CondensedNearestNeighbour', {'rebalance__n_neighbors': 2})}, 'score': 0.9666666666666668, ...}, 'history': [{'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': 2, 'max_features': None, 'max_leaf_nodes': 5, 'min_samples_split': 2, 'n_estimators': 75}, 'config_hash': {'algorithm': '3af5b0cce71c8fe2545246ca24ff5bc3dd516e06', 'config': 'db6ac7e6d348155757e4794bb5f88fe2b4f63d50', 'pipeline': '8d59f4b94cef6be9306ed86a22a9570fa670d567'}, 'duration': 1.149928092956543, 'iteration': 0, 'loss': 0.046666666666666634, 'max_history_score': 0.9533333333333334, 'max_history_score_std': 0.059999999999999984, 'max_history_step': 'joint', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 4, 'features__selectkbest__k': 3}), 'normalizer': ('normalizer_StandardScaler', {'normalizer__with_mean': True, 'normalizer__with_std': True}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 6})}, 'score': 0.9533333333333334, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': 1, 'max_features': 2, 'max_leaf_nodes': 2, 'min_samples_split': 5, 'n_estimators': 100}, 'config_hash': {'algorithm': 'e13eb05fd9a62d2f63bbb1c1deff0cd620d5e6ab', 'config': '4db6fb84d85f52659f780e682ffac5712c3d8a94', 'pipeline': '64c9a1ca9d53ae67244bdd942f4db36a3c05218c'}, 'duration': 1.7678282260894775, 'iteration': 1, 'loss': 0.18000000000000005, 'max_history_score': 0.9533333333333334, 'max_history_score_std': 0.059999999999999984, 'max_history_step': 'joint', 'pipeline': {'features': ('features_NoneType', {}), 'normalizer': ('normalizer_PowerTransformer', {}), 'rebalance': ('rebalance_NearMiss', {'rebalance__n_neighbors': 1})}, 'score': 0.82, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': 1, 'max_features': None, 'max_leaf_nodes': None, 'min_samples_split': 5, 'n_estimators': 75}, 'config_hash': {'algorithm': '94b0d7a654c508cc63643f78fe4f0f07e6f07c1e', 'config': '4403c5a85e951938d3c454e961d3a412780722f6', 'pipeline': '3e47444880d8367fbac2faaba2e52a917274aa58'}, 'duration': 0.8397619724273682, 'iteration': 2, 'loss': 0.03333333333333344, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_PCA', {'features__n_components': 3}), 'normalizer': ('normalizer_MinMaxScaler', {}), 'rebalance': ('rebalance_NoneType', {})}, 'score': 0.9666666666666666, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': None, 'max_features': None, 'max_leaf_nodes': 3, 'min_samples_split': 3, 'n_estimators': 75}, 'config_hash': {'algorithm': 'e8332f0a8902bda03bf70e7978cc5d52affb29d3', 'config': 'a064e2df18ab98d44dabcefbc7bed94913f1d0be', 'pipeline': '7eea819c2a8c103c4b1e9e9c1e224aebba95081f'}, 'duration': 0.8501448631286621, 'iteration': 3, 'loss': 0.053333333333333344, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 2, 'features__selectkbest__k': 4}), 'normalizer': ('normalizer_NoneType', {}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 7})}, 'score': 0.9466666666666667, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'entropy', 'max_depth': 3, 'max_features': 3, 'max_leaf_nodes': None, 'min_samples_split': 5, 'n_estimators': 75}, 'config_hash': {'algorithm': '7a4491035bc6bd737fe9a8cda8a79a02d02d5c74', 'config': '0ddb6f5cab3db4dddd7682966a57205f3e329ad4', 'pipeline': 'a9ae03fe38334f6868cbf84cdd3d629d4bbe3fb0'}, 'duration': 1.1026010513305664, 'iteration': 4, 'loss': 0.05999999999999994, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 2, 'features__selectkbest__k': 1}), 'normalizer': ('normalizer_NoneType', {}), 'rebalance': ('rebalance_NoneType', {})}, 'score': 0.9400000000000001, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'gini', 'max_depth': 3, 'max_features': 1, 'max_leaf_nodes': 5, 'min_samples_split': 2, 'n_estimators': 25}, 'config_hash': {'algorithm': '9826d20b2d6a0f559cf7f16450ce7526f07e8434', 'config': '49f25751bca61cdd461a8cbd2923689b642f98ed', 'pipeline': '19b249664c5bf067de1fed4334a296f947ce774a'}, 'duration': 0.35647010803222656, 'iteration': 5, 'loss': 0.046666666666666634, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_NoneType', {}), 'normalizer': ('normalizer_NoneType', {}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 6})}, 'score': 0.9533333333333334, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'gini', 'max_depth': 2, 'max_features': 1, 'max_leaf_nodes': 2, 'min_samples_split': 2, 'n_estimators': 50}, 'config_hash': {'algorithm': '0a4f6fbb07e0f32c6f675489a0fc82eee05bd8e1', 'config': '5c3a2b6f5e63fb45f10e41e0318b354912ec44f6', 'pipeline': 'dc3b9f176f090005e38b142f11d80e93a7dc5d5e'}, 'duration': 0.7213859558105469, 'iteration': 6, 'loss': 0.31333333333333324, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 1, 'features__selectkbest__k': 4}), 'normalizer': ('normalizer_PowerTransformer', {}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 7})}, 'score': 0.6866666666666668, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'entropy', 'max_depth': 4, 'max_features': 3, 'max_leaf_nodes': 5, 'min_samples_split': 5, 'n_estimators': 10}, 'config_hash': {'algorithm': 'b8112b97ecfc10f00a195af661dcc861cac21289', 'config': 'd3b129b397350f1b6572651c67c01de49b4b174c', 'pipeline': '5b0357ed7072c37b3d6f458bb5d49ff7d825f603'}, 'duration': 0.8299109935760498, 'iteration': 7, 'loss': 1.0, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_PCA', {'features__n_components': 2}), 'normalizer': ('normalizer_StandardScaler', {'normalizer__with_mean': True, 'normalizer__with_std': False}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 6})}, 'score': 0.0, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'gini', 'max_depth': 4, 'max_features': None, 'max_leaf_nodes': 2, 'min_samples_split': 5, 'n_estimators': 100}, 'config_hash': {'algorithm': '40ca24df19b8d164d9d098a6bed1ce056fbbb961', 'config': '813bde1108cc3c4b9bfb3a22cbb421bda7eac671', 'pipeline': '74a7b8705a1c22f7dea5e44e4ebda8f1e48add71'}, 'duration': 2.2111589908599854, 'iteration': 8, 'loss': 0.33333333333333326, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_PCA', {'features__n_components': 2}), 'normalizer': ('normalizer_StandardScaler', {'normalizer__with_mean': False, 'normalizer__with_std': True}), 'rebalance': ('rebalance_NearMiss', {'rebalance__n_neighbors': 2})}, 'score': 0.6666666666666667, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'entropy', 'max_depth': 2, 'max_features': 1, 'max_leaf_nodes': 5, 'min_samples_split': 2, 'n_estimators': 100}, 'config_hash': {'algorithm': '331418a5c12cf1453876eef85e9d98fc8e54fa11', 'config': '31930b6860ed406d59bf7e59ba1925d94704bd3b', 'pipeline': '054bef356f90ec6f644ef3ffc688766744db51c2'}, 'duration': 1.0501940250396729, 'iteration': 9, 'loss': 0.053333333333333344, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_SelectKBest', {'features__k': 1}), 'normalizer': ('normalizer_RobustScaler', {'normalizer__quantile_range': (...), 'normalizer__with_centering': True, 'normalizer__with_scaling': True}), 'rebalance': ('rebalance_NearMiss', {'rebalance__n_neighbors': 2})}, 'score': 0.9466666666666667, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'entropy', 'max_depth': 3, 'max_features': None, 'max_leaf_nodes': 3, 'min_samples_split': 2, 'n_estimators': 100}, 'config_hash': {'algorithm': 'dbc1b8126649fe93dce5fbb37e4015b0acfb179e', 'config': '9913cd550615a9d0946ab4a755a8b9f619e442fd', 'pipeline': 'dd626121cea079ebb32e184ca65483ec7a6d7f59'}, 'duration': 1.120617151260376, 'iteration': 10, 'loss': 0.046666666666666634, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 2, 'features__selectkbest__k': 1}), 'normalizer': ('normalizer_MinMaxScaler', {}), 'rebalance': ('rebalance_NoneType', {})}, 'score': 0.9533333333333334, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'gini', 'max_depth': 3, 'max_features': 3, 'max_leaf_nodes': None, 'min_samples_split': 3, 'n_estimators': 75}, 'config_hash': {'algorithm': '34917a130df5a975f78bd7ec1a0c7b1ffdc787a9', 'config': '95fc8cadc088141290b7de9c388977e4685f0108', 'pipeline': '550d10faf2f08db48516cc3501558816d6a99bc0'}, 'duration': 1.4287099838256836, 'iteration': 11, 'loss': 0.19333333333333313, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 3, 'features__selectkbest__k': 4}), 'normalizer': ('normalizer_StandardScaler', {'normalizer__with_mean': False, 'normalizer__with_std': False}), 'rebalance': ('rebalance_CondensedNearestNeighbour', {'rebalance__n_neighbors': 1})}, 'score': 0.8066666666666669, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'entropy', 'max_depth': 1, 'max_features': 2, 'max_leaf_nodes': 5, 'min_samples_split': 2, 'n_estimators': 75}, 'config_hash': {'algorithm': '33f9abb4aee44a395a9f3b3ffa9ce80a8cdaed7c', 'config': '40fa726f0360cf6af55f9b5902d399d02f61f157', 'pipeline': 'cfd1d20841fe2153da762c95e79f95a3fb1e426a'}, 'duration': 1.2978079319000244, 'iteration': 12, 'loss': 0.053333333333333344, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_PCA', {'features__n_components': 4}), 'normalizer': ('normalizer_MinMaxScaler', {}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 7})}, 'score': 0.9466666666666667, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'entropy', 'max_depth': 4, 'max_features': 2, 'max_leaf_nodes': 5, 'min_samples_split': 3, 'n_estimators': 25}, 'config_hash': {'algorithm': '210111ec6562d09eb093e98ed69ef1c662e11a50', 'config': '0fb8e77c7bd9a58b72f1b33c21a59a09a8c676ba', 'pipeline': '5d269d759e0c7926a685a14b263ace8ae0071e4b'}, 'duration': 0.36649012565612793, 'iteration': 13, 'loss': 0.040000000000000036, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 2, 'features__selectkbest__k': 2}), 'normalizer': ('normalizer_NoneType', {}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 7})}, 'score': 0.96, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'entropy', 'max_depth': 3, 'max_features': 1, 'max_leaf_nodes': 5, 'min_samples_split': 2, 'n_estimators': 25}, 'config_hash': {'algorithm': '0e989a03980101fabf79eda3326ed2870e11d690', 'config': 'f4bffd5d8c67a9c5321a9943c4a99678f59a02b7', 'pipeline': '865ee1e3fe8334c3d5ecb2038d5a5d1b3ba50e75'}, 'duration': 0.35639500617980957, 'iteration': 14, 'loss': 0.046666666666666634, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_NoneType', {}), 'normalizer': ('normalizer_RobustScaler', {'normalizer__quantile_range': (...), 'normalizer__with_centering': True, 'normalizer__with_scaling': False}), 'rebalance': ('rebalance_NoneType', {})}, 'score': 0.9533333333333334, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'entropy', 'max_depth': None, 'max_features': 3, 'max_leaf_nodes': 3, 'min_samples_split': 5, 'n_estimators': 10}, 'config_hash': {'algorithm': '9c592e876c13de5e23e6de5b868e01755d63e72e', 'config': '1e6a68cd1eeac886d90724d78b1cb5fb76a3cde4', 'pipeline': '5a1ca4d82f21b7de0d2c918630a42510673fa36e'}, 'duration': 0.18141412734985352, 'iteration': 15, 'loss': 0.046666666666666634, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_SelectKBest', {'features__k': 3}), 'normalizer': ('normalizer_RobustScaler', {'normalizer__quantile_range': (...), 'normalizer__with_centering': True, 'normalizer__with_scaling': True}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 6})}, 'score': 0.9533333333333334, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': 1, 'max_features': None, 'max_leaf_nodes': None, 'min_samples_split': 5, 'n_estimators': 10}, 'config_hash': {'algorithm': '8bed77aef289bfd453b2858bd288ae5ba7160f2b', 'config': '781185bcb8999045de8d489f253a1a1ba4247932', 'pipeline': '1ece7eabedc2be9e5b0a1be65c570d08ffa3eb54'}, 'duration': 0.1636829376220703, 'iteration': 16, 'loss': 0.053333333333333344, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_NoneType', {}), 'normalizer': ('normalizer_NoneType', {}), 'rebalance': ('rebalance_NearMiss', {'rebalance__n_neighbors': 1})}, 'score': 0.9466666666666667, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'gini', 'max_depth': 3, 'max_features': 2, 'max_leaf_nodes': 2, 'min_samples_split': 5, 'n_estimators': 75}, 'config_hash': {'algorithm': '617b97d9ba21d3373bc51ffa9cccf9c6f91a77b3', 'config': '99fb425b4e8c5d80228cab94202252aa25cdf77c', 'pipeline': 'd6242929c3b515c7719e60423023ac604311afc3'}, 'duration': 0.8468999862670898, 'iteration': 17, 'loss': 0.24, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_PCA', {'features__n_components': 4}), 'normalizer': ('normalizer_PowerTransformer', {}), 'rebalance': ('rebalance_NearMiss', {'rebalance__n_neighbors': 2})}, 'score': 0.76, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': 1, 'max_features': 1, 'max_leaf_nodes': 2, 'min_samples_split': 5, 'n_estimators': 50}, 'config_hash': {'algorithm': 'b92d2697cdd4979da443369d6596229ec091626a', 'config': 'c513a3e13281206ad76187dd817b1fff93d54fe1', 'pipeline': 'c4b4f914a3ca8df967cade997a90366d85a371b9'}, 'duration': 0.6724588871002197, 'iteration': 18, 'loss': 0.23333333333333328, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 1, 'features__selectkbest__k': 3}), 'normalizer': ('normalizer_StandardScaler', {'normalizer__with_mean': True, 'normalizer__with_std': True}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 5})}, 'score': 0.7666666666666667, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'entropy', 'max_depth': None, 'max_features': None, 'max_leaf_nodes': 5, 'min_samples_split': 5, 'n_estimators': 10}, 'config_hash': {'algorithm': 'a0115de695e6cca2e81cbfb54df79bf4b43608b1', 'config': 'ba194015e20b5d67770e8c67342c3d8d0d01dc41', 'pipeline': '8d45fabfeb85ffdcabf7076bd0e65fffe97ce928'}, 'duration': 0.19424200057983398, 'iteration': 19, 'loss': 0.08666666666666667, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_PCA', {'features__n_components': 3}), 'normalizer': ('normalizer_NoneType', {}), 'rebalance': ('rebalance_NoneType', {})}, 'score': 0.9133333333333333, ...}, ...], 'history_hash': ['db6ac7e6d348155757e4794bb5f88fe2b4f63d50', '4db6fb84d85f52659f780e682ffac5712c3d8a94', '4403c5a85e951938d3c454e961d3a412780722f6', 'a064e2df18ab98d44dabcefbc7bed94913f1d0be', '0ddb6f5cab3db4dddd7682966a57205f3e329ad4', '49f25751bca61cdd461a8cbd2923689b642f98ed', '5c3a2b6f5e63fb45f10e41e0318b354912ec44f6', 'd3b129b397350f1b6572651c67c01de49b4b174c', '813bde1108cc3c4b9bfb3a22cbb421bda7eac671', '31930b6860ed406d59bf7e59ba1925d94704bd3b', '9913cd550615a9d0946ab4a755a8b9f619e442fd', '95fc8cadc088141290b7de9c388977e4685f0108', '40fa726f0360cf6af55f9b5902d399d02f61f157', '0fb8e77c7bd9a58b72f1b33c21a59a09a8c676ba', 'f4bffd5d8c67a9c5321a9943c4a99678f59a02b7', '1e6a68cd1eeac886d90724d78b1cb5fb76a3cde4', '781185bcb8999045de8d489f253a1a1ba4247932', '99fb425b4e8c5d80228cab94202252aa25cdf77c', 'c513a3e13281206ad76187dd817b1fff93d54fe1', 'ba194015e20b5d67770e8c67342c3d8d0d01dc41', ...], 'history_index': {'00f0493590a2cb5e98a35b29816f8cd9f87f96ec': 208, '013329309d510b94f19d930320402d65f953a847': 39, '038a0f515e2ec894ee8e34f9caa2889eb3ebd5ce': 66, '052ae4bf232b316187b078abae42c2be19e16a00': 111, '05e9258ebf99dd97202167ef1563fa834b0568f1': 242, '0659afebf316aafeb75612fb07081a04c28545ed': 74, '06e7cde9f3556cd01332ce389ad1d8925cd4b4a4': 120, '08606f2a0f0a6c9de204020b4632e09fcee0ae56': 168, '0a05b5b0a70971a5e347aaab7a4d4a07a92222fd': 191, '0b6551ecfd6f83a15704a9db68f1599c99c6d3ef': 58, ...}, 'iteration': 242, 'max_history_score': 0.9666666666666668, 'max_history_score_std': 0.033333333333333326, 'max_history_step': 'joint'}
        config = {'algorithm': 'RandomForest', 'seed': 42, 'time': 300}
    114 
    115 
    116 def get_baseline_score(algorithm, X, y, seed):
    117     pipeline, _ = pipeline_conf_to_full_pipeline(

...........................................................................
/home/aquemy/dev/dp_hyperparameters/extension/experiment/objective.py in objective(pipeline_config={'features': ('features_PCA', {'features__n_components': 2}), 'normalizer': ('normalizer_PowerTransformer', {}), 'rebalance': ('rebalance_CondensedNearestNeighbour', {'rebalance__n_neighbors': 2})}, algo_config={'bootstrap': False, 'criterion': 'entropy', 'max_depth': 4, 'max_features': 3, 'max_leaf_nodes': 3, 'min_samples_split': 3, 'n_estimators': 10}, algorithm='RandomForest', X=array([[5.1, 3.5, 1.4, 0.2],
       [4.9, 3. , 1....2, 3.4, 5.4, 2.3],
       [5.9, 3. , 5.1, 1.8]]), y=array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,... 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]), context={'baseline_score': 0.9466666666666667, 'baseline_score_std': 0.04988876515698587, 'best_config': {'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': 4, 'max_features': 3, 'max_leaf_nodes': 3, 'min_samples_split': 3, 'n_estimators': 10}, 'config_hash': {'algorithm': 'ffb7ff225ce3d3712c96cf87fe42202988ee2eb0', 'config': 'bae32f426be9cd6243523c023944a8c148fe4aeb', 'pipeline': 'd2a68bfda6fcdec4ae0ffc7d7b6a2122bc1cd673'}, 'duration': 0.7115809917449951, 'iteration': 113, 'loss': 0.033333333333333215, 'max_history_score': 0.9666666666666668, 'max_history_score_std': 0.033333333333333326, 'max_history_step': 'joint', 'pipeline': {'features': ('features_NoneType', {}), 'normalizer': ('normalizer_PowerTransformer', {}), 'rebalance': ('rebalance_CondensedNearestNeighbour', {'rebalance__n_neighbors': 2})}, 'score': 0.9666666666666668, ...}, 'history': [{'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': 2, 'max_features': None, 'max_leaf_nodes': 5, 'min_samples_split': 2, 'n_estimators': 75}, 'config_hash': {'algorithm': '3af5b0cce71c8fe2545246ca24ff5bc3dd516e06', 'config': 'db6ac7e6d348155757e4794bb5f88fe2b4f63d50', 'pipeline': '8d59f4b94cef6be9306ed86a22a9570fa670d567'}, 'duration': 1.149928092956543, 'iteration': 0, 'loss': 0.046666666666666634, 'max_history_score': 0.9533333333333334, 'max_history_score_std': 0.059999999999999984, 'max_history_step': 'joint', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 4, 'features__selectkbest__k': 3}), 'normalizer': ('normalizer_StandardScaler', {'normalizer__with_mean': True, 'normalizer__with_std': True}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 6})}, 'score': 0.9533333333333334, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': 1, 'max_features': 2, 'max_leaf_nodes': 2, 'min_samples_split': 5, 'n_estimators': 100}, 'config_hash': {'algorithm': 'e13eb05fd9a62d2f63bbb1c1deff0cd620d5e6ab', 'config': '4db6fb84d85f52659f780e682ffac5712c3d8a94', 'pipeline': '64c9a1ca9d53ae67244bdd942f4db36a3c05218c'}, 'duration': 1.7678282260894775, 'iteration': 1, 'loss': 0.18000000000000005, 'max_history_score': 0.9533333333333334, 'max_history_score_std': 0.059999999999999984, 'max_history_step': 'joint', 'pipeline': {'features': ('features_NoneType', {}), 'normalizer': ('normalizer_PowerTransformer', {}), 'rebalance': ('rebalance_NearMiss', {'rebalance__n_neighbors': 1})}, 'score': 0.82, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': 1, 'max_features': None, 'max_leaf_nodes': None, 'min_samples_split': 5, 'n_estimators': 75}, 'config_hash': {'algorithm': '94b0d7a654c508cc63643f78fe4f0f07e6f07c1e', 'config': '4403c5a85e951938d3c454e961d3a412780722f6', 'pipeline': '3e47444880d8367fbac2faaba2e52a917274aa58'}, 'duration': 0.8397619724273682, 'iteration': 2, 'loss': 0.03333333333333344, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_PCA', {'features__n_components': 3}), 'normalizer': ('normalizer_MinMaxScaler', {}), 'rebalance': ('rebalance_NoneType', {})}, 'score': 0.9666666666666666, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': None, 'max_features': None, 'max_leaf_nodes': 3, 'min_samples_split': 3, 'n_estimators': 75}, 'config_hash': {'algorithm': 'e8332f0a8902bda03bf70e7978cc5d52affb29d3', 'config': 'a064e2df18ab98d44dabcefbc7bed94913f1d0be', 'pipeline': '7eea819c2a8c103c4b1e9e9c1e224aebba95081f'}, 'duration': 0.8501448631286621, 'iteration': 3, 'loss': 0.053333333333333344, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 2, 'features__selectkbest__k': 4}), 'normalizer': ('normalizer_NoneType', {}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 7})}, 'score': 0.9466666666666667, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'entropy', 'max_depth': 3, 'max_features': 3, 'max_leaf_nodes': None, 'min_samples_split': 5, 'n_estimators': 75}, 'config_hash': {'algorithm': '7a4491035bc6bd737fe9a8cda8a79a02d02d5c74', 'config': '0ddb6f5cab3db4dddd7682966a57205f3e329ad4', 'pipeline': 'a9ae03fe38334f6868cbf84cdd3d629d4bbe3fb0'}, 'duration': 1.1026010513305664, 'iteration': 4, 'loss': 0.05999999999999994, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 2, 'features__selectkbest__k': 1}), 'normalizer': ('normalizer_NoneType', {}), 'rebalance': ('rebalance_NoneType', {})}, 'score': 0.9400000000000001, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'gini', 'max_depth': 3, 'max_features': 1, 'max_leaf_nodes': 5, 'min_samples_split': 2, 'n_estimators': 25}, 'config_hash': {'algorithm': '9826d20b2d6a0f559cf7f16450ce7526f07e8434', 'config': '49f25751bca61cdd461a8cbd2923689b642f98ed', 'pipeline': '19b249664c5bf067de1fed4334a296f947ce774a'}, 'duration': 0.35647010803222656, 'iteration': 5, 'loss': 0.046666666666666634, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_NoneType', {}), 'normalizer': ('normalizer_NoneType', {}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 6})}, 'score': 0.9533333333333334, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'gini', 'max_depth': 2, 'max_features': 1, 'max_leaf_nodes': 2, 'min_samples_split': 2, 'n_estimators': 50}, 'config_hash': {'algorithm': '0a4f6fbb07e0f32c6f675489a0fc82eee05bd8e1', 'config': '5c3a2b6f5e63fb45f10e41e0318b354912ec44f6', 'pipeline': 'dc3b9f176f090005e38b142f11d80e93a7dc5d5e'}, 'duration': 0.7213859558105469, 'iteration': 6, 'loss': 0.31333333333333324, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 1, 'features__selectkbest__k': 4}), 'normalizer': ('normalizer_PowerTransformer', {}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 7})}, 'score': 0.6866666666666668, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'entropy', 'max_depth': 4, 'max_features': 3, 'max_leaf_nodes': 5, 'min_samples_split': 5, 'n_estimators': 10}, 'config_hash': {'algorithm': 'b8112b97ecfc10f00a195af661dcc861cac21289', 'config': 'd3b129b397350f1b6572651c67c01de49b4b174c', 'pipeline': '5b0357ed7072c37b3d6f458bb5d49ff7d825f603'}, 'duration': 0.8299109935760498, 'iteration': 7, 'loss': 1.0, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_PCA', {'features__n_components': 2}), 'normalizer': ('normalizer_StandardScaler', {'normalizer__with_mean': True, 'normalizer__with_std': False}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 6})}, 'score': 0.0, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'gini', 'max_depth': 4, 'max_features': None, 'max_leaf_nodes': 2, 'min_samples_split': 5, 'n_estimators': 100}, 'config_hash': {'algorithm': '40ca24df19b8d164d9d098a6bed1ce056fbbb961', 'config': '813bde1108cc3c4b9bfb3a22cbb421bda7eac671', 'pipeline': '74a7b8705a1c22f7dea5e44e4ebda8f1e48add71'}, 'duration': 2.2111589908599854, 'iteration': 8, 'loss': 0.33333333333333326, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_PCA', {'features__n_components': 2}), 'normalizer': ('normalizer_StandardScaler', {'normalizer__with_mean': False, 'normalizer__with_std': True}), 'rebalance': ('rebalance_NearMiss', {'rebalance__n_neighbors': 2})}, 'score': 0.6666666666666667, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'entropy', 'max_depth': 2, 'max_features': 1, 'max_leaf_nodes': 5, 'min_samples_split': 2, 'n_estimators': 100}, 'config_hash': {'algorithm': '331418a5c12cf1453876eef85e9d98fc8e54fa11', 'config': '31930b6860ed406d59bf7e59ba1925d94704bd3b', 'pipeline': '054bef356f90ec6f644ef3ffc688766744db51c2'}, 'duration': 1.0501940250396729, 'iteration': 9, 'loss': 0.053333333333333344, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_SelectKBest', {'features__k': 1}), 'normalizer': ('normalizer_RobustScaler', {'normalizer__quantile_range': (...), 'normalizer__with_centering': True, 'normalizer__with_scaling': True}), 'rebalance': ('rebalance_NearMiss', {'rebalance__n_neighbors': 2})}, 'score': 0.9466666666666667, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'entropy', 'max_depth': 3, 'max_features': None, 'max_leaf_nodes': 3, 'min_samples_split': 2, 'n_estimators': 100}, 'config_hash': {'algorithm': 'dbc1b8126649fe93dce5fbb37e4015b0acfb179e', 'config': '9913cd550615a9d0946ab4a755a8b9f619e442fd', 'pipeline': 'dd626121cea079ebb32e184ca65483ec7a6d7f59'}, 'duration': 1.120617151260376, 'iteration': 10, 'loss': 0.046666666666666634, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 2, 'features__selectkbest__k': 1}), 'normalizer': ('normalizer_MinMaxScaler', {}), 'rebalance': ('rebalance_NoneType', {})}, 'score': 0.9533333333333334, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'gini', 'max_depth': 3, 'max_features': 3, 'max_leaf_nodes': None, 'min_samples_split': 3, 'n_estimators': 75}, 'config_hash': {'algorithm': '34917a130df5a975f78bd7ec1a0c7b1ffdc787a9', 'config': '95fc8cadc088141290b7de9c388977e4685f0108', 'pipeline': '550d10faf2f08db48516cc3501558816d6a99bc0'}, 'duration': 1.4287099838256836, 'iteration': 11, 'loss': 0.19333333333333313, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 3, 'features__selectkbest__k': 4}), 'normalizer': ('normalizer_StandardScaler', {'normalizer__with_mean': False, 'normalizer__with_std': False}), 'rebalance': ('rebalance_CondensedNearestNeighbour', {'rebalance__n_neighbors': 1})}, 'score': 0.8066666666666669, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'entropy', 'max_depth': 1, 'max_features': 2, 'max_leaf_nodes': 5, 'min_samples_split': 2, 'n_estimators': 75}, 'config_hash': {'algorithm': '33f9abb4aee44a395a9f3b3ffa9ce80a8cdaed7c', 'config': '40fa726f0360cf6af55f9b5902d399d02f61f157', 'pipeline': 'cfd1d20841fe2153da762c95e79f95a3fb1e426a'}, 'duration': 1.2978079319000244, 'iteration': 12, 'loss': 0.053333333333333344, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_PCA', {'features__n_components': 4}), 'normalizer': ('normalizer_MinMaxScaler', {}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 7})}, 'score': 0.9466666666666667, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'entropy', 'max_depth': 4, 'max_features': 2, 'max_leaf_nodes': 5, 'min_samples_split': 3, 'n_estimators': 25}, 'config_hash': {'algorithm': '210111ec6562d09eb093e98ed69ef1c662e11a50', 'config': '0fb8e77c7bd9a58b72f1b33c21a59a09a8c676ba', 'pipeline': '5d269d759e0c7926a685a14b263ace8ae0071e4b'}, 'duration': 0.36649012565612793, 'iteration': 13, 'loss': 0.040000000000000036, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 2, 'features__selectkbest__k': 2}), 'normalizer': ('normalizer_NoneType', {}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 7})}, 'score': 0.96, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'entropy', 'max_depth': 3, 'max_features': 1, 'max_leaf_nodes': 5, 'min_samples_split': 2, 'n_estimators': 25}, 'config_hash': {'algorithm': '0e989a03980101fabf79eda3326ed2870e11d690', 'config': 'f4bffd5d8c67a9c5321a9943c4a99678f59a02b7', 'pipeline': '865ee1e3fe8334c3d5ecb2038d5a5d1b3ba50e75'}, 'duration': 0.35639500617980957, 'iteration': 14, 'loss': 0.046666666666666634, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_NoneType', {}), 'normalizer': ('normalizer_RobustScaler', {'normalizer__quantile_range': (...), 'normalizer__with_centering': True, 'normalizer__with_scaling': False}), 'rebalance': ('rebalance_NoneType', {})}, 'score': 0.9533333333333334, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'entropy', 'max_depth': None, 'max_features': 3, 'max_leaf_nodes': 3, 'min_samples_split': 5, 'n_estimators': 10}, 'config_hash': {'algorithm': '9c592e876c13de5e23e6de5b868e01755d63e72e', 'config': '1e6a68cd1eeac886d90724d78b1cb5fb76a3cde4', 'pipeline': '5a1ca4d82f21b7de0d2c918630a42510673fa36e'}, 'duration': 0.18141412734985352, 'iteration': 15, 'loss': 0.046666666666666634, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_SelectKBest', {'features__k': 3}), 'normalizer': ('normalizer_RobustScaler', {'normalizer__quantile_range': (...), 'normalizer__with_centering': True, 'normalizer__with_scaling': True}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 6})}, 'score': 0.9533333333333334, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': 1, 'max_features': None, 'max_leaf_nodes': None, 'min_samples_split': 5, 'n_estimators': 10}, 'config_hash': {'algorithm': '8bed77aef289bfd453b2858bd288ae5ba7160f2b', 'config': '781185bcb8999045de8d489f253a1a1ba4247932', 'pipeline': '1ece7eabedc2be9e5b0a1be65c570d08ffa3eb54'}, 'duration': 0.1636829376220703, 'iteration': 16, 'loss': 0.053333333333333344, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_NoneType', {}), 'normalizer': ('normalizer_NoneType', {}), 'rebalance': ('rebalance_NearMiss', {'rebalance__n_neighbors': 1})}, 'score': 0.9466666666666667, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'gini', 'max_depth': 3, 'max_features': 2, 'max_leaf_nodes': 2, 'min_samples_split': 5, 'n_estimators': 75}, 'config_hash': {'algorithm': '617b97d9ba21d3373bc51ffa9cccf9c6f91a77b3', 'config': '99fb425b4e8c5d80228cab94202252aa25cdf77c', 'pipeline': 'd6242929c3b515c7719e60423023ac604311afc3'}, 'duration': 0.8468999862670898, 'iteration': 17, 'loss': 0.24, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_PCA', {'features__n_components': 4}), 'normalizer': ('normalizer_PowerTransformer', {}), 'rebalance': ('rebalance_NearMiss', {'rebalance__n_neighbors': 2})}, 'score': 0.76, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': 1, 'max_features': 1, 'max_leaf_nodes': 2, 'min_samples_split': 5, 'n_estimators': 50}, 'config_hash': {'algorithm': 'b92d2697cdd4979da443369d6596229ec091626a', 'config': 'c513a3e13281206ad76187dd817b1fff93d54fe1', 'pipeline': 'c4b4f914a3ca8df967cade997a90366d85a371b9'}, 'duration': 0.6724588871002197, 'iteration': 18, 'loss': 0.23333333333333328, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 1, 'features__selectkbest__k': 3}), 'normalizer': ('normalizer_StandardScaler', {'normalizer__with_mean': True, 'normalizer__with_std': True}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 5})}, 'score': 0.7666666666666667, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'entropy', 'max_depth': None, 'max_features': None, 'max_leaf_nodes': 5, 'min_samples_split': 5, 'n_estimators': 10}, 'config_hash': {'algorithm': 'a0115de695e6cca2e81cbfb54df79bf4b43608b1', 'config': 'ba194015e20b5d67770e8c67342c3d8d0d01dc41', 'pipeline': '8d45fabfeb85ffdcabf7076bd0e65fffe97ce928'}, 'duration': 0.19424200057983398, 'iteration': 19, 'loss': 0.08666666666666667, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_PCA', {'features__n_components': 3}), 'normalizer': ('normalizer_NoneType', {}), 'rebalance': ('rebalance_NoneType', {})}, 'score': 0.9133333333333333, ...}, ...], 'history_hash': ['db6ac7e6d348155757e4794bb5f88fe2b4f63d50', '4db6fb84d85f52659f780e682ffac5712c3d8a94', '4403c5a85e951938d3c454e961d3a412780722f6', 'a064e2df18ab98d44dabcefbc7bed94913f1d0be', '0ddb6f5cab3db4dddd7682966a57205f3e329ad4', '49f25751bca61cdd461a8cbd2923689b642f98ed', '5c3a2b6f5e63fb45f10e41e0318b354912ec44f6', 'd3b129b397350f1b6572651c67c01de49b4b174c', '813bde1108cc3c4b9bfb3a22cbb421bda7eac671', '31930b6860ed406d59bf7e59ba1925d94704bd3b', '9913cd550615a9d0946ab4a755a8b9f619e442fd', '95fc8cadc088141290b7de9c388977e4685f0108', '40fa726f0360cf6af55f9b5902d399d02f61f157', '0fb8e77c7bd9a58b72f1b33c21a59a09a8c676ba', 'f4bffd5d8c67a9c5321a9943c4a99678f59a02b7', '1e6a68cd1eeac886d90724d78b1cb5fb76a3cde4', '781185bcb8999045de8d489f253a1a1ba4247932', '99fb425b4e8c5d80228cab94202252aa25cdf77c', 'c513a3e13281206ad76187dd817b1fff93d54fe1', 'ba194015e20b5d67770e8c67342c3d8d0d01dc41', ...], 'history_index': {'00f0493590a2cb5e98a35b29816f8cd9f87f96ec': 208, '013329309d510b94f19d930320402d65f953a847': 39, '038a0f515e2ec894ee8e34f9caa2889eb3ebd5ce': 66, '052ae4bf232b316187b078abae42c2be19e16a00': 111, '05e9258ebf99dd97202167ef1563fa834b0568f1': 242, '0659afebf316aafeb75612fb07081a04c28545ed': 74, '06e7cde9f3556cd01332ce389ad1d8925cd4b4a4': 120, '08606f2a0f0a6c9de204020b4632e09fcee0ae56': 168, '0a05b5b0a70971a5e347aaab7a4d4a07a92222fd': 191, '0b6551ecfd6f83a15704a9db68f1599c99c6d3ef': 58, ...}, 'iteration': 242, 'max_history_score': 0.9666666666666668, 'max_history_score_std': 0.033333333333333326, 'max_history_step': 'joint'}, config={'algorithm': 'RandomForest', 'seed': 42, 'time': 300}, step='joint')
     45                 y,
     46                 cv=10,
     47                 n_jobs=-1,
     48                 return_estimator=False,
     49                 return_train_score=False,
---> 50                 verbose=0)
     51         score = np.mean(scores['test_score'])
     52         std = np.std(scores['test_score'])
     53         status = STATUS_OK
     54     except Exception as e:

...........................................................................
/home/aquemy/.local/lib/python2.7/site-packages/sklearn/model_selection/_validation.py in cross_validate(estimator=Pipeline(memory=None,
     steps=[('rebalance', ...e=42,
            verbose=0, warm_start=False))]), X=array([[5.1, 3.5, 1.4, 0.2],
       [4.9, 3. , 1....2, 3.4, 5.4, 2.3],
       [5.9, 3. , 5.1, 1.8]]), y=array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,... 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]), groups=None, scoring=None, cv=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1, verbose=0, fit_params=None, pre_dispatch='2*n_jobs', return_train_score=False, return_estimator=False, error_score='raise-deprecating')
    235         delayed(_fit_and_score)(
    236             clone(estimator), X, y, scorers, train, test, verbose, None,
    237             fit_params, return_train_score=return_train_score,
    238             return_times=True, return_estimator=return_estimator,
    239             error_score=error_score)
--> 240         for train, test in cv.split(X, y, groups))
        cv.split = <bound method StratifiedKFold.split of Stratifie...d(n_splits=10, random_state=None, shuffle=False)>
        X = array([[5.1, 3.5, 1.4, 0.2],
       [4.9, 3. , 1....2, 3.4, 5.4, 2.3],
       [5.9, 3. , 5.1, 1.8]])
        y = array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,... 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2])
        groups = None
    241 
    242     zipped_scores = list(zip(*scores))
    243     if return_train_score:
    244         train_scores = zipped_scores.pop(0)

...........................................................................
/home/aquemy/.local/lib/python2.7/site-packages/sklearn/externals/joblib/parallel.py in __call__(self=Parallel(n_jobs=-1), iterable=<generator object <genexpr>>)
    925                 # No need to wait for async callbacks to trigger to
    926                 # consumption.
    927                 self._iterating = False
    928 
    929             with self._backend.retrieval_context():
--> 930                 self.retrieve()
        self.retrieve = <bound method Parallel.retrieve of Parallel(n_jobs=-1)>
    931             # Make sure that we get a last message telling us we are done
    932             elapsed_time = time.time() - self._start_time
    933             self._print('Done %3i out of %3i | elapsed: %s finished',
    934                         (len(self._output), len(self._output),

---------------------------------------------------------------------------
Joblib worker traceback:
---------------------------------------------------------------------------
ValueError                                         Mon Jun 17 13:13:53 2019
PID: 21510                                  Python 2.7.15+: /usr/bin/python
...........................................................................
/home/aquemy/.local/lib/python2.7/site-packages/sklearn/externals/joblib/parallel.py in __call__(self=<sklearn.externals.joblib.parallel.BatchedCalls object>)
    220     def __call__(self):
    221         # Set the default nested backend to self._backend but do not set the
    222         # change the default number of processes to -1
    223         with parallel_backend(self._backend, n_jobs=self._n_jobs):
    224             return [func(*args, **kwargs)
--> 225                     for func, args, kwargs in self.items]
        func = <function _fit_and_score>
        args = (Pipeline(memory=None,
     steps=[('rebalance', ...e=42,
            verbose=0, warm_start=False))]), array([[5.1, 3.5, 1.4, 0.2],
       [4.9, 3. , 1....2, 3.4, 5.4, 2.3],
       [5.9, 3. , 5.1, 1.8]]), array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,... 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]), {'score': <function _passthrough_scorer>}, array([  5,   6,   7,   8,   9,  10,  11,  12,  ..., 142, 143, 144,
       145, 146, 147, 148, 149]), array([  0,   1,   2,   3,   4,  50,  51,  52,  53,  54, 100, 101, 102,
       103, 104]), 0, None, None)
        kwargs = {'error_score': 'raise-deprecating', 'return_estimator': False, 'return_times': True, 'return_train_score': False}
        self.items = [(<function _fit_and_score>, (Pipeline(memory=None,
     steps=[('rebalance', ...e=42,
            verbose=0, warm_start=False))]), array([[5.1, 3.5, 1.4, 0.2],
       [4.9, 3. , 1....2, 3.4, 5.4, 2.3],
       [5.9, 3. , 5.1, 1.8]]), array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,... 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]), {'score': <function _passthrough_scorer>}, array([  5,   6,   7,   8,   9,  10,  11,  12,  ..., 142, 143, 144,
       145, 146, 147, 148, 149]), array([  0,   1,   2,   3,   4,  50,  51,  52,  53,  54, 100, 101, 102,
       103, 104]), 0, None, None), {'error_score': 'raise-deprecating', 'return_estimator': False, 'return_times': True, 'return_train_score': False})]
    226 
    227     def __len__(self):
    228         return self._size
    229 

...........................................................................
/home/aquemy/.local/lib/python2.7/site-packages/sklearn/model_selection/_validation.py in _fit_and_score(estimator=Pipeline(memory=None,
     steps=[('rebalance', ...e=42,
            verbose=0, warm_start=False))]), X=array([[5.1, 3.5, 1.4, 0.2],
       [4.9, 3. , 1....2, 3.4, 5.4, 2.3],
       [5.9, 3. , 5.1, 1.8]]), y=array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,... 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]), scorer={'score': <function _passthrough_scorer>}, train=array([  5,   6,   7,   8,   9,  10,  11,  12,  ..., 142, 143, 144,
       145, 146, 147, 148, 149]), test=array([  0,   1,   2,   3,   4,  50,  51,  52,  53,  54, 100, 101, 102,
       103, 104]), verbose=0, parameters=None, fit_params={}, return_train_score=False, return_parameters=False, return_n_test_samples=False, return_times=True, return_estimator=False, error_score='raise-deprecating')
    523 
    524     try:
    525         if y_train is None:
    526             estimator.fit(X_train, **fit_params)
    527         else:
--> 528             estimator.fit(X_train, y_train, **fit_params)
        estimator.fit = <bound method Pipeline.fit of Pipeline(memory=No...=42,
            verbose=0, warm_start=False))])>
        X_train = array([[5.4, 3.9, 1.7, 0.4],
       [4.6, 3.4, 1....2, 3.4, 5.4, 2.3],
       [5.9, 3. , 5.1, 1.8]])
        y_train = array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,
       2, 2, 2])
        fit_params = {}
    529 
    530     except Exception as e:
    531         # Note fit time as time until error
    532         fit_time = time.time() - start_time

...........................................................................
/usr/local/lib/python2.7/dist-packages/imblearn/pipeline.py in fit(self=Pipeline(memory=None,
     steps=[('rebalance', ...e=42,
            verbose=0, warm_start=False))]), X=array([[5.4, 3.9, 1.7, 0.4],
       [4.6, 3.4, 1....2, 3.4, 5.4, 2.3],
       [5.9, 3. , 5.1, 1.8]]), y=array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,
       2, 2, 2]), **fit_params={})
    234             This estimator
    235 
    236         """
    237         Xt, yt, fit_params = self._fit(X, y, **fit_params)
    238         if self._final_estimator is not None:
--> 239             self._final_estimator.fit(Xt, yt, **fit_params)
        self._final_estimator.fit = <bound method RandomForestClassifier.fit of Rand...ate=42,
            verbose=0, warm_start=False)>
        Xt = array([[ 9.90728206e-01, -1.25197913e+00],
     ...-02],
       [ 2.49893965e+00,  2.44410990e+00]])
        yt = array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...0, 0, 0, 0, 0, 0, 0,
       0, 1, 1, 1, 2, 2, 2])
        fit_params = {}
    240         return self
    241 
    242     def fit_transform(self, X, y=None, **fit_params):
    243         """Fit the model and transform with the final estimator

...........................................................................
/home/aquemy/.local/lib/python2.7/site-packages/sklearn/ensemble/forest.py in fit(self=RandomForestClassifier(bootstrap=False, class_we...tate=42,
            verbose=0, warm_start=False), X=array([[ 9.9072820e-01, -1.2519791e+00],
       ...[ 2.4989398e+00,  2.4441099e+00]], dtype=float32), y=array([[0.],
       [0.],
       [0.],
       [0...    [1.],
       [2.],
       [2.],
       [2.]]), sample_weight=None)
    328             trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,
    329                              **_joblib_parallel_args(prefer='threads'))(
    330                 delayed(_parallel_build_trees)(
    331                     t, self, X, y, sample_weight, i, len(trees),
    332                     verbose=self.verbose, class_weight=self.class_weight)
--> 333                 for i, t in enumerate(trees))
        i = 9
    334 
    335             # Collect newly grown trees
    336             self.estimators_.extend(trees)
    337 

...........................................................................
/home/aquemy/.local/lib/python2.7/site-packages/sklearn/externals/joblib/parallel.py in __call__(self=Parallel(n_jobs=1), iterable=<generator object <genexpr>>)
    912             # self._original_iterator is None, then this means either
    913             # that pre_dispatch == "all", n_jobs == 1 or that the first batch
    914             # was very quick and its callback already dispatched all the
    915             # remaining jobs.
    916             self._iterating = False
--> 917             if self.dispatch_one_batch(iterator):
        self.dispatch_one_batch = <bound method Parallel.dispatch_one_batch of Parallel(n_jobs=1)>
        iterator = <generator object <genexpr>>
    918                 self._iterating = self._original_iterator is not None
    919 
    920             while self.dispatch_one_batch(iterator):
    921                 pass

...........................................................................
/home/aquemy/.local/lib/python2.7/site-packages/sklearn/externals/joblib/parallel.py in dispatch_one_batch(self=Parallel(n_jobs=1), iterator=<generator object <genexpr>>)
    754                                  self._pickle_cache)
    755             if len(tasks) == 0:
    756                 # No more tasks available in the iterator: tell caller to stop.
    757                 return False
    758             else:
--> 759                 self._dispatch(tasks)
        self._dispatch = <bound method Parallel._dispatch of Parallel(n_jobs=1)>
        tasks = <sklearn.externals.joblib.parallel.BatchedCalls object>
    760                 return True
    761 
    762     def _print(self, msg, msg_args):
    763         """Display the message on stout or stderr depending on verbosity"""

...........................................................................
/home/aquemy/.local/lib/python2.7/site-packages/sklearn/externals/joblib/parallel.py in _dispatch(self=Parallel(n_jobs=1), batch=<sklearn.externals.joblib.parallel.BatchedCalls object>)
    711 
    712         dispatch_timestamp = time.time()
    713         cb = BatchCompletionCallBack(dispatch_timestamp, len(batch), self)
    714         with self._lock:
    715             job_idx = len(self._jobs)
--> 716             job = self._backend.apply_async(batch, callback=cb)
        job = undefined
        self._backend.apply_async = <bound method SequentialBackend.apply_async of <...lib._parallel_backends.SequentialBackend object>>
        batch = <sklearn.externals.joblib.parallel.BatchedCalls object>
        cb = <sklearn.externals.joblib.parallel.BatchCompletionCallBack object>
    717             # A job can complete so quickly than its callback is
    718             # called before we get here, causing self._jobs to
    719             # grow. To ensure correct results ordering, .insert is
    720             # used (rather than .append) in the following line

...........................................................................
/home/aquemy/.local/lib/python2.7/site-packages/sklearn/externals/joblib/_parallel_backends.py in apply_async(self=<sklearn.externals.joblib._parallel_backends.SequentialBackend object>, func=<sklearn.externals.joblib.parallel.BatchedCalls object>, callback=<sklearn.externals.joblib.parallel.BatchCompletionCallBack object>)
    177             raise ValueError('n_jobs == 0 in Parallel has no meaning')
    178         return 1
    179 
    180     def apply_async(self, func, callback=None):
    181         """Schedule a func to be run"""
--> 182         result = ImmediateResult(func)
        result = undefined
        func = <sklearn.externals.joblib.parallel.BatchedCalls object>
    183         if callback:
    184             callback(result)
    185         return result
    186 

...........................................................................
/home/aquemy/.local/lib/python2.7/site-packages/sklearn/externals/joblib/_parallel_backends.py in __init__(self=<sklearn.externals.joblib._parallel_backends.ImmediateResult object>, batch=<sklearn.externals.joblib.parallel.BatchedCalls object>)
    544 
    545 class ImmediateResult(object):
    546     def __init__(self, batch):
    547         # Don't delay the application, to avoid keeping the input
    548         # arguments in memory
--> 549         self.results = batch()
        self.results = undefined
        batch = <sklearn.externals.joblib.parallel.BatchedCalls object>
    550 
    551     def get(self):
    552         return self.results
    553 

...........................................................................
/home/aquemy/.local/lib/python2.7/site-packages/sklearn/externals/joblib/parallel.py in __call__(self=<sklearn.externals.joblib.parallel.BatchedCalls object>)
    220     def __call__(self):
    221         # Set the default nested backend to self._backend but do not set the
    222         # change the default number of processes to -1
    223         with parallel_backend(self._backend, n_jobs=self._n_jobs):
    224             return [func(*args, **kwargs)
--> 225                     for func, args, kwargs in self.items]
        func = <function _parallel_build_trees>
        args = (DecisionTreeClassifier(class_weight=None, criter...=False, random_state=1608637542, splitter='best'), RandomForestClassifier(bootstrap=False, class_we...tate=42,
            verbose=0, warm_start=False), array([[ 9.9072820e-01, -1.2519791e+00],
       ...[ 2.4989398e+00,  2.4441099e+00]], dtype=float32), array([[0.],
       [0.],
       [0.],
       [0...    [1.],
       [2.],
       [2.],
       [2.]]), None, 0, 10)
        kwargs = {'class_weight': None, 'verbose': 0}
        self.items = [(<function _parallel_build_trees>, (DecisionTreeClassifier(class_weight=None, criter...=False, random_state=1608637542, splitter='best'), RandomForestClassifier(bootstrap=False, class_we...tate=42,
            verbose=0, warm_start=False), array([[ 9.9072820e-01, -1.2519791e+00],
       ...[ 2.4989398e+00,  2.4441099e+00]], dtype=float32), array([[0.],
       [0.],
       [0.],
       [0...    [1.],
       [2.],
       [2.],
       [2.]]), None, 0, 10), {'class_weight': None, 'verbose': 0})]
    226 
    227     def __len__(self):
    228         return self._size
    229 

...........................................................................
/home/aquemy/.local/lib/python2.7/site-packages/sklearn/ensemble/forest.py in _parallel_build_trees(tree=DecisionTreeClassifier(class_weight=None, criter...=False, random_state=1608637542, splitter='best'), forest=RandomForestClassifier(bootstrap=False, class_we...tate=42,
            verbose=0, warm_start=False), X=array([[ 9.9072820e-01, -1.2519791e+00],
       ...[ 2.4989398e+00,  2.4441099e+00]], dtype=float32), y=array([[0.],
       [0.],
       [0.],
       [0...    [1.],
       [2.],
       [2.],
       [2.]]), sample_weight=None, tree_idx=0, n_trees=10, verbose=0, class_weight=None)
    116         elif class_weight == 'balanced_subsample':
    117             curr_sample_weight *= compute_sample_weight('balanced', y, indices)
    118 
    119         tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)
    120     else:
--> 121         tree.fit(X, y, sample_weight=sample_weight, check_input=False)
        tree.fit = <bound method DecisionTreeClassifier.fit of Deci...False, random_state=1608637542, splitter='best')>
        X = array([[ 9.9072820e-01, -1.2519791e+00],
       ...[ 2.4989398e+00,  2.4441099e+00]], dtype=float32)
        y = array([[0.],
       [0.],
       [0.],
       [0...    [1.],
       [2.],
       [2.],
       [2.]])
        sample_weight = None
    122 
    123     return tree
    124 
    125 

...........................................................................
/home/aquemy/.local/lib/python2.7/site-packages/sklearn/tree/tree.py in fit(self=DecisionTreeClassifier(class_weight=None, criter...=False, random_state=1608637542, splitter='best'), X=array([[ 9.9072820e-01, -1.2519791e+00],
       ...[ 2.4989398e+00,  2.4441099e+00]], dtype=float32), y=array([[0.],
       [0.],
       [0.],
       [0...    [1.],
       [2.],
       [2.],
       [2.]]), sample_weight=None, check_input=False, X_idx_sorted=None)
    796 
    797         super(DecisionTreeClassifier, self).fit(
    798             X, y,
    799             sample_weight=sample_weight,
    800             check_input=check_input,
--> 801             X_idx_sorted=X_idx_sorted)
        X_idx_sorted = None
    802         return self
    803 
    804     def predict_proba(self, X, check_input=True):
    805         """Predict class probabilities of the input samples X.

...........................................................................
/home/aquemy/.local/lib/python2.7/site-packages/sklearn/tree/tree.py in fit(self=DecisionTreeClassifier(class_weight=None, criter...=False, random_state=1608637542, splitter='best'), X=array([[ 9.9072820e-01, -1.2519791e+00],
       ...[ 2.4989398e+00,  2.4441099e+00]], dtype=float32), y=array([[0.],
       [0.],
       [0.],
       [0...    [1.],
       [2.],
       [2.],
       [2.]]), sample_weight=None, check_input=False, X_idx_sorted=None)
    237         if not 0 <= self.min_weight_fraction_leaf <= 0.5:
    238             raise ValueError("min_weight_fraction_leaf must in [0, 0.5]")
    239         if max_depth <= 0:
    240             raise ValueError("max_depth must be greater than zero. ")
    241         if not (0 < max_features <= self.n_features_):
--> 242             raise ValueError("max_features must be in (0, n_features]")
    243         if not isinstance(max_leaf_nodes, (numbers.Integral, np.integer)):
    244             raise ValueError("max_leaf_nodes must be integral number but was "
    245                              "%r" % max_leaf_nodes)
    246         if -1 < max_leaf_nodes < 2:

ValueError: max_features must be in (0, n_features]
___________________________________________________________________________
Best score: 0.966666666667 (0.0333333333333) [J] | Score: 0.0 (0.0) [J]
Best score: 0.966666666667 (0.0333333333333) [J] | Score: 0.913333333333 (0.0733333333333) [J]
Best score: 0.966666666667 (0.0333333333333) [J] | Score: 0.96 (0.0442216638714) [J]
Best score: 0.966666666667 (0.0333333333333) [J] | Score: 0.913333333333 (0.06) [J]
Best score: 0.966666666667 (0.0333333333333) [J] | Score: 0.926666666667 (0.0553774924195) [J]
Best score: 0.966666666667 (0.0333333333333) [J] | Score: 0.72 (0.0832666399786) [J]
Best score: 0.966666666667 (0.0333333333333) [J] | Score: 0.966666666667 (0.04472135955) [J]
Best score: 0.966666666667 (0.0333333333333) [J] | Score: 0.92 (0.0653197264742) [J]
Best score: 0.966666666667 (0.0333333333333) [J] | Score: 0.953333333333 (0.06) [J]
Best score: 0.966666666667 (0.0333333333333) [J] | Score: 0.893333333333 (0.0742368581711) [J]
Best score: 0.966666666667 (0.0333333333333) [J] | Score: 0.966666666667 (0.04472135955) [J]
Best score: 0.966666666667 (0.0333333333333) [J] | Score: 0.72 (0.0933333333333) [J]
Best score: 0.966666666667 (0.0333333333333) [J] | Score: 0.953333333333 (0.0426874949162) [J]
Best score: 0.966666666667 (0.0333333333333) [J] | Score: 0.86 (0.0813770374382) [J]
Best score: 0.966666666667 (0.0333333333333) [J] | Score: 0.946666666667 (0.0653197264742) [J]
Best score: 0.966666666667 (0.0333333333333) [J] | Score: 0.953333333333 (0.06) [J]
Best score: 0.966666666667 (0.0333333333333) [J] | Score: 0.953333333333 (0.0426874949162) [J]
Best score: 0.966666666667 (0.0333333333333) [J] | Score: 0.953333333333 (0.0426874949162) [J]
Best score: 0.966666666667 (0.0333333333333) [J] | Score: 0.94 (0.062893207547) [J]
Best score: 0.966666666667 (0.0333333333333) [J] | Score: 0.753333333333 (0.111753697428) [J]
Best score: 0.966666666667 (0.0333333333333) [J] | Score: 0.92 (0.0884433277428) [J]
JoblibValueError
___________________________________________________________________________
...........................................................................
/home/aquemy/dev/dp_hyperparameters/extension/main.py in <module>()
     27 
     28     serializer.serialize_results(scenario, policy)
     29 
     30 if __name__ == "__main__":
     31     args = cli.parse_args()
---> 32     main(args)

...........................................................................
/home/aquemy/dev/dp_hyperparameters/extension/main.py in main(args=Namespace(customize=[(['control', 'seed'], '42')...io='./scenarios/rf_iris_joint.yaml', verbosity=0))
     21         test_size=0.4, 
     22         random_state=scenario['control']['seed']
     23     )
     24 
     25     policy = policies.initiate(scenario['setup']['policy'], config)
---> 26     policy.run(X,y)
        policy.run = <bound method Joint.run of <experiment.policies.joint.Joint object>>
        X = array([[5.1, 3.5, 1.4, 0.2],
       [4.9, 3. , 1....2, 3.4, 5.4, 2.3],
       [5.9, 3. , 5.1, 1.8]])
        y = array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,... 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2])
     27 
     28     serializer.serialize_results(scenario, policy)
     29 
     30 if __name__ == "__main__":

...........................................................................
/home/aquemy/dev/dp_hyperparameters/extension/experiment/policies/joint.py in run(self=<experiment.policies.joint.Joint object>, X=array([[5.1, 3.5, 1.4, 0.2],
       [4.9, 3. , 1....2, 3.4, 5.4, 2.3],
       [5.9, 3. , 5.1, 1.8]]), y=array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,... 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]))
     32             algo=tpe.suggest, 
     33             max_evals=None,
     34             max_time=self.config['time'],     
     35             trials=trials,
     36             show_progressbar=False,
---> 37             verbose=0
     38         )
     39 
     40         best_config = self.context['best_config']
     41         super(Joint, self).display_step_results(best_config)

...........................................................................
/home/aquemy/dev/dp_hyperparameters/extension/hyperopt/fmin.py in fmin(fn=<functools.partial object>, space={'algorithm': {'bootstrap': <hyperopt.pyll.base.Apply object>, 'criterion': <hyperopt.pyll.base.Apply object>, 'max_depth': <hyperopt.pyll.base.Apply object>, 'max_features': <hyperopt.pyll.base.Apply object>, 'max_leaf_nodes': <hyperopt.pyll.base.Apply object>, 'min_samples_split': <hyperopt.pyll.base.Apply object>, 'n_estimators': <hyperopt.pyll.base.Apply object>}, 'pipeline': {'features': <hyperopt.pyll.base.Apply object>, 'normalizer': <hyperopt.pyll.base.Apply object>, 'rebalance': <hyperopt.pyll.base.Apply object>}}, algo=<function suggest>, max_evals=9223372036854775807, max_time=300, trials=<hyperopt.base.Trials object>, rstate=<mtrand.RandomState object>, allow_trials_fmin=True, pass_expr_memo_ctrl=None, catch_eval_exceptions=False, verbose=0, return_argmin=True, points_to_evaluate=None, max_queue_len=1, show_progressbar=False)
    406             pass_expr_memo_ctrl=pass_expr_memo_ctrl,
    407             verbose=verbose,
    408             catch_eval_exceptions=catch_eval_exceptions,
    409             return_argmin=return_argmin,
    410             show_progressbar=show_progressbar,
--> 411             max_time=max_time
        max_time = 300
    412         )
    413 
    414     if trials is None:
    415         if points_to_evaluate is None:

...........................................................................
/home/aquemy/dev/dp_hyperparameters/extension/hyperopt/base.py in fmin(self=<hyperopt.base.Trials object>, fn=<functools.partial object>, space={'algorithm': {'bootstrap': <hyperopt.pyll.base.Apply object>, 'criterion': <hyperopt.pyll.base.Apply object>, 'max_depth': <hyperopt.pyll.base.Apply object>, 'max_features': <hyperopt.pyll.base.Apply object>, 'max_leaf_nodes': <hyperopt.pyll.base.Apply object>, 'min_samples_split': <hyperopt.pyll.base.Apply object>, 'n_estimators': <hyperopt.pyll.base.Apply object>}, 'pipeline': {'features': <hyperopt.pyll.base.Apply object>, 'normalizer': <hyperopt.pyll.base.Apply object>, 'rebalance': <hyperopt.pyll.base.Apply object>}}, algo=<function suggest>, max_evals=9223372036854775807, max_time=300, rstate=<mtrand.RandomState object>, verbose=0, pass_expr_memo_ctrl=None, catch_eval_exceptions=False, return_argmin=True, show_progressbar=False)
    636             verbose=verbose,
    637             allow_trials_fmin=False,  # -- prevent recursion
    638             pass_expr_memo_ctrl=pass_expr_memo_ctrl,
    639             catch_eval_exceptions=catch_eval_exceptions,
    640             return_argmin=return_argmin,
--> 641             show_progressbar=show_progressbar)
        show_progressbar = False
    642 
    643 
    644 def trials_from_docs(docs, validate=True, **kwargs):
    645     """Construct a Trials base class instance from a list of trials documents

...........................................................................
/home/aquemy/dev/dp_hyperparameters/extension/hyperopt/fmin.py in fmin(fn=<functools.partial object>, space={'algorithm': {'bootstrap': <hyperopt.pyll.base.Apply object>, 'criterion': <hyperopt.pyll.base.Apply object>, 'max_depth': <hyperopt.pyll.base.Apply object>, 'max_features': <hyperopt.pyll.base.Apply object>, 'max_leaf_nodes': <hyperopt.pyll.base.Apply object>, 'min_samples_split': <hyperopt.pyll.base.Apply object>, 'n_estimators': <hyperopt.pyll.base.Apply object>}, 'pipeline': {'features': <hyperopt.pyll.base.Apply object>, 'normalizer': <hyperopt.pyll.base.Apply object>, 'rebalance': <hyperopt.pyll.base.Apply object>}}, algo=<function suggest>, max_evals=9223372036854775807, max_time=300, trials=<hyperopt.base.Trials object>, rstate=<mtrand.RandomState object>, allow_trials_fmin=False, pass_expr_memo_ctrl=None, catch_eval_exceptions=False, verbose=0, return_argmin=True, points_to_evaluate=None, max_queue_len=1, show_progressbar=False)
    426                     verbose=verbose,
    427                     max_queue_len=max_queue_len,
    428                     show_progressbar=show_progressbar,
    429                     max_time=max_time)
    430     rval.catch_eval_exceptions = catch_eval_exceptions
--> 431     rval.exhaust()
        rval.exhaust = <bound method FMinIter.exhaust of <hyperopt.fmin.FMinIter object>>
    432     if return_argmin:
    433         return trials.argmin
    434     elif len(trials) > 0:
    435         # Only if there are some succesfull trail runs, return the best point in the evaluation space

...........................................................................
/home/aquemy/dev/dp_hyperparameters/extension/hyperopt/fmin.py in exhaust(self=<hyperopt.fmin.FMinIter object>)
    273             raise StopIteration()
    274         return self.trials
    275 
    276     def exhaust(self):
    277         n_done = len(self.trials)
--> 278         self.run(self.max_evals - n_done, block_until_done=self.asynchronous)
        self.run = <bound method FMinIter.run of <hyperopt.fmin.FMinIter object>>
        self.max_evals = 9223372036854775807
        n_done = 0
        self.asynchronous = False
    279         self.trials.refresh()
    280         return self
    281 
    282 

...........................................................................
/home/aquemy/dev/dp_hyperparameters/extension/hyperopt/fmin.py in run(self=<hyperopt.fmin.FMinIter object>, N=9223372036854775807, block_until_done=False)
    232                     if self.asynchronous:
    233                         # -- wait for workers to fill in the trials
    234                         time.sleep(self.poll_interval_secs)
    235                     else:
    236                         # -- loop over trials and do the jobs directly
--> 237                         self.serial_evaluate()
        self.serial_evaluate = <bound method FMinIter.serial_evaluate of <hyperopt.fmin.FMinIter object>>
    238                     try:
    239                         res = [d['result']['loss'] for d in
    240                                          self.trials.trials if
    241                                          d['result']['status'] == 'ok']

...........................................................................
/home/aquemy/dev/dp_hyperparameters/extension/hyperopt/fmin.py in serial_evaluate(self=<hyperopt.fmin.FMinIter object>, N=-1)
    138                 trial['book_time'] = now
    139                 trial['refresh_time'] = now
    140                 spec = base.spec_from_misc(trial['misc'])
    141                 ctrl = base.Ctrl(self.trials, current_trial=trial)
    142                 try:
--> 143                     result = self.domain.evaluate(spec, ctrl)
        result = undefined
        self.domain.evaluate = <bound method Domain.evaluate of <hyperopt.base.Domain object>>
        spec = {'bootstrap': 1, 'criterion': 0, 'features': 1, 'features_PCA_features__n_components': 0, 'max_depth': 3, 'max_features': 2, 'max_leaf_nodes': 1, 'min_samples_split': 1, 'n_estimators': 0, 'normalizer': 2, ...}
        ctrl = <hyperopt.base.Ctrl object>
    144                 except Exception as e:
    145                     logger.info('job exception: %s' % str(e))
    146                     trial['state'] = base.JOB_STATE_ERROR
    147                     trial['misc']['error'] = (str(type(e)), str(e))

...........................................................................
/home/aquemy/dev/dp_hyperparameters/extension/hyperopt/base.py in evaluate(self=<hyperopt.base.Domain object>, config={'bootstrap': 1, 'criterion': 0, 'features': 1, 'features_PCA_features__n_components': 0, 'max_depth': 3, 'max_features': 2, 'max_leaf_nodes': 1, 'min_samples_split': 1, 'n_estimators': 0, 'normalizer': 2, ...}, ctrl=<hyperopt.base.Ctrl object>, attach_attachments=True)
    841             #    or the normal Python part (self.fn)
    842             pyll_rval = pyll.rec_eval(
    843                 self.expr,
    844                 memo=memo,
    845                 print_node_on_error=self.rec_eval_print_node_on_error)
--> 846             rval = self.fn(pyll_rval)
        rval = undefined
        self.fn = <functools.partial object>
        pyll_rval = {'algorithm': {'bootstrap': False, 'criterion': 'gini', 'max_depth': 4, 'max_features': 3, 'max_leaf_nodes': 3, 'min_samples_split': 3, 'n_estimators': 10}, 'pipeline': {'features': ('features_PCA', {'features__n_components': 1}), 'normalizer': ('normalizer_PowerTransformer', {}), 'rebalance': ('rebalance_CondensedNearestNeighbour', {'rebalance__n_neighbors': 2})}}
    847 
    848         if isinstance(rval, (float, int, np.number)):
    849             dict_rval = {'loss': float(rval), 'status': STATUS_OK}
    850         else:

...........................................................................
/home/aquemy/dev/dp_hyperparameters/extension/experiment/objective.py in objective_joint(wconfig={'algorithm': {'bootstrap': False, 'criterion': 'gini', 'max_depth': 4, 'max_features': 3, 'max_leaf_nodes': 3, 'min_samples_split': 3, 'n_estimators': 10}, 'pipeline': {'features': ('features_PCA', {'features__n_components': 1}), 'normalizer': ('normalizer_PowerTransformer', {}), 'rebalance': ('rebalance_CondensedNearestNeighbour', {'rebalance__n_neighbors': 2})}}, algorithm='RandomForest', X=array([[5.1, 3.5, 1.4, 0.2],
       [4.9, 3. , 1....2, 3.4, 5.4, 2.3],
       [5.9, 3. , 5.1, 1.8]]), y=array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,... 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]), context={'baseline_score': 0.9466666666666667, 'baseline_score_std': 0.04988876515698587, 'best_config': {'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': 4, 'max_features': 3, 'max_leaf_nodes': 3, 'min_samples_split': 3, 'n_estimators': 10}, 'config_hash': {'algorithm': 'ffb7ff225ce3d3712c96cf87fe42202988ee2eb0', 'config': 'bae32f426be9cd6243523c023944a8c148fe4aeb', 'pipeline': 'd2a68bfda6fcdec4ae0ffc7d7b6a2122bc1cd673'}, 'duration': 0.7115809917449951, 'iteration': 113, 'loss': 0.033333333333333215, 'max_history_score': 0.9666666666666668, 'max_history_score_std': 0.033333333333333326, 'max_history_step': 'joint', 'pipeline': {'features': ('features_NoneType', {}), 'normalizer': ('normalizer_PowerTransformer', {}), 'rebalance': ('rebalance_CondensedNearestNeighbour', {'rebalance__n_neighbors': 2})}, 'score': 0.9666666666666668, ...}, 'history': [{'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': 2, 'max_features': None, 'max_leaf_nodes': 5, 'min_samples_split': 2, 'n_estimators': 75}, 'config_hash': {'algorithm': '3af5b0cce71c8fe2545246ca24ff5bc3dd516e06', 'config': 'db6ac7e6d348155757e4794bb5f88fe2b4f63d50', 'pipeline': '8d59f4b94cef6be9306ed86a22a9570fa670d567'}, 'duration': 1.149928092956543, 'iteration': 0, 'loss': 0.046666666666666634, 'max_history_score': 0.9533333333333334, 'max_history_score_std': 0.059999999999999984, 'max_history_step': 'joint', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 4, 'features__selectkbest__k': 3}), 'normalizer': ('normalizer_StandardScaler', {'normalizer__with_mean': True, 'normalizer__with_std': True}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 6})}, 'score': 0.9533333333333334, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': 1, 'max_features': 2, 'max_leaf_nodes': 2, 'min_samples_split': 5, 'n_estimators': 100}, 'config_hash': {'algorithm': 'e13eb05fd9a62d2f63bbb1c1deff0cd620d5e6ab', 'config': '4db6fb84d85f52659f780e682ffac5712c3d8a94', 'pipeline': '64c9a1ca9d53ae67244bdd942f4db36a3c05218c'}, 'duration': 1.7678282260894775, 'iteration': 1, 'loss': 0.18000000000000005, 'max_history_score': 0.9533333333333334, 'max_history_score_std': 0.059999999999999984, 'max_history_step': 'joint', 'pipeline': {'features': ('features_NoneType', {}), 'normalizer': ('normalizer_PowerTransformer', {}), 'rebalance': ('rebalance_NearMiss', {'rebalance__n_neighbors': 1})}, 'score': 0.82, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': 1, 'max_features': None, 'max_leaf_nodes': None, 'min_samples_split': 5, 'n_estimators': 75}, 'config_hash': {'algorithm': '94b0d7a654c508cc63643f78fe4f0f07e6f07c1e', 'config': '4403c5a85e951938d3c454e961d3a412780722f6', 'pipeline': '3e47444880d8367fbac2faaba2e52a917274aa58'}, 'duration': 0.8397619724273682, 'iteration': 2, 'loss': 0.03333333333333344, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_PCA', {'features__n_components': 3}), 'normalizer': ('normalizer_MinMaxScaler', {}), 'rebalance': ('rebalance_NoneType', {})}, 'score': 0.9666666666666666, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': None, 'max_features': None, 'max_leaf_nodes': 3, 'min_samples_split': 3, 'n_estimators': 75}, 'config_hash': {'algorithm': 'e8332f0a8902bda03bf70e7978cc5d52affb29d3', 'config': 'a064e2df18ab98d44dabcefbc7bed94913f1d0be', 'pipeline': '7eea819c2a8c103c4b1e9e9c1e224aebba95081f'}, 'duration': 0.8501448631286621, 'iteration': 3, 'loss': 0.053333333333333344, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 2, 'features__selectkbest__k': 4}), 'normalizer': ('normalizer_NoneType', {}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 7})}, 'score': 0.9466666666666667, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'entropy', 'max_depth': 3, 'max_features': 3, 'max_leaf_nodes': None, 'min_samples_split': 5, 'n_estimators': 75}, 'config_hash': {'algorithm': '7a4491035bc6bd737fe9a8cda8a79a02d02d5c74', 'config': '0ddb6f5cab3db4dddd7682966a57205f3e329ad4', 'pipeline': 'a9ae03fe38334f6868cbf84cdd3d629d4bbe3fb0'}, 'duration': 1.1026010513305664, 'iteration': 4, 'loss': 0.05999999999999994, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 2, 'features__selectkbest__k': 1}), 'normalizer': ('normalizer_NoneType', {}), 'rebalance': ('rebalance_NoneType', {})}, 'score': 0.9400000000000001, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'gini', 'max_depth': 3, 'max_features': 1, 'max_leaf_nodes': 5, 'min_samples_split': 2, 'n_estimators': 25}, 'config_hash': {'algorithm': '9826d20b2d6a0f559cf7f16450ce7526f07e8434', 'config': '49f25751bca61cdd461a8cbd2923689b642f98ed', 'pipeline': '19b249664c5bf067de1fed4334a296f947ce774a'}, 'duration': 0.35647010803222656, 'iteration': 5, 'loss': 0.046666666666666634, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_NoneType', {}), 'normalizer': ('normalizer_NoneType', {}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 6})}, 'score': 0.9533333333333334, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'gini', 'max_depth': 2, 'max_features': 1, 'max_leaf_nodes': 2, 'min_samples_split': 2, 'n_estimators': 50}, 'config_hash': {'algorithm': '0a4f6fbb07e0f32c6f675489a0fc82eee05bd8e1', 'config': '5c3a2b6f5e63fb45f10e41e0318b354912ec44f6', 'pipeline': 'dc3b9f176f090005e38b142f11d80e93a7dc5d5e'}, 'duration': 0.7213859558105469, 'iteration': 6, 'loss': 0.31333333333333324, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 1, 'features__selectkbest__k': 4}), 'normalizer': ('normalizer_PowerTransformer', {}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 7})}, 'score': 0.6866666666666668, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'entropy', 'max_depth': 4, 'max_features': 3, 'max_leaf_nodes': 5, 'min_samples_split': 5, 'n_estimators': 10}, 'config_hash': {'algorithm': 'b8112b97ecfc10f00a195af661dcc861cac21289', 'config': 'd3b129b397350f1b6572651c67c01de49b4b174c', 'pipeline': '5b0357ed7072c37b3d6f458bb5d49ff7d825f603'}, 'duration': 0.8299109935760498, 'iteration': 7, 'loss': 1.0, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_PCA', {'features__n_components': 2}), 'normalizer': ('normalizer_StandardScaler', {'normalizer__with_mean': True, 'normalizer__with_std': False}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 6})}, 'score': 0.0, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'gini', 'max_depth': 4, 'max_features': None, 'max_leaf_nodes': 2, 'min_samples_split': 5, 'n_estimators': 100}, 'config_hash': {'algorithm': '40ca24df19b8d164d9d098a6bed1ce056fbbb961', 'config': '813bde1108cc3c4b9bfb3a22cbb421bda7eac671', 'pipeline': '74a7b8705a1c22f7dea5e44e4ebda8f1e48add71'}, 'duration': 2.2111589908599854, 'iteration': 8, 'loss': 0.33333333333333326, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_PCA', {'features__n_components': 2}), 'normalizer': ('normalizer_StandardScaler', {'normalizer__with_mean': False, 'normalizer__with_std': True}), 'rebalance': ('rebalance_NearMiss', {'rebalance__n_neighbors': 2})}, 'score': 0.6666666666666667, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'entropy', 'max_depth': 2, 'max_features': 1, 'max_leaf_nodes': 5, 'min_samples_split': 2, 'n_estimators': 100}, 'config_hash': {'algorithm': '331418a5c12cf1453876eef85e9d98fc8e54fa11', 'config': '31930b6860ed406d59bf7e59ba1925d94704bd3b', 'pipeline': '054bef356f90ec6f644ef3ffc688766744db51c2'}, 'duration': 1.0501940250396729, 'iteration': 9, 'loss': 0.053333333333333344, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_SelectKBest', {'features__k': 1}), 'normalizer': ('normalizer_RobustScaler', {'normalizer__quantile_range': (...), 'normalizer__with_centering': True, 'normalizer__with_scaling': True}), 'rebalance': ('rebalance_NearMiss', {'rebalance__n_neighbors': 2})}, 'score': 0.9466666666666667, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'entropy', 'max_depth': 3, 'max_features': None, 'max_leaf_nodes': 3, 'min_samples_split': 2, 'n_estimators': 100}, 'config_hash': {'algorithm': 'dbc1b8126649fe93dce5fbb37e4015b0acfb179e', 'config': '9913cd550615a9d0946ab4a755a8b9f619e442fd', 'pipeline': 'dd626121cea079ebb32e184ca65483ec7a6d7f59'}, 'duration': 1.120617151260376, 'iteration': 10, 'loss': 0.046666666666666634, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 2, 'features__selectkbest__k': 1}), 'normalizer': ('normalizer_MinMaxScaler', {}), 'rebalance': ('rebalance_NoneType', {})}, 'score': 0.9533333333333334, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'gini', 'max_depth': 3, 'max_features': 3, 'max_leaf_nodes': None, 'min_samples_split': 3, 'n_estimators': 75}, 'config_hash': {'algorithm': '34917a130df5a975f78bd7ec1a0c7b1ffdc787a9', 'config': '95fc8cadc088141290b7de9c388977e4685f0108', 'pipeline': '550d10faf2f08db48516cc3501558816d6a99bc0'}, 'duration': 1.4287099838256836, 'iteration': 11, 'loss': 0.19333333333333313, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 3, 'features__selectkbest__k': 4}), 'normalizer': ('normalizer_StandardScaler', {'normalizer__with_mean': False, 'normalizer__with_std': False}), 'rebalance': ('rebalance_CondensedNearestNeighbour', {'rebalance__n_neighbors': 1})}, 'score': 0.8066666666666669, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'entropy', 'max_depth': 1, 'max_features': 2, 'max_leaf_nodes': 5, 'min_samples_split': 2, 'n_estimators': 75}, 'config_hash': {'algorithm': '33f9abb4aee44a395a9f3b3ffa9ce80a8cdaed7c', 'config': '40fa726f0360cf6af55f9b5902d399d02f61f157', 'pipeline': 'cfd1d20841fe2153da762c95e79f95a3fb1e426a'}, 'duration': 1.2978079319000244, 'iteration': 12, 'loss': 0.053333333333333344, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_PCA', {'features__n_components': 4}), 'normalizer': ('normalizer_MinMaxScaler', {}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 7})}, 'score': 0.9466666666666667, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'entropy', 'max_depth': 4, 'max_features': 2, 'max_leaf_nodes': 5, 'min_samples_split': 3, 'n_estimators': 25}, 'config_hash': {'algorithm': '210111ec6562d09eb093e98ed69ef1c662e11a50', 'config': '0fb8e77c7bd9a58b72f1b33c21a59a09a8c676ba', 'pipeline': '5d269d759e0c7926a685a14b263ace8ae0071e4b'}, 'duration': 0.36649012565612793, 'iteration': 13, 'loss': 0.040000000000000036, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 2, 'features__selectkbest__k': 2}), 'normalizer': ('normalizer_NoneType', {}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 7})}, 'score': 0.96, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'entropy', 'max_depth': 3, 'max_features': 1, 'max_leaf_nodes': 5, 'min_samples_split': 2, 'n_estimators': 25}, 'config_hash': {'algorithm': '0e989a03980101fabf79eda3326ed2870e11d690', 'config': 'f4bffd5d8c67a9c5321a9943c4a99678f59a02b7', 'pipeline': '865ee1e3fe8334c3d5ecb2038d5a5d1b3ba50e75'}, 'duration': 0.35639500617980957, 'iteration': 14, 'loss': 0.046666666666666634, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_NoneType', {}), 'normalizer': ('normalizer_RobustScaler', {'normalizer__quantile_range': (...), 'normalizer__with_centering': True, 'normalizer__with_scaling': False}), 'rebalance': ('rebalance_NoneType', {})}, 'score': 0.9533333333333334, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'entropy', 'max_depth': None, 'max_features': 3, 'max_leaf_nodes': 3, 'min_samples_split': 5, 'n_estimators': 10}, 'config_hash': {'algorithm': '9c592e876c13de5e23e6de5b868e01755d63e72e', 'config': '1e6a68cd1eeac886d90724d78b1cb5fb76a3cde4', 'pipeline': '5a1ca4d82f21b7de0d2c918630a42510673fa36e'}, 'duration': 0.18141412734985352, 'iteration': 15, 'loss': 0.046666666666666634, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_SelectKBest', {'features__k': 3}), 'normalizer': ('normalizer_RobustScaler', {'normalizer__quantile_range': (...), 'normalizer__with_centering': True, 'normalizer__with_scaling': True}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 6})}, 'score': 0.9533333333333334, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': 1, 'max_features': None, 'max_leaf_nodes': None, 'min_samples_split': 5, 'n_estimators': 10}, 'config_hash': {'algorithm': '8bed77aef289bfd453b2858bd288ae5ba7160f2b', 'config': '781185bcb8999045de8d489f253a1a1ba4247932', 'pipeline': '1ece7eabedc2be9e5b0a1be65c570d08ffa3eb54'}, 'duration': 0.1636829376220703, 'iteration': 16, 'loss': 0.053333333333333344, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_NoneType', {}), 'normalizer': ('normalizer_NoneType', {}), 'rebalance': ('rebalance_NearMiss', {'rebalance__n_neighbors': 1})}, 'score': 0.9466666666666667, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'gini', 'max_depth': 3, 'max_features': 2, 'max_leaf_nodes': 2, 'min_samples_split': 5, 'n_estimators': 75}, 'config_hash': {'algorithm': '617b97d9ba21d3373bc51ffa9cccf9c6f91a77b3', 'config': '99fb425b4e8c5d80228cab94202252aa25cdf77c', 'pipeline': 'd6242929c3b515c7719e60423023ac604311afc3'}, 'duration': 0.8468999862670898, 'iteration': 17, 'loss': 0.24, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_PCA', {'features__n_components': 4}), 'normalizer': ('normalizer_PowerTransformer', {}), 'rebalance': ('rebalance_NearMiss', {'rebalance__n_neighbors': 2})}, 'score': 0.76, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': 1, 'max_features': 1, 'max_leaf_nodes': 2, 'min_samples_split': 5, 'n_estimators': 50}, 'config_hash': {'algorithm': 'b92d2697cdd4979da443369d6596229ec091626a', 'config': 'c513a3e13281206ad76187dd817b1fff93d54fe1', 'pipeline': 'c4b4f914a3ca8df967cade997a90366d85a371b9'}, 'duration': 0.6724588871002197, 'iteration': 18, 'loss': 0.23333333333333328, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 1, 'features__selectkbest__k': 3}), 'normalizer': ('normalizer_StandardScaler', {'normalizer__with_mean': True, 'normalizer__with_std': True}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 5})}, 'score': 0.7666666666666667, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'entropy', 'max_depth': None, 'max_features': None, 'max_leaf_nodes': 5, 'min_samples_split': 5, 'n_estimators': 10}, 'config_hash': {'algorithm': 'a0115de695e6cca2e81cbfb54df79bf4b43608b1', 'config': 'ba194015e20b5d67770e8c67342c3d8d0d01dc41', 'pipeline': '8d45fabfeb85ffdcabf7076bd0e65fffe97ce928'}, 'duration': 0.19424200057983398, 'iteration': 19, 'loss': 0.08666666666666667, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_PCA', {'features__n_components': 3}), 'normalizer': ('normalizer_NoneType', {}), 'rebalance': ('rebalance_NoneType', {})}, 'score': 0.9133333333333333, ...}, ...], 'history_hash': ['db6ac7e6d348155757e4794bb5f88fe2b4f63d50', '4db6fb84d85f52659f780e682ffac5712c3d8a94', '4403c5a85e951938d3c454e961d3a412780722f6', 'a064e2df18ab98d44dabcefbc7bed94913f1d0be', '0ddb6f5cab3db4dddd7682966a57205f3e329ad4', '49f25751bca61cdd461a8cbd2923689b642f98ed', '5c3a2b6f5e63fb45f10e41e0318b354912ec44f6', 'd3b129b397350f1b6572651c67c01de49b4b174c', '813bde1108cc3c4b9bfb3a22cbb421bda7eac671', '31930b6860ed406d59bf7e59ba1925d94704bd3b', '9913cd550615a9d0946ab4a755a8b9f619e442fd', '95fc8cadc088141290b7de9c388977e4685f0108', '40fa726f0360cf6af55f9b5902d399d02f61f157', '0fb8e77c7bd9a58b72f1b33c21a59a09a8c676ba', 'f4bffd5d8c67a9c5321a9943c4a99678f59a02b7', '1e6a68cd1eeac886d90724d78b1cb5fb76a3cde4', '781185bcb8999045de8d489f253a1a1ba4247932', '99fb425b4e8c5d80228cab94202252aa25cdf77c', 'c513a3e13281206ad76187dd817b1fff93d54fe1', 'ba194015e20b5d67770e8c67342c3d8d0d01dc41', ...], 'history_index': {'00f0493590a2cb5e98a35b29816f8cd9f87f96ec': 208, '013329309d510b94f19d930320402d65f953a847': 39, '038a0f515e2ec894ee8e34f9caa2889eb3ebd5ce': 66, '052ae4bf232b316187b078abae42c2be19e16a00': 111, '05e9258ebf99dd97202167ef1563fa834b0568f1': 242, '0659afebf316aafeb75612fb07081a04c28545ed': 74, '06e7cde9f3556cd01332ce389ad1d8925cd4b4a4': 120, '07ab8a30d853e39a326b7017026a20e94bc45541': 245, '08606f2a0f0a6c9de204020b4632e09fcee0ae56': 168, '09dbd0948e5b8c1b1f0930778babe65c8a81295e': 243, ...}, 'iteration': 263, 'max_history_score': 0.9666666666666668, 'max_history_score_std': 0.033333333333333326, 'max_history_step': 'joint'}, config={'algorithm': 'RandomForest', 'seed': 42, 'time': 300})
    108 
    109 def objective_algo(algo_config, current_pipeline_config, algorithm, X, y, context, config):
    110     return objective(current_pipeline_config, algo_config, algorithm, X, y, context, config, step='algorithm')
    111 
    112 def objective_joint(wconfig, algorithm, X, y, context, config):
--> 113     return objective(wconfig['pipeline'], wconfig['algorithm'], algorithm, X, y, context, config, step='joint')
        wconfig = {'algorithm': {'bootstrap': False, 'criterion': 'gini', 'max_depth': 4, 'max_features': 3, 'max_leaf_nodes': 3, 'min_samples_split': 3, 'n_estimators': 10}, 'pipeline': {'features': ('features_PCA', {'features__n_components': 1}), 'normalizer': ('normalizer_PowerTransformer', {}), 'rebalance': ('rebalance_CondensedNearestNeighbour', {'rebalance__n_neighbors': 2})}}
        algorithm = 'RandomForest'
        X = array([[5.1, 3.5, 1.4, 0.2],
       [4.9, 3. , 1....2, 3.4, 5.4, 2.3],
       [5.9, 3. , 5.1, 1.8]])
        y = array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,... 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2])
        context = {'baseline_score': 0.9466666666666667, 'baseline_score_std': 0.04988876515698587, 'best_config': {'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': 4, 'max_features': 3, 'max_leaf_nodes': 3, 'min_samples_split': 3, 'n_estimators': 10}, 'config_hash': {'algorithm': 'ffb7ff225ce3d3712c96cf87fe42202988ee2eb0', 'config': 'bae32f426be9cd6243523c023944a8c148fe4aeb', 'pipeline': 'd2a68bfda6fcdec4ae0ffc7d7b6a2122bc1cd673'}, 'duration': 0.7115809917449951, 'iteration': 113, 'loss': 0.033333333333333215, 'max_history_score': 0.9666666666666668, 'max_history_score_std': 0.033333333333333326, 'max_history_step': 'joint', 'pipeline': {'features': ('features_NoneType', {}), 'normalizer': ('normalizer_PowerTransformer', {}), 'rebalance': ('rebalance_CondensedNearestNeighbour', {'rebalance__n_neighbors': 2})}, 'score': 0.9666666666666668, ...}, 'history': [{'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': 2, 'max_features': None, 'max_leaf_nodes': 5, 'min_samples_split': 2, 'n_estimators': 75}, 'config_hash': {'algorithm': '3af5b0cce71c8fe2545246ca24ff5bc3dd516e06', 'config': 'db6ac7e6d348155757e4794bb5f88fe2b4f63d50', 'pipeline': '8d59f4b94cef6be9306ed86a22a9570fa670d567'}, 'duration': 1.149928092956543, 'iteration': 0, 'loss': 0.046666666666666634, 'max_history_score': 0.9533333333333334, 'max_history_score_std': 0.059999999999999984, 'max_history_step': 'joint', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 4, 'features__selectkbest__k': 3}), 'normalizer': ('normalizer_StandardScaler', {'normalizer__with_mean': True, 'normalizer__with_std': True}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 6})}, 'score': 0.9533333333333334, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': 1, 'max_features': 2, 'max_leaf_nodes': 2, 'min_samples_split': 5, 'n_estimators': 100}, 'config_hash': {'algorithm': 'e13eb05fd9a62d2f63bbb1c1deff0cd620d5e6ab', 'config': '4db6fb84d85f52659f780e682ffac5712c3d8a94', 'pipeline': '64c9a1ca9d53ae67244bdd942f4db36a3c05218c'}, 'duration': 1.7678282260894775, 'iteration': 1, 'loss': 0.18000000000000005, 'max_history_score': 0.9533333333333334, 'max_history_score_std': 0.059999999999999984, 'max_history_step': 'joint', 'pipeline': {'features': ('features_NoneType', {}), 'normalizer': ('normalizer_PowerTransformer', {}), 'rebalance': ('rebalance_NearMiss', {'rebalance__n_neighbors': 1})}, 'score': 0.82, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': 1, 'max_features': None, 'max_leaf_nodes': None, 'min_samples_split': 5, 'n_estimators': 75}, 'config_hash': {'algorithm': '94b0d7a654c508cc63643f78fe4f0f07e6f07c1e', 'config': '4403c5a85e951938d3c454e961d3a412780722f6', 'pipeline': '3e47444880d8367fbac2faaba2e52a917274aa58'}, 'duration': 0.8397619724273682, 'iteration': 2, 'loss': 0.03333333333333344, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_PCA', {'features__n_components': 3}), 'normalizer': ('normalizer_MinMaxScaler', {}), 'rebalance': ('rebalance_NoneType', {})}, 'score': 0.9666666666666666, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': None, 'max_features': None, 'max_leaf_nodes': 3, 'min_samples_split': 3, 'n_estimators': 75}, 'config_hash': {'algorithm': 'e8332f0a8902bda03bf70e7978cc5d52affb29d3', 'config': 'a064e2df18ab98d44dabcefbc7bed94913f1d0be', 'pipeline': '7eea819c2a8c103c4b1e9e9c1e224aebba95081f'}, 'duration': 0.8501448631286621, 'iteration': 3, 'loss': 0.053333333333333344, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 2, 'features__selectkbest__k': 4}), 'normalizer': ('normalizer_NoneType', {}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 7})}, 'score': 0.9466666666666667, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'entropy', 'max_depth': 3, 'max_features': 3, 'max_leaf_nodes': None, 'min_samples_split': 5, 'n_estimators': 75}, 'config_hash': {'algorithm': '7a4491035bc6bd737fe9a8cda8a79a02d02d5c74', 'config': '0ddb6f5cab3db4dddd7682966a57205f3e329ad4', 'pipeline': 'a9ae03fe38334f6868cbf84cdd3d629d4bbe3fb0'}, 'duration': 1.1026010513305664, 'iteration': 4, 'loss': 0.05999999999999994, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 2, 'features__selectkbest__k': 1}), 'normalizer': ('normalizer_NoneType', {}), 'rebalance': ('rebalance_NoneType', {})}, 'score': 0.9400000000000001, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'gini', 'max_depth': 3, 'max_features': 1, 'max_leaf_nodes': 5, 'min_samples_split': 2, 'n_estimators': 25}, 'config_hash': {'algorithm': '9826d20b2d6a0f559cf7f16450ce7526f07e8434', 'config': '49f25751bca61cdd461a8cbd2923689b642f98ed', 'pipeline': '19b249664c5bf067de1fed4334a296f947ce774a'}, 'duration': 0.35647010803222656, 'iteration': 5, 'loss': 0.046666666666666634, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_NoneType', {}), 'normalizer': ('normalizer_NoneType', {}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 6})}, 'score': 0.9533333333333334, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'gini', 'max_depth': 2, 'max_features': 1, 'max_leaf_nodes': 2, 'min_samples_split': 2, 'n_estimators': 50}, 'config_hash': {'algorithm': '0a4f6fbb07e0f32c6f675489a0fc82eee05bd8e1', 'config': '5c3a2b6f5e63fb45f10e41e0318b354912ec44f6', 'pipeline': 'dc3b9f176f090005e38b142f11d80e93a7dc5d5e'}, 'duration': 0.7213859558105469, 'iteration': 6, 'loss': 0.31333333333333324, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 1, 'features__selectkbest__k': 4}), 'normalizer': ('normalizer_PowerTransformer', {}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 7})}, 'score': 0.6866666666666668, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'entropy', 'max_depth': 4, 'max_features': 3, 'max_leaf_nodes': 5, 'min_samples_split': 5, 'n_estimators': 10}, 'config_hash': {'algorithm': 'b8112b97ecfc10f00a195af661dcc861cac21289', 'config': 'd3b129b397350f1b6572651c67c01de49b4b174c', 'pipeline': '5b0357ed7072c37b3d6f458bb5d49ff7d825f603'}, 'duration': 0.8299109935760498, 'iteration': 7, 'loss': 1.0, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_PCA', {'features__n_components': 2}), 'normalizer': ('normalizer_StandardScaler', {'normalizer__with_mean': True, 'normalizer__with_std': False}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 6})}, 'score': 0.0, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'gini', 'max_depth': 4, 'max_features': None, 'max_leaf_nodes': 2, 'min_samples_split': 5, 'n_estimators': 100}, 'config_hash': {'algorithm': '40ca24df19b8d164d9d098a6bed1ce056fbbb961', 'config': '813bde1108cc3c4b9bfb3a22cbb421bda7eac671', 'pipeline': '74a7b8705a1c22f7dea5e44e4ebda8f1e48add71'}, 'duration': 2.2111589908599854, 'iteration': 8, 'loss': 0.33333333333333326, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_PCA', {'features__n_components': 2}), 'normalizer': ('normalizer_StandardScaler', {'normalizer__with_mean': False, 'normalizer__with_std': True}), 'rebalance': ('rebalance_NearMiss', {'rebalance__n_neighbors': 2})}, 'score': 0.6666666666666667, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'entropy', 'max_depth': 2, 'max_features': 1, 'max_leaf_nodes': 5, 'min_samples_split': 2, 'n_estimators': 100}, 'config_hash': {'algorithm': '331418a5c12cf1453876eef85e9d98fc8e54fa11', 'config': '31930b6860ed406d59bf7e59ba1925d94704bd3b', 'pipeline': '054bef356f90ec6f644ef3ffc688766744db51c2'}, 'duration': 1.0501940250396729, 'iteration': 9, 'loss': 0.053333333333333344, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_SelectKBest', {'features__k': 1}), 'normalizer': ('normalizer_RobustScaler', {'normalizer__quantile_range': (...), 'normalizer__with_centering': True, 'normalizer__with_scaling': True}), 'rebalance': ('rebalance_NearMiss', {'rebalance__n_neighbors': 2})}, 'score': 0.9466666666666667, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'entropy', 'max_depth': 3, 'max_features': None, 'max_leaf_nodes': 3, 'min_samples_split': 2, 'n_estimators': 100}, 'config_hash': {'algorithm': 'dbc1b8126649fe93dce5fbb37e4015b0acfb179e', 'config': '9913cd550615a9d0946ab4a755a8b9f619e442fd', 'pipeline': 'dd626121cea079ebb32e184ca65483ec7a6d7f59'}, 'duration': 1.120617151260376, 'iteration': 10, 'loss': 0.046666666666666634, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 2, 'features__selectkbest__k': 1}), 'normalizer': ('normalizer_MinMaxScaler', {}), 'rebalance': ('rebalance_NoneType', {})}, 'score': 0.9533333333333334, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'gini', 'max_depth': 3, 'max_features': 3, 'max_leaf_nodes': None, 'min_samples_split': 3, 'n_estimators': 75}, 'config_hash': {'algorithm': '34917a130df5a975f78bd7ec1a0c7b1ffdc787a9', 'config': '95fc8cadc088141290b7de9c388977e4685f0108', 'pipeline': '550d10faf2f08db48516cc3501558816d6a99bc0'}, 'duration': 1.4287099838256836, 'iteration': 11, 'loss': 0.19333333333333313, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 3, 'features__selectkbest__k': 4}), 'normalizer': ('normalizer_StandardScaler', {'normalizer__with_mean': False, 'normalizer__with_std': False}), 'rebalance': ('rebalance_CondensedNearestNeighbour', {'rebalance__n_neighbors': 1})}, 'score': 0.8066666666666669, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'entropy', 'max_depth': 1, 'max_features': 2, 'max_leaf_nodes': 5, 'min_samples_split': 2, 'n_estimators': 75}, 'config_hash': {'algorithm': '33f9abb4aee44a395a9f3b3ffa9ce80a8cdaed7c', 'config': '40fa726f0360cf6af55f9b5902d399d02f61f157', 'pipeline': 'cfd1d20841fe2153da762c95e79f95a3fb1e426a'}, 'duration': 1.2978079319000244, 'iteration': 12, 'loss': 0.053333333333333344, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_PCA', {'features__n_components': 4}), 'normalizer': ('normalizer_MinMaxScaler', {}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 7})}, 'score': 0.9466666666666667, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'entropy', 'max_depth': 4, 'max_features': 2, 'max_leaf_nodes': 5, 'min_samples_split': 3, 'n_estimators': 25}, 'config_hash': {'algorithm': '210111ec6562d09eb093e98ed69ef1c662e11a50', 'config': '0fb8e77c7bd9a58b72f1b33c21a59a09a8c676ba', 'pipeline': '5d269d759e0c7926a685a14b263ace8ae0071e4b'}, 'duration': 0.36649012565612793, 'iteration': 13, 'loss': 0.040000000000000036, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 2, 'features__selectkbest__k': 2}), 'normalizer': ('normalizer_NoneType', {}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 7})}, 'score': 0.96, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'entropy', 'max_depth': 3, 'max_features': 1, 'max_leaf_nodes': 5, 'min_samples_split': 2, 'n_estimators': 25}, 'config_hash': {'algorithm': '0e989a03980101fabf79eda3326ed2870e11d690', 'config': 'f4bffd5d8c67a9c5321a9943c4a99678f59a02b7', 'pipeline': '865ee1e3fe8334c3d5ecb2038d5a5d1b3ba50e75'}, 'duration': 0.35639500617980957, 'iteration': 14, 'loss': 0.046666666666666634, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_NoneType', {}), 'normalizer': ('normalizer_RobustScaler', {'normalizer__quantile_range': (...), 'normalizer__with_centering': True, 'normalizer__with_scaling': False}), 'rebalance': ('rebalance_NoneType', {})}, 'score': 0.9533333333333334, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'entropy', 'max_depth': None, 'max_features': 3, 'max_leaf_nodes': 3, 'min_samples_split': 5, 'n_estimators': 10}, 'config_hash': {'algorithm': '9c592e876c13de5e23e6de5b868e01755d63e72e', 'config': '1e6a68cd1eeac886d90724d78b1cb5fb76a3cde4', 'pipeline': '5a1ca4d82f21b7de0d2c918630a42510673fa36e'}, 'duration': 0.18141412734985352, 'iteration': 15, 'loss': 0.046666666666666634, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_SelectKBest', {'features__k': 3}), 'normalizer': ('normalizer_RobustScaler', {'normalizer__quantile_range': (...), 'normalizer__with_centering': True, 'normalizer__with_scaling': True}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 6})}, 'score': 0.9533333333333334, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': 1, 'max_features': None, 'max_leaf_nodes': None, 'min_samples_split': 5, 'n_estimators': 10}, 'config_hash': {'algorithm': '8bed77aef289bfd453b2858bd288ae5ba7160f2b', 'config': '781185bcb8999045de8d489f253a1a1ba4247932', 'pipeline': '1ece7eabedc2be9e5b0a1be65c570d08ffa3eb54'}, 'duration': 0.1636829376220703, 'iteration': 16, 'loss': 0.053333333333333344, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_NoneType', {}), 'normalizer': ('normalizer_NoneType', {}), 'rebalance': ('rebalance_NearMiss', {'rebalance__n_neighbors': 1})}, 'score': 0.9466666666666667, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'gini', 'max_depth': 3, 'max_features': 2, 'max_leaf_nodes': 2, 'min_samples_split': 5, 'n_estimators': 75}, 'config_hash': {'algorithm': '617b97d9ba21d3373bc51ffa9cccf9c6f91a77b3', 'config': '99fb425b4e8c5d80228cab94202252aa25cdf77c', 'pipeline': 'd6242929c3b515c7719e60423023ac604311afc3'}, 'duration': 0.8468999862670898, 'iteration': 17, 'loss': 0.24, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_PCA', {'features__n_components': 4}), 'normalizer': ('normalizer_PowerTransformer', {}), 'rebalance': ('rebalance_NearMiss', {'rebalance__n_neighbors': 2})}, 'score': 0.76, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': 1, 'max_features': 1, 'max_leaf_nodes': 2, 'min_samples_split': 5, 'n_estimators': 50}, 'config_hash': {'algorithm': 'b92d2697cdd4979da443369d6596229ec091626a', 'config': 'c513a3e13281206ad76187dd817b1fff93d54fe1', 'pipeline': 'c4b4f914a3ca8df967cade997a90366d85a371b9'}, 'duration': 0.6724588871002197, 'iteration': 18, 'loss': 0.23333333333333328, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 1, 'features__selectkbest__k': 3}), 'normalizer': ('normalizer_StandardScaler', {'normalizer__with_mean': True, 'normalizer__with_std': True}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 5})}, 'score': 0.7666666666666667, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'entropy', 'max_depth': None, 'max_features': None, 'max_leaf_nodes': 5, 'min_samples_split': 5, 'n_estimators': 10}, 'config_hash': {'algorithm': 'a0115de695e6cca2e81cbfb54df79bf4b43608b1', 'config': 'ba194015e20b5d67770e8c67342c3d8d0d01dc41', 'pipeline': '8d45fabfeb85ffdcabf7076bd0e65fffe97ce928'}, 'duration': 0.19424200057983398, 'iteration': 19, 'loss': 0.08666666666666667, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_PCA', {'features__n_components': 3}), 'normalizer': ('normalizer_NoneType', {}), 'rebalance': ('rebalance_NoneType', {})}, 'score': 0.9133333333333333, ...}, ...], 'history_hash': ['db6ac7e6d348155757e4794bb5f88fe2b4f63d50', '4db6fb84d85f52659f780e682ffac5712c3d8a94', '4403c5a85e951938d3c454e961d3a412780722f6', 'a064e2df18ab98d44dabcefbc7bed94913f1d0be', '0ddb6f5cab3db4dddd7682966a57205f3e329ad4', '49f25751bca61cdd461a8cbd2923689b642f98ed', '5c3a2b6f5e63fb45f10e41e0318b354912ec44f6', 'd3b129b397350f1b6572651c67c01de49b4b174c', '813bde1108cc3c4b9bfb3a22cbb421bda7eac671', '31930b6860ed406d59bf7e59ba1925d94704bd3b', '9913cd550615a9d0946ab4a755a8b9f619e442fd', '95fc8cadc088141290b7de9c388977e4685f0108', '40fa726f0360cf6af55f9b5902d399d02f61f157', '0fb8e77c7bd9a58b72f1b33c21a59a09a8c676ba', 'f4bffd5d8c67a9c5321a9943c4a99678f59a02b7', '1e6a68cd1eeac886d90724d78b1cb5fb76a3cde4', '781185bcb8999045de8d489f253a1a1ba4247932', '99fb425b4e8c5d80228cab94202252aa25cdf77c', 'c513a3e13281206ad76187dd817b1fff93d54fe1', 'ba194015e20b5d67770e8c67342c3d8d0d01dc41', ...], 'history_index': {'00f0493590a2cb5e98a35b29816f8cd9f87f96ec': 208, '013329309d510b94f19d930320402d65f953a847': 39, '038a0f515e2ec894ee8e34f9caa2889eb3ebd5ce': 66, '052ae4bf232b316187b078abae42c2be19e16a00': 111, '05e9258ebf99dd97202167ef1563fa834b0568f1': 242, '0659afebf316aafeb75612fb07081a04c28545ed': 74, '06e7cde9f3556cd01332ce389ad1d8925cd4b4a4': 120, '07ab8a30d853e39a326b7017026a20e94bc45541': 245, '08606f2a0f0a6c9de204020b4632e09fcee0ae56': 168, '09dbd0948e5b8c1b1f0930778babe65c8a81295e': 243, ...}, 'iteration': 263, 'max_history_score': 0.9666666666666668, 'max_history_score_std': 0.033333333333333326, 'max_history_step': 'joint'}
        config = {'algorithm': 'RandomForest', 'seed': 42, 'time': 300}
    114 
    115 
    116 def get_baseline_score(algorithm, X, y, seed):
    117     pipeline, _ = pipeline_conf_to_full_pipeline(

...........................................................................
/home/aquemy/dev/dp_hyperparameters/extension/experiment/objective.py in objective(pipeline_config={'features': ('features_PCA', {'features__n_components': 1}), 'normalizer': ('normalizer_PowerTransformer', {}), 'rebalance': ('rebalance_CondensedNearestNeighbour', {'rebalance__n_neighbors': 2})}, algo_config={'bootstrap': False, 'criterion': 'gini', 'max_depth': 4, 'max_features': 3, 'max_leaf_nodes': 3, 'min_samples_split': 3, 'n_estimators': 10}, algorithm='RandomForest', X=array([[5.1, 3.5, 1.4, 0.2],
       [4.9, 3. , 1....2, 3.4, 5.4, 2.3],
       [5.9, 3. , 5.1, 1.8]]), y=array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,... 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]), context={'baseline_score': 0.9466666666666667, 'baseline_score_std': 0.04988876515698587, 'best_config': {'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': 4, 'max_features': 3, 'max_leaf_nodes': 3, 'min_samples_split': 3, 'n_estimators': 10}, 'config_hash': {'algorithm': 'ffb7ff225ce3d3712c96cf87fe42202988ee2eb0', 'config': 'bae32f426be9cd6243523c023944a8c148fe4aeb', 'pipeline': 'd2a68bfda6fcdec4ae0ffc7d7b6a2122bc1cd673'}, 'duration': 0.7115809917449951, 'iteration': 113, 'loss': 0.033333333333333215, 'max_history_score': 0.9666666666666668, 'max_history_score_std': 0.033333333333333326, 'max_history_step': 'joint', 'pipeline': {'features': ('features_NoneType', {}), 'normalizer': ('normalizer_PowerTransformer', {}), 'rebalance': ('rebalance_CondensedNearestNeighbour', {'rebalance__n_neighbors': 2})}, 'score': 0.9666666666666668, ...}, 'history': [{'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': 2, 'max_features': None, 'max_leaf_nodes': 5, 'min_samples_split': 2, 'n_estimators': 75}, 'config_hash': {'algorithm': '3af5b0cce71c8fe2545246ca24ff5bc3dd516e06', 'config': 'db6ac7e6d348155757e4794bb5f88fe2b4f63d50', 'pipeline': '8d59f4b94cef6be9306ed86a22a9570fa670d567'}, 'duration': 1.149928092956543, 'iteration': 0, 'loss': 0.046666666666666634, 'max_history_score': 0.9533333333333334, 'max_history_score_std': 0.059999999999999984, 'max_history_step': 'joint', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 4, 'features__selectkbest__k': 3}), 'normalizer': ('normalizer_StandardScaler', {'normalizer__with_mean': True, 'normalizer__with_std': True}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 6})}, 'score': 0.9533333333333334, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': 1, 'max_features': 2, 'max_leaf_nodes': 2, 'min_samples_split': 5, 'n_estimators': 100}, 'config_hash': {'algorithm': 'e13eb05fd9a62d2f63bbb1c1deff0cd620d5e6ab', 'config': '4db6fb84d85f52659f780e682ffac5712c3d8a94', 'pipeline': '64c9a1ca9d53ae67244bdd942f4db36a3c05218c'}, 'duration': 1.7678282260894775, 'iteration': 1, 'loss': 0.18000000000000005, 'max_history_score': 0.9533333333333334, 'max_history_score_std': 0.059999999999999984, 'max_history_step': 'joint', 'pipeline': {'features': ('features_NoneType', {}), 'normalizer': ('normalizer_PowerTransformer', {}), 'rebalance': ('rebalance_NearMiss', {'rebalance__n_neighbors': 1})}, 'score': 0.82, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': 1, 'max_features': None, 'max_leaf_nodes': None, 'min_samples_split': 5, 'n_estimators': 75}, 'config_hash': {'algorithm': '94b0d7a654c508cc63643f78fe4f0f07e6f07c1e', 'config': '4403c5a85e951938d3c454e961d3a412780722f6', 'pipeline': '3e47444880d8367fbac2faaba2e52a917274aa58'}, 'duration': 0.8397619724273682, 'iteration': 2, 'loss': 0.03333333333333344, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_PCA', {'features__n_components': 3}), 'normalizer': ('normalizer_MinMaxScaler', {}), 'rebalance': ('rebalance_NoneType', {})}, 'score': 0.9666666666666666, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': None, 'max_features': None, 'max_leaf_nodes': 3, 'min_samples_split': 3, 'n_estimators': 75}, 'config_hash': {'algorithm': 'e8332f0a8902bda03bf70e7978cc5d52affb29d3', 'config': 'a064e2df18ab98d44dabcefbc7bed94913f1d0be', 'pipeline': '7eea819c2a8c103c4b1e9e9c1e224aebba95081f'}, 'duration': 0.8501448631286621, 'iteration': 3, 'loss': 0.053333333333333344, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 2, 'features__selectkbest__k': 4}), 'normalizer': ('normalizer_NoneType', {}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 7})}, 'score': 0.9466666666666667, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'entropy', 'max_depth': 3, 'max_features': 3, 'max_leaf_nodes': None, 'min_samples_split': 5, 'n_estimators': 75}, 'config_hash': {'algorithm': '7a4491035bc6bd737fe9a8cda8a79a02d02d5c74', 'config': '0ddb6f5cab3db4dddd7682966a57205f3e329ad4', 'pipeline': 'a9ae03fe38334f6868cbf84cdd3d629d4bbe3fb0'}, 'duration': 1.1026010513305664, 'iteration': 4, 'loss': 0.05999999999999994, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 2, 'features__selectkbest__k': 1}), 'normalizer': ('normalizer_NoneType', {}), 'rebalance': ('rebalance_NoneType', {})}, 'score': 0.9400000000000001, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'gini', 'max_depth': 3, 'max_features': 1, 'max_leaf_nodes': 5, 'min_samples_split': 2, 'n_estimators': 25}, 'config_hash': {'algorithm': '9826d20b2d6a0f559cf7f16450ce7526f07e8434', 'config': '49f25751bca61cdd461a8cbd2923689b642f98ed', 'pipeline': '19b249664c5bf067de1fed4334a296f947ce774a'}, 'duration': 0.35647010803222656, 'iteration': 5, 'loss': 0.046666666666666634, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_NoneType', {}), 'normalizer': ('normalizer_NoneType', {}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 6})}, 'score': 0.9533333333333334, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'gini', 'max_depth': 2, 'max_features': 1, 'max_leaf_nodes': 2, 'min_samples_split': 2, 'n_estimators': 50}, 'config_hash': {'algorithm': '0a4f6fbb07e0f32c6f675489a0fc82eee05bd8e1', 'config': '5c3a2b6f5e63fb45f10e41e0318b354912ec44f6', 'pipeline': 'dc3b9f176f090005e38b142f11d80e93a7dc5d5e'}, 'duration': 0.7213859558105469, 'iteration': 6, 'loss': 0.31333333333333324, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 1, 'features__selectkbest__k': 4}), 'normalizer': ('normalizer_PowerTransformer', {}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 7})}, 'score': 0.6866666666666668, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'entropy', 'max_depth': 4, 'max_features': 3, 'max_leaf_nodes': 5, 'min_samples_split': 5, 'n_estimators': 10}, 'config_hash': {'algorithm': 'b8112b97ecfc10f00a195af661dcc861cac21289', 'config': 'd3b129b397350f1b6572651c67c01de49b4b174c', 'pipeline': '5b0357ed7072c37b3d6f458bb5d49ff7d825f603'}, 'duration': 0.8299109935760498, 'iteration': 7, 'loss': 1.0, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_PCA', {'features__n_components': 2}), 'normalizer': ('normalizer_StandardScaler', {'normalizer__with_mean': True, 'normalizer__with_std': False}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 6})}, 'score': 0.0, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'gini', 'max_depth': 4, 'max_features': None, 'max_leaf_nodes': 2, 'min_samples_split': 5, 'n_estimators': 100}, 'config_hash': {'algorithm': '40ca24df19b8d164d9d098a6bed1ce056fbbb961', 'config': '813bde1108cc3c4b9bfb3a22cbb421bda7eac671', 'pipeline': '74a7b8705a1c22f7dea5e44e4ebda8f1e48add71'}, 'duration': 2.2111589908599854, 'iteration': 8, 'loss': 0.33333333333333326, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_PCA', {'features__n_components': 2}), 'normalizer': ('normalizer_StandardScaler', {'normalizer__with_mean': False, 'normalizer__with_std': True}), 'rebalance': ('rebalance_NearMiss', {'rebalance__n_neighbors': 2})}, 'score': 0.6666666666666667, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'entropy', 'max_depth': 2, 'max_features': 1, 'max_leaf_nodes': 5, 'min_samples_split': 2, 'n_estimators': 100}, 'config_hash': {'algorithm': '331418a5c12cf1453876eef85e9d98fc8e54fa11', 'config': '31930b6860ed406d59bf7e59ba1925d94704bd3b', 'pipeline': '054bef356f90ec6f644ef3ffc688766744db51c2'}, 'duration': 1.0501940250396729, 'iteration': 9, 'loss': 0.053333333333333344, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_SelectKBest', {'features__k': 1}), 'normalizer': ('normalizer_RobustScaler', {'normalizer__quantile_range': (...), 'normalizer__with_centering': True, 'normalizer__with_scaling': True}), 'rebalance': ('rebalance_NearMiss', {'rebalance__n_neighbors': 2})}, 'score': 0.9466666666666667, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'entropy', 'max_depth': 3, 'max_features': None, 'max_leaf_nodes': 3, 'min_samples_split': 2, 'n_estimators': 100}, 'config_hash': {'algorithm': 'dbc1b8126649fe93dce5fbb37e4015b0acfb179e', 'config': '9913cd550615a9d0946ab4a755a8b9f619e442fd', 'pipeline': 'dd626121cea079ebb32e184ca65483ec7a6d7f59'}, 'duration': 1.120617151260376, 'iteration': 10, 'loss': 0.046666666666666634, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 2, 'features__selectkbest__k': 1}), 'normalizer': ('normalizer_MinMaxScaler', {}), 'rebalance': ('rebalance_NoneType', {})}, 'score': 0.9533333333333334, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'gini', 'max_depth': 3, 'max_features': 3, 'max_leaf_nodes': None, 'min_samples_split': 3, 'n_estimators': 75}, 'config_hash': {'algorithm': '34917a130df5a975f78bd7ec1a0c7b1ffdc787a9', 'config': '95fc8cadc088141290b7de9c388977e4685f0108', 'pipeline': '550d10faf2f08db48516cc3501558816d6a99bc0'}, 'duration': 1.4287099838256836, 'iteration': 11, 'loss': 0.19333333333333313, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 3, 'features__selectkbest__k': 4}), 'normalizer': ('normalizer_StandardScaler', {'normalizer__with_mean': False, 'normalizer__with_std': False}), 'rebalance': ('rebalance_CondensedNearestNeighbour', {'rebalance__n_neighbors': 1})}, 'score': 0.8066666666666669, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'entropy', 'max_depth': 1, 'max_features': 2, 'max_leaf_nodes': 5, 'min_samples_split': 2, 'n_estimators': 75}, 'config_hash': {'algorithm': '33f9abb4aee44a395a9f3b3ffa9ce80a8cdaed7c', 'config': '40fa726f0360cf6af55f9b5902d399d02f61f157', 'pipeline': 'cfd1d20841fe2153da762c95e79f95a3fb1e426a'}, 'duration': 1.2978079319000244, 'iteration': 12, 'loss': 0.053333333333333344, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_PCA', {'features__n_components': 4}), 'normalizer': ('normalizer_MinMaxScaler', {}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 7})}, 'score': 0.9466666666666667, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'entropy', 'max_depth': 4, 'max_features': 2, 'max_leaf_nodes': 5, 'min_samples_split': 3, 'n_estimators': 25}, 'config_hash': {'algorithm': '210111ec6562d09eb093e98ed69ef1c662e11a50', 'config': '0fb8e77c7bd9a58b72f1b33c21a59a09a8c676ba', 'pipeline': '5d269d759e0c7926a685a14b263ace8ae0071e4b'}, 'duration': 0.36649012565612793, 'iteration': 13, 'loss': 0.040000000000000036, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 2, 'features__selectkbest__k': 2}), 'normalizer': ('normalizer_NoneType', {}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 7})}, 'score': 0.96, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'entropy', 'max_depth': 3, 'max_features': 1, 'max_leaf_nodes': 5, 'min_samples_split': 2, 'n_estimators': 25}, 'config_hash': {'algorithm': '0e989a03980101fabf79eda3326ed2870e11d690', 'config': 'f4bffd5d8c67a9c5321a9943c4a99678f59a02b7', 'pipeline': '865ee1e3fe8334c3d5ecb2038d5a5d1b3ba50e75'}, 'duration': 0.35639500617980957, 'iteration': 14, 'loss': 0.046666666666666634, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_NoneType', {}), 'normalizer': ('normalizer_RobustScaler', {'normalizer__quantile_range': (...), 'normalizer__with_centering': True, 'normalizer__with_scaling': False}), 'rebalance': ('rebalance_NoneType', {})}, 'score': 0.9533333333333334, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'entropy', 'max_depth': None, 'max_features': 3, 'max_leaf_nodes': 3, 'min_samples_split': 5, 'n_estimators': 10}, 'config_hash': {'algorithm': '9c592e876c13de5e23e6de5b868e01755d63e72e', 'config': '1e6a68cd1eeac886d90724d78b1cb5fb76a3cde4', 'pipeline': '5a1ca4d82f21b7de0d2c918630a42510673fa36e'}, 'duration': 0.18141412734985352, 'iteration': 15, 'loss': 0.046666666666666634, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_SelectKBest', {'features__k': 3}), 'normalizer': ('normalizer_RobustScaler', {'normalizer__quantile_range': (...), 'normalizer__with_centering': True, 'normalizer__with_scaling': True}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 6})}, 'score': 0.9533333333333334, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': 1, 'max_features': None, 'max_leaf_nodes': None, 'min_samples_split': 5, 'n_estimators': 10}, 'config_hash': {'algorithm': '8bed77aef289bfd453b2858bd288ae5ba7160f2b', 'config': '781185bcb8999045de8d489f253a1a1ba4247932', 'pipeline': '1ece7eabedc2be9e5b0a1be65c570d08ffa3eb54'}, 'duration': 0.1636829376220703, 'iteration': 16, 'loss': 0.053333333333333344, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_NoneType', {}), 'normalizer': ('normalizer_NoneType', {}), 'rebalance': ('rebalance_NearMiss', {'rebalance__n_neighbors': 1})}, 'score': 0.9466666666666667, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'gini', 'max_depth': 3, 'max_features': 2, 'max_leaf_nodes': 2, 'min_samples_split': 5, 'n_estimators': 75}, 'config_hash': {'algorithm': '617b97d9ba21d3373bc51ffa9cccf9c6f91a77b3', 'config': '99fb425b4e8c5d80228cab94202252aa25cdf77c', 'pipeline': 'd6242929c3b515c7719e60423023ac604311afc3'}, 'duration': 0.8468999862670898, 'iteration': 17, 'loss': 0.24, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_PCA', {'features__n_components': 4}), 'normalizer': ('normalizer_PowerTransformer', {}), 'rebalance': ('rebalance_NearMiss', {'rebalance__n_neighbors': 2})}, 'score': 0.76, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': 1, 'max_features': 1, 'max_leaf_nodes': 2, 'min_samples_split': 5, 'n_estimators': 50}, 'config_hash': {'algorithm': 'b92d2697cdd4979da443369d6596229ec091626a', 'config': 'c513a3e13281206ad76187dd817b1fff93d54fe1', 'pipeline': 'c4b4f914a3ca8df967cade997a90366d85a371b9'}, 'duration': 0.6724588871002197, 'iteration': 18, 'loss': 0.23333333333333328, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 1, 'features__selectkbest__k': 3}), 'normalizer': ('normalizer_StandardScaler', {'normalizer__with_mean': True, 'normalizer__with_std': True}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 5})}, 'score': 0.7666666666666667, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'entropy', 'max_depth': None, 'max_features': None, 'max_leaf_nodes': 5, 'min_samples_split': 5, 'n_estimators': 10}, 'config_hash': {'algorithm': 'a0115de695e6cca2e81cbfb54df79bf4b43608b1', 'config': 'ba194015e20b5d67770e8c67342c3d8d0d01dc41', 'pipeline': '8d45fabfeb85ffdcabf7076bd0e65fffe97ce928'}, 'duration': 0.19424200057983398, 'iteration': 19, 'loss': 0.08666666666666667, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_PCA', {'features__n_components': 3}), 'normalizer': ('normalizer_NoneType', {}), 'rebalance': ('rebalance_NoneType', {})}, 'score': 0.9133333333333333, ...}, ...], 'history_hash': ['db6ac7e6d348155757e4794bb5f88fe2b4f63d50', '4db6fb84d85f52659f780e682ffac5712c3d8a94', '4403c5a85e951938d3c454e961d3a412780722f6', 'a064e2df18ab98d44dabcefbc7bed94913f1d0be', '0ddb6f5cab3db4dddd7682966a57205f3e329ad4', '49f25751bca61cdd461a8cbd2923689b642f98ed', '5c3a2b6f5e63fb45f10e41e0318b354912ec44f6', 'd3b129b397350f1b6572651c67c01de49b4b174c', '813bde1108cc3c4b9bfb3a22cbb421bda7eac671', '31930b6860ed406d59bf7e59ba1925d94704bd3b', '9913cd550615a9d0946ab4a755a8b9f619e442fd', '95fc8cadc088141290b7de9c388977e4685f0108', '40fa726f0360cf6af55f9b5902d399d02f61f157', '0fb8e77c7bd9a58b72f1b33c21a59a09a8c676ba', 'f4bffd5d8c67a9c5321a9943c4a99678f59a02b7', '1e6a68cd1eeac886d90724d78b1cb5fb76a3cde4', '781185bcb8999045de8d489f253a1a1ba4247932', '99fb425b4e8c5d80228cab94202252aa25cdf77c', 'c513a3e13281206ad76187dd817b1fff93d54fe1', 'ba194015e20b5d67770e8c67342c3d8d0d01dc41', ...], 'history_index': {'00f0493590a2cb5e98a35b29816f8cd9f87f96ec': 208, '013329309d510b94f19d930320402d65f953a847': 39, '038a0f515e2ec894ee8e34f9caa2889eb3ebd5ce': 66, '052ae4bf232b316187b078abae42c2be19e16a00': 111, '05e9258ebf99dd97202167ef1563fa834b0568f1': 242, '0659afebf316aafeb75612fb07081a04c28545ed': 74, '06e7cde9f3556cd01332ce389ad1d8925cd4b4a4': 120, '07ab8a30d853e39a326b7017026a20e94bc45541': 245, '08606f2a0f0a6c9de204020b4632e09fcee0ae56': 168, '09dbd0948e5b8c1b1f0930778babe65c8a81295e': 243, ...}, 'iteration': 263, 'max_history_score': 0.9666666666666668, 'max_history_score_std': 0.033333333333333326, 'max_history_step': 'joint'}, config={'algorithm': 'RandomForest', 'seed': 42, 'time': 300}, step='joint')
     45                 y,
     46                 cv=10,
     47                 n_jobs=-1,
     48                 return_estimator=False,
     49                 return_train_score=False,
---> 50                 verbose=0)
     51         score = np.mean(scores['test_score'])
     52         std = np.std(scores['test_score'])
     53         status = STATUS_OK
     54     except Exception as e:

...........................................................................
/home/aquemy/.local/lib/python2.7/site-packages/sklearn/model_selection/_validation.py in cross_validate(estimator=Pipeline(memory=None,
     steps=[('rebalance', ... random_state=42, verbose=0, warm_start=False))]), X=array([[5.1, 3.5, 1.4, 0.2],
       [4.9, 3. , 1....2, 3.4, 5.4, 2.3],
       [5.9, 3. , 5.1, 1.8]]), y=array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,... 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]), groups=None, scoring=None, cv=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1, verbose=0, fit_params=None, pre_dispatch='2*n_jobs', return_train_score=False, return_estimator=False, error_score='raise-deprecating')
    235         delayed(_fit_and_score)(
    236             clone(estimator), X, y, scorers, train, test, verbose, None,
    237             fit_params, return_train_score=return_train_score,
    238             return_times=True, return_estimator=return_estimator,
    239             error_score=error_score)
--> 240         for train, test in cv.split(X, y, groups))
        cv.split = <bound method StratifiedKFold.split of Stratifie...d(n_splits=10, random_state=None, shuffle=False)>
        X = array([[5.1, 3.5, 1.4, 0.2],
       [4.9, 3. , 1....2, 3.4, 5.4, 2.3],
       [5.9, 3. , 5.1, 1.8]])
        y = array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,... 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2])
        groups = None
    241 
    242     zipped_scores = list(zip(*scores))
    243     if return_train_score:
    244         train_scores = zipped_scores.pop(0)

...........................................................................
/home/aquemy/.local/lib/python2.7/site-packages/sklearn/externals/joblib/parallel.py in __call__(self=Parallel(n_jobs=-1), iterable=<generator object <genexpr>>)
    925                 # No need to wait for async callbacks to trigger to
    926                 # consumption.
    927                 self._iterating = False
    928 
    929             with self._backend.retrieval_context():
--> 930                 self.retrieve()
        self.retrieve = <bound method Parallel.retrieve of Parallel(n_jobs=-1)>
    931             # Make sure that we get a last message telling us we are done
    932             elapsed_time = time.time() - self._start_time
    933             self._print('Done %3i out of %3i | elapsed: %s finished',
    934                         (len(self._output), len(self._output),

---------------------------------------------------------------------------
Joblib worker traceback:
---------------------------------------------------------------------------
ValueError                                         Mon Jun 17 13:14:06 2019
PID: 21553                                  Python 2.7.15+: /usr/bin/python
...........................................................................
/home/aquemy/.local/lib/python2.7/site-packages/sklearn/externals/joblib/parallel.py in __call__(self=<sklearn.externals.joblib.parallel.BatchedCalls object>)
    220     def __call__(self):
    221         # Set the default nested backend to self._backend but do not set the
    222         # change the default number of processes to -1
    223         with parallel_backend(self._backend, n_jobs=self._n_jobs):
    224             return [func(*args, **kwargs)
--> 225                     for func, args, kwargs in self.items]
        func = <function _fit_and_score>
        args = (Pipeline(memory=None,
     steps=[('rebalance', ... random_state=42, verbose=0, warm_start=False))]), array([[5.1, 3.5, 1.4, 0.2],
       [4.9, 3. , 1....2, 3.4, 5.4, 2.3],
       [5.9, 3. , 5.1, 1.8]]), array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,... 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]), {'score': <function _passthrough_scorer>}, array([  5,   6,   7,   8,   9,  10,  11,  12,  ..., 142, 143, 144,
       145, 146, 147, 148, 149]), array([  0,   1,   2,   3,   4,  50,  51,  52,  53,  54, 100, 101, 102,
       103, 104]), 0, None, None)
        kwargs = {'error_score': 'raise-deprecating', 'return_estimator': False, 'return_times': True, 'return_train_score': False}
        self.items = [(<function _fit_and_score>, (Pipeline(memory=None,
     steps=[('rebalance', ... random_state=42, verbose=0, warm_start=False))]), array([[5.1, 3.5, 1.4, 0.2],
       [4.9, 3. , 1....2, 3.4, 5.4, 2.3],
       [5.9, 3. , 5.1, 1.8]]), array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,... 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]), {'score': <function _passthrough_scorer>}, array([  5,   6,   7,   8,   9,  10,  11,  12,  ..., 142, 143, 144,
       145, 146, 147, 148, 149]), array([  0,   1,   2,   3,   4,  50,  51,  52,  53,  54, 100, 101, 102,
       103, 104]), 0, None, None), {'error_score': 'raise-deprecating', 'return_estimator': False, 'return_times': True, 'return_train_score': False})]
    226 
    227     def __len__(self):
    228         return self._size
    229 

...........................................................................
/home/aquemy/.local/lib/python2.7/site-packages/sklearn/model_selection/_validation.py in _fit_and_score(estimator=Pipeline(memory=None,
     steps=[('rebalance', ... random_state=42, verbose=0, warm_start=False))]), X=array([[5.1, 3.5, 1.4, 0.2],
       [4.9, 3. , 1....2, 3.4, 5.4, 2.3],
       [5.9, 3. , 5.1, 1.8]]), y=array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,... 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]), scorer={'score': <function _passthrough_scorer>}, train=array([  5,   6,   7,   8,   9,  10,  11,  12,  ..., 142, 143, 144,
       145, 146, 147, 148, 149]), test=array([  0,   1,   2,   3,   4,  50,  51,  52,  53,  54, 100, 101, 102,
       103, 104]), verbose=0, parameters=None, fit_params={}, return_train_score=False, return_parameters=False, return_n_test_samples=False, return_times=True, return_estimator=False, error_score='raise-deprecating')
    523 
    524     try:
    525         if y_train is None:
    526             estimator.fit(X_train, **fit_params)
    527         else:
--> 528             estimator.fit(X_train, y_train, **fit_params)
        estimator.fit = <bound method Pipeline.fit of Pipeline(memory=No...random_state=42, verbose=0, warm_start=False))])>
        X_train = array([[5.4, 3.9, 1.7, 0.4],
       [4.6, 3.4, 1....2, 3.4, 5.4, 2.3],
       [5.9, 3. , 5.1, 1.8]])
        y_train = array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,
       2, 2, 2])
        fit_params = {}
    529 
    530     except Exception as e:
    531         # Note fit time as time until error
    532         fit_time = time.time() - start_time

...........................................................................
/usr/local/lib/python2.7/dist-packages/imblearn/pipeline.py in fit(self=Pipeline(memory=None,
     steps=[('rebalance', ... random_state=42, verbose=0, warm_start=False))]), X=array([[5.4, 3.9, 1.7, 0.4],
       [4.6, 3.4, 1....2, 3.4, 5.4, 2.3],
       [5.9, 3. , 5.1, 1.8]]), y=array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,
       2, 2, 2]), **fit_params={})
    234             This estimator
    235 
    236         """
    237         Xt, yt, fit_params = self._fit(X, y, **fit_params)
    238         if self._final_estimator is not None:
--> 239             self._final_estimator.fit(Xt, yt, **fit_params)
        self._final_estimator.fit = <bound method RandomForestClassifier.fit of Rand...e, random_state=42, verbose=0, warm_start=False)>
        Xt = array([[ 1.12201312],
       [-0.76341128],
    ...51],
       [ 3.88929931],
       [ 2.24797343]])
        yt = array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...0, 0, 0, 0, 0, 0, 0,
       0, 1, 1, 1, 2, 2, 2])
        fit_params = {}
    240         return self
    241 
    242     def fit_transform(self, X, y=None, **fit_params):
    243         """Fit the model and transform with the final estimator

...........................................................................
/home/aquemy/.local/lib/python2.7/site-packages/sklearn/ensemble/forest.py in fit(self=RandomForestClassifier(bootstrap=False, class_we...se, random_state=42, verbose=0, warm_start=False), X=array([[ 1.1220131 ],
       [-0.7634113 ],
    ....8892994 ],
       [ 2.2479734 ]], dtype=float32), y=array([[0.],
       [0.],
       [0.],
       [0...    [1.],
       [2.],
       [2.],
       [2.]]), sample_weight=None)
    328             trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,
    329                              **_joblib_parallel_args(prefer='threads'))(
    330                 delayed(_parallel_build_trees)(
    331                     t, self, X, y, sample_weight, i, len(trees),
    332                     verbose=self.verbose, class_weight=self.class_weight)
--> 333                 for i, t in enumerate(trees))
        i = 9
    334 
    335             # Collect newly grown trees
    336             self.estimators_.extend(trees)
    337 

...........................................................................
/home/aquemy/.local/lib/python2.7/site-packages/sklearn/externals/joblib/parallel.py in __call__(self=Parallel(n_jobs=1), iterable=<generator object <genexpr>>)
    912             # self._original_iterator is None, then this means either
    913             # that pre_dispatch == "all", n_jobs == 1 or that the first batch
    914             # was very quick and its callback already dispatched all the
    915             # remaining jobs.
    916             self._iterating = False
--> 917             if self.dispatch_one_batch(iterator):
        self.dispatch_one_batch = <bound method Parallel.dispatch_one_batch of Parallel(n_jobs=1)>
        iterator = <generator object <genexpr>>
    918                 self._iterating = self._original_iterator is not None
    919 
    920             while self.dispatch_one_batch(iterator):
    921                 pass

...........................................................................
/home/aquemy/.local/lib/python2.7/site-packages/sklearn/externals/joblib/parallel.py in dispatch_one_batch(self=Parallel(n_jobs=1), iterator=<generator object <genexpr>>)
    754                                  self._pickle_cache)
    755             if len(tasks) == 0:
    756                 # No more tasks available in the iterator: tell caller to stop.
    757                 return False
    758             else:
--> 759                 self._dispatch(tasks)
        self._dispatch = <bound method Parallel._dispatch of Parallel(n_jobs=1)>
        tasks = <sklearn.externals.joblib.parallel.BatchedCalls object>
    760                 return True
    761 
    762     def _print(self, msg, msg_args):
    763         """Display the message on stout or stderr depending on verbosity"""

...........................................................................
/home/aquemy/.local/lib/python2.7/site-packages/sklearn/externals/joblib/parallel.py in _dispatch(self=Parallel(n_jobs=1), batch=<sklearn.externals.joblib.parallel.BatchedCalls object>)
    711 
    712         dispatch_timestamp = time.time()
    713         cb = BatchCompletionCallBack(dispatch_timestamp, len(batch), self)
    714         with self._lock:
    715             job_idx = len(self._jobs)
--> 716             job = self._backend.apply_async(batch, callback=cb)
        job = undefined
        self._backend.apply_async = <bound method SequentialBackend.apply_async of <...lib._parallel_backends.SequentialBackend object>>
        batch = <sklearn.externals.joblib.parallel.BatchedCalls object>
        cb = <sklearn.externals.joblib.parallel.BatchCompletionCallBack object>
    717             # A job can complete so quickly than its callback is
    718             # called before we get here, causing self._jobs to
    719             # grow. To ensure correct results ordering, .insert is
    720             # used (rather than .append) in the following line

...........................................................................
/home/aquemy/.local/lib/python2.7/site-packages/sklearn/externals/joblib/_parallel_backends.py in apply_async(self=<sklearn.externals.joblib._parallel_backends.SequentialBackend object>, func=<sklearn.externals.joblib.parallel.BatchedCalls object>, callback=<sklearn.externals.joblib.parallel.BatchCompletionCallBack object>)
    177             raise ValueError('n_jobs == 0 in Parallel has no meaning')
    178         return 1
    179 
    180     def apply_async(self, func, callback=None):
    181         """Schedule a func to be run"""
--> 182         result = ImmediateResult(func)
        result = undefined
        func = <sklearn.externals.joblib.parallel.BatchedCalls object>
    183         if callback:
    184             callback(result)
    185         return result
    186 

...........................................................................
/home/aquemy/.local/lib/python2.7/site-packages/sklearn/externals/joblib/_parallel_backends.py in __init__(self=<sklearn.externals.joblib._parallel_backends.ImmediateResult object>, batch=<sklearn.externals.joblib.parallel.BatchedCalls object>)
    544 
    545 class ImmediateResult(object):
    546     def __init__(self, batch):
    547         # Don't delay the application, to avoid keeping the input
    548         # arguments in memory
--> 549         self.results = batch()
        self.results = undefined
        batch = <sklearn.externals.joblib.parallel.BatchedCalls object>
    550 
    551     def get(self):
    552         return self.results
    553 

...........................................................................
/home/aquemy/.local/lib/python2.7/site-packages/sklearn/externals/joblib/parallel.py in __call__(self=<sklearn.externals.joblib.parallel.BatchedCalls object>)
    220     def __call__(self):
    221         # Set the default nested backend to self._backend but do not set the
    222         # change the default number of processes to -1
    223         with parallel_backend(self._backend, n_jobs=self._n_jobs):
    224             return [func(*args, **kwargs)
--> 225                     for func, args, kwargs in self.items]
        func = <function _parallel_build_trees>
        args = (DecisionTreeClassifier(class_weight=None, criter...=False, random_state=1608637542, splitter='best'), RandomForestClassifier(bootstrap=False, class_we...se, random_state=42, verbose=0, warm_start=False), array([[ 1.1220131 ],
       [-0.7634113 ],
    ....8892994 ],
       [ 2.2479734 ]], dtype=float32), array([[0.],
       [0.],
       [0.],
       [0...    [1.],
       [2.],
       [2.],
       [2.]]), None, 0, 10)
        kwargs = {'class_weight': None, 'verbose': 0}
        self.items = [(<function _parallel_build_trees>, (DecisionTreeClassifier(class_weight=None, criter...=False, random_state=1608637542, splitter='best'), RandomForestClassifier(bootstrap=False, class_we...se, random_state=42, verbose=0, warm_start=False), array([[ 1.1220131 ],
       [-0.7634113 ],
    ....8892994 ],
       [ 2.2479734 ]], dtype=float32), array([[0.],
       [0.],
       [0.],
       [0...    [1.],
       [2.],
       [2.],
       [2.]]), None, 0, 10), {'class_weight': None, 'verbose': 0})]
    226 
    227     def __len__(self):
    228         return self._size
    229 

...........................................................................
/home/aquemy/.local/lib/python2.7/site-packages/sklearn/ensemble/forest.py in _parallel_build_trees(tree=DecisionTreeClassifier(class_weight=None, criter...=False, random_state=1608637542, splitter='best'), forest=RandomForestClassifier(bootstrap=False, class_we...se, random_state=42, verbose=0, warm_start=False), X=array([[ 1.1220131 ],
       [-0.7634113 ],
    ....8892994 ],
       [ 2.2479734 ]], dtype=float32), y=array([[0.],
       [0.],
       [0.],
       [0...    [1.],
       [2.],
       [2.],
       [2.]]), sample_weight=None, tree_idx=0, n_trees=10, verbose=0, class_weight=None)
    116         elif class_weight == 'balanced_subsample':
    117             curr_sample_weight *= compute_sample_weight('balanced', y, indices)
    118 
    119         tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)
    120     else:
--> 121         tree.fit(X, y, sample_weight=sample_weight, check_input=False)
        tree.fit = <bound method DecisionTreeClassifier.fit of Deci...False, random_state=1608637542, splitter='best')>
        X = array([[ 1.1220131 ],
       [-0.7634113 ],
    ....8892994 ],
       [ 2.2479734 ]], dtype=float32)
        y = array([[0.],
       [0.],
       [0.],
       [0...    [1.],
       [2.],
       [2.],
       [2.]])
        sample_weight = None
    122 
    123     return tree
    124 
    125 

...........................................................................
/home/aquemy/.local/lib/python2.7/site-packages/sklearn/tree/tree.py in fit(self=DecisionTreeClassifier(class_weight=None, criter...=False, random_state=1608637542, splitter='best'), X=array([[ 1.1220131 ],
       [-0.7634113 ],
    ....8892994 ],
       [ 2.2479734 ]], dtype=float32), y=array([[0.],
       [0.],
       [0.],
       [0...    [1.],
       [2.],
       [2.],
       [2.]]), sample_weight=None, check_input=False, X_idx_sorted=None)
    796 
    797         super(DecisionTreeClassifier, self).fit(
    798             X, y,
    799             sample_weight=sample_weight,
    800             check_input=check_input,
--> 801             X_idx_sorted=X_idx_sorted)
        X_idx_sorted = None
    802         return self
    803 
    804     def predict_proba(self, X, check_input=True):
    805         """Predict class probabilities of the input samples X.

...........................................................................
/home/aquemy/.local/lib/python2.7/site-packages/sklearn/tree/tree.py in fit(self=DecisionTreeClassifier(class_weight=None, criter...=False, random_state=1608637542, splitter='best'), X=array([[ 1.1220131 ],
       [-0.7634113 ],
    ....8892994 ],
       [ 2.2479734 ]], dtype=float32), y=array([[0.],
       [0.],
       [0.],
       [0...    [1.],
       [2.],
       [2.],
       [2.]]), sample_weight=None, check_input=False, X_idx_sorted=None)
    237         if not 0 <= self.min_weight_fraction_leaf <= 0.5:
    238             raise ValueError("min_weight_fraction_leaf must in [0, 0.5]")
    239         if max_depth <= 0:
    240             raise ValueError("max_depth must be greater than zero. ")
    241         if not (0 < max_features <= self.n_features_):
--> 242             raise ValueError("max_features must be in (0, n_features]")
    243         if not isinstance(max_leaf_nodes, (numbers.Integral, np.integer)):
    244             raise ValueError("max_leaf_nodes must be integral number but was "
    245                              "%r" % max_leaf_nodes)
    246         if -1 < max_leaf_nodes < 2:

ValueError: max_features must be in (0, n_features]
___________________________________________________________________________
Best score: 0.966666666667 (0.0333333333333) [J] | Score: 0.0 (0.0) [J]
Best score: 0.966666666667 (0.0333333333333) [J] | Score: 0.953333333333 (0.0426874949162) [J]
Best score: 0.966666666667 (0.0333333333333) [J] | Score: 0.946666666667 (0.049888765157) [J]
Best score: 0.966666666667 (0.0333333333333) [J] | Score: 0.9 (0.0802772971919) [J]
Best score: 0.966666666667 (0.0333333333333) [J] | Score: 0.96 (0.0442216638714) [J]
Best score: 0.966666666667 (0.0333333333333) [J] | Score: 0.96 (0.0442216638714) [J]
Best score: 0.966666666667 (0.0333333333333) [J] | Score: 0.953333333333 (0.0520683311727) [J]
Best score: 0.966666666667 (0.0333333333333) [J] | Score: 0.913333333333 (0.0669991708075) [J]
Best score: 0.966666666667 (0.0333333333333) [J] | Score: 0.706666666667 (0.0853749898324) [J]
Best score: 0.966666666667 (0.0333333333333) [J] | Score: 0.966666666667 (0.04472135955) [J]
Best score: 0.966666666667 (0.0333333333333) [J] | Score: 0.946666666667 (0.0581186525805) [J]
JoblibValueError
___________________________________________________________________________
...........................................................................
/home/aquemy/dev/dp_hyperparameters/extension/main.py in <module>()
     27 
     28     serializer.serialize_results(scenario, policy)
     29 
     30 if __name__ == "__main__":
     31     args = cli.parse_args()
---> 32     main(args)

...........................................................................
/home/aquemy/dev/dp_hyperparameters/extension/main.py in main(args=Namespace(customize=[(['control', 'seed'], '42')...io='./scenarios/rf_iris_joint.yaml', verbosity=0))
     21         test_size=0.4, 
     22         random_state=scenario['control']['seed']
     23     )
     24 
     25     policy = policies.initiate(scenario['setup']['policy'], config)
---> 26     policy.run(X,y)
        policy.run = <bound method Joint.run of <experiment.policies.joint.Joint object>>
        X = array([[5.1, 3.5, 1.4, 0.2],
       [4.9, 3. , 1....2, 3.4, 5.4, 2.3],
       [5.9, 3. , 5.1, 1.8]])
        y = array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,... 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2])
     27 
     28     serializer.serialize_results(scenario, policy)
     29 
     30 if __name__ == "__main__":

...........................................................................
/home/aquemy/dev/dp_hyperparameters/extension/experiment/policies/joint.py in run(self=<experiment.policies.joint.Joint object>, X=array([[5.1, 3.5, 1.4, 0.2],
       [4.9, 3. , 1....2, 3.4, 5.4, 2.3],
       [5.9, 3. , 5.1, 1.8]]), y=array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,... 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]))
     32             algo=tpe.suggest, 
     33             max_evals=None,
     34             max_time=self.config['time'],     
     35             trials=trials,
     36             show_progressbar=False,
---> 37             verbose=0
     38         )
     39 
     40         best_config = self.context['best_config']
     41         super(Joint, self).display_step_results(best_config)

...........................................................................
/home/aquemy/dev/dp_hyperparameters/extension/hyperopt/fmin.py in fmin(fn=<functools.partial object>, space={'algorithm': {'bootstrap': <hyperopt.pyll.base.Apply object>, 'criterion': <hyperopt.pyll.base.Apply object>, 'max_depth': <hyperopt.pyll.base.Apply object>, 'max_features': <hyperopt.pyll.base.Apply object>, 'max_leaf_nodes': <hyperopt.pyll.base.Apply object>, 'min_samples_split': <hyperopt.pyll.base.Apply object>, 'n_estimators': <hyperopt.pyll.base.Apply object>}, 'pipeline': {'features': <hyperopt.pyll.base.Apply object>, 'normalizer': <hyperopt.pyll.base.Apply object>, 'rebalance': <hyperopt.pyll.base.Apply object>}}, algo=<function suggest>, max_evals=9223372036854775807, max_time=300, trials=<hyperopt.base.Trials object>, rstate=<mtrand.RandomState object>, allow_trials_fmin=True, pass_expr_memo_ctrl=None, catch_eval_exceptions=False, verbose=0, return_argmin=True, points_to_evaluate=None, max_queue_len=1, show_progressbar=False)
    406             pass_expr_memo_ctrl=pass_expr_memo_ctrl,
    407             verbose=verbose,
    408             catch_eval_exceptions=catch_eval_exceptions,
    409             return_argmin=return_argmin,
    410             show_progressbar=show_progressbar,
--> 411             max_time=max_time
        max_time = 300
    412         )
    413 
    414     if trials is None:
    415         if points_to_evaluate is None:

...........................................................................
/home/aquemy/dev/dp_hyperparameters/extension/hyperopt/base.py in fmin(self=<hyperopt.base.Trials object>, fn=<functools.partial object>, space={'algorithm': {'bootstrap': <hyperopt.pyll.base.Apply object>, 'criterion': <hyperopt.pyll.base.Apply object>, 'max_depth': <hyperopt.pyll.base.Apply object>, 'max_features': <hyperopt.pyll.base.Apply object>, 'max_leaf_nodes': <hyperopt.pyll.base.Apply object>, 'min_samples_split': <hyperopt.pyll.base.Apply object>, 'n_estimators': <hyperopt.pyll.base.Apply object>}, 'pipeline': {'features': <hyperopt.pyll.base.Apply object>, 'normalizer': <hyperopt.pyll.base.Apply object>, 'rebalance': <hyperopt.pyll.base.Apply object>}}, algo=<function suggest>, max_evals=9223372036854775807, max_time=300, rstate=<mtrand.RandomState object>, verbose=0, pass_expr_memo_ctrl=None, catch_eval_exceptions=False, return_argmin=True, show_progressbar=False)
    636             verbose=verbose,
    637             allow_trials_fmin=False,  # -- prevent recursion
    638             pass_expr_memo_ctrl=pass_expr_memo_ctrl,
    639             catch_eval_exceptions=catch_eval_exceptions,
    640             return_argmin=return_argmin,
--> 641             show_progressbar=show_progressbar)
        show_progressbar = False
    642 
    643 
    644 def trials_from_docs(docs, validate=True, **kwargs):
    645     """Construct a Trials base class instance from a list of trials documents

...........................................................................
/home/aquemy/dev/dp_hyperparameters/extension/hyperopt/fmin.py in fmin(fn=<functools.partial object>, space={'algorithm': {'bootstrap': <hyperopt.pyll.base.Apply object>, 'criterion': <hyperopt.pyll.base.Apply object>, 'max_depth': <hyperopt.pyll.base.Apply object>, 'max_features': <hyperopt.pyll.base.Apply object>, 'max_leaf_nodes': <hyperopt.pyll.base.Apply object>, 'min_samples_split': <hyperopt.pyll.base.Apply object>, 'n_estimators': <hyperopt.pyll.base.Apply object>}, 'pipeline': {'features': <hyperopt.pyll.base.Apply object>, 'normalizer': <hyperopt.pyll.base.Apply object>, 'rebalance': <hyperopt.pyll.base.Apply object>}}, algo=<function suggest>, max_evals=9223372036854775807, max_time=300, trials=<hyperopt.base.Trials object>, rstate=<mtrand.RandomState object>, allow_trials_fmin=False, pass_expr_memo_ctrl=None, catch_eval_exceptions=False, verbose=0, return_argmin=True, points_to_evaluate=None, max_queue_len=1, show_progressbar=False)
    426                     verbose=verbose,
    427                     max_queue_len=max_queue_len,
    428                     show_progressbar=show_progressbar,
    429                     max_time=max_time)
    430     rval.catch_eval_exceptions = catch_eval_exceptions
--> 431     rval.exhaust()
        rval.exhaust = <bound method FMinIter.exhaust of <hyperopt.fmin.FMinIter object>>
    432     if return_argmin:
    433         return trials.argmin
    434     elif len(trials) > 0:
    435         # Only if there are some succesfull trail runs, return the best point in the evaluation space

...........................................................................
/home/aquemy/dev/dp_hyperparameters/extension/hyperopt/fmin.py in exhaust(self=<hyperopt.fmin.FMinIter object>)
    273             raise StopIteration()
    274         return self.trials
    275 
    276     def exhaust(self):
    277         n_done = len(self.trials)
--> 278         self.run(self.max_evals - n_done, block_until_done=self.asynchronous)
        self.run = <bound method FMinIter.run of <hyperopt.fmin.FMinIter object>>
        self.max_evals = 9223372036854775807
        n_done = 0
        self.asynchronous = False
    279         self.trials.refresh()
    280         return self
    281 
    282 

...........................................................................
/home/aquemy/dev/dp_hyperparameters/extension/hyperopt/fmin.py in run(self=<hyperopt.fmin.FMinIter object>, N=9223372036854775807, block_until_done=False)
    232                     if self.asynchronous:
    233                         # -- wait for workers to fill in the trials
    234                         time.sleep(self.poll_interval_secs)
    235                     else:
    236                         # -- loop over trials and do the jobs directly
--> 237                         self.serial_evaluate()
        self.serial_evaluate = <bound method FMinIter.serial_evaluate of <hyperopt.fmin.FMinIter object>>
    238                     try:
    239                         res = [d['result']['loss'] for d in
    240                                          self.trials.trials if
    241                                          d['result']['status'] == 'ok']

...........................................................................
/home/aquemy/dev/dp_hyperparameters/extension/hyperopt/fmin.py in serial_evaluate(self=<hyperopt.fmin.FMinIter object>, N=-1)
    138                 trial['book_time'] = now
    139                 trial['refresh_time'] = now
    140                 spec = base.spec_from_misc(trial['misc'])
    141                 ctrl = base.Ctrl(self.trials, current_trial=trial)
    142                 try:
--> 143                     result = self.domain.evaluate(spec, ctrl)
        result = undefined
        self.domain.evaluate = <bound method Domain.evaluate of <hyperopt.base.Domain object>>
        spec = {'bootstrap': 0, 'criterion': 0, 'features': 2, 'features_SelectKBest_features__k': 0, 'max_depth': 1, 'max_features': 2, 'max_leaf_nodes': 1, 'min_samples_split': 2, 'n_estimators': 4, 'normalizer': 1, ...}
        ctrl = <hyperopt.base.Ctrl object>
    144                 except Exception as e:
    145                     logger.info('job exception: %s' % str(e))
    146                     trial['state'] = base.JOB_STATE_ERROR
    147                     trial['misc']['error'] = (str(type(e)), str(e))

...........................................................................
/home/aquemy/dev/dp_hyperparameters/extension/hyperopt/base.py in evaluate(self=<hyperopt.base.Domain object>, config={'bootstrap': 0, 'criterion': 0, 'features': 2, 'features_SelectKBest_features__k': 0, 'max_depth': 1, 'max_features': 2, 'max_leaf_nodes': 1, 'min_samples_split': 2, 'n_estimators': 4, 'normalizer': 1, ...}, ctrl=<hyperopt.base.Ctrl object>, attach_attachments=True)
    841             #    or the normal Python part (self.fn)
    842             pyll_rval = pyll.rec_eval(
    843                 self.expr,
    844                 memo=memo,
    845                 print_node_on_error=self.rec_eval_print_node_on_error)
--> 846             rval = self.fn(pyll_rval)
        rval = undefined
        self.fn = <functools.partial object>
        pyll_rval = {'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': 2, 'max_features': 3, 'max_leaf_nodes': 3, 'min_samples_split': 5, 'n_estimators': 100}, 'pipeline': {'features': ('features_SelectKBest', {'features__k': 1}), 'normalizer': ('normalizer_StandardScaler', {'normalizer__with_mean': True, 'normalizer__with_std': True}), 'rebalance': ('rebalance_NoneType', {})}}
    847 
    848         if isinstance(rval, (float, int, np.number)):
    849             dict_rval = {'loss': float(rval), 'status': STATUS_OK}
    850         else:

...........................................................................
/home/aquemy/dev/dp_hyperparameters/extension/experiment/objective.py in objective_joint(wconfig={'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': 2, 'max_features': 3, 'max_leaf_nodes': 3, 'min_samples_split': 5, 'n_estimators': 100}, 'pipeline': {'features': ('features_SelectKBest', {'features__k': 1}), 'normalizer': ('normalizer_StandardScaler', {'normalizer__with_mean': True, 'normalizer__with_std': True}), 'rebalance': ('rebalance_NoneType', {})}}, algorithm='RandomForest', X=array([[5.1, 3.5, 1.4, 0.2],
       [4.9, 3. , 1....2, 3.4, 5.4, 2.3],
       [5.9, 3. , 5.1, 1.8]]), y=array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,... 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]), context={'baseline_score': 0.9466666666666667, 'baseline_score_std': 0.04988876515698587, 'best_config': {'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': 4, 'max_features': 3, 'max_leaf_nodes': 3, 'min_samples_split': 3, 'n_estimators': 10}, 'config_hash': {'algorithm': 'ffb7ff225ce3d3712c96cf87fe42202988ee2eb0', 'config': 'bae32f426be9cd6243523c023944a8c148fe4aeb', 'pipeline': 'd2a68bfda6fcdec4ae0ffc7d7b6a2122bc1cd673'}, 'duration': 0.7115809917449951, 'iteration': 113, 'loss': 0.033333333333333215, 'max_history_score': 0.9666666666666668, 'max_history_score_std': 0.033333333333333326, 'max_history_step': 'joint', 'pipeline': {'features': ('features_NoneType', {}), 'normalizer': ('normalizer_PowerTransformer', {}), 'rebalance': ('rebalance_CondensedNearestNeighbour', {'rebalance__n_neighbors': 2})}, 'score': 0.9666666666666668, ...}, 'history': [{'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': 2, 'max_features': None, 'max_leaf_nodes': 5, 'min_samples_split': 2, 'n_estimators': 75}, 'config_hash': {'algorithm': '3af5b0cce71c8fe2545246ca24ff5bc3dd516e06', 'config': 'db6ac7e6d348155757e4794bb5f88fe2b4f63d50', 'pipeline': '8d59f4b94cef6be9306ed86a22a9570fa670d567'}, 'duration': 1.149928092956543, 'iteration': 0, 'loss': 0.046666666666666634, 'max_history_score': 0.9533333333333334, 'max_history_score_std': 0.059999999999999984, 'max_history_step': 'joint', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 4, 'features__selectkbest__k': 3}), 'normalizer': ('normalizer_StandardScaler', {'normalizer__with_mean': True, 'normalizer__with_std': True}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 6})}, 'score': 0.9533333333333334, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': 1, 'max_features': 2, 'max_leaf_nodes': 2, 'min_samples_split': 5, 'n_estimators': 100}, 'config_hash': {'algorithm': 'e13eb05fd9a62d2f63bbb1c1deff0cd620d5e6ab', 'config': '4db6fb84d85f52659f780e682ffac5712c3d8a94', 'pipeline': '64c9a1ca9d53ae67244bdd942f4db36a3c05218c'}, 'duration': 1.7678282260894775, 'iteration': 1, 'loss': 0.18000000000000005, 'max_history_score': 0.9533333333333334, 'max_history_score_std': 0.059999999999999984, 'max_history_step': 'joint', 'pipeline': {'features': ('features_NoneType', {}), 'normalizer': ('normalizer_PowerTransformer', {}), 'rebalance': ('rebalance_NearMiss', {'rebalance__n_neighbors': 1})}, 'score': 0.82, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': 1, 'max_features': None, 'max_leaf_nodes': None, 'min_samples_split': 5, 'n_estimators': 75}, 'config_hash': {'algorithm': '94b0d7a654c508cc63643f78fe4f0f07e6f07c1e', 'config': '4403c5a85e951938d3c454e961d3a412780722f6', 'pipeline': '3e47444880d8367fbac2faaba2e52a917274aa58'}, 'duration': 0.8397619724273682, 'iteration': 2, 'loss': 0.03333333333333344, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_PCA', {'features__n_components': 3}), 'normalizer': ('normalizer_MinMaxScaler', {}), 'rebalance': ('rebalance_NoneType', {})}, 'score': 0.9666666666666666, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': None, 'max_features': None, 'max_leaf_nodes': 3, 'min_samples_split': 3, 'n_estimators': 75}, 'config_hash': {'algorithm': 'e8332f0a8902bda03bf70e7978cc5d52affb29d3', 'config': 'a064e2df18ab98d44dabcefbc7bed94913f1d0be', 'pipeline': '7eea819c2a8c103c4b1e9e9c1e224aebba95081f'}, 'duration': 0.8501448631286621, 'iteration': 3, 'loss': 0.053333333333333344, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 2, 'features__selectkbest__k': 4}), 'normalizer': ('normalizer_NoneType', {}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 7})}, 'score': 0.9466666666666667, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'entropy', 'max_depth': 3, 'max_features': 3, 'max_leaf_nodes': None, 'min_samples_split': 5, 'n_estimators': 75}, 'config_hash': {'algorithm': '7a4491035bc6bd737fe9a8cda8a79a02d02d5c74', 'config': '0ddb6f5cab3db4dddd7682966a57205f3e329ad4', 'pipeline': 'a9ae03fe38334f6868cbf84cdd3d629d4bbe3fb0'}, 'duration': 1.1026010513305664, 'iteration': 4, 'loss': 0.05999999999999994, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 2, 'features__selectkbest__k': 1}), 'normalizer': ('normalizer_NoneType', {}), 'rebalance': ('rebalance_NoneType', {})}, 'score': 0.9400000000000001, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'gini', 'max_depth': 3, 'max_features': 1, 'max_leaf_nodes': 5, 'min_samples_split': 2, 'n_estimators': 25}, 'config_hash': {'algorithm': '9826d20b2d6a0f559cf7f16450ce7526f07e8434', 'config': '49f25751bca61cdd461a8cbd2923689b642f98ed', 'pipeline': '19b249664c5bf067de1fed4334a296f947ce774a'}, 'duration': 0.35647010803222656, 'iteration': 5, 'loss': 0.046666666666666634, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_NoneType', {}), 'normalizer': ('normalizer_NoneType', {}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 6})}, 'score': 0.9533333333333334, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'gini', 'max_depth': 2, 'max_features': 1, 'max_leaf_nodes': 2, 'min_samples_split': 2, 'n_estimators': 50}, 'config_hash': {'algorithm': '0a4f6fbb07e0f32c6f675489a0fc82eee05bd8e1', 'config': '5c3a2b6f5e63fb45f10e41e0318b354912ec44f6', 'pipeline': 'dc3b9f176f090005e38b142f11d80e93a7dc5d5e'}, 'duration': 0.7213859558105469, 'iteration': 6, 'loss': 0.31333333333333324, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 1, 'features__selectkbest__k': 4}), 'normalizer': ('normalizer_PowerTransformer', {}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 7})}, 'score': 0.6866666666666668, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'entropy', 'max_depth': 4, 'max_features': 3, 'max_leaf_nodes': 5, 'min_samples_split': 5, 'n_estimators': 10}, 'config_hash': {'algorithm': 'b8112b97ecfc10f00a195af661dcc861cac21289', 'config': 'd3b129b397350f1b6572651c67c01de49b4b174c', 'pipeline': '5b0357ed7072c37b3d6f458bb5d49ff7d825f603'}, 'duration': 0.8299109935760498, 'iteration': 7, 'loss': 1.0, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_PCA', {'features__n_components': 2}), 'normalizer': ('normalizer_StandardScaler', {'normalizer__with_mean': True, 'normalizer__with_std': False}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 6})}, 'score': 0.0, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'gini', 'max_depth': 4, 'max_features': None, 'max_leaf_nodes': 2, 'min_samples_split': 5, 'n_estimators': 100}, 'config_hash': {'algorithm': '40ca24df19b8d164d9d098a6bed1ce056fbbb961', 'config': '813bde1108cc3c4b9bfb3a22cbb421bda7eac671', 'pipeline': '74a7b8705a1c22f7dea5e44e4ebda8f1e48add71'}, 'duration': 2.2111589908599854, 'iteration': 8, 'loss': 0.33333333333333326, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_PCA', {'features__n_components': 2}), 'normalizer': ('normalizer_StandardScaler', {'normalizer__with_mean': False, 'normalizer__with_std': True}), 'rebalance': ('rebalance_NearMiss', {'rebalance__n_neighbors': 2})}, 'score': 0.6666666666666667, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'entropy', 'max_depth': 2, 'max_features': 1, 'max_leaf_nodes': 5, 'min_samples_split': 2, 'n_estimators': 100}, 'config_hash': {'algorithm': '331418a5c12cf1453876eef85e9d98fc8e54fa11', 'config': '31930b6860ed406d59bf7e59ba1925d94704bd3b', 'pipeline': '054bef356f90ec6f644ef3ffc688766744db51c2'}, 'duration': 1.0501940250396729, 'iteration': 9, 'loss': 0.053333333333333344, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_SelectKBest', {'features__k': 1}), 'normalizer': ('normalizer_RobustScaler', {'normalizer__quantile_range': (...), 'normalizer__with_centering': True, 'normalizer__with_scaling': True}), 'rebalance': ('rebalance_NearMiss', {'rebalance__n_neighbors': 2})}, 'score': 0.9466666666666667, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'entropy', 'max_depth': 3, 'max_features': None, 'max_leaf_nodes': 3, 'min_samples_split': 2, 'n_estimators': 100}, 'config_hash': {'algorithm': 'dbc1b8126649fe93dce5fbb37e4015b0acfb179e', 'config': '9913cd550615a9d0946ab4a755a8b9f619e442fd', 'pipeline': 'dd626121cea079ebb32e184ca65483ec7a6d7f59'}, 'duration': 1.120617151260376, 'iteration': 10, 'loss': 0.046666666666666634, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 2, 'features__selectkbest__k': 1}), 'normalizer': ('normalizer_MinMaxScaler', {}), 'rebalance': ('rebalance_NoneType', {})}, 'score': 0.9533333333333334, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'gini', 'max_depth': 3, 'max_features': 3, 'max_leaf_nodes': None, 'min_samples_split': 3, 'n_estimators': 75}, 'config_hash': {'algorithm': '34917a130df5a975f78bd7ec1a0c7b1ffdc787a9', 'config': '95fc8cadc088141290b7de9c388977e4685f0108', 'pipeline': '550d10faf2f08db48516cc3501558816d6a99bc0'}, 'duration': 1.4287099838256836, 'iteration': 11, 'loss': 0.19333333333333313, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 3, 'features__selectkbest__k': 4}), 'normalizer': ('normalizer_StandardScaler', {'normalizer__with_mean': False, 'normalizer__with_std': False}), 'rebalance': ('rebalance_CondensedNearestNeighbour', {'rebalance__n_neighbors': 1})}, 'score': 0.8066666666666669, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'entropy', 'max_depth': 1, 'max_features': 2, 'max_leaf_nodes': 5, 'min_samples_split': 2, 'n_estimators': 75}, 'config_hash': {'algorithm': '33f9abb4aee44a395a9f3b3ffa9ce80a8cdaed7c', 'config': '40fa726f0360cf6af55f9b5902d399d02f61f157', 'pipeline': 'cfd1d20841fe2153da762c95e79f95a3fb1e426a'}, 'duration': 1.2978079319000244, 'iteration': 12, 'loss': 0.053333333333333344, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_PCA', {'features__n_components': 4}), 'normalizer': ('normalizer_MinMaxScaler', {}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 7})}, 'score': 0.9466666666666667, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'entropy', 'max_depth': 4, 'max_features': 2, 'max_leaf_nodes': 5, 'min_samples_split': 3, 'n_estimators': 25}, 'config_hash': {'algorithm': '210111ec6562d09eb093e98ed69ef1c662e11a50', 'config': '0fb8e77c7bd9a58b72f1b33c21a59a09a8c676ba', 'pipeline': '5d269d759e0c7926a685a14b263ace8ae0071e4b'}, 'duration': 0.36649012565612793, 'iteration': 13, 'loss': 0.040000000000000036, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 2, 'features__selectkbest__k': 2}), 'normalizer': ('normalizer_NoneType', {}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 7})}, 'score': 0.96, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'entropy', 'max_depth': 3, 'max_features': 1, 'max_leaf_nodes': 5, 'min_samples_split': 2, 'n_estimators': 25}, 'config_hash': {'algorithm': '0e989a03980101fabf79eda3326ed2870e11d690', 'config': 'f4bffd5d8c67a9c5321a9943c4a99678f59a02b7', 'pipeline': '865ee1e3fe8334c3d5ecb2038d5a5d1b3ba50e75'}, 'duration': 0.35639500617980957, 'iteration': 14, 'loss': 0.046666666666666634, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_NoneType', {}), 'normalizer': ('normalizer_RobustScaler', {'normalizer__quantile_range': (...), 'normalizer__with_centering': True, 'normalizer__with_scaling': False}), 'rebalance': ('rebalance_NoneType', {})}, 'score': 0.9533333333333334, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'entropy', 'max_depth': None, 'max_features': 3, 'max_leaf_nodes': 3, 'min_samples_split': 5, 'n_estimators': 10}, 'config_hash': {'algorithm': '9c592e876c13de5e23e6de5b868e01755d63e72e', 'config': '1e6a68cd1eeac886d90724d78b1cb5fb76a3cde4', 'pipeline': '5a1ca4d82f21b7de0d2c918630a42510673fa36e'}, 'duration': 0.18141412734985352, 'iteration': 15, 'loss': 0.046666666666666634, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_SelectKBest', {'features__k': 3}), 'normalizer': ('normalizer_RobustScaler', {'normalizer__quantile_range': (...), 'normalizer__with_centering': True, 'normalizer__with_scaling': True}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 6})}, 'score': 0.9533333333333334, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': 1, 'max_features': None, 'max_leaf_nodes': None, 'min_samples_split': 5, 'n_estimators': 10}, 'config_hash': {'algorithm': '8bed77aef289bfd453b2858bd288ae5ba7160f2b', 'config': '781185bcb8999045de8d489f253a1a1ba4247932', 'pipeline': '1ece7eabedc2be9e5b0a1be65c570d08ffa3eb54'}, 'duration': 0.1636829376220703, 'iteration': 16, 'loss': 0.053333333333333344, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_NoneType', {}), 'normalizer': ('normalizer_NoneType', {}), 'rebalance': ('rebalance_NearMiss', {'rebalance__n_neighbors': 1})}, 'score': 0.9466666666666667, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'gini', 'max_depth': 3, 'max_features': 2, 'max_leaf_nodes': 2, 'min_samples_split': 5, 'n_estimators': 75}, 'config_hash': {'algorithm': '617b97d9ba21d3373bc51ffa9cccf9c6f91a77b3', 'config': '99fb425b4e8c5d80228cab94202252aa25cdf77c', 'pipeline': 'd6242929c3b515c7719e60423023ac604311afc3'}, 'duration': 0.8468999862670898, 'iteration': 17, 'loss': 0.24, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_PCA', {'features__n_components': 4}), 'normalizer': ('normalizer_PowerTransformer', {}), 'rebalance': ('rebalance_NearMiss', {'rebalance__n_neighbors': 2})}, 'score': 0.76, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': 1, 'max_features': 1, 'max_leaf_nodes': 2, 'min_samples_split': 5, 'n_estimators': 50}, 'config_hash': {'algorithm': 'b92d2697cdd4979da443369d6596229ec091626a', 'config': 'c513a3e13281206ad76187dd817b1fff93d54fe1', 'pipeline': 'c4b4f914a3ca8df967cade997a90366d85a371b9'}, 'duration': 0.6724588871002197, 'iteration': 18, 'loss': 0.23333333333333328, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 1, 'features__selectkbest__k': 3}), 'normalizer': ('normalizer_StandardScaler', {'normalizer__with_mean': True, 'normalizer__with_std': True}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 5})}, 'score': 0.7666666666666667, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'entropy', 'max_depth': None, 'max_features': None, 'max_leaf_nodes': 5, 'min_samples_split': 5, 'n_estimators': 10}, 'config_hash': {'algorithm': 'a0115de695e6cca2e81cbfb54df79bf4b43608b1', 'config': 'ba194015e20b5d67770e8c67342c3d8d0d01dc41', 'pipeline': '8d45fabfeb85ffdcabf7076bd0e65fffe97ce928'}, 'duration': 0.19424200057983398, 'iteration': 19, 'loss': 0.08666666666666667, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_PCA', {'features__n_components': 3}), 'normalizer': ('normalizer_NoneType', {}), 'rebalance': ('rebalance_NoneType', {})}, 'score': 0.9133333333333333, ...}, ...], 'history_hash': ['db6ac7e6d348155757e4794bb5f88fe2b4f63d50', '4db6fb84d85f52659f780e682ffac5712c3d8a94', '4403c5a85e951938d3c454e961d3a412780722f6', 'a064e2df18ab98d44dabcefbc7bed94913f1d0be', '0ddb6f5cab3db4dddd7682966a57205f3e329ad4', '49f25751bca61cdd461a8cbd2923689b642f98ed', '5c3a2b6f5e63fb45f10e41e0318b354912ec44f6', 'd3b129b397350f1b6572651c67c01de49b4b174c', '813bde1108cc3c4b9bfb3a22cbb421bda7eac671', '31930b6860ed406d59bf7e59ba1925d94704bd3b', '9913cd550615a9d0946ab4a755a8b9f619e442fd', '95fc8cadc088141290b7de9c388977e4685f0108', '40fa726f0360cf6af55f9b5902d399d02f61f157', '0fb8e77c7bd9a58b72f1b33c21a59a09a8c676ba', 'f4bffd5d8c67a9c5321a9943c4a99678f59a02b7', '1e6a68cd1eeac886d90724d78b1cb5fb76a3cde4', '781185bcb8999045de8d489f253a1a1ba4247932', '99fb425b4e8c5d80228cab94202252aa25cdf77c', 'c513a3e13281206ad76187dd817b1fff93d54fe1', 'ba194015e20b5d67770e8c67342c3d8d0d01dc41', ...], 'history_index': {'00f0493590a2cb5e98a35b29816f8cd9f87f96ec': 208, '013329309d510b94f19d930320402d65f953a847': 39, '038a0f515e2ec894ee8e34f9caa2889eb3ebd5ce': 66, '052ae4bf232b316187b078abae42c2be19e16a00': 111, '05e9258ebf99dd97202167ef1563fa834b0568f1': 242, '0659afebf316aafeb75612fb07081a04c28545ed': 74, '06e7cde9f3556cd01332ce389ad1d8925cd4b4a4': 120, '07ab8a30d853e39a326b7017026a20e94bc45541': 245, '08606f2a0f0a6c9de204020b4632e09fcee0ae56': 168, '09dbd0948e5b8c1b1f0930778babe65c8a81295e': 243, ...}, 'iteration': 274, 'max_history_score': 0.9666666666666668, 'max_history_score_std': 0.033333333333333326, 'max_history_step': 'joint'}, config={'algorithm': 'RandomForest', 'seed': 42, 'time': 300})
    108 
    109 def objective_algo(algo_config, current_pipeline_config, algorithm, X, y, context, config):
    110     return objective(current_pipeline_config, algo_config, algorithm, X, y, context, config, step='algorithm')
    111 
    112 def objective_joint(wconfig, algorithm, X, y, context, config):
--> 113     return objective(wconfig['pipeline'], wconfig['algorithm'], algorithm, X, y, context, config, step='joint')
        wconfig = {'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': 2, 'max_features': 3, 'max_leaf_nodes': 3, 'min_samples_split': 5, 'n_estimators': 100}, 'pipeline': {'features': ('features_SelectKBest', {'features__k': 1}), 'normalizer': ('normalizer_StandardScaler', {'normalizer__with_mean': True, 'normalizer__with_std': True}), 'rebalance': ('rebalance_NoneType', {})}}
        algorithm = 'RandomForest'
        X = array([[5.1, 3.5, 1.4, 0.2],
       [4.9, 3. , 1....2, 3.4, 5.4, 2.3],
       [5.9, 3. , 5.1, 1.8]])
        y = array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,... 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2])
        context = {'baseline_score': 0.9466666666666667, 'baseline_score_std': 0.04988876515698587, 'best_config': {'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': 4, 'max_features': 3, 'max_leaf_nodes': 3, 'min_samples_split': 3, 'n_estimators': 10}, 'config_hash': {'algorithm': 'ffb7ff225ce3d3712c96cf87fe42202988ee2eb0', 'config': 'bae32f426be9cd6243523c023944a8c148fe4aeb', 'pipeline': 'd2a68bfda6fcdec4ae0ffc7d7b6a2122bc1cd673'}, 'duration': 0.7115809917449951, 'iteration': 113, 'loss': 0.033333333333333215, 'max_history_score': 0.9666666666666668, 'max_history_score_std': 0.033333333333333326, 'max_history_step': 'joint', 'pipeline': {'features': ('features_NoneType', {}), 'normalizer': ('normalizer_PowerTransformer', {}), 'rebalance': ('rebalance_CondensedNearestNeighbour', {'rebalance__n_neighbors': 2})}, 'score': 0.9666666666666668, ...}, 'history': [{'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': 2, 'max_features': None, 'max_leaf_nodes': 5, 'min_samples_split': 2, 'n_estimators': 75}, 'config_hash': {'algorithm': '3af5b0cce71c8fe2545246ca24ff5bc3dd516e06', 'config': 'db6ac7e6d348155757e4794bb5f88fe2b4f63d50', 'pipeline': '8d59f4b94cef6be9306ed86a22a9570fa670d567'}, 'duration': 1.149928092956543, 'iteration': 0, 'loss': 0.046666666666666634, 'max_history_score': 0.9533333333333334, 'max_history_score_std': 0.059999999999999984, 'max_history_step': 'joint', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 4, 'features__selectkbest__k': 3}), 'normalizer': ('normalizer_StandardScaler', {'normalizer__with_mean': True, 'normalizer__with_std': True}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 6})}, 'score': 0.9533333333333334, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': 1, 'max_features': 2, 'max_leaf_nodes': 2, 'min_samples_split': 5, 'n_estimators': 100}, 'config_hash': {'algorithm': 'e13eb05fd9a62d2f63bbb1c1deff0cd620d5e6ab', 'config': '4db6fb84d85f52659f780e682ffac5712c3d8a94', 'pipeline': '64c9a1ca9d53ae67244bdd942f4db36a3c05218c'}, 'duration': 1.7678282260894775, 'iteration': 1, 'loss': 0.18000000000000005, 'max_history_score': 0.9533333333333334, 'max_history_score_std': 0.059999999999999984, 'max_history_step': 'joint', 'pipeline': {'features': ('features_NoneType', {}), 'normalizer': ('normalizer_PowerTransformer', {}), 'rebalance': ('rebalance_NearMiss', {'rebalance__n_neighbors': 1})}, 'score': 0.82, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': 1, 'max_features': None, 'max_leaf_nodes': None, 'min_samples_split': 5, 'n_estimators': 75}, 'config_hash': {'algorithm': '94b0d7a654c508cc63643f78fe4f0f07e6f07c1e', 'config': '4403c5a85e951938d3c454e961d3a412780722f6', 'pipeline': '3e47444880d8367fbac2faaba2e52a917274aa58'}, 'duration': 0.8397619724273682, 'iteration': 2, 'loss': 0.03333333333333344, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_PCA', {'features__n_components': 3}), 'normalizer': ('normalizer_MinMaxScaler', {}), 'rebalance': ('rebalance_NoneType', {})}, 'score': 0.9666666666666666, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': None, 'max_features': None, 'max_leaf_nodes': 3, 'min_samples_split': 3, 'n_estimators': 75}, 'config_hash': {'algorithm': 'e8332f0a8902bda03bf70e7978cc5d52affb29d3', 'config': 'a064e2df18ab98d44dabcefbc7bed94913f1d0be', 'pipeline': '7eea819c2a8c103c4b1e9e9c1e224aebba95081f'}, 'duration': 0.8501448631286621, 'iteration': 3, 'loss': 0.053333333333333344, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 2, 'features__selectkbest__k': 4}), 'normalizer': ('normalizer_NoneType', {}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 7})}, 'score': 0.9466666666666667, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'entropy', 'max_depth': 3, 'max_features': 3, 'max_leaf_nodes': None, 'min_samples_split': 5, 'n_estimators': 75}, 'config_hash': {'algorithm': '7a4491035bc6bd737fe9a8cda8a79a02d02d5c74', 'config': '0ddb6f5cab3db4dddd7682966a57205f3e329ad4', 'pipeline': 'a9ae03fe38334f6868cbf84cdd3d629d4bbe3fb0'}, 'duration': 1.1026010513305664, 'iteration': 4, 'loss': 0.05999999999999994, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 2, 'features__selectkbest__k': 1}), 'normalizer': ('normalizer_NoneType', {}), 'rebalance': ('rebalance_NoneType', {})}, 'score': 0.9400000000000001, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'gini', 'max_depth': 3, 'max_features': 1, 'max_leaf_nodes': 5, 'min_samples_split': 2, 'n_estimators': 25}, 'config_hash': {'algorithm': '9826d20b2d6a0f559cf7f16450ce7526f07e8434', 'config': '49f25751bca61cdd461a8cbd2923689b642f98ed', 'pipeline': '19b249664c5bf067de1fed4334a296f947ce774a'}, 'duration': 0.35647010803222656, 'iteration': 5, 'loss': 0.046666666666666634, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_NoneType', {}), 'normalizer': ('normalizer_NoneType', {}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 6})}, 'score': 0.9533333333333334, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'gini', 'max_depth': 2, 'max_features': 1, 'max_leaf_nodes': 2, 'min_samples_split': 2, 'n_estimators': 50}, 'config_hash': {'algorithm': '0a4f6fbb07e0f32c6f675489a0fc82eee05bd8e1', 'config': '5c3a2b6f5e63fb45f10e41e0318b354912ec44f6', 'pipeline': 'dc3b9f176f090005e38b142f11d80e93a7dc5d5e'}, 'duration': 0.7213859558105469, 'iteration': 6, 'loss': 0.31333333333333324, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 1, 'features__selectkbest__k': 4}), 'normalizer': ('normalizer_PowerTransformer', {}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 7})}, 'score': 0.6866666666666668, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'entropy', 'max_depth': 4, 'max_features': 3, 'max_leaf_nodes': 5, 'min_samples_split': 5, 'n_estimators': 10}, 'config_hash': {'algorithm': 'b8112b97ecfc10f00a195af661dcc861cac21289', 'config': 'd3b129b397350f1b6572651c67c01de49b4b174c', 'pipeline': '5b0357ed7072c37b3d6f458bb5d49ff7d825f603'}, 'duration': 0.8299109935760498, 'iteration': 7, 'loss': 1.0, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_PCA', {'features__n_components': 2}), 'normalizer': ('normalizer_StandardScaler', {'normalizer__with_mean': True, 'normalizer__with_std': False}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 6})}, 'score': 0.0, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'gini', 'max_depth': 4, 'max_features': None, 'max_leaf_nodes': 2, 'min_samples_split': 5, 'n_estimators': 100}, 'config_hash': {'algorithm': '40ca24df19b8d164d9d098a6bed1ce056fbbb961', 'config': '813bde1108cc3c4b9bfb3a22cbb421bda7eac671', 'pipeline': '74a7b8705a1c22f7dea5e44e4ebda8f1e48add71'}, 'duration': 2.2111589908599854, 'iteration': 8, 'loss': 0.33333333333333326, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_PCA', {'features__n_components': 2}), 'normalizer': ('normalizer_StandardScaler', {'normalizer__with_mean': False, 'normalizer__with_std': True}), 'rebalance': ('rebalance_NearMiss', {'rebalance__n_neighbors': 2})}, 'score': 0.6666666666666667, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'entropy', 'max_depth': 2, 'max_features': 1, 'max_leaf_nodes': 5, 'min_samples_split': 2, 'n_estimators': 100}, 'config_hash': {'algorithm': '331418a5c12cf1453876eef85e9d98fc8e54fa11', 'config': '31930b6860ed406d59bf7e59ba1925d94704bd3b', 'pipeline': '054bef356f90ec6f644ef3ffc688766744db51c2'}, 'duration': 1.0501940250396729, 'iteration': 9, 'loss': 0.053333333333333344, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_SelectKBest', {'features__k': 1}), 'normalizer': ('normalizer_RobustScaler', {'normalizer__quantile_range': (...), 'normalizer__with_centering': True, 'normalizer__with_scaling': True}), 'rebalance': ('rebalance_NearMiss', {'rebalance__n_neighbors': 2})}, 'score': 0.9466666666666667, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'entropy', 'max_depth': 3, 'max_features': None, 'max_leaf_nodes': 3, 'min_samples_split': 2, 'n_estimators': 100}, 'config_hash': {'algorithm': 'dbc1b8126649fe93dce5fbb37e4015b0acfb179e', 'config': '9913cd550615a9d0946ab4a755a8b9f619e442fd', 'pipeline': 'dd626121cea079ebb32e184ca65483ec7a6d7f59'}, 'duration': 1.120617151260376, 'iteration': 10, 'loss': 0.046666666666666634, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 2, 'features__selectkbest__k': 1}), 'normalizer': ('normalizer_MinMaxScaler', {}), 'rebalance': ('rebalance_NoneType', {})}, 'score': 0.9533333333333334, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'gini', 'max_depth': 3, 'max_features': 3, 'max_leaf_nodes': None, 'min_samples_split': 3, 'n_estimators': 75}, 'config_hash': {'algorithm': '34917a130df5a975f78bd7ec1a0c7b1ffdc787a9', 'config': '95fc8cadc088141290b7de9c388977e4685f0108', 'pipeline': '550d10faf2f08db48516cc3501558816d6a99bc0'}, 'duration': 1.4287099838256836, 'iteration': 11, 'loss': 0.19333333333333313, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 3, 'features__selectkbest__k': 4}), 'normalizer': ('normalizer_StandardScaler', {'normalizer__with_mean': False, 'normalizer__with_std': False}), 'rebalance': ('rebalance_CondensedNearestNeighbour', {'rebalance__n_neighbors': 1})}, 'score': 0.8066666666666669, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'entropy', 'max_depth': 1, 'max_features': 2, 'max_leaf_nodes': 5, 'min_samples_split': 2, 'n_estimators': 75}, 'config_hash': {'algorithm': '33f9abb4aee44a395a9f3b3ffa9ce80a8cdaed7c', 'config': '40fa726f0360cf6af55f9b5902d399d02f61f157', 'pipeline': 'cfd1d20841fe2153da762c95e79f95a3fb1e426a'}, 'duration': 1.2978079319000244, 'iteration': 12, 'loss': 0.053333333333333344, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_PCA', {'features__n_components': 4}), 'normalizer': ('normalizer_MinMaxScaler', {}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 7})}, 'score': 0.9466666666666667, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'entropy', 'max_depth': 4, 'max_features': 2, 'max_leaf_nodes': 5, 'min_samples_split': 3, 'n_estimators': 25}, 'config_hash': {'algorithm': '210111ec6562d09eb093e98ed69ef1c662e11a50', 'config': '0fb8e77c7bd9a58b72f1b33c21a59a09a8c676ba', 'pipeline': '5d269d759e0c7926a685a14b263ace8ae0071e4b'}, 'duration': 0.36649012565612793, 'iteration': 13, 'loss': 0.040000000000000036, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 2, 'features__selectkbest__k': 2}), 'normalizer': ('normalizer_NoneType', {}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 7})}, 'score': 0.96, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'entropy', 'max_depth': 3, 'max_features': 1, 'max_leaf_nodes': 5, 'min_samples_split': 2, 'n_estimators': 25}, 'config_hash': {'algorithm': '0e989a03980101fabf79eda3326ed2870e11d690', 'config': 'f4bffd5d8c67a9c5321a9943c4a99678f59a02b7', 'pipeline': '865ee1e3fe8334c3d5ecb2038d5a5d1b3ba50e75'}, 'duration': 0.35639500617980957, 'iteration': 14, 'loss': 0.046666666666666634, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_NoneType', {}), 'normalizer': ('normalizer_RobustScaler', {'normalizer__quantile_range': (...), 'normalizer__with_centering': True, 'normalizer__with_scaling': False}), 'rebalance': ('rebalance_NoneType', {})}, 'score': 0.9533333333333334, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'entropy', 'max_depth': None, 'max_features': 3, 'max_leaf_nodes': 3, 'min_samples_split': 5, 'n_estimators': 10}, 'config_hash': {'algorithm': '9c592e876c13de5e23e6de5b868e01755d63e72e', 'config': '1e6a68cd1eeac886d90724d78b1cb5fb76a3cde4', 'pipeline': '5a1ca4d82f21b7de0d2c918630a42510673fa36e'}, 'duration': 0.18141412734985352, 'iteration': 15, 'loss': 0.046666666666666634, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_SelectKBest', {'features__k': 3}), 'normalizer': ('normalizer_RobustScaler', {'normalizer__quantile_range': (...), 'normalizer__with_centering': True, 'normalizer__with_scaling': True}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 6})}, 'score': 0.9533333333333334, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': 1, 'max_features': None, 'max_leaf_nodes': None, 'min_samples_split': 5, 'n_estimators': 10}, 'config_hash': {'algorithm': '8bed77aef289bfd453b2858bd288ae5ba7160f2b', 'config': '781185bcb8999045de8d489f253a1a1ba4247932', 'pipeline': '1ece7eabedc2be9e5b0a1be65c570d08ffa3eb54'}, 'duration': 0.1636829376220703, 'iteration': 16, 'loss': 0.053333333333333344, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_NoneType', {}), 'normalizer': ('normalizer_NoneType', {}), 'rebalance': ('rebalance_NearMiss', {'rebalance__n_neighbors': 1})}, 'score': 0.9466666666666667, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'gini', 'max_depth': 3, 'max_features': 2, 'max_leaf_nodes': 2, 'min_samples_split': 5, 'n_estimators': 75}, 'config_hash': {'algorithm': '617b97d9ba21d3373bc51ffa9cccf9c6f91a77b3', 'config': '99fb425b4e8c5d80228cab94202252aa25cdf77c', 'pipeline': 'd6242929c3b515c7719e60423023ac604311afc3'}, 'duration': 0.8468999862670898, 'iteration': 17, 'loss': 0.24, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_PCA', {'features__n_components': 4}), 'normalizer': ('normalizer_PowerTransformer', {}), 'rebalance': ('rebalance_NearMiss', {'rebalance__n_neighbors': 2})}, 'score': 0.76, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': 1, 'max_features': 1, 'max_leaf_nodes': 2, 'min_samples_split': 5, 'n_estimators': 50}, 'config_hash': {'algorithm': 'b92d2697cdd4979da443369d6596229ec091626a', 'config': 'c513a3e13281206ad76187dd817b1fff93d54fe1', 'pipeline': 'c4b4f914a3ca8df967cade997a90366d85a371b9'}, 'duration': 0.6724588871002197, 'iteration': 18, 'loss': 0.23333333333333328, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 1, 'features__selectkbest__k': 3}), 'normalizer': ('normalizer_StandardScaler', {'normalizer__with_mean': True, 'normalizer__with_std': True}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 5})}, 'score': 0.7666666666666667, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'entropy', 'max_depth': None, 'max_features': None, 'max_leaf_nodes': 5, 'min_samples_split': 5, 'n_estimators': 10}, 'config_hash': {'algorithm': 'a0115de695e6cca2e81cbfb54df79bf4b43608b1', 'config': 'ba194015e20b5d67770e8c67342c3d8d0d01dc41', 'pipeline': '8d45fabfeb85ffdcabf7076bd0e65fffe97ce928'}, 'duration': 0.19424200057983398, 'iteration': 19, 'loss': 0.08666666666666667, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_PCA', {'features__n_components': 3}), 'normalizer': ('normalizer_NoneType', {}), 'rebalance': ('rebalance_NoneType', {})}, 'score': 0.9133333333333333, ...}, ...], 'history_hash': ['db6ac7e6d348155757e4794bb5f88fe2b4f63d50', '4db6fb84d85f52659f780e682ffac5712c3d8a94', '4403c5a85e951938d3c454e961d3a412780722f6', 'a064e2df18ab98d44dabcefbc7bed94913f1d0be', '0ddb6f5cab3db4dddd7682966a57205f3e329ad4', '49f25751bca61cdd461a8cbd2923689b642f98ed', '5c3a2b6f5e63fb45f10e41e0318b354912ec44f6', 'd3b129b397350f1b6572651c67c01de49b4b174c', '813bde1108cc3c4b9bfb3a22cbb421bda7eac671', '31930b6860ed406d59bf7e59ba1925d94704bd3b', '9913cd550615a9d0946ab4a755a8b9f619e442fd', '95fc8cadc088141290b7de9c388977e4685f0108', '40fa726f0360cf6af55f9b5902d399d02f61f157', '0fb8e77c7bd9a58b72f1b33c21a59a09a8c676ba', 'f4bffd5d8c67a9c5321a9943c4a99678f59a02b7', '1e6a68cd1eeac886d90724d78b1cb5fb76a3cde4', '781185bcb8999045de8d489f253a1a1ba4247932', '99fb425b4e8c5d80228cab94202252aa25cdf77c', 'c513a3e13281206ad76187dd817b1fff93d54fe1', 'ba194015e20b5d67770e8c67342c3d8d0d01dc41', ...], 'history_index': {'00f0493590a2cb5e98a35b29816f8cd9f87f96ec': 208, '013329309d510b94f19d930320402d65f953a847': 39, '038a0f515e2ec894ee8e34f9caa2889eb3ebd5ce': 66, '052ae4bf232b316187b078abae42c2be19e16a00': 111, '05e9258ebf99dd97202167ef1563fa834b0568f1': 242, '0659afebf316aafeb75612fb07081a04c28545ed': 74, '06e7cde9f3556cd01332ce389ad1d8925cd4b4a4': 120, '07ab8a30d853e39a326b7017026a20e94bc45541': 245, '08606f2a0f0a6c9de204020b4632e09fcee0ae56': 168, '09dbd0948e5b8c1b1f0930778babe65c8a81295e': 243, ...}, 'iteration': 274, 'max_history_score': 0.9666666666666668, 'max_history_score_std': 0.033333333333333326, 'max_history_step': 'joint'}
        config = {'algorithm': 'RandomForest', 'seed': 42, 'time': 300}
    114 
    115 
    116 def get_baseline_score(algorithm, X, y, seed):
    117     pipeline, _ = pipeline_conf_to_full_pipeline(

...........................................................................
/home/aquemy/dev/dp_hyperparameters/extension/experiment/objective.py in objective(pipeline_config={'features': ('features_SelectKBest', {'features__k': 1}), 'normalizer': ('normalizer_StandardScaler', {'normalizer__with_mean': True, 'normalizer__with_std': True}), 'rebalance': ('rebalance_NoneType', {})}, algo_config={'bootstrap': True, 'criterion': 'gini', 'max_depth': 2, 'max_features': 3, 'max_leaf_nodes': 3, 'min_samples_split': 5, 'n_estimators': 100}, algorithm='RandomForest', X=array([[5.1, 3.5, 1.4, 0.2],
       [4.9, 3. , 1....2, 3.4, 5.4, 2.3],
       [5.9, 3. , 5.1, 1.8]]), y=array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,... 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]), context={'baseline_score': 0.9466666666666667, 'baseline_score_std': 0.04988876515698587, 'best_config': {'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': 4, 'max_features': 3, 'max_leaf_nodes': 3, 'min_samples_split': 3, 'n_estimators': 10}, 'config_hash': {'algorithm': 'ffb7ff225ce3d3712c96cf87fe42202988ee2eb0', 'config': 'bae32f426be9cd6243523c023944a8c148fe4aeb', 'pipeline': 'd2a68bfda6fcdec4ae0ffc7d7b6a2122bc1cd673'}, 'duration': 0.7115809917449951, 'iteration': 113, 'loss': 0.033333333333333215, 'max_history_score': 0.9666666666666668, 'max_history_score_std': 0.033333333333333326, 'max_history_step': 'joint', 'pipeline': {'features': ('features_NoneType', {}), 'normalizer': ('normalizer_PowerTransformer', {}), 'rebalance': ('rebalance_CondensedNearestNeighbour', {'rebalance__n_neighbors': 2})}, 'score': 0.9666666666666668, ...}, 'history': [{'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': 2, 'max_features': None, 'max_leaf_nodes': 5, 'min_samples_split': 2, 'n_estimators': 75}, 'config_hash': {'algorithm': '3af5b0cce71c8fe2545246ca24ff5bc3dd516e06', 'config': 'db6ac7e6d348155757e4794bb5f88fe2b4f63d50', 'pipeline': '8d59f4b94cef6be9306ed86a22a9570fa670d567'}, 'duration': 1.149928092956543, 'iteration': 0, 'loss': 0.046666666666666634, 'max_history_score': 0.9533333333333334, 'max_history_score_std': 0.059999999999999984, 'max_history_step': 'joint', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 4, 'features__selectkbest__k': 3}), 'normalizer': ('normalizer_StandardScaler', {'normalizer__with_mean': True, 'normalizer__with_std': True}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 6})}, 'score': 0.9533333333333334, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': 1, 'max_features': 2, 'max_leaf_nodes': 2, 'min_samples_split': 5, 'n_estimators': 100}, 'config_hash': {'algorithm': 'e13eb05fd9a62d2f63bbb1c1deff0cd620d5e6ab', 'config': '4db6fb84d85f52659f780e682ffac5712c3d8a94', 'pipeline': '64c9a1ca9d53ae67244bdd942f4db36a3c05218c'}, 'duration': 1.7678282260894775, 'iteration': 1, 'loss': 0.18000000000000005, 'max_history_score': 0.9533333333333334, 'max_history_score_std': 0.059999999999999984, 'max_history_step': 'joint', 'pipeline': {'features': ('features_NoneType', {}), 'normalizer': ('normalizer_PowerTransformer', {}), 'rebalance': ('rebalance_NearMiss', {'rebalance__n_neighbors': 1})}, 'score': 0.82, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': 1, 'max_features': None, 'max_leaf_nodes': None, 'min_samples_split': 5, 'n_estimators': 75}, 'config_hash': {'algorithm': '94b0d7a654c508cc63643f78fe4f0f07e6f07c1e', 'config': '4403c5a85e951938d3c454e961d3a412780722f6', 'pipeline': '3e47444880d8367fbac2faaba2e52a917274aa58'}, 'duration': 0.8397619724273682, 'iteration': 2, 'loss': 0.03333333333333344, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_PCA', {'features__n_components': 3}), 'normalizer': ('normalizer_MinMaxScaler', {}), 'rebalance': ('rebalance_NoneType', {})}, 'score': 0.9666666666666666, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': None, 'max_features': None, 'max_leaf_nodes': 3, 'min_samples_split': 3, 'n_estimators': 75}, 'config_hash': {'algorithm': 'e8332f0a8902bda03bf70e7978cc5d52affb29d3', 'config': 'a064e2df18ab98d44dabcefbc7bed94913f1d0be', 'pipeline': '7eea819c2a8c103c4b1e9e9c1e224aebba95081f'}, 'duration': 0.8501448631286621, 'iteration': 3, 'loss': 0.053333333333333344, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 2, 'features__selectkbest__k': 4}), 'normalizer': ('normalizer_NoneType', {}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 7})}, 'score': 0.9466666666666667, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'entropy', 'max_depth': 3, 'max_features': 3, 'max_leaf_nodes': None, 'min_samples_split': 5, 'n_estimators': 75}, 'config_hash': {'algorithm': '7a4491035bc6bd737fe9a8cda8a79a02d02d5c74', 'config': '0ddb6f5cab3db4dddd7682966a57205f3e329ad4', 'pipeline': 'a9ae03fe38334f6868cbf84cdd3d629d4bbe3fb0'}, 'duration': 1.1026010513305664, 'iteration': 4, 'loss': 0.05999999999999994, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 2, 'features__selectkbest__k': 1}), 'normalizer': ('normalizer_NoneType', {}), 'rebalance': ('rebalance_NoneType', {})}, 'score': 0.9400000000000001, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'gini', 'max_depth': 3, 'max_features': 1, 'max_leaf_nodes': 5, 'min_samples_split': 2, 'n_estimators': 25}, 'config_hash': {'algorithm': '9826d20b2d6a0f559cf7f16450ce7526f07e8434', 'config': '49f25751bca61cdd461a8cbd2923689b642f98ed', 'pipeline': '19b249664c5bf067de1fed4334a296f947ce774a'}, 'duration': 0.35647010803222656, 'iteration': 5, 'loss': 0.046666666666666634, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_NoneType', {}), 'normalizer': ('normalizer_NoneType', {}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 6})}, 'score': 0.9533333333333334, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'gini', 'max_depth': 2, 'max_features': 1, 'max_leaf_nodes': 2, 'min_samples_split': 2, 'n_estimators': 50}, 'config_hash': {'algorithm': '0a4f6fbb07e0f32c6f675489a0fc82eee05bd8e1', 'config': '5c3a2b6f5e63fb45f10e41e0318b354912ec44f6', 'pipeline': 'dc3b9f176f090005e38b142f11d80e93a7dc5d5e'}, 'duration': 0.7213859558105469, 'iteration': 6, 'loss': 0.31333333333333324, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 1, 'features__selectkbest__k': 4}), 'normalizer': ('normalizer_PowerTransformer', {}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 7})}, 'score': 0.6866666666666668, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'entropy', 'max_depth': 4, 'max_features': 3, 'max_leaf_nodes': 5, 'min_samples_split': 5, 'n_estimators': 10}, 'config_hash': {'algorithm': 'b8112b97ecfc10f00a195af661dcc861cac21289', 'config': 'd3b129b397350f1b6572651c67c01de49b4b174c', 'pipeline': '5b0357ed7072c37b3d6f458bb5d49ff7d825f603'}, 'duration': 0.8299109935760498, 'iteration': 7, 'loss': 1.0, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_PCA', {'features__n_components': 2}), 'normalizer': ('normalizer_StandardScaler', {'normalizer__with_mean': True, 'normalizer__with_std': False}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 6})}, 'score': 0.0, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'gini', 'max_depth': 4, 'max_features': None, 'max_leaf_nodes': 2, 'min_samples_split': 5, 'n_estimators': 100}, 'config_hash': {'algorithm': '40ca24df19b8d164d9d098a6bed1ce056fbbb961', 'config': '813bde1108cc3c4b9bfb3a22cbb421bda7eac671', 'pipeline': '74a7b8705a1c22f7dea5e44e4ebda8f1e48add71'}, 'duration': 2.2111589908599854, 'iteration': 8, 'loss': 0.33333333333333326, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_PCA', {'features__n_components': 2}), 'normalizer': ('normalizer_StandardScaler', {'normalizer__with_mean': False, 'normalizer__with_std': True}), 'rebalance': ('rebalance_NearMiss', {'rebalance__n_neighbors': 2})}, 'score': 0.6666666666666667, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'entropy', 'max_depth': 2, 'max_features': 1, 'max_leaf_nodes': 5, 'min_samples_split': 2, 'n_estimators': 100}, 'config_hash': {'algorithm': '331418a5c12cf1453876eef85e9d98fc8e54fa11', 'config': '31930b6860ed406d59bf7e59ba1925d94704bd3b', 'pipeline': '054bef356f90ec6f644ef3ffc688766744db51c2'}, 'duration': 1.0501940250396729, 'iteration': 9, 'loss': 0.053333333333333344, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_SelectKBest', {'features__k': 1}), 'normalizer': ('normalizer_RobustScaler', {'normalizer__quantile_range': (...), 'normalizer__with_centering': True, 'normalizer__with_scaling': True}), 'rebalance': ('rebalance_NearMiss', {'rebalance__n_neighbors': 2})}, 'score': 0.9466666666666667, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'entropy', 'max_depth': 3, 'max_features': None, 'max_leaf_nodes': 3, 'min_samples_split': 2, 'n_estimators': 100}, 'config_hash': {'algorithm': 'dbc1b8126649fe93dce5fbb37e4015b0acfb179e', 'config': '9913cd550615a9d0946ab4a755a8b9f619e442fd', 'pipeline': 'dd626121cea079ebb32e184ca65483ec7a6d7f59'}, 'duration': 1.120617151260376, 'iteration': 10, 'loss': 0.046666666666666634, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 2, 'features__selectkbest__k': 1}), 'normalizer': ('normalizer_MinMaxScaler', {}), 'rebalance': ('rebalance_NoneType', {})}, 'score': 0.9533333333333334, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'gini', 'max_depth': 3, 'max_features': 3, 'max_leaf_nodes': None, 'min_samples_split': 3, 'n_estimators': 75}, 'config_hash': {'algorithm': '34917a130df5a975f78bd7ec1a0c7b1ffdc787a9', 'config': '95fc8cadc088141290b7de9c388977e4685f0108', 'pipeline': '550d10faf2f08db48516cc3501558816d6a99bc0'}, 'duration': 1.4287099838256836, 'iteration': 11, 'loss': 0.19333333333333313, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 3, 'features__selectkbest__k': 4}), 'normalizer': ('normalizer_StandardScaler', {'normalizer__with_mean': False, 'normalizer__with_std': False}), 'rebalance': ('rebalance_CondensedNearestNeighbour', {'rebalance__n_neighbors': 1})}, 'score': 0.8066666666666669, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'entropy', 'max_depth': 1, 'max_features': 2, 'max_leaf_nodes': 5, 'min_samples_split': 2, 'n_estimators': 75}, 'config_hash': {'algorithm': '33f9abb4aee44a395a9f3b3ffa9ce80a8cdaed7c', 'config': '40fa726f0360cf6af55f9b5902d399d02f61f157', 'pipeline': 'cfd1d20841fe2153da762c95e79f95a3fb1e426a'}, 'duration': 1.2978079319000244, 'iteration': 12, 'loss': 0.053333333333333344, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_PCA', {'features__n_components': 4}), 'normalizer': ('normalizer_MinMaxScaler', {}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 7})}, 'score': 0.9466666666666667, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'entropy', 'max_depth': 4, 'max_features': 2, 'max_leaf_nodes': 5, 'min_samples_split': 3, 'n_estimators': 25}, 'config_hash': {'algorithm': '210111ec6562d09eb093e98ed69ef1c662e11a50', 'config': '0fb8e77c7bd9a58b72f1b33c21a59a09a8c676ba', 'pipeline': '5d269d759e0c7926a685a14b263ace8ae0071e4b'}, 'duration': 0.36649012565612793, 'iteration': 13, 'loss': 0.040000000000000036, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 2, 'features__selectkbest__k': 2}), 'normalizer': ('normalizer_NoneType', {}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 7})}, 'score': 0.96, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'entropy', 'max_depth': 3, 'max_features': 1, 'max_leaf_nodes': 5, 'min_samples_split': 2, 'n_estimators': 25}, 'config_hash': {'algorithm': '0e989a03980101fabf79eda3326ed2870e11d690', 'config': 'f4bffd5d8c67a9c5321a9943c4a99678f59a02b7', 'pipeline': '865ee1e3fe8334c3d5ecb2038d5a5d1b3ba50e75'}, 'duration': 0.35639500617980957, 'iteration': 14, 'loss': 0.046666666666666634, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_NoneType', {}), 'normalizer': ('normalizer_RobustScaler', {'normalizer__quantile_range': (...), 'normalizer__with_centering': True, 'normalizer__with_scaling': False}), 'rebalance': ('rebalance_NoneType', {})}, 'score': 0.9533333333333334, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'entropy', 'max_depth': None, 'max_features': 3, 'max_leaf_nodes': 3, 'min_samples_split': 5, 'n_estimators': 10}, 'config_hash': {'algorithm': '9c592e876c13de5e23e6de5b868e01755d63e72e', 'config': '1e6a68cd1eeac886d90724d78b1cb5fb76a3cde4', 'pipeline': '5a1ca4d82f21b7de0d2c918630a42510673fa36e'}, 'duration': 0.18141412734985352, 'iteration': 15, 'loss': 0.046666666666666634, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_SelectKBest', {'features__k': 3}), 'normalizer': ('normalizer_RobustScaler', {'normalizer__quantile_range': (...), 'normalizer__with_centering': True, 'normalizer__with_scaling': True}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 6})}, 'score': 0.9533333333333334, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': 1, 'max_features': None, 'max_leaf_nodes': None, 'min_samples_split': 5, 'n_estimators': 10}, 'config_hash': {'algorithm': '8bed77aef289bfd453b2858bd288ae5ba7160f2b', 'config': '781185bcb8999045de8d489f253a1a1ba4247932', 'pipeline': '1ece7eabedc2be9e5b0a1be65c570d08ffa3eb54'}, 'duration': 0.1636829376220703, 'iteration': 16, 'loss': 0.053333333333333344, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_NoneType', {}), 'normalizer': ('normalizer_NoneType', {}), 'rebalance': ('rebalance_NearMiss', {'rebalance__n_neighbors': 1})}, 'score': 0.9466666666666667, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'gini', 'max_depth': 3, 'max_features': 2, 'max_leaf_nodes': 2, 'min_samples_split': 5, 'n_estimators': 75}, 'config_hash': {'algorithm': '617b97d9ba21d3373bc51ffa9cccf9c6f91a77b3', 'config': '99fb425b4e8c5d80228cab94202252aa25cdf77c', 'pipeline': 'd6242929c3b515c7719e60423023ac604311afc3'}, 'duration': 0.8468999862670898, 'iteration': 17, 'loss': 0.24, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_PCA', {'features__n_components': 4}), 'normalizer': ('normalizer_PowerTransformer', {}), 'rebalance': ('rebalance_NearMiss', {'rebalance__n_neighbors': 2})}, 'score': 0.76, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': 1, 'max_features': 1, 'max_leaf_nodes': 2, 'min_samples_split': 5, 'n_estimators': 50}, 'config_hash': {'algorithm': 'b92d2697cdd4979da443369d6596229ec091626a', 'config': 'c513a3e13281206ad76187dd817b1fff93d54fe1', 'pipeline': 'c4b4f914a3ca8df967cade997a90366d85a371b9'}, 'duration': 0.6724588871002197, 'iteration': 18, 'loss': 0.23333333333333328, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 1, 'features__selectkbest__k': 3}), 'normalizer': ('normalizer_StandardScaler', {'normalizer__with_mean': True, 'normalizer__with_std': True}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 5})}, 'score': 0.7666666666666667, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'entropy', 'max_depth': None, 'max_features': None, 'max_leaf_nodes': 5, 'min_samples_split': 5, 'n_estimators': 10}, 'config_hash': {'algorithm': 'a0115de695e6cca2e81cbfb54df79bf4b43608b1', 'config': 'ba194015e20b5d67770e8c67342c3d8d0d01dc41', 'pipeline': '8d45fabfeb85ffdcabf7076bd0e65fffe97ce928'}, 'duration': 0.19424200057983398, 'iteration': 19, 'loss': 0.08666666666666667, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_PCA', {'features__n_components': 3}), 'normalizer': ('normalizer_NoneType', {}), 'rebalance': ('rebalance_NoneType', {})}, 'score': 0.9133333333333333, ...}, ...], 'history_hash': ['db6ac7e6d348155757e4794bb5f88fe2b4f63d50', '4db6fb84d85f52659f780e682ffac5712c3d8a94', '4403c5a85e951938d3c454e961d3a412780722f6', 'a064e2df18ab98d44dabcefbc7bed94913f1d0be', '0ddb6f5cab3db4dddd7682966a57205f3e329ad4', '49f25751bca61cdd461a8cbd2923689b642f98ed', '5c3a2b6f5e63fb45f10e41e0318b354912ec44f6', 'd3b129b397350f1b6572651c67c01de49b4b174c', '813bde1108cc3c4b9bfb3a22cbb421bda7eac671', '31930b6860ed406d59bf7e59ba1925d94704bd3b', '9913cd550615a9d0946ab4a755a8b9f619e442fd', '95fc8cadc088141290b7de9c388977e4685f0108', '40fa726f0360cf6af55f9b5902d399d02f61f157', '0fb8e77c7bd9a58b72f1b33c21a59a09a8c676ba', 'f4bffd5d8c67a9c5321a9943c4a99678f59a02b7', '1e6a68cd1eeac886d90724d78b1cb5fb76a3cde4', '781185bcb8999045de8d489f253a1a1ba4247932', '99fb425b4e8c5d80228cab94202252aa25cdf77c', 'c513a3e13281206ad76187dd817b1fff93d54fe1', 'ba194015e20b5d67770e8c67342c3d8d0d01dc41', ...], 'history_index': {'00f0493590a2cb5e98a35b29816f8cd9f87f96ec': 208, '013329309d510b94f19d930320402d65f953a847': 39, '038a0f515e2ec894ee8e34f9caa2889eb3ebd5ce': 66, '052ae4bf232b316187b078abae42c2be19e16a00': 111, '05e9258ebf99dd97202167ef1563fa834b0568f1': 242, '0659afebf316aafeb75612fb07081a04c28545ed': 74, '06e7cde9f3556cd01332ce389ad1d8925cd4b4a4': 120, '07ab8a30d853e39a326b7017026a20e94bc45541': 245, '08606f2a0f0a6c9de204020b4632e09fcee0ae56': 168, '09dbd0948e5b8c1b1f0930778babe65c8a81295e': 243, ...}, 'iteration': 274, 'max_history_score': 0.9666666666666668, 'max_history_score_std': 0.033333333333333326, 'max_history_step': 'joint'}, config={'algorithm': 'RandomForest', 'seed': 42, 'time': 300}, step='joint')
     45                 y,
     46                 cv=10,
     47                 n_jobs=-1,
     48                 return_estimator=False,
     49                 return_train_score=False,
---> 50                 verbose=0)
     51         score = np.mean(scores['test_score'])
     52         std = np.std(scores['test_score'])
     53         status = STATUS_OK
     54     except Exception as e:

...........................................................................
/home/aquemy/.local/lib/python2.7/site-packages/sklearn/model_selection/_validation.py in cross_validate(estimator=Pipeline(memory=None,
     steps=[('normalizer',... random_state=42, verbose=0, warm_start=False))]), X=array([[5.1, 3.5, 1.4, 0.2],
       [4.9, 3. , 1....2, 3.4, 5.4, 2.3],
       [5.9, 3. , 5.1, 1.8]]), y=array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,... 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]), groups=None, scoring=None, cv=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1, verbose=0, fit_params=None, pre_dispatch='2*n_jobs', return_train_score=False, return_estimator=False, error_score='raise-deprecating')
    235         delayed(_fit_and_score)(
    236             clone(estimator), X, y, scorers, train, test, verbose, None,
    237             fit_params, return_train_score=return_train_score,
    238             return_times=True, return_estimator=return_estimator,
    239             error_score=error_score)
--> 240         for train, test in cv.split(X, y, groups))
        cv.split = <bound method StratifiedKFold.split of Stratifie...d(n_splits=10, random_state=None, shuffle=False)>
        X = array([[5.1, 3.5, 1.4, 0.2],
       [4.9, 3. , 1....2, 3.4, 5.4, 2.3],
       [5.9, 3. , 5.1, 1.8]])
        y = array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,... 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2])
        groups = None
    241 
    242     zipped_scores = list(zip(*scores))
    243     if return_train_score:
    244         train_scores = zipped_scores.pop(0)

...........................................................................
/home/aquemy/.local/lib/python2.7/site-packages/sklearn/externals/joblib/parallel.py in __call__(self=Parallel(n_jobs=-1), iterable=<generator object <genexpr>>)
    925                 # No need to wait for async callbacks to trigger to
    926                 # consumption.
    927                 self._iterating = False
    928 
    929             with self._backend.retrieval_context():
--> 930                 self.retrieve()
        self.retrieve = <bound method Parallel.retrieve of Parallel(n_jobs=-1)>
    931             # Make sure that we get a last message telling us we are done
    932             elapsed_time = time.time() - self._start_time
    933             self._print('Done %3i out of %3i | elapsed: %s finished',
    934                         (len(self._output), len(self._output),

---------------------------------------------------------------------------
Joblib worker traceback:
---------------------------------------------------------------------------
ValueError                                         Mon Jun 17 13:14:14 2019
PID: 21598                                  Python 2.7.15+: /usr/bin/python
...........................................................................
/home/aquemy/.local/lib/python2.7/site-packages/sklearn/externals/joblib/parallel.py in __call__(self=<sklearn.externals.joblib.parallel.BatchedCalls object>)
    220     def __call__(self):
    221         # Set the default nested backend to self._backend but do not set the
    222         # change the default number of processes to -1
    223         with parallel_backend(self._backend, n_jobs=self._n_jobs):
    224             return [func(*args, **kwargs)
--> 225                     for func, args, kwargs in self.items]
        func = <function _fit_and_score>
        args = (Pipeline(memory=None,
     steps=[('normalizer',... random_state=42, verbose=0, warm_start=False))]), array([[5.1, 3.5, 1.4, 0.2],
       [4.9, 3. , 1....2, 3.4, 5.4, 2.3],
       [5.9, 3. , 5.1, 1.8]]), array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,... 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]), {'score': <function _passthrough_scorer>}, array([  5,   6,   7,   8,   9,  10,  11,  12,  ..., 142, 143, 144,
       145, 146, 147, 148, 149]), array([  0,   1,   2,   3,   4,  50,  51,  52,  53,  54, 100, 101, 102,
       103, 104]), 0, None, None)
        kwargs = {'error_score': 'raise-deprecating', 'return_estimator': False, 'return_times': True, 'return_train_score': False}
        self.items = [(<function _fit_and_score>, (Pipeline(memory=None,
     steps=[('normalizer',... random_state=42, verbose=0, warm_start=False))]), array([[5.1, 3.5, 1.4, 0.2],
       [4.9, 3. , 1....2, 3.4, 5.4, 2.3],
       [5.9, 3. , 5.1, 1.8]]), array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,... 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]), {'score': <function _passthrough_scorer>}, array([  5,   6,   7,   8,   9,  10,  11,  12,  ..., 142, 143, 144,
       145, 146, 147, 148, 149]), array([  0,   1,   2,   3,   4,  50,  51,  52,  53,  54, 100, 101, 102,
       103, 104]), 0, None, None), {'error_score': 'raise-deprecating', 'return_estimator': False, 'return_times': True, 'return_train_score': False})]
    226 
    227     def __len__(self):
    228         return self._size
    229 

...........................................................................
/home/aquemy/.local/lib/python2.7/site-packages/sklearn/model_selection/_validation.py in _fit_and_score(estimator=Pipeline(memory=None,
     steps=[('normalizer',... random_state=42, verbose=0, warm_start=False))]), X=array([[5.1, 3.5, 1.4, 0.2],
       [4.9, 3. , 1....2, 3.4, 5.4, 2.3],
       [5.9, 3. , 5.1, 1.8]]), y=array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,... 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]), scorer={'score': <function _passthrough_scorer>}, train=array([  5,   6,   7,   8,   9,  10,  11,  12,  ..., 142, 143, 144,
       145, 146, 147, 148, 149]), test=array([  0,   1,   2,   3,   4,  50,  51,  52,  53,  54, 100, 101, 102,
       103, 104]), verbose=0, parameters=None, fit_params={}, return_train_score=False, return_parameters=False, return_n_test_samples=False, return_times=True, return_estimator=False, error_score='raise-deprecating')
    523 
    524     try:
    525         if y_train is None:
    526             estimator.fit(X_train, **fit_params)
    527         else:
--> 528             estimator.fit(X_train, y_train, **fit_params)
        estimator.fit = <bound method Pipeline.fit of Pipeline(memory=No...random_state=42, verbose=0, warm_start=False))])>
        X_train = array([[5.4, 3.9, 1.7, 0.4],
       [4.6, 3.4, 1....2, 3.4, 5.4, 2.3],
       [5.9, 3. , 5.1, 1.8]])
        y_train = array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,
       2, 2, 2])
        fit_params = {}
    529 
    530     except Exception as e:
    531         # Note fit time as time until error
    532         fit_time = time.time() - start_time

...........................................................................
/usr/local/lib/python2.7/dist-packages/imblearn/pipeline.py in fit(self=Pipeline(memory=None,
     steps=[('normalizer',... random_state=42, verbose=0, warm_start=False))]), X=array([[5.4, 3.9, 1.7, 0.4],
       [4.6, 3.4, 1....2, 3.4, 5.4, 2.3],
       [5.9, 3. , 5.1, 1.8]]), y=array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,
       2, 2, 2]), **fit_params={})
    234             This estimator
    235 
    236         """
    237         Xt, yt, fit_params = self._fit(X, y, **fit_params)
    238         if self._final_estimator is not None:
--> 239             self._final_estimator.fit(Xt, yt, **fit_params)
        self._final_estimator.fit = <bound method RandomForestClassifier.fit of Rand...e, random_state=42, verbose=0, warm_start=False)>
        Xt = array([[-1.16789098],
       [-1.33920422],
    ...45],
       [ 0.94497228],
       [ 0.77365904]])
        yt = array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,
       2, 2, 2])
        fit_params = {}
    240         return self
    241 
    242     def fit_transform(self, X, y=None, **fit_params):
    243         """Fit the model and transform with the final estimator

...........................................................................
/home/aquemy/.local/lib/python2.7/site-packages/sklearn/ensemble/forest.py in fit(self=RandomForestClassifier(bootstrap=True, class_wei...se, random_state=42, verbose=0, warm_start=False), X=array([[-1.167891  ],
       [-1.3392042 ],
    ....9449723 ],
       [ 0.77365905]], dtype=float32), y=array([[0.],
       [0.],
       [0.],
       [0...    [2.],
       [2.],
       [2.],
       [2.]]), sample_weight=None)
    328             trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,
    329                              **_joblib_parallel_args(prefer='threads'))(
    330                 delayed(_parallel_build_trees)(
    331                     t, self, X, y, sample_weight, i, len(trees),
    332                     verbose=self.verbose, class_weight=self.class_weight)
--> 333                 for i, t in enumerate(trees))
        i = 99
    334 
    335             # Collect newly grown trees
    336             self.estimators_.extend(trees)
    337 

...........................................................................
/home/aquemy/.local/lib/python2.7/site-packages/sklearn/externals/joblib/parallel.py in __call__(self=Parallel(n_jobs=1), iterable=<generator object <genexpr>>)
    912             # self._original_iterator is None, then this means either
    913             # that pre_dispatch == "all", n_jobs == 1 or that the first batch
    914             # was very quick and its callback already dispatched all the
    915             # remaining jobs.
    916             self._iterating = False
--> 917             if self.dispatch_one_batch(iterator):
        self.dispatch_one_batch = <bound method Parallel.dispatch_one_batch of Parallel(n_jobs=1)>
        iterator = <generator object <genexpr>>
    918                 self._iterating = self._original_iterator is not None
    919 
    920             while self.dispatch_one_batch(iterator):
    921                 pass

...........................................................................
/home/aquemy/.local/lib/python2.7/site-packages/sklearn/externals/joblib/parallel.py in dispatch_one_batch(self=Parallel(n_jobs=1), iterator=<generator object <genexpr>>)
    754                                  self._pickle_cache)
    755             if len(tasks) == 0:
    756                 # No more tasks available in the iterator: tell caller to stop.
    757                 return False
    758             else:
--> 759                 self._dispatch(tasks)
        self._dispatch = <bound method Parallel._dispatch of Parallel(n_jobs=1)>
        tasks = <sklearn.externals.joblib.parallel.BatchedCalls object>
    760                 return True
    761 
    762     def _print(self, msg, msg_args):
    763         """Display the message on stout or stderr depending on verbosity"""

...........................................................................
/home/aquemy/.local/lib/python2.7/site-packages/sklearn/externals/joblib/parallel.py in _dispatch(self=Parallel(n_jobs=1), batch=<sklearn.externals.joblib.parallel.BatchedCalls object>)
    711 
    712         dispatch_timestamp = time.time()
    713         cb = BatchCompletionCallBack(dispatch_timestamp, len(batch), self)
    714         with self._lock:
    715             job_idx = len(self._jobs)
--> 716             job = self._backend.apply_async(batch, callback=cb)
        job = undefined
        self._backend.apply_async = <bound method SequentialBackend.apply_async of <...lib._parallel_backends.SequentialBackend object>>
        batch = <sklearn.externals.joblib.parallel.BatchedCalls object>
        cb = <sklearn.externals.joblib.parallel.BatchCompletionCallBack object>
    717             # A job can complete so quickly than its callback is
    718             # called before we get here, causing self._jobs to
    719             # grow. To ensure correct results ordering, .insert is
    720             # used (rather than .append) in the following line

...........................................................................
/home/aquemy/.local/lib/python2.7/site-packages/sklearn/externals/joblib/_parallel_backends.py in apply_async(self=<sklearn.externals.joblib._parallel_backends.SequentialBackend object>, func=<sklearn.externals.joblib.parallel.BatchedCalls object>, callback=<sklearn.externals.joblib.parallel.BatchCompletionCallBack object>)
    177             raise ValueError('n_jobs == 0 in Parallel has no meaning')
    178         return 1
    179 
    180     def apply_async(self, func, callback=None):
    181         """Schedule a func to be run"""
--> 182         result = ImmediateResult(func)
        result = undefined
        func = <sklearn.externals.joblib.parallel.BatchedCalls object>
    183         if callback:
    184             callback(result)
    185         return result
    186 

...........................................................................
/home/aquemy/.local/lib/python2.7/site-packages/sklearn/externals/joblib/_parallel_backends.py in __init__(self=<sklearn.externals.joblib._parallel_backends.ImmediateResult object>, batch=<sklearn.externals.joblib.parallel.BatchedCalls object>)
    544 
    545 class ImmediateResult(object):
    546     def __init__(self, batch):
    547         # Don't delay the application, to avoid keeping the input
    548         # arguments in memory
--> 549         self.results = batch()
        self.results = undefined
        batch = <sklearn.externals.joblib.parallel.BatchedCalls object>
    550 
    551     def get(self):
    552         return self.results
    553 

...........................................................................
/home/aquemy/.local/lib/python2.7/site-packages/sklearn/externals/joblib/parallel.py in __call__(self=<sklearn.externals.joblib.parallel.BatchedCalls object>)
    220     def __call__(self):
    221         # Set the default nested backend to self._backend but do not set the
    222         # change the default number of processes to -1
    223         with parallel_backend(self._backend, n_jobs=self._n_jobs):
    224             return [func(*args, **kwargs)
--> 225                     for func, args, kwargs in self.items]
        func = <function _parallel_build_trees>
        args = (DecisionTreeClassifier(class_weight=None, criter...=False, random_state=1608637542, splitter='best'), RandomForestClassifier(bootstrap=True, class_wei...se, random_state=42, verbose=0, warm_start=False), array([[-1.167891  ],
       [-1.3392042 ],
    ....9449723 ],
       [ 0.77365905]], dtype=float32), array([[0.],
       [0.],
       [0.],
       [0...    [2.],
       [2.],
       [2.],
       [2.]]), None, 0, 100)
        kwargs = {'class_weight': None, 'verbose': 0}
        self.items = [(<function _parallel_build_trees>, (DecisionTreeClassifier(class_weight=None, criter...=False, random_state=1608637542, splitter='best'), RandomForestClassifier(bootstrap=True, class_wei...se, random_state=42, verbose=0, warm_start=False), array([[-1.167891  ],
       [-1.3392042 ],
    ....9449723 ],
       [ 0.77365905]], dtype=float32), array([[0.],
       [0.],
       [0.],
       [0...    [2.],
       [2.],
       [2.],
       [2.]]), None, 0, 100), {'class_weight': None, 'verbose': 0})]
    226 
    227     def __len__(self):
    228         return self._size
    229 

...........................................................................
/home/aquemy/.local/lib/python2.7/site-packages/sklearn/ensemble/forest.py in _parallel_build_trees(tree=DecisionTreeClassifier(class_weight=None, criter...=False, random_state=1608637542, splitter='best'), forest=RandomForestClassifier(bootstrap=True, class_wei...se, random_state=42, verbose=0, warm_start=False), X=array([[-1.167891  ],
       [-1.3392042 ],
    ....9449723 ],
       [ 0.77365905]], dtype=float32), y=array([[0.],
       [0.],
       [0.],
       [0...    [2.],
       [2.],
       [2.],
       [2.]]), sample_weight=None, tree_idx=0, n_trees=100, verbose=0, class_weight=None)
    114                 simplefilter('ignore', DeprecationWarning)
    115                 curr_sample_weight *= compute_sample_weight('auto', y, indices)
    116         elif class_weight == 'balanced_subsample':
    117             curr_sample_weight *= compute_sample_weight('balanced', y, indices)
    118 
--> 119         tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)
        tree.fit = <bound method DecisionTreeClassifier.fit of Deci...False, random_state=1608637542, splitter='best')>
        X = array([[-1.167891  ],
       [-1.3392042 ],
    ....9449723 ],
       [ 0.77365905]], dtype=float32)
        y = array([[0.],
       [0.],
       [0.],
       [0...    [2.],
       [2.],
       [2.],
       [2.]])
        sample_weight = None
        curr_sample_weight = array([3., 3., 0., 1., 1., 2., 2., 0., 1., 2., 0... 1., 0., 1., 0., 1., 1., 1., 1., 1., 1., 0., 0.])
    120     else:
    121         tree.fit(X, y, sample_weight=sample_weight, check_input=False)
    122 
    123     return tree

...........................................................................
/home/aquemy/.local/lib/python2.7/site-packages/sklearn/tree/tree.py in fit(self=DecisionTreeClassifier(class_weight=None, criter...=False, random_state=1608637542, splitter='best'), X=array([[-1.167891  ],
       [-1.3392042 ],
    ....9449723 ],
       [ 0.77365905]], dtype=float32), y=array([[0.],
       [0.],
       [0.],
       [0...    [2.],
       [2.],
       [2.],
       [2.]]), sample_weight=array([3., 3., 0., 1., 1., 2., 2., 0., 1., 2., 0... 1., 0., 1., 0., 1., 1., 1., 1., 1., 1., 0., 0.]), check_input=False, X_idx_sorted=None)
    796 
    797         super(DecisionTreeClassifier, self).fit(
    798             X, y,
    799             sample_weight=sample_weight,
    800             check_input=check_input,
--> 801             X_idx_sorted=X_idx_sorted)
        X_idx_sorted = None
    802         return self
    803 
    804     def predict_proba(self, X, check_input=True):
    805         """Predict class probabilities of the input samples X.

...........................................................................
/home/aquemy/.local/lib/python2.7/site-packages/sklearn/tree/tree.py in fit(self=DecisionTreeClassifier(class_weight=None, criter...=False, random_state=1608637542, splitter='best'), X=array([[-1.167891  ],
       [-1.3392042 ],
    ....9449723 ],
       [ 0.77365905]], dtype=float32), y=array([[0.],
       [0.],
       [0.],
       [0...    [2.],
       [2.],
       [2.],
       [2.]]), sample_weight=array([3., 3., 0., 1., 1., 2., 2., 0., 1., 2., 0... 1., 0., 1., 0., 1., 1., 1., 1., 1., 1., 0., 0.]), check_input=False, X_idx_sorted=None)
    237         if not 0 <= self.min_weight_fraction_leaf <= 0.5:
    238             raise ValueError("min_weight_fraction_leaf must in [0, 0.5]")
    239         if max_depth <= 0:
    240             raise ValueError("max_depth must be greater than zero. ")
    241         if not (0 < max_features <= self.n_features_):
--> 242             raise ValueError("max_features must be in (0, n_features]")
    243         if not isinstance(max_leaf_nodes, (numbers.Integral, np.integer)):
    244             raise ValueError("max_leaf_nodes must be integral number but was "
    245                              "%r" % max_leaf_nodes)
    246         if -1 < max_leaf_nodes < 2:

ValueError: max_features must be in (0, n_features]
___________________________________________________________________________
Best score: 0.966666666667 (0.0333333333333) [J] | Score: 0.0 (0.0) [J]
Best score: 0.966666666667 (0.0333333333333) [J] | Score: 0.92 (0.0832666399786) [J]
Best score: 0.966666666667 (0.0333333333333) [J] | Score: 0.966666666667 (0.04472135955) [J]
Best score: 0.966666666667 (0.0333333333333) [J] | Score: 0.953333333333 (0.0426874949162) [J]
Best score: 0.966666666667 (0.0333333333333) [J] | Score: 0.953333333333 (0.0426874949162) [J]
JoblibValueError
___________________________________________________________________________
...........................................................................
/home/aquemy/dev/dp_hyperparameters/extension/main.py in <module>()
     27 
     28     serializer.serialize_results(scenario, policy)
     29 
     30 if __name__ == "__main__":
     31     args = cli.parse_args()
---> 32     main(args)

...........................................................................
/home/aquemy/dev/dp_hyperparameters/extension/main.py in main(args=Namespace(customize=[(['control', 'seed'], '42')...io='./scenarios/rf_iris_joint.yaml', verbosity=0))
     21         test_size=0.4, 
     22         random_state=scenario['control']['seed']
     23     )
     24 
     25     policy = policies.initiate(scenario['setup']['policy'], config)
---> 26     policy.run(X,y)
        policy.run = <bound method Joint.run of <experiment.policies.joint.Joint object>>
        X = array([[5.1, 3.5, 1.4, 0.2],
       [4.9, 3. , 1....2, 3.4, 5.4, 2.3],
       [5.9, 3. , 5.1, 1.8]])
        y = array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,... 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2])
     27 
     28     serializer.serialize_results(scenario, policy)
     29 
     30 if __name__ == "__main__":

...........................................................................
/home/aquemy/dev/dp_hyperparameters/extension/experiment/policies/joint.py in run(self=<experiment.policies.joint.Joint object>, X=array([[5.1, 3.5, 1.4, 0.2],
       [4.9, 3. , 1....2, 3.4, 5.4, 2.3],
       [5.9, 3. , 5.1, 1.8]]), y=array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,... 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]))
     32             algo=tpe.suggest, 
     33             max_evals=None,
     34             max_time=self.config['time'],     
     35             trials=trials,
     36             show_progressbar=False,
---> 37             verbose=0
     38         )
     39 
     40         best_config = self.context['best_config']
     41         super(Joint, self).display_step_results(best_config)

...........................................................................
/home/aquemy/dev/dp_hyperparameters/extension/hyperopt/fmin.py in fmin(fn=<functools.partial object>, space={'algorithm': {'bootstrap': <hyperopt.pyll.base.Apply object>, 'criterion': <hyperopt.pyll.base.Apply object>, 'max_depth': <hyperopt.pyll.base.Apply object>, 'max_features': <hyperopt.pyll.base.Apply object>, 'max_leaf_nodes': <hyperopt.pyll.base.Apply object>, 'min_samples_split': <hyperopt.pyll.base.Apply object>, 'n_estimators': <hyperopt.pyll.base.Apply object>}, 'pipeline': {'features': <hyperopt.pyll.base.Apply object>, 'normalizer': <hyperopt.pyll.base.Apply object>, 'rebalance': <hyperopt.pyll.base.Apply object>}}, algo=<function suggest>, max_evals=9223372036854775807, max_time=300, trials=<hyperopt.base.Trials object>, rstate=<mtrand.RandomState object>, allow_trials_fmin=True, pass_expr_memo_ctrl=None, catch_eval_exceptions=False, verbose=0, return_argmin=True, points_to_evaluate=None, max_queue_len=1, show_progressbar=False)
    406             pass_expr_memo_ctrl=pass_expr_memo_ctrl,
    407             verbose=verbose,
    408             catch_eval_exceptions=catch_eval_exceptions,
    409             return_argmin=return_argmin,
    410             show_progressbar=show_progressbar,
--> 411             max_time=max_time
        max_time = 300
    412         )
    413 
    414     if trials is None:
    415         if points_to_evaluate is None:

...........................................................................
/home/aquemy/dev/dp_hyperparameters/extension/hyperopt/base.py in fmin(self=<hyperopt.base.Trials object>, fn=<functools.partial object>, space={'algorithm': {'bootstrap': <hyperopt.pyll.base.Apply object>, 'criterion': <hyperopt.pyll.base.Apply object>, 'max_depth': <hyperopt.pyll.base.Apply object>, 'max_features': <hyperopt.pyll.base.Apply object>, 'max_leaf_nodes': <hyperopt.pyll.base.Apply object>, 'min_samples_split': <hyperopt.pyll.base.Apply object>, 'n_estimators': <hyperopt.pyll.base.Apply object>}, 'pipeline': {'features': <hyperopt.pyll.base.Apply object>, 'normalizer': <hyperopt.pyll.base.Apply object>, 'rebalance': <hyperopt.pyll.base.Apply object>}}, algo=<function suggest>, max_evals=9223372036854775807, max_time=300, rstate=<mtrand.RandomState object>, verbose=0, pass_expr_memo_ctrl=None, catch_eval_exceptions=False, return_argmin=True, show_progressbar=False)
    636             verbose=verbose,
    637             allow_trials_fmin=False,  # -- prevent recursion
    638             pass_expr_memo_ctrl=pass_expr_memo_ctrl,
    639             catch_eval_exceptions=catch_eval_exceptions,
    640             return_argmin=return_argmin,
--> 641             show_progressbar=show_progressbar)
        show_progressbar = False
    642 
    643 
    644 def trials_from_docs(docs, validate=True, **kwargs):
    645     """Construct a Trials base class instance from a list of trials documents

...........................................................................
/home/aquemy/dev/dp_hyperparameters/extension/hyperopt/fmin.py in fmin(fn=<functools.partial object>, space={'algorithm': {'bootstrap': <hyperopt.pyll.base.Apply object>, 'criterion': <hyperopt.pyll.base.Apply object>, 'max_depth': <hyperopt.pyll.base.Apply object>, 'max_features': <hyperopt.pyll.base.Apply object>, 'max_leaf_nodes': <hyperopt.pyll.base.Apply object>, 'min_samples_split': <hyperopt.pyll.base.Apply object>, 'n_estimators': <hyperopt.pyll.base.Apply object>}, 'pipeline': {'features': <hyperopt.pyll.base.Apply object>, 'normalizer': <hyperopt.pyll.base.Apply object>, 'rebalance': <hyperopt.pyll.base.Apply object>}}, algo=<function suggest>, max_evals=9223372036854775807, max_time=300, trials=<hyperopt.base.Trials object>, rstate=<mtrand.RandomState object>, allow_trials_fmin=False, pass_expr_memo_ctrl=None, catch_eval_exceptions=False, verbose=0, return_argmin=True, points_to_evaluate=None, max_queue_len=1, show_progressbar=False)
    426                     verbose=verbose,
    427                     max_queue_len=max_queue_len,
    428                     show_progressbar=show_progressbar,
    429                     max_time=max_time)
    430     rval.catch_eval_exceptions = catch_eval_exceptions
--> 431     rval.exhaust()
        rval.exhaust = <bound method FMinIter.exhaust of <hyperopt.fmin.FMinIter object>>
    432     if return_argmin:
    433         return trials.argmin
    434     elif len(trials) > 0:
    435         # Only if there are some succesfull trail runs, return the best point in the evaluation space

...........................................................................
/home/aquemy/dev/dp_hyperparameters/extension/hyperopt/fmin.py in exhaust(self=<hyperopt.fmin.FMinIter object>)
    273             raise StopIteration()
    274         return self.trials
    275 
    276     def exhaust(self):
    277         n_done = len(self.trials)
--> 278         self.run(self.max_evals - n_done, block_until_done=self.asynchronous)
        self.run = <bound method FMinIter.run of <hyperopt.fmin.FMinIter object>>
        self.max_evals = 9223372036854775807
        n_done = 0
        self.asynchronous = False
    279         self.trials.refresh()
    280         return self
    281 
    282 

...........................................................................
/home/aquemy/dev/dp_hyperparameters/extension/hyperopt/fmin.py in run(self=<hyperopt.fmin.FMinIter object>, N=9223372036854775807, block_until_done=False)
    232                     if self.asynchronous:
    233                         # -- wait for workers to fill in the trials
    234                         time.sleep(self.poll_interval_secs)
    235                     else:
    236                         # -- loop over trials and do the jobs directly
--> 237                         self.serial_evaluate()
        self.serial_evaluate = <bound method FMinIter.serial_evaluate of <hyperopt.fmin.FMinIter object>>
    238                     try:
    239                         res = [d['result']['loss'] for d in
    240                                          self.trials.trials if
    241                                          d['result']['status'] == 'ok']

...........................................................................
/home/aquemy/dev/dp_hyperparameters/extension/hyperopt/fmin.py in serial_evaluate(self=<hyperopt.fmin.FMinIter object>, N=-1)
    138                 trial['book_time'] = now
    139                 trial['refresh_time'] = now
    140                 spec = base.spec_from_misc(trial['misc'])
    141                 ctrl = base.Ctrl(self.trials, current_trial=trial)
    142                 try:
--> 143                     result = self.domain.evaluate(spec, ctrl)
        result = undefined
        self.domain.evaluate = <bound method Domain.evaluate of <hyperopt.base.Domain object>>
        spec = {'bootstrap': 0, 'criterion': 0, 'features': 1, 'features_PCA_features__n_components': 1, 'max_depth': 3, 'max_features': 2, 'max_leaf_nodes': 1, 'min_samples_split': 1, 'n_estimators': 3, 'normalizer': 2, ...}
        ctrl = <hyperopt.base.Ctrl object>
    144                 except Exception as e:
    145                     logger.info('job exception: %s' % str(e))
    146                     trial['state'] = base.JOB_STATE_ERROR
    147                     trial['misc']['error'] = (str(type(e)), str(e))

...........................................................................
/home/aquemy/dev/dp_hyperparameters/extension/hyperopt/base.py in evaluate(self=<hyperopt.base.Domain object>, config={'bootstrap': 0, 'criterion': 0, 'features': 1, 'features_PCA_features__n_components': 1, 'max_depth': 3, 'max_features': 2, 'max_leaf_nodes': 1, 'min_samples_split': 1, 'n_estimators': 3, 'normalizer': 2, ...}, ctrl=<hyperopt.base.Ctrl object>, attach_attachments=True)
    841             #    or the normal Python part (self.fn)
    842             pyll_rval = pyll.rec_eval(
    843                 self.expr,
    844                 memo=memo,
    845                 print_node_on_error=self.rec_eval_print_node_on_error)
--> 846             rval = self.fn(pyll_rval)
        rval = undefined
        self.fn = <functools.partial object>
        pyll_rval = {'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': 4, 'max_features': 3, 'max_leaf_nodes': 3, 'min_samples_split': 3, 'n_estimators': 75}, 'pipeline': {'features': ('features_PCA', {'features__n_components': 2}), 'normalizer': ('normalizer_PowerTransformer', {}), 'rebalance': ('rebalance_CondensedNearestNeighbour', {'rebalance__n_neighbors': 2})}}
    847 
    848         if isinstance(rval, (float, int, np.number)):
    849             dict_rval = {'loss': float(rval), 'status': STATUS_OK}
    850         else:

...........................................................................
/home/aquemy/dev/dp_hyperparameters/extension/experiment/objective.py in objective_joint(wconfig={'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': 4, 'max_features': 3, 'max_leaf_nodes': 3, 'min_samples_split': 3, 'n_estimators': 75}, 'pipeline': {'features': ('features_PCA', {'features__n_components': 2}), 'normalizer': ('normalizer_PowerTransformer', {}), 'rebalance': ('rebalance_CondensedNearestNeighbour', {'rebalance__n_neighbors': 2})}}, algorithm='RandomForest', X=array([[5.1, 3.5, 1.4, 0.2],
       [4.9, 3. , 1....2, 3.4, 5.4, 2.3],
       [5.9, 3. , 5.1, 1.8]]), y=array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,... 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]), context={'baseline_score': 0.9466666666666667, 'baseline_score_std': 0.04988876515698587, 'best_config': {'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': 4, 'max_features': 3, 'max_leaf_nodes': 3, 'min_samples_split': 3, 'n_estimators': 10}, 'config_hash': {'algorithm': 'ffb7ff225ce3d3712c96cf87fe42202988ee2eb0', 'config': 'bae32f426be9cd6243523c023944a8c148fe4aeb', 'pipeline': 'd2a68bfda6fcdec4ae0ffc7d7b6a2122bc1cd673'}, 'duration': 0.7115809917449951, 'iteration': 113, 'loss': 0.033333333333333215, 'max_history_score': 0.9666666666666668, 'max_history_score_std': 0.033333333333333326, 'max_history_step': 'joint', 'pipeline': {'features': ('features_NoneType', {}), 'normalizer': ('normalizer_PowerTransformer', {}), 'rebalance': ('rebalance_CondensedNearestNeighbour', {'rebalance__n_neighbors': 2})}, 'score': 0.9666666666666668, ...}, 'history': [{'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': 2, 'max_features': None, 'max_leaf_nodes': 5, 'min_samples_split': 2, 'n_estimators': 75}, 'config_hash': {'algorithm': '3af5b0cce71c8fe2545246ca24ff5bc3dd516e06', 'config': 'db6ac7e6d348155757e4794bb5f88fe2b4f63d50', 'pipeline': '8d59f4b94cef6be9306ed86a22a9570fa670d567'}, 'duration': 1.149928092956543, 'iteration': 0, 'loss': 0.046666666666666634, 'max_history_score': 0.9533333333333334, 'max_history_score_std': 0.059999999999999984, 'max_history_step': 'joint', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 4, 'features__selectkbest__k': 3}), 'normalizer': ('normalizer_StandardScaler', {'normalizer__with_mean': True, 'normalizer__with_std': True}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 6})}, 'score': 0.9533333333333334, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': 1, 'max_features': 2, 'max_leaf_nodes': 2, 'min_samples_split': 5, 'n_estimators': 100}, 'config_hash': {'algorithm': 'e13eb05fd9a62d2f63bbb1c1deff0cd620d5e6ab', 'config': '4db6fb84d85f52659f780e682ffac5712c3d8a94', 'pipeline': '64c9a1ca9d53ae67244bdd942f4db36a3c05218c'}, 'duration': 1.7678282260894775, 'iteration': 1, 'loss': 0.18000000000000005, 'max_history_score': 0.9533333333333334, 'max_history_score_std': 0.059999999999999984, 'max_history_step': 'joint', 'pipeline': {'features': ('features_NoneType', {}), 'normalizer': ('normalizer_PowerTransformer', {}), 'rebalance': ('rebalance_NearMiss', {'rebalance__n_neighbors': 1})}, 'score': 0.82, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': 1, 'max_features': None, 'max_leaf_nodes': None, 'min_samples_split': 5, 'n_estimators': 75}, 'config_hash': {'algorithm': '94b0d7a654c508cc63643f78fe4f0f07e6f07c1e', 'config': '4403c5a85e951938d3c454e961d3a412780722f6', 'pipeline': '3e47444880d8367fbac2faaba2e52a917274aa58'}, 'duration': 0.8397619724273682, 'iteration': 2, 'loss': 0.03333333333333344, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_PCA', {'features__n_components': 3}), 'normalizer': ('normalizer_MinMaxScaler', {}), 'rebalance': ('rebalance_NoneType', {})}, 'score': 0.9666666666666666, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': None, 'max_features': None, 'max_leaf_nodes': 3, 'min_samples_split': 3, 'n_estimators': 75}, 'config_hash': {'algorithm': 'e8332f0a8902bda03bf70e7978cc5d52affb29d3', 'config': 'a064e2df18ab98d44dabcefbc7bed94913f1d0be', 'pipeline': '7eea819c2a8c103c4b1e9e9c1e224aebba95081f'}, 'duration': 0.8501448631286621, 'iteration': 3, 'loss': 0.053333333333333344, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 2, 'features__selectkbest__k': 4}), 'normalizer': ('normalizer_NoneType', {}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 7})}, 'score': 0.9466666666666667, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'entropy', 'max_depth': 3, 'max_features': 3, 'max_leaf_nodes': None, 'min_samples_split': 5, 'n_estimators': 75}, 'config_hash': {'algorithm': '7a4491035bc6bd737fe9a8cda8a79a02d02d5c74', 'config': '0ddb6f5cab3db4dddd7682966a57205f3e329ad4', 'pipeline': 'a9ae03fe38334f6868cbf84cdd3d629d4bbe3fb0'}, 'duration': 1.1026010513305664, 'iteration': 4, 'loss': 0.05999999999999994, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 2, 'features__selectkbest__k': 1}), 'normalizer': ('normalizer_NoneType', {}), 'rebalance': ('rebalance_NoneType', {})}, 'score': 0.9400000000000001, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'gini', 'max_depth': 3, 'max_features': 1, 'max_leaf_nodes': 5, 'min_samples_split': 2, 'n_estimators': 25}, 'config_hash': {'algorithm': '9826d20b2d6a0f559cf7f16450ce7526f07e8434', 'config': '49f25751bca61cdd461a8cbd2923689b642f98ed', 'pipeline': '19b249664c5bf067de1fed4334a296f947ce774a'}, 'duration': 0.35647010803222656, 'iteration': 5, 'loss': 0.046666666666666634, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_NoneType', {}), 'normalizer': ('normalizer_NoneType', {}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 6})}, 'score': 0.9533333333333334, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'gini', 'max_depth': 2, 'max_features': 1, 'max_leaf_nodes': 2, 'min_samples_split': 2, 'n_estimators': 50}, 'config_hash': {'algorithm': '0a4f6fbb07e0f32c6f675489a0fc82eee05bd8e1', 'config': '5c3a2b6f5e63fb45f10e41e0318b354912ec44f6', 'pipeline': 'dc3b9f176f090005e38b142f11d80e93a7dc5d5e'}, 'duration': 0.7213859558105469, 'iteration': 6, 'loss': 0.31333333333333324, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 1, 'features__selectkbest__k': 4}), 'normalizer': ('normalizer_PowerTransformer', {}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 7})}, 'score': 0.6866666666666668, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'entropy', 'max_depth': 4, 'max_features': 3, 'max_leaf_nodes': 5, 'min_samples_split': 5, 'n_estimators': 10}, 'config_hash': {'algorithm': 'b8112b97ecfc10f00a195af661dcc861cac21289', 'config': 'd3b129b397350f1b6572651c67c01de49b4b174c', 'pipeline': '5b0357ed7072c37b3d6f458bb5d49ff7d825f603'}, 'duration': 0.8299109935760498, 'iteration': 7, 'loss': 1.0, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_PCA', {'features__n_components': 2}), 'normalizer': ('normalizer_StandardScaler', {'normalizer__with_mean': True, 'normalizer__with_std': False}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 6})}, 'score': 0.0, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'gini', 'max_depth': 4, 'max_features': None, 'max_leaf_nodes': 2, 'min_samples_split': 5, 'n_estimators': 100}, 'config_hash': {'algorithm': '40ca24df19b8d164d9d098a6bed1ce056fbbb961', 'config': '813bde1108cc3c4b9bfb3a22cbb421bda7eac671', 'pipeline': '74a7b8705a1c22f7dea5e44e4ebda8f1e48add71'}, 'duration': 2.2111589908599854, 'iteration': 8, 'loss': 0.33333333333333326, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_PCA', {'features__n_components': 2}), 'normalizer': ('normalizer_StandardScaler', {'normalizer__with_mean': False, 'normalizer__with_std': True}), 'rebalance': ('rebalance_NearMiss', {'rebalance__n_neighbors': 2})}, 'score': 0.6666666666666667, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'entropy', 'max_depth': 2, 'max_features': 1, 'max_leaf_nodes': 5, 'min_samples_split': 2, 'n_estimators': 100}, 'config_hash': {'algorithm': '331418a5c12cf1453876eef85e9d98fc8e54fa11', 'config': '31930b6860ed406d59bf7e59ba1925d94704bd3b', 'pipeline': '054bef356f90ec6f644ef3ffc688766744db51c2'}, 'duration': 1.0501940250396729, 'iteration': 9, 'loss': 0.053333333333333344, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_SelectKBest', {'features__k': 1}), 'normalizer': ('normalizer_RobustScaler', {'normalizer__quantile_range': (...), 'normalizer__with_centering': True, 'normalizer__with_scaling': True}), 'rebalance': ('rebalance_NearMiss', {'rebalance__n_neighbors': 2})}, 'score': 0.9466666666666667, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'entropy', 'max_depth': 3, 'max_features': None, 'max_leaf_nodes': 3, 'min_samples_split': 2, 'n_estimators': 100}, 'config_hash': {'algorithm': 'dbc1b8126649fe93dce5fbb37e4015b0acfb179e', 'config': '9913cd550615a9d0946ab4a755a8b9f619e442fd', 'pipeline': 'dd626121cea079ebb32e184ca65483ec7a6d7f59'}, 'duration': 1.120617151260376, 'iteration': 10, 'loss': 0.046666666666666634, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 2, 'features__selectkbest__k': 1}), 'normalizer': ('normalizer_MinMaxScaler', {}), 'rebalance': ('rebalance_NoneType', {})}, 'score': 0.9533333333333334, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'gini', 'max_depth': 3, 'max_features': 3, 'max_leaf_nodes': None, 'min_samples_split': 3, 'n_estimators': 75}, 'config_hash': {'algorithm': '34917a130df5a975f78bd7ec1a0c7b1ffdc787a9', 'config': '95fc8cadc088141290b7de9c388977e4685f0108', 'pipeline': '550d10faf2f08db48516cc3501558816d6a99bc0'}, 'duration': 1.4287099838256836, 'iteration': 11, 'loss': 0.19333333333333313, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 3, 'features__selectkbest__k': 4}), 'normalizer': ('normalizer_StandardScaler', {'normalizer__with_mean': False, 'normalizer__with_std': False}), 'rebalance': ('rebalance_CondensedNearestNeighbour', {'rebalance__n_neighbors': 1})}, 'score': 0.8066666666666669, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'entropy', 'max_depth': 1, 'max_features': 2, 'max_leaf_nodes': 5, 'min_samples_split': 2, 'n_estimators': 75}, 'config_hash': {'algorithm': '33f9abb4aee44a395a9f3b3ffa9ce80a8cdaed7c', 'config': '40fa726f0360cf6af55f9b5902d399d02f61f157', 'pipeline': 'cfd1d20841fe2153da762c95e79f95a3fb1e426a'}, 'duration': 1.2978079319000244, 'iteration': 12, 'loss': 0.053333333333333344, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_PCA', {'features__n_components': 4}), 'normalizer': ('normalizer_MinMaxScaler', {}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 7})}, 'score': 0.9466666666666667, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'entropy', 'max_depth': 4, 'max_features': 2, 'max_leaf_nodes': 5, 'min_samples_split': 3, 'n_estimators': 25}, 'config_hash': {'algorithm': '210111ec6562d09eb093e98ed69ef1c662e11a50', 'config': '0fb8e77c7bd9a58b72f1b33c21a59a09a8c676ba', 'pipeline': '5d269d759e0c7926a685a14b263ace8ae0071e4b'}, 'duration': 0.36649012565612793, 'iteration': 13, 'loss': 0.040000000000000036, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 2, 'features__selectkbest__k': 2}), 'normalizer': ('normalizer_NoneType', {}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 7})}, 'score': 0.96, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'entropy', 'max_depth': 3, 'max_features': 1, 'max_leaf_nodes': 5, 'min_samples_split': 2, 'n_estimators': 25}, 'config_hash': {'algorithm': '0e989a03980101fabf79eda3326ed2870e11d690', 'config': 'f4bffd5d8c67a9c5321a9943c4a99678f59a02b7', 'pipeline': '865ee1e3fe8334c3d5ecb2038d5a5d1b3ba50e75'}, 'duration': 0.35639500617980957, 'iteration': 14, 'loss': 0.046666666666666634, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_NoneType', {}), 'normalizer': ('normalizer_RobustScaler', {'normalizer__quantile_range': (...), 'normalizer__with_centering': True, 'normalizer__with_scaling': False}), 'rebalance': ('rebalance_NoneType', {})}, 'score': 0.9533333333333334, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'entropy', 'max_depth': None, 'max_features': 3, 'max_leaf_nodes': 3, 'min_samples_split': 5, 'n_estimators': 10}, 'config_hash': {'algorithm': '9c592e876c13de5e23e6de5b868e01755d63e72e', 'config': '1e6a68cd1eeac886d90724d78b1cb5fb76a3cde4', 'pipeline': '5a1ca4d82f21b7de0d2c918630a42510673fa36e'}, 'duration': 0.18141412734985352, 'iteration': 15, 'loss': 0.046666666666666634, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_SelectKBest', {'features__k': 3}), 'normalizer': ('normalizer_RobustScaler', {'normalizer__quantile_range': (...), 'normalizer__with_centering': True, 'normalizer__with_scaling': True}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 6})}, 'score': 0.9533333333333334, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': 1, 'max_features': None, 'max_leaf_nodes': None, 'min_samples_split': 5, 'n_estimators': 10}, 'config_hash': {'algorithm': '8bed77aef289bfd453b2858bd288ae5ba7160f2b', 'config': '781185bcb8999045de8d489f253a1a1ba4247932', 'pipeline': '1ece7eabedc2be9e5b0a1be65c570d08ffa3eb54'}, 'duration': 0.1636829376220703, 'iteration': 16, 'loss': 0.053333333333333344, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_NoneType', {}), 'normalizer': ('normalizer_NoneType', {}), 'rebalance': ('rebalance_NearMiss', {'rebalance__n_neighbors': 1})}, 'score': 0.9466666666666667, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'gini', 'max_depth': 3, 'max_features': 2, 'max_leaf_nodes': 2, 'min_samples_split': 5, 'n_estimators': 75}, 'config_hash': {'algorithm': '617b97d9ba21d3373bc51ffa9cccf9c6f91a77b3', 'config': '99fb425b4e8c5d80228cab94202252aa25cdf77c', 'pipeline': 'd6242929c3b515c7719e60423023ac604311afc3'}, 'duration': 0.8468999862670898, 'iteration': 17, 'loss': 0.24, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_PCA', {'features__n_components': 4}), 'normalizer': ('normalizer_PowerTransformer', {}), 'rebalance': ('rebalance_NearMiss', {'rebalance__n_neighbors': 2})}, 'score': 0.76, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': 1, 'max_features': 1, 'max_leaf_nodes': 2, 'min_samples_split': 5, 'n_estimators': 50}, 'config_hash': {'algorithm': 'b92d2697cdd4979da443369d6596229ec091626a', 'config': 'c513a3e13281206ad76187dd817b1fff93d54fe1', 'pipeline': 'c4b4f914a3ca8df967cade997a90366d85a371b9'}, 'duration': 0.6724588871002197, 'iteration': 18, 'loss': 0.23333333333333328, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 1, 'features__selectkbest__k': 3}), 'normalizer': ('normalizer_StandardScaler', {'normalizer__with_mean': True, 'normalizer__with_std': True}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 5})}, 'score': 0.7666666666666667, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'entropy', 'max_depth': None, 'max_features': None, 'max_leaf_nodes': 5, 'min_samples_split': 5, 'n_estimators': 10}, 'config_hash': {'algorithm': 'a0115de695e6cca2e81cbfb54df79bf4b43608b1', 'config': 'ba194015e20b5d67770e8c67342c3d8d0d01dc41', 'pipeline': '8d45fabfeb85ffdcabf7076bd0e65fffe97ce928'}, 'duration': 0.19424200057983398, 'iteration': 19, 'loss': 0.08666666666666667, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_PCA', {'features__n_components': 3}), 'normalizer': ('normalizer_NoneType', {}), 'rebalance': ('rebalance_NoneType', {})}, 'score': 0.9133333333333333, ...}, ...], 'history_hash': ['db6ac7e6d348155757e4794bb5f88fe2b4f63d50', '4db6fb84d85f52659f780e682ffac5712c3d8a94', '4403c5a85e951938d3c454e961d3a412780722f6', 'a064e2df18ab98d44dabcefbc7bed94913f1d0be', '0ddb6f5cab3db4dddd7682966a57205f3e329ad4', '49f25751bca61cdd461a8cbd2923689b642f98ed', '5c3a2b6f5e63fb45f10e41e0318b354912ec44f6', 'd3b129b397350f1b6572651c67c01de49b4b174c', '813bde1108cc3c4b9bfb3a22cbb421bda7eac671', '31930b6860ed406d59bf7e59ba1925d94704bd3b', '9913cd550615a9d0946ab4a755a8b9f619e442fd', '95fc8cadc088141290b7de9c388977e4685f0108', '40fa726f0360cf6af55f9b5902d399d02f61f157', '0fb8e77c7bd9a58b72f1b33c21a59a09a8c676ba', 'f4bffd5d8c67a9c5321a9943c4a99678f59a02b7', '1e6a68cd1eeac886d90724d78b1cb5fb76a3cde4', '781185bcb8999045de8d489f253a1a1ba4247932', '99fb425b4e8c5d80228cab94202252aa25cdf77c', 'c513a3e13281206ad76187dd817b1fff93d54fe1', 'ba194015e20b5d67770e8c67342c3d8d0d01dc41', ...], 'history_index': {'00f0493590a2cb5e98a35b29816f8cd9f87f96ec': 208, '013329309d510b94f19d930320402d65f953a847': 39, '038a0f515e2ec894ee8e34f9caa2889eb3ebd5ce': 66, '052ae4bf232b316187b078abae42c2be19e16a00': 111, '05e9258ebf99dd97202167ef1563fa834b0568f1': 242, '0659afebf316aafeb75612fb07081a04c28545ed': 74, '06e7cde9f3556cd01332ce389ad1d8925cd4b4a4': 120, '07ab8a30d853e39a326b7017026a20e94bc45541': 245, '08606f2a0f0a6c9de204020b4632e09fcee0ae56': 168, '09dbd0948e5b8c1b1f0930778babe65c8a81295e': 243, ...}, 'iteration': 279, 'max_history_score': 0.9666666666666668, 'max_history_score_std': 0.033333333333333326, 'max_history_step': 'joint'}, config={'algorithm': 'RandomForest', 'seed': 42, 'time': 300})
    108 
    109 def objective_algo(algo_config, current_pipeline_config, algorithm, X, y, context, config):
    110     return objective(current_pipeline_config, algo_config, algorithm, X, y, context, config, step='algorithm')
    111 
    112 def objective_joint(wconfig, algorithm, X, y, context, config):
--> 113     return objective(wconfig['pipeline'], wconfig['algorithm'], algorithm, X, y, context, config, step='joint')
        wconfig = {'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': 4, 'max_features': 3, 'max_leaf_nodes': 3, 'min_samples_split': 3, 'n_estimators': 75}, 'pipeline': {'features': ('features_PCA', {'features__n_components': 2}), 'normalizer': ('normalizer_PowerTransformer', {}), 'rebalance': ('rebalance_CondensedNearestNeighbour', {'rebalance__n_neighbors': 2})}}
        algorithm = 'RandomForest'
        X = array([[5.1, 3.5, 1.4, 0.2],
       [4.9, 3. , 1....2, 3.4, 5.4, 2.3],
       [5.9, 3. , 5.1, 1.8]])
        y = array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,... 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2])
        context = {'baseline_score': 0.9466666666666667, 'baseline_score_std': 0.04988876515698587, 'best_config': {'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': 4, 'max_features': 3, 'max_leaf_nodes': 3, 'min_samples_split': 3, 'n_estimators': 10}, 'config_hash': {'algorithm': 'ffb7ff225ce3d3712c96cf87fe42202988ee2eb0', 'config': 'bae32f426be9cd6243523c023944a8c148fe4aeb', 'pipeline': 'd2a68bfda6fcdec4ae0ffc7d7b6a2122bc1cd673'}, 'duration': 0.7115809917449951, 'iteration': 113, 'loss': 0.033333333333333215, 'max_history_score': 0.9666666666666668, 'max_history_score_std': 0.033333333333333326, 'max_history_step': 'joint', 'pipeline': {'features': ('features_NoneType', {}), 'normalizer': ('normalizer_PowerTransformer', {}), 'rebalance': ('rebalance_CondensedNearestNeighbour', {'rebalance__n_neighbors': 2})}, 'score': 0.9666666666666668, ...}, 'history': [{'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': 2, 'max_features': None, 'max_leaf_nodes': 5, 'min_samples_split': 2, 'n_estimators': 75}, 'config_hash': {'algorithm': '3af5b0cce71c8fe2545246ca24ff5bc3dd516e06', 'config': 'db6ac7e6d348155757e4794bb5f88fe2b4f63d50', 'pipeline': '8d59f4b94cef6be9306ed86a22a9570fa670d567'}, 'duration': 1.149928092956543, 'iteration': 0, 'loss': 0.046666666666666634, 'max_history_score': 0.9533333333333334, 'max_history_score_std': 0.059999999999999984, 'max_history_step': 'joint', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 4, 'features__selectkbest__k': 3}), 'normalizer': ('normalizer_StandardScaler', {'normalizer__with_mean': True, 'normalizer__with_std': True}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 6})}, 'score': 0.9533333333333334, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': 1, 'max_features': 2, 'max_leaf_nodes': 2, 'min_samples_split': 5, 'n_estimators': 100}, 'config_hash': {'algorithm': 'e13eb05fd9a62d2f63bbb1c1deff0cd620d5e6ab', 'config': '4db6fb84d85f52659f780e682ffac5712c3d8a94', 'pipeline': '64c9a1ca9d53ae67244bdd942f4db36a3c05218c'}, 'duration': 1.7678282260894775, 'iteration': 1, 'loss': 0.18000000000000005, 'max_history_score': 0.9533333333333334, 'max_history_score_std': 0.059999999999999984, 'max_history_step': 'joint', 'pipeline': {'features': ('features_NoneType', {}), 'normalizer': ('normalizer_PowerTransformer', {}), 'rebalance': ('rebalance_NearMiss', {'rebalance__n_neighbors': 1})}, 'score': 0.82, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': 1, 'max_features': None, 'max_leaf_nodes': None, 'min_samples_split': 5, 'n_estimators': 75}, 'config_hash': {'algorithm': '94b0d7a654c508cc63643f78fe4f0f07e6f07c1e', 'config': '4403c5a85e951938d3c454e961d3a412780722f6', 'pipeline': '3e47444880d8367fbac2faaba2e52a917274aa58'}, 'duration': 0.8397619724273682, 'iteration': 2, 'loss': 0.03333333333333344, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_PCA', {'features__n_components': 3}), 'normalizer': ('normalizer_MinMaxScaler', {}), 'rebalance': ('rebalance_NoneType', {})}, 'score': 0.9666666666666666, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': None, 'max_features': None, 'max_leaf_nodes': 3, 'min_samples_split': 3, 'n_estimators': 75}, 'config_hash': {'algorithm': 'e8332f0a8902bda03bf70e7978cc5d52affb29d3', 'config': 'a064e2df18ab98d44dabcefbc7bed94913f1d0be', 'pipeline': '7eea819c2a8c103c4b1e9e9c1e224aebba95081f'}, 'duration': 0.8501448631286621, 'iteration': 3, 'loss': 0.053333333333333344, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 2, 'features__selectkbest__k': 4}), 'normalizer': ('normalizer_NoneType', {}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 7})}, 'score': 0.9466666666666667, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'entropy', 'max_depth': 3, 'max_features': 3, 'max_leaf_nodes': None, 'min_samples_split': 5, 'n_estimators': 75}, 'config_hash': {'algorithm': '7a4491035bc6bd737fe9a8cda8a79a02d02d5c74', 'config': '0ddb6f5cab3db4dddd7682966a57205f3e329ad4', 'pipeline': 'a9ae03fe38334f6868cbf84cdd3d629d4bbe3fb0'}, 'duration': 1.1026010513305664, 'iteration': 4, 'loss': 0.05999999999999994, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 2, 'features__selectkbest__k': 1}), 'normalizer': ('normalizer_NoneType', {}), 'rebalance': ('rebalance_NoneType', {})}, 'score': 0.9400000000000001, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'gini', 'max_depth': 3, 'max_features': 1, 'max_leaf_nodes': 5, 'min_samples_split': 2, 'n_estimators': 25}, 'config_hash': {'algorithm': '9826d20b2d6a0f559cf7f16450ce7526f07e8434', 'config': '49f25751bca61cdd461a8cbd2923689b642f98ed', 'pipeline': '19b249664c5bf067de1fed4334a296f947ce774a'}, 'duration': 0.35647010803222656, 'iteration': 5, 'loss': 0.046666666666666634, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_NoneType', {}), 'normalizer': ('normalizer_NoneType', {}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 6})}, 'score': 0.9533333333333334, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'gini', 'max_depth': 2, 'max_features': 1, 'max_leaf_nodes': 2, 'min_samples_split': 2, 'n_estimators': 50}, 'config_hash': {'algorithm': '0a4f6fbb07e0f32c6f675489a0fc82eee05bd8e1', 'config': '5c3a2b6f5e63fb45f10e41e0318b354912ec44f6', 'pipeline': 'dc3b9f176f090005e38b142f11d80e93a7dc5d5e'}, 'duration': 0.7213859558105469, 'iteration': 6, 'loss': 0.31333333333333324, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 1, 'features__selectkbest__k': 4}), 'normalizer': ('normalizer_PowerTransformer', {}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 7})}, 'score': 0.6866666666666668, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'entropy', 'max_depth': 4, 'max_features': 3, 'max_leaf_nodes': 5, 'min_samples_split': 5, 'n_estimators': 10}, 'config_hash': {'algorithm': 'b8112b97ecfc10f00a195af661dcc861cac21289', 'config': 'd3b129b397350f1b6572651c67c01de49b4b174c', 'pipeline': '5b0357ed7072c37b3d6f458bb5d49ff7d825f603'}, 'duration': 0.8299109935760498, 'iteration': 7, 'loss': 1.0, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_PCA', {'features__n_components': 2}), 'normalizer': ('normalizer_StandardScaler', {'normalizer__with_mean': True, 'normalizer__with_std': False}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 6})}, 'score': 0.0, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'gini', 'max_depth': 4, 'max_features': None, 'max_leaf_nodes': 2, 'min_samples_split': 5, 'n_estimators': 100}, 'config_hash': {'algorithm': '40ca24df19b8d164d9d098a6bed1ce056fbbb961', 'config': '813bde1108cc3c4b9bfb3a22cbb421bda7eac671', 'pipeline': '74a7b8705a1c22f7dea5e44e4ebda8f1e48add71'}, 'duration': 2.2111589908599854, 'iteration': 8, 'loss': 0.33333333333333326, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_PCA', {'features__n_components': 2}), 'normalizer': ('normalizer_StandardScaler', {'normalizer__with_mean': False, 'normalizer__with_std': True}), 'rebalance': ('rebalance_NearMiss', {'rebalance__n_neighbors': 2})}, 'score': 0.6666666666666667, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'entropy', 'max_depth': 2, 'max_features': 1, 'max_leaf_nodes': 5, 'min_samples_split': 2, 'n_estimators': 100}, 'config_hash': {'algorithm': '331418a5c12cf1453876eef85e9d98fc8e54fa11', 'config': '31930b6860ed406d59bf7e59ba1925d94704bd3b', 'pipeline': '054bef356f90ec6f644ef3ffc688766744db51c2'}, 'duration': 1.0501940250396729, 'iteration': 9, 'loss': 0.053333333333333344, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_SelectKBest', {'features__k': 1}), 'normalizer': ('normalizer_RobustScaler', {'normalizer__quantile_range': (...), 'normalizer__with_centering': True, 'normalizer__with_scaling': True}), 'rebalance': ('rebalance_NearMiss', {'rebalance__n_neighbors': 2})}, 'score': 0.9466666666666667, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'entropy', 'max_depth': 3, 'max_features': None, 'max_leaf_nodes': 3, 'min_samples_split': 2, 'n_estimators': 100}, 'config_hash': {'algorithm': 'dbc1b8126649fe93dce5fbb37e4015b0acfb179e', 'config': '9913cd550615a9d0946ab4a755a8b9f619e442fd', 'pipeline': 'dd626121cea079ebb32e184ca65483ec7a6d7f59'}, 'duration': 1.120617151260376, 'iteration': 10, 'loss': 0.046666666666666634, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 2, 'features__selectkbest__k': 1}), 'normalizer': ('normalizer_MinMaxScaler', {}), 'rebalance': ('rebalance_NoneType', {})}, 'score': 0.9533333333333334, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'gini', 'max_depth': 3, 'max_features': 3, 'max_leaf_nodes': None, 'min_samples_split': 3, 'n_estimators': 75}, 'config_hash': {'algorithm': '34917a130df5a975f78bd7ec1a0c7b1ffdc787a9', 'config': '95fc8cadc088141290b7de9c388977e4685f0108', 'pipeline': '550d10faf2f08db48516cc3501558816d6a99bc0'}, 'duration': 1.4287099838256836, 'iteration': 11, 'loss': 0.19333333333333313, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 3, 'features__selectkbest__k': 4}), 'normalizer': ('normalizer_StandardScaler', {'normalizer__with_mean': False, 'normalizer__with_std': False}), 'rebalance': ('rebalance_CondensedNearestNeighbour', {'rebalance__n_neighbors': 1})}, 'score': 0.8066666666666669, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'entropy', 'max_depth': 1, 'max_features': 2, 'max_leaf_nodes': 5, 'min_samples_split': 2, 'n_estimators': 75}, 'config_hash': {'algorithm': '33f9abb4aee44a395a9f3b3ffa9ce80a8cdaed7c', 'config': '40fa726f0360cf6af55f9b5902d399d02f61f157', 'pipeline': 'cfd1d20841fe2153da762c95e79f95a3fb1e426a'}, 'duration': 1.2978079319000244, 'iteration': 12, 'loss': 0.053333333333333344, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_PCA', {'features__n_components': 4}), 'normalizer': ('normalizer_MinMaxScaler', {}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 7})}, 'score': 0.9466666666666667, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'entropy', 'max_depth': 4, 'max_features': 2, 'max_leaf_nodes': 5, 'min_samples_split': 3, 'n_estimators': 25}, 'config_hash': {'algorithm': '210111ec6562d09eb093e98ed69ef1c662e11a50', 'config': '0fb8e77c7bd9a58b72f1b33c21a59a09a8c676ba', 'pipeline': '5d269d759e0c7926a685a14b263ace8ae0071e4b'}, 'duration': 0.36649012565612793, 'iteration': 13, 'loss': 0.040000000000000036, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 2, 'features__selectkbest__k': 2}), 'normalizer': ('normalizer_NoneType', {}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 7})}, 'score': 0.96, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'entropy', 'max_depth': 3, 'max_features': 1, 'max_leaf_nodes': 5, 'min_samples_split': 2, 'n_estimators': 25}, 'config_hash': {'algorithm': '0e989a03980101fabf79eda3326ed2870e11d690', 'config': 'f4bffd5d8c67a9c5321a9943c4a99678f59a02b7', 'pipeline': '865ee1e3fe8334c3d5ecb2038d5a5d1b3ba50e75'}, 'duration': 0.35639500617980957, 'iteration': 14, 'loss': 0.046666666666666634, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_NoneType', {}), 'normalizer': ('normalizer_RobustScaler', {'normalizer__quantile_range': (...), 'normalizer__with_centering': True, 'normalizer__with_scaling': False}), 'rebalance': ('rebalance_NoneType', {})}, 'score': 0.9533333333333334, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'entropy', 'max_depth': None, 'max_features': 3, 'max_leaf_nodes': 3, 'min_samples_split': 5, 'n_estimators': 10}, 'config_hash': {'algorithm': '9c592e876c13de5e23e6de5b868e01755d63e72e', 'config': '1e6a68cd1eeac886d90724d78b1cb5fb76a3cde4', 'pipeline': '5a1ca4d82f21b7de0d2c918630a42510673fa36e'}, 'duration': 0.18141412734985352, 'iteration': 15, 'loss': 0.046666666666666634, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_SelectKBest', {'features__k': 3}), 'normalizer': ('normalizer_RobustScaler', {'normalizer__quantile_range': (...), 'normalizer__with_centering': True, 'normalizer__with_scaling': True}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 6})}, 'score': 0.9533333333333334, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': 1, 'max_features': None, 'max_leaf_nodes': None, 'min_samples_split': 5, 'n_estimators': 10}, 'config_hash': {'algorithm': '8bed77aef289bfd453b2858bd288ae5ba7160f2b', 'config': '781185bcb8999045de8d489f253a1a1ba4247932', 'pipeline': '1ece7eabedc2be9e5b0a1be65c570d08ffa3eb54'}, 'duration': 0.1636829376220703, 'iteration': 16, 'loss': 0.053333333333333344, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_NoneType', {}), 'normalizer': ('normalizer_NoneType', {}), 'rebalance': ('rebalance_NearMiss', {'rebalance__n_neighbors': 1})}, 'score': 0.9466666666666667, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'gini', 'max_depth': 3, 'max_features': 2, 'max_leaf_nodes': 2, 'min_samples_split': 5, 'n_estimators': 75}, 'config_hash': {'algorithm': '617b97d9ba21d3373bc51ffa9cccf9c6f91a77b3', 'config': '99fb425b4e8c5d80228cab94202252aa25cdf77c', 'pipeline': 'd6242929c3b515c7719e60423023ac604311afc3'}, 'duration': 0.8468999862670898, 'iteration': 17, 'loss': 0.24, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_PCA', {'features__n_components': 4}), 'normalizer': ('normalizer_PowerTransformer', {}), 'rebalance': ('rebalance_NearMiss', {'rebalance__n_neighbors': 2})}, 'score': 0.76, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': 1, 'max_features': 1, 'max_leaf_nodes': 2, 'min_samples_split': 5, 'n_estimators': 50}, 'config_hash': {'algorithm': 'b92d2697cdd4979da443369d6596229ec091626a', 'config': 'c513a3e13281206ad76187dd817b1fff93d54fe1', 'pipeline': 'c4b4f914a3ca8df967cade997a90366d85a371b9'}, 'duration': 0.6724588871002197, 'iteration': 18, 'loss': 0.23333333333333328, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 1, 'features__selectkbest__k': 3}), 'normalizer': ('normalizer_StandardScaler', {'normalizer__with_mean': True, 'normalizer__with_std': True}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 5})}, 'score': 0.7666666666666667, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'entropy', 'max_depth': None, 'max_features': None, 'max_leaf_nodes': 5, 'min_samples_split': 5, 'n_estimators': 10}, 'config_hash': {'algorithm': 'a0115de695e6cca2e81cbfb54df79bf4b43608b1', 'config': 'ba194015e20b5d67770e8c67342c3d8d0d01dc41', 'pipeline': '8d45fabfeb85ffdcabf7076bd0e65fffe97ce928'}, 'duration': 0.19424200057983398, 'iteration': 19, 'loss': 0.08666666666666667, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_PCA', {'features__n_components': 3}), 'normalizer': ('normalizer_NoneType', {}), 'rebalance': ('rebalance_NoneType', {})}, 'score': 0.9133333333333333, ...}, ...], 'history_hash': ['db6ac7e6d348155757e4794bb5f88fe2b4f63d50', '4db6fb84d85f52659f780e682ffac5712c3d8a94', '4403c5a85e951938d3c454e961d3a412780722f6', 'a064e2df18ab98d44dabcefbc7bed94913f1d0be', '0ddb6f5cab3db4dddd7682966a57205f3e329ad4', '49f25751bca61cdd461a8cbd2923689b642f98ed', '5c3a2b6f5e63fb45f10e41e0318b354912ec44f6', 'd3b129b397350f1b6572651c67c01de49b4b174c', '813bde1108cc3c4b9bfb3a22cbb421bda7eac671', '31930b6860ed406d59bf7e59ba1925d94704bd3b', '9913cd550615a9d0946ab4a755a8b9f619e442fd', '95fc8cadc088141290b7de9c388977e4685f0108', '40fa726f0360cf6af55f9b5902d399d02f61f157', '0fb8e77c7bd9a58b72f1b33c21a59a09a8c676ba', 'f4bffd5d8c67a9c5321a9943c4a99678f59a02b7', '1e6a68cd1eeac886d90724d78b1cb5fb76a3cde4', '781185bcb8999045de8d489f253a1a1ba4247932', '99fb425b4e8c5d80228cab94202252aa25cdf77c', 'c513a3e13281206ad76187dd817b1fff93d54fe1', 'ba194015e20b5d67770e8c67342c3d8d0d01dc41', ...], 'history_index': {'00f0493590a2cb5e98a35b29816f8cd9f87f96ec': 208, '013329309d510b94f19d930320402d65f953a847': 39, '038a0f515e2ec894ee8e34f9caa2889eb3ebd5ce': 66, '052ae4bf232b316187b078abae42c2be19e16a00': 111, '05e9258ebf99dd97202167ef1563fa834b0568f1': 242, '0659afebf316aafeb75612fb07081a04c28545ed': 74, '06e7cde9f3556cd01332ce389ad1d8925cd4b4a4': 120, '07ab8a30d853e39a326b7017026a20e94bc45541': 245, '08606f2a0f0a6c9de204020b4632e09fcee0ae56': 168, '09dbd0948e5b8c1b1f0930778babe65c8a81295e': 243, ...}, 'iteration': 279, 'max_history_score': 0.9666666666666668, 'max_history_score_std': 0.033333333333333326, 'max_history_step': 'joint'}
        config = {'algorithm': 'RandomForest', 'seed': 42, 'time': 300}
    114 
    115 
    116 def get_baseline_score(algorithm, X, y, seed):
    117     pipeline, _ = pipeline_conf_to_full_pipeline(

...........................................................................
/home/aquemy/dev/dp_hyperparameters/extension/experiment/objective.py in objective(pipeline_config={'features': ('features_PCA', {'features__n_components': 2}), 'normalizer': ('normalizer_PowerTransformer', {}), 'rebalance': ('rebalance_CondensedNearestNeighbour', {'rebalance__n_neighbors': 2})}, algo_config={'bootstrap': True, 'criterion': 'gini', 'max_depth': 4, 'max_features': 3, 'max_leaf_nodes': 3, 'min_samples_split': 3, 'n_estimators': 75}, algorithm='RandomForest', X=array([[5.1, 3.5, 1.4, 0.2],
       [4.9, 3. , 1....2, 3.4, 5.4, 2.3],
       [5.9, 3. , 5.1, 1.8]]), y=array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,... 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]), context={'baseline_score': 0.9466666666666667, 'baseline_score_std': 0.04988876515698587, 'best_config': {'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': 4, 'max_features': 3, 'max_leaf_nodes': 3, 'min_samples_split': 3, 'n_estimators': 10}, 'config_hash': {'algorithm': 'ffb7ff225ce3d3712c96cf87fe42202988ee2eb0', 'config': 'bae32f426be9cd6243523c023944a8c148fe4aeb', 'pipeline': 'd2a68bfda6fcdec4ae0ffc7d7b6a2122bc1cd673'}, 'duration': 0.7115809917449951, 'iteration': 113, 'loss': 0.033333333333333215, 'max_history_score': 0.9666666666666668, 'max_history_score_std': 0.033333333333333326, 'max_history_step': 'joint', 'pipeline': {'features': ('features_NoneType', {}), 'normalizer': ('normalizer_PowerTransformer', {}), 'rebalance': ('rebalance_CondensedNearestNeighbour', {'rebalance__n_neighbors': 2})}, 'score': 0.9666666666666668, ...}, 'history': [{'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': 2, 'max_features': None, 'max_leaf_nodes': 5, 'min_samples_split': 2, 'n_estimators': 75}, 'config_hash': {'algorithm': '3af5b0cce71c8fe2545246ca24ff5bc3dd516e06', 'config': 'db6ac7e6d348155757e4794bb5f88fe2b4f63d50', 'pipeline': '8d59f4b94cef6be9306ed86a22a9570fa670d567'}, 'duration': 1.149928092956543, 'iteration': 0, 'loss': 0.046666666666666634, 'max_history_score': 0.9533333333333334, 'max_history_score_std': 0.059999999999999984, 'max_history_step': 'joint', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 4, 'features__selectkbest__k': 3}), 'normalizer': ('normalizer_StandardScaler', {'normalizer__with_mean': True, 'normalizer__with_std': True}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 6})}, 'score': 0.9533333333333334, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': 1, 'max_features': 2, 'max_leaf_nodes': 2, 'min_samples_split': 5, 'n_estimators': 100}, 'config_hash': {'algorithm': 'e13eb05fd9a62d2f63bbb1c1deff0cd620d5e6ab', 'config': '4db6fb84d85f52659f780e682ffac5712c3d8a94', 'pipeline': '64c9a1ca9d53ae67244bdd942f4db36a3c05218c'}, 'duration': 1.7678282260894775, 'iteration': 1, 'loss': 0.18000000000000005, 'max_history_score': 0.9533333333333334, 'max_history_score_std': 0.059999999999999984, 'max_history_step': 'joint', 'pipeline': {'features': ('features_NoneType', {}), 'normalizer': ('normalizer_PowerTransformer', {}), 'rebalance': ('rebalance_NearMiss', {'rebalance__n_neighbors': 1})}, 'score': 0.82, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': 1, 'max_features': None, 'max_leaf_nodes': None, 'min_samples_split': 5, 'n_estimators': 75}, 'config_hash': {'algorithm': '94b0d7a654c508cc63643f78fe4f0f07e6f07c1e', 'config': '4403c5a85e951938d3c454e961d3a412780722f6', 'pipeline': '3e47444880d8367fbac2faaba2e52a917274aa58'}, 'duration': 0.8397619724273682, 'iteration': 2, 'loss': 0.03333333333333344, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_PCA', {'features__n_components': 3}), 'normalizer': ('normalizer_MinMaxScaler', {}), 'rebalance': ('rebalance_NoneType', {})}, 'score': 0.9666666666666666, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': None, 'max_features': None, 'max_leaf_nodes': 3, 'min_samples_split': 3, 'n_estimators': 75}, 'config_hash': {'algorithm': 'e8332f0a8902bda03bf70e7978cc5d52affb29d3', 'config': 'a064e2df18ab98d44dabcefbc7bed94913f1d0be', 'pipeline': '7eea819c2a8c103c4b1e9e9c1e224aebba95081f'}, 'duration': 0.8501448631286621, 'iteration': 3, 'loss': 0.053333333333333344, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 2, 'features__selectkbest__k': 4}), 'normalizer': ('normalizer_NoneType', {}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 7})}, 'score': 0.9466666666666667, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'entropy', 'max_depth': 3, 'max_features': 3, 'max_leaf_nodes': None, 'min_samples_split': 5, 'n_estimators': 75}, 'config_hash': {'algorithm': '7a4491035bc6bd737fe9a8cda8a79a02d02d5c74', 'config': '0ddb6f5cab3db4dddd7682966a57205f3e329ad4', 'pipeline': 'a9ae03fe38334f6868cbf84cdd3d629d4bbe3fb0'}, 'duration': 1.1026010513305664, 'iteration': 4, 'loss': 0.05999999999999994, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 2, 'features__selectkbest__k': 1}), 'normalizer': ('normalizer_NoneType', {}), 'rebalance': ('rebalance_NoneType', {})}, 'score': 0.9400000000000001, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'gini', 'max_depth': 3, 'max_features': 1, 'max_leaf_nodes': 5, 'min_samples_split': 2, 'n_estimators': 25}, 'config_hash': {'algorithm': '9826d20b2d6a0f559cf7f16450ce7526f07e8434', 'config': '49f25751bca61cdd461a8cbd2923689b642f98ed', 'pipeline': '19b249664c5bf067de1fed4334a296f947ce774a'}, 'duration': 0.35647010803222656, 'iteration': 5, 'loss': 0.046666666666666634, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_NoneType', {}), 'normalizer': ('normalizer_NoneType', {}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 6})}, 'score': 0.9533333333333334, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'gini', 'max_depth': 2, 'max_features': 1, 'max_leaf_nodes': 2, 'min_samples_split': 2, 'n_estimators': 50}, 'config_hash': {'algorithm': '0a4f6fbb07e0f32c6f675489a0fc82eee05bd8e1', 'config': '5c3a2b6f5e63fb45f10e41e0318b354912ec44f6', 'pipeline': 'dc3b9f176f090005e38b142f11d80e93a7dc5d5e'}, 'duration': 0.7213859558105469, 'iteration': 6, 'loss': 0.31333333333333324, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 1, 'features__selectkbest__k': 4}), 'normalizer': ('normalizer_PowerTransformer', {}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 7})}, 'score': 0.6866666666666668, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'entropy', 'max_depth': 4, 'max_features': 3, 'max_leaf_nodes': 5, 'min_samples_split': 5, 'n_estimators': 10}, 'config_hash': {'algorithm': 'b8112b97ecfc10f00a195af661dcc861cac21289', 'config': 'd3b129b397350f1b6572651c67c01de49b4b174c', 'pipeline': '5b0357ed7072c37b3d6f458bb5d49ff7d825f603'}, 'duration': 0.8299109935760498, 'iteration': 7, 'loss': 1.0, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_PCA', {'features__n_components': 2}), 'normalizer': ('normalizer_StandardScaler', {'normalizer__with_mean': True, 'normalizer__with_std': False}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 6})}, 'score': 0.0, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'gini', 'max_depth': 4, 'max_features': None, 'max_leaf_nodes': 2, 'min_samples_split': 5, 'n_estimators': 100}, 'config_hash': {'algorithm': '40ca24df19b8d164d9d098a6bed1ce056fbbb961', 'config': '813bde1108cc3c4b9bfb3a22cbb421bda7eac671', 'pipeline': '74a7b8705a1c22f7dea5e44e4ebda8f1e48add71'}, 'duration': 2.2111589908599854, 'iteration': 8, 'loss': 0.33333333333333326, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_PCA', {'features__n_components': 2}), 'normalizer': ('normalizer_StandardScaler', {'normalizer__with_mean': False, 'normalizer__with_std': True}), 'rebalance': ('rebalance_NearMiss', {'rebalance__n_neighbors': 2})}, 'score': 0.6666666666666667, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'entropy', 'max_depth': 2, 'max_features': 1, 'max_leaf_nodes': 5, 'min_samples_split': 2, 'n_estimators': 100}, 'config_hash': {'algorithm': '331418a5c12cf1453876eef85e9d98fc8e54fa11', 'config': '31930b6860ed406d59bf7e59ba1925d94704bd3b', 'pipeline': '054bef356f90ec6f644ef3ffc688766744db51c2'}, 'duration': 1.0501940250396729, 'iteration': 9, 'loss': 0.053333333333333344, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_SelectKBest', {'features__k': 1}), 'normalizer': ('normalizer_RobustScaler', {'normalizer__quantile_range': (...), 'normalizer__with_centering': True, 'normalizer__with_scaling': True}), 'rebalance': ('rebalance_NearMiss', {'rebalance__n_neighbors': 2})}, 'score': 0.9466666666666667, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'entropy', 'max_depth': 3, 'max_features': None, 'max_leaf_nodes': 3, 'min_samples_split': 2, 'n_estimators': 100}, 'config_hash': {'algorithm': 'dbc1b8126649fe93dce5fbb37e4015b0acfb179e', 'config': '9913cd550615a9d0946ab4a755a8b9f619e442fd', 'pipeline': 'dd626121cea079ebb32e184ca65483ec7a6d7f59'}, 'duration': 1.120617151260376, 'iteration': 10, 'loss': 0.046666666666666634, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 2, 'features__selectkbest__k': 1}), 'normalizer': ('normalizer_MinMaxScaler', {}), 'rebalance': ('rebalance_NoneType', {})}, 'score': 0.9533333333333334, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'gini', 'max_depth': 3, 'max_features': 3, 'max_leaf_nodes': None, 'min_samples_split': 3, 'n_estimators': 75}, 'config_hash': {'algorithm': '34917a130df5a975f78bd7ec1a0c7b1ffdc787a9', 'config': '95fc8cadc088141290b7de9c388977e4685f0108', 'pipeline': '550d10faf2f08db48516cc3501558816d6a99bc0'}, 'duration': 1.4287099838256836, 'iteration': 11, 'loss': 0.19333333333333313, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 3, 'features__selectkbest__k': 4}), 'normalizer': ('normalizer_StandardScaler', {'normalizer__with_mean': False, 'normalizer__with_std': False}), 'rebalance': ('rebalance_CondensedNearestNeighbour', {'rebalance__n_neighbors': 1})}, 'score': 0.8066666666666669, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'entropy', 'max_depth': 1, 'max_features': 2, 'max_leaf_nodes': 5, 'min_samples_split': 2, 'n_estimators': 75}, 'config_hash': {'algorithm': '33f9abb4aee44a395a9f3b3ffa9ce80a8cdaed7c', 'config': '40fa726f0360cf6af55f9b5902d399d02f61f157', 'pipeline': 'cfd1d20841fe2153da762c95e79f95a3fb1e426a'}, 'duration': 1.2978079319000244, 'iteration': 12, 'loss': 0.053333333333333344, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_PCA', {'features__n_components': 4}), 'normalizer': ('normalizer_MinMaxScaler', {}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 7})}, 'score': 0.9466666666666667, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'entropy', 'max_depth': 4, 'max_features': 2, 'max_leaf_nodes': 5, 'min_samples_split': 3, 'n_estimators': 25}, 'config_hash': {'algorithm': '210111ec6562d09eb093e98ed69ef1c662e11a50', 'config': '0fb8e77c7bd9a58b72f1b33c21a59a09a8c676ba', 'pipeline': '5d269d759e0c7926a685a14b263ace8ae0071e4b'}, 'duration': 0.36649012565612793, 'iteration': 13, 'loss': 0.040000000000000036, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 2, 'features__selectkbest__k': 2}), 'normalizer': ('normalizer_NoneType', {}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 7})}, 'score': 0.96, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'entropy', 'max_depth': 3, 'max_features': 1, 'max_leaf_nodes': 5, 'min_samples_split': 2, 'n_estimators': 25}, 'config_hash': {'algorithm': '0e989a03980101fabf79eda3326ed2870e11d690', 'config': 'f4bffd5d8c67a9c5321a9943c4a99678f59a02b7', 'pipeline': '865ee1e3fe8334c3d5ecb2038d5a5d1b3ba50e75'}, 'duration': 0.35639500617980957, 'iteration': 14, 'loss': 0.046666666666666634, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_NoneType', {}), 'normalizer': ('normalizer_RobustScaler', {'normalizer__quantile_range': (...), 'normalizer__with_centering': True, 'normalizer__with_scaling': False}), 'rebalance': ('rebalance_NoneType', {})}, 'score': 0.9533333333333334, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'entropy', 'max_depth': None, 'max_features': 3, 'max_leaf_nodes': 3, 'min_samples_split': 5, 'n_estimators': 10}, 'config_hash': {'algorithm': '9c592e876c13de5e23e6de5b868e01755d63e72e', 'config': '1e6a68cd1eeac886d90724d78b1cb5fb76a3cde4', 'pipeline': '5a1ca4d82f21b7de0d2c918630a42510673fa36e'}, 'duration': 0.18141412734985352, 'iteration': 15, 'loss': 0.046666666666666634, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_SelectKBest', {'features__k': 3}), 'normalizer': ('normalizer_RobustScaler', {'normalizer__quantile_range': (...), 'normalizer__with_centering': True, 'normalizer__with_scaling': True}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 6})}, 'score': 0.9533333333333334, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': 1, 'max_features': None, 'max_leaf_nodes': None, 'min_samples_split': 5, 'n_estimators': 10}, 'config_hash': {'algorithm': '8bed77aef289bfd453b2858bd288ae5ba7160f2b', 'config': '781185bcb8999045de8d489f253a1a1ba4247932', 'pipeline': '1ece7eabedc2be9e5b0a1be65c570d08ffa3eb54'}, 'duration': 0.1636829376220703, 'iteration': 16, 'loss': 0.053333333333333344, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_NoneType', {}), 'normalizer': ('normalizer_NoneType', {}), 'rebalance': ('rebalance_NearMiss', {'rebalance__n_neighbors': 1})}, 'score': 0.9466666666666667, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'gini', 'max_depth': 3, 'max_features': 2, 'max_leaf_nodes': 2, 'min_samples_split': 5, 'n_estimators': 75}, 'config_hash': {'algorithm': '617b97d9ba21d3373bc51ffa9cccf9c6f91a77b3', 'config': '99fb425b4e8c5d80228cab94202252aa25cdf77c', 'pipeline': 'd6242929c3b515c7719e60423023ac604311afc3'}, 'duration': 0.8468999862670898, 'iteration': 17, 'loss': 0.24, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_PCA', {'features__n_components': 4}), 'normalizer': ('normalizer_PowerTransformer', {}), 'rebalance': ('rebalance_NearMiss', {'rebalance__n_neighbors': 2})}, 'score': 0.76, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': 1, 'max_features': 1, 'max_leaf_nodes': 2, 'min_samples_split': 5, 'n_estimators': 50}, 'config_hash': {'algorithm': 'b92d2697cdd4979da443369d6596229ec091626a', 'config': 'c513a3e13281206ad76187dd817b1fff93d54fe1', 'pipeline': 'c4b4f914a3ca8df967cade997a90366d85a371b9'}, 'duration': 0.6724588871002197, 'iteration': 18, 'loss': 0.23333333333333328, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 1, 'features__selectkbest__k': 3}), 'normalizer': ('normalizer_StandardScaler', {'normalizer__with_mean': True, 'normalizer__with_std': True}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 5})}, 'score': 0.7666666666666667, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'entropy', 'max_depth': None, 'max_features': None, 'max_leaf_nodes': 5, 'min_samples_split': 5, 'n_estimators': 10}, 'config_hash': {'algorithm': 'a0115de695e6cca2e81cbfb54df79bf4b43608b1', 'config': 'ba194015e20b5d67770e8c67342c3d8d0d01dc41', 'pipeline': '8d45fabfeb85ffdcabf7076bd0e65fffe97ce928'}, 'duration': 0.19424200057983398, 'iteration': 19, 'loss': 0.08666666666666667, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_PCA', {'features__n_components': 3}), 'normalizer': ('normalizer_NoneType', {}), 'rebalance': ('rebalance_NoneType', {})}, 'score': 0.9133333333333333, ...}, ...], 'history_hash': ['db6ac7e6d348155757e4794bb5f88fe2b4f63d50', '4db6fb84d85f52659f780e682ffac5712c3d8a94', '4403c5a85e951938d3c454e961d3a412780722f6', 'a064e2df18ab98d44dabcefbc7bed94913f1d0be', '0ddb6f5cab3db4dddd7682966a57205f3e329ad4', '49f25751bca61cdd461a8cbd2923689b642f98ed', '5c3a2b6f5e63fb45f10e41e0318b354912ec44f6', 'd3b129b397350f1b6572651c67c01de49b4b174c', '813bde1108cc3c4b9bfb3a22cbb421bda7eac671', '31930b6860ed406d59bf7e59ba1925d94704bd3b', '9913cd550615a9d0946ab4a755a8b9f619e442fd', '95fc8cadc088141290b7de9c388977e4685f0108', '40fa726f0360cf6af55f9b5902d399d02f61f157', '0fb8e77c7bd9a58b72f1b33c21a59a09a8c676ba', 'f4bffd5d8c67a9c5321a9943c4a99678f59a02b7', '1e6a68cd1eeac886d90724d78b1cb5fb76a3cde4', '781185bcb8999045de8d489f253a1a1ba4247932', '99fb425b4e8c5d80228cab94202252aa25cdf77c', 'c513a3e13281206ad76187dd817b1fff93d54fe1', 'ba194015e20b5d67770e8c67342c3d8d0d01dc41', ...], 'history_index': {'00f0493590a2cb5e98a35b29816f8cd9f87f96ec': 208, '013329309d510b94f19d930320402d65f953a847': 39, '038a0f515e2ec894ee8e34f9caa2889eb3ebd5ce': 66, '052ae4bf232b316187b078abae42c2be19e16a00': 111, '05e9258ebf99dd97202167ef1563fa834b0568f1': 242, '0659afebf316aafeb75612fb07081a04c28545ed': 74, '06e7cde9f3556cd01332ce389ad1d8925cd4b4a4': 120, '07ab8a30d853e39a326b7017026a20e94bc45541': 245, '08606f2a0f0a6c9de204020b4632e09fcee0ae56': 168, '09dbd0948e5b8c1b1f0930778babe65c8a81295e': 243, ...}, 'iteration': 279, 'max_history_score': 0.9666666666666668, 'max_history_score_std': 0.033333333333333326, 'max_history_step': 'joint'}, config={'algorithm': 'RandomForest', 'seed': 42, 'time': 300}, step='joint')
     45                 y,
     46                 cv=10,
     47                 n_jobs=-1,
     48                 return_estimator=False,
     49                 return_train_score=False,
---> 50                 verbose=0)
     51         score = np.mean(scores['test_score'])
     52         std = np.std(scores['test_score'])
     53         status = STATUS_OK
     54     except Exception as e:

...........................................................................
/home/aquemy/.local/lib/python2.7/site-packages/sklearn/model_selection/_validation.py in cross_validate(estimator=Pipeline(memory=None,
     steps=[('rebalance', ... random_state=42, verbose=0, warm_start=False))]), X=array([[5.1, 3.5, 1.4, 0.2],
       [4.9, 3. , 1....2, 3.4, 5.4, 2.3],
       [5.9, 3. , 5.1, 1.8]]), y=array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,... 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]), groups=None, scoring=None, cv=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1, verbose=0, fit_params=None, pre_dispatch='2*n_jobs', return_train_score=False, return_estimator=False, error_score='raise-deprecating')
    235         delayed(_fit_and_score)(
    236             clone(estimator), X, y, scorers, train, test, verbose, None,
    237             fit_params, return_train_score=return_train_score,
    238             return_times=True, return_estimator=return_estimator,
    239             error_score=error_score)
--> 240         for train, test in cv.split(X, y, groups))
        cv.split = <bound method StratifiedKFold.split of Stratifie...d(n_splits=10, random_state=None, shuffle=False)>
        X = array([[5.1, 3.5, 1.4, 0.2],
       [4.9, 3. , 1....2, 3.4, 5.4, 2.3],
       [5.9, 3. , 5.1, 1.8]])
        y = array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,... 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2])
        groups = None
    241 
    242     zipped_scores = list(zip(*scores))
    243     if return_train_score:
    244         train_scores = zipped_scores.pop(0)

...........................................................................
/home/aquemy/.local/lib/python2.7/site-packages/sklearn/externals/joblib/parallel.py in __call__(self=Parallel(n_jobs=-1), iterable=<generator object <genexpr>>)
    925                 # No need to wait for async callbacks to trigger to
    926                 # consumption.
    927                 self._iterating = False
    928 
    929             with self._backend.retrieval_context():
--> 930                 self.retrieve()
        self.retrieve = <bound method Parallel.retrieve of Parallel(n_jobs=-1)>
    931             # Make sure that we get a last message telling us we are done
    932             elapsed_time = time.time() - self._start_time
    933             self._print('Done %3i out of %3i | elapsed: %s finished',
    934                         (len(self._output), len(self._output),

---------------------------------------------------------------------------
Joblib worker traceback:
---------------------------------------------------------------------------
ValueError                                         Mon Jun 17 13:14:18 2019
PID: 21643                                  Python 2.7.15+: /usr/bin/python
...........................................................................
/home/aquemy/.local/lib/python2.7/site-packages/sklearn/externals/joblib/parallel.py in __call__(self=<sklearn.externals.joblib.parallel.BatchedCalls object>)
    220     def __call__(self):
    221         # Set the default nested backend to self._backend but do not set the
    222         # change the default number of processes to -1
    223         with parallel_backend(self._backend, n_jobs=self._n_jobs):
    224             return [func(*args, **kwargs)
--> 225                     for func, args, kwargs in self.items]
        func = <function _fit_and_score>
        args = (Pipeline(memory=None,
     steps=[('rebalance', ... random_state=42, verbose=0, warm_start=False))]), array([[5.1, 3.5, 1.4, 0.2],
       [4.9, 3. , 1....2, 3.4, 5.4, 2.3],
       [5.9, 3. , 5.1, 1.8]]), array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,... 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]), {'score': <function _passthrough_scorer>}, array([  5,   6,   7,   8,   9,  10,  11,  12,  ..., 142, 143, 144,
       145, 146, 147, 148, 149]), array([  0,   1,   2,   3,   4,  50,  51,  52,  53,  54, 100, 101, 102,
       103, 104]), 0, None, None)
        kwargs = {'error_score': 'raise-deprecating', 'return_estimator': False, 'return_times': True, 'return_train_score': False}
        self.items = [(<function _fit_and_score>, (Pipeline(memory=None,
     steps=[('rebalance', ... random_state=42, verbose=0, warm_start=False))]), array([[5.1, 3.5, 1.4, 0.2],
       [4.9, 3. , 1....2, 3.4, 5.4, 2.3],
       [5.9, 3. , 5.1, 1.8]]), array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,... 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]), {'score': <function _passthrough_scorer>}, array([  5,   6,   7,   8,   9,  10,  11,  12,  ..., 142, 143, 144,
       145, 146, 147, 148, 149]), array([  0,   1,   2,   3,   4,  50,  51,  52,  53,  54, 100, 101, 102,
       103, 104]), 0, None, None), {'error_score': 'raise-deprecating', 'return_estimator': False, 'return_times': True, 'return_train_score': False})]
    226 
    227     def __len__(self):
    228         return self._size
    229 

...........................................................................
/home/aquemy/.local/lib/python2.7/site-packages/sklearn/model_selection/_validation.py in _fit_and_score(estimator=Pipeline(memory=None,
     steps=[('rebalance', ... random_state=42, verbose=0, warm_start=False))]), X=array([[5.1, 3.5, 1.4, 0.2],
       [4.9, 3. , 1....2, 3.4, 5.4, 2.3],
       [5.9, 3. , 5.1, 1.8]]), y=array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,... 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]), scorer={'score': <function _passthrough_scorer>}, train=array([  5,   6,   7,   8,   9,  10,  11,  12,  ..., 142, 143, 144,
       145, 146, 147, 148, 149]), test=array([  0,   1,   2,   3,   4,  50,  51,  52,  53,  54, 100, 101, 102,
       103, 104]), verbose=0, parameters=None, fit_params={}, return_train_score=False, return_parameters=False, return_n_test_samples=False, return_times=True, return_estimator=False, error_score='raise-deprecating')
    523 
    524     try:
    525         if y_train is None:
    526             estimator.fit(X_train, **fit_params)
    527         else:
--> 528             estimator.fit(X_train, y_train, **fit_params)
        estimator.fit = <bound method Pipeline.fit of Pipeline(memory=No...random_state=42, verbose=0, warm_start=False))])>
        X_train = array([[5.4, 3.9, 1.7, 0.4],
       [4.6, 3.4, 1....2, 3.4, 5.4, 2.3],
       [5.9, 3. , 5.1, 1.8]])
        y_train = array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,
       2, 2, 2])
        fit_params = {}
    529 
    530     except Exception as e:
    531         # Note fit time as time until error
    532         fit_time = time.time() - start_time

...........................................................................
/usr/local/lib/python2.7/dist-packages/imblearn/pipeline.py in fit(self=Pipeline(memory=None,
     steps=[('rebalance', ... random_state=42, verbose=0, warm_start=False))]), X=array([[5.4, 3.9, 1.7, 0.4],
       [4.6, 3.4, 1....2, 3.4, 5.4, 2.3],
       [5.9, 3. , 5.1, 1.8]]), y=array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,
       2, 2, 2]), **fit_params={})
    234             This estimator
    235 
    236         """
    237         Xt, yt, fit_params = self._fit(X, y, **fit_params)
    238         if self._final_estimator is not None:
--> 239             self._final_estimator.fit(Xt, yt, **fit_params)
        self._final_estimator.fit = <bound method RandomForestClassifier.fit of Rand...e, random_state=42, verbose=0, warm_start=False)>
        Xt = array([[ 0.88875487, -1.28952128],
       [-0.72...-0.16298528],
       [ 2.60655505,  2.2460382 ]])
        yt = array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...0, 0, 0, 0, 0, 0, 0,
       0, 1, 1, 1, 2, 2, 2])
        fit_params = {}
    240         return self
    241 
    242     def fit_transform(self, X, y=None, **fit_params):
    243         """Fit the model and transform with the final estimator

...........................................................................
/home/aquemy/.local/lib/python2.7/site-packages/sklearn/ensemble/forest.py in fit(self=RandomForestClassifier(bootstrap=True, class_wei...se, random_state=42, verbose=0, warm_start=False), X=array([[ 0.88875484, -1.2895213 ],
       [-0.72...      [ 2.606555  ,  2.2460382 ]], dtype=float32), y=array([[0.],
       [0.],
       [0.],
       [0...    [1.],
       [2.],
       [2.],
       [2.]]), sample_weight=None)
    328             trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,
    329                              **_joblib_parallel_args(prefer='threads'))(
    330                 delayed(_parallel_build_trees)(
    331                     t, self, X, y, sample_weight, i, len(trees),
    332                     verbose=self.verbose, class_weight=self.class_weight)
--> 333                 for i, t in enumerate(trees))
        i = 74
    334 
    335             # Collect newly grown trees
    336             self.estimators_.extend(trees)
    337 

...........................................................................
/home/aquemy/.local/lib/python2.7/site-packages/sklearn/externals/joblib/parallel.py in __call__(self=Parallel(n_jobs=1), iterable=<generator object <genexpr>>)
    912             # self._original_iterator is None, then this means either
    913             # that pre_dispatch == "all", n_jobs == 1 or that the first batch
    914             # was very quick and its callback already dispatched all the
    915             # remaining jobs.
    916             self._iterating = False
--> 917             if self.dispatch_one_batch(iterator):
        self.dispatch_one_batch = <bound method Parallel.dispatch_one_batch of Parallel(n_jobs=1)>
        iterator = <generator object <genexpr>>
    918                 self._iterating = self._original_iterator is not None
    919 
    920             while self.dispatch_one_batch(iterator):
    921                 pass

...........................................................................
/home/aquemy/.local/lib/python2.7/site-packages/sklearn/externals/joblib/parallel.py in dispatch_one_batch(self=Parallel(n_jobs=1), iterator=<generator object <genexpr>>)
    754                                  self._pickle_cache)
    755             if len(tasks) == 0:
    756                 # No more tasks available in the iterator: tell caller to stop.
    757                 return False
    758             else:
--> 759                 self._dispatch(tasks)
        self._dispatch = <bound method Parallel._dispatch of Parallel(n_jobs=1)>
        tasks = <sklearn.externals.joblib.parallel.BatchedCalls object>
    760                 return True
    761 
    762     def _print(self, msg, msg_args):
    763         """Display the message on stout or stderr depending on verbosity"""

...........................................................................
/home/aquemy/.local/lib/python2.7/site-packages/sklearn/externals/joblib/parallel.py in _dispatch(self=Parallel(n_jobs=1), batch=<sklearn.externals.joblib.parallel.BatchedCalls object>)
    711 
    712         dispatch_timestamp = time.time()
    713         cb = BatchCompletionCallBack(dispatch_timestamp, len(batch), self)
    714         with self._lock:
    715             job_idx = len(self._jobs)
--> 716             job = self._backend.apply_async(batch, callback=cb)
        job = undefined
        self._backend.apply_async = <bound method SequentialBackend.apply_async of <...lib._parallel_backends.SequentialBackend object>>
        batch = <sklearn.externals.joblib.parallel.BatchedCalls object>
        cb = <sklearn.externals.joblib.parallel.BatchCompletionCallBack object>
    717             # A job can complete so quickly than its callback is
    718             # called before we get here, causing self._jobs to
    719             # grow. To ensure correct results ordering, .insert is
    720             # used (rather than .append) in the following line

...........................................................................
/home/aquemy/.local/lib/python2.7/site-packages/sklearn/externals/joblib/_parallel_backends.py in apply_async(self=<sklearn.externals.joblib._parallel_backends.SequentialBackend object>, func=<sklearn.externals.joblib.parallel.BatchedCalls object>, callback=<sklearn.externals.joblib.parallel.BatchCompletionCallBack object>)
    177             raise ValueError('n_jobs == 0 in Parallel has no meaning')
    178         return 1
    179 
    180     def apply_async(self, func, callback=None):
    181         """Schedule a func to be run"""
--> 182         result = ImmediateResult(func)
        result = undefined
        func = <sklearn.externals.joblib.parallel.BatchedCalls object>
    183         if callback:
    184             callback(result)
    185         return result
    186 

...........................................................................
/home/aquemy/.local/lib/python2.7/site-packages/sklearn/externals/joblib/_parallel_backends.py in __init__(self=<sklearn.externals.joblib._parallel_backends.ImmediateResult object>, batch=<sklearn.externals.joblib.parallel.BatchedCalls object>)
    544 
    545 class ImmediateResult(object):
    546     def __init__(self, batch):
    547         # Don't delay the application, to avoid keeping the input
    548         # arguments in memory
--> 549         self.results = batch()
        self.results = undefined
        batch = <sklearn.externals.joblib.parallel.BatchedCalls object>
    550 
    551     def get(self):
    552         return self.results
    553 

...........................................................................
/home/aquemy/.local/lib/python2.7/site-packages/sklearn/externals/joblib/parallel.py in __call__(self=<sklearn.externals.joblib.parallel.BatchedCalls object>)
    220     def __call__(self):
    221         # Set the default nested backend to self._backend but do not set the
    222         # change the default number of processes to -1
    223         with parallel_backend(self._backend, n_jobs=self._n_jobs):
    224             return [func(*args, **kwargs)
--> 225                     for func, args, kwargs in self.items]
        func = <function _parallel_build_trees>
        args = (DecisionTreeClassifier(class_weight=None, criter...=False, random_state=1608637542, splitter='best'), RandomForestClassifier(bootstrap=True, class_wei...se, random_state=42, verbose=0, warm_start=False), array([[ 0.88875484, -1.2895213 ],
       [-0.72...      [ 2.606555  ,  2.2460382 ]], dtype=float32), array([[0.],
       [0.],
       [0.],
       [0...    [1.],
       [2.],
       [2.],
       [2.]]), None, 0, 75)
        kwargs = {'class_weight': None, 'verbose': 0}
        self.items = [(<function _parallel_build_trees>, (DecisionTreeClassifier(class_weight=None, criter...=False, random_state=1608637542, splitter='best'), RandomForestClassifier(bootstrap=True, class_wei...se, random_state=42, verbose=0, warm_start=False), array([[ 0.88875484, -1.2895213 ],
       [-0.72...      [ 2.606555  ,  2.2460382 ]], dtype=float32), array([[0.],
       [0.],
       [0.],
       [0...    [1.],
       [2.],
       [2.],
       [2.]]), None, 0, 75), {'class_weight': None, 'verbose': 0})]
    226 
    227     def __len__(self):
    228         return self._size
    229 

...........................................................................
/home/aquemy/.local/lib/python2.7/site-packages/sklearn/ensemble/forest.py in _parallel_build_trees(tree=DecisionTreeClassifier(class_weight=None, criter...=False, random_state=1608637542, splitter='best'), forest=RandomForestClassifier(bootstrap=True, class_wei...se, random_state=42, verbose=0, warm_start=False), X=array([[ 0.88875484, -1.2895213 ],
       [-0.72...      [ 2.606555  ,  2.2460382 ]], dtype=float32), y=array([[0.],
       [0.],
       [0.],
       [0...    [1.],
       [2.],
       [2.],
       [2.]]), sample_weight=None, tree_idx=0, n_trees=75, verbose=0, class_weight=None)
    114                 simplefilter('ignore', DeprecationWarning)
    115                 curr_sample_weight *= compute_sample_weight('auto', y, indices)
    116         elif class_weight == 'balanced_subsample':
    117             curr_sample_weight *= compute_sample_weight('balanced', y, indices)
    118 
--> 119         tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)
        tree.fit = <bound method DecisionTreeClassifier.fit of Deci...False, random_state=1608637542, splitter='best')>
        X = array([[ 0.88875484, -1.2895213 ],
       [-0.72...      [ 2.606555  ,  2.2460382 ]], dtype=float32)
        y = array([[0.],
       [0.],
       [0.],
       [0...    [1.],
       [2.],
       [2.],
       [2.]])
        sample_weight = None
        curr_sample_weight = array([2., 0., 2., 1., 2., 0., 1., 2., 1., 1., 2... 2., 0., 4., 0., 2., 0., 0., 1., 0., 0., 3., 2.])
    120     else:
    121         tree.fit(X, y, sample_weight=sample_weight, check_input=False)
    122 
    123     return tree

...........................................................................
/home/aquemy/.local/lib/python2.7/site-packages/sklearn/tree/tree.py in fit(self=DecisionTreeClassifier(class_weight=None, criter...=False, random_state=1608637542, splitter='best'), X=array([[ 0.88875484, -1.2895213 ],
       [-0.72...      [ 2.606555  ,  2.2460382 ]], dtype=float32), y=array([[0.],
       [0.],
       [0.],
       [0...    [1.],
       [2.],
       [2.],
       [2.]]), sample_weight=array([2., 0., 2., 1., 2., 0., 1., 2., 1., 1., 2... 2., 0., 4., 0., 2., 0., 0., 1., 0., 0., 3., 2.]), check_input=False, X_idx_sorted=None)
    796 
    797         super(DecisionTreeClassifier, self).fit(
    798             X, y,
    799             sample_weight=sample_weight,
    800             check_input=check_input,
--> 801             X_idx_sorted=X_idx_sorted)
        X_idx_sorted = None
    802         return self
    803 
    804     def predict_proba(self, X, check_input=True):
    805         """Predict class probabilities of the input samples X.

...........................................................................
/home/aquemy/.local/lib/python2.7/site-packages/sklearn/tree/tree.py in fit(self=DecisionTreeClassifier(class_weight=None, criter...=False, random_state=1608637542, splitter='best'), X=array([[ 0.88875484, -1.2895213 ],
       [-0.72...      [ 2.606555  ,  2.2460382 ]], dtype=float32), y=array([[0.],
       [0.],
       [0.],
       [0...    [1.],
       [2.],
       [2.],
       [2.]]), sample_weight=array([2., 0., 2., 1., 2., 0., 1., 2., 1., 1., 2... 2., 0., 4., 0., 2., 0., 0., 1., 0., 0., 3., 2.]), check_input=False, X_idx_sorted=None)
    237         if not 0 <= self.min_weight_fraction_leaf <= 0.5:
    238             raise ValueError("min_weight_fraction_leaf must in [0, 0.5]")
    239         if max_depth <= 0:
    240             raise ValueError("max_depth must be greater than zero. ")
    241         if not (0 < max_features <= self.n_features_):
--> 242             raise ValueError("max_features must be in (0, n_features]")
    243         if not isinstance(max_leaf_nodes, (numbers.Integral, np.integer)):
    244             raise ValueError("max_leaf_nodes must be integral number but was "
    245                              "%r" % max_leaf_nodes)
    246         if -1 < max_leaf_nodes < 2:

ValueError: max_features must be in (0, n_features]
___________________________________________________________________________
Best score: 0.966666666667 (0.0333333333333) [J] | Score: 0.0 (0.0) [J]
Best score: 0.966666666667 (0.0333333333333) [J] | Score: 0.633333333333 (0.13416407865) [J]
Best score: 0.966666666667 (0.0333333333333) [J] | Score: 0.946666666667 (0.0581186525805) [J]
Best score: 0.966666666667 (0.0333333333333) [J] | Score: 0.526666666667 (0.100884973003) [J]
Best score: 0.966666666667 (0.0333333333333) [J] | Score: 0.94 (0.062893207547) [J]
JoblibValueError
___________________________________________________________________________
...........................................................................
/home/aquemy/dev/dp_hyperparameters/extension/main.py in <module>()
     27 
     28     serializer.serialize_results(scenario, policy)
     29 
     30 if __name__ == "__main__":
     31     args = cli.parse_args()
---> 32     main(args)

...........................................................................
/home/aquemy/dev/dp_hyperparameters/extension/main.py in main(args=Namespace(customize=[(['control', 'seed'], '42')...io='./scenarios/rf_iris_joint.yaml', verbosity=0))
     21         test_size=0.4, 
     22         random_state=scenario['control']['seed']
     23     )
     24 
     25     policy = policies.initiate(scenario['setup']['policy'], config)
---> 26     policy.run(X,y)
        policy.run = <bound method Joint.run of <experiment.policies.joint.Joint object>>
        X = array([[5.1, 3.5, 1.4, 0.2],
       [4.9, 3. , 1....2, 3.4, 5.4, 2.3],
       [5.9, 3. , 5.1, 1.8]])
        y = array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,... 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2])
     27 
     28     serializer.serialize_results(scenario, policy)
     29 
     30 if __name__ == "__main__":

...........................................................................
/home/aquemy/dev/dp_hyperparameters/extension/experiment/policies/joint.py in run(self=<experiment.policies.joint.Joint object>, X=array([[5.1, 3.5, 1.4, 0.2],
       [4.9, 3. , 1....2, 3.4, 5.4, 2.3],
       [5.9, 3. , 5.1, 1.8]]), y=array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,... 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]))
     32             algo=tpe.suggest, 
     33             max_evals=None,
     34             max_time=self.config['time'],     
     35             trials=trials,
     36             show_progressbar=False,
---> 37             verbose=0
     38         )
     39 
     40         best_config = self.context['best_config']
     41         super(Joint, self).display_step_results(best_config)

...........................................................................
/home/aquemy/dev/dp_hyperparameters/extension/hyperopt/fmin.py in fmin(fn=<functools.partial object>, space={'algorithm': {'bootstrap': <hyperopt.pyll.base.Apply object>, 'criterion': <hyperopt.pyll.base.Apply object>, 'max_depth': <hyperopt.pyll.base.Apply object>, 'max_features': <hyperopt.pyll.base.Apply object>, 'max_leaf_nodes': <hyperopt.pyll.base.Apply object>, 'min_samples_split': <hyperopt.pyll.base.Apply object>, 'n_estimators': <hyperopt.pyll.base.Apply object>}, 'pipeline': {'features': <hyperopt.pyll.base.Apply object>, 'normalizer': <hyperopt.pyll.base.Apply object>, 'rebalance': <hyperopt.pyll.base.Apply object>}}, algo=<function suggest>, max_evals=9223372036854775807, max_time=300, trials=<hyperopt.base.Trials object>, rstate=<mtrand.RandomState object>, allow_trials_fmin=True, pass_expr_memo_ctrl=None, catch_eval_exceptions=False, verbose=0, return_argmin=True, points_to_evaluate=None, max_queue_len=1, show_progressbar=False)
    406             pass_expr_memo_ctrl=pass_expr_memo_ctrl,
    407             verbose=verbose,
    408             catch_eval_exceptions=catch_eval_exceptions,
    409             return_argmin=return_argmin,
    410             show_progressbar=show_progressbar,
--> 411             max_time=max_time
        max_time = 300
    412         )
    413 
    414     if trials is None:
    415         if points_to_evaluate is None:

...........................................................................
/home/aquemy/dev/dp_hyperparameters/extension/hyperopt/base.py in fmin(self=<hyperopt.base.Trials object>, fn=<functools.partial object>, space={'algorithm': {'bootstrap': <hyperopt.pyll.base.Apply object>, 'criterion': <hyperopt.pyll.base.Apply object>, 'max_depth': <hyperopt.pyll.base.Apply object>, 'max_features': <hyperopt.pyll.base.Apply object>, 'max_leaf_nodes': <hyperopt.pyll.base.Apply object>, 'min_samples_split': <hyperopt.pyll.base.Apply object>, 'n_estimators': <hyperopt.pyll.base.Apply object>}, 'pipeline': {'features': <hyperopt.pyll.base.Apply object>, 'normalizer': <hyperopt.pyll.base.Apply object>, 'rebalance': <hyperopt.pyll.base.Apply object>}}, algo=<function suggest>, max_evals=9223372036854775807, max_time=300, rstate=<mtrand.RandomState object>, verbose=0, pass_expr_memo_ctrl=None, catch_eval_exceptions=False, return_argmin=True, show_progressbar=False)
    636             verbose=verbose,
    637             allow_trials_fmin=False,  # -- prevent recursion
    638             pass_expr_memo_ctrl=pass_expr_memo_ctrl,
    639             catch_eval_exceptions=catch_eval_exceptions,
    640             return_argmin=return_argmin,
--> 641             show_progressbar=show_progressbar)
        show_progressbar = False
    642 
    643 
    644 def trials_from_docs(docs, validate=True, **kwargs):
    645     """Construct a Trials base class instance from a list of trials documents

...........................................................................
/home/aquemy/dev/dp_hyperparameters/extension/hyperopt/fmin.py in fmin(fn=<functools.partial object>, space={'algorithm': {'bootstrap': <hyperopt.pyll.base.Apply object>, 'criterion': <hyperopt.pyll.base.Apply object>, 'max_depth': <hyperopt.pyll.base.Apply object>, 'max_features': <hyperopt.pyll.base.Apply object>, 'max_leaf_nodes': <hyperopt.pyll.base.Apply object>, 'min_samples_split': <hyperopt.pyll.base.Apply object>, 'n_estimators': <hyperopt.pyll.base.Apply object>}, 'pipeline': {'features': <hyperopt.pyll.base.Apply object>, 'normalizer': <hyperopt.pyll.base.Apply object>, 'rebalance': <hyperopt.pyll.base.Apply object>}}, algo=<function suggest>, max_evals=9223372036854775807, max_time=300, trials=<hyperopt.base.Trials object>, rstate=<mtrand.RandomState object>, allow_trials_fmin=False, pass_expr_memo_ctrl=None, catch_eval_exceptions=False, verbose=0, return_argmin=True, points_to_evaluate=None, max_queue_len=1, show_progressbar=False)
    426                     verbose=verbose,
    427                     max_queue_len=max_queue_len,
    428                     show_progressbar=show_progressbar,
    429                     max_time=max_time)
    430     rval.catch_eval_exceptions = catch_eval_exceptions
--> 431     rval.exhaust()
        rval.exhaust = <bound method FMinIter.exhaust of <hyperopt.fmin.FMinIter object>>
    432     if return_argmin:
    433         return trials.argmin
    434     elif len(trials) > 0:
    435         # Only if there are some succesfull trail runs, return the best point in the evaluation space

...........................................................................
/home/aquemy/dev/dp_hyperparameters/extension/hyperopt/fmin.py in exhaust(self=<hyperopt.fmin.FMinIter object>)
    273             raise StopIteration()
    274         return self.trials
    275 
    276     def exhaust(self):
    277         n_done = len(self.trials)
--> 278         self.run(self.max_evals - n_done, block_until_done=self.asynchronous)
        self.run = <bound method FMinIter.run of <hyperopt.fmin.FMinIter object>>
        self.max_evals = 9223372036854775807
        n_done = 0
        self.asynchronous = False
    279         self.trials.refresh()
    280         return self
    281 
    282 

...........................................................................
/home/aquemy/dev/dp_hyperparameters/extension/hyperopt/fmin.py in run(self=<hyperopt.fmin.FMinIter object>, N=9223372036854775807, block_until_done=False)
    232                     if self.asynchronous:
    233                         # -- wait for workers to fill in the trials
    234                         time.sleep(self.poll_interval_secs)
    235                     else:
    236                         # -- loop over trials and do the jobs directly
--> 237                         self.serial_evaluate()
        self.serial_evaluate = <bound method FMinIter.serial_evaluate of <hyperopt.fmin.FMinIter object>>
    238                     try:
    239                         res = [d['result']['loss'] for d in
    240                                          self.trials.trials if
    241                                          d['result']['status'] == 'ok']

...........................................................................
/home/aquemy/dev/dp_hyperparameters/extension/hyperopt/fmin.py in serial_evaluate(self=<hyperopt.fmin.FMinIter object>, N=-1)
    138                 trial['book_time'] = now
    139                 trial['refresh_time'] = now
    140                 spec = base.spec_from_misc(trial['misc'])
    141                 ctrl = base.Ctrl(self.trials, current_trial=trial)
    142                 try:
--> 143                     result = self.domain.evaluate(spec, ctrl)
        result = undefined
        self.domain.evaluate = <bound method Domain.evaluate of <hyperopt.base.Domain object>>
        spec = {'bootstrap': 0, 'criterion': 0, 'features': 2, 'features_SelectKBest_features__k': 1, 'max_depth': 1, 'max_features': 2, 'max_leaf_nodes': 1, 'min_samples_split': 2, 'n_estimators': 0, 'normalizer': 1, ...}
        ctrl = <hyperopt.base.Ctrl object>
    144                 except Exception as e:
    145                     logger.info('job exception: %s' % str(e))
    146                     trial['state'] = base.JOB_STATE_ERROR
    147                     trial['misc']['error'] = (str(type(e)), str(e))

...........................................................................
/home/aquemy/dev/dp_hyperparameters/extension/hyperopt/base.py in evaluate(self=<hyperopt.base.Domain object>, config={'bootstrap': 0, 'criterion': 0, 'features': 2, 'features_SelectKBest_features__k': 1, 'max_depth': 1, 'max_features': 2, 'max_leaf_nodes': 1, 'min_samples_split': 2, 'n_estimators': 0, 'normalizer': 1, ...}, ctrl=<hyperopt.base.Ctrl object>, attach_attachments=True)
    841             #    or the normal Python part (self.fn)
    842             pyll_rval = pyll.rec_eval(
    843                 self.expr,
    844                 memo=memo,
    845                 print_node_on_error=self.rec_eval_print_node_on_error)
--> 846             rval = self.fn(pyll_rval)
        rval = undefined
        self.fn = <functools.partial object>
        pyll_rval = {'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': 2, 'max_features': 3, 'max_leaf_nodes': 3, 'min_samples_split': 5, 'n_estimators': 10}, 'pipeline': {'features': ('features_SelectKBest', {'features__k': 2}), 'normalizer': ('normalizer_StandardScaler', {'normalizer__with_mean': False, 'normalizer__with_std': True}), 'rebalance': ('rebalance_NoneType', {})}}
    847 
    848         if isinstance(rval, (float, int, np.number)):
    849             dict_rval = {'loss': float(rval), 'status': STATUS_OK}
    850         else:

...........................................................................
/home/aquemy/dev/dp_hyperparameters/extension/experiment/objective.py in objective_joint(wconfig={'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': 2, 'max_features': 3, 'max_leaf_nodes': 3, 'min_samples_split': 5, 'n_estimators': 10}, 'pipeline': {'features': ('features_SelectKBest', {'features__k': 2}), 'normalizer': ('normalizer_StandardScaler', {'normalizer__with_mean': False, 'normalizer__with_std': True}), 'rebalance': ('rebalance_NoneType', {})}}, algorithm='RandomForest', X=array([[5.1, 3.5, 1.4, 0.2],
       [4.9, 3. , 1....2, 3.4, 5.4, 2.3],
       [5.9, 3. , 5.1, 1.8]]), y=array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,... 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]), context={'baseline_score': 0.9466666666666667, 'baseline_score_std': 0.04988876515698587, 'best_config': {'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': 4, 'max_features': 3, 'max_leaf_nodes': 3, 'min_samples_split': 3, 'n_estimators': 10}, 'config_hash': {'algorithm': 'ffb7ff225ce3d3712c96cf87fe42202988ee2eb0', 'config': 'bae32f426be9cd6243523c023944a8c148fe4aeb', 'pipeline': 'd2a68bfda6fcdec4ae0ffc7d7b6a2122bc1cd673'}, 'duration': 0.7115809917449951, 'iteration': 113, 'loss': 0.033333333333333215, 'max_history_score': 0.9666666666666668, 'max_history_score_std': 0.033333333333333326, 'max_history_step': 'joint', 'pipeline': {'features': ('features_NoneType', {}), 'normalizer': ('normalizer_PowerTransformer', {}), 'rebalance': ('rebalance_CondensedNearestNeighbour', {'rebalance__n_neighbors': 2})}, 'score': 0.9666666666666668, ...}, 'history': [{'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': 2, 'max_features': None, 'max_leaf_nodes': 5, 'min_samples_split': 2, 'n_estimators': 75}, 'config_hash': {'algorithm': '3af5b0cce71c8fe2545246ca24ff5bc3dd516e06', 'config': 'db6ac7e6d348155757e4794bb5f88fe2b4f63d50', 'pipeline': '8d59f4b94cef6be9306ed86a22a9570fa670d567'}, 'duration': 1.149928092956543, 'iteration': 0, 'loss': 0.046666666666666634, 'max_history_score': 0.9533333333333334, 'max_history_score_std': 0.059999999999999984, 'max_history_step': 'joint', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 4, 'features__selectkbest__k': 3}), 'normalizer': ('normalizer_StandardScaler', {'normalizer__with_mean': True, 'normalizer__with_std': True}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 6})}, 'score': 0.9533333333333334, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': 1, 'max_features': 2, 'max_leaf_nodes': 2, 'min_samples_split': 5, 'n_estimators': 100}, 'config_hash': {'algorithm': 'e13eb05fd9a62d2f63bbb1c1deff0cd620d5e6ab', 'config': '4db6fb84d85f52659f780e682ffac5712c3d8a94', 'pipeline': '64c9a1ca9d53ae67244bdd942f4db36a3c05218c'}, 'duration': 1.7678282260894775, 'iteration': 1, 'loss': 0.18000000000000005, 'max_history_score': 0.9533333333333334, 'max_history_score_std': 0.059999999999999984, 'max_history_step': 'joint', 'pipeline': {'features': ('features_NoneType', {}), 'normalizer': ('normalizer_PowerTransformer', {}), 'rebalance': ('rebalance_NearMiss', {'rebalance__n_neighbors': 1})}, 'score': 0.82, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': 1, 'max_features': None, 'max_leaf_nodes': None, 'min_samples_split': 5, 'n_estimators': 75}, 'config_hash': {'algorithm': '94b0d7a654c508cc63643f78fe4f0f07e6f07c1e', 'config': '4403c5a85e951938d3c454e961d3a412780722f6', 'pipeline': '3e47444880d8367fbac2faaba2e52a917274aa58'}, 'duration': 0.8397619724273682, 'iteration': 2, 'loss': 0.03333333333333344, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_PCA', {'features__n_components': 3}), 'normalizer': ('normalizer_MinMaxScaler', {}), 'rebalance': ('rebalance_NoneType', {})}, 'score': 0.9666666666666666, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': None, 'max_features': None, 'max_leaf_nodes': 3, 'min_samples_split': 3, 'n_estimators': 75}, 'config_hash': {'algorithm': 'e8332f0a8902bda03bf70e7978cc5d52affb29d3', 'config': 'a064e2df18ab98d44dabcefbc7bed94913f1d0be', 'pipeline': '7eea819c2a8c103c4b1e9e9c1e224aebba95081f'}, 'duration': 0.8501448631286621, 'iteration': 3, 'loss': 0.053333333333333344, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 2, 'features__selectkbest__k': 4}), 'normalizer': ('normalizer_NoneType', {}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 7})}, 'score': 0.9466666666666667, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'entropy', 'max_depth': 3, 'max_features': 3, 'max_leaf_nodes': None, 'min_samples_split': 5, 'n_estimators': 75}, 'config_hash': {'algorithm': '7a4491035bc6bd737fe9a8cda8a79a02d02d5c74', 'config': '0ddb6f5cab3db4dddd7682966a57205f3e329ad4', 'pipeline': 'a9ae03fe38334f6868cbf84cdd3d629d4bbe3fb0'}, 'duration': 1.1026010513305664, 'iteration': 4, 'loss': 0.05999999999999994, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 2, 'features__selectkbest__k': 1}), 'normalizer': ('normalizer_NoneType', {}), 'rebalance': ('rebalance_NoneType', {})}, 'score': 0.9400000000000001, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'gini', 'max_depth': 3, 'max_features': 1, 'max_leaf_nodes': 5, 'min_samples_split': 2, 'n_estimators': 25}, 'config_hash': {'algorithm': '9826d20b2d6a0f559cf7f16450ce7526f07e8434', 'config': '49f25751bca61cdd461a8cbd2923689b642f98ed', 'pipeline': '19b249664c5bf067de1fed4334a296f947ce774a'}, 'duration': 0.35647010803222656, 'iteration': 5, 'loss': 0.046666666666666634, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_NoneType', {}), 'normalizer': ('normalizer_NoneType', {}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 6})}, 'score': 0.9533333333333334, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'gini', 'max_depth': 2, 'max_features': 1, 'max_leaf_nodes': 2, 'min_samples_split': 2, 'n_estimators': 50}, 'config_hash': {'algorithm': '0a4f6fbb07e0f32c6f675489a0fc82eee05bd8e1', 'config': '5c3a2b6f5e63fb45f10e41e0318b354912ec44f6', 'pipeline': 'dc3b9f176f090005e38b142f11d80e93a7dc5d5e'}, 'duration': 0.7213859558105469, 'iteration': 6, 'loss': 0.31333333333333324, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 1, 'features__selectkbest__k': 4}), 'normalizer': ('normalizer_PowerTransformer', {}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 7})}, 'score': 0.6866666666666668, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'entropy', 'max_depth': 4, 'max_features': 3, 'max_leaf_nodes': 5, 'min_samples_split': 5, 'n_estimators': 10}, 'config_hash': {'algorithm': 'b8112b97ecfc10f00a195af661dcc861cac21289', 'config': 'd3b129b397350f1b6572651c67c01de49b4b174c', 'pipeline': '5b0357ed7072c37b3d6f458bb5d49ff7d825f603'}, 'duration': 0.8299109935760498, 'iteration': 7, 'loss': 1.0, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_PCA', {'features__n_components': 2}), 'normalizer': ('normalizer_StandardScaler', {'normalizer__with_mean': True, 'normalizer__with_std': False}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 6})}, 'score': 0.0, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'gini', 'max_depth': 4, 'max_features': None, 'max_leaf_nodes': 2, 'min_samples_split': 5, 'n_estimators': 100}, 'config_hash': {'algorithm': '40ca24df19b8d164d9d098a6bed1ce056fbbb961', 'config': '813bde1108cc3c4b9bfb3a22cbb421bda7eac671', 'pipeline': '74a7b8705a1c22f7dea5e44e4ebda8f1e48add71'}, 'duration': 2.2111589908599854, 'iteration': 8, 'loss': 0.33333333333333326, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_PCA', {'features__n_components': 2}), 'normalizer': ('normalizer_StandardScaler', {'normalizer__with_mean': False, 'normalizer__with_std': True}), 'rebalance': ('rebalance_NearMiss', {'rebalance__n_neighbors': 2})}, 'score': 0.6666666666666667, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'entropy', 'max_depth': 2, 'max_features': 1, 'max_leaf_nodes': 5, 'min_samples_split': 2, 'n_estimators': 100}, 'config_hash': {'algorithm': '331418a5c12cf1453876eef85e9d98fc8e54fa11', 'config': '31930b6860ed406d59bf7e59ba1925d94704bd3b', 'pipeline': '054bef356f90ec6f644ef3ffc688766744db51c2'}, 'duration': 1.0501940250396729, 'iteration': 9, 'loss': 0.053333333333333344, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_SelectKBest', {'features__k': 1}), 'normalizer': ('normalizer_RobustScaler', {'normalizer__quantile_range': (...), 'normalizer__with_centering': True, 'normalizer__with_scaling': True}), 'rebalance': ('rebalance_NearMiss', {'rebalance__n_neighbors': 2})}, 'score': 0.9466666666666667, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'entropy', 'max_depth': 3, 'max_features': None, 'max_leaf_nodes': 3, 'min_samples_split': 2, 'n_estimators': 100}, 'config_hash': {'algorithm': 'dbc1b8126649fe93dce5fbb37e4015b0acfb179e', 'config': '9913cd550615a9d0946ab4a755a8b9f619e442fd', 'pipeline': 'dd626121cea079ebb32e184ca65483ec7a6d7f59'}, 'duration': 1.120617151260376, 'iteration': 10, 'loss': 0.046666666666666634, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 2, 'features__selectkbest__k': 1}), 'normalizer': ('normalizer_MinMaxScaler', {}), 'rebalance': ('rebalance_NoneType', {})}, 'score': 0.9533333333333334, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'gini', 'max_depth': 3, 'max_features': 3, 'max_leaf_nodes': None, 'min_samples_split': 3, 'n_estimators': 75}, 'config_hash': {'algorithm': '34917a130df5a975f78bd7ec1a0c7b1ffdc787a9', 'config': '95fc8cadc088141290b7de9c388977e4685f0108', 'pipeline': '550d10faf2f08db48516cc3501558816d6a99bc0'}, 'duration': 1.4287099838256836, 'iteration': 11, 'loss': 0.19333333333333313, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 3, 'features__selectkbest__k': 4}), 'normalizer': ('normalizer_StandardScaler', {'normalizer__with_mean': False, 'normalizer__with_std': False}), 'rebalance': ('rebalance_CondensedNearestNeighbour', {'rebalance__n_neighbors': 1})}, 'score': 0.8066666666666669, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'entropy', 'max_depth': 1, 'max_features': 2, 'max_leaf_nodes': 5, 'min_samples_split': 2, 'n_estimators': 75}, 'config_hash': {'algorithm': '33f9abb4aee44a395a9f3b3ffa9ce80a8cdaed7c', 'config': '40fa726f0360cf6af55f9b5902d399d02f61f157', 'pipeline': 'cfd1d20841fe2153da762c95e79f95a3fb1e426a'}, 'duration': 1.2978079319000244, 'iteration': 12, 'loss': 0.053333333333333344, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_PCA', {'features__n_components': 4}), 'normalizer': ('normalizer_MinMaxScaler', {}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 7})}, 'score': 0.9466666666666667, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'entropy', 'max_depth': 4, 'max_features': 2, 'max_leaf_nodes': 5, 'min_samples_split': 3, 'n_estimators': 25}, 'config_hash': {'algorithm': '210111ec6562d09eb093e98ed69ef1c662e11a50', 'config': '0fb8e77c7bd9a58b72f1b33c21a59a09a8c676ba', 'pipeline': '5d269d759e0c7926a685a14b263ace8ae0071e4b'}, 'duration': 0.36649012565612793, 'iteration': 13, 'loss': 0.040000000000000036, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 2, 'features__selectkbest__k': 2}), 'normalizer': ('normalizer_NoneType', {}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 7})}, 'score': 0.96, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'entropy', 'max_depth': 3, 'max_features': 1, 'max_leaf_nodes': 5, 'min_samples_split': 2, 'n_estimators': 25}, 'config_hash': {'algorithm': '0e989a03980101fabf79eda3326ed2870e11d690', 'config': 'f4bffd5d8c67a9c5321a9943c4a99678f59a02b7', 'pipeline': '865ee1e3fe8334c3d5ecb2038d5a5d1b3ba50e75'}, 'duration': 0.35639500617980957, 'iteration': 14, 'loss': 0.046666666666666634, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_NoneType', {}), 'normalizer': ('normalizer_RobustScaler', {'normalizer__quantile_range': (...), 'normalizer__with_centering': True, 'normalizer__with_scaling': False}), 'rebalance': ('rebalance_NoneType', {})}, 'score': 0.9533333333333334, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'entropy', 'max_depth': None, 'max_features': 3, 'max_leaf_nodes': 3, 'min_samples_split': 5, 'n_estimators': 10}, 'config_hash': {'algorithm': '9c592e876c13de5e23e6de5b868e01755d63e72e', 'config': '1e6a68cd1eeac886d90724d78b1cb5fb76a3cde4', 'pipeline': '5a1ca4d82f21b7de0d2c918630a42510673fa36e'}, 'duration': 0.18141412734985352, 'iteration': 15, 'loss': 0.046666666666666634, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_SelectKBest', {'features__k': 3}), 'normalizer': ('normalizer_RobustScaler', {'normalizer__quantile_range': (...), 'normalizer__with_centering': True, 'normalizer__with_scaling': True}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 6})}, 'score': 0.9533333333333334, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': 1, 'max_features': None, 'max_leaf_nodes': None, 'min_samples_split': 5, 'n_estimators': 10}, 'config_hash': {'algorithm': '8bed77aef289bfd453b2858bd288ae5ba7160f2b', 'config': '781185bcb8999045de8d489f253a1a1ba4247932', 'pipeline': '1ece7eabedc2be9e5b0a1be65c570d08ffa3eb54'}, 'duration': 0.1636829376220703, 'iteration': 16, 'loss': 0.053333333333333344, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_NoneType', {}), 'normalizer': ('normalizer_NoneType', {}), 'rebalance': ('rebalance_NearMiss', {'rebalance__n_neighbors': 1})}, 'score': 0.9466666666666667, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'gini', 'max_depth': 3, 'max_features': 2, 'max_leaf_nodes': 2, 'min_samples_split': 5, 'n_estimators': 75}, 'config_hash': {'algorithm': '617b97d9ba21d3373bc51ffa9cccf9c6f91a77b3', 'config': '99fb425b4e8c5d80228cab94202252aa25cdf77c', 'pipeline': 'd6242929c3b515c7719e60423023ac604311afc3'}, 'duration': 0.8468999862670898, 'iteration': 17, 'loss': 0.24, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_PCA', {'features__n_components': 4}), 'normalizer': ('normalizer_PowerTransformer', {}), 'rebalance': ('rebalance_NearMiss', {'rebalance__n_neighbors': 2})}, 'score': 0.76, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': 1, 'max_features': 1, 'max_leaf_nodes': 2, 'min_samples_split': 5, 'n_estimators': 50}, 'config_hash': {'algorithm': 'b92d2697cdd4979da443369d6596229ec091626a', 'config': 'c513a3e13281206ad76187dd817b1fff93d54fe1', 'pipeline': 'c4b4f914a3ca8df967cade997a90366d85a371b9'}, 'duration': 0.6724588871002197, 'iteration': 18, 'loss': 0.23333333333333328, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 1, 'features__selectkbest__k': 3}), 'normalizer': ('normalizer_StandardScaler', {'normalizer__with_mean': True, 'normalizer__with_std': True}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 5})}, 'score': 0.7666666666666667, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'entropy', 'max_depth': None, 'max_features': None, 'max_leaf_nodes': 5, 'min_samples_split': 5, 'n_estimators': 10}, 'config_hash': {'algorithm': 'a0115de695e6cca2e81cbfb54df79bf4b43608b1', 'config': 'ba194015e20b5d67770e8c67342c3d8d0d01dc41', 'pipeline': '8d45fabfeb85ffdcabf7076bd0e65fffe97ce928'}, 'duration': 0.19424200057983398, 'iteration': 19, 'loss': 0.08666666666666667, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_PCA', {'features__n_components': 3}), 'normalizer': ('normalizer_NoneType', {}), 'rebalance': ('rebalance_NoneType', {})}, 'score': 0.9133333333333333, ...}, ...], 'history_hash': ['db6ac7e6d348155757e4794bb5f88fe2b4f63d50', '4db6fb84d85f52659f780e682ffac5712c3d8a94', '4403c5a85e951938d3c454e961d3a412780722f6', 'a064e2df18ab98d44dabcefbc7bed94913f1d0be', '0ddb6f5cab3db4dddd7682966a57205f3e329ad4', '49f25751bca61cdd461a8cbd2923689b642f98ed', '5c3a2b6f5e63fb45f10e41e0318b354912ec44f6', 'd3b129b397350f1b6572651c67c01de49b4b174c', '813bde1108cc3c4b9bfb3a22cbb421bda7eac671', '31930b6860ed406d59bf7e59ba1925d94704bd3b', '9913cd550615a9d0946ab4a755a8b9f619e442fd', '95fc8cadc088141290b7de9c388977e4685f0108', '40fa726f0360cf6af55f9b5902d399d02f61f157', '0fb8e77c7bd9a58b72f1b33c21a59a09a8c676ba', 'f4bffd5d8c67a9c5321a9943c4a99678f59a02b7', '1e6a68cd1eeac886d90724d78b1cb5fb76a3cde4', '781185bcb8999045de8d489f253a1a1ba4247932', '99fb425b4e8c5d80228cab94202252aa25cdf77c', 'c513a3e13281206ad76187dd817b1fff93d54fe1', 'ba194015e20b5d67770e8c67342c3d8d0d01dc41', ...], 'history_index': {'00f0493590a2cb5e98a35b29816f8cd9f87f96ec': 208, '013329309d510b94f19d930320402d65f953a847': 39, '038a0f515e2ec894ee8e34f9caa2889eb3ebd5ce': 66, '052ae4bf232b316187b078abae42c2be19e16a00': 111, '05e9258ebf99dd97202167ef1563fa834b0568f1': 242, '0659afebf316aafeb75612fb07081a04c28545ed': 74, '06e7cde9f3556cd01332ce389ad1d8925cd4b4a4': 120, '07ab8a30d853e39a326b7017026a20e94bc45541': 245, '08606f2a0f0a6c9de204020b4632e09fcee0ae56': 168, '09dbd0948e5b8c1b1f0930778babe65c8a81295e': 243, ...}, 'iteration': 284, 'max_history_score': 0.9666666666666668, 'max_history_score_std': 0.033333333333333326, 'max_history_step': 'joint'}, config={'algorithm': 'RandomForest', 'seed': 42, 'time': 300})
    108 
    109 def objective_algo(algo_config, current_pipeline_config, algorithm, X, y, context, config):
    110     return objective(current_pipeline_config, algo_config, algorithm, X, y, context, config, step='algorithm')
    111 
    112 def objective_joint(wconfig, algorithm, X, y, context, config):
--> 113     return objective(wconfig['pipeline'], wconfig['algorithm'], algorithm, X, y, context, config, step='joint')
        wconfig = {'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': 2, 'max_features': 3, 'max_leaf_nodes': 3, 'min_samples_split': 5, 'n_estimators': 10}, 'pipeline': {'features': ('features_SelectKBest', {'features__k': 2}), 'normalizer': ('normalizer_StandardScaler', {'normalizer__with_mean': False, 'normalizer__with_std': True}), 'rebalance': ('rebalance_NoneType', {})}}
        algorithm = 'RandomForest'
        X = array([[5.1, 3.5, 1.4, 0.2],
       [4.9, 3. , 1....2, 3.4, 5.4, 2.3],
       [5.9, 3. , 5.1, 1.8]])
        y = array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,... 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2])
        context = {'baseline_score': 0.9466666666666667, 'baseline_score_std': 0.04988876515698587, 'best_config': {'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': 4, 'max_features': 3, 'max_leaf_nodes': 3, 'min_samples_split': 3, 'n_estimators': 10}, 'config_hash': {'algorithm': 'ffb7ff225ce3d3712c96cf87fe42202988ee2eb0', 'config': 'bae32f426be9cd6243523c023944a8c148fe4aeb', 'pipeline': 'd2a68bfda6fcdec4ae0ffc7d7b6a2122bc1cd673'}, 'duration': 0.7115809917449951, 'iteration': 113, 'loss': 0.033333333333333215, 'max_history_score': 0.9666666666666668, 'max_history_score_std': 0.033333333333333326, 'max_history_step': 'joint', 'pipeline': {'features': ('features_NoneType', {}), 'normalizer': ('normalizer_PowerTransformer', {}), 'rebalance': ('rebalance_CondensedNearestNeighbour', {'rebalance__n_neighbors': 2})}, 'score': 0.9666666666666668, ...}, 'history': [{'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': 2, 'max_features': None, 'max_leaf_nodes': 5, 'min_samples_split': 2, 'n_estimators': 75}, 'config_hash': {'algorithm': '3af5b0cce71c8fe2545246ca24ff5bc3dd516e06', 'config': 'db6ac7e6d348155757e4794bb5f88fe2b4f63d50', 'pipeline': '8d59f4b94cef6be9306ed86a22a9570fa670d567'}, 'duration': 1.149928092956543, 'iteration': 0, 'loss': 0.046666666666666634, 'max_history_score': 0.9533333333333334, 'max_history_score_std': 0.059999999999999984, 'max_history_step': 'joint', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 4, 'features__selectkbest__k': 3}), 'normalizer': ('normalizer_StandardScaler', {'normalizer__with_mean': True, 'normalizer__with_std': True}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 6})}, 'score': 0.9533333333333334, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': 1, 'max_features': 2, 'max_leaf_nodes': 2, 'min_samples_split': 5, 'n_estimators': 100}, 'config_hash': {'algorithm': 'e13eb05fd9a62d2f63bbb1c1deff0cd620d5e6ab', 'config': '4db6fb84d85f52659f780e682ffac5712c3d8a94', 'pipeline': '64c9a1ca9d53ae67244bdd942f4db36a3c05218c'}, 'duration': 1.7678282260894775, 'iteration': 1, 'loss': 0.18000000000000005, 'max_history_score': 0.9533333333333334, 'max_history_score_std': 0.059999999999999984, 'max_history_step': 'joint', 'pipeline': {'features': ('features_NoneType', {}), 'normalizer': ('normalizer_PowerTransformer', {}), 'rebalance': ('rebalance_NearMiss', {'rebalance__n_neighbors': 1})}, 'score': 0.82, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': 1, 'max_features': None, 'max_leaf_nodes': None, 'min_samples_split': 5, 'n_estimators': 75}, 'config_hash': {'algorithm': '94b0d7a654c508cc63643f78fe4f0f07e6f07c1e', 'config': '4403c5a85e951938d3c454e961d3a412780722f6', 'pipeline': '3e47444880d8367fbac2faaba2e52a917274aa58'}, 'duration': 0.8397619724273682, 'iteration': 2, 'loss': 0.03333333333333344, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_PCA', {'features__n_components': 3}), 'normalizer': ('normalizer_MinMaxScaler', {}), 'rebalance': ('rebalance_NoneType', {})}, 'score': 0.9666666666666666, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': None, 'max_features': None, 'max_leaf_nodes': 3, 'min_samples_split': 3, 'n_estimators': 75}, 'config_hash': {'algorithm': 'e8332f0a8902bda03bf70e7978cc5d52affb29d3', 'config': 'a064e2df18ab98d44dabcefbc7bed94913f1d0be', 'pipeline': '7eea819c2a8c103c4b1e9e9c1e224aebba95081f'}, 'duration': 0.8501448631286621, 'iteration': 3, 'loss': 0.053333333333333344, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 2, 'features__selectkbest__k': 4}), 'normalizer': ('normalizer_NoneType', {}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 7})}, 'score': 0.9466666666666667, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'entropy', 'max_depth': 3, 'max_features': 3, 'max_leaf_nodes': None, 'min_samples_split': 5, 'n_estimators': 75}, 'config_hash': {'algorithm': '7a4491035bc6bd737fe9a8cda8a79a02d02d5c74', 'config': '0ddb6f5cab3db4dddd7682966a57205f3e329ad4', 'pipeline': 'a9ae03fe38334f6868cbf84cdd3d629d4bbe3fb0'}, 'duration': 1.1026010513305664, 'iteration': 4, 'loss': 0.05999999999999994, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 2, 'features__selectkbest__k': 1}), 'normalizer': ('normalizer_NoneType', {}), 'rebalance': ('rebalance_NoneType', {})}, 'score': 0.9400000000000001, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'gini', 'max_depth': 3, 'max_features': 1, 'max_leaf_nodes': 5, 'min_samples_split': 2, 'n_estimators': 25}, 'config_hash': {'algorithm': '9826d20b2d6a0f559cf7f16450ce7526f07e8434', 'config': '49f25751bca61cdd461a8cbd2923689b642f98ed', 'pipeline': '19b249664c5bf067de1fed4334a296f947ce774a'}, 'duration': 0.35647010803222656, 'iteration': 5, 'loss': 0.046666666666666634, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_NoneType', {}), 'normalizer': ('normalizer_NoneType', {}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 6})}, 'score': 0.9533333333333334, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'gini', 'max_depth': 2, 'max_features': 1, 'max_leaf_nodes': 2, 'min_samples_split': 2, 'n_estimators': 50}, 'config_hash': {'algorithm': '0a4f6fbb07e0f32c6f675489a0fc82eee05bd8e1', 'config': '5c3a2b6f5e63fb45f10e41e0318b354912ec44f6', 'pipeline': 'dc3b9f176f090005e38b142f11d80e93a7dc5d5e'}, 'duration': 0.7213859558105469, 'iteration': 6, 'loss': 0.31333333333333324, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 1, 'features__selectkbest__k': 4}), 'normalizer': ('normalizer_PowerTransformer', {}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 7})}, 'score': 0.6866666666666668, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'entropy', 'max_depth': 4, 'max_features': 3, 'max_leaf_nodes': 5, 'min_samples_split': 5, 'n_estimators': 10}, 'config_hash': {'algorithm': 'b8112b97ecfc10f00a195af661dcc861cac21289', 'config': 'd3b129b397350f1b6572651c67c01de49b4b174c', 'pipeline': '5b0357ed7072c37b3d6f458bb5d49ff7d825f603'}, 'duration': 0.8299109935760498, 'iteration': 7, 'loss': 1.0, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_PCA', {'features__n_components': 2}), 'normalizer': ('normalizer_StandardScaler', {'normalizer__with_mean': True, 'normalizer__with_std': False}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 6})}, 'score': 0.0, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'gini', 'max_depth': 4, 'max_features': None, 'max_leaf_nodes': 2, 'min_samples_split': 5, 'n_estimators': 100}, 'config_hash': {'algorithm': '40ca24df19b8d164d9d098a6bed1ce056fbbb961', 'config': '813bde1108cc3c4b9bfb3a22cbb421bda7eac671', 'pipeline': '74a7b8705a1c22f7dea5e44e4ebda8f1e48add71'}, 'duration': 2.2111589908599854, 'iteration': 8, 'loss': 0.33333333333333326, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_PCA', {'features__n_components': 2}), 'normalizer': ('normalizer_StandardScaler', {'normalizer__with_mean': False, 'normalizer__with_std': True}), 'rebalance': ('rebalance_NearMiss', {'rebalance__n_neighbors': 2})}, 'score': 0.6666666666666667, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'entropy', 'max_depth': 2, 'max_features': 1, 'max_leaf_nodes': 5, 'min_samples_split': 2, 'n_estimators': 100}, 'config_hash': {'algorithm': '331418a5c12cf1453876eef85e9d98fc8e54fa11', 'config': '31930b6860ed406d59bf7e59ba1925d94704bd3b', 'pipeline': '054bef356f90ec6f644ef3ffc688766744db51c2'}, 'duration': 1.0501940250396729, 'iteration': 9, 'loss': 0.053333333333333344, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_SelectKBest', {'features__k': 1}), 'normalizer': ('normalizer_RobustScaler', {'normalizer__quantile_range': (...), 'normalizer__with_centering': True, 'normalizer__with_scaling': True}), 'rebalance': ('rebalance_NearMiss', {'rebalance__n_neighbors': 2})}, 'score': 0.9466666666666667, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'entropy', 'max_depth': 3, 'max_features': None, 'max_leaf_nodes': 3, 'min_samples_split': 2, 'n_estimators': 100}, 'config_hash': {'algorithm': 'dbc1b8126649fe93dce5fbb37e4015b0acfb179e', 'config': '9913cd550615a9d0946ab4a755a8b9f619e442fd', 'pipeline': 'dd626121cea079ebb32e184ca65483ec7a6d7f59'}, 'duration': 1.120617151260376, 'iteration': 10, 'loss': 0.046666666666666634, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 2, 'features__selectkbest__k': 1}), 'normalizer': ('normalizer_MinMaxScaler', {}), 'rebalance': ('rebalance_NoneType', {})}, 'score': 0.9533333333333334, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'gini', 'max_depth': 3, 'max_features': 3, 'max_leaf_nodes': None, 'min_samples_split': 3, 'n_estimators': 75}, 'config_hash': {'algorithm': '34917a130df5a975f78bd7ec1a0c7b1ffdc787a9', 'config': '95fc8cadc088141290b7de9c388977e4685f0108', 'pipeline': '550d10faf2f08db48516cc3501558816d6a99bc0'}, 'duration': 1.4287099838256836, 'iteration': 11, 'loss': 0.19333333333333313, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 3, 'features__selectkbest__k': 4}), 'normalizer': ('normalizer_StandardScaler', {'normalizer__with_mean': False, 'normalizer__with_std': False}), 'rebalance': ('rebalance_CondensedNearestNeighbour', {'rebalance__n_neighbors': 1})}, 'score': 0.8066666666666669, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'entropy', 'max_depth': 1, 'max_features': 2, 'max_leaf_nodes': 5, 'min_samples_split': 2, 'n_estimators': 75}, 'config_hash': {'algorithm': '33f9abb4aee44a395a9f3b3ffa9ce80a8cdaed7c', 'config': '40fa726f0360cf6af55f9b5902d399d02f61f157', 'pipeline': 'cfd1d20841fe2153da762c95e79f95a3fb1e426a'}, 'duration': 1.2978079319000244, 'iteration': 12, 'loss': 0.053333333333333344, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_PCA', {'features__n_components': 4}), 'normalizer': ('normalizer_MinMaxScaler', {}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 7})}, 'score': 0.9466666666666667, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'entropy', 'max_depth': 4, 'max_features': 2, 'max_leaf_nodes': 5, 'min_samples_split': 3, 'n_estimators': 25}, 'config_hash': {'algorithm': '210111ec6562d09eb093e98ed69ef1c662e11a50', 'config': '0fb8e77c7bd9a58b72f1b33c21a59a09a8c676ba', 'pipeline': '5d269d759e0c7926a685a14b263ace8ae0071e4b'}, 'duration': 0.36649012565612793, 'iteration': 13, 'loss': 0.040000000000000036, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 2, 'features__selectkbest__k': 2}), 'normalizer': ('normalizer_NoneType', {}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 7})}, 'score': 0.96, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'entropy', 'max_depth': 3, 'max_features': 1, 'max_leaf_nodes': 5, 'min_samples_split': 2, 'n_estimators': 25}, 'config_hash': {'algorithm': '0e989a03980101fabf79eda3326ed2870e11d690', 'config': 'f4bffd5d8c67a9c5321a9943c4a99678f59a02b7', 'pipeline': '865ee1e3fe8334c3d5ecb2038d5a5d1b3ba50e75'}, 'duration': 0.35639500617980957, 'iteration': 14, 'loss': 0.046666666666666634, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_NoneType', {}), 'normalizer': ('normalizer_RobustScaler', {'normalizer__quantile_range': (...), 'normalizer__with_centering': True, 'normalizer__with_scaling': False}), 'rebalance': ('rebalance_NoneType', {})}, 'score': 0.9533333333333334, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'entropy', 'max_depth': None, 'max_features': 3, 'max_leaf_nodes': 3, 'min_samples_split': 5, 'n_estimators': 10}, 'config_hash': {'algorithm': '9c592e876c13de5e23e6de5b868e01755d63e72e', 'config': '1e6a68cd1eeac886d90724d78b1cb5fb76a3cde4', 'pipeline': '5a1ca4d82f21b7de0d2c918630a42510673fa36e'}, 'duration': 0.18141412734985352, 'iteration': 15, 'loss': 0.046666666666666634, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_SelectKBest', {'features__k': 3}), 'normalizer': ('normalizer_RobustScaler', {'normalizer__quantile_range': (...), 'normalizer__with_centering': True, 'normalizer__with_scaling': True}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 6})}, 'score': 0.9533333333333334, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': 1, 'max_features': None, 'max_leaf_nodes': None, 'min_samples_split': 5, 'n_estimators': 10}, 'config_hash': {'algorithm': '8bed77aef289bfd453b2858bd288ae5ba7160f2b', 'config': '781185bcb8999045de8d489f253a1a1ba4247932', 'pipeline': '1ece7eabedc2be9e5b0a1be65c570d08ffa3eb54'}, 'duration': 0.1636829376220703, 'iteration': 16, 'loss': 0.053333333333333344, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_NoneType', {}), 'normalizer': ('normalizer_NoneType', {}), 'rebalance': ('rebalance_NearMiss', {'rebalance__n_neighbors': 1})}, 'score': 0.9466666666666667, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'gini', 'max_depth': 3, 'max_features': 2, 'max_leaf_nodes': 2, 'min_samples_split': 5, 'n_estimators': 75}, 'config_hash': {'algorithm': '617b97d9ba21d3373bc51ffa9cccf9c6f91a77b3', 'config': '99fb425b4e8c5d80228cab94202252aa25cdf77c', 'pipeline': 'd6242929c3b515c7719e60423023ac604311afc3'}, 'duration': 0.8468999862670898, 'iteration': 17, 'loss': 0.24, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_PCA', {'features__n_components': 4}), 'normalizer': ('normalizer_PowerTransformer', {}), 'rebalance': ('rebalance_NearMiss', {'rebalance__n_neighbors': 2})}, 'score': 0.76, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': 1, 'max_features': 1, 'max_leaf_nodes': 2, 'min_samples_split': 5, 'n_estimators': 50}, 'config_hash': {'algorithm': 'b92d2697cdd4979da443369d6596229ec091626a', 'config': 'c513a3e13281206ad76187dd817b1fff93d54fe1', 'pipeline': 'c4b4f914a3ca8df967cade997a90366d85a371b9'}, 'duration': 0.6724588871002197, 'iteration': 18, 'loss': 0.23333333333333328, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 1, 'features__selectkbest__k': 3}), 'normalizer': ('normalizer_StandardScaler', {'normalizer__with_mean': True, 'normalizer__with_std': True}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 5})}, 'score': 0.7666666666666667, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'entropy', 'max_depth': None, 'max_features': None, 'max_leaf_nodes': 5, 'min_samples_split': 5, 'n_estimators': 10}, 'config_hash': {'algorithm': 'a0115de695e6cca2e81cbfb54df79bf4b43608b1', 'config': 'ba194015e20b5d67770e8c67342c3d8d0d01dc41', 'pipeline': '8d45fabfeb85ffdcabf7076bd0e65fffe97ce928'}, 'duration': 0.19424200057983398, 'iteration': 19, 'loss': 0.08666666666666667, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_PCA', {'features__n_components': 3}), 'normalizer': ('normalizer_NoneType', {}), 'rebalance': ('rebalance_NoneType', {})}, 'score': 0.9133333333333333, ...}, ...], 'history_hash': ['db6ac7e6d348155757e4794bb5f88fe2b4f63d50', '4db6fb84d85f52659f780e682ffac5712c3d8a94', '4403c5a85e951938d3c454e961d3a412780722f6', 'a064e2df18ab98d44dabcefbc7bed94913f1d0be', '0ddb6f5cab3db4dddd7682966a57205f3e329ad4', '49f25751bca61cdd461a8cbd2923689b642f98ed', '5c3a2b6f5e63fb45f10e41e0318b354912ec44f6', 'd3b129b397350f1b6572651c67c01de49b4b174c', '813bde1108cc3c4b9bfb3a22cbb421bda7eac671', '31930b6860ed406d59bf7e59ba1925d94704bd3b', '9913cd550615a9d0946ab4a755a8b9f619e442fd', '95fc8cadc088141290b7de9c388977e4685f0108', '40fa726f0360cf6af55f9b5902d399d02f61f157', '0fb8e77c7bd9a58b72f1b33c21a59a09a8c676ba', 'f4bffd5d8c67a9c5321a9943c4a99678f59a02b7', '1e6a68cd1eeac886d90724d78b1cb5fb76a3cde4', '781185bcb8999045de8d489f253a1a1ba4247932', '99fb425b4e8c5d80228cab94202252aa25cdf77c', 'c513a3e13281206ad76187dd817b1fff93d54fe1', 'ba194015e20b5d67770e8c67342c3d8d0d01dc41', ...], 'history_index': {'00f0493590a2cb5e98a35b29816f8cd9f87f96ec': 208, '013329309d510b94f19d930320402d65f953a847': 39, '038a0f515e2ec894ee8e34f9caa2889eb3ebd5ce': 66, '052ae4bf232b316187b078abae42c2be19e16a00': 111, '05e9258ebf99dd97202167ef1563fa834b0568f1': 242, '0659afebf316aafeb75612fb07081a04c28545ed': 74, '06e7cde9f3556cd01332ce389ad1d8925cd4b4a4': 120, '07ab8a30d853e39a326b7017026a20e94bc45541': 245, '08606f2a0f0a6c9de204020b4632e09fcee0ae56': 168, '09dbd0948e5b8c1b1f0930778babe65c8a81295e': 243, ...}, 'iteration': 284, 'max_history_score': 0.9666666666666668, 'max_history_score_std': 0.033333333333333326, 'max_history_step': 'joint'}
        config = {'algorithm': 'RandomForest', 'seed': 42, 'time': 300}
    114 
    115 
    116 def get_baseline_score(algorithm, X, y, seed):
    117     pipeline, _ = pipeline_conf_to_full_pipeline(

...........................................................................
/home/aquemy/dev/dp_hyperparameters/extension/experiment/objective.py in objective(pipeline_config={'features': ('features_SelectKBest', {'features__k': 2}), 'normalizer': ('normalizer_StandardScaler', {'normalizer__with_mean': False, 'normalizer__with_std': True}), 'rebalance': ('rebalance_NoneType', {})}, algo_config={'bootstrap': True, 'criterion': 'gini', 'max_depth': 2, 'max_features': 3, 'max_leaf_nodes': 3, 'min_samples_split': 5, 'n_estimators': 10}, algorithm='RandomForest', X=array([[5.1, 3.5, 1.4, 0.2],
       [4.9, 3. , 1....2, 3.4, 5.4, 2.3],
       [5.9, 3. , 5.1, 1.8]]), y=array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,... 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]), context={'baseline_score': 0.9466666666666667, 'baseline_score_std': 0.04988876515698587, 'best_config': {'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': 4, 'max_features': 3, 'max_leaf_nodes': 3, 'min_samples_split': 3, 'n_estimators': 10}, 'config_hash': {'algorithm': 'ffb7ff225ce3d3712c96cf87fe42202988ee2eb0', 'config': 'bae32f426be9cd6243523c023944a8c148fe4aeb', 'pipeline': 'd2a68bfda6fcdec4ae0ffc7d7b6a2122bc1cd673'}, 'duration': 0.7115809917449951, 'iteration': 113, 'loss': 0.033333333333333215, 'max_history_score': 0.9666666666666668, 'max_history_score_std': 0.033333333333333326, 'max_history_step': 'joint', 'pipeline': {'features': ('features_NoneType', {}), 'normalizer': ('normalizer_PowerTransformer', {}), 'rebalance': ('rebalance_CondensedNearestNeighbour', {'rebalance__n_neighbors': 2})}, 'score': 0.9666666666666668, ...}, 'history': [{'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': 2, 'max_features': None, 'max_leaf_nodes': 5, 'min_samples_split': 2, 'n_estimators': 75}, 'config_hash': {'algorithm': '3af5b0cce71c8fe2545246ca24ff5bc3dd516e06', 'config': 'db6ac7e6d348155757e4794bb5f88fe2b4f63d50', 'pipeline': '8d59f4b94cef6be9306ed86a22a9570fa670d567'}, 'duration': 1.149928092956543, 'iteration': 0, 'loss': 0.046666666666666634, 'max_history_score': 0.9533333333333334, 'max_history_score_std': 0.059999999999999984, 'max_history_step': 'joint', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 4, 'features__selectkbest__k': 3}), 'normalizer': ('normalizer_StandardScaler', {'normalizer__with_mean': True, 'normalizer__with_std': True}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 6})}, 'score': 0.9533333333333334, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': 1, 'max_features': 2, 'max_leaf_nodes': 2, 'min_samples_split': 5, 'n_estimators': 100}, 'config_hash': {'algorithm': 'e13eb05fd9a62d2f63bbb1c1deff0cd620d5e6ab', 'config': '4db6fb84d85f52659f780e682ffac5712c3d8a94', 'pipeline': '64c9a1ca9d53ae67244bdd942f4db36a3c05218c'}, 'duration': 1.7678282260894775, 'iteration': 1, 'loss': 0.18000000000000005, 'max_history_score': 0.9533333333333334, 'max_history_score_std': 0.059999999999999984, 'max_history_step': 'joint', 'pipeline': {'features': ('features_NoneType', {}), 'normalizer': ('normalizer_PowerTransformer', {}), 'rebalance': ('rebalance_NearMiss', {'rebalance__n_neighbors': 1})}, 'score': 0.82, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': 1, 'max_features': None, 'max_leaf_nodes': None, 'min_samples_split': 5, 'n_estimators': 75}, 'config_hash': {'algorithm': '94b0d7a654c508cc63643f78fe4f0f07e6f07c1e', 'config': '4403c5a85e951938d3c454e961d3a412780722f6', 'pipeline': '3e47444880d8367fbac2faaba2e52a917274aa58'}, 'duration': 0.8397619724273682, 'iteration': 2, 'loss': 0.03333333333333344, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_PCA', {'features__n_components': 3}), 'normalizer': ('normalizer_MinMaxScaler', {}), 'rebalance': ('rebalance_NoneType', {})}, 'score': 0.9666666666666666, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': None, 'max_features': None, 'max_leaf_nodes': 3, 'min_samples_split': 3, 'n_estimators': 75}, 'config_hash': {'algorithm': 'e8332f0a8902bda03bf70e7978cc5d52affb29d3', 'config': 'a064e2df18ab98d44dabcefbc7bed94913f1d0be', 'pipeline': '7eea819c2a8c103c4b1e9e9c1e224aebba95081f'}, 'duration': 0.8501448631286621, 'iteration': 3, 'loss': 0.053333333333333344, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 2, 'features__selectkbest__k': 4}), 'normalizer': ('normalizer_NoneType', {}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 7})}, 'score': 0.9466666666666667, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'entropy', 'max_depth': 3, 'max_features': 3, 'max_leaf_nodes': None, 'min_samples_split': 5, 'n_estimators': 75}, 'config_hash': {'algorithm': '7a4491035bc6bd737fe9a8cda8a79a02d02d5c74', 'config': '0ddb6f5cab3db4dddd7682966a57205f3e329ad4', 'pipeline': 'a9ae03fe38334f6868cbf84cdd3d629d4bbe3fb0'}, 'duration': 1.1026010513305664, 'iteration': 4, 'loss': 0.05999999999999994, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 2, 'features__selectkbest__k': 1}), 'normalizer': ('normalizer_NoneType', {}), 'rebalance': ('rebalance_NoneType', {})}, 'score': 0.9400000000000001, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'gini', 'max_depth': 3, 'max_features': 1, 'max_leaf_nodes': 5, 'min_samples_split': 2, 'n_estimators': 25}, 'config_hash': {'algorithm': '9826d20b2d6a0f559cf7f16450ce7526f07e8434', 'config': '49f25751bca61cdd461a8cbd2923689b642f98ed', 'pipeline': '19b249664c5bf067de1fed4334a296f947ce774a'}, 'duration': 0.35647010803222656, 'iteration': 5, 'loss': 0.046666666666666634, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_NoneType', {}), 'normalizer': ('normalizer_NoneType', {}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 6})}, 'score': 0.9533333333333334, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'gini', 'max_depth': 2, 'max_features': 1, 'max_leaf_nodes': 2, 'min_samples_split': 2, 'n_estimators': 50}, 'config_hash': {'algorithm': '0a4f6fbb07e0f32c6f675489a0fc82eee05bd8e1', 'config': '5c3a2b6f5e63fb45f10e41e0318b354912ec44f6', 'pipeline': 'dc3b9f176f090005e38b142f11d80e93a7dc5d5e'}, 'duration': 0.7213859558105469, 'iteration': 6, 'loss': 0.31333333333333324, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 1, 'features__selectkbest__k': 4}), 'normalizer': ('normalizer_PowerTransformer', {}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 7})}, 'score': 0.6866666666666668, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'entropy', 'max_depth': 4, 'max_features': 3, 'max_leaf_nodes': 5, 'min_samples_split': 5, 'n_estimators': 10}, 'config_hash': {'algorithm': 'b8112b97ecfc10f00a195af661dcc861cac21289', 'config': 'd3b129b397350f1b6572651c67c01de49b4b174c', 'pipeline': '5b0357ed7072c37b3d6f458bb5d49ff7d825f603'}, 'duration': 0.8299109935760498, 'iteration': 7, 'loss': 1.0, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_PCA', {'features__n_components': 2}), 'normalizer': ('normalizer_StandardScaler', {'normalizer__with_mean': True, 'normalizer__with_std': False}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 6})}, 'score': 0.0, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'gini', 'max_depth': 4, 'max_features': None, 'max_leaf_nodes': 2, 'min_samples_split': 5, 'n_estimators': 100}, 'config_hash': {'algorithm': '40ca24df19b8d164d9d098a6bed1ce056fbbb961', 'config': '813bde1108cc3c4b9bfb3a22cbb421bda7eac671', 'pipeline': '74a7b8705a1c22f7dea5e44e4ebda8f1e48add71'}, 'duration': 2.2111589908599854, 'iteration': 8, 'loss': 0.33333333333333326, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_PCA', {'features__n_components': 2}), 'normalizer': ('normalizer_StandardScaler', {'normalizer__with_mean': False, 'normalizer__with_std': True}), 'rebalance': ('rebalance_NearMiss', {'rebalance__n_neighbors': 2})}, 'score': 0.6666666666666667, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'entropy', 'max_depth': 2, 'max_features': 1, 'max_leaf_nodes': 5, 'min_samples_split': 2, 'n_estimators': 100}, 'config_hash': {'algorithm': '331418a5c12cf1453876eef85e9d98fc8e54fa11', 'config': '31930b6860ed406d59bf7e59ba1925d94704bd3b', 'pipeline': '054bef356f90ec6f644ef3ffc688766744db51c2'}, 'duration': 1.0501940250396729, 'iteration': 9, 'loss': 0.053333333333333344, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_SelectKBest', {'features__k': 1}), 'normalizer': ('normalizer_RobustScaler', {'normalizer__quantile_range': (...), 'normalizer__with_centering': True, 'normalizer__with_scaling': True}), 'rebalance': ('rebalance_NearMiss', {'rebalance__n_neighbors': 2})}, 'score': 0.9466666666666667, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'entropy', 'max_depth': 3, 'max_features': None, 'max_leaf_nodes': 3, 'min_samples_split': 2, 'n_estimators': 100}, 'config_hash': {'algorithm': 'dbc1b8126649fe93dce5fbb37e4015b0acfb179e', 'config': '9913cd550615a9d0946ab4a755a8b9f619e442fd', 'pipeline': 'dd626121cea079ebb32e184ca65483ec7a6d7f59'}, 'duration': 1.120617151260376, 'iteration': 10, 'loss': 0.046666666666666634, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 2, 'features__selectkbest__k': 1}), 'normalizer': ('normalizer_MinMaxScaler', {}), 'rebalance': ('rebalance_NoneType', {})}, 'score': 0.9533333333333334, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'gini', 'max_depth': 3, 'max_features': 3, 'max_leaf_nodes': None, 'min_samples_split': 3, 'n_estimators': 75}, 'config_hash': {'algorithm': '34917a130df5a975f78bd7ec1a0c7b1ffdc787a9', 'config': '95fc8cadc088141290b7de9c388977e4685f0108', 'pipeline': '550d10faf2f08db48516cc3501558816d6a99bc0'}, 'duration': 1.4287099838256836, 'iteration': 11, 'loss': 0.19333333333333313, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 3, 'features__selectkbest__k': 4}), 'normalizer': ('normalizer_StandardScaler', {'normalizer__with_mean': False, 'normalizer__with_std': False}), 'rebalance': ('rebalance_CondensedNearestNeighbour', {'rebalance__n_neighbors': 1})}, 'score': 0.8066666666666669, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'entropy', 'max_depth': 1, 'max_features': 2, 'max_leaf_nodes': 5, 'min_samples_split': 2, 'n_estimators': 75}, 'config_hash': {'algorithm': '33f9abb4aee44a395a9f3b3ffa9ce80a8cdaed7c', 'config': '40fa726f0360cf6af55f9b5902d399d02f61f157', 'pipeline': 'cfd1d20841fe2153da762c95e79f95a3fb1e426a'}, 'duration': 1.2978079319000244, 'iteration': 12, 'loss': 0.053333333333333344, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_PCA', {'features__n_components': 4}), 'normalizer': ('normalizer_MinMaxScaler', {}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 7})}, 'score': 0.9466666666666667, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'entropy', 'max_depth': 4, 'max_features': 2, 'max_leaf_nodes': 5, 'min_samples_split': 3, 'n_estimators': 25}, 'config_hash': {'algorithm': '210111ec6562d09eb093e98ed69ef1c662e11a50', 'config': '0fb8e77c7bd9a58b72f1b33c21a59a09a8c676ba', 'pipeline': '5d269d759e0c7926a685a14b263ace8ae0071e4b'}, 'duration': 0.36649012565612793, 'iteration': 13, 'loss': 0.040000000000000036, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 2, 'features__selectkbest__k': 2}), 'normalizer': ('normalizer_NoneType', {}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 7})}, 'score': 0.96, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'entropy', 'max_depth': 3, 'max_features': 1, 'max_leaf_nodes': 5, 'min_samples_split': 2, 'n_estimators': 25}, 'config_hash': {'algorithm': '0e989a03980101fabf79eda3326ed2870e11d690', 'config': 'f4bffd5d8c67a9c5321a9943c4a99678f59a02b7', 'pipeline': '865ee1e3fe8334c3d5ecb2038d5a5d1b3ba50e75'}, 'duration': 0.35639500617980957, 'iteration': 14, 'loss': 0.046666666666666634, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_NoneType', {}), 'normalizer': ('normalizer_RobustScaler', {'normalizer__quantile_range': (...), 'normalizer__with_centering': True, 'normalizer__with_scaling': False}), 'rebalance': ('rebalance_NoneType', {})}, 'score': 0.9533333333333334, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'entropy', 'max_depth': None, 'max_features': 3, 'max_leaf_nodes': 3, 'min_samples_split': 5, 'n_estimators': 10}, 'config_hash': {'algorithm': '9c592e876c13de5e23e6de5b868e01755d63e72e', 'config': '1e6a68cd1eeac886d90724d78b1cb5fb76a3cde4', 'pipeline': '5a1ca4d82f21b7de0d2c918630a42510673fa36e'}, 'duration': 0.18141412734985352, 'iteration': 15, 'loss': 0.046666666666666634, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_SelectKBest', {'features__k': 3}), 'normalizer': ('normalizer_RobustScaler', {'normalizer__quantile_range': (...), 'normalizer__with_centering': True, 'normalizer__with_scaling': True}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 6})}, 'score': 0.9533333333333334, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': 1, 'max_features': None, 'max_leaf_nodes': None, 'min_samples_split': 5, 'n_estimators': 10}, 'config_hash': {'algorithm': '8bed77aef289bfd453b2858bd288ae5ba7160f2b', 'config': '781185bcb8999045de8d489f253a1a1ba4247932', 'pipeline': '1ece7eabedc2be9e5b0a1be65c570d08ffa3eb54'}, 'duration': 0.1636829376220703, 'iteration': 16, 'loss': 0.053333333333333344, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_NoneType', {}), 'normalizer': ('normalizer_NoneType', {}), 'rebalance': ('rebalance_NearMiss', {'rebalance__n_neighbors': 1})}, 'score': 0.9466666666666667, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'gini', 'max_depth': 3, 'max_features': 2, 'max_leaf_nodes': 2, 'min_samples_split': 5, 'n_estimators': 75}, 'config_hash': {'algorithm': '617b97d9ba21d3373bc51ffa9cccf9c6f91a77b3', 'config': '99fb425b4e8c5d80228cab94202252aa25cdf77c', 'pipeline': 'd6242929c3b515c7719e60423023ac604311afc3'}, 'duration': 0.8468999862670898, 'iteration': 17, 'loss': 0.24, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_PCA', {'features__n_components': 4}), 'normalizer': ('normalizer_PowerTransformer', {}), 'rebalance': ('rebalance_NearMiss', {'rebalance__n_neighbors': 2})}, 'score': 0.76, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': 1, 'max_features': 1, 'max_leaf_nodes': 2, 'min_samples_split': 5, 'n_estimators': 50}, 'config_hash': {'algorithm': 'b92d2697cdd4979da443369d6596229ec091626a', 'config': 'c513a3e13281206ad76187dd817b1fff93d54fe1', 'pipeline': 'c4b4f914a3ca8df967cade997a90366d85a371b9'}, 'duration': 0.6724588871002197, 'iteration': 18, 'loss': 0.23333333333333328, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 1, 'features__selectkbest__k': 3}), 'normalizer': ('normalizer_StandardScaler', {'normalizer__with_mean': True, 'normalizer__with_std': True}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 5})}, 'score': 0.7666666666666667, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'entropy', 'max_depth': None, 'max_features': None, 'max_leaf_nodes': 5, 'min_samples_split': 5, 'n_estimators': 10}, 'config_hash': {'algorithm': 'a0115de695e6cca2e81cbfb54df79bf4b43608b1', 'config': 'ba194015e20b5d67770e8c67342c3d8d0d01dc41', 'pipeline': '8d45fabfeb85ffdcabf7076bd0e65fffe97ce928'}, 'duration': 0.19424200057983398, 'iteration': 19, 'loss': 0.08666666666666667, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_PCA', {'features__n_components': 3}), 'normalizer': ('normalizer_NoneType', {}), 'rebalance': ('rebalance_NoneType', {})}, 'score': 0.9133333333333333, ...}, ...], 'history_hash': ['db6ac7e6d348155757e4794bb5f88fe2b4f63d50', '4db6fb84d85f52659f780e682ffac5712c3d8a94', '4403c5a85e951938d3c454e961d3a412780722f6', 'a064e2df18ab98d44dabcefbc7bed94913f1d0be', '0ddb6f5cab3db4dddd7682966a57205f3e329ad4', '49f25751bca61cdd461a8cbd2923689b642f98ed', '5c3a2b6f5e63fb45f10e41e0318b354912ec44f6', 'd3b129b397350f1b6572651c67c01de49b4b174c', '813bde1108cc3c4b9bfb3a22cbb421bda7eac671', '31930b6860ed406d59bf7e59ba1925d94704bd3b', '9913cd550615a9d0946ab4a755a8b9f619e442fd', '95fc8cadc088141290b7de9c388977e4685f0108', '40fa726f0360cf6af55f9b5902d399d02f61f157', '0fb8e77c7bd9a58b72f1b33c21a59a09a8c676ba', 'f4bffd5d8c67a9c5321a9943c4a99678f59a02b7', '1e6a68cd1eeac886d90724d78b1cb5fb76a3cde4', '781185bcb8999045de8d489f253a1a1ba4247932', '99fb425b4e8c5d80228cab94202252aa25cdf77c', 'c513a3e13281206ad76187dd817b1fff93d54fe1', 'ba194015e20b5d67770e8c67342c3d8d0d01dc41', ...], 'history_index': {'00f0493590a2cb5e98a35b29816f8cd9f87f96ec': 208, '013329309d510b94f19d930320402d65f953a847': 39, '038a0f515e2ec894ee8e34f9caa2889eb3ebd5ce': 66, '052ae4bf232b316187b078abae42c2be19e16a00': 111, '05e9258ebf99dd97202167ef1563fa834b0568f1': 242, '0659afebf316aafeb75612fb07081a04c28545ed': 74, '06e7cde9f3556cd01332ce389ad1d8925cd4b4a4': 120, '07ab8a30d853e39a326b7017026a20e94bc45541': 245, '08606f2a0f0a6c9de204020b4632e09fcee0ae56': 168, '09dbd0948e5b8c1b1f0930778babe65c8a81295e': 243, ...}, 'iteration': 284, 'max_history_score': 0.9666666666666668, 'max_history_score_std': 0.033333333333333326, 'max_history_step': 'joint'}, config={'algorithm': 'RandomForest', 'seed': 42, 'time': 300}, step='joint')
     45                 y,
     46                 cv=10,
     47                 n_jobs=-1,
     48                 return_estimator=False,
     49                 return_train_score=False,
---> 50                 verbose=0)
     51         score = np.mean(scores['test_score'])
     52         std = np.std(scores['test_score'])
     53         status = STATUS_OK
     54     except Exception as e:

...........................................................................
/home/aquemy/.local/lib/python2.7/site-packages/sklearn/model_selection/_validation.py in cross_validate(estimator=Pipeline(memory=None,
     steps=[('normalizer',... random_state=42, verbose=0, warm_start=False))]), X=array([[5.1, 3.5, 1.4, 0.2],
       [4.9, 3. , 1....2, 3.4, 5.4, 2.3],
       [5.9, 3. , 5.1, 1.8]]), y=array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,... 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]), groups=None, scoring=None, cv=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1, verbose=0, fit_params=None, pre_dispatch='2*n_jobs', return_train_score=False, return_estimator=False, error_score='raise-deprecating')
    235         delayed(_fit_and_score)(
    236             clone(estimator), X, y, scorers, train, test, verbose, None,
    237             fit_params, return_train_score=return_train_score,
    238             return_times=True, return_estimator=return_estimator,
    239             error_score=error_score)
--> 240         for train, test in cv.split(X, y, groups))
        cv.split = <bound method StratifiedKFold.split of Stratifie...d(n_splits=10, random_state=None, shuffle=False)>
        X = array([[5.1, 3.5, 1.4, 0.2],
       [4.9, 3. , 1....2, 3.4, 5.4, 2.3],
       [5.9, 3. , 5.1, 1.8]])
        y = array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,... 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2])
        groups = None
    241 
    242     zipped_scores = list(zip(*scores))
    243     if return_train_score:
    244         train_scores = zipped_scores.pop(0)

...........................................................................
/home/aquemy/.local/lib/python2.7/site-packages/sklearn/externals/joblib/parallel.py in __call__(self=Parallel(n_jobs=-1), iterable=<generator object <genexpr>>)
    925                 # No need to wait for async callbacks to trigger to
    926                 # consumption.
    927                 self._iterating = False
    928 
    929             with self._backend.retrieval_context():
--> 930                 self.retrieve()
        self.retrieve = <bound method Parallel.retrieve of Parallel(n_jobs=-1)>
    931             # Make sure that we get a last message telling us we are done
    932             elapsed_time = time.time() - self._start_time
    933             self._print('Done %3i out of %3i | elapsed: %s finished',
    934                         (len(self._output), len(self._output),

---------------------------------------------------------------------------
Joblib worker traceback:
---------------------------------------------------------------------------
ValueError                                         Mon Jun 17 13:14:23 2019
PID: 21713                                  Python 2.7.15+: /usr/bin/python
...........................................................................
/home/aquemy/.local/lib/python2.7/site-packages/sklearn/externals/joblib/parallel.py in __call__(self=<sklearn.externals.joblib.parallel.BatchedCalls object>)
    220     def __call__(self):
    221         # Set the default nested backend to self._backend but do not set the
    222         # change the default number of processes to -1
    223         with parallel_backend(self._backend, n_jobs=self._n_jobs):
    224             return [func(*args, **kwargs)
--> 225                     for func, args, kwargs in self.items]
        func = <function _fit_and_score>
        args = (Pipeline(memory=None,
     steps=[('normalizer',... random_state=42, verbose=0, warm_start=False))]), array([[5.1, 3.5, 1.4, 0.2],
       [4.9, 3. , 1....2, 3.4, 5.4, 2.3],
       [5.9, 3. , 5.1, 1.8]]), array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,... 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]), {'score': <function _passthrough_scorer>}, array([  5,   6,   7,   8,   9,  10,  11,  12,  ..., 142, 143, 144,
       145, 146, 147, 148, 149]), array([  0,   1,   2,   3,   4,  50,  51,  52,  53,  54, 100, 101, 102,
       103, 104]), 0, None, None)
        kwargs = {'error_score': 'raise-deprecating', 'return_estimator': False, 'return_times': True, 'return_train_score': False}
        self.items = [(<function _fit_and_score>, (Pipeline(memory=None,
     steps=[('normalizer',... random_state=42, verbose=0, warm_start=False))]), array([[5.1, 3.5, 1.4, 0.2],
       [4.9, 3. , 1....2, 3.4, 5.4, 2.3],
       [5.9, 3. , 5.1, 1.8]]), array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,... 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]), {'score': <function _passthrough_scorer>}, array([  5,   6,   7,   8,   9,  10,  11,  12,  ..., 142, 143, 144,
       145, 146, 147, 148, 149]), array([  0,   1,   2,   3,   4,  50,  51,  52,  53,  54, 100, 101, 102,
       103, 104]), 0, None, None), {'error_score': 'raise-deprecating', 'return_estimator': False, 'return_times': True, 'return_train_score': False})]
    226 
    227     def __len__(self):
    228         return self._size
    229 

...........................................................................
/home/aquemy/.local/lib/python2.7/site-packages/sklearn/model_selection/_validation.py in _fit_and_score(estimator=Pipeline(memory=None,
     steps=[('normalizer',... random_state=42, verbose=0, warm_start=False))]), X=array([[5.1, 3.5, 1.4, 0.2],
       [4.9, 3. , 1....2, 3.4, 5.4, 2.3],
       [5.9, 3. , 5.1, 1.8]]), y=array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,... 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]), scorer={'score': <function _passthrough_scorer>}, train=array([  5,   6,   7,   8,   9,  10,  11,  12,  ..., 142, 143, 144,
       145, 146, 147, 148, 149]), test=array([  0,   1,   2,   3,   4,  50,  51,  52,  53,  54, 100, 101, 102,
       103, 104]), verbose=0, parameters=None, fit_params={}, return_train_score=False, return_parameters=False, return_n_test_samples=False, return_times=True, return_estimator=False, error_score='raise-deprecating')
    523 
    524     try:
    525         if y_train is None:
    526             estimator.fit(X_train, **fit_params)
    527         else:
--> 528             estimator.fit(X_train, y_train, **fit_params)
        estimator.fit = <bound method Pipeline.fit of Pipeline(memory=No...random_state=42, verbose=0, warm_start=False))])>
        X_train = array([[5.4, 3.9, 1.7, 0.4],
       [4.6, 3.4, 1....2, 3.4, 5.4, 2.3],
       [5.9, 3. , 5.1, 1.8]])
        y_train = array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,
       2, 2, 2])
        fit_params = {}
    529 
    530     except Exception as e:
    531         # Note fit time as time until error
    532         fit_time = time.time() - start_time

...........................................................................
/usr/local/lib/python2.7/dist-packages/imblearn/pipeline.py in fit(self=Pipeline(memory=None,
     steps=[('normalizer',... random_state=42, verbose=0, warm_start=False))]), X=array([[5.4, 3.9, 1.7, 0.4],
       [4.6, 3.4, 1....2, 3.4, 5.4, 2.3],
       [5.9, 3. , 5.1, 1.8]]), y=array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,
       2, 2, 2]), **fit_params={})
    234             This estimator
    235 
    236         """
    237         Xt, yt, fit_params = self._fit(X, y, **fit_params)
    238         if self._final_estimator is not None:
--> 239             self._final_estimator.fit(Xt, yt, **fit_params)
        self._final_estimator.fit = <bound method RandomForestClassifier.fit of Rand...e, random_state=42, verbose=0, warm_start=False)>
        Xt = array([[0.97077501, 0.53000149],
       [0.79946...7, 3.04750858],
       [2.91232503, 2.38500672]])
        yt = array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,
       2, 2, 2])
        fit_params = {}
    240         return self
    241 
    242     def fit_transform(self, X, y=None, **fit_params):
    243         """Fit the model and transform with the final estimator

...........................................................................
/home/aquemy/.local/lib/python2.7/site-packages/sklearn/ensemble/forest.py in fit(self=RandomForestClassifier(bootstrap=True, class_wei...se, random_state=42, verbose=0, warm_start=False), X=array([[0.970775  , 0.5300015 ],
       [0.79946...
       [2.9123251 , 2.3850067 ]], dtype=float32), y=array([[0.],
       [0.],
       [0.],
       [0...    [2.],
       [2.],
       [2.],
       [2.]]), sample_weight=None)
    328             trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,
    329                              **_joblib_parallel_args(prefer='threads'))(
    330                 delayed(_parallel_build_trees)(
    331                     t, self, X, y, sample_weight, i, len(trees),
    332                     verbose=self.verbose, class_weight=self.class_weight)
--> 333                 for i, t in enumerate(trees))
        i = 9
    334 
    335             # Collect newly grown trees
    336             self.estimators_.extend(trees)
    337 

...........................................................................
/home/aquemy/.local/lib/python2.7/site-packages/sklearn/externals/joblib/parallel.py in __call__(self=Parallel(n_jobs=1), iterable=<generator object <genexpr>>)
    912             # self._original_iterator is None, then this means either
    913             # that pre_dispatch == "all", n_jobs == 1 or that the first batch
    914             # was very quick and its callback already dispatched all the
    915             # remaining jobs.
    916             self._iterating = False
--> 917             if self.dispatch_one_batch(iterator):
        self.dispatch_one_batch = <bound method Parallel.dispatch_one_batch of Parallel(n_jobs=1)>
        iterator = <generator object <genexpr>>
    918                 self._iterating = self._original_iterator is not None
    919 
    920             while self.dispatch_one_batch(iterator):
    921                 pass

...........................................................................
/home/aquemy/.local/lib/python2.7/site-packages/sklearn/externals/joblib/parallel.py in dispatch_one_batch(self=Parallel(n_jobs=1), iterator=<generator object <genexpr>>)
    754                                  self._pickle_cache)
    755             if len(tasks) == 0:
    756                 # No more tasks available in the iterator: tell caller to stop.
    757                 return False
    758             else:
--> 759                 self._dispatch(tasks)
        self._dispatch = <bound method Parallel._dispatch of Parallel(n_jobs=1)>
        tasks = <sklearn.externals.joblib.parallel.BatchedCalls object>
    760                 return True
    761 
    762     def _print(self, msg, msg_args):
    763         """Display the message on stout or stderr depending on verbosity"""

...........................................................................
/home/aquemy/.local/lib/python2.7/site-packages/sklearn/externals/joblib/parallel.py in _dispatch(self=Parallel(n_jobs=1), batch=<sklearn.externals.joblib.parallel.BatchedCalls object>)
    711 
    712         dispatch_timestamp = time.time()
    713         cb = BatchCompletionCallBack(dispatch_timestamp, len(batch), self)
    714         with self._lock:
    715             job_idx = len(self._jobs)
--> 716             job = self._backend.apply_async(batch, callback=cb)
        job = undefined
        self._backend.apply_async = <bound method SequentialBackend.apply_async of <...lib._parallel_backends.SequentialBackend object>>
        batch = <sklearn.externals.joblib.parallel.BatchedCalls object>
        cb = <sklearn.externals.joblib.parallel.BatchCompletionCallBack object>
    717             # A job can complete so quickly than its callback is
    718             # called before we get here, causing self._jobs to
    719             # grow. To ensure correct results ordering, .insert is
    720             # used (rather than .append) in the following line

...........................................................................
/home/aquemy/.local/lib/python2.7/site-packages/sklearn/externals/joblib/_parallel_backends.py in apply_async(self=<sklearn.externals.joblib._parallel_backends.SequentialBackend object>, func=<sklearn.externals.joblib.parallel.BatchedCalls object>, callback=<sklearn.externals.joblib.parallel.BatchCompletionCallBack object>)
    177             raise ValueError('n_jobs == 0 in Parallel has no meaning')
    178         return 1
    179 
    180     def apply_async(self, func, callback=None):
    181         """Schedule a func to be run"""
--> 182         result = ImmediateResult(func)
        result = undefined
        func = <sklearn.externals.joblib.parallel.BatchedCalls object>
    183         if callback:
    184             callback(result)
    185         return result
    186 

...........................................................................
/home/aquemy/.local/lib/python2.7/site-packages/sklearn/externals/joblib/_parallel_backends.py in __init__(self=<sklearn.externals.joblib._parallel_backends.ImmediateResult object>, batch=<sklearn.externals.joblib.parallel.BatchedCalls object>)
    544 
    545 class ImmediateResult(object):
    546     def __init__(self, batch):
    547         # Don't delay the application, to avoid keeping the input
    548         # arguments in memory
--> 549         self.results = batch()
        self.results = undefined
        batch = <sklearn.externals.joblib.parallel.BatchedCalls object>
    550 
    551     def get(self):
    552         return self.results
    553 

...........................................................................
/home/aquemy/.local/lib/python2.7/site-packages/sklearn/externals/joblib/parallel.py in __call__(self=<sklearn.externals.joblib.parallel.BatchedCalls object>)
    220     def __call__(self):
    221         # Set the default nested backend to self._backend but do not set the
    222         # change the default number of processes to -1
    223         with parallel_backend(self._backend, n_jobs=self._n_jobs):
    224             return [func(*args, **kwargs)
--> 225                     for func, args, kwargs in self.items]
        func = <function _parallel_build_trees>
        args = (DecisionTreeClassifier(class_weight=None, criter...=False, random_state=1608637542, splitter='best'), RandomForestClassifier(bootstrap=True, class_wei...se, random_state=42, verbose=0, warm_start=False), array([[0.970775  , 0.5300015 ],
       [0.79946...
       [2.9123251 , 2.3850067 ]], dtype=float32), array([[0.],
       [0.],
       [0.],
       [0...    [2.],
       [2.],
       [2.],
       [2.]]), None, 0, 10)
        kwargs = {'class_weight': None, 'verbose': 0}
        self.items = [(<function _parallel_build_trees>, (DecisionTreeClassifier(class_weight=None, criter...=False, random_state=1608637542, splitter='best'), RandomForestClassifier(bootstrap=True, class_wei...se, random_state=42, verbose=0, warm_start=False), array([[0.970775  , 0.5300015 ],
       [0.79946...
       [2.9123251 , 2.3850067 ]], dtype=float32), array([[0.],
       [0.],
       [0.],
       [0...    [2.],
       [2.],
       [2.],
       [2.]]), None, 0, 10), {'class_weight': None, 'verbose': 0})]
    226 
    227     def __len__(self):
    228         return self._size
    229 

...........................................................................
/home/aquemy/.local/lib/python2.7/site-packages/sklearn/ensemble/forest.py in _parallel_build_trees(tree=DecisionTreeClassifier(class_weight=None, criter...=False, random_state=1608637542, splitter='best'), forest=RandomForestClassifier(bootstrap=True, class_wei...se, random_state=42, verbose=0, warm_start=False), X=array([[0.970775  , 0.5300015 ],
       [0.79946...
       [2.9123251 , 2.3850067 ]], dtype=float32), y=array([[0.],
       [0.],
       [0.],
       [0...    [2.],
       [2.],
       [2.],
       [2.]]), sample_weight=None, tree_idx=0, n_trees=10, verbose=0, class_weight=None)
    114                 simplefilter('ignore', DeprecationWarning)
    115                 curr_sample_weight *= compute_sample_weight('auto', y, indices)
    116         elif class_weight == 'balanced_subsample':
    117             curr_sample_weight *= compute_sample_weight('balanced', y, indices)
    118 
--> 119         tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)
        tree.fit = <bound method DecisionTreeClassifier.fit of Deci...False, random_state=1608637542, splitter='best')>
        X = array([[0.970775  , 0.5300015 ],
       [0.79946...
       [2.9123251 , 2.3850067 ]], dtype=float32)
        y = array([[0.],
       [0.],
       [0.],
       [0...    [2.],
       [2.],
       [2.],
       [2.]])
        sample_weight = None
        curr_sample_weight = array([3., 3., 0., 1., 1., 2., 2., 0., 1., 2., 0... 1., 0., 1., 0., 1., 1., 1., 1., 1., 1., 0., 0.])
    120     else:
    121         tree.fit(X, y, sample_weight=sample_weight, check_input=False)
    122 
    123     return tree

...........................................................................
/home/aquemy/.local/lib/python2.7/site-packages/sklearn/tree/tree.py in fit(self=DecisionTreeClassifier(class_weight=None, criter...=False, random_state=1608637542, splitter='best'), X=array([[0.970775  , 0.5300015 ],
       [0.79946...
       [2.9123251 , 2.3850067 ]], dtype=float32), y=array([[0.],
       [0.],
       [0.],
       [0...    [2.],
       [2.],
       [2.],
       [2.]]), sample_weight=array([3., 3., 0., 1., 1., 2., 2., 0., 1., 2., 0... 1., 0., 1., 0., 1., 1., 1., 1., 1., 1., 0., 0.]), check_input=False, X_idx_sorted=None)
    796 
    797         super(DecisionTreeClassifier, self).fit(
    798             X, y,
    799             sample_weight=sample_weight,
    800             check_input=check_input,
--> 801             X_idx_sorted=X_idx_sorted)
        X_idx_sorted = None
    802         return self
    803 
    804     def predict_proba(self, X, check_input=True):
    805         """Predict class probabilities of the input samples X.

...........................................................................
/home/aquemy/.local/lib/python2.7/site-packages/sklearn/tree/tree.py in fit(self=DecisionTreeClassifier(class_weight=None, criter...=False, random_state=1608637542, splitter='best'), X=array([[0.970775  , 0.5300015 ],
       [0.79946...
       [2.9123251 , 2.3850067 ]], dtype=float32), y=array([[0.],
       [0.],
       [0.],
       [0...    [2.],
       [2.],
       [2.],
       [2.]]), sample_weight=array([3., 3., 0., 1., 1., 2., 2., 0., 1., 2., 0... 1., 0., 1., 0., 1., 1., 1., 1., 1., 1., 0., 0.]), check_input=False, X_idx_sorted=None)
    237         if not 0 <= self.min_weight_fraction_leaf <= 0.5:
    238             raise ValueError("min_weight_fraction_leaf must in [0, 0.5]")
    239         if max_depth <= 0:
    240             raise ValueError("max_depth must be greater than zero. ")
    241         if not (0 < max_features <= self.n_features_):
--> 242             raise ValueError("max_features must be in (0, n_features]")
    243         if not isinstance(max_leaf_nodes, (numbers.Integral, np.integer)):
    244             raise ValueError("max_leaf_nodes must be integral number but was "
    245                              "%r" % max_leaf_nodes)
    246         if -1 < max_leaf_nodes < 2:

ValueError: max_features must be in (0, n_features]
___________________________________________________________________________
Best score: 0.966666666667 (0.0333333333333) [J] | Score: 0.0 (0.0) [J]
Best score: 0.966666666667 (0.0333333333333) [J] | Score: 0.926666666667 (0.075718777944) [J]
Best score: 0.966666666667 (0.0333333333333) [J] | Score: 0.746666666667 (0.157197681634) [J]
Best score: 0.966666666667 (0.0333333333333) [J] | Score: 0.953333333333 (0.06) [J]
JoblibValueError
___________________________________________________________________________
...........................................................................
/home/aquemy/dev/dp_hyperparameters/extension/main.py in <module>()
     27 
     28     serializer.serialize_results(scenario, policy)
     29 
     30 if __name__ == "__main__":
     31     args = cli.parse_args()
---> 32     main(args)

...........................................................................
/home/aquemy/dev/dp_hyperparameters/extension/main.py in main(args=Namespace(customize=[(['control', 'seed'], '42')...io='./scenarios/rf_iris_joint.yaml', verbosity=0))
     21         test_size=0.4, 
     22         random_state=scenario['control']['seed']
     23     )
     24 
     25     policy = policies.initiate(scenario['setup']['policy'], config)
---> 26     policy.run(X,y)
        policy.run = <bound method Joint.run of <experiment.policies.joint.Joint object>>
        X = array([[5.1, 3.5, 1.4, 0.2],
       [4.9, 3. , 1....2, 3.4, 5.4, 2.3],
       [5.9, 3. , 5.1, 1.8]])
        y = array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,... 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2])
     27 
     28     serializer.serialize_results(scenario, policy)
     29 
     30 if __name__ == "__main__":

...........................................................................
/home/aquemy/dev/dp_hyperparameters/extension/experiment/policies/joint.py in run(self=<experiment.policies.joint.Joint object>, X=array([[5.1, 3.5, 1.4, 0.2],
       [4.9, 3. , 1....2, 3.4, 5.4, 2.3],
       [5.9, 3. , 5.1, 1.8]]), y=array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,... 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]))
     32             algo=tpe.suggest, 
     33             max_evals=None,
     34             max_time=self.config['time'],     
     35             trials=trials,
     36             show_progressbar=False,
---> 37             verbose=0
     38         )
     39 
     40         best_config = self.context['best_config']
     41         super(Joint, self).display_step_results(best_config)

...........................................................................
/home/aquemy/dev/dp_hyperparameters/extension/hyperopt/fmin.py in fmin(fn=<functools.partial object>, space={'algorithm': {'bootstrap': <hyperopt.pyll.base.Apply object>, 'criterion': <hyperopt.pyll.base.Apply object>, 'max_depth': <hyperopt.pyll.base.Apply object>, 'max_features': <hyperopt.pyll.base.Apply object>, 'max_leaf_nodes': <hyperopt.pyll.base.Apply object>, 'min_samples_split': <hyperopt.pyll.base.Apply object>, 'n_estimators': <hyperopt.pyll.base.Apply object>}, 'pipeline': {'features': <hyperopt.pyll.base.Apply object>, 'normalizer': <hyperopt.pyll.base.Apply object>, 'rebalance': <hyperopt.pyll.base.Apply object>}}, algo=<function suggest>, max_evals=9223372036854775807, max_time=300, trials=<hyperopt.base.Trials object>, rstate=<mtrand.RandomState object>, allow_trials_fmin=True, pass_expr_memo_ctrl=None, catch_eval_exceptions=False, verbose=0, return_argmin=True, points_to_evaluate=None, max_queue_len=1, show_progressbar=False)
    406             pass_expr_memo_ctrl=pass_expr_memo_ctrl,
    407             verbose=verbose,
    408             catch_eval_exceptions=catch_eval_exceptions,
    409             return_argmin=return_argmin,
    410             show_progressbar=show_progressbar,
--> 411             max_time=max_time
        max_time = 300
    412         )
    413 
    414     if trials is None:
    415         if points_to_evaluate is None:

...........................................................................
/home/aquemy/dev/dp_hyperparameters/extension/hyperopt/base.py in fmin(self=<hyperopt.base.Trials object>, fn=<functools.partial object>, space={'algorithm': {'bootstrap': <hyperopt.pyll.base.Apply object>, 'criterion': <hyperopt.pyll.base.Apply object>, 'max_depth': <hyperopt.pyll.base.Apply object>, 'max_features': <hyperopt.pyll.base.Apply object>, 'max_leaf_nodes': <hyperopt.pyll.base.Apply object>, 'min_samples_split': <hyperopt.pyll.base.Apply object>, 'n_estimators': <hyperopt.pyll.base.Apply object>}, 'pipeline': {'features': <hyperopt.pyll.base.Apply object>, 'normalizer': <hyperopt.pyll.base.Apply object>, 'rebalance': <hyperopt.pyll.base.Apply object>}}, algo=<function suggest>, max_evals=9223372036854775807, max_time=300, rstate=<mtrand.RandomState object>, verbose=0, pass_expr_memo_ctrl=None, catch_eval_exceptions=False, return_argmin=True, show_progressbar=False)
    636             verbose=verbose,
    637             allow_trials_fmin=False,  # -- prevent recursion
    638             pass_expr_memo_ctrl=pass_expr_memo_ctrl,
    639             catch_eval_exceptions=catch_eval_exceptions,
    640             return_argmin=return_argmin,
--> 641             show_progressbar=show_progressbar)
        show_progressbar = False
    642 
    643 
    644 def trials_from_docs(docs, validate=True, **kwargs):
    645     """Construct a Trials base class instance from a list of trials documents

...........................................................................
/home/aquemy/dev/dp_hyperparameters/extension/hyperopt/fmin.py in fmin(fn=<functools.partial object>, space={'algorithm': {'bootstrap': <hyperopt.pyll.base.Apply object>, 'criterion': <hyperopt.pyll.base.Apply object>, 'max_depth': <hyperopt.pyll.base.Apply object>, 'max_features': <hyperopt.pyll.base.Apply object>, 'max_leaf_nodes': <hyperopt.pyll.base.Apply object>, 'min_samples_split': <hyperopt.pyll.base.Apply object>, 'n_estimators': <hyperopt.pyll.base.Apply object>}, 'pipeline': {'features': <hyperopt.pyll.base.Apply object>, 'normalizer': <hyperopt.pyll.base.Apply object>, 'rebalance': <hyperopt.pyll.base.Apply object>}}, algo=<function suggest>, max_evals=9223372036854775807, max_time=300, trials=<hyperopt.base.Trials object>, rstate=<mtrand.RandomState object>, allow_trials_fmin=False, pass_expr_memo_ctrl=None, catch_eval_exceptions=False, verbose=0, return_argmin=True, points_to_evaluate=None, max_queue_len=1, show_progressbar=False)
    426                     verbose=verbose,
    427                     max_queue_len=max_queue_len,
    428                     show_progressbar=show_progressbar,
    429                     max_time=max_time)
    430     rval.catch_eval_exceptions = catch_eval_exceptions
--> 431     rval.exhaust()
        rval.exhaust = <bound method FMinIter.exhaust of <hyperopt.fmin.FMinIter object>>
    432     if return_argmin:
    433         return trials.argmin
    434     elif len(trials) > 0:
    435         # Only if there are some succesfull trail runs, return the best point in the evaluation space

...........................................................................
/home/aquemy/dev/dp_hyperparameters/extension/hyperopt/fmin.py in exhaust(self=<hyperopt.fmin.FMinIter object>)
    273             raise StopIteration()
    274         return self.trials
    275 
    276     def exhaust(self):
    277         n_done = len(self.trials)
--> 278         self.run(self.max_evals - n_done, block_until_done=self.asynchronous)
        self.run = <bound method FMinIter.run of <hyperopt.fmin.FMinIter object>>
        self.max_evals = 9223372036854775807
        n_done = 0
        self.asynchronous = False
    279         self.trials.refresh()
    280         return self
    281 
    282 

...........................................................................
/home/aquemy/dev/dp_hyperparameters/extension/hyperopt/fmin.py in run(self=<hyperopt.fmin.FMinIter object>, N=9223372036854775807, block_until_done=False)
    232                     if self.asynchronous:
    233                         # -- wait for workers to fill in the trials
    234                         time.sleep(self.poll_interval_secs)
    235                     else:
    236                         # -- loop over trials and do the jobs directly
--> 237                         self.serial_evaluate()
        self.serial_evaluate = <bound method FMinIter.serial_evaluate of <hyperopt.fmin.FMinIter object>>
    238                     try:
    239                         res = [d['result']['loss'] for d in
    240                                          self.trials.trials if
    241                                          d['result']['status'] == 'ok']

...........................................................................
/home/aquemy/dev/dp_hyperparameters/extension/hyperopt/fmin.py in serial_evaluate(self=<hyperopt.fmin.FMinIter object>, N=-1)
    138                 trial['book_time'] = now
    139                 trial['refresh_time'] = now
    140                 spec = base.spec_from_misc(trial['misc'])
    141                 ctrl = base.Ctrl(self.trials, current_trial=trial)
    142                 try:
--> 143                     result = self.domain.evaluate(spec, ctrl)
        result = undefined
        self.domain.evaluate = <bound method Domain.evaluate of <hyperopt.base.Domain object>>
        spec = {'bootstrap': 1, 'criterion': 0, 'features': 3, 'features_FeatureUnion_features__pca__n_components': 0, 'features_FeatureUnion_features__selectkbest__k': 0, 'max_depth': 0, 'max_features': 2, 'max_leaf_nodes': 2, 'min_samples_split': 1, 'n_estimators': 0, ...}
        ctrl = <hyperopt.base.Ctrl object>
    144                 except Exception as e:
    145                     logger.info('job exception: %s' % str(e))
    146                     trial['state'] = base.JOB_STATE_ERROR
    147                     trial['misc']['error'] = (str(type(e)), str(e))

...........................................................................
/home/aquemy/dev/dp_hyperparameters/extension/hyperopt/base.py in evaluate(self=<hyperopt.base.Domain object>, config={'bootstrap': 1, 'criterion': 0, 'features': 3, 'features_FeatureUnion_features__pca__n_components': 0, 'features_FeatureUnion_features__selectkbest__k': 0, 'max_depth': 0, 'max_features': 2, 'max_leaf_nodes': 2, 'min_samples_split': 1, 'n_estimators': 0, ...}, ctrl=<hyperopt.base.Ctrl object>, attach_attachments=True)
    841             #    or the normal Python part (self.fn)
    842             pyll_rval = pyll.rec_eval(
    843                 self.expr,
    844                 memo=memo,
    845                 print_node_on_error=self.rec_eval_print_node_on_error)
--> 846             rval = self.fn(pyll_rval)
        rval = undefined
        self.fn = <functools.partial object>
        pyll_rval = {'algorithm': {'bootstrap': False, 'criterion': 'gini', 'max_depth': 1, 'max_features': 3, 'max_leaf_nodes': 5, 'min_samples_split': 3, 'n_estimators': 10}, 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 1, 'features__selectkbest__k': 1}), 'normalizer': ('normalizer_NoneType', {}), 'rebalance': ('rebalance_CondensedNearestNeighbour', {'rebalance__n_neighbors': 2})}}
    847 
    848         if isinstance(rval, (float, int, np.number)):
    849             dict_rval = {'loss': float(rval), 'status': STATUS_OK}
    850         else:

...........................................................................
/home/aquemy/dev/dp_hyperparameters/extension/experiment/objective.py in objective_joint(wconfig={'algorithm': {'bootstrap': False, 'criterion': 'gini', 'max_depth': 1, 'max_features': 3, 'max_leaf_nodes': 5, 'min_samples_split': 3, 'n_estimators': 10}, 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 1, 'features__selectkbest__k': 1}), 'normalizer': ('normalizer_NoneType', {}), 'rebalance': ('rebalance_CondensedNearestNeighbour', {'rebalance__n_neighbors': 2})}}, algorithm='RandomForest', X=array([[5.1, 3.5, 1.4, 0.2],
       [4.9, 3. , 1....2, 3.4, 5.4, 2.3],
       [5.9, 3. , 5.1, 1.8]]), y=array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,... 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]), context={'baseline_score': 0.9466666666666667, 'baseline_score_std': 0.04988876515698587, 'best_config': {'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': 4, 'max_features': 3, 'max_leaf_nodes': 3, 'min_samples_split': 3, 'n_estimators': 10}, 'config_hash': {'algorithm': 'ffb7ff225ce3d3712c96cf87fe42202988ee2eb0', 'config': 'bae32f426be9cd6243523c023944a8c148fe4aeb', 'pipeline': 'd2a68bfda6fcdec4ae0ffc7d7b6a2122bc1cd673'}, 'duration': 0.7115809917449951, 'iteration': 113, 'loss': 0.033333333333333215, 'max_history_score': 0.9666666666666668, 'max_history_score_std': 0.033333333333333326, 'max_history_step': 'joint', 'pipeline': {'features': ('features_NoneType', {}), 'normalizer': ('normalizer_PowerTransformer', {}), 'rebalance': ('rebalance_CondensedNearestNeighbour', {'rebalance__n_neighbors': 2})}, 'score': 0.9666666666666668, ...}, 'history': [{'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': 2, 'max_features': None, 'max_leaf_nodes': 5, 'min_samples_split': 2, 'n_estimators': 75}, 'config_hash': {'algorithm': '3af5b0cce71c8fe2545246ca24ff5bc3dd516e06', 'config': 'db6ac7e6d348155757e4794bb5f88fe2b4f63d50', 'pipeline': '8d59f4b94cef6be9306ed86a22a9570fa670d567'}, 'duration': 1.149928092956543, 'iteration': 0, 'loss': 0.046666666666666634, 'max_history_score': 0.9533333333333334, 'max_history_score_std': 0.059999999999999984, 'max_history_step': 'joint', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 4, 'features__selectkbest__k': 3}), 'normalizer': ('normalizer_StandardScaler', {'normalizer__with_mean': True, 'normalizer__with_std': True}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 6})}, 'score': 0.9533333333333334, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': 1, 'max_features': 2, 'max_leaf_nodes': 2, 'min_samples_split': 5, 'n_estimators': 100}, 'config_hash': {'algorithm': 'e13eb05fd9a62d2f63bbb1c1deff0cd620d5e6ab', 'config': '4db6fb84d85f52659f780e682ffac5712c3d8a94', 'pipeline': '64c9a1ca9d53ae67244bdd942f4db36a3c05218c'}, 'duration': 1.7678282260894775, 'iteration': 1, 'loss': 0.18000000000000005, 'max_history_score': 0.9533333333333334, 'max_history_score_std': 0.059999999999999984, 'max_history_step': 'joint', 'pipeline': {'features': ('features_NoneType', {}), 'normalizer': ('normalizer_PowerTransformer', {}), 'rebalance': ('rebalance_NearMiss', {'rebalance__n_neighbors': 1})}, 'score': 0.82, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': 1, 'max_features': None, 'max_leaf_nodes': None, 'min_samples_split': 5, 'n_estimators': 75}, 'config_hash': {'algorithm': '94b0d7a654c508cc63643f78fe4f0f07e6f07c1e', 'config': '4403c5a85e951938d3c454e961d3a412780722f6', 'pipeline': '3e47444880d8367fbac2faaba2e52a917274aa58'}, 'duration': 0.8397619724273682, 'iteration': 2, 'loss': 0.03333333333333344, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_PCA', {'features__n_components': 3}), 'normalizer': ('normalizer_MinMaxScaler', {}), 'rebalance': ('rebalance_NoneType', {})}, 'score': 0.9666666666666666, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': None, 'max_features': None, 'max_leaf_nodes': 3, 'min_samples_split': 3, 'n_estimators': 75}, 'config_hash': {'algorithm': 'e8332f0a8902bda03bf70e7978cc5d52affb29d3', 'config': 'a064e2df18ab98d44dabcefbc7bed94913f1d0be', 'pipeline': '7eea819c2a8c103c4b1e9e9c1e224aebba95081f'}, 'duration': 0.8501448631286621, 'iteration': 3, 'loss': 0.053333333333333344, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 2, 'features__selectkbest__k': 4}), 'normalizer': ('normalizer_NoneType', {}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 7})}, 'score': 0.9466666666666667, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'entropy', 'max_depth': 3, 'max_features': 3, 'max_leaf_nodes': None, 'min_samples_split': 5, 'n_estimators': 75}, 'config_hash': {'algorithm': '7a4491035bc6bd737fe9a8cda8a79a02d02d5c74', 'config': '0ddb6f5cab3db4dddd7682966a57205f3e329ad4', 'pipeline': 'a9ae03fe38334f6868cbf84cdd3d629d4bbe3fb0'}, 'duration': 1.1026010513305664, 'iteration': 4, 'loss': 0.05999999999999994, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 2, 'features__selectkbest__k': 1}), 'normalizer': ('normalizer_NoneType', {}), 'rebalance': ('rebalance_NoneType', {})}, 'score': 0.9400000000000001, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'gini', 'max_depth': 3, 'max_features': 1, 'max_leaf_nodes': 5, 'min_samples_split': 2, 'n_estimators': 25}, 'config_hash': {'algorithm': '9826d20b2d6a0f559cf7f16450ce7526f07e8434', 'config': '49f25751bca61cdd461a8cbd2923689b642f98ed', 'pipeline': '19b249664c5bf067de1fed4334a296f947ce774a'}, 'duration': 0.35647010803222656, 'iteration': 5, 'loss': 0.046666666666666634, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_NoneType', {}), 'normalizer': ('normalizer_NoneType', {}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 6})}, 'score': 0.9533333333333334, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'gini', 'max_depth': 2, 'max_features': 1, 'max_leaf_nodes': 2, 'min_samples_split': 2, 'n_estimators': 50}, 'config_hash': {'algorithm': '0a4f6fbb07e0f32c6f675489a0fc82eee05bd8e1', 'config': '5c3a2b6f5e63fb45f10e41e0318b354912ec44f6', 'pipeline': 'dc3b9f176f090005e38b142f11d80e93a7dc5d5e'}, 'duration': 0.7213859558105469, 'iteration': 6, 'loss': 0.31333333333333324, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 1, 'features__selectkbest__k': 4}), 'normalizer': ('normalizer_PowerTransformer', {}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 7})}, 'score': 0.6866666666666668, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'entropy', 'max_depth': 4, 'max_features': 3, 'max_leaf_nodes': 5, 'min_samples_split': 5, 'n_estimators': 10}, 'config_hash': {'algorithm': 'b8112b97ecfc10f00a195af661dcc861cac21289', 'config': 'd3b129b397350f1b6572651c67c01de49b4b174c', 'pipeline': '5b0357ed7072c37b3d6f458bb5d49ff7d825f603'}, 'duration': 0.8299109935760498, 'iteration': 7, 'loss': 1.0, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_PCA', {'features__n_components': 2}), 'normalizer': ('normalizer_StandardScaler', {'normalizer__with_mean': True, 'normalizer__with_std': False}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 6})}, 'score': 0.0, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'gini', 'max_depth': 4, 'max_features': None, 'max_leaf_nodes': 2, 'min_samples_split': 5, 'n_estimators': 100}, 'config_hash': {'algorithm': '40ca24df19b8d164d9d098a6bed1ce056fbbb961', 'config': '813bde1108cc3c4b9bfb3a22cbb421bda7eac671', 'pipeline': '74a7b8705a1c22f7dea5e44e4ebda8f1e48add71'}, 'duration': 2.2111589908599854, 'iteration': 8, 'loss': 0.33333333333333326, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_PCA', {'features__n_components': 2}), 'normalizer': ('normalizer_StandardScaler', {'normalizer__with_mean': False, 'normalizer__with_std': True}), 'rebalance': ('rebalance_NearMiss', {'rebalance__n_neighbors': 2})}, 'score': 0.6666666666666667, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'entropy', 'max_depth': 2, 'max_features': 1, 'max_leaf_nodes': 5, 'min_samples_split': 2, 'n_estimators': 100}, 'config_hash': {'algorithm': '331418a5c12cf1453876eef85e9d98fc8e54fa11', 'config': '31930b6860ed406d59bf7e59ba1925d94704bd3b', 'pipeline': '054bef356f90ec6f644ef3ffc688766744db51c2'}, 'duration': 1.0501940250396729, 'iteration': 9, 'loss': 0.053333333333333344, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_SelectKBest', {'features__k': 1}), 'normalizer': ('normalizer_RobustScaler', {'normalizer__quantile_range': (...), 'normalizer__with_centering': True, 'normalizer__with_scaling': True}), 'rebalance': ('rebalance_NearMiss', {'rebalance__n_neighbors': 2})}, 'score': 0.9466666666666667, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'entropy', 'max_depth': 3, 'max_features': None, 'max_leaf_nodes': 3, 'min_samples_split': 2, 'n_estimators': 100}, 'config_hash': {'algorithm': 'dbc1b8126649fe93dce5fbb37e4015b0acfb179e', 'config': '9913cd550615a9d0946ab4a755a8b9f619e442fd', 'pipeline': 'dd626121cea079ebb32e184ca65483ec7a6d7f59'}, 'duration': 1.120617151260376, 'iteration': 10, 'loss': 0.046666666666666634, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 2, 'features__selectkbest__k': 1}), 'normalizer': ('normalizer_MinMaxScaler', {}), 'rebalance': ('rebalance_NoneType', {})}, 'score': 0.9533333333333334, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'gini', 'max_depth': 3, 'max_features': 3, 'max_leaf_nodes': None, 'min_samples_split': 3, 'n_estimators': 75}, 'config_hash': {'algorithm': '34917a130df5a975f78bd7ec1a0c7b1ffdc787a9', 'config': '95fc8cadc088141290b7de9c388977e4685f0108', 'pipeline': '550d10faf2f08db48516cc3501558816d6a99bc0'}, 'duration': 1.4287099838256836, 'iteration': 11, 'loss': 0.19333333333333313, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 3, 'features__selectkbest__k': 4}), 'normalizer': ('normalizer_StandardScaler', {'normalizer__with_mean': False, 'normalizer__with_std': False}), 'rebalance': ('rebalance_CondensedNearestNeighbour', {'rebalance__n_neighbors': 1})}, 'score': 0.8066666666666669, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'entropy', 'max_depth': 1, 'max_features': 2, 'max_leaf_nodes': 5, 'min_samples_split': 2, 'n_estimators': 75}, 'config_hash': {'algorithm': '33f9abb4aee44a395a9f3b3ffa9ce80a8cdaed7c', 'config': '40fa726f0360cf6af55f9b5902d399d02f61f157', 'pipeline': 'cfd1d20841fe2153da762c95e79f95a3fb1e426a'}, 'duration': 1.2978079319000244, 'iteration': 12, 'loss': 0.053333333333333344, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_PCA', {'features__n_components': 4}), 'normalizer': ('normalizer_MinMaxScaler', {}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 7})}, 'score': 0.9466666666666667, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'entropy', 'max_depth': 4, 'max_features': 2, 'max_leaf_nodes': 5, 'min_samples_split': 3, 'n_estimators': 25}, 'config_hash': {'algorithm': '210111ec6562d09eb093e98ed69ef1c662e11a50', 'config': '0fb8e77c7bd9a58b72f1b33c21a59a09a8c676ba', 'pipeline': '5d269d759e0c7926a685a14b263ace8ae0071e4b'}, 'duration': 0.36649012565612793, 'iteration': 13, 'loss': 0.040000000000000036, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 2, 'features__selectkbest__k': 2}), 'normalizer': ('normalizer_NoneType', {}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 7})}, 'score': 0.96, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'entropy', 'max_depth': 3, 'max_features': 1, 'max_leaf_nodes': 5, 'min_samples_split': 2, 'n_estimators': 25}, 'config_hash': {'algorithm': '0e989a03980101fabf79eda3326ed2870e11d690', 'config': 'f4bffd5d8c67a9c5321a9943c4a99678f59a02b7', 'pipeline': '865ee1e3fe8334c3d5ecb2038d5a5d1b3ba50e75'}, 'duration': 0.35639500617980957, 'iteration': 14, 'loss': 0.046666666666666634, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_NoneType', {}), 'normalizer': ('normalizer_RobustScaler', {'normalizer__quantile_range': (...), 'normalizer__with_centering': True, 'normalizer__with_scaling': False}), 'rebalance': ('rebalance_NoneType', {})}, 'score': 0.9533333333333334, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'entropy', 'max_depth': None, 'max_features': 3, 'max_leaf_nodes': 3, 'min_samples_split': 5, 'n_estimators': 10}, 'config_hash': {'algorithm': '9c592e876c13de5e23e6de5b868e01755d63e72e', 'config': '1e6a68cd1eeac886d90724d78b1cb5fb76a3cde4', 'pipeline': '5a1ca4d82f21b7de0d2c918630a42510673fa36e'}, 'duration': 0.18141412734985352, 'iteration': 15, 'loss': 0.046666666666666634, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_SelectKBest', {'features__k': 3}), 'normalizer': ('normalizer_RobustScaler', {'normalizer__quantile_range': (...), 'normalizer__with_centering': True, 'normalizer__with_scaling': True}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 6})}, 'score': 0.9533333333333334, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': 1, 'max_features': None, 'max_leaf_nodes': None, 'min_samples_split': 5, 'n_estimators': 10}, 'config_hash': {'algorithm': '8bed77aef289bfd453b2858bd288ae5ba7160f2b', 'config': '781185bcb8999045de8d489f253a1a1ba4247932', 'pipeline': '1ece7eabedc2be9e5b0a1be65c570d08ffa3eb54'}, 'duration': 0.1636829376220703, 'iteration': 16, 'loss': 0.053333333333333344, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_NoneType', {}), 'normalizer': ('normalizer_NoneType', {}), 'rebalance': ('rebalance_NearMiss', {'rebalance__n_neighbors': 1})}, 'score': 0.9466666666666667, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'gini', 'max_depth': 3, 'max_features': 2, 'max_leaf_nodes': 2, 'min_samples_split': 5, 'n_estimators': 75}, 'config_hash': {'algorithm': '617b97d9ba21d3373bc51ffa9cccf9c6f91a77b3', 'config': '99fb425b4e8c5d80228cab94202252aa25cdf77c', 'pipeline': 'd6242929c3b515c7719e60423023ac604311afc3'}, 'duration': 0.8468999862670898, 'iteration': 17, 'loss': 0.24, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_PCA', {'features__n_components': 4}), 'normalizer': ('normalizer_PowerTransformer', {}), 'rebalance': ('rebalance_NearMiss', {'rebalance__n_neighbors': 2})}, 'score': 0.76, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': 1, 'max_features': 1, 'max_leaf_nodes': 2, 'min_samples_split': 5, 'n_estimators': 50}, 'config_hash': {'algorithm': 'b92d2697cdd4979da443369d6596229ec091626a', 'config': 'c513a3e13281206ad76187dd817b1fff93d54fe1', 'pipeline': 'c4b4f914a3ca8df967cade997a90366d85a371b9'}, 'duration': 0.6724588871002197, 'iteration': 18, 'loss': 0.23333333333333328, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 1, 'features__selectkbest__k': 3}), 'normalizer': ('normalizer_StandardScaler', {'normalizer__with_mean': True, 'normalizer__with_std': True}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 5})}, 'score': 0.7666666666666667, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'entropy', 'max_depth': None, 'max_features': None, 'max_leaf_nodes': 5, 'min_samples_split': 5, 'n_estimators': 10}, 'config_hash': {'algorithm': 'a0115de695e6cca2e81cbfb54df79bf4b43608b1', 'config': 'ba194015e20b5d67770e8c67342c3d8d0d01dc41', 'pipeline': '8d45fabfeb85ffdcabf7076bd0e65fffe97ce928'}, 'duration': 0.19424200057983398, 'iteration': 19, 'loss': 0.08666666666666667, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_PCA', {'features__n_components': 3}), 'normalizer': ('normalizer_NoneType', {}), 'rebalance': ('rebalance_NoneType', {})}, 'score': 0.9133333333333333, ...}, ...], 'history_hash': ['db6ac7e6d348155757e4794bb5f88fe2b4f63d50', '4db6fb84d85f52659f780e682ffac5712c3d8a94', '4403c5a85e951938d3c454e961d3a412780722f6', 'a064e2df18ab98d44dabcefbc7bed94913f1d0be', '0ddb6f5cab3db4dddd7682966a57205f3e329ad4', '49f25751bca61cdd461a8cbd2923689b642f98ed', '5c3a2b6f5e63fb45f10e41e0318b354912ec44f6', 'd3b129b397350f1b6572651c67c01de49b4b174c', '813bde1108cc3c4b9bfb3a22cbb421bda7eac671', '31930b6860ed406d59bf7e59ba1925d94704bd3b', '9913cd550615a9d0946ab4a755a8b9f619e442fd', '95fc8cadc088141290b7de9c388977e4685f0108', '40fa726f0360cf6af55f9b5902d399d02f61f157', '0fb8e77c7bd9a58b72f1b33c21a59a09a8c676ba', 'f4bffd5d8c67a9c5321a9943c4a99678f59a02b7', '1e6a68cd1eeac886d90724d78b1cb5fb76a3cde4', '781185bcb8999045de8d489f253a1a1ba4247932', '99fb425b4e8c5d80228cab94202252aa25cdf77c', 'c513a3e13281206ad76187dd817b1fff93d54fe1', 'ba194015e20b5d67770e8c67342c3d8d0d01dc41', ...], 'history_index': {'00f0493590a2cb5e98a35b29816f8cd9f87f96ec': 208, '013329309d510b94f19d930320402d65f953a847': 39, '038a0f515e2ec894ee8e34f9caa2889eb3ebd5ce': 66, '052ae4bf232b316187b078abae42c2be19e16a00': 111, '05e9258ebf99dd97202167ef1563fa834b0568f1': 242, '0659afebf316aafeb75612fb07081a04c28545ed': 74, '06e7cde9f3556cd01332ce389ad1d8925cd4b4a4': 120, '07ab8a30d853e39a326b7017026a20e94bc45541': 245, '08606f2a0f0a6c9de204020b4632e09fcee0ae56': 168, '09dbd0948e5b8c1b1f0930778babe65c8a81295e': 243, ...}, 'iteration': 288, 'max_history_score': 0.9666666666666668, 'max_history_score_std': 0.033333333333333326, 'max_history_step': 'joint'}, config={'algorithm': 'RandomForest', 'seed': 42, 'time': 300})
    108 
    109 def objective_algo(algo_config, current_pipeline_config, algorithm, X, y, context, config):
    110     return objective(current_pipeline_config, algo_config, algorithm, X, y, context, config, step='algorithm')
    111 
    112 def objective_joint(wconfig, algorithm, X, y, context, config):
--> 113     return objective(wconfig['pipeline'], wconfig['algorithm'], algorithm, X, y, context, config, step='joint')
        wconfig = {'algorithm': {'bootstrap': False, 'criterion': 'gini', 'max_depth': 1, 'max_features': 3, 'max_leaf_nodes': 5, 'min_samples_split': 3, 'n_estimators': 10}, 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 1, 'features__selectkbest__k': 1}), 'normalizer': ('normalizer_NoneType', {}), 'rebalance': ('rebalance_CondensedNearestNeighbour', {'rebalance__n_neighbors': 2})}}
        algorithm = 'RandomForest'
        X = array([[5.1, 3.5, 1.4, 0.2],
       [4.9, 3. , 1....2, 3.4, 5.4, 2.3],
       [5.9, 3. , 5.1, 1.8]])
        y = array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,... 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2])
        context = {'baseline_score': 0.9466666666666667, 'baseline_score_std': 0.04988876515698587, 'best_config': {'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': 4, 'max_features': 3, 'max_leaf_nodes': 3, 'min_samples_split': 3, 'n_estimators': 10}, 'config_hash': {'algorithm': 'ffb7ff225ce3d3712c96cf87fe42202988ee2eb0', 'config': 'bae32f426be9cd6243523c023944a8c148fe4aeb', 'pipeline': 'd2a68bfda6fcdec4ae0ffc7d7b6a2122bc1cd673'}, 'duration': 0.7115809917449951, 'iteration': 113, 'loss': 0.033333333333333215, 'max_history_score': 0.9666666666666668, 'max_history_score_std': 0.033333333333333326, 'max_history_step': 'joint', 'pipeline': {'features': ('features_NoneType', {}), 'normalizer': ('normalizer_PowerTransformer', {}), 'rebalance': ('rebalance_CondensedNearestNeighbour', {'rebalance__n_neighbors': 2})}, 'score': 0.9666666666666668, ...}, 'history': [{'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': 2, 'max_features': None, 'max_leaf_nodes': 5, 'min_samples_split': 2, 'n_estimators': 75}, 'config_hash': {'algorithm': '3af5b0cce71c8fe2545246ca24ff5bc3dd516e06', 'config': 'db6ac7e6d348155757e4794bb5f88fe2b4f63d50', 'pipeline': '8d59f4b94cef6be9306ed86a22a9570fa670d567'}, 'duration': 1.149928092956543, 'iteration': 0, 'loss': 0.046666666666666634, 'max_history_score': 0.9533333333333334, 'max_history_score_std': 0.059999999999999984, 'max_history_step': 'joint', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 4, 'features__selectkbest__k': 3}), 'normalizer': ('normalizer_StandardScaler', {'normalizer__with_mean': True, 'normalizer__with_std': True}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 6})}, 'score': 0.9533333333333334, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': 1, 'max_features': 2, 'max_leaf_nodes': 2, 'min_samples_split': 5, 'n_estimators': 100}, 'config_hash': {'algorithm': 'e13eb05fd9a62d2f63bbb1c1deff0cd620d5e6ab', 'config': '4db6fb84d85f52659f780e682ffac5712c3d8a94', 'pipeline': '64c9a1ca9d53ae67244bdd942f4db36a3c05218c'}, 'duration': 1.7678282260894775, 'iteration': 1, 'loss': 0.18000000000000005, 'max_history_score': 0.9533333333333334, 'max_history_score_std': 0.059999999999999984, 'max_history_step': 'joint', 'pipeline': {'features': ('features_NoneType', {}), 'normalizer': ('normalizer_PowerTransformer', {}), 'rebalance': ('rebalance_NearMiss', {'rebalance__n_neighbors': 1})}, 'score': 0.82, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': 1, 'max_features': None, 'max_leaf_nodes': None, 'min_samples_split': 5, 'n_estimators': 75}, 'config_hash': {'algorithm': '94b0d7a654c508cc63643f78fe4f0f07e6f07c1e', 'config': '4403c5a85e951938d3c454e961d3a412780722f6', 'pipeline': '3e47444880d8367fbac2faaba2e52a917274aa58'}, 'duration': 0.8397619724273682, 'iteration': 2, 'loss': 0.03333333333333344, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_PCA', {'features__n_components': 3}), 'normalizer': ('normalizer_MinMaxScaler', {}), 'rebalance': ('rebalance_NoneType', {})}, 'score': 0.9666666666666666, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': None, 'max_features': None, 'max_leaf_nodes': 3, 'min_samples_split': 3, 'n_estimators': 75}, 'config_hash': {'algorithm': 'e8332f0a8902bda03bf70e7978cc5d52affb29d3', 'config': 'a064e2df18ab98d44dabcefbc7bed94913f1d0be', 'pipeline': '7eea819c2a8c103c4b1e9e9c1e224aebba95081f'}, 'duration': 0.8501448631286621, 'iteration': 3, 'loss': 0.053333333333333344, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 2, 'features__selectkbest__k': 4}), 'normalizer': ('normalizer_NoneType', {}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 7})}, 'score': 0.9466666666666667, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'entropy', 'max_depth': 3, 'max_features': 3, 'max_leaf_nodes': None, 'min_samples_split': 5, 'n_estimators': 75}, 'config_hash': {'algorithm': '7a4491035bc6bd737fe9a8cda8a79a02d02d5c74', 'config': '0ddb6f5cab3db4dddd7682966a57205f3e329ad4', 'pipeline': 'a9ae03fe38334f6868cbf84cdd3d629d4bbe3fb0'}, 'duration': 1.1026010513305664, 'iteration': 4, 'loss': 0.05999999999999994, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 2, 'features__selectkbest__k': 1}), 'normalizer': ('normalizer_NoneType', {}), 'rebalance': ('rebalance_NoneType', {})}, 'score': 0.9400000000000001, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'gini', 'max_depth': 3, 'max_features': 1, 'max_leaf_nodes': 5, 'min_samples_split': 2, 'n_estimators': 25}, 'config_hash': {'algorithm': '9826d20b2d6a0f559cf7f16450ce7526f07e8434', 'config': '49f25751bca61cdd461a8cbd2923689b642f98ed', 'pipeline': '19b249664c5bf067de1fed4334a296f947ce774a'}, 'duration': 0.35647010803222656, 'iteration': 5, 'loss': 0.046666666666666634, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_NoneType', {}), 'normalizer': ('normalizer_NoneType', {}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 6})}, 'score': 0.9533333333333334, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'gini', 'max_depth': 2, 'max_features': 1, 'max_leaf_nodes': 2, 'min_samples_split': 2, 'n_estimators': 50}, 'config_hash': {'algorithm': '0a4f6fbb07e0f32c6f675489a0fc82eee05bd8e1', 'config': '5c3a2b6f5e63fb45f10e41e0318b354912ec44f6', 'pipeline': 'dc3b9f176f090005e38b142f11d80e93a7dc5d5e'}, 'duration': 0.7213859558105469, 'iteration': 6, 'loss': 0.31333333333333324, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 1, 'features__selectkbest__k': 4}), 'normalizer': ('normalizer_PowerTransformer', {}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 7})}, 'score': 0.6866666666666668, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'entropy', 'max_depth': 4, 'max_features': 3, 'max_leaf_nodes': 5, 'min_samples_split': 5, 'n_estimators': 10}, 'config_hash': {'algorithm': 'b8112b97ecfc10f00a195af661dcc861cac21289', 'config': 'd3b129b397350f1b6572651c67c01de49b4b174c', 'pipeline': '5b0357ed7072c37b3d6f458bb5d49ff7d825f603'}, 'duration': 0.8299109935760498, 'iteration': 7, 'loss': 1.0, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_PCA', {'features__n_components': 2}), 'normalizer': ('normalizer_StandardScaler', {'normalizer__with_mean': True, 'normalizer__with_std': False}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 6})}, 'score': 0.0, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'gini', 'max_depth': 4, 'max_features': None, 'max_leaf_nodes': 2, 'min_samples_split': 5, 'n_estimators': 100}, 'config_hash': {'algorithm': '40ca24df19b8d164d9d098a6bed1ce056fbbb961', 'config': '813bde1108cc3c4b9bfb3a22cbb421bda7eac671', 'pipeline': '74a7b8705a1c22f7dea5e44e4ebda8f1e48add71'}, 'duration': 2.2111589908599854, 'iteration': 8, 'loss': 0.33333333333333326, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_PCA', {'features__n_components': 2}), 'normalizer': ('normalizer_StandardScaler', {'normalizer__with_mean': False, 'normalizer__with_std': True}), 'rebalance': ('rebalance_NearMiss', {'rebalance__n_neighbors': 2})}, 'score': 0.6666666666666667, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'entropy', 'max_depth': 2, 'max_features': 1, 'max_leaf_nodes': 5, 'min_samples_split': 2, 'n_estimators': 100}, 'config_hash': {'algorithm': '331418a5c12cf1453876eef85e9d98fc8e54fa11', 'config': '31930b6860ed406d59bf7e59ba1925d94704bd3b', 'pipeline': '054bef356f90ec6f644ef3ffc688766744db51c2'}, 'duration': 1.0501940250396729, 'iteration': 9, 'loss': 0.053333333333333344, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_SelectKBest', {'features__k': 1}), 'normalizer': ('normalizer_RobustScaler', {'normalizer__quantile_range': (...), 'normalizer__with_centering': True, 'normalizer__with_scaling': True}), 'rebalance': ('rebalance_NearMiss', {'rebalance__n_neighbors': 2})}, 'score': 0.9466666666666667, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'entropy', 'max_depth': 3, 'max_features': None, 'max_leaf_nodes': 3, 'min_samples_split': 2, 'n_estimators': 100}, 'config_hash': {'algorithm': 'dbc1b8126649fe93dce5fbb37e4015b0acfb179e', 'config': '9913cd550615a9d0946ab4a755a8b9f619e442fd', 'pipeline': 'dd626121cea079ebb32e184ca65483ec7a6d7f59'}, 'duration': 1.120617151260376, 'iteration': 10, 'loss': 0.046666666666666634, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 2, 'features__selectkbest__k': 1}), 'normalizer': ('normalizer_MinMaxScaler', {}), 'rebalance': ('rebalance_NoneType', {})}, 'score': 0.9533333333333334, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'gini', 'max_depth': 3, 'max_features': 3, 'max_leaf_nodes': None, 'min_samples_split': 3, 'n_estimators': 75}, 'config_hash': {'algorithm': '34917a130df5a975f78bd7ec1a0c7b1ffdc787a9', 'config': '95fc8cadc088141290b7de9c388977e4685f0108', 'pipeline': '550d10faf2f08db48516cc3501558816d6a99bc0'}, 'duration': 1.4287099838256836, 'iteration': 11, 'loss': 0.19333333333333313, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 3, 'features__selectkbest__k': 4}), 'normalizer': ('normalizer_StandardScaler', {'normalizer__with_mean': False, 'normalizer__with_std': False}), 'rebalance': ('rebalance_CondensedNearestNeighbour', {'rebalance__n_neighbors': 1})}, 'score': 0.8066666666666669, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'entropy', 'max_depth': 1, 'max_features': 2, 'max_leaf_nodes': 5, 'min_samples_split': 2, 'n_estimators': 75}, 'config_hash': {'algorithm': '33f9abb4aee44a395a9f3b3ffa9ce80a8cdaed7c', 'config': '40fa726f0360cf6af55f9b5902d399d02f61f157', 'pipeline': 'cfd1d20841fe2153da762c95e79f95a3fb1e426a'}, 'duration': 1.2978079319000244, 'iteration': 12, 'loss': 0.053333333333333344, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_PCA', {'features__n_components': 4}), 'normalizer': ('normalizer_MinMaxScaler', {}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 7})}, 'score': 0.9466666666666667, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'entropy', 'max_depth': 4, 'max_features': 2, 'max_leaf_nodes': 5, 'min_samples_split': 3, 'n_estimators': 25}, 'config_hash': {'algorithm': '210111ec6562d09eb093e98ed69ef1c662e11a50', 'config': '0fb8e77c7bd9a58b72f1b33c21a59a09a8c676ba', 'pipeline': '5d269d759e0c7926a685a14b263ace8ae0071e4b'}, 'duration': 0.36649012565612793, 'iteration': 13, 'loss': 0.040000000000000036, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 2, 'features__selectkbest__k': 2}), 'normalizer': ('normalizer_NoneType', {}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 7})}, 'score': 0.96, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'entropy', 'max_depth': 3, 'max_features': 1, 'max_leaf_nodes': 5, 'min_samples_split': 2, 'n_estimators': 25}, 'config_hash': {'algorithm': '0e989a03980101fabf79eda3326ed2870e11d690', 'config': 'f4bffd5d8c67a9c5321a9943c4a99678f59a02b7', 'pipeline': '865ee1e3fe8334c3d5ecb2038d5a5d1b3ba50e75'}, 'duration': 0.35639500617980957, 'iteration': 14, 'loss': 0.046666666666666634, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_NoneType', {}), 'normalizer': ('normalizer_RobustScaler', {'normalizer__quantile_range': (...), 'normalizer__with_centering': True, 'normalizer__with_scaling': False}), 'rebalance': ('rebalance_NoneType', {})}, 'score': 0.9533333333333334, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'entropy', 'max_depth': None, 'max_features': 3, 'max_leaf_nodes': 3, 'min_samples_split': 5, 'n_estimators': 10}, 'config_hash': {'algorithm': '9c592e876c13de5e23e6de5b868e01755d63e72e', 'config': '1e6a68cd1eeac886d90724d78b1cb5fb76a3cde4', 'pipeline': '5a1ca4d82f21b7de0d2c918630a42510673fa36e'}, 'duration': 0.18141412734985352, 'iteration': 15, 'loss': 0.046666666666666634, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_SelectKBest', {'features__k': 3}), 'normalizer': ('normalizer_RobustScaler', {'normalizer__quantile_range': (...), 'normalizer__with_centering': True, 'normalizer__with_scaling': True}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 6})}, 'score': 0.9533333333333334, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': 1, 'max_features': None, 'max_leaf_nodes': None, 'min_samples_split': 5, 'n_estimators': 10}, 'config_hash': {'algorithm': '8bed77aef289bfd453b2858bd288ae5ba7160f2b', 'config': '781185bcb8999045de8d489f253a1a1ba4247932', 'pipeline': '1ece7eabedc2be9e5b0a1be65c570d08ffa3eb54'}, 'duration': 0.1636829376220703, 'iteration': 16, 'loss': 0.053333333333333344, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_NoneType', {}), 'normalizer': ('normalizer_NoneType', {}), 'rebalance': ('rebalance_NearMiss', {'rebalance__n_neighbors': 1})}, 'score': 0.9466666666666667, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'gini', 'max_depth': 3, 'max_features': 2, 'max_leaf_nodes': 2, 'min_samples_split': 5, 'n_estimators': 75}, 'config_hash': {'algorithm': '617b97d9ba21d3373bc51ffa9cccf9c6f91a77b3', 'config': '99fb425b4e8c5d80228cab94202252aa25cdf77c', 'pipeline': 'd6242929c3b515c7719e60423023ac604311afc3'}, 'duration': 0.8468999862670898, 'iteration': 17, 'loss': 0.24, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_PCA', {'features__n_components': 4}), 'normalizer': ('normalizer_PowerTransformer', {}), 'rebalance': ('rebalance_NearMiss', {'rebalance__n_neighbors': 2})}, 'score': 0.76, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': 1, 'max_features': 1, 'max_leaf_nodes': 2, 'min_samples_split': 5, 'n_estimators': 50}, 'config_hash': {'algorithm': 'b92d2697cdd4979da443369d6596229ec091626a', 'config': 'c513a3e13281206ad76187dd817b1fff93d54fe1', 'pipeline': 'c4b4f914a3ca8df967cade997a90366d85a371b9'}, 'duration': 0.6724588871002197, 'iteration': 18, 'loss': 0.23333333333333328, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 1, 'features__selectkbest__k': 3}), 'normalizer': ('normalizer_StandardScaler', {'normalizer__with_mean': True, 'normalizer__with_std': True}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 5})}, 'score': 0.7666666666666667, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'entropy', 'max_depth': None, 'max_features': None, 'max_leaf_nodes': 5, 'min_samples_split': 5, 'n_estimators': 10}, 'config_hash': {'algorithm': 'a0115de695e6cca2e81cbfb54df79bf4b43608b1', 'config': 'ba194015e20b5d67770e8c67342c3d8d0d01dc41', 'pipeline': '8d45fabfeb85ffdcabf7076bd0e65fffe97ce928'}, 'duration': 0.19424200057983398, 'iteration': 19, 'loss': 0.08666666666666667, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_PCA', {'features__n_components': 3}), 'normalizer': ('normalizer_NoneType', {}), 'rebalance': ('rebalance_NoneType', {})}, 'score': 0.9133333333333333, ...}, ...], 'history_hash': ['db6ac7e6d348155757e4794bb5f88fe2b4f63d50', '4db6fb84d85f52659f780e682ffac5712c3d8a94', '4403c5a85e951938d3c454e961d3a412780722f6', 'a064e2df18ab98d44dabcefbc7bed94913f1d0be', '0ddb6f5cab3db4dddd7682966a57205f3e329ad4', '49f25751bca61cdd461a8cbd2923689b642f98ed', '5c3a2b6f5e63fb45f10e41e0318b354912ec44f6', 'd3b129b397350f1b6572651c67c01de49b4b174c', '813bde1108cc3c4b9bfb3a22cbb421bda7eac671', '31930b6860ed406d59bf7e59ba1925d94704bd3b', '9913cd550615a9d0946ab4a755a8b9f619e442fd', '95fc8cadc088141290b7de9c388977e4685f0108', '40fa726f0360cf6af55f9b5902d399d02f61f157', '0fb8e77c7bd9a58b72f1b33c21a59a09a8c676ba', 'f4bffd5d8c67a9c5321a9943c4a99678f59a02b7', '1e6a68cd1eeac886d90724d78b1cb5fb76a3cde4', '781185bcb8999045de8d489f253a1a1ba4247932', '99fb425b4e8c5d80228cab94202252aa25cdf77c', 'c513a3e13281206ad76187dd817b1fff93d54fe1', 'ba194015e20b5d67770e8c67342c3d8d0d01dc41', ...], 'history_index': {'00f0493590a2cb5e98a35b29816f8cd9f87f96ec': 208, '013329309d510b94f19d930320402d65f953a847': 39, '038a0f515e2ec894ee8e34f9caa2889eb3ebd5ce': 66, '052ae4bf232b316187b078abae42c2be19e16a00': 111, '05e9258ebf99dd97202167ef1563fa834b0568f1': 242, '0659afebf316aafeb75612fb07081a04c28545ed': 74, '06e7cde9f3556cd01332ce389ad1d8925cd4b4a4': 120, '07ab8a30d853e39a326b7017026a20e94bc45541': 245, '08606f2a0f0a6c9de204020b4632e09fcee0ae56': 168, '09dbd0948e5b8c1b1f0930778babe65c8a81295e': 243, ...}, 'iteration': 288, 'max_history_score': 0.9666666666666668, 'max_history_score_std': 0.033333333333333326, 'max_history_step': 'joint'}
        config = {'algorithm': 'RandomForest', 'seed': 42, 'time': 300}
    114 
    115 
    116 def get_baseline_score(algorithm, X, y, seed):
    117     pipeline, _ = pipeline_conf_to_full_pipeline(

...........................................................................
/home/aquemy/dev/dp_hyperparameters/extension/experiment/objective.py in objective(pipeline_config={'features': ('features_FeatureUnion', {'features__pca__n_components': 1, 'features__selectkbest__k': 1}), 'normalizer': ('normalizer_NoneType', {}), 'rebalance': ('rebalance_CondensedNearestNeighbour', {'rebalance__n_neighbors': 2})}, algo_config={'bootstrap': False, 'criterion': 'gini', 'max_depth': 1, 'max_features': 3, 'max_leaf_nodes': 5, 'min_samples_split': 3, 'n_estimators': 10}, algorithm='RandomForest', X=array([[5.1, 3.5, 1.4, 0.2],
       [4.9, 3. , 1....2, 3.4, 5.4, 2.3],
       [5.9, 3. , 5.1, 1.8]]), y=array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,... 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]), context={'baseline_score': 0.9466666666666667, 'baseline_score_std': 0.04988876515698587, 'best_config': {'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': 4, 'max_features': 3, 'max_leaf_nodes': 3, 'min_samples_split': 3, 'n_estimators': 10}, 'config_hash': {'algorithm': 'ffb7ff225ce3d3712c96cf87fe42202988ee2eb0', 'config': 'bae32f426be9cd6243523c023944a8c148fe4aeb', 'pipeline': 'd2a68bfda6fcdec4ae0ffc7d7b6a2122bc1cd673'}, 'duration': 0.7115809917449951, 'iteration': 113, 'loss': 0.033333333333333215, 'max_history_score': 0.9666666666666668, 'max_history_score_std': 0.033333333333333326, 'max_history_step': 'joint', 'pipeline': {'features': ('features_NoneType', {}), 'normalizer': ('normalizer_PowerTransformer', {}), 'rebalance': ('rebalance_CondensedNearestNeighbour', {'rebalance__n_neighbors': 2})}, 'score': 0.9666666666666668, ...}, 'history': [{'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': 2, 'max_features': None, 'max_leaf_nodes': 5, 'min_samples_split': 2, 'n_estimators': 75}, 'config_hash': {'algorithm': '3af5b0cce71c8fe2545246ca24ff5bc3dd516e06', 'config': 'db6ac7e6d348155757e4794bb5f88fe2b4f63d50', 'pipeline': '8d59f4b94cef6be9306ed86a22a9570fa670d567'}, 'duration': 1.149928092956543, 'iteration': 0, 'loss': 0.046666666666666634, 'max_history_score': 0.9533333333333334, 'max_history_score_std': 0.059999999999999984, 'max_history_step': 'joint', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 4, 'features__selectkbest__k': 3}), 'normalizer': ('normalizer_StandardScaler', {'normalizer__with_mean': True, 'normalizer__with_std': True}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 6})}, 'score': 0.9533333333333334, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': 1, 'max_features': 2, 'max_leaf_nodes': 2, 'min_samples_split': 5, 'n_estimators': 100}, 'config_hash': {'algorithm': 'e13eb05fd9a62d2f63bbb1c1deff0cd620d5e6ab', 'config': '4db6fb84d85f52659f780e682ffac5712c3d8a94', 'pipeline': '64c9a1ca9d53ae67244bdd942f4db36a3c05218c'}, 'duration': 1.7678282260894775, 'iteration': 1, 'loss': 0.18000000000000005, 'max_history_score': 0.9533333333333334, 'max_history_score_std': 0.059999999999999984, 'max_history_step': 'joint', 'pipeline': {'features': ('features_NoneType', {}), 'normalizer': ('normalizer_PowerTransformer', {}), 'rebalance': ('rebalance_NearMiss', {'rebalance__n_neighbors': 1})}, 'score': 0.82, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': 1, 'max_features': None, 'max_leaf_nodes': None, 'min_samples_split': 5, 'n_estimators': 75}, 'config_hash': {'algorithm': '94b0d7a654c508cc63643f78fe4f0f07e6f07c1e', 'config': '4403c5a85e951938d3c454e961d3a412780722f6', 'pipeline': '3e47444880d8367fbac2faaba2e52a917274aa58'}, 'duration': 0.8397619724273682, 'iteration': 2, 'loss': 0.03333333333333344, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_PCA', {'features__n_components': 3}), 'normalizer': ('normalizer_MinMaxScaler', {}), 'rebalance': ('rebalance_NoneType', {})}, 'score': 0.9666666666666666, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': None, 'max_features': None, 'max_leaf_nodes': 3, 'min_samples_split': 3, 'n_estimators': 75}, 'config_hash': {'algorithm': 'e8332f0a8902bda03bf70e7978cc5d52affb29d3', 'config': 'a064e2df18ab98d44dabcefbc7bed94913f1d0be', 'pipeline': '7eea819c2a8c103c4b1e9e9c1e224aebba95081f'}, 'duration': 0.8501448631286621, 'iteration': 3, 'loss': 0.053333333333333344, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 2, 'features__selectkbest__k': 4}), 'normalizer': ('normalizer_NoneType', {}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 7})}, 'score': 0.9466666666666667, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'entropy', 'max_depth': 3, 'max_features': 3, 'max_leaf_nodes': None, 'min_samples_split': 5, 'n_estimators': 75}, 'config_hash': {'algorithm': '7a4491035bc6bd737fe9a8cda8a79a02d02d5c74', 'config': '0ddb6f5cab3db4dddd7682966a57205f3e329ad4', 'pipeline': 'a9ae03fe38334f6868cbf84cdd3d629d4bbe3fb0'}, 'duration': 1.1026010513305664, 'iteration': 4, 'loss': 0.05999999999999994, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 2, 'features__selectkbest__k': 1}), 'normalizer': ('normalizer_NoneType', {}), 'rebalance': ('rebalance_NoneType', {})}, 'score': 0.9400000000000001, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'gini', 'max_depth': 3, 'max_features': 1, 'max_leaf_nodes': 5, 'min_samples_split': 2, 'n_estimators': 25}, 'config_hash': {'algorithm': '9826d20b2d6a0f559cf7f16450ce7526f07e8434', 'config': '49f25751bca61cdd461a8cbd2923689b642f98ed', 'pipeline': '19b249664c5bf067de1fed4334a296f947ce774a'}, 'duration': 0.35647010803222656, 'iteration': 5, 'loss': 0.046666666666666634, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_NoneType', {}), 'normalizer': ('normalizer_NoneType', {}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 6})}, 'score': 0.9533333333333334, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'gini', 'max_depth': 2, 'max_features': 1, 'max_leaf_nodes': 2, 'min_samples_split': 2, 'n_estimators': 50}, 'config_hash': {'algorithm': '0a4f6fbb07e0f32c6f675489a0fc82eee05bd8e1', 'config': '5c3a2b6f5e63fb45f10e41e0318b354912ec44f6', 'pipeline': 'dc3b9f176f090005e38b142f11d80e93a7dc5d5e'}, 'duration': 0.7213859558105469, 'iteration': 6, 'loss': 0.31333333333333324, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 1, 'features__selectkbest__k': 4}), 'normalizer': ('normalizer_PowerTransformer', {}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 7})}, 'score': 0.6866666666666668, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'entropy', 'max_depth': 4, 'max_features': 3, 'max_leaf_nodes': 5, 'min_samples_split': 5, 'n_estimators': 10}, 'config_hash': {'algorithm': 'b8112b97ecfc10f00a195af661dcc861cac21289', 'config': 'd3b129b397350f1b6572651c67c01de49b4b174c', 'pipeline': '5b0357ed7072c37b3d6f458bb5d49ff7d825f603'}, 'duration': 0.8299109935760498, 'iteration': 7, 'loss': 1.0, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_PCA', {'features__n_components': 2}), 'normalizer': ('normalizer_StandardScaler', {'normalizer__with_mean': True, 'normalizer__with_std': False}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 6})}, 'score': 0.0, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'gini', 'max_depth': 4, 'max_features': None, 'max_leaf_nodes': 2, 'min_samples_split': 5, 'n_estimators': 100}, 'config_hash': {'algorithm': '40ca24df19b8d164d9d098a6bed1ce056fbbb961', 'config': '813bde1108cc3c4b9bfb3a22cbb421bda7eac671', 'pipeline': '74a7b8705a1c22f7dea5e44e4ebda8f1e48add71'}, 'duration': 2.2111589908599854, 'iteration': 8, 'loss': 0.33333333333333326, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_PCA', {'features__n_components': 2}), 'normalizer': ('normalizer_StandardScaler', {'normalizer__with_mean': False, 'normalizer__with_std': True}), 'rebalance': ('rebalance_NearMiss', {'rebalance__n_neighbors': 2})}, 'score': 0.6666666666666667, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'entropy', 'max_depth': 2, 'max_features': 1, 'max_leaf_nodes': 5, 'min_samples_split': 2, 'n_estimators': 100}, 'config_hash': {'algorithm': '331418a5c12cf1453876eef85e9d98fc8e54fa11', 'config': '31930b6860ed406d59bf7e59ba1925d94704bd3b', 'pipeline': '054bef356f90ec6f644ef3ffc688766744db51c2'}, 'duration': 1.0501940250396729, 'iteration': 9, 'loss': 0.053333333333333344, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_SelectKBest', {'features__k': 1}), 'normalizer': ('normalizer_RobustScaler', {'normalizer__quantile_range': (...), 'normalizer__with_centering': True, 'normalizer__with_scaling': True}), 'rebalance': ('rebalance_NearMiss', {'rebalance__n_neighbors': 2})}, 'score': 0.9466666666666667, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'entropy', 'max_depth': 3, 'max_features': None, 'max_leaf_nodes': 3, 'min_samples_split': 2, 'n_estimators': 100}, 'config_hash': {'algorithm': 'dbc1b8126649fe93dce5fbb37e4015b0acfb179e', 'config': '9913cd550615a9d0946ab4a755a8b9f619e442fd', 'pipeline': 'dd626121cea079ebb32e184ca65483ec7a6d7f59'}, 'duration': 1.120617151260376, 'iteration': 10, 'loss': 0.046666666666666634, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 2, 'features__selectkbest__k': 1}), 'normalizer': ('normalizer_MinMaxScaler', {}), 'rebalance': ('rebalance_NoneType', {})}, 'score': 0.9533333333333334, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'gini', 'max_depth': 3, 'max_features': 3, 'max_leaf_nodes': None, 'min_samples_split': 3, 'n_estimators': 75}, 'config_hash': {'algorithm': '34917a130df5a975f78bd7ec1a0c7b1ffdc787a9', 'config': '95fc8cadc088141290b7de9c388977e4685f0108', 'pipeline': '550d10faf2f08db48516cc3501558816d6a99bc0'}, 'duration': 1.4287099838256836, 'iteration': 11, 'loss': 0.19333333333333313, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 3, 'features__selectkbest__k': 4}), 'normalizer': ('normalizer_StandardScaler', {'normalizer__with_mean': False, 'normalizer__with_std': False}), 'rebalance': ('rebalance_CondensedNearestNeighbour', {'rebalance__n_neighbors': 1})}, 'score': 0.8066666666666669, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'entropy', 'max_depth': 1, 'max_features': 2, 'max_leaf_nodes': 5, 'min_samples_split': 2, 'n_estimators': 75}, 'config_hash': {'algorithm': '33f9abb4aee44a395a9f3b3ffa9ce80a8cdaed7c', 'config': '40fa726f0360cf6af55f9b5902d399d02f61f157', 'pipeline': 'cfd1d20841fe2153da762c95e79f95a3fb1e426a'}, 'duration': 1.2978079319000244, 'iteration': 12, 'loss': 0.053333333333333344, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_PCA', {'features__n_components': 4}), 'normalizer': ('normalizer_MinMaxScaler', {}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 7})}, 'score': 0.9466666666666667, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'entropy', 'max_depth': 4, 'max_features': 2, 'max_leaf_nodes': 5, 'min_samples_split': 3, 'n_estimators': 25}, 'config_hash': {'algorithm': '210111ec6562d09eb093e98ed69ef1c662e11a50', 'config': '0fb8e77c7bd9a58b72f1b33c21a59a09a8c676ba', 'pipeline': '5d269d759e0c7926a685a14b263ace8ae0071e4b'}, 'duration': 0.36649012565612793, 'iteration': 13, 'loss': 0.040000000000000036, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 2, 'features__selectkbest__k': 2}), 'normalizer': ('normalizer_NoneType', {}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 7})}, 'score': 0.96, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'entropy', 'max_depth': 3, 'max_features': 1, 'max_leaf_nodes': 5, 'min_samples_split': 2, 'n_estimators': 25}, 'config_hash': {'algorithm': '0e989a03980101fabf79eda3326ed2870e11d690', 'config': 'f4bffd5d8c67a9c5321a9943c4a99678f59a02b7', 'pipeline': '865ee1e3fe8334c3d5ecb2038d5a5d1b3ba50e75'}, 'duration': 0.35639500617980957, 'iteration': 14, 'loss': 0.046666666666666634, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_NoneType', {}), 'normalizer': ('normalizer_RobustScaler', {'normalizer__quantile_range': (...), 'normalizer__with_centering': True, 'normalizer__with_scaling': False}), 'rebalance': ('rebalance_NoneType', {})}, 'score': 0.9533333333333334, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'entropy', 'max_depth': None, 'max_features': 3, 'max_leaf_nodes': 3, 'min_samples_split': 5, 'n_estimators': 10}, 'config_hash': {'algorithm': '9c592e876c13de5e23e6de5b868e01755d63e72e', 'config': '1e6a68cd1eeac886d90724d78b1cb5fb76a3cde4', 'pipeline': '5a1ca4d82f21b7de0d2c918630a42510673fa36e'}, 'duration': 0.18141412734985352, 'iteration': 15, 'loss': 0.046666666666666634, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_SelectKBest', {'features__k': 3}), 'normalizer': ('normalizer_RobustScaler', {'normalizer__quantile_range': (...), 'normalizer__with_centering': True, 'normalizer__with_scaling': True}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 6})}, 'score': 0.9533333333333334, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': 1, 'max_features': None, 'max_leaf_nodes': None, 'min_samples_split': 5, 'n_estimators': 10}, 'config_hash': {'algorithm': '8bed77aef289bfd453b2858bd288ae5ba7160f2b', 'config': '781185bcb8999045de8d489f253a1a1ba4247932', 'pipeline': '1ece7eabedc2be9e5b0a1be65c570d08ffa3eb54'}, 'duration': 0.1636829376220703, 'iteration': 16, 'loss': 0.053333333333333344, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_NoneType', {}), 'normalizer': ('normalizer_NoneType', {}), 'rebalance': ('rebalance_NearMiss', {'rebalance__n_neighbors': 1})}, 'score': 0.9466666666666667, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'gini', 'max_depth': 3, 'max_features': 2, 'max_leaf_nodes': 2, 'min_samples_split': 5, 'n_estimators': 75}, 'config_hash': {'algorithm': '617b97d9ba21d3373bc51ffa9cccf9c6f91a77b3', 'config': '99fb425b4e8c5d80228cab94202252aa25cdf77c', 'pipeline': 'd6242929c3b515c7719e60423023ac604311afc3'}, 'duration': 0.8468999862670898, 'iteration': 17, 'loss': 0.24, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_PCA', {'features__n_components': 4}), 'normalizer': ('normalizer_PowerTransformer', {}), 'rebalance': ('rebalance_NearMiss', {'rebalance__n_neighbors': 2})}, 'score': 0.76, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': 1, 'max_features': 1, 'max_leaf_nodes': 2, 'min_samples_split': 5, 'n_estimators': 50}, 'config_hash': {'algorithm': 'b92d2697cdd4979da443369d6596229ec091626a', 'config': 'c513a3e13281206ad76187dd817b1fff93d54fe1', 'pipeline': 'c4b4f914a3ca8df967cade997a90366d85a371b9'}, 'duration': 0.6724588871002197, 'iteration': 18, 'loss': 0.23333333333333328, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 1, 'features__selectkbest__k': 3}), 'normalizer': ('normalizer_StandardScaler', {'normalizer__with_mean': True, 'normalizer__with_std': True}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 5})}, 'score': 0.7666666666666667, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'entropy', 'max_depth': None, 'max_features': None, 'max_leaf_nodes': 5, 'min_samples_split': 5, 'n_estimators': 10}, 'config_hash': {'algorithm': 'a0115de695e6cca2e81cbfb54df79bf4b43608b1', 'config': 'ba194015e20b5d67770e8c67342c3d8d0d01dc41', 'pipeline': '8d45fabfeb85ffdcabf7076bd0e65fffe97ce928'}, 'duration': 0.19424200057983398, 'iteration': 19, 'loss': 0.08666666666666667, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_PCA', {'features__n_components': 3}), 'normalizer': ('normalizer_NoneType', {}), 'rebalance': ('rebalance_NoneType', {})}, 'score': 0.9133333333333333, ...}, ...], 'history_hash': ['db6ac7e6d348155757e4794bb5f88fe2b4f63d50', '4db6fb84d85f52659f780e682ffac5712c3d8a94', '4403c5a85e951938d3c454e961d3a412780722f6', 'a064e2df18ab98d44dabcefbc7bed94913f1d0be', '0ddb6f5cab3db4dddd7682966a57205f3e329ad4', '49f25751bca61cdd461a8cbd2923689b642f98ed', '5c3a2b6f5e63fb45f10e41e0318b354912ec44f6', 'd3b129b397350f1b6572651c67c01de49b4b174c', '813bde1108cc3c4b9bfb3a22cbb421bda7eac671', '31930b6860ed406d59bf7e59ba1925d94704bd3b', '9913cd550615a9d0946ab4a755a8b9f619e442fd', '95fc8cadc088141290b7de9c388977e4685f0108', '40fa726f0360cf6af55f9b5902d399d02f61f157', '0fb8e77c7bd9a58b72f1b33c21a59a09a8c676ba', 'f4bffd5d8c67a9c5321a9943c4a99678f59a02b7', '1e6a68cd1eeac886d90724d78b1cb5fb76a3cde4', '781185bcb8999045de8d489f253a1a1ba4247932', '99fb425b4e8c5d80228cab94202252aa25cdf77c', 'c513a3e13281206ad76187dd817b1fff93d54fe1', 'ba194015e20b5d67770e8c67342c3d8d0d01dc41', ...], 'history_index': {'00f0493590a2cb5e98a35b29816f8cd9f87f96ec': 208, '013329309d510b94f19d930320402d65f953a847': 39, '038a0f515e2ec894ee8e34f9caa2889eb3ebd5ce': 66, '052ae4bf232b316187b078abae42c2be19e16a00': 111, '05e9258ebf99dd97202167ef1563fa834b0568f1': 242, '0659afebf316aafeb75612fb07081a04c28545ed': 74, '06e7cde9f3556cd01332ce389ad1d8925cd4b4a4': 120, '07ab8a30d853e39a326b7017026a20e94bc45541': 245, '08606f2a0f0a6c9de204020b4632e09fcee0ae56': 168, '09dbd0948e5b8c1b1f0930778babe65c8a81295e': 243, ...}, 'iteration': 288, 'max_history_score': 0.9666666666666668, 'max_history_score_std': 0.033333333333333326, 'max_history_step': 'joint'}, config={'algorithm': 'RandomForest', 'seed': 42, 'time': 300}, step='joint')
     45                 y,
     46                 cv=10,
     47                 n_jobs=-1,
     48                 return_estimator=False,
     49                 return_train_score=False,
---> 50                 verbose=0)
     51         score = np.mean(scores['test_score'])
     52         std = np.std(scores['test_score'])
     53         status = STATUS_OK
     54     except Exception as e:

...........................................................................
/home/aquemy/.local/lib/python2.7/site-packages/sklearn/model_selection/_validation.py in cross_validate(estimator=Pipeline(memory=None,
     steps=[('rebalance', ... random_state=42, verbose=0, warm_start=False))]), X=array([[5.1, 3.5, 1.4, 0.2],
       [4.9, 3. , 1....2, 3.4, 5.4, 2.3],
       [5.9, 3. , 5.1, 1.8]]), y=array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,... 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]), groups=None, scoring=None, cv=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1, verbose=0, fit_params=None, pre_dispatch='2*n_jobs', return_train_score=False, return_estimator=False, error_score='raise-deprecating')
    235         delayed(_fit_and_score)(
    236             clone(estimator), X, y, scorers, train, test, verbose, None,
    237             fit_params, return_train_score=return_train_score,
    238             return_times=True, return_estimator=return_estimator,
    239             error_score=error_score)
--> 240         for train, test in cv.split(X, y, groups))
        cv.split = <bound method StratifiedKFold.split of Stratifie...d(n_splits=10, random_state=None, shuffle=False)>
        X = array([[5.1, 3.5, 1.4, 0.2],
       [4.9, 3. , 1....2, 3.4, 5.4, 2.3],
       [5.9, 3. , 5.1, 1.8]])
        y = array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,... 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2])
        groups = None
    241 
    242     zipped_scores = list(zip(*scores))
    243     if return_train_score:
    244         train_scores = zipped_scores.pop(0)

...........................................................................
/home/aquemy/.local/lib/python2.7/site-packages/sklearn/externals/joblib/parallel.py in __call__(self=Parallel(n_jobs=-1), iterable=<generator object <genexpr>>)
    925                 # No need to wait for async callbacks to trigger to
    926                 # consumption.
    927                 self._iterating = False
    928 
    929             with self._backend.retrieval_context():
--> 930                 self.retrieve()
        self.retrieve = <bound method Parallel.retrieve of Parallel(n_jobs=-1)>
    931             # Make sure that we get a last message telling us we are done
    932             elapsed_time = time.time() - self._start_time
    933             self._print('Done %3i out of %3i | elapsed: %s finished',
    934                         (len(self._output), len(self._output),

---------------------------------------------------------------------------
Joblib worker traceback:
---------------------------------------------------------------------------
ValueError                                         Mon Jun 17 13:14:27 2019
PID: 21756                                  Python 2.7.15+: /usr/bin/python
...........................................................................
/home/aquemy/.local/lib/python2.7/site-packages/sklearn/externals/joblib/parallel.py in __call__(self=<sklearn.externals.joblib.parallel.BatchedCalls object>)
    220     def __call__(self):
    221         # Set the default nested backend to self._backend but do not set the
    222         # change the default number of processes to -1
    223         with parallel_backend(self._backend, n_jobs=self._n_jobs):
    224             return [func(*args, **kwargs)
--> 225                     for func, args, kwargs in self.items]
        func = <function _fit_and_score>
        args = (Pipeline(memory=None,
     steps=[('rebalance', ... random_state=42, verbose=0, warm_start=False))]), array([[5.1, 3.5, 1.4, 0.2],
       [4.9, 3. , 1....2, 3.4, 5.4, 2.3],
       [5.9, 3. , 5.1, 1.8]]), array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,... 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]), {'score': <function _passthrough_scorer>}, array([  5,   6,   7,   8,   9,  10,  11,  12,  ..., 142, 143, 144,
       145, 146, 147, 148, 149]), array([  0,   1,   2,   3,   4,  50,  51,  52,  53,  54, 100, 101, 102,
       103, 104]), 0, None, None)
        kwargs = {'error_score': 'raise-deprecating', 'return_estimator': False, 'return_times': True, 'return_train_score': False}
        self.items = [(<function _fit_and_score>, (Pipeline(memory=None,
     steps=[('rebalance', ... random_state=42, verbose=0, warm_start=False))]), array([[5.1, 3.5, 1.4, 0.2],
       [4.9, 3. , 1....2, 3.4, 5.4, 2.3],
       [5.9, 3. , 5.1, 1.8]]), array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,... 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]), {'score': <function _passthrough_scorer>}, array([  5,   6,   7,   8,   9,  10,  11,  12,  ..., 142, 143, 144,
       145, 146, 147, 148, 149]), array([  0,   1,   2,   3,   4,  50,  51,  52,  53,  54, 100, 101, 102,
       103, 104]), 0, None, None), {'error_score': 'raise-deprecating', 'return_estimator': False, 'return_times': True, 'return_train_score': False})]
    226 
    227     def __len__(self):
    228         return self._size
    229 

...........................................................................
/home/aquemy/.local/lib/python2.7/site-packages/sklearn/model_selection/_validation.py in _fit_and_score(estimator=Pipeline(memory=None,
     steps=[('rebalance', ... random_state=42, verbose=0, warm_start=False))]), X=array([[5.1, 3.5, 1.4, 0.2],
       [4.9, 3. , 1....2, 3.4, 5.4, 2.3],
       [5.9, 3. , 5.1, 1.8]]), y=array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,... 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]), scorer={'score': <function _passthrough_scorer>}, train=array([  5,   6,   7,   8,   9,  10,  11,  12,  ..., 142, 143, 144,
       145, 146, 147, 148, 149]), test=array([  0,   1,   2,   3,   4,  50,  51,  52,  53,  54, 100, 101, 102,
       103, 104]), verbose=0, parameters=None, fit_params={}, return_train_score=False, return_parameters=False, return_n_test_samples=False, return_times=True, return_estimator=False, error_score='raise-deprecating')
    523 
    524     try:
    525         if y_train is None:
    526             estimator.fit(X_train, **fit_params)
    527         else:
--> 528             estimator.fit(X_train, y_train, **fit_params)
        estimator.fit = <bound method Pipeline.fit of Pipeline(memory=No...random_state=42, verbose=0, warm_start=False))])>
        X_train = array([[5.4, 3.9, 1.7, 0.4],
       [4.6, 3.4, 1....2, 3.4, 5.4, 2.3],
       [5.9, 3. , 5.1, 1.8]])
        y_train = array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,
       2, 2, 2])
        fit_params = {}
    529 
    530     except Exception as e:
    531         # Note fit time as time until error
    532         fit_time = time.time() - start_time

...........................................................................
/usr/local/lib/python2.7/dist-packages/imblearn/pipeline.py in fit(self=Pipeline(memory=None,
     steps=[('rebalance', ... random_state=42, verbose=0, warm_start=False))]), X=array([[5.4, 3.9, 1.7, 0.4],
       [4.6, 3.4, 1....2, 3.4, 5.4, 2.3],
       [5.9, 3. , 5.1, 1.8]]), y=array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,
       2, 2, 2]), **fit_params={})
    234             This estimator
    235 
    236         """
    237         Xt, yt, fit_params = self._fit(X, y, **fit_params)
    238         if self._final_estimator is not None:
--> 239             self._final_estimator.fit(Xt, yt, **fit_params)
        self._final_estimator.fit = <bound method RandomForestClassifier.fit of Rand...e, random_state=42, verbose=0, warm_start=False)>
        Xt = array([[ 0.4       , -0.12384609],
       [ 0.3 ... 5.56542188],
       [ 1.7       ,  2.75295096]])
        yt = array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...0, 0, 0, 0, 0, 0, 0,
       0, 1, 1, 1, 2, 2, 2])
        fit_params = {}
    240         return self
    241 
    242     def fit_transform(self, X, y=None, **fit_params):
    243         """Fit the model and transform with the final estimator

...........................................................................
/home/aquemy/.local/lib/python2.7/site-packages/sklearn/ensemble/forest.py in fit(self=RandomForestClassifier(bootstrap=False, class_we...se, random_state=42, verbose=0, warm_start=False), X=array([[ 0.4       , -0.12384608],
       [ 0.3 ...      [ 1.7       ,  2.752951  ]], dtype=float32), y=array([[0.],
       [0.],
       [0.],
       [0...    [1.],
       [2.],
       [2.],
       [2.]]), sample_weight=None)
    328             trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,
    329                              **_joblib_parallel_args(prefer='threads'))(
    330                 delayed(_parallel_build_trees)(
    331                     t, self, X, y, sample_weight, i, len(trees),
    332                     verbose=self.verbose, class_weight=self.class_weight)
--> 333                 for i, t in enumerate(trees))
        i = 9
    334 
    335             # Collect newly grown trees
    336             self.estimators_.extend(trees)
    337 

...........................................................................
/home/aquemy/.local/lib/python2.7/site-packages/sklearn/externals/joblib/parallel.py in __call__(self=Parallel(n_jobs=1), iterable=<generator object <genexpr>>)
    912             # self._original_iterator is None, then this means either
    913             # that pre_dispatch == "all", n_jobs == 1 or that the first batch
    914             # was very quick and its callback already dispatched all the
    915             # remaining jobs.
    916             self._iterating = False
--> 917             if self.dispatch_one_batch(iterator):
        self.dispatch_one_batch = <bound method Parallel.dispatch_one_batch of Parallel(n_jobs=1)>
        iterator = <generator object <genexpr>>
    918                 self._iterating = self._original_iterator is not None
    919 
    920             while self.dispatch_one_batch(iterator):
    921                 pass

...........................................................................
/home/aquemy/.local/lib/python2.7/site-packages/sklearn/externals/joblib/parallel.py in dispatch_one_batch(self=Parallel(n_jobs=1), iterator=<generator object <genexpr>>)
    754                                  self._pickle_cache)
    755             if len(tasks) == 0:
    756                 # No more tasks available in the iterator: tell caller to stop.
    757                 return False
    758             else:
--> 759                 self._dispatch(tasks)
        self._dispatch = <bound method Parallel._dispatch of Parallel(n_jobs=1)>
        tasks = <sklearn.externals.joblib.parallel.BatchedCalls object>
    760                 return True
    761 
    762     def _print(self, msg, msg_args):
    763         """Display the message on stout or stderr depending on verbosity"""

...........................................................................
/home/aquemy/.local/lib/python2.7/site-packages/sklearn/externals/joblib/parallel.py in _dispatch(self=Parallel(n_jobs=1), batch=<sklearn.externals.joblib.parallel.BatchedCalls object>)
    711 
    712         dispatch_timestamp = time.time()
    713         cb = BatchCompletionCallBack(dispatch_timestamp, len(batch), self)
    714         with self._lock:
    715             job_idx = len(self._jobs)
--> 716             job = self._backend.apply_async(batch, callback=cb)
        job = undefined
        self._backend.apply_async = <bound method SequentialBackend.apply_async of <...lib._parallel_backends.SequentialBackend object>>
        batch = <sklearn.externals.joblib.parallel.BatchedCalls object>
        cb = <sklearn.externals.joblib.parallel.BatchCompletionCallBack object>
    717             # A job can complete so quickly than its callback is
    718             # called before we get here, causing self._jobs to
    719             # grow. To ensure correct results ordering, .insert is
    720             # used (rather than .append) in the following line

...........................................................................
/home/aquemy/.local/lib/python2.7/site-packages/sklearn/externals/joblib/_parallel_backends.py in apply_async(self=<sklearn.externals.joblib._parallel_backends.SequentialBackend object>, func=<sklearn.externals.joblib.parallel.BatchedCalls object>, callback=<sklearn.externals.joblib.parallel.BatchCompletionCallBack object>)
    177             raise ValueError('n_jobs == 0 in Parallel has no meaning')
    178         return 1
    179 
    180     def apply_async(self, func, callback=None):
    181         """Schedule a func to be run"""
--> 182         result = ImmediateResult(func)
        result = undefined
        func = <sklearn.externals.joblib.parallel.BatchedCalls object>
    183         if callback:
    184             callback(result)
    185         return result
    186 

...........................................................................
/home/aquemy/.local/lib/python2.7/site-packages/sklearn/externals/joblib/_parallel_backends.py in __init__(self=<sklearn.externals.joblib._parallel_backends.ImmediateResult object>, batch=<sklearn.externals.joblib.parallel.BatchedCalls object>)
    544 
    545 class ImmediateResult(object):
    546     def __init__(self, batch):
    547         # Don't delay the application, to avoid keeping the input
    548         # arguments in memory
--> 549         self.results = batch()
        self.results = undefined
        batch = <sklearn.externals.joblib.parallel.BatchedCalls object>
    550 
    551     def get(self):
    552         return self.results
    553 

...........................................................................
/home/aquemy/.local/lib/python2.7/site-packages/sklearn/externals/joblib/parallel.py in __call__(self=<sklearn.externals.joblib.parallel.BatchedCalls object>)
    220     def __call__(self):
    221         # Set the default nested backend to self._backend but do not set the
    222         # change the default number of processes to -1
    223         with parallel_backend(self._backend, n_jobs=self._n_jobs):
    224             return [func(*args, **kwargs)
--> 225                     for func, args, kwargs in self.items]
        func = <function _parallel_build_trees>
        args = (DecisionTreeClassifier(class_weight=None, criter...=False, random_state=1608637542, splitter='best'), RandomForestClassifier(bootstrap=False, class_we...se, random_state=42, verbose=0, warm_start=False), array([[ 0.4       , -0.12384608],
       [ 0.3 ...      [ 1.7       ,  2.752951  ]], dtype=float32), array([[0.],
       [0.],
       [0.],
       [0...    [1.],
       [2.],
       [2.],
       [2.]]), None, 0, 10)
        kwargs = {'class_weight': None, 'verbose': 0}
        self.items = [(<function _parallel_build_trees>, (DecisionTreeClassifier(class_weight=None, criter...=False, random_state=1608637542, splitter='best'), RandomForestClassifier(bootstrap=False, class_we...se, random_state=42, verbose=0, warm_start=False), array([[ 0.4       , -0.12384608],
       [ 0.3 ...      [ 1.7       ,  2.752951  ]], dtype=float32), array([[0.],
       [0.],
       [0.],
       [0...    [1.],
       [2.],
       [2.],
       [2.]]), None, 0, 10), {'class_weight': None, 'verbose': 0})]
    226 
    227     def __len__(self):
    228         return self._size
    229 

...........................................................................
/home/aquemy/.local/lib/python2.7/site-packages/sklearn/ensemble/forest.py in _parallel_build_trees(tree=DecisionTreeClassifier(class_weight=None, criter...=False, random_state=1608637542, splitter='best'), forest=RandomForestClassifier(bootstrap=False, class_we...se, random_state=42, verbose=0, warm_start=False), X=array([[ 0.4       , -0.12384608],
       [ 0.3 ...      [ 1.7       ,  2.752951  ]], dtype=float32), y=array([[0.],
       [0.],
       [0.],
       [0...    [1.],
       [2.],
       [2.],
       [2.]]), sample_weight=None, tree_idx=0, n_trees=10, verbose=0, class_weight=None)
    116         elif class_weight == 'balanced_subsample':
    117             curr_sample_weight *= compute_sample_weight('balanced', y, indices)
    118 
    119         tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)
    120     else:
--> 121         tree.fit(X, y, sample_weight=sample_weight, check_input=False)
        tree.fit = <bound method DecisionTreeClassifier.fit of Deci...False, random_state=1608637542, splitter='best')>
        X = array([[ 0.4       , -0.12384608],
       [ 0.3 ...      [ 1.7       ,  2.752951  ]], dtype=float32)
        y = array([[0.],
       [0.],
       [0.],
       [0...    [1.],
       [2.],
       [2.],
       [2.]])
        sample_weight = None
    122 
    123     return tree
    124 
    125 

...........................................................................
/home/aquemy/.local/lib/python2.7/site-packages/sklearn/tree/tree.py in fit(self=DecisionTreeClassifier(class_weight=None, criter...=False, random_state=1608637542, splitter='best'), X=array([[ 0.4       , -0.12384608],
       [ 0.3 ...      [ 1.7       ,  2.752951  ]], dtype=float32), y=array([[0.],
       [0.],
       [0.],
       [0...    [1.],
       [2.],
       [2.],
       [2.]]), sample_weight=None, check_input=False, X_idx_sorted=None)
    796 
    797         super(DecisionTreeClassifier, self).fit(
    798             X, y,
    799             sample_weight=sample_weight,
    800             check_input=check_input,
--> 801             X_idx_sorted=X_idx_sorted)
        X_idx_sorted = None
    802         return self
    803 
    804     def predict_proba(self, X, check_input=True):
    805         """Predict class probabilities of the input samples X.

...........................................................................
/home/aquemy/.local/lib/python2.7/site-packages/sklearn/tree/tree.py in fit(self=DecisionTreeClassifier(class_weight=None, criter...=False, random_state=1608637542, splitter='best'), X=array([[ 0.4       , -0.12384608],
       [ 0.3 ...      [ 1.7       ,  2.752951  ]], dtype=float32), y=array([[0.],
       [0.],
       [0.],
       [0...    [1.],
       [2.],
       [2.],
       [2.]]), sample_weight=None, check_input=False, X_idx_sorted=None)
    237         if not 0 <= self.min_weight_fraction_leaf <= 0.5:
    238             raise ValueError("min_weight_fraction_leaf must in [0, 0.5]")
    239         if max_depth <= 0:
    240             raise ValueError("max_depth must be greater than zero. ")
    241         if not (0 < max_features <= self.n_features_):
--> 242             raise ValueError("max_features must be in (0, n_features]")
    243         if not isinstance(max_leaf_nodes, (numbers.Integral, np.integer)):
    244             raise ValueError("max_leaf_nodes must be integral number but was "
    245                              "%r" % max_leaf_nodes)
    246         if -1 < max_leaf_nodes < 2:

ValueError: max_features must be in (0, n_features]
___________________________________________________________________________
Best score: 0.966666666667 (0.0333333333333) [J] | Score: 0.0 (0.0) [J]
Best score: 0.966666666667 (0.0333333333333) [J] | Score: 0.966666666667 (0.04472135955) [J]
Best score: 0.966666666667 (0.0333333333333) [J] | Score: 0.926666666667 (0.0553774924195) [J]
Best score: 0.966666666667 (0.0333333333333) [J] | Score: 0.953333333333 (0.0426874949162) [J]
Best score: 0.966666666667 (0.0333333333333) [J] | Score: 0.946666666667 (0.0653197264742) [J]
Best score: 0.966666666667 (0.0333333333333) [J] | Score: 0.92 (0.0718021974285) [J]
Best score: 0.966666666667 (0.0333333333333) [J] | Score: 0.906666666667 (0.0742368581711) [J]
Best score: 0.966666666667 (0.0333333333333) [J] | Score: 0.953333333333 (0.0669991708075) [J]
JoblibValueError
___________________________________________________________________________
...........................................................................
/home/aquemy/dev/dp_hyperparameters/extension/main.py in <module>()
     27 
     28     serializer.serialize_results(scenario, policy)
     29 
     30 if __name__ == "__main__":
     31     args = cli.parse_args()
---> 32     main(args)

...........................................................................
/home/aquemy/dev/dp_hyperparameters/extension/main.py in main(args=Namespace(customize=[(['control', 'seed'], '42')...io='./scenarios/rf_iris_joint.yaml', verbosity=0))
     21         test_size=0.4, 
     22         random_state=scenario['control']['seed']
     23     )
     24 
     25     policy = policies.initiate(scenario['setup']['policy'], config)
---> 26     policy.run(X,y)
        policy.run = <bound method Joint.run of <experiment.policies.joint.Joint object>>
        X = array([[5.1, 3.5, 1.4, 0.2],
       [4.9, 3. , 1....2, 3.4, 5.4, 2.3],
       [5.9, 3. , 5.1, 1.8]])
        y = array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,... 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2])
     27 
     28     serializer.serialize_results(scenario, policy)
     29 
     30 if __name__ == "__main__":

...........................................................................
/home/aquemy/dev/dp_hyperparameters/extension/experiment/policies/joint.py in run(self=<experiment.policies.joint.Joint object>, X=array([[5.1, 3.5, 1.4, 0.2],
       [4.9, 3. , 1....2, 3.4, 5.4, 2.3],
       [5.9, 3. , 5.1, 1.8]]), y=array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,... 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]))
     32             algo=tpe.suggest, 
     33             max_evals=None,
     34             max_time=self.config['time'],     
     35             trials=trials,
     36             show_progressbar=False,
---> 37             verbose=0
     38         )
     39 
     40         best_config = self.context['best_config']
     41         super(Joint, self).display_step_results(best_config)

...........................................................................
/home/aquemy/dev/dp_hyperparameters/extension/hyperopt/fmin.py in fmin(fn=<functools.partial object>, space={'algorithm': {'bootstrap': <hyperopt.pyll.base.Apply object>, 'criterion': <hyperopt.pyll.base.Apply object>, 'max_depth': <hyperopt.pyll.base.Apply object>, 'max_features': <hyperopt.pyll.base.Apply object>, 'max_leaf_nodes': <hyperopt.pyll.base.Apply object>, 'min_samples_split': <hyperopt.pyll.base.Apply object>, 'n_estimators': <hyperopt.pyll.base.Apply object>}, 'pipeline': {'features': <hyperopt.pyll.base.Apply object>, 'normalizer': <hyperopt.pyll.base.Apply object>, 'rebalance': <hyperopt.pyll.base.Apply object>}}, algo=<function suggest>, max_evals=9223372036854775807, max_time=300, trials=<hyperopt.base.Trials object>, rstate=<mtrand.RandomState object>, allow_trials_fmin=True, pass_expr_memo_ctrl=None, catch_eval_exceptions=False, verbose=0, return_argmin=True, points_to_evaluate=None, max_queue_len=1, show_progressbar=False)
    406             pass_expr_memo_ctrl=pass_expr_memo_ctrl,
    407             verbose=verbose,
    408             catch_eval_exceptions=catch_eval_exceptions,
    409             return_argmin=return_argmin,
    410             show_progressbar=show_progressbar,
--> 411             max_time=max_time
        max_time = 300
    412         )
    413 
    414     if trials is None:
    415         if points_to_evaluate is None:

...........................................................................
/home/aquemy/dev/dp_hyperparameters/extension/hyperopt/base.py in fmin(self=<hyperopt.base.Trials object>, fn=<functools.partial object>, space={'algorithm': {'bootstrap': <hyperopt.pyll.base.Apply object>, 'criterion': <hyperopt.pyll.base.Apply object>, 'max_depth': <hyperopt.pyll.base.Apply object>, 'max_features': <hyperopt.pyll.base.Apply object>, 'max_leaf_nodes': <hyperopt.pyll.base.Apply object>, 'min_samples_split': <hyperopt.pyll.base.Apply object>, 'n_estimators': <hyperopt.pyll.base.Apply object>}, 'pipeline': {'features': <hyperopt.pyll.base.Apply object>, 'normalizer': <hyperopt.pyll.base.Apply object>, 'rebalance': <hyperopt.pyll.base.Apply object>}}, algo=<function suggest>, max_evals=9223372036854775807, max_time=300, rstate=<mtrand.RandomState object>, verbose=0, pass_expr_memo_ctrl=None, catch_eval_exceptions=False, return_argmin=True, show_progressbar=False)
    636             verbose=verbose,
    637             allow_trials_fmin=False,  # -- prevent recursion
    638             pass_expr_memo_ctrl=pass_expr_memo_ctrl,
    639             catch_eval_exceptions=catch_eval_exceptions,
    640             return_argmin=return_argmin,
--> 641             show_progressbar=show_progressbar)
        show_progressbar = False
    642 
    643 
    644 def trials_from_docs(docs, validate=True, **kwargs):
    645     """Construct a Trials base class instance from a list of trials documents

...........................................................................
/home/aquemy/dev/dp_hyperparameters/extension/hyperopt/fmin.py in fmin(fn=<functools.partial object>, space={'algorithm': {'bootstrap': <hyperopt.pyll.base.Apply object>, 'criterion': <hyperopt.pyll.base.Apply object>, 'max_depth': <hyperopt.pyll.base.Apply object>, 'max_features': <hyperopt.pyll.base.Apply object>, 'max_leaf_nodes': <hyperopt.pyll.base.Apply object>, 'min_samples_split': <hyperopt.pyll.base.Apply object>, 'n_estimators': <hyperopt.pyll.base.Apply object>}, 'pipeline': {'features': <hyperopt.pyll.base.Apply object>, 'normalizer': <hyperopt.pyll.base.Apply object>, 'rebalance': <hyperopt.pyll.base.Apply object>}}, algo=<function suggest>, max_evals=9223372036854775807, max_time=300, trials=<hyperopt.base.Trials object>, rstate=<mtrand.RandomState object>, allow_trials_fmin=False, pass_expr_memo_ctrl=None, catch_eval_exceptions=False, verbose=0, return_argmin=True, points_to_evaluate=None, max_queue_len=1, show_progressbar=False)
    426                     verbose=verbose,
    427                     max_queue_len=max_queue_len,
    428                     show_progressbar=show_progressbar,
    429                     max_time=max_time)
    430     rval.catch_eval_exceptions = catch_eval_exceptions
--> 431     rval.exhaust()
        rval.exhaust = <bound method FMinIter.exhaust of <hyperopt.fmin.FMinIter object>>
    432     if return_argmin:
    433         return trials.argmin
    434     elif len(trials) > 0:
    435         # Only if there are some succesfull trail runs, return the best point in the evaluation space

...........................................................................
/home/aquemy/dev/dp_hyperparameters/extension/hyperopt/fmin.py in exhaust(self=<hyperopt.fmin.FMinIter object>)
    273             raise StopIteration()
    274         return self.trials
    275 
    276     def exhaust(self):
    277         n_done = len(self.trials)
--> 278         self.run(self.max_evals - n_done, block_until_done=self.asynchronous)
        self.run = <bound method FMinIter.run of <hyperopt.fmin.FMinIter object>>
        self.max_evals = 9223372036854775807
        n_done = 0
        self.asynchronous = False
    279         self.trials.refresh()
    280         return self
    281 
    282 

...........................................................................
/home/aquemy/dev/dp_hyperparameters/extension/hyperopt/fmin.py in run(self=<hyperopt.fmin.FMinIter object>, N=9223372036854775807, block_until_done=False)
    232                     if self.asynchronous:
    233                         # -- wait for workers to fill in the trials
    234                         time.sleep(self.poll_interval_secs)
    235                     else:
    236                         # -- loop over trials and do the jobs directly
--> 237                         self.serial_evaluate()
        self.serial_evaluate = <bound method FMinIter.serial_evaluate of <hyperopt.fmin.FMinIter object>>
    238                     try:
    239                         res = [d['result']['loss'] for d in
    240                                          self.trials.trials if
    241                                          d['result']['status'] == 'ok']

...........................................................................
/home/aquemy/dev/dp_hyperparameters/extension/hyperopt/fmin.py in serial_evaluate(self=<hyperopt.fmin.FMinIter object>, N=-1)
    138                 trial['book_time'] = now
    139                 trial['refresh_time'] = now
    140                 spec = base.spec_from_misc(trial['misc'])
    141                 ctrl = base.Ctrl(self.trials, current_trial=trial)
    142                 try:
--> 143                     result = self.domain.evaluate(spec, ctrl)
        result = undefined
        self.domain.evaluate = <bound method Domain.evaluate of <hyperopt.base.Domain object>>
        spec = {'bootstrap': 0, 'criterion': 0, 'features': 2, 'features_SelectKBest_features__k': 0, 'max_depth': 1, 'max_features': 2, 'max_leaf_nodes': 1, 'min_samples_split': 2, 'n_estimators': 0, 'normalizer': 1, ...}
        ctrl = <hyperopt.base.Ctrl object>
    144                 except Exception as e:
    145                     logger.info('job exception: %s' % str(e))
    146                     trial['state'] = base.JOB_STATE_ERROR
    147                     trial['misc']['error'] = (str(type(e)), str(e))

...........................................................................
/home/aquemy/dev/dp_hyperparameters/extension/hyperopt/base.py in evaluate(self=<hyperopt.base.Domain object>, config={'bootstrap': 0, 'criterion': 0, 'features': 2, 'features_SelectKBest_features__k': 0, 'max_depth': 1, 'max_features': 2, 'max_leaf_nodes': 1, 'min_samples_split': 2, 'n_estimators': 0, 'normalizer': 1, ...}, ctrl=<hyperopt.base.Ctrl object>, attach_attachments=True)
    841             #    or the normal Python part (self.fn)
    842             pyll_rval = pyll.rec_eval(
    843                 self.expr,
    844                 memo=memo,
    845                 print_node_on_error=self.rec_eval_print_node_on_error)
--> 846             rval = self.fn(pyll_rval)
        rval = undefined
        self.fn = <functools.partial object>
        pyll_rval = {'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': 2, 'max_features': 3, 'max_leaf_nodes': 3, 'min_samples_split': 5, 'n_estimators': 10}, 'pipeline': {'features': ('features_SelectKBest', {'features__k': 1}), 'normalizer': ('normalizer_StandardScaler', {'normalizer__with_mean': False, 'normalizer__with_std': True}), 'rebalance': ('rebalance_NoneType', {})}}
    847 
    848         if isinstance(rval, (float, int, np.number)):
    849             dict_rval = {'loss': float(rval), 'status': STATUS_OK}
    850         else:

...........................................................................
/home/aquemy/dev/dp_hyperparameters/extension/experiment/objective.py in objective_joint(wconfig={'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': 2, 'max_features': 3, 'max_leaf_nodes': 3, 'min_samples_split': 5, 'n_estimators': 10}, 'pipeline': {'features': ('features_SelectKBest', {'features__k': 1}), 'normalizer': ('normalizer_StandardScaler', {'normalizer__with_mean': False, 'normalizer__with_std': True}), 'rebalance': ('rebalance_NoneType', {})}}, algorithm='RandomForest', X=array([[5.1, 3.5, 1.4, 0.2],
       [4.9, 3. , 1....2, 3.4, 5.4, 2.3],
       [5.9, 3. , 5.1, 1.8]]), y=array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,... 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]), context={'baseline_score': 0.9466666666666667, 'baseline_score_std': 0.04988876515698587, 'best_config': {'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': 4, 'max_features': 3, 'max_leaf_nodes': 3, 'min_samples_split': 3, 'n_estimators': 10}, 'config_hash': {'algorithm': 'ffb7ff225ce3d3712c96cf87fe42202988ee2eb0', 'config': 'bae32f426be9cd6243523c023944a8c148fe4aeb', 'pipeline': 'd2a68bfda6fcdec4ae0ffc7d7b6a2122bc1cd673'}, 'duration': 0.7115809917449951, 'iteration': 113, 'loss': 0.033333333333333215, 'max_history_score': 0.9666666666666668, 'max_history_score_std': 0.033333333333333326, 'max_history_step': 'joint', 'pipeline': {'features': ('features_NoneType', {}), 'normalizer': ('normalizer_PowerTransformer', {}), 'rebalance': ('rebalance_CondensedNearestNeighbour', {'rebalance__n_neighbors': 2})}, 'score': 0.9666666666666668, ...}, 'history': [{'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': 2, 'max_features': None, 'max_leaf_nodes': 5, 'min_samples_split': 2, 'n_estimators': 75}, 'config_hash': {'algorithm': '3af5b0cce71c8fe2545246ca24ff5bc3dd516e06', 'config': 'db6ac7e6d348155757e4794bb5f88fe2b4f63d50', 'pipeline': '8d59f4b94cef6be9306ed86a22a9570fa670d567'}, 'duration': 1.149928092956543, 'iteration': 0, 'loss': 0.046666666666666634, 'max_history_score': 0.9533333333333334, 'max_history_score_std': 0.059999999999999984, 'max_history_step': 'joint', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 4, 'features__selectkbest__k': 3}), 'normalizer': ('normalizer_StandardScaler', {'normalizer__with_mean': True, 'normalizer__with_std': True}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 6})}, 'score': 0.9533333333333334, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': 1, 'max_features': 2, 'max_leaf_nodes': 2, 'min_samples_split': 5, 'n_estimators': 100}, 'config_hash': {'algorithm': 'e13eb05fd9a62d2f63bbb1c1deff0cd620d5e6ab', 'config': '4db6fb84d85f52659f780e682ffac5712c3d8a94', 'pipeline': '64c9a1ca9d53ae67244bdd942f4db36a3c05218c'}, 'duration': 1.7678282260894775, 'iteration': 1, 'loss': 0.18000000000000005, 'max_history_score': 0.9533333333333334, 'max_history_score_std': 0.059999999999999984, 'max_history_step': 'joint', 'pipeline': {'features': ('features_NoneType', {}), 'normalizer': ('normalizer_PowerTransformer', {}), 'rebalance': ('rebalance_NearMiss', {'rebalance__n_neighbors': 1})}, 'score': 0.82, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': 1, 'max_features': None, 'max_leaf_nodes': None, 'min_samples_split': 5, 'n_estimators': 75}, 'config_hash': {'algorithm': '94b0d7a654c508cc63643f78fe4f0f07e6f07c1e', 'config': '4403c5a85e951938d3c454e961d3a412780722f6', 'pipeline': '3e47444880d8367fbac2faaba2e52a917274aa58'}, 'duration': 0.8397619724273682, 'iteration': 2, 'loss': 0.03333333333333344, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_PCA', {'features__n_components': 3}), 'normalizer': ('normalizer_MinMaxScaler', {}), 'rebalance': ('rebalance_NoneType', {})}, 'score': 0.9666666666666666, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': None, 'max_features': None, 'max_leaf_nodes': 3, 'min_samples_split': 3, 'n_estimators': 75}, 'config_hash': {'algorithm': 'e8332f0a8902bda03bf70e7978cc5d52affb29d3', 'config': 'a064e2df18ab98d44dabcefbc7bed94913f1d0be', 'pipeline': '7eea819c2a8c103c4b1e9e9c1e224aebba95081f'}, 'duration': 0.8501448631286621, 'iteration': 3, 'loss': 0.053333333333333344, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 2, 'features__selectkbest__k': 4}), 'normalizer': ('normalizer_NoneType', {}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 7})}, 'score': 0.9466666666666667, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'entropy', 'max_depth': 3, 'max_features': 3, 'max_leaf_nodes': None, 'min_samples_split': 5, 'n_estimators': 75}, 'config_hash': {'algorithm': '7a4491035bc6bd737fe9a8cda8a79a02d02d5c74', 'config': '0ddb6f5cab3db4dddd7682966a57205f3e329ad4', 'pipeline': 'a9ae03fe38334f6868cbf84cdd3d629d4bbe3fb0'}, 'duration': 1.1026010513305664, 'iteration': 4, 'loss': 0.05999999999999994, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 2, 'features__selectkbest__k': 1}), 'normalizer': ('normalizer_NoneType', {}), 'rebalance': ('rebalance_NoneType', {})}, 'score': 0.9400000000000001, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'gini', 'max_depth': 3, 'max_features': 1, 'max_leaf_nodes': 5, 'min_samples_split': 2, 'n_estimators': 25}, 'config_hash': {'algorithm': '9826d20b2d6a0f559cf7f16450ce7526f07e8434', 'config': '49f25751bca61cdd461a8cbd2923689b642f98ed', 'pipeline': '19b249664c5bf067de1fed4334a296f947ce774a'}, 'duration': 0.35647010803222656, 'iteration': 5, 'loss': 0.046666666666666634, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_NoneType', {}), 'normalizer': ('normalizer_NoneType', {}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 6})}, 'score': 0.9533333333333334, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'gini', 'max_depth': 2, 'max_features': 1, 'max_leaf_nodes': 2, 'min_samples_split': 2, 'n_estimators': 50}, 'config_hash': {'algorithm': '0a4f6fbb07e0f32c6f675489a0fc82eee05bd8e1', 'config': '5c3a2b6f5e63fb45f10e41e0318b354912ec44f6', 'pipeline': 'dc3b9f176f090005e38b142f11d80e93a7dc5d5e'}, 'duration': 0.7213859558105469, 'iteration': 6, 'loss': 0.31333333333333324, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 1, 'features__selectkbest__k': 4}), 'normalizer': ('normalizer_PowerTransformer', {}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 7})}, 'score': 0.6866666666666668, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'entropy', 'max_depth': 4, 'max_features': 3, 'max_leaf_nodes': 5, 'min_samples_split': 5, 'n_estimators': 10}, 'config_hash': {'algorithm': 'b8112b97ecfc10f00a195af661dcc861cac21289', 'config': 'd3b129b397350f1b6572651c67c01de49b4b174c', 'pipeline': '5b0357ed7072c37b3d6f458bb5d49ff7d825f603'}, 'duration': 0.8299109935760498, 'iteration': 7, 'loss': 1.0, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_PCA', {'features__n_components': 2}), 'normalizer': ('normalizer_StandardScaler', {'normalizer__with_mean': True, 'normalizer__with_std': False}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 6})}, 'score': 0.0, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'gini', 'max_depth': 4, 'max_features': None, 'max_leaf_nodes': 2, 'min_samples_split': 5, 'n_estimators': 100}, 'config_hash': {'algorithm': '40ca24df19b8d164d9d098a6bed1ce056fbbb961', 'config': '813bde1108cc3c4b9bfb3a22cbb421bda7eac671', 'pipeline': '74a7b8705a1c22f7dea5e44e4ebda8f1e48add71'}, 'duration': 2.2111589908599854, 'iteration': 8, 'loss': 0.33333333333333326, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_PCA', {'features__n_components': 2}), 'normalizer': ('normalizer_StandardScaler', {'normalizer__with_mean': False, 'normalizer__with_std': True}), 'rebalance': ('rebalance_NearMiss', {'rebalance__n_neighbors': 2})}, 'score': 0.6666666666666667, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'entropy', 'max_depth': 2, 'max_features': 1, 'max_leaf_nodes': 5, 'min_samples_split': 2, 'n_estimators': 100}, 'config_hash': {'algorithm': '331418a5c12cf1453876eef85e9d98fc8e54fa11', 'config': '31930b6860ed406d59bf7e59ba1925d94704bd3b', 'pipeline': '054bef356f90ec6f644ef3ffc688766744db51c2'}, 'duration': 1.0501940250396729, 'iteration': 9, 'loss': 0.053333333333333344, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_SelectKBest', {'features__k': 1}), 'normalizer': ('normalizer_RobustScaler', {'normalizer__quantile_range': (...), 'normalizer__with_centering': True, 'normalizer__with_scaling': True}), 'rebalance': ('rebalance_NearMiss', {'rebalance__n_neighbors': 2})}, 'score': 0.9466666666666667, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'entropy', 'max_depth': 3, 'max_features': None, 'max_leaf_nodes': 3, 'min_samples_split': 2, 'n_estimators': 100}, 'config_hash': {'algorithm': 'dbc1b8126649fe93dce5fbb37e4015b0acfb179e', 'config': '9913cd550615a9d0946ab4a755a8b9f619e442fd', 'pipeline': 'dd626121cea079ebb32e184ca65483ec7a6d7f59'}, 'duration': 1.120617151260376, 'iteration': 10, 'loss': 0.046666666666666634, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 2, 'features__selectkbest__k': 1}), 'normalizer': ('normalizer_MinMaxScaler', {}), 'rebalance': ('rebalance_NoneType', {})}, 'score': 0.9533333333333334, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'gini', 'max_depth': 3, 'max_features': 3, 'max_leaf_nodes': None, 'min_samples_split': 3, 'n_estimators': 75}, 'config_hash': {'algorithm': '34917a130df5a975f78bd7ec1a0c7b1ffdc787a9', 'config': '95fc8cadc088141290b7de9c388977e4685f0108', 'pipeline': '550d10faf2f08db48516cc3501558816d6a99bc0'}, 'duration': 1.4287099838256836, 'iteration': 11, 'loss': 0.19333333333333313, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 3, 'features__selectkbest__k': 4}), 'normalizer': ('normalizer_StandardScaler', {'normalizer__with_mean': False, 'normalizer__with_std': False}), 'rebalance': ('rebalance_CondensedNearestNeighbour', {'rebalance__n_neighbors': 1})}, 'score': 0.8066666666666669, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'entropy', 'max_depth': 1, 'max_features': 2, 'max_leaf_nodes': 5, 'min_samples_split': 2, 'n_estimators': 75}, 'config_hash': {'algorithm': '33f9abb4aee44a395a9f3b3ffa9ce80a8cdaed7c', 'config': '40fa726f0360cf6af55f9b5902d399d02f61f157', 'pipeline': 'cfd1d20841fe2153da762c95e79f95a3fb1e426a'}, 'duration': 1.2978079319000244, 'iteration': 12, 'loss': 0.053333333333333344, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_PCA', {'features__n_components': 4}), 'normalizer': ('normalizer_MinMaxScaler', {}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 7})}, 'score': 0.9466666666666667, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'entropy', 'max_depth': 4, 'max_features': 2, 'max_leaf_nodes': 5, 'min_samples_split': 3, 'n_estimators': 25}, 'config_hash': {'algorithm': '210111ec6562d09eb093e98ed69ef1c662e11a50', 'config': '0fb8e77c7bd9a58b72f1b33c21a59a09a8c676ba', 'pipeline': '5d269d759e0c7926a685a14b263ace8ae0071e4b'}, 'duration': 0.36649012565612793, 'iteration': 13, 'loss': 0.040000000000000036, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 2, 'features__selectkbest__k': 2}), 'normalizer': ('normalizer_NoneType', {}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 7})}, 'score': 0.96, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'entropy', 'max_depth': 3, 'max_features': 1, 'max_leaf_nodes': 5, 'min_samples_split': 2, 'n_estimators': 25}, 'config_hash': {'algorithm': '0e989a03980101fabf79eda3326ed2870e11d690', 'config': 'f4bffd5d8c67a9c5321a9943c4a99678f59a02b7', 'pipeline': '865ee1e3fe8334c3d5ecb2038d5a5d1b3ba50e75'}, 'duration': 0.35639500617980957, 'iteration': 14, 'loss': 0.046666666666666634, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_NoneType', {}), 'normalizer': ('normalizer_RobustScaler', {'normalizer__quantile_range': (...), 'normalizer__with_centering': True, 'normalizer__with_scaling': False}), 'rebalance': ('rebalance_NoneType', {})}, 'score': 0.9533333333333334, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'entropy', 'max_depth': None, 'max_features': 3, 'max_leaf_nodes': 3, 'min_samples_split': 5, 'n_estimators': 10}, 'config_hash': {'algorithm': '9c592e876c13de5e23e6de5b868e01755d63e72e', 'config': '1e6a68cd1eeac886d90724d78b1cb5fb76a3cde4', 'pipeline': '5a1ca4d82f21b7de0d2c918630a42510673fa36e'}, 'duration': 0.18141412734985352, 'iteration': 15, 'loss': 0.046666666666666634, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_SelectKBest', {'features__k': 3}), 'normalizer': ('normalizer_RobustScaler', {'normalizer__quantile_range': (...), 'normalizer__with_centering': True, 'normalizer__with_scaling': True}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 6})}, 'score': 0.9533333333333334, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': 1, 'max_features': None, 'max_leaf_nodes': None, 'min_samples_split': 5, 'n_estimators': 10}, 'config_hash': {'algorithm': '8bed77aef289bfd453b2858bd288ae5ba7160f2b', 'config': '781185bcb8999045de8d489f253a1a1ba4247932', 'pipeline': '1ece7eabedc2be9e5b0a1be65c570d08ffa3eb54'}, 'duration': 0.1636829376220703, 'iteration': 16, 'loss': 0.053333333333333344, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_NoneType', {}), 'normalizer': ('normalizer_NoneType', {}), 'rebalance': ('rebalance_NearMiss', {'rebalance__n_neighbors': 1})}, 'score': 0.9466666666666667, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'gini', 'max_depth': 3, 'max_features': 2, 'max_leaf_nodes': 2, 'min_samples_split': 5, 'n_estimators': 75}, 'config_hash': {'algorithm': '617b97d9ba21d3373bc51ffa9cccf9c6f91a77b3', 'config': '99fb425b4e8c5d80228cab94202252aa25cdf77c', 'pipeline': 'd6242929c3b515c7719e60423023ac604311afc3'}, 'duration': 0.8468999862670898, 'iteration': 17, 'loss': 0.24, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_PCA', {'features__n_components': 4}), 'normalizer': ('normalizer_PowerTransformer', {}), 'rebalance': ('rebalance_NearMiss', {'rebalance__n_neighbors': 2})}, 'score': 0.76, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': 1, 'max_features': 1, 'max_leaf_nodes': 2, 'min_samples_split': 5, 'n_estimators': 50}, 'config_hash': {'algorithm': 'b92d2697cdd4979da443369d6596229ec091626a', 'config': 'c513a3e13281206ad76187dd817b1fff93d54fe1', 'pipeline': 'c4b4f914a3ca8df967cade997a90366d85a371b9'}, 'duration': 0.6724588871002197, 'iteration': 18, 'loss': 0.23333333333333328, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 1, 'features__selectkbest__k': 3}), 'normalizer': ('normalizer_StandardScaler', {'normalizer__with_mean': True, 'normalizer__with_std': True}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 5})}, 'score': 0.7666666666666667, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'entropy', 'max_depth': None, 'max_features': None, 'max_leaf_nodes': 5, 'min_samples_split': 5, 'n_estimators': 10}, 'config_hash': {'algorithm': 'a0115de695e6cca2e81cbfb54df79bf4b43608b1', 'config': 'ba194015e20b5d67770e8c67342c3d8d0d01dc41', 'pipeline': '8d45fabfeb85ffdcabf7076bd0e65fffe97ce928'}, 'duration': 0.19424200057983398, 'iteration': 19, 'loss': 0.08666666666666667, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_PCA', {'features__n_components': 3}), 'normalizer': ('normalizer_NoneType', {}), 'rebalance': ('rebalance_NoneType', {})}, 'score': 0.9133333333333333, ...}, ...], 'history_hash': ['db6ac7e6d348155757e4794bb5f88fe2b4f63d50', '4db6fb84d85f52659f780e682ffac5712c3d8a94', '4403c5a85e951938d3c454e961d3a412780722f6', 'a064e2df18ab98d44dabcefbc7bed94913f1d0be', '0ddb6f5cab3db4dddd7682966a57205f3e329ad4', '49f25751bca61cdd461a8cbd2923689b642f98ed', '5c3a2b6f5e63fb45f10e41e0318b354912ec44f6', 'd3b129b397350f1b6572651c67c01de49b4b174c', '813bde1108cc3c4b9bfb3a22cbb421bda7eac671', '31930b6860ed406d59bf7e59ba1925d94704bd3b', '9913cd550615a9d0946ab4a755a8b9f619e442fd', '95fc8cadc088141290b7de9c388977e4685f0108', '40fa726f0360cf6af55f9b5902d399d02f61f157', '0fb8e77c7bd9a58b72f1b33c21a59a09a8c676ba', 'f4bffd5d8c67a9c5321a9943c4a99678f59a02b7', '1e6a68cd1eeac886d90724d78b1cb5fb76a3cde4', '781185bcb8999045de8d489f253a1a1ba4247932', '99fb425b4e8c5d80228cab94202252aa25cdf77c', 'c513a3e13281206ad76187dd817b1fff93d54fe1', 'ba194015e20b5d67770e8c67342c3d8d0d01dc41', ...], 'history_index': {'00f0493590a2cb5e98a35b29816f8cd9f87f96ec': 208, '013329309d510b94f19d930320402d65f953a847': 39, '038a0f515e2ec894ee8e34f9caa2889eb3ebd5ce': 66, '052ae4bf232b316187b078abae42c2be19e16a00': 111, '05e9258ebf99dd97202167ef1563fa834b0568f1': 242, '0659afebf316aafeb75612fb07081a04c28545ed': 74, '06e7cde9f3556cd01332ce389ad1d8925cd4b4a4': 120, '07ab8a30d853e39a326b7017026a20e94bc45541': 245, '08606f2a0f0a6c9de204020b4632e09fcee0ae56': 168, '09dbd0948e5b8c1b1f0930778babe65c8a81295e': 243, ...}, 'iteration': 296, 'max_history_score': 0.9666666666666668, 'max_history_score_std': 0.033333333333333326, 'max_history_step': 'joint'}, config={'algorithm': 'RandomForest', 'seed': 42, 'time': 300})
    108 
    109 def objective_algo(algo_config, current_pipeline_config, algorithm, X, y, context, config):
    110     return objective(current_pipeline_config, algo_config, algorithm, X, y, context, config, step='algorithm')
    111 
    112 def objective_joint(wconfig, algorithm, X, y, context, config):
--> 113     return objective(wconfig['pipeline'], wconfig['algorithm'], algorithm, X, y, context, config, step='joint')
        wconfig = {'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': 2, 'max_features': 3, 'max_leaf_nodes': 3, 'min_samples_split': 5, 'n_estimators': 10}, 'pipeline': {'features': ('features_SelectKBest', {'features__k': 1}), 'normalizer': ('normalizer_StandardScaler', {'normalizer__with_mean': False, 'normalizer__with_std': True}), 'rebalance': ('rebalance_NoneType', {})}}
        algorithm = 'RandomForest'
        X = array([[5.1, 3.5, 1.4, 0.2],
       [4.9, 3. , 1....2, 3.4, 5.4, 2.3],
       [5.9, 3. , 5.1, 1.8]])
        y = array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,... 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2])
        context = {'baseline_score': 0.9466666666666667, 'baseline_score_std': 0.04988876515698587, 'best_config': {'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': 4, 'max_features': 3, 'max_leaf_nodes': 3, 'min_samples_split': 3, 'n_estimators': 10}, 'config_hash': {'algorithm': 'ffb7ff225ce3d3712c96cf87fe42202988ee2eb0', 'config': 'bae32f426be9cd6243523c023944a8c148fe4aeb', 'pipeline': 'd2a68bfda6fcdec4ae0ffc7d7b6a2122bc1cd673'}, 'duration': 0.7115809917449951, 'iteration': 113, 'loss': 0.033333333333333215, 'max_history_score': 0.9666666666666668, 'max_history_score_std': 0.033333333333333326, 'max_history_step': 'joint', 'pipeline': {'features': ('features_NoneType', {}), 'normalizer': ('normalizer_PowerTransformer', {}), 'rebalance': ('rebalance_CondensedNearestNeighbour', {'rebalance__n_neighbors': 2})}, 'score': 0.9666666666666668, ...}, 'history': [{'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': 2, 'max_features': None, 'max_leaf_nodes': 5, 'min_samples_split': 2, 'n_estimators': 75}, 'config_hash': {'algorithm': '3af5b0cce71c8fe2545246ca24ff5bc3dd516e06', 'config': 'db6ac7e6d348155757e4794bb5f88fe2b4f63d50', 'pipeline': '8d59f4b94cef6be9306ed86a22a9570fa670d567'}, 'duration': 1.149928092956543, 'iteration': 0, 'loss': 0.046666666666666634, 'max_history_score': 0.9533333333333334, 'max_history_score_std': 0.059999999999999984, 'max_history_step': 'joint', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 4, 'features__selectkbest__k': 3}), 'normalizer': ('normalizer_StandardScaler', {'normalizer__with_mean': True, 'normalizer__with_std': True}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 6})}, 'score': 0.9533333333333334, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': 1, 'max_features': 2, 'max_leaf_nodes': 2, 'min_samples_split': 5, 'n_estimators': 100}, 'config_hash': {'algorithm': 'e13eb05fd9a62d2f63bbb1c1deff0cd620d5e6ab', 'config': '4db6fb84d85f52659f780e682ffac5712c3d8a94', 'pipeline': '64c9a1ca9d53ae67244bdd942f4db36a3c05218c'}, 'duration': 1.7678282260894775, 'iteration': 1, 'loss': 0.18000000000000005, 'max_history_score': 0.9533333333333334, 'max_history_score_std': 0.059999999999999984, 'max_history_step': 'joint', 'pipeline': {'features': ('features_NoneType', {}), 'normalizer': ('normalizer_PowerTransformer', {}), 'rebalance': ('rebalance_NearMiss', {'rebalance__n_neighbors': 1})}, 'score': 0.82, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': 1, 'max_features': None, 'max_leaf_nodes': None, 'min_samples_split': 5, 'n_estimators': 75}, 'config_hash': {'algorithm': '94b0d7a654c508cc63643f78fe4f0f07e6f07c1e', 'config': '4403c5a85e951938d3c454e961d3a412780722f6', 'pipeline': '3e47444880d8367fbac2faaba2e52a917274aa58'}, 'duration': 0.8397619724273682, 'iteration': 2, 'loss': 0.03333333333333344, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_PCA', {'features__n_components': 3}), 'normalizer': ('normalizer_MinMaxScaler', {}), 'rebalance': ('rebalance_NoneType', {})}, 'score': 0.9666666666666666, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': None, 'max_features': None, 'max_leaf_nodes': 3, 'min_samples_split': 3, 'n_estimators': 75}, 'config_hash': {'algorithm': 'e8332f0a8902bda03bf70e7978cc5d52affb29d3', 'config': 'a064e2df18ab98d44dabcefbc7bed94913f1d0be', 'pipeline': '7eea819c2a8c103c4b1e9e9c1e224aebba95081f'}, 'duration': 0.8501448631286621, 'iteration': 3, 'loss': 0.053333333333333344, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 2, 'features__selectkbest__k': 4}), 'normalizer': ('normalizer_NoneType', {}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 7})}, 'score': 0.9466666666666667, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'entropy', 'max_depth': 3, 'max_features': 3, 'max_leaf_nodes': None, 'min_samples_split': 5, 'n_estimators': 75}, 'config_hash': {'algorithm': '7a4491035bc6bd737fe9a8cda8a79a02d02d5c74', 'config': '0ddb6f5cab3db4dddd7682966a57205f3e329ad4', 'pipeline': 'a9ae03fe38334f6868cbf84cdd3d629d4bbe3fb0'}, 'duration': 1.1026010513305664, 'iteration': 4, 'loss': 0.05999999999999994, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 2, 'features__selectkbest__k': 1}), 'normalizer': ('normalizer_NoneType', {}), 'rebalance': ('rebalance_NoneType', {})}, 'score': 0.9400000000000001, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'gini', 'max_depth': 3, 'max_features': 1, 'max_leaf_nodes': 5, 'min_samples_split': 2, 'n_estimators': 25}, 'config_hash': {'algorithm': '9826d20b2d6a0f559cf7f16450ce7526f07e8434', 'config': '49f25751bca61cdd461a8cbd2923689b642f98ed', 'pipeline': '19b249664c5bf067de1fed4334a296f947ce774a'}, 'duration': 0.35647010803222656, 'iteration': 5, 'loss': 0.046666666666666634, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_NoneType', {}), 'normalizer': ('normalizer_NoneType', {}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 6})}, 'score': 0.9533333333333334, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'gini', 'max_depth': 2, 'max_features': 1, 'max_leaf_nodes': 2, 'min_samples_split': 2, 'n_estimators': 50}, 'config_hash': {'algorithm': '0a4f6fbb07e0f32c6f675489a0fc82eee05bd8e1', 'config': '5c3a2b6f5e63fb45f10e41e0318b354912ec44f6', 'pipeline': 'dc3b9f176f090005e38b142f11d80e93a7dc5d5e'}, 'duration': 0.7213859558105469, 'iteration': 6, 'loss': 0.31333333333333324, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 1, 'features__selectkbest__k': 4}), 'normalizer': ('normalizer_PowerTransformer', {}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 7})}, 'score': 0.6866666666666668, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'entropy', 'max_depth': 4, 'max_features': 3, 'max_leaf_nodes': 5, 'min_samples_split': 5, 'n_estimators': 10}, 'config_hash': {'algorithm': 'b8112b97ecfc10f00a195af661dcc861cac21289', 'config': 'd3b129b397350f1b6572651c67c01de49b4b174c', 'pipeline': '5b0357ed7072c37b3d6f458bb5d49ff7d825f603'}, 'duration': 0.8299109935760498, 'iteration': 7, 'loss': 1.0, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_PCA', {'features__n_components': 2}), 'normalizer': ('normalizer_StandardScaler', {'normalizer__with_mean': True, 'normalizer__with_std': False}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 6})}, 'score': 0.0, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'gini', 'max_depth': 4, 'max_features': None, 'max_leaf_nodes': 2, 'min_samples_split': 5, 'n_estimators': 100}, 'config_hash': {'algorithm': '40ca24df19b8d164d9d098a6bed1ce056fbbb961', 'config': '813bde1108cc3c4b9bfb3a22cbb421bda7eac671', 'pipeline': '74a7b8705a1c22f7dea5e44e4ebda8f1e48add71'}, 'duration': 2.2111589908599854, 'iteration': 8, 'loss': 0.33333333333333326, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_PCA', {'features__n_components': 2}), 'normalizer': ('normalizer_StandardScaler', {'normalizer__with_mean': False, 'normalizer__with_std': True}), 'rebalance': ('rebalance_NearMiss', {'rebalance__n_neighbors': 2})}, 'score': 0.6666666666666667, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'entropy', 'max_depth': 2, 'max_features': 1, 'max_leaf_nodes': 5, 'min_samples_split': 2, 'n_estimators': 100}, 'config_hash': {'algorithm': '331418a5c12cf1453876eef85e9d98fc8e54fa11', 'config': '31930b6860ed406d59bf7e59ba1925d94704bd3b', 'pipeline': '054bef356f90ec6f644ef3ffc688766744db51c2'}, 'duration': 1.0501940250396729, 'iteration': 9, 'loss': 0.053333333333333344, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_SelectKBest', {'features__k': 1}), 'normalizer': ('normalizer_RobustScaler', {'normalizer__quantile_range': (...), 'normalizer__with_centering': True, 'normalizer__with_scaling': True}), 'rebalance': ('rebalance_NearMiss', {'rebalance__n_neighbors': 2})}, 'score': 0.9466666666666667, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'entropy', 'max_depth': 3, 'max_features': None, 'max_leaf_nodes': 3, 'min_samples_split': 2, 'n_estimators': 100}, 'config_hash': {'algorithm': 'dbc1b8126649fe93dce5fbb37e4015b0acfb179e', 'config': '9913cd550615a9d0946ab4a755a8b9f619e442fd', 'pipeline': 'dd626121cea079ebb32e184ca65483ec7a6d7f59'}, 'duration': 1.120617151260376, 'iteration': 10, 'loss': 0.046666666666666634, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 2, 'features__selectkbest__k': 1}), 'normalizer': ('normalizer_MinMaxScaler', {}), 'rebalance': ('rebalance_NoneType', {})}, 'score': 0.9533333333333334, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'gini', 'max_depth': 3, 'max_features': 3, 'max_leaf_nodes': None, 'min_samples_split': 3, 'n_estimators': 75}, 'config_hash': {'algorithm': '34917a130df5a975f78bd7ec1a0c7b1ffdc787a9', 'config': '95fc8cadc088141290b7de9c388977e4685f0108', 'pipeline': '550d10faf2f08db48516cc3501558816d6a99bc0'}, 'duration': 1.4287099838256836, 'iteration': 11, 'loss': 0.19333333333333313, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 3, 'features__selectkbest__k': 4}), 'normalizer': ('normalizer_StandardScaler', {'normalizer__with_mean': False, 'normalizer__with_std': False}), 'rebalance': ('rebalance_CondensedNearestNeighbour', {'rebalance__n_neighbors': 1})}, 'score': 0.8066666666666669, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'entropy', 'max_depth': 1, 'max_features': 2, 'max_leaf_nodes': 5, 'min_samples_split': 2, 'n_estimators': 75}, 'config_hash': {'algorithm': '33f9abb4aee44a395a9f3b3ffa9ce80a8cdaed7c', 'config': '40fa726f0360cf6af55f9b5902d399d02f61f157', 'pipeline': 'cfd1d20841fe2153da762c95e79f95a3fb1e426a'}, 'duration': 1.2978079319000244, 'iteration': 12, 'loss': 0.053333333333333344, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_PCA', {'features__n_components': 4}), 'normalizer': ('normalizer_MinMaxScaler', {}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 7})}, 'score': 0.9466666666666667, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'entropy', 'max_depth': 4, 'max_features': 2, 'max_leaf_nodes': 5, 'min_samples_split': 3, 'n_estimators': 25}, 'config_hash': {'algorithm': '210111ec6562d09eb093e98ed69ef1c662e11a50', 'config': '0fb8e77c7bd9a58b72f1b33c21a59a09a8c676ba', 'pipeline': '5d269d759e0c7926a685a14b263ace8ae0071e4b'}, 'duration': 0.36649012565612793, 'iteration': 13, 'loss': 0.040000000000000036, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 2, 'features__selectkbest__k': 2}), 'normalizer': ('normalizer_NoneType', {}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 7})}, 'score': 0.96, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'entropy', 'max_depth': 3, 'max_features': 1, 'max_leaf_nodes': 5, 'min_samples_split': 2, 'n_estimators': 25}, 'config_hash': {'algorithm': '0e989a03980101fabf79eda3326ed2870e11d690', 'config': 'f4bffd5d8c67a9c5321a9943c4a99678f59a02b7', 'pipeline': '865ee1e3fe8334c3d5ecb2038d5a5d1b3ba50e75'}, 'duration': 0.35639500617980957, 'iteration': 14, 'loss': 0.046666666666666634, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_NoneType', {}), 'normalizer': ('normalizer_RobustScaler', {'normalizer__quantile_range': (...), 'normalizer__with_centering': True, 'normalizer__with_scaling': False}), 'rebalance': ('rebalance_NoneType', {})}, 'score': 0.9533333333333334, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'entropy', 'max_depth': None, 'max_features': 3, 'max_leaf_nodes': 3, 'min_samples_split': 5, 'n_estimators': 10}, 'config_hash': {'algorithm': '9c592e876c13de5e23e6de5b868e01755d63e72e', 'config': '1e6a68cd1eeac886d90724d78b1cb5fb76a3cde4', 'pipeline': '5a1ca4d82f21b7de0d2c918630a42510673fa36e'}, 'duration': 0.18141412734985352, 'iteration': 15, 'loss': 0.046666666666666634, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_SelectKBest', {'features__k': 3}), 'normalizer': ('normalizer_RobustScaler', {'normalizer__quantile_range': (...), 'normalizer__with_centering': True, 'normalizer__with_scaling': True}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 6})}, 'score': 0.9533333333333334, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': 1, 'max_features': None, 'max_leaf_nodes': None, 'min_samples_split': 5, 'n_estimators': 10}, 'config_hash': {'algorithm': '8bed77aef289bfd453b2858bd288ae5ba7160f2b', 'config': '781185bcb8999045de8d489f253a1a1ba4247932', 'pipeline': '1ece7eabedc2be9e5b0a1be65c570d08ffa3eb54'}, 'duration': 0.1636829376220703, 'iteration': 16, 'loss': 0.053333333333333344, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_NoneType', {}), 'normalizer': ('normalizer_NoneType', {}), 'rebalance': ('rebalance_NearMiss', {'rebalance__n_neighbors': 1})}, 'score': 0.9466666666666667, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'gini', 'max_depth': 3, 'max_features': 2, 'max_leaf_nodes': 2, 'min_samples_split': 5, 'n_estimators': 75}, 'config_hash': {'algorithm': '617b97d9ba21d3373bc51ffa9cccf9c6f91a77b3', 'config': '99fb425b4e8c5d80228cab94202252aa25cdf77c', 'pipeline': 'd6242929c3b515c7719e60423023ac604311afc3'}, 'duration': 0.8468999862670898, 'iteration': 17, 'loss': 0.24, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_PCA', {'features__n_components': 4}), 'normalizer': ('normalizer_PowerTransformer', {}), 'rebalance': ('rebalance_NearMiss', {'rebalance__n_neighbors': 2})}, 'score': 0.76, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': 1, 'max_features': 1, 'max_leaf_nodes': 2, 'min_samples_split': 5, 'n_estimators': 50}, 'config_hash': {'algorithm': 'b92d2697cdd4979da443369d6596229ec091626a', 'config': 'c513a3e13281206ad76187dd817b1fff93d54fe1', 'pipeline': 'c4b4f914a3ca8df967cade997a90366d85a371b9'}, 'duration': 0.6724588871002197, 'iteration': 18, 'loss': 0.23333333333333328, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 1, 'features__selectkbest__k': 3}), 'normalizer': ('normalizer_StandardScaler', {'normalizer__with_mean': True, 'normalizer__with_std': True}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 5})}, 'score': 0.7666666666666667, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'entropy', 'max_depth': None, 'max_features': None, 'max_leaf_nodes': 5, 'min_samples_split': 5, 'n_estimators': 10}, 'config_hash': {'algorithm': 'a0115de695e6cca2e81cbfb54df79bf4b43608b1', 'config': 'ba194015e20b5d67770e8c67342c3d8d0d01dc41', 'pipeline': '8d45fabfeb85ffdcabf7076bd0e65fffe97ce928'}, 'duration': 0.19424200057983398, 'iteration': 19, 'loss': 0.08666666666666667, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_PCA', {'features__n_components': 3}), 'normalizer': ('normalizer_NoneType', {}), 'rebalance': ('rebalance_NoneType', {})}, 'score': 0.9133333333333333, ...}, ...], 'history_hash': ['db6ac7e6d348155757e4794bb5f88fe2b4f63d50', '4db6fb84d85f52659f780e682ffac5712c3d8a94', '4403c5a85e951938d3c454e961d3a412780722f6', 'a064e2df18ab98d44dabcefbc7bed94913f1d0be', '0ddb6f5cab3db4dddd7682966a57205f3e329ad4', '49f25751bca61cdd461a8cbd2923689b642f98ed', '5c3a2b6f5e63fb45f10e41e0318b354912ec44f6', 'd3b129b397350f1b6572651c67c01de49b4b174c', '813bde1108cc3c4b9bfb3a22cbb421bda7eac671', '31930b6860ed406d59bf7e59ba1925d94704bd3b', '9913cd550615a9d0946ab4a755a8b9f619e442fd', '95fc8cadc088141290b7de9c388977e4685f0108', '40fa726f0360cf6af55f9b5902d399d02f61f157', '0fb8e77c7bd9a58b72f1b33c21a59a09a8c676ba', 'f4bffd5d8c67a9c5321a9943c4a99678f59a02b7', '1e6a68cd1eeac886d90724d78b1cb5fb76a3cde4', '781185bcb8999045de8d489f253a1a1ba4247932', '99fb425b4e8c5d80228cab94202252aa25cdf77c', 'c513a3e13281206ad76187dd817b1fff93d54fe1', 'ba194015e20b5d67770e8c67342c3d8d0d01dc41', ...], 'history_index': {'00f0493590a2cb5e98a35b29816f8cd9f87f96ec': 208, '013329309d510b94f19d930320402d65f953a847': 39, '038a0f515e2ec894ee8e34f9caa2889eb3ebd5ce': 66, '052ae4bf232b316187b078abae42c2be19e16a00': 111, '05e9258ebf99dd97202167ef1563fa834b0568f1': 242, '0659afebf316aafeb75612fb07081a04c28545ed': 74, '06e7cde9f3556cd01332ce389ad1d8925cd4b4a4': 120, '07ab8a30d853e39a326b7017026a20e94bc45541': 245, '08606f2a0f0a6c9de204020b4632e09fcee0ae56': 168, '09dbd0948e5b8c1b1f0930778babe65c8a81295e': 243, ...}, 'iteration': 296, 'max_history_score': 0.9666666666666668, 'max_history_score_std': 0.033333333333333326, 'max_history_step': 'joint'}
        config = {'algorithm': 'RandomForest', 'seed': 42, 'time': 300}
    114 
    115 
    116 def get_baseline_score(algorithm, X, y, seed):
    117     pipeline, _ = pipeline_conf_to_full_pipeline(

...........................................................................
/home/aquemy/dev/dp_hyperparameters/extension/experiment/objective.py in objective(pipeline_config={'features': ('features_SelectKBest', {'features__k': 1}), 'normalizer': ('normalizer_StandardScaler', {'normalizer__with_mean': False, 'normalizer__with_std': True}), 'rebalance': ('rebalance_NoneType', {})}, algo_config={'bootstrap': True, 'criterion': 'gini', 'max_depth': 2, 'max_features': 3, 'max_leaf_nodes': 3, 'min_samples_split': 5, 'n_estimators': 10}, algorithm='RandomForest', X=array([[5.1, 3.5, 1.4, 0.2],
       [4.9, 3. , 1....2, 3.4, 5.4, 2.3],
       [5.9, 3. , 5.1, 1.8]]), y=array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,... 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]), context={'baseline_score': 0.9466666666666667, 'baseline_score_std': 0.04988876515698587, 'best_config': {'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': 4, 'max_features': 3, 'max_leaf_nodes': 3, 'min_samples_split': 3, 'n_estimators': 10}, 'config_hash': {'algorithm': 'ffb7ff225ce3d3712c96cf87fe42202988ee2eb0', 'config': 'bae32f426be9cd6243523c023944a8c148fe4aeb', 'pipeline': 'd2a68bfda6fcdec4ae0ffc7d7b6a2122bc1cd673'}, 'duration': 0.7115809917449951, 'iteration': 113, 'loss': 0.033333333333333215, 'max_history_score': 0.9666666666666668, 'max_history_score_std': 0.033333333333333326, 'max_history_step': 'joint', 'pipeline': {'features': ('features_NoneType', {}), 'normalizer': ('normalizer_PowerTransformer', {}), 'rebalance': ('rebalance_CondensedNearestNeighbour', {'rebalance__n_neighbors': 2})}, 'score': 0.9666666666666668, ...}, 'history': [{'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': 2, 'max_features': None, 'max_leaf_nodes': 5, 'min_samples_split': 2, 'n_estimators': 75}, 'config_hash': {'algorithm': '3af5b0cce71c8fe2545246ca24ff5bc3dd516e06', 'config': 'db6ac7e6d348155757e4794bb5f88fe2b4f63d50', 'pipeline': '8d59f4b94cef6be9306ed86a22a9570fa670d567'}, 'duration': 1.149928092956543, 'iteration': 0, 'loss': 0.046666666666666634, 'max_history_score': 0.9533333333333334, 'max_history_score_std': 0.059999999999999984, 'max_history_step': 'joint', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 4, 'features__selectkbest__k': 3}), 'normalizer': ('normalizer_StandardScaler', {'normalizer__with_mean': True, 'normalizer__with_std': True}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 6})}, 'score': 0.9533333333333334, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': 1, 'max_features': 2, 'max_leaf_nodes': 2, 'min_samples_split': 5, 'n_estimators': 100}, 'config_hash': {'algorithm': 'e13eb05fd9a62d2f63bbb1c1deff0cd620d5e6ab', 'config': '4db6fb84d85f52659f780e682ffac5712c3d8a94', 'pipeline': '64c9a1ca9d53ae67244bdd942f4db36a3c05218c'}, 'duration': 1.7678282260894775, 'iteration': 1, 'loss': 0.18000000000000005, 'max_history_score': 0.9533333333333334, 'max_history_score_std': 0.059999999999999984, 'max_history_step': 'joint', 'pipeline': {'features': ('features_NoneType', {}), 'normalizer': ('normalizer_PowerTransformer', {}), 'rebalance': ('rebalance_NearMiss', {'rebalance__n_neighbors': 1})}, 'score': 0.82, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': 1, 'max_features': None, 'max_leaf_nodes': None, 'min_samples_split': 5, 'n_estimators': 75}, 'config_hash': {'algorithm': '94b0d7a654c508cc63643f78fe4f0f07e6f07c1e', 'config': '4403c5a85e951938d3c454e961d3a412780722f6', 'pipeline': '3e47444880d8367fbac2faaba2e52a917274aa58'}, 'duration': 0.8397619724273682, 'iteration': 2, 'loss': 0.03333333333333344, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_PCA', {'features__n_components': 3}), 'normalizer': ('normalizer_MinMaxScaler', {}), 'rebalance': ('rebalance_NoneType', {})}, 'score': 0.9666666666666666, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': None, 'max_features': None, 'max_leaf_nodes': 3, 'min_samples_split': 3, 'n_estimators': 75}, 'config_hash': {'algorithm': 'e8332f0a8902bda03bf70e7978cc5d52affb29d3', 'config': 'a064e2df18ab98d44dabcefbc7bed94913f1d0be', 'pipeline': '7eea819c2a8c103c4b1e9e9c1e224aebba95081f'}, 'duration': 0.8501448631286621, 'iteration': 3, 'loss': 0.053333333333333344, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 2, 'features__selectkbest__k': 4}), 'normalizer': ('normalizer_NoneType', {}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 7})}, 'score': 0.9466666666666667, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'entropy', 'max_depth': 3, 'max_features': 3, 'max_leaf_nodes': None, 'min_samples_split': 5, 'n_estimators': 75}, 'config_hash': {'algorithm': '7a4491035bc6bd737fe9a8cda8a79a02d02d5c74', 'config': '0ddb6f5cab3db4dddd7682966a57205f3e329ad4', 'pipeline': 'a9ae03fe38334f6868cbf84cdd3d629d4bbe3fb0'}, 'duration': 1.1026010513305664, 'iteration': 4, 'loss': 0.05999999999999994, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 2, 'features__selectkbest__k': 1}), 'normalizer': ('normalizer_NoneType', {}), 'rebalance': ('rebalance_NoneType', {})}, 'score': 0.9400000000000001, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'gini', 'max_depth': 3, 'max_features': 1, 'max_leaf_nodes': 5, 'min_samples_split': 2, 'n_estimators': 25}, 'config_hash': {'algorithm': '9826d20b2d6a0f559cf7f16450ce7526f07e8434', 'config': '49f25751bca61cdd461a8cbd2923689b642f98ed', 'pipeline': '19b249664c5bf067de1fed4334a296f947ce774a'}, 'duration': 0.35647010803222656, 'iteration': 5, 'loss': 0.046666666666666634, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_NoneType', {}), 'normalizer': ('normalizer_NoneType', {}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 6})}, 'score': 0.9533333333333334, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'gini', 'max_depth': 2, 'max_features': 1, 'max_leaf_nodes': 2, 'min_samples_split': 2, 'n_estimators': 50}, 'config_hash': {'algorithm': '0a4f6fbb07e0f32c6f675489a0fc82eee05bd8e1', 'config': '5c3a2b6f5e63fb45f10e41e0318b354912ec44f6', 'pipeline': 'dc3b9f176f090005e38b142f11d80e93a7dc5d5e'}, 'duration': 0.7213859558105469, 'iteration': 6, 'loss': 0.31333333333333324, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 1, 'features__selectkbest__k': 4}), 'normalizer': ('normalizer_PowerTransformer', {}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 7})}, 'score': 0.6866666666666668, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'entropy', 'max_depth': 4, 'max_features': 3, 'max_leaf_nodes': 5, 'min_samples_split': 5, 'n_estimators': 10}, 'config_hash': {'algorithm': 'b8112b97ecfc10f00a195af661dcc861cac21289', 'config': 'd3b129b397350f1b6572651c67c01de49b4b174c', 'pipeline': '5b0357ed7072c37b3d6f458bb5d49ff7d825f603'}, 'duration': 0.8299109935760498, 'iteration': 7, 'loss': 1.0, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_PCA', {'features__n_components': 2}), 'normalizer': ('normalizer_StandardScaler', {'normalizer__with_mean': True, 'normalizer__with_std': False}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 6})}, 'score': 0.0, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'gini', 'max_depth': 4, 'max_features': None, 'max_leaf_nodes': 2, 'min_samples_split': 5, 'n_estimators': 100}, 'config_hash': {'algorithm': '40ca24df19b8d164d9d098a6bed1ce056fbbb961', 'config': '813bde1108cc3c4b9bfb3a22cbb421bda7eac671', 'pipeline': '74a7b8705a1c22f7dea5e44e4ebda8f1e48add71'}, 'duration': 2.2111589908599854, 'iteration': 8, 'loss': 0.33333333333333326, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_PCA', {'features__n_components': 2}), 'normalizer': ('normalizer_StandardScaler', {'normalizer__with_mean': False, 'normalizer__with_std': True}), 'rebalance': ('rebalance_NearMiss', {'rebalance__n_neighbors': 2})}, 'score': 0.6666666666666667, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'entropy', 'max_depth': 2, 'max_features': 1, 'max_leaf_nodes': 5, 'min_samples_split': 2, 'n_estimators': 100}, 'config_hash': {'algorithm': '331418a5c12cf1453876eef85e9d98fc8e54fa11', 'config': '31930b6860ed406d59bf7e59ba1925d94704bd3b', 'pipeline': '054bef356f90ec6f644ef3ffc688766744db51c2'}, 'duration': 1.0501940250396729, 'iteration': 9, 'loss': 0.053333333333333344, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_SelectKBest', {'features__k': 1}), 'normalizer': ('normalizer_RobustScaler', {'normalizer__quantile_range': (...), 'normalizer__with_centering': True, 'normalizer__with_scaling': True}), 'rebalance': ('rebalance_NearMiss', {'rebalance__n_neighbors': 2})}, 'score': 0.9466666666666667, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'entropy', 'max_depth': 3, 'max_features': None, 'max_leaf_nodes': 3, 'min_samples_split': 2, 'n_estimators': 100}, 'config_hash': {'algorithm': 'dbc1b8126649fe93dce5fbb37e4015b0acfb179e', 'config': '9913cd550615a9d0946ab4a755a8b9f619e442fd', 'pipeline': 'dd626121cea079ebb32e184ca65483ec7a6d7f59'}, 'duration': 1.120617151260376, 'iteration': 10, 'loss': 0.046666666666666634, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 2, 'features__selectkbest__k': 1}), 'normalizer': ('normalizer_MinMaxScaler', {}), 'rebalance': ('rebalance_NoneType', {})}, 'score': 0.9533333333333334, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'gini', 'max_depth': 3, 'max_features': 3, 'max_leaf_nodes': None, 'min_samples_split': 3, 'n_estimators': 75}, 'config_hash': {'algorithm': '34917a130df5a975f78bd7ec1a0c7b1ffdc787a9', 'config': '95fc8cadc088141290b7de9c388977e4685f0108', 'pipeline': '550d10faf2f08db48516cc3501558816d6a99bc0'}, 'duration': 1.4287099838256836, 'iteration': 11, 'loss': 0.19333333333333313, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 3, 'features__selectkbest__k': 4}), 'normalizer': ('normalizer_StandardScaler', {'normalizer__with_mean': False, 'normalizer__with_std': False}), 'rebalance': ('rebalance_CondensedNearestNeighbour', {'rebalance__n_neighbors': 1})}, 'score': 0.8066666666666669, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'entropy', 'max_depth': 1, 'max_features': 2, 'max_leaf_nodes': 5, 'min_samples_split': 2, 'n_estimators': 75}, 'config_hash': {'algorithm': '33f9abb4aee44a395a9f3b3ffa9ce80a8cdaed7c', 'config': '40fa726f0360cf6af55f9b5902d399d02f61f157', 'pipeline': 'cfd1d20841fe2153da762c95e79f95a3fb1e426a'}, 'duration': 1.2978079319000244, 'iteration': 12, 'loss': 0.053333333333333344, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_PCA', {'features__n_components': 4}), 'normalizer': ('normalizer_MinMaxScaler', {}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 7})}, 'score': 0.9466666666666667, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'entropy', 'max_depth': 4, 'max_features': 2, 'max_leaf_nodes': 5, 'min_samples_split': 3, 'n_estimators': 25}, 'config_hash': {'algorithm': '210111ec6562d09eb093e98ed69ef1c662e11a50', 'config': '0fb8e77c7bd9a58b72f1b33c21a59a09a8c676ba', 'pipeline': '5d269d759e0c7926a685a14b263ace8ae0071e4b'}, 'duration': 0.36649012565612793, 'iteration': 13, 'loss': 0.040000000000000036, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 2, 'features__selectkbest__k': 2}), 'normalizer': ('normalizer_NoneType', {}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 7})}, 'score': 0.96, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'entropy', 'max_depth': 3, 'max_features': 1, 'max_leaf_nodes': 5, 'min_samples_split': 2, 'n_estimators': 25}, 'config_hash': {'algorithm': '0e989a03980101fabf79eda3326ed2870e11d690', 'config': 'f4bffd5d8c67a9c5321a9943c4a99678f59a02b7', 'pipeline': '865ee1e3fe8334c3d5ecb2038d5a5d1b3ba50e75'}, 'duration': 0.35639500617980957, 'iteration': 14, 'loss': 0.046666666666666634, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_NoneType', {}), 'normalizer': ('normalizer_RobustScaler', {'normalizer__quantile_range': (...), 'normalizer__with_centering': True, 'normalizer__with_scaling': False}), 'rebalance': ('rebalance_NoneType', {})}, 'score': 0.9533333333333334, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'entropy', 'max_depth': None, 'max_features': 3, 'max_leaf_nodes': 3, 'min_samples_split': 5, 'n_estimators': 10}, 'config_hash': {'algorithm': '9c592e876c13de5e23e6de5b868e01755d63e72e', 'config': '1e6a68cd1eeac886d90724d78b1cb5fb76a3cde4', 'pipeline': '5a1ca4d82f21b7de0d2c918630a42510673fa36e'}, 'duration': 0.18141412734985352, 'iteration': 15, 'loss': 0.046666666666666634, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_SelectKBest', {'features__k': 3}), 'normalizer': ('normalizer_RobustScaler', {'normalizer__quantile_range': (...), 'normalizer__with_centering': True, 'normalizer__with_scaling': True}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 6})}, 'score': 0.9533333333333334, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': 1, 'max_features': None, 'max_leaf_nodes': None, 'min_samples_split': 5, 'n_estimators': 10}, 'config_hash': {'algorithm': '8bed77aef289bfd453b2858bd288ae5ba7160f2b', 'config': '781185bcb8999045de8d489f253a1a1ba4247932', 'pipeline': '1ece7eabedc2be9e5b0a1be65c570d08ffa3eb54'}, 'duration': 0.1636829376220703, 'iteration': 16, 'loss': 0.053333333333333344, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_NoneType', {}), 'normalizer': ('normalizer_NoneType', {}), 'rebalance': ('rebalance_NearMiss', {'rebalance__n_neighbors': 1})}, 'score': 0.9466666666666667, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'gini', 'max_depth': 3, 'max_features': 2, 'max_leaf_nodes': 2, 'min_samples_split': 5, 'n_estimators': 75}, 'config_hash': {'algorithm': '617b97d9ba21d3373bc51ffa9cccf9c6f91a77b3', 'config': '99fb425b4e8c5d80228cab94202252aa25cdf77c', 'pipeline': 'd6242929c3b515c7719e60423023ac604311afc3'}, 'duration': 0.8468999862670898, 'iteration': 17, 'loss': 0.24, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_PCA', {'features__n_components': 4}), 'normalizer': ('normalizer_PowerTransformer', {}), 'rebalance': ('rebalance_NearMiss', {'rebalance__n_neighbors': 2})}, 'score': 0.76, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': 1, 'max_features': 1, 'max_leaf_nodes': 2, 'min_samples_split': 5, 'n_estimators': 50}, 'config_hash': {'algorithm': 'b92d2697cdd4979da443369d6596229ec091626a', 'config': 'c513a3e13281206ad76187dd817b1fff93d54fe1', 'pipeline': 'c4b4f914a3ca8df967cade997a90366d85a371b9'}, 'duration': 0.6724588871002197, 'iteration': 18, 'loss': 0.23333333333333328, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 1, 'features__selectkbest__k': 3}), 'normalizer': ('normalizer_StandardScaler', {'normalizer__with_mean': True, 'normalizer__with_std': True}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 5})}, 'score': 0.7666666666666667, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'entropy', 'max_depth': None, 'max_features': None, 'max_leaf_nodes': 5, 'min_samples_split': 5, 'n_estimators': 10}, 'config_hash': {'algorithm': 'a0115de695e6cca2e81cbfb54df79bf4b43608b1', 'config': 'ba194015e20b5d67770e8c67342c3d8d0d01dc41', 'pipeline': '8d45fabfeb85ffdcabf7076bd0e65fffe97ce928'}, 'duration': 0.19424200057983398, 'iteration': 19, 'loss': 0.08666666666666667, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_PCA', {'features__n_components': 3}), 'normalizer': ('normalizer_NoneType', {}), 'rebalance': ('rebalance_NoneType', {})}, 'score': 0.9133333333333333, ...}, ...], 'history_hash': ['db6ac7e6d348155757e4794bb5f88fe2b4f63d50', '4db6fb84d85f52659f780e682ffac5712c3d8a94', '4403c5a85e951938d3c454e961d3a412780722f6', 'a064e2df18ab98d44dabcefbc7bed94913f1d0be', '0ddb6f5cab3db4dddd7682966a57205f3e329ad4', '49f25751bca61cdd461a8cbd2923689b642f98ed', '5c3a2b6f5e63fb45f10e41e0318b354912ec44f6', 'd3b129b397350f1b6572651c67c01de49b4b174c', '813bde1108cc3c4b9bfb3a22cbb421bda7eac671', '31930b6860ed406d59bf7e59ba1925d94704bd3b', '9913cd550615a9d0946ab4a755a8b9f619e442fd', '95fc8cadc088141290b7de9c388977e4685f0108', '40fa726f0360cf6af55f9b5902d399d02f61f157', '0fb8e77c7bd9a58b72f1b33c21a59a09a8c676ba', 'f4bffd5d8c67a9c5321a9943c4a99678f59a02b7', '1e6a68cd1eeac886d90724d78b1cb5fb76a3cde4', '781185bcb8999045de8d489f253a1a1ba4247932', '99fb425b4e8c5d80228cab94202252aa25cdf77c', 'c513a3e13281206ad76187dd817b1fff93d54fe1', 'ba194015e20b5d67770e8c67342c3d8d0d01dc41', ...], 'history_index': {'00f0493590a2cb5e98a35b29816f8cd9f87f96ec': 208, '013329309d510b94f19d930320402d65f953a847': 39, '038a0f515e2ec894ee8e34f9caa2889eb3ebd5ce': 66, '052ae4bf232b316187b078abae42c2be19e16a00': 111, '05e9258ebf99dd97202167ef1563fa834b0568f1': 242, '0659afebf316aafeb75612fb07081a04c28545ed': 74, '06e7cde9f3556cd01332ce389ad1d8925cd4b4a4': 120, '07ab8a30d853e39a326b7017026a20e94bc45541': 245, '08606f2a0f0a6c9de204020b4632e09fcee0ae56': 168, '09dbd0948e5b8c1b1f0930778babe65c8a81295e': 243, ...}, 'iteration': 296, 'max_history_score': 0.9666666666666668, 'max_history_score_std': 0.033333333333333326, 'max_history_step': 'joint'}, config={'algorithm': 'RandomForest', 'seed': 42, 'time': 300}, step='joint')
     45                 y,
     46                 cv=10,
     47                 n_jobs=-1,
     48                 return_estimator=False,
     49                 return_train_score=False,
---> 50                 verbose=0)
     51         score = np.mean(scores['test_score'])
     52         std = np.std(scores['test_score'])
     53         status = STATUS_OK
     54     except Exception as e:

...........................................................................
/home/aquemy/.local/lib/python2.7/site-packages/sklearn/model_selection/_validation.py in cross_validate(estimator=Pipeline(memory=None,
     steps=[('normalizer',... random_state=42, verbose=0, warm_start=False))]), X=array([[5.1, 3.5, 1.4, 0.2],
       [4.9, 3. , 1....2, 3.4, 5.4, 2.3],
       [5.9, 3. , 5.1, 1.8]]), y=array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,... 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]), groups=None, scoring=None, cv=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1, verbose=0, fit_params=None, pre_dispatch='2*n_jobs', return_train_score=False, return_estimator=False, error_score='raise-deprecating')
    235         delayed(_fit_and_score)(
    236             clone(estimator), X, y, scorers, train, test, verbose, None,
    237             fit_params, return_train_score=return_train_score,
    238             return_times=True, return_estimator=return_estimator,
    239             error_score=error_score)
--> 240         for train, test in cv.split(X, y, groups))
        cv.split = <bound method StratifiedKFold.split of Stratifie...d(n_splits=10, random_state=None, shuffle=False)>
        X = array([[5.1, 3.5, 1.4, 0.2],
       [4.9, 3. , 1....2, 3.4, 5.4, 2.3],
       [5.9, 3. , 5.1, 1.8]])
        y = array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,... 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2])
        groups = None
    241 
    242     zipped_scores = list(zip(*scores))
    243     if return_train_score:
    244         train_scores = zipped_scores.pop(0)

...........................................................................
/home/aquemy/.local/lib/python2.7/site-packages/sklearn/externals/joblib/parallel.py in __call__(self=Parallel(n_jobs=-1), iterable=<generator object <genexpr>>)
    925                 # No need to wait for async callbacks to trigger to
    926                 # consumption.
    927                 self._iterating = False
    928 
    929             with self._backend.retrieval_context():
--> 930                 self.retrieve()
        self.retrieve = <bound method Parallel.retrieve of Parallel(n_jobs=-1)>
    931             # Make sure that we get a last message telling us we are done
    932             elapsed_time = time.time() - self._start_time
    933             self._print('Done %3i out of %3i | elapsed: %s finished',
    934                         (len(self._output), len(self._output),

---------------------------------------------------------------------------
Joblib worker traceback:
---------------------------------------------------------------------------
ValueError                                         Mon Jun 17 13:14:33 2019
PID: 21801                                  Python 2.7.15+: /usr/bin/python
...........................................................................
/home/aquemy/.local/lib/python2.7/site-packages/sklearn/externals/joblib/parallel.py in __call__(self=<sklearn.externals.joblib.parallel.BatchedCalls object>)
    220     def __call__(self):
    221         # Set the default nested backend to self._backend but do not set the
    222         # change the default number of processes to -1
    223         with parallel_backend(self._backend, n_jobs=self._n_jobs):
    224             return [func(*args, **kwargs)
--> 225                     for func, args, kwargs in self.items]
        func = <function _fit_and_score>
        args = (Pipeline(memory=None,
     steps=[('normalizer',... random_state=42, verbose=0, warm_start=False))]), array([[5.1, 3.5, 1.4, 0.2],
       [4.9, 3. , 1....2, 3.4, 5.4, 2.3],
       [5.9, 3. , 5.1, 1.8]]), array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,... 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]), {'score': <function _passthrough_scorer>}, array([  5,   6,   7,   8,   9,  10,  11,  12,  ..., 142, 143, 144,
       145, 146, 147, 148, 149]), array([  0,   1,   2,   3,   4,  50,  51,  52,  53,  54, 100, 101, 102,
       103, 104]), 0, None, None)
        kwargs = {'error_score': 'raise-deprecating', 'return_estimator': False, 'return_times': True, 'return_train_score': False}
        self.items = [(<function _fit_and_score>, (Pipeline(memory=None,
     steps=[('normalizer',... random_state=42, verbose=0, warm_start=False))]), array([[5.1, 3.5, 1.4, 0.2],
       [4.9, 3. , 1....2, 3.4, 5.4, 2.3],
       [5.9, 3. , 5.1, 1.8]]), array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,... 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]), {'score': <function _passthrough_scorer>}, array([  5,   6,   7,   8,   9,  10,  11,  12,  ..., 142, 143, 144,
       145, 146, 147, 148, 149]), array([  0,   1,   2,   3,   4,  50,  51,  52,  53,  54, 100, 101, 102,
       103, 104]), 0, None, None), {'error_score': 'raise-deprecating', 'return_estimator': False, 'return_times': True, 'return_train_score': False})]
    226 
    227     def __len__(self):
    228         return self._size
    229 

...........................................................................
/home/aquemy/.local/lib/python2.7/site-packages/sklearn/model_selection/_validation.py in _fit_and_score(estimator=Pipeline(memory=None,
     steps=[('normalizer',... random_state=42, verbose=0, warm_start=False))]), X=array([[5.1, 3.5, 1.4, 0.2],
       [4.9, 3. , 1....2, 3.4, 5.4, 2.3],
       [5.9, 3. , 5.1, 1.8]]), y=array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,... 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]), scorer={'score': <function _passthrough_scorer>}, train=array([  5,   6,   7,   8,   9,  10,  11,  12,  ..., 142, 143, 144,
       145, 146, 147, 148, 149]), test=array([  0,   1,   2,   3,   4,  50,  51,  52,  53,  54, 100, 101, 102,
       103, 104]), verbose=0, parameters=None, fit_params={}, return_train_score=False, return_parameters=False, return_n_test_samples=False, return_times=True, return_estimator=False, error_score='raise-deprecating')
    523 
    524     try:
    525         if y_train is None:
    526             estimator.fit(X_train, **fit_params)
    527         else:
--> 528             estimator.fit(X_train, y_train, **fit_params)
        estimator.fit = <bound method Pipeline.fit of Pipeline(memory=No...random_state=42, verbose=0, warm_start=False))])>
        X_train = array([[5.4, 3.9, 1.7, 0.4],
       [4.6, 3.4, 1....2, 3.4, 5.4, 2.3],
       [5.9, 3. , 5.1, 1.8]])
        y_train = array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,
       2, 2, 2])
        fit_params = {}
    529 
    530     except Exception as e:
    531         # Note fit time as time until error
    532         fit_time = time.time() - start_time

...........................................................................
/usr/local/lib/python2.7/dist-packages/imblearn/pipeline.py in fit(self=Pipeline(memory=None,
     steps=[('normalizer',... random_state=42, verbose=0, warm_start=False))]), X=array([[5.4, 3.9, 1.7, 0.4],
       [4.6, 3.4, 1....2, 3.4, 5.4, 2.3],
       [5.9, 3. , 5.1, 1.8]]), y=array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,
       2, 2, 2]), **fit_params={})
    234             This estimator
    235 
    236         """
    237         Xt, yt, fit_params = self._fit(X, y, **fit_params)
    238         if self._final_estimator is not None:
--> 239             self._final_estimator.fit(Xt, yt, **fit_params)
        self._final_estimator.fit = <bound method RandomForestClassifier.fit of Rand...e, random_state=42, verbose=0, warm_start=False)>
        Xt = array([[0.97077501],
       [0.79946177],
      ...2944],
       [3.08363827],
       [2.91232503]])
        yt = array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,
       2, 2, 2])
        fit_params = {}
    240         return self
    241 
    242     def fit_transform(self, X, y=None, **fit_params):
    243         """Fit the model and transform with the final estimator

...........................................................................
/home/aquemy/.local/lib/python2.7/site-packages/sklearn/ensemble/forest.py in fit(self=RandomForestClassifier(bootstrap=True, class_wei...se, random_state=42, verbose=0, warm_start=False), X=array([[0.970775  ],
       [0.7994618 ],
      ...3.0836382 ],
       [2.9123251 ]], dtype=float32), y=array([[0.],
       [0.],
       [0.],
       [0...    [2.],
       [2.],
       [2.],
       [2.]]), sample_weight=None)
    328             trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,
    329                              **_joblib_parallel_args(prefer='threads'))(
    330                 delayed(_parallel_build_trees)(
    331                     t, self, X, y, sample_weight, i, len(trees),
    332                     verbose=self.verbose, class_weight=self.class_weight)
--> 333                 for i, t in enumerate(trees))
        i = 9
    334 
    335             # Collect newly grown trees
    336             self.estimators_.extend(trees)
    337 

...........................................................................
/home/aquemy/.local/lib/python2.7/site-packages/sklearn/externals/joblib/parallel.py in __call__(self=Parallel(n_jobs=1), iterable=<generator object <genexpr>>)
    912             # self._original_iterator is None, then this means either
    913             # that pre_dispatch == "all", n_jobs == 1 or that the first batch
    914             # was very quick and its callback already dispatched all the
    915             # remaining jobs.
    916             self._iterating = False
--> 917             if self.dispatch_one_batch(iterator):
        self.dispatch_one_batch = <bound method Parallel.dispatch_one_batch of Parallel(n_jobs=1)>
        iterator = <generator object <genexpr>>
    918                 self._iterating = self._original_iterator is not None
    919 
    920             while self.dispatch_one_batch(iterator):
    921                 pass

...........................................................................
/home/aquemy/.local/lib/python2.7/site-packages/sklearn/externals/joblib/parallel.py in dispatch_one_batch(self=Parallel(n_jobs=1), iterator=<generator object <genexpr>>)
    754                                  self._pickle_cache)
    755             if len(tasks) == 0:
    756                 # No more tasks available in the iterator: tell caller to stop.
    757                 return False
    758             else:
--> 759                 self._dispatch(tasks)
        self._dispatch = <bound method Parallel._dispatch of Parallel(n_jobs=1)>
        tasks = <sklearn.externals.joblib.parallel.BatchedCalls object>
    760                 return True
    761 
    762     def _print(self, msg, msg_args):
    763         """Display the message on stout or stderr depending on verbosity"""

...........................................................................
/home/aquemy/.local/lib/python2.7/site-packages/sklearn/externals/joblib/parallel.py in _dispatch(self=Parallel(n_jobs=1), batch=<sklearn.externals.joblib.parallel.BatchedCalls object>)
    711 
    712         dispatch_timestamp = time.time()
    713         cb = BatchCompletionCallBack(dispatch_timestamp, len(batch), self)
    714         with self._lock:
    715             job_idx = len(self._jobs)
--> 716             job = self._backend.apply_async(batch, callback=cb)
        job = undefined
        self._backend.apply_async = <bound method SequentialBackend.apply_async of <...lib._parallel_backends.SequentialBackend object>>
        batch = <sklearn.externals.joblib.parallel.BatchedCalls object>
        cb = <sklearn.externals.joblib.parallel.BatchCompletionCallBack object>
    717             # A job can complete so quickly than its callback is
    718             # called before we get here, causing self._jobs to
    719             # grow. To ensure correct results ordering, .insert is
    720             # used (rather than .append) in the following line

...........................................................................
/home/aquemy/.local/lib/python2.7/site-packages/sklearn/externals/joblib/_parallel_backends.py in apply_async(self=<sklearn.externals.joblib._parallel_backends.SequentialBackend object>, func=<sklearn.externals.joblib.parallel.BatchedCalls object>, callback=<sklearn.externals.joblib.parallel.BatchCompletionCallBack object>)
    177             raise ValueError('n_jobs == 0 in Parallel has no meaning')
    178         return 1
    179 
    180     def apply_async(self, func, callback=None):
    181         """Schedule a func to be run"""
--> 182         result = ImmediateResult(func)
        result = undefined
        func = <sklearn.externals.joblib.parallel.BatchedCalls object>
    183         if callback:
    184             callback(result)
    185         return result
    186 

...........................................................................
/home/aquemy/.local/lib/python2.7/site-packages/sklearn/externals/joblib/_parallel_backends.py in __init__(self=<sklearn.externals.joblib._parallel_backends.ImmediateResult object>, batch=<sklearn.externals.joblib.parallel.BatchedCalls object>)
    544 
    545 class ImmediateResult(object):
    546     def __init__(self, batch):
    547         # Don't delay the application, to avoid keeping the input
    548         # arguments in memory
--> 549         self.results = batch()
        self.results = undefined
        batch = <sklearn.externals.joblib.parallel.BatchedCalls object>
    550 
    551     def get(self):
    552         return self.results
    553 

...........................................................................
/home/aquemy/.local/lib/python2.7/site-packages/sklearn/externals/joblib/parallel.py in __call__(self=<sklearn.externals.joblib.parallel.BatchedCalls object>)
    220     def __call__(self):
    221         # Set the default nested backend to self._backend but do not set the
    222         # change the default number of processes to -1
    223         with parallel_backend(self._backend, n_jobs=self._n_jobs):
    224             return [func(*args, **kwargs)
--> 225                     for func, args, kwargs in self.items]
        func = <function _parallel_build_trees>
        args = (DecisionTreeClassifier(class_weight=None, criter...=False, random_state=1608637542, splitter='best'), RandomForestClassifier(bootstrap=True, class_wei...se, random_state=42, verbose=0, warm_start=False), array([[0.970775  ],
       [0.7994618 ],
      ...3.0836382 ],
       [2.9123251 ]], dtype=float32), array([[0.],
       [0.],
       [0.],
       [0...    [2.],
       [2.],
       [2.],
       [2.]]), None, 0, 10)
        kwargs = {'class_weight': None, 'verbose': 0}
        self.items = [(<function _parallel_build_trees>, (DecisionTreeClassifier(class_weight=None, criter...=False, random_state=1608637542, splitter='best'), RandomForestClassifier(bootstrap=True, class_wei...se, random_state=42, verbose=0, warm_start=False), array([[0.970775  ],
       [0.7994618 ],
      ...3.0836382 ],
       [2.9123251 ]], dtype=float32), array([[0.],
       [0.],
       [0.],
       [0...    [2.],
       [2.],
       [2.],
       [2.]]), None, 0, 10), {'class_weight': None, 'verbose': 0})]
    226 
    227     def __len__(self):
    228         return self._size
    229 

...........................................................................
/home/aquemy/.local/lib/python2.7/site-packages/sklearn/ensemble/forest.py in _parallel_build_trees(tree=DecisionTreeClassifier(class_weight=None, criter...=False, random_state=1608637542, splitter='best'), forest=RandomForestClassifier(bootstrap=True, class_wei...se, random_state=42, verbose=0, warm_start=False), X=array([[0.970775  ],
       [0.7994618 ],
      ...3.0836382 ],
       [2.9123251 ]], dtype=float32), y=array([[0.],
       [0.],
       [0.],
       [0...    [2.],
       [2.],
       [2.],
       [2.]]), sample_weight=None, tree_idx=0, n_trees=10, verbose=0, class_weight=None)
    114                 simplefilter('ignore', DeprecationWarning)
    115                 curr_sample_weight *= compute_sample_weight('auto', y, indices)
    116         elif class_weight == 'balanced_subsample':
    117             curr_sample_weight *= compute_sample_weight('balanced', y, indices)
    118 
--> 119         tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)
        tree.fit = <bound method DecisionTreeClassifier.fit of Deci...False, random_state=1608637542, splitter='best')>
        X = array([[0.970775  ],
       [0.7994618 ],
      ...3.0836382 ],
       [2.9123251 ]], dtype=float32)
        y = array([[0.],
       [0.],
       [0.],
       [0...    [2.],
       [2.],
       [2.],
       [2.]])
        sample_weight = None
        curr_sample_weight = array([3., 3., 0., 1., 1., 2., 2., 0., 1., 2., 0... 1., 0., 1., 0., 1., 1., 1., 1., 1., 1., 0., 0.])
    120     else:
    121         tree.fit(X, y, sample_weight=sample_weight, check_input=False)
    122 
    123     return tree

...........................................................................
/home/aquemy/.local/lib/python2.7/site-packages/sklearn/tree/tree.py in fit(self=DecisionTreeClassifier(class_weight=None, criter...=False, random_state=1608637542, splitter='best'), X=array([[0.970775  ],
       [0.7994618 ],
      ...3.0836382 ],
       [2.9123251 ]], dtype=float32), y=array([[0.],
       [0.],
       [0.],
       [0...    [2.],
       [2.],
       [2.],
       [2.]]), sample_weight=array([3., 3., 0., 1., 1., 2., 2., 0., 1., 2., 0... 1., 0., 1., 0., 1., 1., 1., 1., 1., 1., 0., 0.]), check_input=False, X_idx_sorted=None)
    796 
    797         super(DecisionTreeClassifier, self).fit(
    798             X, y,
    799             sample_weight=sample_weight,
    800             check_input=check_input,
--> 801             X_idx_sorted=X_idx_sorted)
        X_idx_sorted = None
    802         return self
    803 
    804     def predict_proba(self, X, check_input=True):
    805         """Predict class probabilities of the input samples X.

...........................................................................
/home/aquemy/.local/lib/python2.7/site-packages/sklearn/tree/tree.py in fit(self=DecisionTreeClassifier(class_weight=None, criter...=False, random_state=1608637542, splitter='best'), X=array([[0.970775  ],
       [0.7994618 ],
      ...3.0836382 ],
       [2.9123251 ]], dtype=float32), y=array([[0.],
       [0.],
       [0.],
       [0...    [2.],
       [2.],
       [2.],
       [2.]]), sample_weight=array([3., 3., 0., 1., 1., 2., 2., 0., 1., 2., 0... 1., 0., 1., 0., 1., 1., 1., 1., 1., 1., 0., 0.]), check_input=False, X_idx_sorted=None)
    237         if not 0 <= self.min_weight_fraction_leaf <= 0.5:
    238             raise ValueError("min_weight_fraction_leaf must in [0, 0.5]")
    239         if max_depth <= 0:
    240             raise ValueError("max_depth must be greater than zero. ")
    241         if not (0 < max_features <= self.n_features_):
--> 242             raise ValueError("max_features must be in (0, n_features]")
    243         if not isinstance(max_leaf_nodes, (numbers.Integral, np.integer)):
    244             raise ValueError("max_leaf_nodes must be integral number but was "
    245                              "%r" % max_leaf_nodes)
    246         if -1 < max_leaf_nodes < 2:

ValueError: max_features must be in (0, n_features]
___________________________________________________________________________
Best score: 0.966666666667 (0.0333333333333) [J] | Score: 0.0 (0.0) [J]
JoblibValueError
___________________________________________________________________________
...........................................................................
/home/aquemy/dev/dp_hyperparameters/extension/main.py in <module>()
     27 
     28     serializer.serialize_results(scenario, policy)
     29 
     30 if __name__ == "__main__":
     31     args = cli.parse_args()
---> 32     main(args)

...........................................................................
/home/aquemy/dev/dp_hyperparameters/extension/main.py in main(args=Namespace(customize=[(['control', 'seed'], '42')...io='./scenarios/rf_iris_joint.yaml', verbosity=0))
     21         test_size=0.4, 
     22         random_state=scenario['control']['seed']
     23     )
     24 
     25     policy = policies.initiate(scenario['setup']['policy'], config)
---> 26     policy.run(X,y)
        policy.run = <bound method Joint.run of <experiment.policies.joint.Joint object>>
        X = array([[5.1, 3.5, 1.4, 0.2],
       [4.9, 3. , 1....2, 3.4, 5.4, 2.3],
       [5.9, 3. , 5.1, 1.8]])
        y = array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,... 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2])
     27 
     28     serializer.serialize_results(scenario, policy)
     29 
     30 if __name__ == "__main__":

...........................................................................
/home/aquemy/dev/dp_hyperparameters/extension/experiment/policies/joint.py in run(self=<experiment.policies.joint.Joint object>, X=array([[5.1, 3.5, 1.4, 0.2],
       [4.9, 3. , 1....2, 3.4, 5.4, 2.3],
       [5.9, 3. , 5.1, 1.8]]), y=array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,... 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]))
     32             algo=tpe.suggest, 
     33             max_evals=None,
     34             max_time=self.config['time'],     
     35             trials=trials,
     36             show_progressbar=False,
---> 37             verbose=0
     38         )
     39 
     40         best_config = self.context['best_config']
     41         super(Joint, self).display_step_results(best_config)

...........................................................................
/home/aquemy/dev/dp_hyperparameters/extension/hyperopt/fmin.py in fmin(fn=<functools.partial object>, space={'algorithm': {'bootstrap': <hyperopt.pyll.base.Apply object>, 'criterion': <hyperopt.pyll.base.Apply object>, 'max_depth': <hyperopt.pyll.base.Apply object>, 'max_features': <hyperopt.pyll.base.Apply object>, 'max_leaf_nodes': <hyperopt.pyll.base.Apply object>, 'min_samples_split': <hyperopt.pyll.base.Apply object>, 'n_estimators': <hyperopt.pyll.base.Apply object>}, 'pipeline': {'features': <hyperopt.pyll.base.Apply object>, 'normalizer': <hyperopt.pyll.base.Apply object>, 'rebalance': <hyperopt.pyll.base.Apply object>}}, algo=<function suggest>, max_evals=9223372036854775807, max_time=300, trials=<hyperopt.base.Trials object>, rstate=<mtrand.RandomState object>, allow_trials_fmin=True, pass_expr_memo_ctrl=None, catch_eval_exceptions=False, verbose=0, return_argmin=True, points_to_evaluate=None, max_queue_len=1, show_progressbar=False)
    406             pass_expr_memo_ctrl=pass_expr_memo_ctrl,
    407             verbose=verbose,
    408             catch_eval_exceptions=catch_eval_exceptions,
    409             return_argmin=return_argmin,
    410             show_progressbar=show_progressbar,
--> 411             max_time=max_time
        max_time = 300
    412         )
    413 
    414     if trials is None:
    415         if points_to_evaluate is None:

...........................................................................
/home/aquemy/dev/dp_hyperparameters/extension/hyperopt/base.py in fmin(self=<hyperopt.base.Trials object>, fn=<functools.partial object>, space={'algorithm': {'bootstrap': <hyperopt.pyll.base.Apply object>, 'criterion': <hyperopt.pyll.base.Apply object>, 'max_depth': <hyperopt.pyll.base.Apply object>, 'max_features': <hyperopt.pyll.base.Apply object>, 'max_leaf_nodes': <hyperopt.pyll.base.Apply object>, 'min_samples_split': <hyperopt.pyll.base.Apply object>, 'n_estimators': <hyperopt.pyll.base.Apply object>}, 'pipeline': {'features': <hyperopt.pyll.base.Apply object>, 'normalizer': <hyperopt.pyll.base.Apply object>, 'rebalance': <hyperopt.pyll.base.Apply object>}}, algo=<function suggest>, max_evals=9223372036854775807, max_time=300, rstate=<mtrand.RandomState object>, verbose=0, pass_expr_memo_ctrl=None, catch_eval_exceptions=False, return_argmin=True, show_progressbar=False)
    636             verbose=verbose,
    637             allow_trials_fmin=False,  # -- prevent recursion
    638             pass_expr_memo_ctrl=pass_expr_memo_ctrl,
    639             catch_eval_exceptions=catch_eval_exceptions,
    640             return_argmin=return_argmin,
--> 641             show_progressbar=show_progressbar)
        show_progressbar = False
    642 
    643 
    644 def trials_from_docs(docs, validate=True, **kwargs):
    645     """Construct a Trials base class instance from a list of trials documents

...........................................................................
/home/aquemy/dev/dp_hyperparameters/extension/hyperopt/fmin.py in fmin(fn=<functools.partial object>, space={'algorithm': {'bootstrap': <hyperopt.pyll.base.Apply object>, 'criterion': <hyperopt.pyll.base.Apply object>, 'max_depth': <hyperopt.pyll.base.Apply object>, 'max_features': <hyperopt.pyll.base.Apply object>, 'max_leaf_nodes': <hyperopt.pyll.base.Apply object>, 'min_samples_split': <hyperopt.pyll.base.Apply object>, 'n_estimators': <hyperopt.pyll.base.Apply object>}, 'pipeline': {'features': <hyperopt.pyll.base.Apply object>, 'normalizer': <hyperopt.pyll.base.Apply object>, 'rebalance': <hyperopt.pyll.base.Apply object>}}, algo=<function suggest>, max_evals=9223372036854775807, max_time=300, trials=<hyperopt.base.Trials object>, rstate=<mtrand.RandomState object>, allow_trials_fmin=False, pass_expr_memo_ctrl=None, catch_eval_exceptions=False, verbose=0, return_argmin=True, points_to_evaluate=None, max_queue_len=1, show_progressbar=False)
    426                     verbose=verbose,
    427                     max_queue_len=max_queue_len,
    428                     show_progressbar=show_progressbar,
    429                     max_time=max_time)
    430     rval.catch_eval_exceptions = catch_eval_exceptions
--> 431     rval.exhaust()
        rval.exhaust = <bound method FMinIter.exhaust of <hyperopt.fmin.FMinIter object>>
    432     if return_argmin:
    433         return trials.argmin
    434     elif len(trials) > 0:
    435         # Only if there are some succesfull trail runs, return the best point in the evaluation space

...........................................................................
/home/aquemy/dev/dp_hyperparameters/extension/hyperopt/fmin.py in exhaust(self=<hyperopt.fmin.FMinIter object>)
    273             raise StopIteration()
    274         return self.trials
    275 
    276     def exhaust(self):
    277         n_done = len(self.trials)
--> 278         self.run(self.max_evals - n_done, block_until_done=self.asynchronous)
        self.run = <bound method FMinIter.run of <hyperopt.fmin.FMinIter object>>
        self.max_evals = 9223372036854775807
        n_done = 0
        self.asynchronous = False
    279         self.trials.refresh()
    280         return self
    281 
    282 

...........................................................................
/home/aquemy/dev/dp_hyperparameters/extension/hyperopt/fmin.py in run(self=<hyperopt.fmin.FMinIter object>, N=9223372036854775807, block_until_done=False)
    232                     if self.asynchronous:
    233                         # -- wait for workers to fill in the trials
    234                         time.sleep(self.poll_interval_secs)
    235                     else:
    236                         # -- loop over trials and do the jobs directly
--> 237                         self.serial_evaluate()
        self.serial_evaluate = <bound method FMinIter.serial_evaluate of <hyperopt.fmin.FMinIter object>>
    238                     try:
    239                         res = [d['result']['loss'] for d in
    240                                          self.trials.trials if
    241                                          d['result']['status'] == 'ok']

...........................................................................
/home/aquemy/dev/dp_hyperparameters/extension/hyperopt/fmin.py in serial_evaluate(self=<hyperopt.fmin.FMinIter object>, N=-1)
    138                 trial['book_time'] = now
    139                 trial['refresh_time'] = now
    140                 spec = base.spec_from_misc(trial['misc'])
    141                 ctrl = base.Ctrl(self.trials, current_trial=trial)
    142                 try:
--> 143                     result = self.domain.evaluate(spec, ctrl)
        result = undefined
        self.domain.evaluate = <bound method Domain.evaluate of <hyperopt.base.Domain object>>
        spec = {'bootstrap': 0, 'criterion': 0, 'features': 2, 'features_SelectKBest_features__k': 1, 'max_depth': 1, 'max_features': 2, 'max_leaf_nodes': 1, 'min_samples_split': 2, 'n_estimators': 0, 'normalizer': 1, ...}
        ctrl = <hyperopt.base.Ctrl object>
    144                 except Exception as e:
    145                     logger.info('job exception: %s' % str(e))
    146                     trial['state'] = base.JOB_STATE_ERROR
    147                     trial['misc']['error'] = (str(type(e)), str(e))

...........................................................................
/home/aquemy/dev/dp_hyperparameters/extension/hyperopt/base.py in evaluate(self=<hyperopt.base.Domain object>, config={'bootstrap': 0, 'criterion': 0, 'features': 2, 'features_SelectKBest_features__k': 1, 'max_depth': 1, 'max_features': 2, 'max_leaf_nodes': 1, 'min_samples_split': 2, 'n_estimators': 0, 'normalizer': 1, ...}, ctrl=<hyperopt.base.Ctrl object>, attach_attachments=True)
    841             #    or the normal Python part (self.fn)
    842             pyll_rval = pyll.rec_eval(
    843                 self.expr,
    844                 memo=memo,
    845                 print_node_on_error=self.rec_eval_print_node_on_error)
--> 846             rval = self.fn(pyll_rval)
        rval = undefined
        self.fn = <functools.partial object>
        pyll_rval = {'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': 2, 'max_features': 3, 'max_leaf_nodes': 3, 'min_samples_split': 5, 'n_estimators': 10}, 'pipeline': {'features': ('features_SelectKBest', {'features__k': 2}), 'normalizer': ('normalizer_StandardScaler', {'normalizer__with_mean': True, 'normalizer__with_std': False}), 'rebalance': ('rebalance_NoneType', {})}}
    847 
    848         if isinstance(rval, (float, int, np.number)):
    849             dict_rval = {'loss': float(rval), 'status': STATUS_OK}
    850         else:

...........................................................................
/home/aquemy/dev/dp_hyperparameters/extension/experiment/objective.py in objective_joint(wconfig={'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': 2, 'max_features': 3, 'max_leaf_nodes': 3, 'min_samples_split': 5, 'n_estimators': 10}, 'pipeline': {'features': ('features_SelectKBest', {'features__k': 2}), 'normalizer': ('normalizer_StandardScaler', {'normalizer__with_mean': True, 'normalizer__with_std': False}), 'rebalance': ('rebalance_NoneType', {})}}, algorithm='RandomForest', X=array([[5.1, 3.5, 1.4, 0.2],
       [4.9, 3. , 1....2, 3.4, 5.4, 2.3],
       [5.9, 3. , 5.1, 1.8]]), y=array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,... 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]), context={'baseline_score': 0.9466666666666667, 'baseline_score_std': 0.04988876515698587, 'best_config': {'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': 4, 'max_features': 3, 'max_leaf_nodes': 3, 'min_samples_split': 3, 'n_estimators': 10}, 'config_hash': {'algorithm': 'ffb7ff225ce3d3712c96cf87fe42202988ee2eb0', 'config': 'bae32f426be9cd6243523c023944a8c148fe4aeb', 'pipeline': 'd2a68bfda6fcdec4ae0ffc7d7b6a2122bc1cd673'}, 'duration': 0.7115809917449951, 'iteration': 113, 'loss': 0.033333333333333215, 'max_history_score': 0.9666666666666668, 'max_history_score_std': 0.033333333333333326, 'max_history_step': 'joint', 'pipeline': {'features': ('features_NoneType', {}), 'normalizer': ('normalizer_PowerTransformer', {}), 'rebalance': ('rebalance_CondensedNearestNeighbour', {'rebalance__n_neighbors': 2})}, 'score': 0.9666666666666668, ...}, 'history': [{'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': 2, 'max_features': None, 'max_leaf_nodes': 5, 'min_samples_split': 2, 'n_estimators': 75}, 'config_hash': {'algorithm': '3af5b0cce71c8fe2545246ca24ff5bc3dd516e06', 'config': 'db6ac7e6d348155757e4794bb5f88fe2b4f63d50', 'pipeline': '8d59f4b94cef6be9306ed86a22a9570fa670d567'}, 'duration': 1.149928092956543, 'iteration': 0, 'loss': 0.046666666666666634, 'max_history_score': 0.9533333333333334, 'max_history_score_std': 0.059999999999999984, 'max_history_step': 'joint', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 4, 'features__selectkbest__k': 3}), 'normalizer': ('normalizer_StandardScaler', {'normalizer__with_mean': True, 'normalizer__with_std': True}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 6})}, 'score': 0.9533333333333334, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': 1, 'max_features': 2, 'max_leaf_nodes': 2, 'min_samples_split': 5, 'n_estimators': 100}, 'config_hash': {'algorithm': 'e13eb05fd9a62d2f63bbb1c1deff0cd620d5e6ab', 'config': '4db6fb84d85f52659f780e682ffac5712c3d8a94', 'pipeline': '64c9a1ca9d53ae67244bdd942f4db36a3c05218c'}, 'duration': 1.7678282260894775, 'iteration': 1, 'loss': 0.18000000000000005, 'max_history_score': 0.9533333333333334, 'max_history_score_std': 0.059999999999999984, 'max_history_step': 'joint', 'pipeline': {'features': ('features_NoneType', {}), 'normalizer': ('normalizer_PowerTransformer', {}), 'rebalance': ('rebalance_NearMiss', {'rebalance__n_neighbors': 1})}, 'score': 0.82, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': 1, 'max_features': None, 'max_leaf_nodes': None, 'min_samples_split': 5, 'n_estimators': 75}, 'config_hash': {'algorithm': '94b0d7a654c508cc63643f78fe4f0f07e6f07c1e', 'config': '4403c5a85e951938d3c454e961d3a412780722f6', 'pipeline': '3e47444880d8367fbac2faaba2e52a917274aa58'}, 'duration': 0.8397619724273682, 'iteration': 2, 'loss': 0.03333333333333344, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_PCA', {'features__n_components': 3}), 'normalizer': ('normalizer_MinMaxScaler', {}), 'rebalance': ('rebalance_NoneType', {})}, 'score': 0.9666666666666666, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': None, 'max_features': None, 'max_leaf_nodes': 3, 'min_samples_split': 3, 'n_estimators': 75}, 'config_hash': {'algorithm': 'e8332f0a8902bda03bf70e7978cc5d52affb29d3', 'config': 'a064e2df18ab98d44dabcefbc7bed94913f1d0be', 'pipeline': '7eea819c2a8c103c4b1e9e9c1e224aebba95081f'}, 'duration': 0.8501448631286621, 'iteration': 3, 'loss': 0.053333333333333344, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 2, 'features__selectkbest__k': 4}), 'normalizer': ('normalizer_NoneType', {}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 7})}, 'score': 0.9466666666666667, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'entropy', 'max_depth': 3, 'max_features': 3, 'max_leaf_nodes': None, 'min_samples_split': 5, 'n_estimators': 75}, 'config_hash': {'algorithm': '7a4491035bc6bd737fe9a8cda8a79a02d02d5c74', 'config': '0ddb6f5cab3db4dddd7682966a57205f3e329ad4', 'pipeline': 'a9ae03fe38334f6868cbf84cdd3d629d4bbe3fb0'}, 'duration': 1.1026010513305664, 'iteration': 4, 'loss': 0.05999999999999994, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 2, 'features__selectkbest__k': 1}), 'normalizer': ('normalizer_NoneType', {}), 'rebalance': ('rebalance_NoneType', {})}, 'score': 0.9400000000000001, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'gini', 'max_depth': 3, 'max_features': 1, 'max_leaf_nodes': 5, 'min_samples_split': 2, 'n_estimators': 25}, 'config_hash': {'algorithm': '9826d20b2d6a0f559cf7f16450ce7526f07e8434', 'config': '49f25751bca61cdd461a8cbd2923689b642f98ed', 'pipeline': '19b249664c5bf067de1fed4334a296f947ce774a'}, 'duration': 0.35647010803222656, 'iteration': 5, 'loss': 0.046666666666666634, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_NoneType', {}), 'normalizer': ('normalizer_NoneType', {}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 6})}, 'score': 0.9533333333333334, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'gini', 'max_depth': 2, 'max_features': 1, 'max_leaf_nodes': 2, 'min_samples_split': 2, 'n_estimators': 50}, 'config_hash': {'algorithm': '0a4f6fbb07e0f32c6f675489a0fc82eee05bd8e1', 'config': '5c3a2b6f5e63fb45f10e41e0318b354912ec44f6', 'pipeline': 'dc3b9f176f090005e38b142f11d80e93a7dc5d5e'}, 'duration': 0.7213859558105469, 'iteration': 6, 'loss': 0.31333333333333324, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 1, 'features__selectkbest__k': 4}), 'normalizer': ('normalizer_PowerTransformer', {}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 7})}, 'score': 0.6866666666666668, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'entropy', 'max_depth': 4, 'max_features': 3, 'max_leaf_nodes': 5, 'min_samples_split': 5, 'n_estimators': 10}, 'config_hash': {'algorithm': 'b8112b97ecfc10f00a195af661dcc861cac21289', 'config': 'd3b129b397350f1b6572651c67c01de49b4b174c', 'pipeline': '5b0357ed7072c37b3d6f458bb5d49ff7d825f603'}, 'duration': 0.8299109935760498, 'iteration': 7, 'loss': 1.0, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_PCA', {'features__n_components': 2}), 'normalizer': ('normalizer_StandardScaler', {'normalizer__with_mean': True, 'normalizer__with_std': False}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 6})}, 'score': 0.0, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'gini', 'max_depth': 4, 'max_features': None, 'max_leaf_nodes': 2, 'min_samples_split': 5, 'n_estimators': 100}, 'config_hash': {'algorithm': '40ca24df19b8d164d9d098a6bed1ce056fbbb961', 'config': '813bde1108cc3c4b9bfb3a22cbb421bda7eac671', 'pipeline': '74a7b8705a1c22f7dea5e44e4ebda8f1e48add71'}, 'duration': 2.2111589908599854, 'iteration': 8, 'loss': 0.33333333333333326, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_PCA', {'features__n_components': 2}), 'normalizer': ('normalizer_StandardScaler', {'normalizer__with_mean': False, 'normalizer__with_std': True}), 'rebalance': ('rebalance_NearMiss', {'rebalance__n_neighbors': 2})}, 'score': 0.6666666666666667, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'entropy', 'max_depth': 2, 'max_features': 1, 'max_leaf_nodes': 5, 'min_samples_split': 2, 'n_estimators': 100}, 'config_hash': {'algorithm': '331418a5c12cf1453876eef85e9d98fc8e54fa11', 'config': '31930b6860ed406d59bf7e59ba1925d94704bd3b', 'pipeline': '054bef356f90ec6f644ef3ffc688766744db51c2'}, 'duration': 1.0501940250396729, 'iteration': 9, 'loss': 0.053333333333333344, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_SelectKBest', {'features__k': 1}), 'normalizer': ('normalizer_RobustScaler', {'normalizer__quantile_range': (...), 'normalizer__with_centering': True, 'normalizer__with_scaling': True}), 'rebalance': ('rebalance_NearMiss', {'rebalance__n_neighbors': 2})}, 'score': 0.9466666666666667, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'entropy', 'max_depth': 3, 'max_features': None, 'max_leaf_nodes': 3, 'min_samples_split': 2, 'n_estimators': 100}, 'config_hash': {'algorithm': 'dbc1b8126649fe93dce5fbb37e4015b0acfb179e', 'config': '9913cd550615a9d0946ab4a755a8b9f619e442fd', 'pipeline': 'dd626121cea079ebb32e184ca65483ec7a6d7f59'}, 'duration': 1.120617151260376, 'iteration': 10, 'loss': 0.046666666666666634, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 2, 'features__selectkbest__k': 1}), 'normalizer': ('normalizer_MinMaxScaler', {}), 'rebalance': ('rebalance_NoneType', {})}, 'score': 0.9533333333333334, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'gini', 'max_depth': 3, 'max_features': 3, 'max_leaf_nodes': None, 'min_samples_split': 3, 'n_estimators': 75}, 'config_hash': {'algorithm': '34917a130df5a975f78bd7ec1a0c7b1ffdc787a9', 'config': '95fc8cadc088141290b7de9c388977e4685f0108', 'pipeline': '550d10faf2f08db48516cc3501558816d6a99bc0'}, 'duration': 1.4287099838256836, 'iteration': 11, 'loss': 0.19333333333333313, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 3, 'features__selectkbest__k': 4}), 'normalizer': ('normalizer_StandardScaler', {'normalizer__with_mean': False, 'normalizer__with_std': False}), 'rebalance': ('rebalance_CondensedNearestNeighbour', {'rebalance__n_neighbors': 1})}, 'score': 0.8066666666666669, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'entropy', 'max_depth': 1, 'max_features': 2, 'max_leaf_nodes': 5, 'min_samples_split': 2, 'n_estimators': 75}, 'config_hash': {'algorithm': '33f9abb4aee44a395a9f3b3ffa9ce80a8cdaed7c', 'config': '40fa726f0360cf6af55f9b5902d399d02f61f157', 'pipeline': 'cfd1d20841fe2153da762c95e79f95a3fb1e426a'}, 'duration': 1.2978079319000244, 'iteration': 12, 'loss': 0.053333333333333344, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_PCA', {'features__n_components': 4}), 'normalizer': ('normalizer_MinMaxScaler', {}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 7})}, 'score': 0.9466666666666667, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'entropy', 'max_depth': 4, 'max_features': 2, 'max_leaf_nodes': 5, 'min_samples_split': 3, 'n_estimators': 25}, 'config_hash': {'algorithm': '210111ec6562d09eb093e98ed69ef1c662e11a50', 'config': '0fb8e77c7bd9a58b72f1b33c21a59a09a8c676ba', 'pipeline': '5d269d759e0c7926a685a14b263ace8ae0071e4b'}, 'duration': 0.36649012565612793, 'iteration': 13, 'loss': 0.040000000000000036, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 2, 'features__selectkbest__k': 2}), 'normalizer': ('normalizer_NoneType', {}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 7})}, 'score': 0.96, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'entropy', 'max_depth': 3, 'max_features': 1, 'max_leaf_nodes': 5, 'min_samples_split': 2, 'n_estimators': 25}, 'config_hash': {'algorithm': '0e989a03980101fabf79eda3326ed2870e11d690', 'config': 'f4bffd5d8c67a9c5321a9943c4a99678f59a02b7', 'pipeline': '865ee1e3fe8334c3d5ecb2038d5a5d1b3ba50e75'}, 'duration': 0.35639500617980957, 'iteration': 14, 'loss': 0.046666666666666634, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_NoneType', {}), 'normalizer': ('normalizer_RobustScaler', {'normalizer__quantile_range': (...), 'normalizer__with_centering': True, 'normalizer__with_scaling': False}), 'rebalance': ('rebalance_NoneType', {})}, 'score': 0.9533333333333334, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'entropy', 'max_depth': None, 'max_features': 3, 'max_leaf_nodes': 3, 'min_samples_split': 5, 'n_estimators': 10}, 'config_hash': {'algorithm': '9c592e876c13de5e23e6de5b868e01755d63e72e', 'config': '1e6a68cd1eeac886d90724d78b1cb5fb76a3cde4', 'pipeline': '5a1ca4d82f21b7de0d2c918630a42510673fa36e'}, 'duration': 0.18141412734985352, 'iteration': 15, 'loss': 0.046666666666666634, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_SelectKBest', {'features__k': 3}), 'normalizer': ('normalizer_RobustScaler', {'normalizer__quantile_range': (...), 'normalizer__with_centering': True, 'normalizer__with_scaling': True}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 6})}, 'score': 0.9533333333333334, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': 1, 'max_features': None, 'max_leaf_nodes': None, 'min_samples_split': 5, 'n_estimators': 10}, 'config_hash': {'algorithm': '8bed77aef289bfd453b2858bd288ae5ba7160f2b', 'config': '781185bcb8999045de8d489f253a1a1ba4247932', 'pipeline': '1ece7eabedc2be9e5b0a1be65c570d08ffa3eb54'}, 'duration': 0.1636829376220703, 'iteration': 16, 'loss': 0.053333333333333344, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_NoneType', {}), 'normalizer': ('normalizer_NoneType', {}), 'rebalance': ('rebalance_NearMiss', {'rebalance__n_neighbors': 1})}, 'score': 0.9466666666666667, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'gini', 'max_depth': 3, 'max_features': 2, 'max_leaf_nodes': 2, 'min_samples_split': 5, 'n_estimators': 75}, 'config_hash': {'algorithm': '617b97d9ba21d3373bc51ffa9cccf9c6f91a77b3', 'config': '99fb425b4e8c5d80228cab94202252aa25cdf77c', 'pipeline': 'd6242929c3b515c7719e60423023ac604311afc3'}, 'duration': 0.8468999862670898, 'iteration': 17, 'loss': 0.24, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_PCA', {'features__n_components': 4}), 'normalizer': ('normalizer_PowerTransformer', {}), 'rebalance': ('rebalance_NearMiss', {'rebalance__n_neighbors': 2})}, 'score': 0.76, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': 1, 'max_features': 1, 'max_leaf_nodes': 2, 'min_samples_split': 5, 'n_estimators': 50}, 'config_hash': {'algorithm': 'b92d2697cdd4979da443369d6596229ec091626a', 'config': 'c513a3e13281206ad76187dd817b1fff93d54fe1', 'pipeline': 'c4b4f914a3ca8df967cade997a90366d85a371b9'}, 'duration': 0.6724588871002197, 'iteration': 18, 'loss': 0.23333333333333328, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 1, 'features__selectkbest__k': 3}), 'normalizer': ('normalizer_StandardScaler', {'normalizer__with_mean': True, 'normalizer__with_std': True}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 5})}, 'score': 0.7666666666666667, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'entropy', 'max_depth': None, 'max_features': None, 'max_leaf_nodes': 5, 'min_samples_split': 5, 'n_estimators': 10}, 'config_hash': {'algorithm': 'a0115de695e6cca2e81cbfb54df79bf4b43608b1', 'config': 'ba194015e20b5d67770e8c67342c3d8d0d01dc41', 'pipeline': '8d45fabfeb85ffdcabf7076bd0e65fffe97ce928'}, 'duration': 0.19424200057983398, 'iteration': 19, 'loss': 0.08666666666666667, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_PCA', {'features__n_components': 3}), 'normalizer': ('normalizer_NoneType', {}), 'rebalance': ('rebalance_NoneType', {})}, 'score': 0.9133333333333333, ...}, ...], 'history_hash': ['db6ac7e6d348155757e4794bb5f88fe2b4f63d50', '4db6fb84d85f52659f780e682ffac5712c3d8a94', '4403c5a85e951938d3c454e961d3a412780722f6', 'a064e2df18ab98d44dabcefbc7bed94913f1d0be', '0ddb6f5cab3db4dddd7682966a57205f3e329ad4', '49f25751bca61cdd461a8cbd2923689b642f98ed', '5c3a2b6f5e63fb45f10e41e0318b354912ec44f6', 'd3b129b397350f1b6572651c67c01de49b4b174c', '813bde1108cc3c4b9bfb3a22cbb421bda7eac671', '31930b6860ed406d59bf7e59ba1925d94704bd3b', '9913cd550615a9d0946ab4a755a8b9f619e442fd', '95fc8cadc088141290b7de9c388977e4685f0108', '40fa726f0360cf6af55f9b5902d399d02f61f157', '0fb8e77c7bd9a58b72f1b33c21a59a09a8c676ba', 'f4bffd5d8c67a9c5321a9943c4a99678f59a02b7', '1e6a68cd1eeac886d90724d78b1cb5fb76a3cde4', '781185bcb8999045de8d489f253a1a1ba4247932', '99fb425b4e8c5d80228cab94202252aa25cdf77c', 'c513a3e13281206ad76187dd817b1fff93d54fe1', 'ba194015e20b5d67770e8c67342c3d8d0d01dc41', ...], 'history_index': {'00f0493590a2cb5e98a35b29816f8cd9f87f96ec': 208, '013329309d510b94f19d930320402d65f953a847': 39, '038a0f515e2ec894ee8e34f9caa2889eb3ebd5ce': 66, '052ae4bf232b316187b078abae42c2be19e16a00': 111, '05e9258ebf99dd97202167ef1563fa834b0568f1': 242, '0659afebf316aafeb75612fb07081a04c28545ed': 74, '06e7cde9f3556cd01332ce389ad1d8925cd4b4a4': 120, '07ab8a30d853e39a326b7017026a20e94bc45541': 245, '08606f2a0f0a6c9de204020b4632e09fcee0ae56': 168, '09dbd0948e5b8c1b1f0930778babe65c8a81295e': 243, ...}, 'iteration': 297, 'max_history_score': 0.9666666666666668, 'max_history_score_std': 0.033333333333333326, 'max_history_step': 'joint'}, config={'algorithm': 'RandomForest', 'seed': 42, 'time': 300})
    108 
    109 def objective_algo(algo_config, current_pipeline_config, algorithm, X, y, context, config):
    110     return objective(current_pipeline_config, algo_config, algorithm, X, y, context, config, step='algorithm')
    111 
    112 def objective_joint(wconfig, algorithm, X, y, context, config):
--> 113     return objective(wconfig['pipeline'], wconfig['algorithm'], algorithm, X, y, context, config, step='joint')
        wconfig = {'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': 2, 'max_features': 3, 'max_leaf_nodes': 3, 'min_samples_split': 5, 'n_estimators': 10}, 'pipeline': {'features': ('features_SelectKBest', {'features__k': 2}), 'normalizer': ('normalizer_StandardScaler', {'normalizer__with_mean': True, 'normalizer__with_std': False}), 'rebalance': ('rebalance_NoneType', {})}}
        algorithm = 'RandomForest'
        X = array([[5.1, 3.5, 1.4, 0.2],
       [4.9, 3. , 1....2, 3.4, 5.4, 2.3],
       [5.9, 3. , 5.1, 1.8]])
        y = array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,... 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2])
        context = {'baseline_score': 0.9466666666666667, 'baseline_score_std': 0.04988876515698587, 'best_config': {'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': 4, 'max_features': 3, 'max_leaf_nodes': 3, 'min_samples_split': 3, 'n_estimators': 10}, 'config_hash': {'algorithm': 'ffb7ff225ce3d3712c96cf87fe42202988ee2eb0', 'config': 'bae32f426be9cd6243523c023944a8c148fe4aeb', 'pipeline': 'd2a68bfda6fcdec4ae0ffc7d7b6a2122bc1cd673'}, 'duration': 0.7115809917449951, 'iteration': 113, 'loss': 0.033333333333333215, 'max_history_score': 0.9666666666666668, 'max_history_score_std': 0.033333333333333326, 'max_history_step': 'joint', 'pipeline': {'features': ('features_NoneType', {}), 'normalizer': ('normalizer_PowerTransformer', {}), 'rebalance': ('rebalance_CondensedNearestNeighbour', {'rebalance__n_neighbors': 2})}, 'score': 0.9666666666666668, ...}, 'history': [{'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': 2, 'max_features': None, 'max_leaf_nodes': 5, 'min_samples_split': 2, 'n_estimators': 75}, 'config_hash': {'algorithm': '3af5b0cce71c8fe2545246ca24ff5bc3dd516e06', 'config': 'db6ac7e6d348155757e4794bb5f88fe2b4f63d50', 'pipeline': '8d59f4b94cef6be9306ed86a22a9570fa670d567'}, 'duration': 1.149928092956543, 'iteration': 0, 'loss': 0.046666666666666634, 'max_history_score': 0.9533333333333334, 'max_history_score_std': 0.059999999999999984, 'max_history_step': 'joint', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 4, 'features__selectkbest__k': 3}), 'normalizer': ('normalizer_StandardScaler', {'normalizer__with_mean': True, 'normalizer__with_std': True}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 6})}, 'score': 0.9533333333333334, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': 1, 'max_features': 2, 'max_leaf_nodes': 2, 'min_samples_split': 5, 'n_estimators': 100}, 'config_hash': {'algorithm': 'e13eb05fd9a62d2f63bbb1c1deff0cd620d5e6ab', 'config': '4db6fb84d85f52659f780e682ffac5712c3d8a94', 'pipeline': '64c9a1ca9d53ae67244bdd942f4db36a3c05218c'}, 'duration': 1.7678282260894775, 'iteration': 1, 'loss': 0.18000000000000005, 'max_history_score': 0.9533333333333334, 'max_history_score_std': 0.059999999999999984, 'max_history_step': 'joint', 'pipeline': {'features': ('features_NoneType', {}), 'normalizer': ('normalizer_PowerTransformer', {}), 'rebalance': ('rebalance_NearMiss', {'rebalance__n_neighbors': 1})}, 'score': 0.82, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': 1, 'max_features': None, 'max_leaf_nodes': None, 'min_samples_split': 5, 'n_estimators': 75}, 'config_hash': {'algorithm': '94b0d7a654c508cc63643f78fe4f0f07e6f07c1e', 'config': '4403c5a85e951938d3c454e961d3a412780722f6', 'pipeline': '3e47444880d8367fbac2faaba2e52a917274aa58'}, 'duration': 0.8397619724273682, 'iteration': 2, 'loss': 0.03333333333333344, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_PCA', {'features__n_components': 3}), 'normalizer': ('normalizer_MinMaxScaler', {}), 'rebalance': ('rebalance_NoneType', {})}, 'score': 0.9666666666666666, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': None, 'max_features': None, 'max_leaf_nodes': 3, 'min_samples_split': 3, 'n_estimators': 75}, 'config_hash': {'algorithm': 'e8332f0a8902bda03bf70e7978cc5d52affb29d3', 'config': 'a064e2df18ab98d44dabcefbc7bed94913f1d0be', 'pipeline': '7eea819c2a8c103c4b1e9e9c1e224aebba95081f'}, 'duration': 0.8501448631286621, 'iteration': 3, 'loss': 0.053333333333333344, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 2, 'features__selectkbest__k': 4}), 'normalizer': ('normalizer_NoneType', {}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 7})}, 'score': 0.9466666666666667, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'entropy', 'max_depth': 3, 'max_features': 3, 'max_leaf_nodes': None, 'min_samples_split': 5, 'n_estimators': 75}, 'config_hash': {'algorithm': '7a4491035bc6bd737fe9a8cda8a79a02d02d5c74', 'config': '0ddb6f5cab3db4dddd7682966a57205f3e329ad4', 'pipeline': 'a9ae03fe38334f6868cbf84cdd3d629d4bbe3fb0'}, 'duration': 1.1026010513305664, 'iteration': 4, 'loss': 0.05999999999999994, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 2, 'features__selectkbest__k': 1}), 'normalizer': ('normalizer_NoneType', {}), 'rebalance': ('rebalance_NoneType', {})}, 'score': 0.9400000000000001, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'gini', 'max_depth': 3, 'max_features': 1, 'max_leaf_nodes': 5, 'min_samples_split': 2, 'n_estimators': 25}, 'config_hash': {'algorithm': '9826d20b2d6a0f559cf7f16450ce7526f07e8434', 'config': '49f25751bca61cdd461a8cbd2923689b642f98ed', 'pipeline': '19b249664c5bf067de1fed4334a296f947ce774a'}, 'duration': 0.35647010803222656, 'iteration': 5, 'loss': 0.046666666666666634, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_NoneType', {}), 'normalizer': ('normalizer_NoneType', {}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 6})}, 'score': 0.9533333333333334, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'gini', 'max_depth': 2, 'max_features': 1, 'max_leaf_nodes': 2, 'min_samples_split': 2, 'n_estimators': 50}, 'config_hash': {'algorithm': '0a4f6fbb07e0f32c6f675489a0fc82eee05bd8e1', 'config': '5c3a2b6f5e63fb45f10e41e0318b354912ec44f6', 'pipeline': 'dc3b9f176f090005e38b142f11d80e93a7dc5d5e'}, 'duration': 0.7213859558105469, 'iteration': 6, 'loss': 0.31333333333333324, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 1, 'features__selectkbest__k': 4}), 'normalizer': ('normalizer_PowerTransformer', {}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 7})}, 'score': 0.6866666666666668, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'entropy', 'max_depth': 4, 'max_features': 3, 'max_leaf_nodes': 5, 'min_samples_split': 5, 'n_estimators': 10}, 'config_hash': {'algorithm': 'b8112b97ecfc10f00a195af661dcc861cac21289', 'config': 'd3b129b397350f1b6572651c67c01de49b4b174c', 'pipeline': '5b0357ed7072c37b3d6f458bb5d49ff7d825f603'}, 'duration': 0.8299109935760498, 'iteration': 7, 'loss': 1.0, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_PCA', {'features__n_components': 2}), 'normalizer': ('normalizer_StandardScaler', {'normalizer__with_mean': True, 'normalizer__with_std': False}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 6})}, 'score': 0.0, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'gini', 'max_depth': 4, 'max_features': None, 'max_leaf_nodes': 2, 'min_samples_split': 5, 'n_estimators': 100}, 'config_hash': {'algorithm': '40ca24df19b8d164d9d098a6bed1ce056fbbb961', 'config': '813bde1108cc3c4b9bfb3a22cbb421bda7eac671', 'pipeline': '74a7b8705a1c22f7dea5e44e4ebda8f1e48add71'}, 'duration': 2.2111589908599854, 'iteration': 8, 'loss': 0.33333333333333326, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_PCA', {'features__n_components': 2}), 'normalizer': ('normalizer_StandardScaler', {'normalizer__with_mean': False, 'normalizer__with_std': True}), 'rebalance': ('rebalance_NearMiss', {'rebalance__n_neighbors': 2})}, 'score': 0.6666666666666667, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'entropy', 'max_depth': 2, 'max_features': 1, 'max_leaf_nodes': 5, 'min_samples_split': 2, 'n_estimators': 100}, 'config_hash': {'algorithm': '331418a5c12cf1453876eef85e9d98fc8e54fa11', 'config': '31930b6860ed406d59bf7e59ba1925d94704bd3b', 'pipeline': '054bef356f90ec6f644ef3ffc688766744db51c2'}, 'duration': 1.0501940250396729, 'iteration': 9, 'loss': 0.053333333333333344, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_SelectKBest', {'features__k': 1}), 'normalizer': ('normalizer_RobustScaler', {'normalizer__quantile_range': (...), 'normalizer__with_centering': True, 'normalizer__with_scaling': True}), 'rebalance': ('rebalance_NearMiss', {'rebalance__n_neighbors': 2})}, 'score': 0.9466666666666667, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'entropy', 'max_depth': 3, 'max_features': None, 'max_leaf_nodes': 3, 'min_samples_split': 2, 'n_estimators': 100}, 'config_hash': {'algorithm': 'dbc1b8126649fe93dce5fbb37e4015b0acfb179e', 'config': '9913cd550615a9d0946ab4a755a8b9f619e442fd', 'pipeline': 'dd626121cea079ebb32e184ca65483ec7a6d7f59'}, 'duration': 1.120617151260376, 'iteration': 10, 'loss': 0.046666666666666634, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 2, 'features__selectkbest__k': 1}), 'normalizer': ('normalizer_MinMaxScaler', {}), 'rebalance': ('rebalance_NoneType', {})}, 'score': 0.9533333333333334, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'gini', 'max_depth': 3, 'max_features': 3, 'max_leaf_nodes': None, 'min_samples_split': 3, 'n_estimators': 75}, 'config_hash': {'algorithm': '34917a130df5a975f78bd7ec1a0c7b1ffdc787a9', 'config': '95fc8cadc088141290b7de9c388977e4685f0108', 'pipeline': '550d10faf2f08db48516cc3501558816d6a99bc0'}, 'duration': 1.4287099838256836, 'iteration': 11, 'loss': 0.19333333333333313, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 3, 'features__selectkbest__k': 4}), 'normalizer': ('normalizer_StandardScaler', {'normalizer__with_mean': False, 'normalizer__with_std': False}), 'rebalance': ('rebalance_CondensedNearestNeighbour', {'rebalance__n_neighbors': 1})}, 'score': 0.8066666666666669, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'entropy', 'max_depth': 1, 'max_features': 2, 'max_leaf_nodes': 5, 'min_samples_split': 2, 'n_estimators': 75}, 'config_hash': {'algorithm': '33f9abb4aee44a395a9f3b3ffa9ce80a8cdaed7c', 'config': '40fa726f0360cf6af55f9b5902d399d02f61f157', 'pipeline': 'cfd1d20841fe2153da762c95e79f95a3fb1e426a'}, 'duration': 1.2978079319000244, 'iteration': 12, 'loss': 0.053333333333333344, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_PCA', {'features__n_components': 4}), 'normalizer': ('normalizer_MinMaxScaler', {}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 7})}, 'score': 0.9466666666666667, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'entropy', 'max_depth': 4, 'max_features': 2, 'max_leaf_nodes': 5, 'min_samples_split': 3, 'n_estimators': 25}, 'config_hash': {'algorithm': '210111ec6562d09eb093e98ed69ef1c662e11a50', 'config': '0fb8e77c7bd9a58b72f1b33c21a59a09a8c676ba', 'pipeline': '5d269d759e0c7926a685a14b263ace8ae0071e4b'}, 'duration': 0.36649012565612793, 'iteration': 13, 'loss': 0.040000000000000036, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 2, 'features__selectkbest__k': 2}), 'normalizer': ('normalizer_NoneType', {}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 7})}, 'score': 0.96, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'entropy', 'max_depth': 3, 'max_features': 1, 'max_leaf_nodes': 5, 'min_samples_split': 2, 'n_estimators': 25}, 'config_hash': {'algorithm': '0e989a03980101fabf79eda3326ed2870e11d690', 'config': 'f4bffd5d8c67a9c5321a9943c4a99678f59a02b7', 'pipeline': '865ee1e3fe8334c3d5ecb2038d5a5d1b3ba50e75'}, 'duration': 0.35639500617980957, 'iteration': 14, 'loss': 0.046666666666666634, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_NoneType', {}), 'normalizer': ('normalizer_RobustScaler', {'normalizer__quantile_range': (...), 'normalizer__with_centering': True, 'normalizer__with_scaling': False}), 'rebalance': ('rebalance_NoneType', {})}, 'score': 0.9533333333333334, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'entropy', 'max_depth': None, 'max_features': 3, 'max_leaf_nodes': 3, 'min_samples_split': 5, 'n_estimators': 10}, 'config_hash': {'algorithm': '9c592e876c13de5e23e6de5b868e01755d63e72e', 'config': '1e6a68cd1eeac886d90724d78b1cb5fb76a3cde4', 'pipeline': '5a1ca4d82f21b7de0d2c918630a42510673fa36e'}, 'duration': 0.18141412734985352, 'iteration': 15, 'loss': 0.046666666666666634, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_SelectKBest', {'features__k': 3}), 'normalizer': ('normalizer_RobustScaler', {'normalizer__quantile_range': (...), 'normalizer__with_centering': True, 'normalizer__with_scaling': True}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 6})}, 'score': 0.9533333333333334, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': 1, 'max_features': None, 'max_leaf_nodes': None, 'min_samples_split': 5, 'n_estimators': 10}, 'config_hash': {'algorithm': '8bed77aef289bfd453b2858bd288ae5ba7160f2b', 'config': '781185bcb8999045de8d489f253a1a1ba4247932', 'pipeline': '1ece7eabedc2be9e5b0a1be65c570d08ffa3eb54'}, 'duration': 0.1636829376220703, 'iteration': 16, 'loss': 0.053333333333333344, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_NoneType', {}), 'normalizer': ('normalizer_NoneType', {}), 'rebalance': ('rebalance_NearMiss', {'rebalance__n_neighbors': 1})}, 'score': 0.9466666666666667, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'gini', 'max_depth': 3, 'max_features': 2, 'max_leaf_nodes': 2, 'min_samples_split': 5, 'n_estimators': 75}, 'config_hash': {'algorithm': '617b97d9ba21d3373bc51ffa9cccf9c6f91a77b3', 'config': '99fb425b4e8c5d80228cab94202252aa25cdf77c', 'pipeline': 'd6242929c3b515c7719e60423023ac604311afc3'}, 'duration': 0.8468999862670898, 'iteration': 17, 'loss': 0.24, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_PCA', {'features__n_components': 4}), 'normalizer': ('normalizer_PowerTransformer', {}), 'rebalance': ('rebalance_NearMiss', {'rebalance__n_neighbors': 2})}, 'score': 0.76, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': 1, 'max_features': 1, 'max_leaf_nodes': 2, 'min_samples_split': 5, 'n_estimators': 50}, 'config_hash': {'algorithm': 'b92d2697cdd4979da443369d6596229ec091626a', 'config': 'c513a3e13281206ad76187dd817b1fff93d54fe1', 'pipeline': 'c4b4f914a3ca8df967cade997a90366d85a371b9'}, 'duration': 0.6724588871002197, 'iteration': 18, 'loss': 0.23333333333333328, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 1, 'features__selectkbest__k': 3}), 'normalizer': ('normalizer_StandardScaler', {'normalizer__with_mean': True, 'normalizer__with_std': True}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 5})}, 'score': 0.7666666666666667, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'entropy', 'max_depth': None, 'max_features': None, 'max_leaf_nodes': 5, 'min_samples_split': 5, 'n_estimators': 10}, 'config_hash': {'algorithm': 'a0115de695e6cca2e81cbfb54df79bf4b43608b1', 'config': 'ba194015e20b5d67770e8c67342c3d8d0d01dc41', 'pipeline': '8d45fabfeb85ffdcabf7076bd0e65fffe97ce928'}, 'duration': 0.19424200057983398, 'iteration': 19, 'loss': 0.08666666666666667, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_PCA', {'features__n_components': 3}), 'normalizer': ('normalizer_NoneType', {}), 'rebalance': ('rebalance_NoneType', {})}, 'score': 0.9133333333333333, ...}, ...], 'history_hash': ['db6ac7e6d348155757e4794bb5f88fe2b4f63d50', '4db6fb84d85f52659f780e682ffac5712c3d8a94', '4403c5a85e951938d3c454e961d3a412780722f6', 'a064e2df18ab98d44dabcefbc7bed94913f1d0be', '0ddb6f5cab3db4dddd7682966a57205f3e329ad4', '49f25751bca61cdd461a8cbd2923689b642f98ed', '5c3a2b6f5e63fb45f10e41e0318b354912ec44f6', 'd3b129b397350f1b6572651c67c01de49b4b174c', '813bde1108cc3c4b9bfb3a22cbb421bda7eac671', '31930b6860ed406d59bf7e59ba1925d94704bd3b', '9913cd550615a9d0946ab4a755a8b9f619e442fd', '95fc8cadc088141290b7de9c388977e4685f0108', '40fa726f0360cf6af55f9b5902d399d02f61f157', '0fb8e77c7bd9a58b72f1b33c21a59a09a8c676ba', 'f4bffd5d8c67a9c5321a9943c4a99678f59a02b7', '1e6a68cd1eeac886d90724d78b1cb5fb76a3cde4', '781185bcb8999045de8d489f253a1a1ba4247932', '99fb425b4e8c5d80228cab94202252aa25cdf77c', 'c513a3e13281206ad76187dd817b1fff93d54fe1', 'ba194015e20b5d67770e8c67342c3d8d0d01dc41', ...], 'history_index': {'00f0493590a2cb5e98a35b29816f8cd9f87f96ec': 208, '013329309d510b94f19d930320402d65f953a847': 39, '038a0f515e2ec894ee8e34f9caa2889eb3ebd5ce': 66, '052ae4bf232b316187b078abae42c2be19e16a00': 111, '05e9258ebf99dd97202167ef1563fa834b0568f1': 242, '0659afebf316aafeb75612fb07081a04c28545ed': 74, '06e7cde9f3556cd01332ce389ad1d8925cd4b4a4': 120, '07ab8a30d853e39a326b7017026a20e94bc45541': 245, '08606f2a0f0a6c9de204020b4632e09fcee0ae56': 168, '09dbd0948e5b8c1b1f0930778babe65c8a81295e': 243, ...}, 'iteration': 297, 'max_history_score': 0.9666666666666668, 'max_history_score_std': 0.033333333333333326, 'max_history_step': 'joint'}
        config = {'algorithm': 'RandomForest', 'seed': 42, 'time': 300}
    114 
    115 
    116 def get_baseline_score(algorithm, X, y, seed):
    117     pipeline, _ = pipeline_conf_to_full_pipeline(

...........................................................................
/home/aquemy/dev/dp_hyperparameters/extension/experiment/objective.py in objective(pipeline_config={'features': ('features_SelectKBest', {'features__k': 2}), 'normalizer': ('normalizer_StandardScaler', {'normalizer__with_mean': True, 'normalizer__with_std': False}), 'rebalance': ('rebalance_NoneType', {})}, algo_config={'bootstrap': True, 'criterion': 'gini', 'max_depth': 2, 'max_features': 3, 'max_leaf_nodes': 3, 'min_samples_split': 5, 'n_estimators': 10}, algorithm='RandomForest', X=array([[5.1, 3.5, 1.4, 0.2],
       [4.9, 3. , 1....2, 3.4, 5.4, 2.3],
       [5.9, 3. , 5.1, 1.8]]), y=array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,... 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]), context={'baseline_score': 0.9466666666666667, 'baseline_score_std': 0.04988876515698587, 'best_config': {'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': 4, 'max_features': 3, 'max_leaf_nodes': 3, 'min_samples_split': 3, 'n_estimators': 10}, 'config_hash': {'algorithm': 'ffb7ff225ce3d3712c96cf87fe42202988ee2eb0', 'config': 'bae32f426be9cd6243523c023944a8c148fe4aeb', 'pipeline': 'd2a68bfda6fcdec4ae0ffc7d7b6a2122bc1cd673'}, 'duration': 0.7115809917449951, 'iteration': 113, 'loss': 0.033333333333333215, 'max_history_score': 0.9666666666666668, 'max_history_score_std': 0.033333333333333326, 'max_history_step': 'joint', 'pipeline': {'features': ('features_NoneType', {}), 'normalizer': ('normalizer_PowerTransformer', {}), 'rebalance': ('rebalance_CondensedNearestNeighbour', {'rebalance__n_neighbors': 2})}, 'score': 0.9666666666666668, ...}, 'history': [{'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': 2, 'max_features': None, 'max_leaf_nodes': 5, 'min_samples_split': 2, 'n_estimators': 75}, 'config_hash': {'algorithm': '3af5b0cce71c8fe2545246ca24ff5bc3dd516e06', 'config': 'db6ac7e6d348155757e4794bb5f88fe2b4f63d50', 'pipeline': '8d59f4b94cef6be9306ed86a22a9570fa670d567'}, 'duration': 1.149928092956543, 'iteration': 0, 'loss': 0.046666666666666634, 'max_history_score': 0.9533333333333334, 'max_history_score_std': 0.059999999999999984, 'max_history_step': 'joint', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 4, 'features__selectkbest__k': 3}), 'normalizer': ('normalizer_StandardScaler', {'normalizer__with_mean': True, 'normalizer__with_std': True}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 6})}, 'score': 0.9533333333333334, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': 1, 'max_features': 2, 'max_leaf_nodes': 2, 'min_samples_split': 5, 'n_estimators': 100}, 'config_hash': {'algorithm': 'e13eb05fd9a62d2f63bbb1c1deff0cd620d5e6ab', 'config': '4db6fb84d85f52659f780e682ffac5712c3d8a94', 'pipeline': '64c9a1ca9d53ae67244bdd942f4db36a3c05218c'}, 'duration': 1.7678282260894775, 'iteration': 1, 'loss': 0.18000000000000005, 'max_history_score': 0.9533333333333334, 'max_history_score_std': 0.059999999999999984, 'max_history_step': 'joint', 'pipeline': {'features': ('features_NoneType', {}), 'normalizer': ('normalizer_PowerTransformer', {}), 'rebalance': ('rebalance_NearMiss', {'rebalance__n_neighbors': 1})}, 'score': 0.82, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': 1, 'max_features': None, 'max_leaf_nodes': None, 'min_samples_split': 5, 'n_estimators': 75}, 'config_hash': {'algorithm': '94b0d7a654c508cc63643f78fe4f0f07e6f07c1e', 'config': '4403c5a85e951938d3c454e961d3a412780722f6', 'pipeline': '3e47444880d8367fbac2faaba2e52a917274aa58'}, 'duration': 0.8397619724273682, 'iteration': 2, 'loss': 0.03333333333333344, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_PCA', {'features__n_components': 3}), 'normalizer': ('normalizer_MinMaxScaler', {}), 'rebalance': ('rebalance_NoneType', {})}, 'score': 0.9666666666666666, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': None, 'max_features': None, 'max_leaf_nodes': 3, 'min_samples_split': 3, 'n_estimators': 75}, 'config_hash': {'algorithm': 'e8332f0a8902bda03bf70e7978cc5d52affb29d3', 'config': 'a064e2df18ab98d44dabcefbc7bed94913f1d0be', 'pipeline': '7eea819c2a8c103c4b1e9e9c1e224aebba95081f'}, 'duration': 0.8501448631286621, 'iteration': 3, 'loss': 0.053333333333333344, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 2, 'features__selectkbest__k': 4}), 'normalizer': ('normalizer_NoneType', {}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 7})}, 'score': 0.9466666666666667, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'entropy', 'max_depth': 3, 'max_features': 3, 'max_leaf_nodes': None, 'min_samples_split': 5, 'n_estimators': 75}, 'config_hash': {'algorithm': '7a4491035bc6bd737fe9a8cda8a79a02d02d5c74', 'config': '0ddb6f5cab3db4dddd7682966a57205f3e329ad4', 'pipeline': 'a9ae03fe38334f6868cbf84cdd3d629d4bbe3fb0'}, 'duration': 1.1026010513305664, 'iteration': 4, 'loss': 0.05999999999999994, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 2, 'features__selectkbest__k': 1}), 'normalizer': ('normalizer_NoneType', {}), 'rebalance': ('rebalance_NoneType', {})}, 'score': 0.9400000000000001, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'gini', 'max_depth': 3, 'max_features': 1, 'max_leaf_nodes': 5, 'min_samples_split': 2, 'n_estimators': 25}, 'config_hash': {'algorithm': '9826d20b2d6a0f559cf7f16450ce7526f07e8434', 'config': '49f25751bca61cdd461a8cbd2923689b642f98ed', 'pipeline': '19b249664c5bf067de1fed4334a296f947ce774a'}, 'duration': 0.35647010803222656, 'iteration': 5, 'loss': 0.046666666666666634, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_NoneType', {}), 'normalizer': ('normalizer_NoneType', {}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 6})}, 'score': 0.9533333333333334, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'gini', 'max_depth': 2, 'max_features': 1, 'max_leaf_nodes': 2, 'min_samples_split': 2, 'n_estimators': 50}, 'config_hash': {'algorithm': '0a4f6fbb07e0f32c6f675489a0fc82eee05bd8e1', 'config': '5c3a2b6f5e63fb45f10e41e0318b354912ec44f6', 'pipeline': 'dc3b9f176f090005e38b142f11d80e93a7dc5d5e'}, 'duration': 0.7213859558105469, 'iteration': 6, 'loss': 0.31333333333333324, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 1, 'features__selectkbest__k': 4}), 'normalizer': ('normalizer_PowerTransformer', {}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 7})}, 'score': 0.6866666666666668, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'entropy', 'max_depth': 4, 'max_features': 3, 'max_leaf_nodes': 5, 'min_samples_split': 5, 'n_estimators': 10}, 'config_hash': {'algorithm': 'b8112b97ecfc10f00a195af661dcc861cac21289', 'config': 'd3b129b397350f1b6572651c67c01de49b4b174c', 'pipeline': '5b0357ed7072c37b3d6f458bb5d49ff7d825f603'}, 'duration': 0.8299109935760498, 'iteration': 7, 'loss': 1.0, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_PCA', {'features__n_components': 2}), 'normalizer': ('normalizer_StandardScaler', {'normalizer__with_mean': True, 'normalizer__with_std': False}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 6})}, 'score': 0.0, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'gini', 'max_depth': 4, 'max_features': None, 'max_leaf_nodes': 2, 'min_samples_split': 5, 'n_estimators': 100}, 'config_hash': {'algorithm': '40ca24df19b8d164d9d098a6bed1ce056fbbb961', 'config': '813bde1108cc3c4b9bfb3a22cbb421bda7eac671', 'pipeline': '74a7b8705a1c22f7dea5e44e4ebda8f1e48add71'}, 'duration': 2.2111589908599854, 'iteration': 8, 'loss': 0.33333333333333326, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_PCA', {'features__n_components': 2}), 'normalizer': ('normalizer_StandardScaler', {'normalizer__with_mean': False, 'normalizer__with_std': True}), 'rebalance': ('rebalance_NearMiss', {'rebalance__n_neighbors': 2})}, 'score': 0.6666666666666667, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'entropy', 'max_depth': 2, 'max_features': 1, 'max_leaf_nodes': 5, 'min_samples_split': 2, 'n_estimators': 100}, 'config_hash': {'algorithm': '331418a5c12cf1453876eef85e9d98fc8e54fa11', 'config': '31930b6860ed406d59bf7e59ba1925d94704bd3b', 'pipeline': '054bef356f90ec6f644ef3ffc688766744db51c2'}, 'duration': 1.0501940250396729, 'iteration': 9, 'loss': 0.053333333333333344, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_SelectKBest', {'features__k': 1}), 'normalizer': ('normalizer_RobustScaler', {'normalizer__quantile_range': (...), 'normalizer__with_centering': True, 'normalizer__with_scaling': True}), 'rebalance': ('rebalance_NearMiss', {'rebalance__n_neighbors': 2})}, 'score': 0.9466666666666667, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'entropy', 'max_depth': 3, 'max_features': None, 'max_leaf_nodes': 3, 'min_samples_split': 2, 'n_estimators': 100}, 'config_hash': {'algorithm': 'dbc1b8126649fe93dce5fbb37e4015b0acfb179e', 'config': '9913cd550615a9d0946ab4a755a8b9f619e442fd', 'pipeline': 'dd626121cea079ebb32e184ca65483ec7a6d7f59'}, 'duration': 1.120617151260376, 'iteration': 10, 'loss': 0.046666666666666634, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 2, 'features__selectkbest__k': 1}), 'normalizer': ('normalizer_MinMaxScaler', {}), 'rebalance': ('rebalance_NoneType', {})}, 'score': 0.9533333333333334, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'gini', 'max_depth': 3, 'max_features': 3, 'max_leaf_nodes': None, 'min_samples_split': 3, 'n_estimators': 75}, 'config_hash': {'algorithm': '34917a130df5a975f78bd7ec1a0c7b1ffdc787a9', 'config': '95fc8cadc088141290b7de9c388977e4685f0108', 'pipeline': '550d10faf2f08db48516cc3501558816d6a99bc0'}, 'duration': 1.4287099838256836, 'iteration': 11, 'loss': 0.19333333333333313, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 3, 'features__selectkbest__k': 4}), 'normalizer': ('normalizer_StandardScaler', {'normalizer__with_mean': False, 'normalizer__with_std': False}), 'rebalance': ('rebalance_CondensedNearestNeighbour', {'rebalance__n_neighbors': 1})}, 'score': 0.8066666666666669, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'entropy', 'max_depth': 1, 'max_features': 2, 'max_leaf_nodes': 5, 'min_samples_split': 2, 'n_estimators': 75}, 'config_hash': {'algorithm': '33f9abb4aee44a395a9f3b3ffa9ce80a8cdaed7c', 'config': '40fa726f0360cf6af55f9b5902d399d02f61f157', 'pipeline': 'cfd1d20841fe2153da762c95e79f95a3fb1e426a'}, 'duration': 1.2978079319000244, 'iteration': 12, 'loss': 0.053333333333333344, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_PCA', {'features__n_components': 4}), 'normalizer': ('normalizer_MinMaxScaler', {}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 7})}, 'score': 0.9466666666666667, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'entropy', 'max_depth': 4, 'max_features': 2, 'max_leaf_nodes': 5, 'min_samples_split': 3, 'n_estimators': 25}, 'config_hash': {'algorithm': '210111ec6562d09eb093e98ed69ef1c662e11a50', 'config': '0fb8e77c7bd9a58b72f1b33c21a59a09a8c676ba', 'pipeline': '5d269d759e0c7926a685a14b263ace8ae0071e4b'}, 'duration': 0.36649012565612793, 'iteration': 13, 'loss': 0.040000000000000036, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 2, 'features__selectkbest__k': 2}), 'normalizer': ('normalizer_NoneType', {}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 7})}, 'score': 0.96, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'entropy', 'max_depth': 3, 'max_features': 1, 'max_leaf_nodes': 5, 'min_samples_split': 2, 'n_estimators': 25}, 'config_hash': {'algorithm': '0e989a03980101fabf79eda3326ed2870e11d690', 'config': 'f4bffd5d8c67a9c5321a9943c4a99678f59a02b7', 'pipeline': '865ee1e3fe8334c3d5ecb2038d5a5d1b3ba50e75'}, 'duration': 0.35639500617980957, 'iteration': 14, 'loss': 0.046666666666666634, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_NoneType', {}), 'normalizer': ('normalizer_RobustScaler', {'normalizer__quantile_range': (...), 'normalizer__with_centering': True, 'normalizer__with_scaling': False}), 'rebalance': ('rebalance_NoneType', {})}, 'score': 0.9533333333333334, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'entropy', 'max_depth': None, 'max_features': 3, 'max_leaf_nodes': 3, 'min_samples_split': 5, 'n_estimators': 10}, 'config_hash': {'algorithm': '9c592e876c13de5e23e6de5b868e01755d63e72e', 'config': '1e6a68cd1eeac886d90724d78b1cb5fb76a3cde4', 'pipeline': '5a1ca4d82f21b7de0d2c918630a42510673fa36e'}, 'duration': 0.18141412734985352, 'iteration': 15, 'loss': 0.046666666666666634, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_SelectKBest', {'features__k': 3}), 'normalizer': ('normalizer_RobustScaler', {'normalizer__quantile_range': (...), 'normalizer__with_centering': True, 'normalizer__with_scaling': True}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 6})}, 'score': 0.9533333333333334, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': 1, 'max_features': None, 'max_leaf_nodes': None, 'min_samples_split': 5, 'n_estimators': 10}, 'config_hash': {'algorithm': '8bed77aef289bfd453b2858bd288ae5ba7160f2b', 'config': '781185bcb8999045de8d489f253a1a1ba4247932', 'pipeline': '1ece7eabedc2be9e5b0a1be65c570d08ffa3eb54'}, 'duration': 0.1636829376220703, 'iteration': 16, 'loss': 0.053333333333333344, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_NoneType', {}), 'normalizer': ('normalizer_NoneType', {}), 'rebalance': ('rebalance_NearMiss', {'rebalance__n_neighbors': 1})}, 'score': 0.9466666666666667, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'gini', 'max_depth': 3, 'max_features': 2, 'max_leaf_nodes': 2, 'min_samples_split': 5, 'n_estimators': 75}, 'config_hash': {'algorithm': '617b97d9ba21d3373bc51ffa9cccf9c6f91a77b3', 'config': '99fb425b4e8c5d80228cab94202252aa25cdf77c', 'pipeline': 'd6242929c3b515c7719e60423023ac604311afc3'}, 'duration': 0.8468999862670898, 'iteration': 17, 'loss': 0.24, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_PCA', {'features__n_components': 4}), 'normalizer': ('normalizer_PowerTransformer', {}), 'rebalance': ('rebalance_NearMiss', {'rebalance__n_neighbors': 2})}, 'score': 0.76, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': 1, 'max_features': 1, 'max_leaf_nodes': 2, 'min_samples_split': 5, 'n_estimators': 50}, 'config_hash': {'algorithm': 'b92d2697cdd4979da443369d6596229ec091626a', 'config': 'c513a3e13281206ad76187dd817b1fff93d54fe1', 'pipeline': 'c4b4f914a3ca8df967cade997a90366d85a371b9'}, 'duration': 0.6724588871002197, 'iteration': 18, 'loss': 0.23333333333333328, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 1, 'features__selectkbest__k': 3}), 'normalizer': ('normalizer_StandardScaler', {'normalizer__with_mean': True, 'normalizer__with_std': True}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 5})}, 'score': 0.7666666666666667, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'entropy', 'max_depth': None, 'max_features': None, 'max_leaf_nodes': 5, 'min_samples_split': 5, 'n_estimators': 10}, 'config_hash': {'algorithm': 'a0115de695e6cca2e81cbfb54df79bf4b43608b1', 'config': 'ba194015e20b5d67770e8c67342c3d8d0d01dc41', 'pipeline': '8d45fabfeb85ffdcabf7076bd0e65fffe97ce928'}, 'duration': 0.19424200057983398, 'iteration': 19, 'loss': 0.08666666666666667, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_PCA', {'features__n_components': 3}), 'normalizer': ('normalizer_NoneType', {}), 'rebalance': ('rebalance_NoneType', {})}, 'score': 0.9133333333333333, ...}, ...], 'history_hash': ['db6ac7e6d348155757e4794bb5f88fe2b4f63d50', '4db6fb84d85f52659f780e682ffac5712c3d8a94', '4403c5a85e951938d3c454e961d3a412780722f6', 'a064e2df18ab98d44dabcefbc7bed94913f1d0be', '0ddb6f5cab3db4dddd7682966a57205f3e329ad4', '49f25751bca61cdd461a8cbd2923689b642f98ed', '5c3a2b6f5e63fb45f10e41e0318b354912ec44f6', 'd3b129b397350f1b6572651c67c01de49b4b174c', '813bde1108cc3c4b9bfb3a22cbb421bda7eac671', '31930b6860ed406d59bf7e59ba1925d94704bd3b', '9913cd550615a9d0946ab4a755a8b9f619e442fd', '95fc8cadc088141290b7de9c388977e4685f0108', '40fa726f0360cf6af55f9b5902d399d02f61f157', '0fb8e77c7bd9a58b72f1b33c21a59a09a8c676ba', 'f4bffd5d8c67a9c5321a9943c4a99678f59a02b7', '1e6a68cd1eeac886d90724d78b1cb5fb76a3cde4', '781185bcb8999045de8d489f253a1a1ba4247932', '99fb425b4e8c5d80228cab94202252aa25cdf77c', 'c513a3e13281206ad76187dd817b1fff93d54fe1', 'ba194015e20b5d67770e8c67342c3d8d0d01dc41', ...], 'history_index': {'00f0493590a2cb5e98a35b29816f8cd9f87f96ec': 208, '013329309d510b94f19d930320402d65f953a847': 39, '038a0f515e2ec894ee8e34f9caa2889eb3ebd5ce': 66, '052ae4bf232b316187b078abae42c2be19e16a00': 111, '05e9258ebf99dd97202167ef1563fa834b0568f1': 242, '0659afebf316aafeb75612fb07081a04c28545ed': 74, '06e7cde9f3556cd01332ce389ad1d8925cd4b4a4': 120, '07ab8a30d853e39a326b7017026a20e94bc45541': 245, '08606f2a0f0a6c9de204020b4632e09fcee0ae56': 168, '09dbd0948e5b8c1b1f0930778babe65c8a81295e': 243, ...}, 'iteration': 297, 'max_history_score': 0.9666666666666668, 'max_history_score_std': 0.033333333333333326, 'max_history_step': 'joint'}, config={'algorithm': 'RandomForest', 'seed': 42, 'time': 300}, step='joint')
     45                 y,
     46                 cv=10,
     47                 n_jobs=-1,
     48                 return_estimator=False,
     49                 return_train_score=False,
---> 50                 verbose=0)
     51         score = np.mean(scores['test_score'])
     52         std = np.std(scores['test_score'])
     53         status = STATUS_OK
     54     except Exception as e:

...........................................................................
/home/aquemy/.local/lib/python2.7/site-packages/sklearn/model_selection/_validation.py in cross_validate(estimator=Pipeline(memory=None,
     steps=[('normalizer',... random_state=42, verbose=0, warm_start=False))]), X=array([[5.1, 3.5, 1.4, 0.2],
       [4.9, 3. , 1....2, 3.4, 5.4, 2.3],
       [5.9, 3. , 5.1, 1.8]]), y=array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,... 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]), groups=None, scoring=None, cv=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1, verbose=0, fit_params=None, pre_dispatch='2*n_jobs', return_train_score=False, return_estimator=False, error_score='raise-deprecating')
    235         delayed(_fit_and_score)(
    236             clone(estimator), X, y, scorers, train, test, verbose, None,
    237             fit_params, return_train_score=return_train_score,
    238             return_times=True, return_estimator=return_estimator,
    239             error_score=error_score)
--> 240         for train, test in cv.split(X, y, groups))
        cv.split = <bound method StratifiedKFold.split of Stratifie...d(n_splits=10, random_state=None, shuffle=False)>
        X = array([[5.1, 3.5, 1.4, 0.2],
       [4.9, 3. , 1....2, 3.4, 5.4, 2.3],
       [5.9, 3. , 5.1, 1.8]])
        y = array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,... 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2])
        groups = None
    241 
    242     zipped_scores = list(zip(*scores))
    243     if return_train_score:
    244         train_scores = zipped_scores.pop(0)

...........................................................................
/home/aquemy/.local/lib/python2.7/site-packages/sklearn/externals/joblib/parallel.py in __call__(self=Parallel(n_jobs=-1), iterable=<generator object <genexpr>>)
    925                 # No need to wait for async callbacks to trigger to
    926                 # consumption.
    927                 self._iterating = False
    928 
    929             with self._backend.retrieval_context():
--> 930                 self.retrieve()
        self.retrieve = <bound method Parallel.retrieve of Parallel(n_jobs=-1)>
    931             # Make sure that we get a last message telling us we are done
    932             elapsed_time = time.time() - self._start_time
    933             self._print('Done %3i out of %3i | elapsed: %s finished',
    934                         (len(self._output), len(self._output),

---------------------------------------------------------------------------
Joblib worker traceback:
---------------------------------------------------------------------------
ValueError                                         Mon Jun 17 13:14:34 2019
PID: 21844                                  Python 2.7.15+: /usr/bin/python
...........................................................................
/home/aquemy/.local/lib/python2.7/site-packages/sklearn/externals/joblib/parallel.py in __call__(self=<sklearn.externals.joblib.parallel.BatchedCalls object>)
    220     def __call__(self):
    221         # Set the default nested backend to self._backend but do not set the
    222         # change the default number of processes to -1
    223         with parallel_backend(self._backend, n_jobs=self._n_jobs):
    224             return [func(*args, **kwargs)
--> 225                     for func, args, kwargs in self.items]
        func = <function _fit_and_score>
        args = (Pipeline(memory=None,
     steps=[('normalizer',... random_state=42, verbose=0, warm_start=False))]), array([[5.1, 3.5, 1.4, 0.2],
       [4.9, 3. , 1....2, 3.4, 5.4, 2.3],
       [5.9, 3. , 5.1, 1.8]]), array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,... 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]), {'score': <function _passthrough_scorer>}, array([  5,   6,   7,   8,   9,  10,  11,  12,  ..., 142, 143, 144,
       145, 146, 147, 148, 149]), array([  0,   1,   2,   3,   4,  50,  51,  52,  53,  54, 100, 101, 102,
       103, 104]), 0, None, None)
        kwargs = {'error_score': 'raise-deprecating', 'return_estimator': False, 'return_times': True, 'return_train_score': False}
        self.items = [(<function _fit_and_score>, (Pipeline(memory=None,
     steps=[('normalizer',... random_state=42, verbose=0, warm_start=False))]), array([[5.1, 3.5, 1.4, 0.2],
       [4.9, 3. , 1....2, 3.4, 5.4, 2.3],
       [5.9, 3. , 5.1, 1.8]]), array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,... 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]), {'score': <function _passthrough_scorer>}, array([  5,   6,   7,   8,   9,  10,  11,  12,  ..., 142, 143, 144,
       145, 146, 147, 148, 149]), array([  0,   1,   2,   3,   4,  50,  51,  52,  53,  54, 100, 101, 102,
       103, 104]), 0, None, None), {'error_score': 'raise-deprecating', 'return_estimator': False, 'return_times': True, 'return_train_score': False})]
    226 
    227     def __len__(self):
    228         return self._size
    229 

...........................................................................
/home/aquemy/.local/lib/python2.7/site-packages/sklearn/model_selection/_validation.py in _fit_and_score(estimator=Pipeline(memory=None,
     steps=[('normalizer',... random_state=42, verbose=0, warm_start=False))]), X=array([[5.1, 3.5, 1.4, 0.2],
       [4.9, 3. , 1....2, 3.4, 5.4, 2.3],
       [5.9, 3. , 5.1, 1.8]]), y=array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,... 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]), scorer={'score': <function _passthrough_scorer>}, train=array([  5,   6,   7,   8,   9,  10,  11,  12,  ..., 142, 143, 144,
       145, 146, 147, 148, 149]), test=array([  0,   1,   2,   3,   4,  50,  51,  52,  53,  54, 100, 101, 102,
       103, 104]), verbose=0, parameters=None, fit_params={}, return_train_score=False, return_parameters=False, return_n_test_samples=False, return_times=True, return_estimator=False, error_score='raise-deprecating')
    523 
    524     try:
    525         if y_train is None:
    526             estimator.fit(X_train, **fit_params)
    527         else:
--> 528             estimator.fit(X_train, y_train, **fit_params)
        estimator.fit = <bound method Pipeline.fit of Pipeline(memory=No...random_state=42, verbose=0, warm_start=False))])>
        X_train = array([[5.4, 3.9, 1.7, 0.4],
       [4.6, 3.4, 1....2, 3.4, 5.4, 2.3],
       [5.9, 3. , 5.1, 1.8]])
        y_train = array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,
       2, 2, 2])
        fit_params = {}
    529 
    530     except Exception as e:
    531         # Note fit time as time until error
    532         fit_time = time.time() - start_time

...........................................................................
/usr/local/lib/python2.7/dist-packages/imblearn/pipeline.py in fit(self=Pipeline(memory=None,
     steps=[('normalizer',... random_state=42, verbose=0, warm_start=False))]), X=array([[5.4, 3.9, 1.7, 0.4],
       [4.6, 3.4, 1....2, 3.4, 5.4, 2.3],
       [5.9, 3. , 5.1, 1.8]]), y=array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,
       2, 2, 2]), **fit_params={})
    234             This estimator
    235 
    236         """
    237         Xt, yt, fit_params = self._fit(X, y, **fit_params)
    238         if self._final_estimator is not None:
--> 239             self._final_estimator.fit(Xt, yt, **fit_params)
        self._final_estimator.fit = <bound method RandomForestClassifier.fit of Rand...e, random_state=42, verbose=0, warm_start=False)>
        Xt = array([[-2.04518519, -0.79407407],
       [-2.34... 1.10592593],
       [ 1.35481481,  0.60592593]])
        yt = array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,
       2, 2, 2])
        fit_params = {}
    240         return self
    241 
    242     def fit_transform(self, X, y=None, **fit_params):
    243         """Fit the model and transform with the final estimator

...........................................................................
/home/aquemy/.local/lib/python2.7/site-packages/sklearn/ensemble/forest.py in fit(self=RandomForestClassifier(bootstrap=True, class_wei...se, random_state=42, verbose=0, warm_start=False), X=array([[-2.045185  , -0.79407406],
       [-2.34...      [ 1.3548148 ,  0.6059259 ]], dtype=float32), y=array([[0.],
       [0.],
       [0.],
       [0...    [2.],
       [2.],
       [2.],
       [2.]]), sample_weight=None)
    328             trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,
    329                              **_joblib_parallel_args(prefer='threads'))(
    330                 delayed(_parallel_build_trees)(
    331                     t, self, X, y, sample_weight, i, len(trees),
    332                     verbose=self.verbose, class_weight=self.class_weight)
--> 333                 for i, t in enumerate(trees))
        i = 9
    334 
    335             # Collect newly grown trees
    336             self.estimators_.extend(trees)
    337 

...........................................................................
/home/aquemy/.local/lib/python2.7/site-packages/sklearn/externals/joblib/parallel.py in __call__(self=Parallel(n_jobs=1), iterable=<generator object <genexpr>>)
    912             # self._original_iterator is None, then this means either
    913             # that pre_dispatch == "all", n_jobs == 1 or that the first batch
    914             # was very quick and its callback already dispatched all the
    915             # remaining jobs.
    916             self._iterating = False
--> 917             if self.dispatch_one_batch(iterator):
        self.dispatch_one_batch = <bound method Parallel.dispatch_one_batch of Parallel(n_jobs=1)>
        iterator = <generator object <genexpr>>
    918                 self._iterating = self._original_iterator is not None
    919 
    920             while self.dispatch_one_batch(iterator):
    921                 pass

...........................................................................
/home/aquemy/.local/lib/python2.7/site-packages/sklearn/externals/joblib/parallel.py in dispatch_one_batch(self=Parallel(n_jobs=1), iterator=<generator object <genexpr>>)
    754                                  self._pickle_cache)
    755             if len(tasks) == 0:
    756                 # No more tasks available in the iterator: tell caller to stop.
    757                 return False
    758             else:
--> 759                 self._dispatch(tasks)
        self._dispatch = <bound method Parallel._dispatch of Parallel(n_jobs=1)>
        tasks = <sklearn.externals.joblib.parallel.BatchedCalls object>
    760                 return True
    761 
    762     def _print(self, msg, msg_args):
    763         """Display the message on stout or stderr depending on verbosity"""

...........................................................................
/home/aquemy/.local/lib/python2.7/site-packages/sklearn/externals/joblib/parallel.py in _dispatch(self=Parallel(n_jobs=1), batch=<sklearn.externals.joblib.parallel.BatchedCalls object>)
    711 
    712         dispatch_timestamp = time.time()
    713         cb = BatchCompletionCallBack(dispatch_timestamp, len(batch), self)
    714         with self._lock:
    715             job_idx = len(self._jobs)
--> 716             job = self._backend.apply_async(batch, callback=cb)
        job = undefined
        self._backend.apply_async = <bound method SequentialBackend.apply_async of <...lib._parallel_backends.SequentialBackend object>>
        batch = <sklearn.externals.joblib.parallel.BatchedCalls object>
        cb = <sklearn.externals.joblib.parallel.BatchCompletionCallBack object>
    717             # A job can complete so quickly than its callback is
    718             # called before we get here, causing self._jobs to
    719             # grow. To ensure correct results ordering, .insert is
    720             # used (rather than .append) in the following line

...........................................................................
/home/aquemy/.local/lib/python2.7/site-packages/sklearn/externals/joblib/_parallel_backends.py in apply_async(self=<sklearn.externals.joblib._parallel_backends.SequentialBackend object>, func=<sklearn.externals.joblib.parallel.BatchedCalls object>, callback=<sklearn.externals.joblib.parallel.BatchCompletionCallBack object>)
    177             raise ValueError('n_jobs == 0 in Parallel has no meaning')
    178         return 1
    179 
    180     def apply_async(self, func, callback=None):
    181         """Schedule a func to be run"""
--> 182         result = ImmediateResult(func)
        result = undefined
        func = <sklearn.externals.joblib.parallel.BatchedCalls object>
    183         if callback:
    184             callback(result)
    185         return result
    186 

...........................................................................
/home/aquemy/.local/lib/python2.7/site-packages/sklearn/externals/joblib/_parallel_backends.py in __init__(self=<sklearn.externals.joblib._parallel_backends.ImmediateResult object>, batch=<sklearn.externals.joblib.parallel.BatchedCalls object>)
    544 
    545 class ImmediateResult(object):
    546     def __init__(self, batch):
    547         # Don't delay the application, to avoid keeping the input
    548         # arguments in memory
--> 549         self.results = batch()
        self.results = undefined
        batch = <sklearn.externals.joblib.parallel.BatchedCalls object>
    550 
    551     def get(self):
    552         return self.results
    553 

...........................................................................
/home/aquemy/.local/lib/python2.7/site-packages/sklearn/externals/joblib/parallel.py in __call__(self=<sklearn.externals.joblib.parallel.BatchedCalls object>)
    220     def __call__(self):
    221         # Set the default nested backend to self._backend but do not set the
    222         # change the default number of processes to -1
    223         with parallel_backend(self._backend, n_jobs=self._n_jobs):
    224             return [func(*args, **kwargs)
--> 225                     for func, args, kwargs in self.items]
        func = <function _parallel_build_trees>
        args = (DecisionTreeClassifier(class_weight=None, criter...=False, random_state=1608637542, splitter='best'), RandomForestClassifier(bootstrap=True, class_wei...se, random_state=42, verbose=0, warm_start=False), array([[-2.045185  , -0.79407406],
       [-2.34...      [ 1.3548148 ,  0.6059259 ]], dtype=float32), array([[0.],
       [0.],
       [0.],
       [0...    [2.],
       [2.],
       [2.],
       [2.]]), None, 0, 10)
        kwargs = {'class_weight': None, 'verbose': 0}
        self.items = [(<function _parallel_build_trees>, (DecisionTreeClassifier(class_weight=None, criter...=False, random_state=1608637542, splitter='best'), RandomForestClassifier(bootstrap=True, class_wei...se, random_state=42, verbose=0, warm_start=False), array([[-2.045185  , -0.79407406],
       [-2.34...      [ 1.3548148 ,  0.6059259 ]], dtype=float32), array([[0.],
       [0.],
       [0.],
       [0...    [2.],
       [2.],
       [2.],
       [2.]]), None, 0, 10), {'class_weight': None, 'verbose': 0})]
    226 
    227     def __len__(self):
    228         return self._size
    229 

...........................................................................
/home/aquemy/.local/lib/python2.7/site-packages/sklearn/ensemble/forest.py in _parallel_build_trees(tree=DecisionTreeClassifier(class_weight=None, criter...=False, random_state=1608637542, splitter='best'), forest=RandomForestClassifier(bootstrap=True, class_wei...se, random_state=42, verbose=0, warm_start=False), X=array([[-2.045185  , -0.79407406],
       [-2.34...      [ 1.3548148 ,  0.6059259 ]], dtype=float32), y=array([[0.],
       [0.],
       [0.],
       [0...    [2.],
       [2.],
       [2.],
       [2.]]), sample_weight=None, tree_idx=0, n_trees=10, verbose=0, class_weight=None)
    114                 simplefilter('ignore', DeprecationWarning)
    115                 curr_sample_weight *= compute_sample_weight('auto', y, indices)
    116         elif class_weight == 'balanced_subsample':
    117             curr_sample_weight *= compute_sample_weight('balanced', y, indices)
    118 
--> 119         tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)
        tree.fit = <bound method DecisionTreeClassifier.fit of Deci...False, random_state=1608637542, splitter='best')>
        X = array([[-2.045185  , -0.79407406],
       [-2.34...      [ 1.3548148 ,  0.6059259 ]], dtype=float32)
        y = array([[0.],
       [0.],
       [0.],
       [0...    [2.],
       [2.],
       [2.],
       [2.]])
        sample_weight = None
        curr_sample_weight = array([3., 3., 0., 1., 1., 2., 2., 0., 1., 2., 0... 1., 0., 1., 0., 1., 1., 1., 1., 1., 1., 0., 0.])
    120     else:
    121         tree.fit(X, y, sample_weight=sample_weight, check_input=False)
    122 
    123     return tree

...........................................................................
/home/aquemy/.local/lib/python2.7/site-packages/sklearn/tree/tree.py in fit(self=DecisionTreeClassifier(class_weight=None, criter...=False, random_state=1608637542, splitter='best'), X=array([[-2.045185  , -0.79407406],
       [-2.34...      [ 1.3548148 ,  0.6059259 ]], dtype=float32), y=array([[0.],
       [0.],
       [0.],
       [0...    [2.],
       [2.],
       [2.],
       [2.]]), sample_weight=array([3., 3., 0., 1., 1., 2., 2., 0., 1., 2., 0... 1., 0., 1., 0., 1., 1., 1., 1., 1., 1., 0., 0.]), check_input=False, X_idx_sorted=None)
    796 
    797         super(DecisionTreeClassifier, self).fit(
    798             X, y,
    799             sample_weight=sample_weight,
    800             check_input=check_input,
--> 801             X_idx_sorted=X_idx_sorted)
        X_idx_sorted = None
    802         return self
    803 
    804     def predict_proba(self, X, check_input=True):
    805         """Predict class probabilities of the input samples X.

...........................................................................
/home/aquemy/.local/lib/python2.7/site-packages/sklearn/tree/tree.py in fit(self=DecisionTreeClassifier(class_weight=None, criter...=False, random_state=1608637542, splitter='best'), X=array([[-2.045185  , -0.79407406],
       [-2.34...      [ 1.3548148 ,  0.6059259 ]], dtype=float32), y=array([[0.],
       [0.],
       [0.],
       [0...    [2.],
       [2.],
       [2.],
       [2.]]), sample_weight=array([3., 3., 0., 1., 1., 2., 2., 0., 1., 2., 0... 1., 0., 1., 0., 1., 1., 1., 1., 1., 1., 0., 0.]), check_input=False, X_idx_sorted=None)
    237         if not 0 <= self.min_weight_fraction_leaf <= 0.5:
    238             raise ValueError("min_weight_fraction_leaf must in [0, 0.5]")
    239         if max_depth <= 0:
    240             raise ValueError("max_depth must be greater than zero. ")
    241         if not (0 < max_features <= self.n_features_):
--> 242             raise ValueError("max_features must be in (0, n_features]")
    243         if not isinstance(max_leaf_nodes, (numbers.Integral, np.integer)):
    244             raise ValueError("max_leaf_nodes must be integral number but was "
    245                              "%r" % max_leaf_nodes)
    246         if -1 < max_leaf_nodes < 2:

ValueError: max_features must be in (0, n_features]
___________________________________________________________________________
Best score: 0.966666666667 (0.0333333333333) [J] | Score: 0.0 (0.0) [J]
Best score: 0.966666666667 (0.0333333333333) [J] | Score: 0.946666666667 (0.0581186525805) [J]
JoblibValueError
___________________________________________________________________________
...........................................................................
/home/aquemy/dev/dp_hyperparameters/extension/main.py in <module>()
     27 
     28     serializer.serialize_results(scenario, policy)
     29 
     30 if __name__ == "__main__":
     31     args = cli.parse_args()
---> 32     main(args)

...........................................................................
/home/aquemy/dev/dp_hyperparameters/extension/main.py in main(args=Namespace(customize=[(['control', 'seed'], '42')...io='./scenarios/rf_iris_joint.yaml', verbosity=0))
     21         test_size=0.4, 
     22         random_state=scenario['control']['seed']
     23     )
     24 
     25     policy = policies.initiate(scenario['setup']['policy'], config)
---> 26     policy.run(X,y)
        policy.run = <bound method Joint.run of <experiment.policies.joint.Joint object>>
        X = array([[5.1, 3.5, 1.4, 0.2],
       [4.9, 3. , 1....2, 3.4, 5.4, 2.3],
       [5.9, 3. , 5.1, 1.8]])
        y = array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,... 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2])
     27 
     28     serializer.serialize_results(scenario, policy)
     29 
     30 if __name__ == "__main__":

...........................................................................
/home/aquemy/dev/dp_hyperparameters/extension/experiment/policies/joint.py in run(self=<experiment.policies.joint.Joint object>, X=array([[5.1, 3.5, 1.4, 0.2],
       [4.9, 3. , 1....2, 3.4, 5.4, 2.3],
       [5.9, 3. , 5.1, 1.8]]), y=array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,... 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]))
     32             algo=tpe.suggest, 
     33             max_evals=None,
     34             max_time=self.config['time'],     
     35             trials=trials,
     36             show_progressbar=False,
---> 37             verbose=0
     38         )
     39 
     40         best_config = self.context['best_config']
     41         super(Joint, self).display_step_results(best_config)

...........................................................................
/home/aquemy/dev/dp_hyperparameters/extension/hyperopt/fmin.py in fmin(fn=<functools.partial object>, space={'algorithm': {'bootstrap': <hyperopt.pyll.base.Apply object>, 'criterion': <hyperopt.pyll.base.Apply object>, 'max_depth': <hyperopt.pyll.base.Apply object>, 'max_features': <hyperopt.pyll.base.Apply object>, 'max_leaf_nodes': <hyperopt.pyll.base.Apply object>, 'min_samples_split': <hyperopt.pyll.base.Apply object>, 'n_estimators': <hyperopt.pyll.base.Apply object>}, 'pipeline': {'features': <hyperopt.pyll.base.Apply object>, 'normalizer': <hyperopt.pyll.base.Apply object>, 'rebalance': <hyperopt.pyll.base.Apply object>}}, algo=<function suggest>, max_evals=9223372036854775807, max_time=300, trials=<hyperopt.base.Trials object>, rstate=<mtrand.RandomState object>, allow_trials_fmin=True, pass_expr_memo_ctrl=None, catch_eval_exceptions=False, verbose=0, return_argmin=True, points_to_evaluate=None, max_queue_len=1, show_progressbar=False)
    406             pass_expr_memo_ctrl=pass_expr_memo_ctrl,
    407             verbose=verbose,
    408             catch_eval_exceptions=catch_eval_exceptions,
    409             return_argmin=return_argmin,
    410             show_progressbar=show_progressbar,
--> 411             max_time=max_time
        max_time = 300
    412         )
    413 
    414     if trials is None:
    415         if points_to_evaluate is None:

...........................................................................
/home/aquemy/dev/dp_hyperparameters/extension/hyperopt/base.py in fmin(self=<hyperopt.base.Trials object>, fn=<functools.partial object>, space={'algorithm': {'bootstrap': <hyperopt.pyll.base.Apply object>, 'criterion': <hyperopt.pyll.base.Apply object>, 'max_depth': <hyperopt.pyll.base.Apply object>, 'max_features': <hyperopt.pyll.base.Apply object>, 'max_leaf_nodes': <hyperopt.pyll.base.Apply object>, 'min_samples_split': <hyperopt.pyll.base.Apply object>, 'n_estimators': <hyperopt.pyll.base.Apply object>}, 'pipeline': {'features': <hyperopt.pyll.base.Apply object>, 'normalizer': <hyperopt.pyll.base.Apply object>, 'rebalance': <hyperopt.pyll.base.Apply object>}}, algo=<function suggest>, max_evals=9223372036854775807, max_time=300, rstate=<mtrand.RandomState object>, verbose=0, pass_expr_memo_ctrl=None, catch_eval_exceptions=False, return_argmin=True, show_progressbar=False)
    636             verbose=verbose,
    637             allow_trials_fmin=False,  # -- prevent recursion
    638             pass_expr_memo_ctrl=pass_expr_memo_ctrl,
    639             catch_eval_exceptions=catch_eval_exceptions,
    640             return_argmin=return_argmin,
--> 641             show_progressbar=show_progressbar)
        show_progressbar = False
    642 
    643 
    644 def trials_from_docs(docs, validate=True, **kwargs):
    645     """Construct a Trials base class instance from a list of trials documents

...........................................................................
/home/aquemy/dev/dp_hyperparameters/extension/hyperopt/fmin.py in fmin(fn=<functools.partial object>, space={'algorithm': {'bootstrap': <hyperopt.pyll.base.Apply object>, 'criterion': <hyperopt.pyll.base.Apply object>, 'max_depth': <hyperopt.pyll.base.Apply object>, 'max_features': <hyperopt.pyll.base.Apply object>, 'max_leaf_nodes': <hyperopt.pyll.base.Apply object>, 'min_samples_split': <hyperopt.pyll.base.Apply object>, 'n_estimators': <hyperopt.pyll.base.Apply object>}, 'pipeline': {'features': <hyperopt.pyll.base.Apply object>, 'normalizer': <hyperopt.pyll.base.Apply object>, 'rebalance': <hyperopt.pyll.base.Apply object>}}, algo=<function suggest>, max_evals=9223372036854775807, max_time=300, trials=<hyperopt.base.Trials object>, rstate=<mtrand.RandomState object>, allow_trials_fmin=False, pass_expr_memo_ctrl=None, catch_eval_exceptions=False, verbose=0, return_argmin=True, points_to_evaluate=None, max_queue_len=1, show_progressbar=False)
    426                     verbose=verbose,
    427                     max_queue_len=max_queue_len,
    428                     show_progressbar=show_progressbar,
    429                     max_time=max_time)
    430     rval.catch_eval_exceptions = catch_eval_exceptions
--> 431     rval.exhaust()
        rval.exhaust = <bound method FMinIter.exhaust of <hyperopt.fmin.FMinIter object>>
    432     if return_argmin:
    433         return trials.argmin
    434     elif len(trials) > 0:
    435         # Only if there are some succesfull trail runs, return the best point in the evaluation space

...........................................................................
/home/aquemy/dev/dp_hyperparameters/extension/hyperopt/fmin.py in exhaust(self=<hyperopt.fmin.FMinIter object>)
    273             raise StopIteration()
    274         return self.trials
    275 
    276     def exhaust(self):
    277         n_done = len(self.trials)
--> 278         self.run(self.max_evals - n_done, block_until_done=self.asynchronous)
        self.run = <bound method FMinIter.run of <hyperopt.fmin.FMinIter object>>
        self.max_evals = 9223372036854775807
        n_done = 0
        self.asynchronous = False
    279         self.trials.refresh()
    280         return self
    281 
    282 

...........................................................................
/home/aquemy/dev/dp_hyperparameters/extension/hyperopt/fmin.py in run(self=<hyperopt.fmin.FMinIter object>, N=9223372036854775807, block_until_done=False)
    232                     if self.asynchronous:
    233                         # -- wait for workers to fill in the trials
    234                         time.sleep(self.poll_interval_secs)
    235                     else:
    236                         # -- loop over trials and do the jobs directly
--> 237                         self.serial_evaluate()
        self.serial_evaluate = <bound method FMinIter.serial_evaluate of <hyperopt.fmin.FMinIter object>>
    238                     try:
    239                         res = [d['result']['loss'] for d in
    240                                          self.trials.trials if
    241                                          d['result']['status'] == 'ok']

...........................................................................
/home/aquemy/dev/dp_hyperparameters/extension/hyperopt/fmin.py in serial_evaluate(self=<hyperopt.fmin.FMinIter object>, N=-1)
    138                 trial['book_time'] = now
    139                 trial['refresh_time'] = now
    140                 spec = base.spec_from_misc(trial['misc'])
    141                 ctrl = base.Ctrl(self.trials, current_trial=trial)
    142                 try:
--> 143                     result = self.domain.evaluate(spec, ctrl)
        result = undefined
        self.domain.evaluate = <bound method Domain.evaluate of <hyperopt.base.Domain object>>
        spec = {'bootstrap': 0, 'criterion': 0, 'features': 2, 'features_SelectKBest_features__k': 0, 'max_depth': 1, 'max_features': 2, 'max_leaf_nodes': 1, 'min_samples_split': 2, 'n_estimators': 0, 'normalizer': 1, ...}
        ctrl = <hyperopt.base.Ctrl object>
    144                 except Exception as e:
    145                     logger.info('job exception: %s' % str(e))
    146                     trial['state'] = base.JOB_STATE_ERROR
    147                     trial['misc']['error'] = (str(type(e)), str(e))

...........................................................................
/home/aquemy/dev/dp_hyperparameters/extension/hyperopt/base.py in evaluate(self=<hyperopt.base.Domain object>, config={'bootstrap': 0, 'criterion': 0, 'features': 2, 'features_SelectKBest_features__k': 0, 'max_depth': 1, 'max_features': 2, 'max_leaf_nodes': 1, 'min_samples_split': 2, 'n_estimators': 0, 'normalizer': 1, ...}, ctrl=<hyperopt.base.Ctrl object>, attach_attachments=True)
    841             #    or the normal Python part (self.fn)
    842             pyll_rval = pyll.rec_eval(
    843                 self.expr,
    844                 memo=memo,
    845                 print_node_on_error=self.rec_eval_print_node_on_error)
--> 846             rval = self.fn(pyll_rval)
        rval = undefined
        self.fn = <functools.partial object>
        pyll_rval = {'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': 2, 'max_features': 3, 'max_leaf_nodes': 3, 'min_samples_split': 5, 'n_estimators': 10}, 'pipeline': {'features': ('features_SelectKBest', {'features__k': 1}), 'normalizer': ('normalizer_StandardScaler', {'normalizer__with_mean': True, 'normalizer__with_std': False}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 7})}}
    847 
    848         if isinstance(rval, (float, int, np.number)):
    849             dict_rval = {'loss': float(rval), 'status': STATUS_OK}
    850         else:

...........................................................................
/home/aquemy/dev/dp_hyperparameters/extension/experiment/objective.py in objective_joint(wconfig={'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': 2, 'max_features': 3, 'max_leaf_nodes': 3, 'min_samples_split': 5, 'n_estimators': 10}, 'pipeline': {'features': ('features_SelectKBest', {'features__k': 1}), 'normalizer': ('normalizer_StandardScaler', {'normalizer__with_mean': True, 'normalizer__with_std': False}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 7})}}, algorithm='RandomForest', X=array([[5.1, 3.5, 1.4, 0.2],
       [4.9, 3. , 1....2, 3.4, 5.4, 2.3],
       [5.9, 3. , 5.1, 1.8]]), y=array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,... 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]), context={'baseline_score': 0.9466666666666667, 'baseline_score_std': 0.04988876515698587, 'best_config': {'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': 4, 'max_features': 3, 'max_leaf_nodes': 3, 'min_samples_split': 3, 'n_estimators': 10}, 'config_hash': {'algorithm': 'ffb7ff225ce3d3712c96cf87fe42202988ee2eb0', 'config': 'bae32f426be9cd6243523c023944a8c148fe4aeb', 'pipeline': 'd2a68bfda6fcdec4ae0ffc7d7b6a2122bc1cd673'}, 'duration': 0.7115809917449951, 'iteration': 113, 'loss': 0.033333333333333215, 'max_history_score': 0.9666666666666668, 'max_history_score_std': 0.033333333333333326, 'max_history_step': 'joint', 'pipeline': {'features': ('features_NoneType', {}), 'normalizer': ('normalizer_PowerTransformer', {}), 'rebalance': ('rebalance_CondensedNearestNeighbour', {'rebalance__n_neighbors': 2})}, 'score': 0.9666666666666668, ...}, 'history': [{'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': 2, 'max_features': None, 'max_leaf_nodes': 5, 'min_samples_split': 2, 'n_estimators': 75}, 'config_hash': {'algorithm': '3af5b0cce71c8fe2545246ca24ff5bc3dd516e06', 'config': 'db6ac7e6d348155757e4794bb5f88fe2b4f63d50', 'pipeline': '8d59f4b94cef6be9306ed86a22a9570fa670d567'}, 'duration': 1.149928092956543, 'iteration': 0, 'loss': 0.046666666666666634, 'max_history_score': 0.9533333333333334, 'max_history_score_std': 0.059999999999999984, 'max_history_step': 'joint', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 4, 'features__selectkbest__k': 3}), 'normalizer': ('normalizer_StandardScaler', {'normalizer__with_mean': True, 'normalizer__with_std': True}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 6})}, 'score': 0.9533333333333334, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': 1, 'max_features': 2, 'max_leaf_nodes': 2, 'min_samples_split': 5, 'n_estimators': 100}, 'config_hash': {'algorithm': 'e13eb05fd9a62d2f63bbb1c1deff0cd620d5e6ab', 'config': '4db6fb84d85f52659f780e682ffac5712c3d8a94', 'pipeline': '64c9a1ca9d53ae67244bdd942f4db36a3c05218c'}, 'duration': 1.7678282260894775, 'iteration': 1, 'loss': 0.18000000000000005, 'max_history_score': 0.9533333333333334, 'max_history_score_std': 0.059999999999999984, 'max_history_step': 'joint', 'pipeline': {'features': ('features_NoneType', {}), 'normalizer': ('normalizer_PowerTransformer', {}), 'rebalance': ('rebalance_NearMiss', {'rebalance__n_neighbors': 1})}, 'score': 0.82, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': 1, 'max_features': None, 'max_leaf_nodes': None, 'min_samples_split': 5, 'n_estimators': 75}, 'config_hash': {'algorithm': '94b0d7a654c508cc63643f78fe4f0f07e6f07c1e', 'config': '4403c5a85e951938d3c454e961d3a412780722f6', 'pipeline': '3e47444880d8367fbac2faaba2e52a917274aa58'}, 'duration': 0.8397619724273682, 'iteration': 2, 'loss': 0.03333333333333344, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_PCA', {'features__n_components': 3}), 'normalizer': ('normalizer_MinMaxScaler', {}), 'rebalance': ('rebalance_NoneType', {})}, 'score': 0.9666666666666666, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': None, 'max_features': None, 'max_leaf_nodes': 3, 'min_samples_split': 3, 'n_estimators': 75}, 'config_hash': {'algorithm': 'e8332f0a8902bda03bf70e7978cc5d52affb29d3', 'config': 'a064e2df18ab98d44dabcefbc7bed94913f1d0be', 'pipeline': '7eea819c2a8c103c4b1e9e9c1e224aebba95081f'}, 'duration': 0.8501448631286621, 'iteration': 3, 'loss': 0.053333333333333344, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 2, 'features__selectkbest__k': 4}), 'normalizer': ('normalizer_NoneType', {}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 7})}, 'score': 0.9466666666666667, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'entropy', 'max_depth': 3, 'max_features': 3, 'max_leaf_nodes': None, 'min_samples_split': 5, 'n_estimators': 75}, 'config_hash': {'algorithm': '7a4491035bc6bd737fe9a8cda8a79a02d02d5c74', 'config': '0ddb6f5cab3db4dddd7682966a57205f3e329ad4', 'pipeline': 'a9ae03fe38334f6868cbf84cdd3d629d4bbe3fb0'}, 'duration': 1.1026010513305664, 'iteration': 4, 'loss': 0.05999999999999994, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 2, 'features__selectkbest__k': 1}), 'normalizer': ('normalizer_NoneType', {}), 'rebalance': ('rebalance_NoneType', {})}, 'score': 0.9400000000000001, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'gini', 'max_depth': 3, 'max_features': 1, 'max_leaf_nodes': 5, 'min_samples_split': 2, 'n_estimators': 25}, 'config_hash': {'algorithm': '9826d20b2d6a0f559cf7f16450ce7526f07e8434', 'config': '49f25751bca61cdd461a8cbd2923689b642f98ed', 'pipeline': '19b249664c5bf067de1fed4334a296f947ce774a'}, 'duration': 0.35647010803222656, 'iteration': 5, 'loss': 0.046666666666666634, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_NoneType', {}), 'normalizer': ('normalizer_NoneType', {}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 6})}, 'score': 0.9533333333333334, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'gini', 'max_depth': 2, 'max_features': 1, 'max_leaf_nodes': 2, 'min_samples_split': 2, 'n_estimators': 50}, 'config_hash': {'algorithm': '0a4f6fbb07e0f32c6f675489a0fc82eee05bd8e1', 'config': '5c3a2b6f5e63fb45f10e41e0318b354912ec44f6', 'pipeline': 'dc3b9f176f090005e38b142f11d80e93a7dc5d5e'}, 'duration': 0.7213859558105469, 'iteration': 6, 'loss': 0.31333333333333324, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 1, 'features__selectkbest__k': 4}), 'normalizer': ('normalizer_PowerTransformer', {}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 7})}, 'score': 0.6866666666666668, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'entropy', 'max_depth': 4, 'max_features': 3, 'max_leaf_nodes': 5, 'min_samples_split': 5, 'n_estimators': 10}, 'config_hash': {'algorithm': 'b8112b97ecfc10f00a195af661dcc861cac21289', 'config': 'd3b129b397350f1b6572651c67c01de49b4b174c', 'pipeline': '5b0357ed7072c37b3d6f458bb5d49ff7d825f603'}, 'duration': 0.8299109935760498, 'iteration': 7, 'loss': 1.0, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_PCA', {'features__n_components': 2}), 'normalizer': ('normalizer_StandardScaler', {'normalizer__with_mean': True, 'normalizer__with_std': False}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 6})}, 'score': 0.0, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'gini', 'max_depth': 4, 'max_features': None, 'max_leaf_nodes': 2, 'min_samples_split': 5, 'n_estimators': 100}, 'config_hash': {'algorithm': '40ca24df19b8d164d9d098a6bed1ce056fbbb961', 'config': '813bde1108cc3c4b9bfb3a22cbb421bda7eac671', 'pipeline': '74a7b8705a1c22f7dea5e44e4ebda8f1e48add71'}, 'duration': 2.2111589908599854, 'iteration': 8, 'loss': 0.33333333333333326, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_PCA', {'features__n_components': 2}), 'normalizer': ('normalizer_StandardScaler', {'normalizer__with_mean': False, 'normalizer__with_std': True}), 'rebalance': ('rebalance_NearMiss', {'rebalance__n_neighbors': 2})}, 'score': 0.6666666666666667, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'entropy', 'max_depth': 2, 'max_features': 1, 'max_leaf_nodes': 5, 'min_samples_split': 2, 'n_estimators': 100}, 'config_hash': {'algorithm': '331418a5c12cf1453876eef85e9d98fc8e54fa11', 'config': '31930b6860ed406d59bf7e59ba1925d94704bd3b', 'pipeline': '054bef356f90ec6f644ef3ffc688766744db51c2'}, 'duration': 1.0501940250396729, 'iteration': 9, 'loss': 0.053333333333333344, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_SelectKBest', {'features__k': 1}), 'normalizer': ('normalizer_RobustScaler', {'normalizer__quantile_range': (...), 'normalizer__with_centering': True, 'normalizer__with_scaling': True}), 'rebalance': ('rebalance_NearMiss', {'rebalance__n_neighbors': 2})}, 'score': 0.9466666666666667, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'entropy', 'max_depth': 3, 'max_features': None, 'max_leaf_nodes': 3, 'min_samples_split': 2, 'n_estimators': 100}, 'config_hash': {'algorithm': 'dbc1b8126649fe93dce5fbb37e4015b0acfb179e', 'config': '9913cd550615a9d0946ab4a755a8b9f619e442fd', 'pipeline': 'dd626121cea079ebb32e184ca65483ec7a6d7f59'}, 'duration': 1.120617151260376, 'iteration': 10, 'loss': 0.046666666666666634, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 2, 'features__selectkbest__k': 1}), 'normalizer': ('normalizer_MinMaxScaler', {}), 'rebalance': ('rebalance_NoneType', {})}, 'score': 0.9533333333333334, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'gini', 'max_depth': 3, 'max_features': 3, 'max_leaf_nodes': None, 'min_samples_split': 3, 'n_estimators': 75}, 'config_hash': {'algorithm': '34917a130df5a975f78bd7ec1a0c7b1ffdc787a9', 'config': '95fc8cadc088141290b7de9c388977e4685f0108', 'pipeline': '550d10faf2f08db48516cc3501558816d6a99bc0'}, 'duration': 1.4287099838256836, 'iteration': 11, 'loss': 0.19333333333333313, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 3, 'features__selectkbest__k': 4}), 'normalizer': ('normalizer_StandardScaler', {'normalizer__with_mean': False, 'normalizer__with_std': False}), 'rebalance': ('rebalance_CondensedNearestNeighbour', {'rebalance__n_neighbors': 1})}, 'score': 0.8066666666666669, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'entropy', 'max_depth': 1, 'max_features': 2, 'max_leaf_nodes': 5, 'min_samples_split': 2, 'n_estimators': 75}, 'config_hash': {'algorithm': '33f9abb4aee44a395a9f3b3ffa9ce80a8cdaed7c', 'config': '40fa726f0360cf6af55f9b5902d399d02f61f157', 'pipeline': 'cfd1d20841fe2153da762c95e79f95a3fb1e426a'}, 'duration': 1.2978079319000244, 'iteration': 12, 'loss': 0.053333333333333344, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_PCA', {'features__n_components': 4}), 'normalizer': ('normalizer_MinMaxScaler', {}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 7})}, 'score': 0.9466666666666667, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'entropy', 'max_depth': 4, 'max_features': 2, 'max_leaf_nodes': 5, 'min_samples_split': 3, 'n_estimators': 25}, 'config_hash': {'algorithm': '210111ec6562d09eb093e98ed69ef1c662e11a50', 'config': '0fb8e77c7bd9a58b72f1b33c21a59a09a8c676ba', 'pipeline': '5d269d759e0c7926a685a14b263ace8ae0071e4b'}, 'duration': 0.36649012565612793, 'iteration': 13, 'loss': 0.040000000000000036, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 2, 'features__selectkbest__k': 2}), 'normalizer': ('normalizer_NoneType', {}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 7})}, 'score': 0.96, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'entropy', 'max_depth': 3, 'max_features': 1, 'max_leaf_nodes': 5, 'min_samples_split': 2, 'n_estimators': 25}, 'config_hash': {'algorithm': '0e989a03980101fabf79eda3326ed2870e11d690', 'config': 'f4bffd5d8c67a9c5321a9943c4a99678f59a02b7', 'pipeline': '865ee1e3fe8334c3d5ecb2038d5a5d1b3ba50e75'}, 'duration': 0.35639500617980957, 'iteration': 14, 'loss': 0.046666666666666634, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_NoneType', {}), 'normalizer': ('normalizer_RobustScaler', {'normalizer__quantile_range': (...), 'normalizer__with_centering': True, 'normalizer__with_scaling': False}), 'rebalance': ('rebalance_NoneType', {})}, 'score': 0.9533333333333334, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'entropy', 'max_depth': None, 'max_features': 3, 'max_leaf_nodes': 3, 'min_samples_split': 5, 'n_estimators': 10}, 'config_hash': {'algorithm': '9c592e876c13de5e23e6de5b868e01755d63e72e', 'config': '1e6a68cd1eeac886d90724d78b1cb5fb76a3cde4', 'pipeline': '5a1ca4d82f21b7de0d2c918630a42510673fa36e'}, 'duration': 0.18141412734985352, 'iteration': 15, 'loss': 0.046666666666666634, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_SelectKBest', {'features__k': 3}), 'normalizer': ('normalizer_RobustScaler', {'normalizer__quantile_range': (...), 'normalizer__with_centering': True, 'normalizer__with_scaling': True}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 6})}, 'score': 0.9533333333333334, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': 1, 'max_features': None, 'max_leaf_nodes': None, 'min_samples_split': 5, 'n_estimators': 10}, 'config_hash': {'algorithm': '8bed77aef289bfd453b2858bd288ae5ba7160f2b', 'config': '781185bcb8999045de8d489f253a1a1ba4247932', 'pipeline': '1ece7eabedc2be9e5b0a1be65c570d08ffa3eb54'}, 'duration': 0.1636829376220703, 'iteration': 16, 'loss': 0.053333333333333344, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_NoneType', {}), 'normalizer': ('normalizer_NoneType', {}), 'rebalance': ('rebalance_NearMiss', {'rebalance__n_neighbors': 1})}, 'score': 0.9466666666666667, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'gini', 'max_depth': 3, 'max_features': 2, 'max_leaf_nodes': 2, 'min_samples_split': 5, 'n_estimators': 75}, 'config_hash': {'algorithm': '617b97d9ba21d3373bc51ffa9cccf9c6f91a77b3', 'config': '99fb425b4e8c5d80228cab94202252aa25cdf77c', 'pipeline': 'd6242929c3b515c7719e60423023ac604311afc3'}, 'duration': 0.8468999862670898, 'iteration': 17, 'loss': 0.24, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_PCA', {'features__n_components': 4}), 'normalizer': ('normalizer_PowerTransformer', {}), 'rebalance': ('rebalance_NearMiss', {'rebalance__n_neighbors': 2})}, 'score': 0.76, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': 1, 'max_features': 1, 'max_leaf_nodes': 2, 'min_samples_split': 5, 'n_estimators': 50}, 'config_hash': {'algorithm': 'b92d2697cdd4979da443369d6596229ec091626a', 'config': 'c513a3e13281206ad76187dd817b1fff93d54fe1', 'pipeline': 'c4b4f914a3ca8df967cade997a90366d85a371b9'}, 'duration': 0.6724588871002197, 'iteration': 18, 'loss': 0.23333333333333328, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 1, 'features__selectkbest__k': 3}), 'normalizer': ('normalizer_StandardScaler', {'normalizer__with_mean': True, 'normalizer__with_std': True}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 5})}, 'score': 0.7666666666666667, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'entropy', 'max_depth': None, 'max_features': None, 'max_leaf_nodes': 5, 'min_samples_split': 5, 'n_estimators': 10}, 'config_hash': {'algorithm': 'a0115de695e6cca2e81cbfb54df79bf4b43608b1', 'config': 'ba194015e20b5d67770e8c67342c3d8d0d01dc41', 'pipeline': '8d45fabfeb85ffdcabf7076bd0e65fffe97ce928'}, 'duration': 0.19424200057983398, 'iteration': 19, 'loss': 0.08666666666666667, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_PCA', {'features__n_components': 3}), 'normalizer': ('normalizer_NoneType', {}), 'rebalance': ('rebalance_NoneType', {})}, 'score': 0.9133333333333333, ...}, ...], 'history_hash': ['db6ac7e6d348155757e4794bb5f88fe2b4f63d50', '4db6fb84d85f52659f780e682ffac5712c3d8a94', '4403c5a85e951938d3c454e961d3a412780722f6', 'a064e2df18ab98d44dabcefbc7bed94913f1d0be', '0ddb6f5cab3db4dddd7682966a57205f3e329ad4', '49f25751bca61cdd461a8cbd2923689b642f98ed', '5c3a2b6f5e63fb45f10e41e0318b354912ec44f6', 'd3b129b397350f1b6572651c67c01de49b4b174c', '813bde1108cc3c4b9bfb3a22cbb421bda7eac671', '31930b6860ed406d59bf7e59ba1925d94704bd3b', '9913cd550615a9d0946ab4a755a8b9f619e442fd', '95fc8cadc088141290b7de9c388977e4685f0108', '40fa726f0360cf6af55f9b5902d399d02f61f157', '0fb8e77c7bd9a58b72f1b33c21a59a09a8c676ba', 'f4bffd5d8c67a9c5321a9943c4a99678f59a02b7', '1e6a68cd1eeac886d90724d78b1cb5fb76a3cde4', '781185bcb8999045de8d489f253a1a1ba4247932', '99fb425b4e8c5d80228cab94202252aa25cdf77c', 'c513a3e13281206ad76187dd817b1fff93d54fe1', 'ba194015e20b5d67770e8c67342c3d8d0d01dc41', ...], 'history_index': {'00f0493590a2cb5e98a35b29816f8cd9f87f96ec': 208, '013329309d510b94f19d930320402d65f953a847': 39, '038a0f515e2ec894ee8e34f9caa2889eb3ebd5ce': 66, '052ae4bf232b316187b078abae42c2be19e16a00': 111, '05e9258ebf99dd97202167ef1563fa834b0568f1': 242, '0659afebf316aafeb75612fb07081a04c28545ed': 74, '06e7cde9f3556cd01332ce389ad1d8925cd4b4a4': 120, '07ab8a30d853e39a326b7017026a20e94bc45541': 245, '08606f2a0f0a6c9de204020b4632e09fcee0ae56': 168, '09dbd0948e5b8c1b1f0930778babe65c8a81295e': 243, ...}, 'iteration': 299, 'max_history_score': 0.9666666666666668, 'max_history_score_std': 0.033333333333333326, 'max_history_step': 'joint'}, config={'algorithm': 'RandomForest', 'seed': 42, 'time': 300})
    108 
    109 def objective_algo(algo_config, current_pipeline_config, algorithm, X, y, context, config):
    110     return objective(current_pipeline_config, algo_config, algorithm, X, y, context, config, step='algorithm')
    111 
    112 def objective_joint(wconfig, algorithm, X, y, context, config):
--> 113     return objective(wconfig['pipeline'], wconfig['algorithm'], algorithm, X, y, context, config, step='joint')
        wconfig = {'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': 2, 'max_features': 3, 'max_leaf_nodes': 3, 'min_samples_split': 5, 'n_estimators': 10}, 'pipeline': {'features': ('features_SelectKBest', {'features__k': 1}), 'normalizer': ('normalizer_StandardScaler', {'normalizer__with_mean': True, 'normalizer__with_std': False}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 7})}}
        algorithm = 'RandomForest'
        X = array([[5.1, 3.5, 1.4, 0.2],
       [4.9, 3. , 1....2, 3.4, 5.4, 2.3],
       [5.9, 3. , 5.1, 1.8]])
        y = array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,... 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2])
        context = {'baseline_score': 0.9466666666666667, 'baseline_score_std': 0.04988876515698587, 'best_config': {'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': 4, 'max_features': 3, 'max_leaf_nodes': 3, 'min_samples_split': 3, 'n_estimators': 10}, 'config_hash': {'algorithm': 'ffb7ff225ce3d3712c96cf87fe42202988ee2eb0', 'config': 'bae32f426be9cd6243523c023944a8c148fe4aeb', 'pipeline': 'd2a68bfda6fcdec4ae0ffc7d7b6a2122bc1cd673'}, 'duration': 0.7115809917449951, 'iteration': 113, 'loss': 0.033333333333333215, 'max_history_score': 0.9666666666666668, 'max_history_score_std': 0.033333333333333326, 'max_history_step': 'joint', 'pipeline': {'features': ('features_NoneType', {}), 'normalizer': ('normalizer_PowerTransformer', {}), 'rebalance': ('rebalance_CondensedNearestNeighbour', {'rebalance__n_neighbors': 2})}, 'score': 0.9666666666666668, ...}, 'history': [{'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': 2, 'max_features': None, 'max_leaf_nodes': 5, 'min_samples_split': 2, 'n_estimators': 75}, 'config_hash': {'algorithm': '3af5b0cce71c8fe2545246ca24ff5bc3dd516e06', 'config': 'db6ac7e6d348155757e4794bb5f88fe2b4f63d50', 'pipeline': '8d59f4b94cef6be9306ed86a22a9570fa670d567'}, 'duration': 1.149928092956543, 'iteration': 0, 'loss': 0.046666666666666634, 'max_history_score': 0.9533333333333334, 'max_history_score_std': 0.059999999999999984, 'max_history_step': 'joint', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 4, 'features__selectkbest__k': 3}), 'normalizer': ('normalizer_StandardScaler', {'normalizer__with_mean': True, 'normalizer__with_std': True}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 6})}, 'score': 0.9533333333333334, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': 1, 'max_features': 2, 'max_leaf_nodes': 2, 'min_samples_split': 5, 'n_estimators': 100}, 'config_hash': {'algorithm': 'e13eb05fd9a62d2f63bbb1c1deff0cd620d5e6ab', 'config': '4db6fb84d85f52659f780e682ffac5712c3d8a94', 'pipeline': '64c9a1ca9d53ae67244bdd942f4db36a3c05218c'}, 'duration': 1.7678282260894775, 'iteration': 1, 'loss': 0.18000000000000005, 'max_history_score': 0.9533333333333334, 'max_history_score_std': 0.059999999999999984, 'max_history_step': 'joint', 'pipeline': {'features': ('features_NoneType', {}), 'normalizer': ('normalizer_PowerTransformer', {}), 'rebalance': ('rebalance_NearMiss', {'rebalance__n_neighbors': 1})}, 'score': 0.82, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': 1, 'max_features': None, 'max_leaf_nodes': None, 'min_samples_split': 5, 'n_estimators': 75}, 'config_hash': {'algorithm': '94b0d7a654c508cc63643f78fe4f0f07e6f07c1e', 'config': '4403c5a85e951938d3c454e961d3a412780722f6', 'pipeline': '3e47444880d8367fbac2faaba2e52a917274aa58'}, 'duration': 0.8397619724273682, 'iteration': 2, 'loss': 0.03333333333333344, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_PCA', {'features__n_components': 3}), 'normalizer': ('normalizer_MinMaxScaler', {}), 'rebalance': ('rebalance_NoneType', {})}, 'score': 0.9666666666666666, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': None, 'max_features': None, 'max_leaf_nodes': 3, 'min_samples_split': 3, 'n_estimators': 75}, 'config_hash': {'algorithm': 'e8332f0a8902bda03bf70e7978cc5d52affb29d3', 'config': 'a064e2df18ab98d44dabcefbc7bed94913f1d0be', 'pipeline': '7eea819c2a8c103c4b1e9e9c1e224aebba95081f'}, 'duration': 0.8501448631286621, 'iteration': 3, 'loss': 0.053333333333333344, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 2, 'features__selectkbest__k': 4}), 'normalizer': ('normalizer_NoneType', {}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 7})}, 'score': 0.9466666666666667, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'entropy', 'max_depth': 3, 'max_features': 3, 'max_leaf_nodes': None, 'min_samples_split': 5, 'n_estimators': 75}, 'config_hash': {'algorithm': '7a4491035bc6bd737fe9a8cda8a79a02d02d5c74', 'config': '0ddb6f5cab3db4dddd7682966a57205f3e329ad4', 'pipeline': 'a9ae03fe38334f6868cbf84cdd3d629d4bbe3fb0'}, 'duration': 1.1026010513305664, 'iteration': 4, 'loss': 0.05999999999999994, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 2, 'features__selectkbest__k': 1}), 'normalizer': ('normalizer_NoneType', {}), 'rebalance': ('rebalance_NoneType', {})}, 'score': 0.9400000000000001, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'gini', 'max_depth': 3, 'max_features': 1, 'max_leaf_nodes': 5, 'min_samples_split': 2, 'n_estimators': 25}, 'config_hash': {'algorithm': '9826d20b2d6a0f559cf7f16450ce7526f07e8434', 'config': '49f25751bca61cdd461a8cbd2923689b642f98ed', 'pipeline': '19b249664c5bf067de1fed4334a296f947ce774a'}, 'duration': 0.35647010803222656, 'iteration': 5, 'loss': 0.046666666666666634, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_NoneType', {}), 'normalizer': ('normalizer_NoneType', {}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 6})}, 'score': 0.9533333333333334, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'gini', 'max_depth': 2, 'max_features': 1, 'max_leaf_nodes': 2, 'min_samples_split': 2, 'n_estimators': 50}, 'config_hash': {'algorithm': '0a4f6fbb07e0f32c6f675489a0fc82eee05bd8e1', 'config': '5c3a2b6f5e63fb45f10e41e0318b354912ec44f6', 'pipeline': 'dc3b9f176f090005e38b142f11d80e93a7dc5d5e'}, 'duration': 0.7213859558105469, 'iteration': 6, 'loss': 0.31333333333333324, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 1, 'features__selectkbest__k': 4}), 'normalizer': ('normalizer_PowerTransformer', {}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 7})}, 'score': 0.6866666666666668, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'entropy', 'max_depth': 4, 'max_features': 3, 'max_leaf_nodes': 5, 'min_samples_split': 5, 'n_estimators': 10}, 'config_hash': {'algorithm': 'b8112b97ecfc10f00a195af661dcc861cac21289', 'config': 'd3b129b397350f1b6572651c67c01de49b4b174c', 'pipeline': '5b0357ed7072c37b3d6f458bb5d49ff7d825f603'}, 'duration': 0.8299109935760498, 'iteration': 7, 'loss': 1.0, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_PCA', {'features__n_components': 2}), 'normalizer': ('normalizer_StandardScaler', {'normalizer__with_mean': True, 'normalizer__with_std': False}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 6})}, 'score': 0.0, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'gini', 'max_depth': 4, 'max_features': None, 'max_leaf_nodes': 2, 'min_samples_split': 5, 'n_estimators': 100}, 'config_hash': {'algorithm': '40ca24df19b8d164d9d098a6bed1ce056fbbb961', 'config': '813bde1108cc3c4b9bfb3a22cbb421bda7eac671', 'pipeline': '74a7b8705a1c22f7dea5e44e4ebda8f1e48add71'}, 'duration': 2.2111589908599854, 'iteration': 8, 'loss': 0.33333333333333326, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_PCA', {'features__n_components': 2}), 'normalizer': ('normalizer_StandardScaler', {'normalizer__with_mean': False, 'normalizer__with_std': True}), 'rebalance': ('rebalance_NearMiss', {'rebalance__n_neighbors': 2})}, 'score': 0.6666666666666667, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'entropy', 'max_depth': 2, 'max_features': 1, 'max_leaf_nodes': 5, 'min_samples_split': 2, 'n_estimators': 100}, 'config_hash': {'algorithm': '331418a5c12cf1453876eef85e9d98fc8e54fa11', 'config': '31930b6860ed406d59bf7e59ba1925d94704bd3b', 'pipeline': '054bef356f90ec6f644ef3ffc688766744db51c2'}, 'duration': 1.0501940250396729, 'iteration': 9, 'loss': 0.053333333333333344, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_SelectKBest', {'features__k': 1}), 'normalizer': ('normalizer_RobustScaler', {'normalizer__quantile_range': (...), 'normalizer__with_centering': True, 'normalizer__with_scaling': True}), 'rebalance': ('rebalance_NearMiss', {'rebalance__n_neighbors': 2})}, 'score': 0.9466666666666667, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'entropy', 'max_depth': 3, 'max_features': None, 'max_leaf_nodes': 3, 'min_samples_split': 2, 'n_estimators': 100}, 'config_hash': {'algorithm': 'dbc1b8126649fe93dce5fbb37e4015b0acfb179e', 'config': '9913cd550615a9d0946ab4a755a8b9f619e442fd', 'pipeline': 'dd626121cea079ebb32e184ca65483ec7a6d7f59'}, 'duration': 1.120617151260376, 'iteration': 10, 'loss': 0.046666666666666634, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 2, 'features__selectkbest__k': 1}), 'normalizer': ('normalizer_MinMaxScaler', {}), 'rebalance': ('rebalance_NoneType', {})}, 'score': 0.9533333333333334, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'gini', 'max_depth': 3, 'max_features': 3, 'max_leaf_nodes': None, 'min_samples_split': 3, 'n_estimators': 75}, 'config_hash': {'algorithm': '34917a130df5a975f78bd7ec1a0c7b1ffdc787a9', 'config': '95fc8cadc088141290b7de9c388977e4685f0108', 'pipeline': '550d10faf2f08db48516cc3501558816d6a99bc0'}, 'duration': 1.4287099838256836, 'iteration': 11, 'loss': 0.19333333333333313, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 3, 'features__selectkbest__k': 4}), 'normalizer': ('normalizer_StandardScaler', {'normalizer__with_mean': False, 'normalizer__with_std': False}), 'rebalance': ('rebalance_CondensedNearestNeighbour', {'rebalance__n_neighbors': 1})}, 'score': 0.8066666666666669, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'entropy', 'max_depth': 1, 'max_features': 2, 'max_leaf_nodes': 5, 'min_samples_split': 2, 'n_estimators': 75}, 'config_hash': {'algorithm': '33f9abb4aee44a395a9f3b3ffa9ce80a8cdaed7c', 'config': '40fa726f0360cf6af55f9b5902d399d02f61f157', 'pipeline': 'cfd1d20841fe2153da762c95e79f95a3fb1e426a'}, 'duration': 1.2978079319000244, 'iteration': 12, 'loss': 0.053333333333333344, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_PCA', {'features__n_components': 4}), 'normalizer': ('normalizer_MinMaxScaler', {}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 7})}, 'score': 0.9466666666666667, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'entropy', 'max_depth': 4, 'max_features': 2, 'max_leaf_nodes': 5, 'min_samples_split': 3, 'n_estimators': 25}, 'config_hash': {'algorithm': '210111ec6562d09eb093e98ed69ef1c662e11a50', 'config': '0fb8e77c7bd9a58b72f1b33c21a59a09a8c676ba', 'pipeline': '5d269d759e0c7926a685a14b263ace8ae0071e4b'}, 'duration': 0.36649012565612793, 'iteration': 13, 'loss': 0.040000000000000036, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 2, 'features__selectkbest__k': 2}), 'normalizer': ('normalizer_NoneType', {}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 7})}, 'score': 0.96, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'entropy', 'max_depth': 3, 'max_features': 1, 'max_leaf_nodes': 5, 'min_samples_split': 2, 'n_estimators': 25}, 'config_hash': {'algorithm': '0e989a03980101fabf79eda3326ed2870e11d690', 'config': 'f4bffd5d8c67a9c5321a9943c4a99678f59a02b7', 'pipeline': '865ee1e3fe8334c3d5ecb2038d5a5d1b3ba50e75'}, 'duration': 0.35639500617980957, 'iteration': 14, 'loss': 0.046666666666666634, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_NoneType', {}), 'normalizer': ('normalizer_RobustScaler', {'normalizer__quantile_range': (...), 'normalizer__with_centering': True, 'normalizer__with_scaling': False}), 'rebalance': ('rebalance_NoneType', {})}, 'score': 0.9533333333333334, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'entropy', 'max_depth': None, 'max_features': 3, 'max_leaf_nodes': 3, 'min_samples_split': 5, 'n_estimators': 10}, 'config_hash': {'algorithm': '9c592e876c13de5e23e6de5b868e01755d63e72e', 'config': '1e6a68cd1eeac886d90724d78b1cb5fb76a3cde4', 'pipeline': '5a1ca4d82f21b7de0d2c918630a42510673fa36e'}, 'duration': 0.18141412734985352, 'iteration': 15, 'loss': 0.046666666666666634, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_SelectKBest', {'features__k': 3}), 'normalizer': ('normalizer_RobustScaler', {'normalizer__quantile_range': (...), 'normalizer__with_centering': True, 'normalizer__with_scaling': True}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 6})}, 'score': 0.9533333333333334, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': 1, 'max_features': None, 'max_leaf_nodes': None, 'min_samples_split': 5, 'n_estimators': 10}, 'config_hash': {'algorithm': '8bed77aef289bfd453b2858bd288ae5ba7160f2b', 'config': '781185bcb8999045de8d489f253a1a1ba4247932', 'pipeline': '1ece7eabedc2be9e5b0a1be65c570d08ffa3eb54'}, 'duration': 0.1636829376220703, 'iteration': 16, 'loss': 0.053333333333333344, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_NoneType', {}), 'normalizer': ('normalizer_NoneType', {}), 'rebalance': ('rebalance_NearMiss', {'rebalance__n_neighbors': 1})}, 'score': 0.9466666666666667, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'gini', 'max_depth': 3, 'max_features': 2, 'max_leaf_nodes': 2, 'min_samples_split': 5, 'n_estimators': 75}, 'config_hash': {'algorithm': '617b97d9ba21d3373bc51ffa9cccf9c6f91a77b3', 'config': '99fb425b4e8c5d80228cab94202252aa25cdf77c', 'pipeline': 'd6242929c3b515c7719e60423023ac604311afc3'}, 'duration': 0.8468999862670898, 'iteration': 17, 'loss': 0.24, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_PCA', {'features__n_components': 4}), 'normalizer': ('normalizer_PowerTransformer', {}), 'rebalance': ('rebalance_NearMiss', {'rebalance__n_neighbors': 2})}, 'score': 0.76, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': 1, 'max_features': 1, 'max_leaf_nodes': 2, 'min_samples_split': 5, 'n_estimators': 50}, 'config_hash': {'algorithm': 'b92d2697cdd4979da443369d6596229ec091626a', 'config': 'c513a3e13281206ad76187dd817b1fff93d54fe1', 'pipeline': 'c4b4f914a3ca8df967cade997a90366d85a371b9'}, 'duration': 0.6724588871002197, 'iteration': 18, 'loss': 0.23333333333333328, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 1, 'features__selectkbest__k': 3}), 'normalizer': ('normalizer_StandardScaler', {'normalizer__with_mean': True, 'normalizer__with_std': True}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 5})}, 'score': 0.7666666666666667, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'entropy', 'max_depth': None, 'max_features': None, 'max_leaf_nodes': 5, 'min_samples_split': 5, 'n_estimators': 10}, 'config_hash': {'algorithm': 'a0115de695e6cca2e81cbfb54df79bf4b43608b1', 'config': 'ba194015e20b5d67770e8c67342c3d8d0d01dc41', 'pipeline': '8d45fabfeb85ffdcabf7076bd0e65fffe97ce928'}, 'duration': 0.19424200057983398, 'iteration': 19, 'loss': 0.08666666666666667, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_PCA', {'features__n_components': 3}), 'normalizer': ('normalizer_NoneType', {}), 'rebalance': ('rebalance_NoneType', {})}, 'score': 0.9133333333333333, ...}, ...], 'history_hash': ['db6ac7e6d348155757e4794bb5f88fe2b4f63d50', '4db6fb84d85f52659f780e682ffac5712c3d8a94', '4403c5a85e951938d3c454e961d3a412780722f6', 'a064e2df18ab98d44dabcefbc7bed94913f1d0be', '0ddb6f5cab3db4dddd7682966a57205f3e329ad4', '49f25751bca61cdd461a8cbd2923689b642f98ed', '5c3a2b6f5e63fb45f10e41e0318b354912ec44f6', 'd3b129b397350f1b6572651c67c01de49b4b174c', '813bde1108cc3c4b9bfb3a22cbb421bda7eac671', '31930b6860ed406d59bf7e59ba1925d94704bd3b', '9913cd550615a9d0946ab4a755a8b9f619e442fd', '95fc8cadc088141290b7de9c388977e4685f0108', '40fa726f0360cf6af55f9b5902d399d02f61f157', '0fb8e77c7bd9a58b72f1b33c21a59a09a8c676ba', 'f4bffd5d8c67a9c5321a9943c4a99678f59a02b7', '1e6a68cd1eeac886d90724d78b1cb5fb76a3cde4', '781185bcb8999045de8d489f253a1a1ba4247932', '99fb425b4e8c5d80228cab94202252aa25cdf77c', 'c513a3e13281206ad76187dd817b1fff93d54fe1', 'ba194015e20b5d67770e8c67342c3d8d0d01dc41', ...], 'history_index': {'00f0493590a2cb5e98a35b29816f8cd9f87f96ec': 208, '013329309d510b94f19d930320402d65f953a847': 39, '038a0f515e2ec894ee8e34f9caa2889eb3ebd5ce': 66, '052ae4bf232b316187b078abae42c2be19e16a00': 111, '05e9258ebf99dd97202167ef1563fa834b0568f1': 242, '0659afebf316aafeb75612fb07081a04c28545ed': 74, '06e7cde9f3556cd01332ce389ad1d8925cd4b4a4': 120, '07ab8a30d853e39a326b7017026a20e94bc45541': 245, '08606f2a0f0a6c9de204020b4632e09fcee0ae56': 168, '09dbd0948e5b8c1b1f0930778babe65c8a81295e': 243, ...}, 'iteration': 299, 'max_history_score': 0.9666666666666668, 'max_history_score_std': 0.033333333333333326, 'max_history_step': 'joint'}
        config = {'algorithm': 'RandomForest', 'seed': 42, 'time': 300}
    114 
    115 
    116 def get_baseline_score(algorithm, X, y, seed):
    117     pipeline, _ = pipeline_conf_to_full_pipeline(

...........................................................................
/home/aquemy/dev/dp_hyperparameters/extension/experiment/objective.py in objective(pipeline_config={'features': ('features_SelectKBest', {'features__k': 1}), 'normalizer': ('normalizer_StandardScaler', {'normalizer__with_mean': True, 'normalizer__with_std': False}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 7})}, algo_config={'bootstrap': True, 'criterion': 'gini', 'max_depth': 2, 'max_features': 3, 'max_leaf_nodes': 3, 'min_samples_split': 5, 'n_estimators': 10}, algorithm='RandomForest', X=array([[5.1, 3.5, 1.4, 0.2],
       [4.9, 3. , 1....2, 3.4, 5.4, 2.3],
       [5.9, 3. , 5.1, 1.8]]), y=array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,... 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]), context={'baseline_score': 0.9466666666666667, 'baseline_score_std': 0.04988876515698587, 'best_config': {'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': 4, 'max_features': 3, 'max_leaf_nodes': 3, 'min_samples_split': 3, 'n_estimators': 10}, 'config_hash': {'algorithm': 'ffb7ff225ce3d3712c96cf87fe42202988ee2eb0', 'config': 'bae32f426be9cd6243523c023944a8c148fe4aeb', 'pipeline': 'd2a68bfda6fcdec4ae0ffc7d7b6a2122bc1cd673'}, 'duration': 0.7115809917449951, 'iteration': 113, 'loss': 0.033333333333333215, 'max_history_score': 0.9666666666666668, 'max_history_score_std': 0.033333333333333326, 'max_history_step': 'joint', 'pipeline': {'features': ('features_NoneType', {}), 'normalizer': ('normalizer_PowerTransformer', {}), 'rebalance': ('rebalance_CondensedNearestNeighbour', {'rebalance__n_neighbors': 2})}, 'score': 0.9666666666666668, ...}, 'history': [{'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': 2, 'max_features': None, 'max_leaf_nodes': 5, 'min_samples_split': 2, 'n_estimators': 75}, 'config_hash': {'algorithm': '3af5b0cce71c8fe2545246ca24ff5bc3dd516e06', 'config': 'db6ac7e6d348155757e4794bb5f88fe2b4f63d50', 'pipeline': '8d59f4b94cef6be9306ed86a22a9570fa670d567'}, 'duration': 1.149928092956543, 'iteration': 0, 'loss': 0.046666666666666634, 'max_history_score': 0.9533333333333334, 'max_history_score_std': 0.059999999999999984, 'max_history_step': 'joint', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 4, 'features__selectkbest__k': 3}), 'normalizer': ('normalizer_StandardScaler', {'normalizer__with_mean': True, 'normalizer__with_std': True}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 6})}, 'score': 0.9533333333333334, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': 1, 'max_features': 2, 'max_leaf_nodes': 2, 'min_samples_split': 5, 'n_estimators': 100}, 'config_hash': {'algorithm': 'e13eb05fd9a62d2f63bbb1c1deff0cd620d5e6ab', 'config': '4db6fb84d85f52659f780e682ffac5712c3d8a94', 'pipeline': '64c9a1ca9d53ae67244bdd942f4db36a3c05218c'}, 'duration': 1.7678282260894775, 'iteration': 1, 'loss': 0.18000000000000005, 'max_history_score': 0.9533333333333334, 'max_history_score_std': 0.059999999999999984, 'max_history_step': 'joint', 'pipeline': {'features': ('features_NoneType', {}), 'normalizer': ('normalizer_PowerTransformer', {}), 'rebalance': ('rebalance_NearMiss', {'rebalance__n_neighbors': 1})}, 'score': 0.82, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': 1, 'max_features': None, 'max_leaf_nodes': None, 'min_samples_split': 5, 'n_estimators': 75}, 'config_hash': {'algorithm': '94b0d7a654c508cc63643f78fe4f0f07e6f07c1e', 'config': '4403c5a85e951938d3c454e961d3a412780722f6', 'pipeline': '3e47444880d8367fbac2faaba2e52a917274aa58'}, 'duration': 0.8397619724273682, 'iteration': 2, 'loss': 0.03333333333333344, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_PCA', {'features__n_components': 3}), 'normalizer': ('normalizer_MinMaxScaler', {}), 'rebalance': ('rebalance_NoneType', {})}, 'score': 0.9666666666666666, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': None, 'max_features': None, 'max_leaf_nodes': 3, 'min_samples_split': 3, 'n_estimators': 75}, 'config_hash': {'algorithm': 'e8332f0a8902bda03bf70e7978cc5d52affb29d3', 'config': 'a064e2df18ab98d44dabcefbc7bed94913f1d0be', 'pipeline': '7eea819c2a8c103c4b1e9e9c1e224aebba95081f'}, 'duration': 0.8501448631286621, 'iteration': 3, 'loss': 0.053333333333333344, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 2, 'features__selectkbest__k': 4}), 'normalizer': ('normalizer_NoneType', {}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 7})}, 'score': 0.9466666666666667, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'entropy', 'max_depth': 3, 'max_features': 3, 'max_leaf_nodes': None, 'min_samples_split': 5, 'n_estimators': 75}, 'config_hash': {'algorithm': '7a4491035bc6bd737fe9a8cda8a79a02d02d5c74', 'config': '0ddb6f5cab3db4dddd7682966a57205f3e329ad4', 'pipeline': 'a9ae03fe38334f6868cbf84cdd3d629d4bbe3fb0'}, 'duration': 1.1026010513305664, 'iteration': 4, 'loss': 0.05999999999999994, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 2, 'features__selectkbest__k': 1}), 'normalizer': ('normalizer_NoneType', {}), 'rebalance': ('rebalance_NoneType', {})}, 'score': 0.9400000000000001, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'gini', 'max_depth': 3, 'max_features': 1, 'max_leaf_nodes': 5, 'min_samples_split': 2, 'n_estimators': 25}, 'config_hash': {'algorithm': '9826d20b2d6a0f559cf7f16450ce7526f07e8434', 'config': '49f25751bca61cdd461a8cbd2923689b642f98ed', 'pipeline': '19b249664c5bf067de1fed4334a296f947ce774a'}, 'duration': 0.35647010803222656, 'iteration': 5, 'loss': 0.046666666666666634, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_NoneType', {}), 'normalizer': ('normalizer_NoneType', {}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 6})}, 'score': 0.9533333333333334, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'gini', 'max_depth': 2, 'max_features': 1, 'max_leaf_nodes': 2, 'min_samples_split': 2, 'n_estimators': 50}, 'config_hash': {'algorithm': '0a4f6fbb07e0f32c6f675489a0fc82eee05bd8e1', 'config': '5c3a2b6f5e63fb45f10e41e0318b354912ec44f6', 'pipeline': 'dc3b9f176f090005e38b142f11d80e93a7dc5d5e'}, 'duration': 0.7213859558105469, 'iteration': 6, 'loss': 0.31333333333333324, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 1, 'features__selectkbest__k': 4}), 'normalizer': ('normalizer_PowerTransformer', {}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 7})}, 'score': 0.6866666666666668, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'entropy', 'max_depth': 4, 'max_features': 3, 'max_leaf_nodes': 5, 'min_samples_split': 5, 'n_estimators': 10}, 'config_hash': {'algorithm': 'b8112b97ecfc10f00a195af661dcc861cac21289', 'config': 'd3b129b397350f1b6572651c67c01de49b4b174c', 'pipeline': '5b0357ed7072c37b3d6f458bb5d49ff7d825f603'}, 'duration': 0.8299109935760498, 'iteration': 7, 'loss': 1.0, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_PCA', {'features__n_components': 2}), 'normalizer': ('normalizer_StandardScaler', {'normalizer__with_mean': True, 'normalizer__with_std': False}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 6})}, 'score': 0.0, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'gini', 'max_depth': 4, 'max_features': None, 'max_leaf_nodes': 2, 'min_samples_split': 5, 'n_estimators': 100}, 'config_hash': {'algorithm': '40ca24df19b8d164d9d098a6bed1ce056fbbb961', 'config': '813bde1108cc3c4b9bfb3a22cbb421bda7eac671', 'pipeline': '74a7b8705a1c22f7dea5e44e4ebda8f1e48add71'}, 'duration': 2.2111589908599854, 'iteration': 8, 'loss': 0.33333333333333326, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_PCA', {'features__n_components': 2}), 'normalizer': ('normalizer_StandardScaler', {'normalizer__with_mean': False, 'normalizer__with_std': True}), 'rebalance': ('rebalance_NearMiss', {'rebalance__n_neighbors': 2})}, 'score': 0.6666666666666667, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'entropy', 'max_depth': 2, 'max_features': 1, 'max_leaf_nodes': 5, 'min_samples_split': 2, 'n_estimators': 100}, 'config_hash': {'algorithm': '331418a5c12cf1453876eef85e9d98fc8e54fa11', 'config': '31930b6860ed406d59bf7e59ba1925d94704bd3b', 'pipeline': '054bef356f90ec6f644ef3ffc688766744db51c2'}, 'duration': 1.0501940250396729, 'iteration': 9, 'loss': 0.053333333333333344, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_SelectKBest', {'features__k': 1}), 'normalizer': ('normalizer_RobustScaler', {'normalizer__quantile_range': (...), 'normalizer__with_centering': True, 'normalizer__with_scaling': True}), 'rebalance': ('rebalance_NearMiss', {'rebalance__n_neighbors': 2})}, 'score': 0.9466666666666667, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'entropy', 'max_depth': 3, 'max_features': None, 'max_leaf_nodes': 3, 'min_samples_split': 2, 'n_estimators': 100}, 'config_hash': {'algorithm': 'dbc1b8126649fe93dce5fbb37e4015b0acfb179e', 'config': '9913cd550615a9d0946ab4a755a8b9f619e442fd', 'pipeline': 'dd626121cea079ebb32e184ca65483ec7a6d7f59'}, 'duration': 1.120617151260376, 'iteration': 10, 'loss': 0.046666666666666634, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 2, 'features__selectkbest__k': 1}), 'normalizer': ('normalizer_MinMaxScaler', {}), 'rebalance': ('rebalance_NoneType', {})}, 'score': 0.9533333333333334, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'gini', 'max_depth': 3, 'max_features': 3, 'max_leaf_nodes': None, 'min_samples_split': 3, 'n_estimators': 75}, 'config_hash': {'algorithm': '34917a130df5a975f78bd7ec1a0c7b1ffdc787a9', 'config': '95fc8cadc088141290b7de9c388977e4685f0108', 'pipeline': '550d10faf2f08db48516cc3501558816d6a99bc0'}, 'duration': 1.4287099838256836, 'iteration': 11, 'loss': 0.19333333333333313, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 3, 'features__selectkbest__k': 4}), 'normalizer': ('normalizer_StandardScaler', {'normalizer__with_mean': False, 'normalizer__with_std': False}), 'rebalance': ('rebalance_CondensedNearestNeighbour', {'rebalance__n_neighbors': 1})}, 'score': 0.8066666666666669, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'entropy', 'max_depth': 1, 'max_features': 2, 'max_leaf_nodes': 5, 'min_samples_split': 2, 'n_estimators': 75}, 'config_hash': {'algorithm': '33f9abb4aee44a395a9f3b3ffa9ce80a8cdaed7c', 'config': '40fa726f0360cf6af55f9b5902d399d02f61f157', 'pipeline': 'cfd1d20841fe2153da762c95e79f95a3fb1e426a'}, 'duration': 1.2978079319000244, 'iteration': 12, 'loss': 0.053333333333333344, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_PCA', {'features__n_components': 4}), 'normalizer': ('normalizer_MinMaxScaler', {}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 7})}, 'score': 0.9466666666666667, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'entropy', 'max_depth': 4, 'max_features': 2, 'max_leaf_nodes': 5, 'min_samples_split': 3, 'n_estimators': 25}, 'config_hash': {'algorithm': '210111ec6562d09eb093e98ed69ef1c662e11a50', 'config': '0fb8e77c7bd9a58b72f1b33c21a59a09a8c676ba', 'pipeline': '5d269d759e0c7926a685a14b263ace8ae0071e4b'}, 'duration': 0.36649012565612793, 'iteration': 13, 'loss': 0.040000000000000036, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 2, 'features__selectkbest__k': 2}), 'normalizer': ('normalizer_NoneType', {}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 7})}, 'score': 0.96, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'entropy', 'max_depth': 3, 'max_features': 1, 'max_leaf_nodes': 5, 'min_samples_split': 2, 'n_estimators': 25}, 'config_hash': {'algorithm': '0e989a03980101fabf79eda3326ed2870e11d690', 'config': 'f4bffd5d8c67a9c5321a9943c4a99678f59a02b7', 'pipeline': '865ee1e3fe8334c3d5ecb2038d5a5d1b3ba50e75'}, 'duration': 0.35639500617980957, 'iteration': 14, 'loss': 0.046666666666666634, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_NoneType', {}), 'normalizer': ('normalizer_RobustScaler', {'normalizer__quantile_range': (...), 'normalizer__with_centering': True, 'normalizer__with_scaling': False}), 'rebalance': ('rebalance_NoneType', {})}, 'score': 0.9533333333333334, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'entropy', 'max_depth': None, 'max_features': 3, 'max_leaf_nodes': 3, 'min_samples_split': 5, 'n_estimators': 10}, 'config_hash': {'algorithm': '9c592e876c13de5e23e6de5b868e01755d63e72e', 'config': '1e6a68cd1eeac886d90724d78b1cb5fb76a3cde4', 'pipeline': '5a1ca4d82f21b7de0d2c918630a42510673fa36e'}, 'duration': 0.18141412734985352, 'iteration': 15, 'loss': 0.046666666666666634, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_SelectKBest', {'features__k': 3}), 'normalizer': ('normalizer_RobustScaler', {'normalizer__quantile_range': (...), 'normalizer__with_centering': True, 'normalizer__with_scaling': True}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 6})}, 'score': 0.9533333333333334, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': 1, 'max_features': None, 'max_leaf_nodes': None, 'min_samples_split': 5, 'n_estimators': 10}, 'config_hash': {'algorithm': '8bed77aef289bfd453b2858bd288ae5ba7160f2b', 'config': '781185bcb8999045de8d489f253a1a1ba4247932', 'pipeline': '1ece7eabedc2be9e5b0a1be65c570d08ffa3eb54'}, 'duration': 0.1636829376220703, 'iteration': 16, 'loss': 0.053333333333333344, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_NoneType', {}), 'normalizer': ('normalizer_NoneType', {}), 'rebalance': ('rebalance_NearMiss', {'rebalance__n_neighbors': 1})}, 'score': 0.9466666666666667, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'gini', 'max_depth': 3, 'max_features': 2, 'max_leaf_nodes': 2, 'min_samples_split': 5, 'n_estimators': 75}, 'config_hash': {'algorithm': '617b97d9ba21d3373bc51ffa9cccf9c6f91a77b3', 'config': '99fb425b4e8c5d80228cab94202252aa25cdf77c', 'pipeline': 'd6242929c3b515c7719e60423023ac604311afc3'}, 'duration': 0.8468999862670898, 'iteration': 17, 'loss': 0.24, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_PCA', {'features__n_components': 4}), 'normalizer': ('normalizer_PowerTransformer', {}), 'rebalance': ('rebalance_NearMiss', {'rebalance__n_neighbors': 2})}, 'score': 0.76, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': 1, 'max_features': 1, 'max_leaf_nodes': 2, 'min_samples_split': 5, 'n_estimators': 50}, 'config_hash': {'algorithm': 'b92d2697cdd4979da443369d6596229ec091626a', 'config': 'c513a3e13281206ad76187dd817b1fff93d54fe1', 'pipeline': 'c4b4f914a3ca8df967cade997a90366d85a371b9'}, 'duration': 0.6724588871002197, 'iteration': 18, 'loss': 0.23333333333333328, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 1, 'features__selectkbest__k': 3}), 'normalizer': ('normalizer_StandardScaler', {'normalizer__with_mean': True, 'normalizer__with_std': True}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 5})}, 'score': 0.7666666666666667, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'entropy', 'max_depth': None, 'max_features': None, 'max_leaf_nodes': 5, 'min_samples_split': 5, 'n_estimators': 10}, 'config_hash': {'algorithm': 'a0115de695e6cca2e81cbfb54df79bf4b43608b1', 'config': 'ba194015e20b5d67770e8c67342c3d8d0d01dc41', 'pipeline': '8d45fabfeb85ffdcabf7076bd0e65fffe97ce928'}, 'duration': 0.19424200057983398, 'iteration': 19, 'loss': 0.08666666666666667, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_PCA', {'features__n_components': 3}), 'normalizer': ('normalizer_NoneType', {}), 'rebalance': ('rebalance_NoneType', {})}, 'score': 0.9133333333333333, ...}, ...], 'history_hash': ['db6ac7e6d348155757e4794bb5f88fe2b4f63d50', '4db6fb84d85f52659f780e682ffac5712c3d8a94', '4403c5a85e951938d3c454e961d3a412780722f6', 'a064e2df18ab98d44dabcefbc7bed94913f1d0be', '0ddb6f5cab3db4dddd7682966a57205f3e329ad4', '49f25751bca61cdd461a8cbd2923689b642f98ed', '5c3a2b6f5e63fb45f10e41e0318b354912ec44f6', 'd3b129b397350f1b6572651c67c01de49b4b174c', '813bde1108cc3c4b9bfb3a22cbb421bda7eac671', '31930b6860ed406d59bf7e59ba1925d94704bd3b', '9913cd550615a9d0946ab4a755a8b9f619e442fd', '95fc8cadc088141290b7de9c388977e4685f0108', '40fa726f0360cf6af55f9b5902d399d02f61f157', '0fb8e77c7bd9a58b72f1b33c21a59a09a8c676ba', 'f4bffd5d8c67a9c5321a9943c4a99678f59a02b7', '1e6a68cd1eeac886d90724d78b1cb5fb76a3cde4', '781185bcb8999045de8d489f253a1a1ba4247932', '99fb425b4e8c5d80228cab94202252aa25cdf77c', 'c513a3e13281206ad76187dd817b1fff93d54fe1', 'ba194015e20b5d67770e8c67342c3d8d0d01dc41', ...], 'history_index': {'00f0493590a2cb5e98a35b29816f8cd9f87f96ec': 208, '013329309d510b94f19d930320402d65f953a847': 39, '038a0f515e2ec894ee8e34f9caa2889eb3ebd5ce': 66, '052ae4bf232b316187b078abae42c2be19e16a00': 111, '05e9258ebf99dd97202167ef1563fa834b0568f1': 242, '0659afebf316aafeb75612fb07081a04c28545ed': 74, '06e7cde9f3556cd01332ce389ad1d8925cd4b4a4': 120, '07ab8a30d853e39a326b7017026a20e94bc45541': 245, '08606f2a0f0a6c9de204020b4632e09fcee0ae56': 168, '09dbd0948e5b8c1b1f0930778babe65c8a81295e': 243, ...}, 'iteration': 299, 'max_history_score': 0.9666666666666668, 'max_history_score_std': 0.033333333333333326, 'max_history_step': 'joint'}, config={'algorithm': 'RandomForest', 'seed': 42, 'time': 300}, step='joint')
     45                 y,
     46                 cv=10,
     47                 n_jobs=-1,
     48                 return_estimator=False,
     49                 return_train_score=False,
---> 50                 verbose=0)
     51         score = np.mean(scores['test_score'])
     52         std = np.std(scores['test_score'])
     53         status = STATUS_OK
     54     except Exception as e:

...........................................................................
/home/aquemy/.local/lib/python2.7/site-packages/sklearn/model_selection/_validation.py in cross_validate(estimator=Pipeline(memory=None,
     steps=[('rebalance', ... random_state=42, verbose=0, warm_start=False))]), X=array([[5.1, 3.5, 1.4, 0.2],
       [4.9, 3. , 1....2, 3.4, 5.4, 2.3],
       [5.9, 3. , 5.1, 1.8]]), y=array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,... 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]), groups=None, scoring=None, cv=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1, verbose=0, fit_params=None, pre_dispatch='2*n_jobs', return_train_score=False, return_estimator=False, error_score='raise-deprecating')
    235         delayed(_fit_and_score)(
    236             clone(estimator), X, y, scorers, train, test, verbose, None,
    237             fit_params, return_train_score=return_train_score,
    238             return_times=True, return_estimator=return_estimator,
    239             error_score=error_score)
--> 240         for train, test in cv.split(X, y, groups))
        cv.split = <bound method StratifiedKFold.split of Stratifie...d(n_splits=10, random_state=None, shuffle=False)>
        X = array([[5.1, 3.5, 1.4, 0.2],
       [4.9, 3. , 1....2, 3.4, 5.4, 2.3],
       [5.9, 3. , 5.1, 1.8]])
        y = array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,... 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2])
        groups = None
    241 
    242     zipped_scores = list(zip(*scores))
    243     if return_train_score:
    244         train_scores = zipped_scores.pop(0)

...........................................................................
/home/aquemy/.local/lib/python2.7/site-packages/sklearn/externals/joblib/parallel.py in __call__(self=Parallel(n_jobs=-1), iterable=<generator object <genexpr>>)
    925                 # No need to wait for async callbacks to trigger to
    926                 # consumption.
    927                 self._iterating = False
    928 
    929             with self._backend.retrieval_context():
--> 930                 self.retrieve()
        self.retrieve = <bound method Parallel.retrieve of Parallel(n_jobs=-1)>
    931             # Make sure that we get a last message telling us we are done
    932             elapsed_time = time.time() - self._start_time
    933             self._print('Done %3i out of %3i | elapsed: %s finished',
    934                         (len(self._output), len(self._output),

---------------------------------------------------------------------------
Joblib worker traceback:
---------------------------------------------------------------------------
ValueError                                         Mon Jun 17 13:14:38 2019
PID: 21889                                  Python 2.7.15+: /usr/bin/python
...........................................................................
/home/aquemy/.local/lib/python2.7/site-packages/sklearn/externals/joblib/parallel.py in __call__(self=<sklearn.externals.joblib.parallel.BatchedCalls object>)
    220     def __call__(self):
    221         # Set the default nested backend to self._backend but do not set the
    222         # change the default number of processes to -1
    223         with parallel_backend(self._backend, n_jobs=self._n_jobs):
    224             return [func(*args, **kwargs)
--> 225                     for func, args, kwargs in self.items]
        func = <function _fit_and_score>
        args = (Pipeline(memory=None,
     steps=[('rebalance', ... random_state=42, verbose=0, warm_start=False))]), array([[5.1, 3.5, 1.4, 0.2],
       [4.9, 3. , 1....2, 3.4, 5.4, 2.3],
       [5.9, 3. , 5.1, 1.8]]), array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,... 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]), {'score': <function _passthrough_scorer>}, array([  5,   6,   7,   8,   9,  10,  11,  12,  ..., 142, 143, 144,
       145, 146, 147, 148, 149]), array([  0,   1,   2,   3,   4,  50,  51,  52,  53,  54, 100, 101, 102,
       103, 104]), 0, None, None)
        kwargs = {'error_score': 'raise-deprecating', 'return_estimator': False, 'return_times': True, 'return_train_score': False}
        self.items = [(<function _fit_and_score>, (Pipeline(memory=None,
     steps=[('rebalance', ... random_state=42, verbose=0, warm_start=False))]), array([[5.1, 3.5, 1.4, 0.2],
       [4.9, 3. , 1....2, 3.4, 5.4, 2.3],
       [5.9, 3. , 5.1, 1.8]]), array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,... 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]), {'score': <function _passthrough_scorer>}, array([  5,   6,   7,   8,   9,  10,  11,  12,  ..., 142, 143, 144,
       145, 146, 147, 148, 149]), array([  0,   1,   2,   3,   4,  50,  51,  52,  53,  54, 100, 101, 102,
       103, 104]), 0, None, None), {'error_score': 'raise-deprecating', 'return_estimator': False, 'return_times': True, 'return_train_score': False})]
    226 
    227     def __len__(self):
    228         return self._size
    229 

...........................................................................
/home/aquemy/.local/lib/python2.7/site-packages/sklearn/model_selection/_validation.py in _fit_and_score(estimator=Pipeline(memory=None,
     steps=[('rebalance', ... random_state=42, verbose=0, warm_start=False))]), X=array([[5.1, 3.5, 1.4, 0.2],
       [4.9, 3. , 1....2, 3.4, 5.4, 2.3],
       [5.9, 3. , 5.1, 1.8]]), y=array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,... 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]), scorer={'score': <function _passthrough_scorer>}, train=array([  5,   6,   7,   8,   9,  10,  11,  12,  ..., 142, 143, 144,
       145, 146, 147, 148, 149]), test=array([  0,   1,   2,   3,   4,  50,  51,  52,  53,  54, 100, 101, 102,
       103, 104]), verbose=0, parameters=None, fit_params={}, return_train_score=False, return_parameters=False, return_n_test_samples=False, return_times=True, return_estimator=False, error_score='raise-deprecating')
    523 
    524     try:
    525         if y_train is None:
    526             estimator.fit(X_train, **fit_params)
    527         else:
--> 528             estimator.fit(X_train, y_train, **fit_params)
        estimator.fit = <bound method Pipeline.fit of Pipeline(memory=No...random_state=42, verbose=0, warm_start=False))])>
        X_train = array([[5.4, 3.9, 1.7, 0.4],
       [4.6, 3.4, 1....2, 3.4, 5.4, 2.3],
       [5.9, 3. , 5.1, 1.8]])
        y_train = array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,
       2, 2, 2])
        fit_params = {}
    529 
    530     except Exception as e:
    531         # Note fit time as time until error
    532         fit_time = time.time() - start_time

...........................................................................
/usr/local/lib/python2.7/dist-packages/imblearn/pipeline.py in fit(self=Pipeline(memory=None,
     steps=[('rebalance', ... random_state=42, verbose=0, warm_start=False))]), X=array([[5.4, 3.9, 1.7, 0.4],
       [4.6, 3.4, 1....2, 3.4, 5.4, 2.3],
       [5.9, 3. , 5.1, 1.8]]), y=array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,
       2, 2, 2]), **fit_params={})
    234             This estimator
    235 
    236         """
    237         Xt, yt, fit_params = self._fit(X, y, **fit_params)
    238         if self._final_estimator is not None:
--> 239             self._final_estimator.fit(Xt, yt, **fit_params)
        self._final_estimator.fit = <bound method RandomForestClassifier.fit of Rand...e, random_state=42, verbose=0, warm_start=False)>
        Xt = array([[-2.04518519],
       [-2.34518519],
    ...81],
       [ 1.65481481],
       [ 1.35481481]])
        yt = array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,
       2, 2, 2])
        fit_params = {}
    240         return self
    241 
    242     def fit_transform(self, X, y=None, **fit_params):
    243         """Fit the model and transform with the final estimator

...........................................................................
/home/aquemy/.local/lib/python2.7/site-packages/sklearn/ensemble/forest.py in fit(self=RandomForestClassifier(bootstrap=True, class_wei...se, random_state=42, verbose=0, warm_start=False), X=array([[-2.045185  ],
       [-2.3451853 ],
    ....6548148 ],
       [ 1.3548148 ]], dtype=float32), y=array([[0.],
       [0.],
       [0.],
       [0...    [2.],
       [2.],
       [2.],
       [2.]]), sample_weight=None)
    328             trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,
    329                              **_joblib_parallel_args(prefer='threads'))(
    330                 delayed(_parallel_build_trees)(
    331                     t, self, X, y, sample_weight, i, len(trees),
    332                     verbose=self.verbose, class_weight=self.class_weight)
--> 333                 for i, t in enumerate(trees))
        i = 9
    334 
    335             # Collect newly grown trees
    336             self.estimators_.extend(trees)
    337 

...........................................................................
/home/aquemy/.local/lib/python2.7/site-packages/sklearn/externals/joblib/parallel.py in __call__(self=Parallel(n_jobs=1), iterable=<generator object <genexpr>>)
    912             # self._original_iterator is None, then this means either
    913             # that pre_dispatch == "all", n_jobs == 1 or that the first batch
    914             # was very quick and its callback already dispatched all the
    915             # remaining jobs.
    916             self._iterating = False
--> 917             if self.dispatch_one_batch(iterator):
        self.dispatch_one_batch = <bound method Parallel.dispatch_one_batch of Parallel(n_jobs=1)>
        iterator = <generator object <genexpr>>
    918                 self._iterating = self._original_iterator is not None
    919 
    920             while self.dispatch_one_batch(iterator):
    921                 pass

...........................................................................
/home/aquemy/.local/lib/python2.7/site-packages/sklearn/externals/joblib/parallel.py in dispatch_one_batch(self=Parallel(n_jobs=1), iterator=<generator object <genexpr>>)
    754                                  self._pickle_cache)
    755             if len(tasks) == 0:
    756                 # No more tasks available in the iterator: tell caller to stop.
    757                 return False
    758             else:
--> 759                 self._dispatch(tasks)
        self._dispatch = <bound method Parallel._dispatch of Parallel(n_jobs=1)>
        tasks = <sklearn.externals.joblib.parallel.BatchedCalls object>
    760                 return True
    761 
    762     def _print(self, msg, msg_args):
    763         """Display the message on stout or stderr depending on verbosity"""

...........................................................................
/home/aquemy/.local/lib/python2.7/site-packages/sklearn/externals/joblib/parallel.py in _dispatch(self=Parallel(n_jobs=1), batch=<sklearn.externals.joblib.parallel.BatchedCalls object>)
    711 
    712         dispatch_timestamp = time.time()
    713         cb = BatchCompletionCallBack(dispatch_timestamp, len(batch), self)
    714         with self._lock:
    715             job_idx = len(self._jobs)
--> 716             job = self._backend.apply_async(batch, callback=cb)
        job = undefined
        self._backend.apply_async = <bound method SequentialBackend.apply_async of <...lib._parallel_backends.SequentialBackend object>>
        batch = <sklearn.externals.joblib.parallel.BatchedCalls object>
        cb = <sklearn.externals.joblib.parallel.BatchCompletionCallBack object>
    717             # A job can complete so quickly than its callback is
    718             # called before we get here, causing self._jobs to
    719             # grow. To ensure correct results ordering, .insert is
    720             # used (rather than .append) in the following line

...........................................................................
/home/aquemy/.local/lib/python2.7/site-packages/sklearn/externals/joblib/_parallel_backends.py in apply_async(self=<sklearn.externals.joblib._parallel_backends.SequentialBackend object>, func=<sklearn.externals.joblib.parallel.BatchedCalls object>, callback=<sklearn.externals.joblib.parallel.BatchCompletionCallBack object>)
    177             raise ValueError('n_jobs == 0 in Parallel has no meaning')
    178         return 1
    179 
    180     def apply_async(self, func, callback=None):
    181         """Schedule a func to be run"""
--> 182         result = ImmediateResult(func)
        result = undefined
        func = <sklearn.externals.joblib.parallel.BatchedCalls object>
    183         if callback:
    184             callback(result)
    185         return result
    186 

...........................................................................
/home/aquemy/.local/lib/python2.7/site-packages/sklearn/externals/joblib/_parallel_backends.py in __init__(self=<sklearn.externals.joblib._parallel_backends.ImmediateResult object>, batch=<sklearn.externals.joblib.parallel.BatchedCalls object>)
    544 
    545 class ImmediateResult(object):
    546     def __init__(self, batch):
    547         # Don't delay the application, to avoid keeping the input
    548         # arguments in memory
--> 549         self.results = batch()
        self.results = undefined
        batch = <sklearn.externals.joblib.parallel.BatchedCalls object>
    550 
    551     def get(self):
    552         return self.results
    553 

...........................................................................
/home/aquemy/.local/lib/python2.7/site-packages/sklearn/externals/joblib/parallel.py in __call__(self=<sklearn.externals.joblib.parallel.BatchedCalls object>)
    220     def __call__(self):
    221         # Set the default nested backend to self._backend but do not set the
    222         # change the default number of processes to -1
    223         with parallel_backend(self._backend, n_jobs=self._n_jobs):
    224             return [func(*args, **kwargs)
--> 225                     for func, args, kwargs in self.items]
        func = <function _parallel_build_trees>
        args = (DecisionTreeClassifier(class_weight=None, criter...=False, random_state=1608637542, splitter='best'), RandomForestClassifier(bootstrap=True, class_wei...se, random_state=42, verbose=0, warm_start=False), array([[-2.045185  ],
       [-2.3451853 ],
    ....6548148 ],
       [ 1.3548148 ]], dtype=float32), array([[0.],
       [0.],
       [0.],
       [0...    [2.],
       [2.],
       [2.],
       [2.]]), None, 0, 10)
        kwargs = {'class_weight': None, 'verbose': 0}
        self.items = [(<function _parallel_build_trees>, (DecisionTreeClassifier(class_weight=None, criter...=False, random_state=1608637542, splitter='best'), RandomForestClassifier(bootstrap=True, class_wei...se, random_state=42, verbose=0, warm_start=False), array([[-2.045185  ],
       [-2.3451853 ],
    ....6548148 ],
       [ 1.3548148 ]], dtype=float32), array([[0.],
       [0.],
       [0.],
       [0...    [2.],
       [2.],
       [2.],
       [2.]]), None, 0, 10), {'class_weight': None, 'verbose': 0})]
    226 
    227     def __len__(self):
    228         return self._size
    229 

...........................................................................
/home/aquemy/.local/lib/python2.7/site-packages/sklearn/ensemble/forest.py in _parallel_build_trees(tree=DecisionTreeClassifier(class_weight=None, criter...=False, random_state=1608637542, splitter='best'), forest=RandomForestClassifier(bootstrap=True, class_wei...se, random_state=42, verbose=0, warm_start=False), X=array([[-2.045185  ],
       [-2.3451853 ],
    ....6548148 ],
       [ 1.3548148 ]], dtype=float32), y=array([[0.],
       [0.],
       [0.],
       [0...    [2.],
       [2.],
       [2.],
       [2.]]), sample_weight=None, tree_idx=0, n_trees=10, verbose=0, class_weight=None)
    114                 simplefilter('ignore', DeprecationWarning)
    115                 curr_sample_weight *= compute_sample_weight('auto', y, indices)
    116         elif class_weight == 'balanced_subsample':
    117             curr_sample_weight *= compute_sample_weight('balanced', y, indices)
    118 
--> 119         tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)
        tree.fit = <bound method DecisionTreeClassifier.fit of Deci...False, random_state=1608637542, splitter='best')>
        X = array([[-2.045185  ],
       [-2.3451853 ],
    ....6548148 ],
       [ 1.3548148 ]], dtype=float32)
        y = array([[0.],
       [0.],
       [0.],
       [0...    [2.],
       [2.],
       [2.],
       [2.]])
        sample_weight = None
        curr_sample_weight = array([3., 3., 0., 1., 1., 2., 2., 0., 1., 2., 0... 1., 0., 1., 0., 1., 1., 1., 1., 1., 1., 0., 0.])
    120     else:
    121         tree.fit(X, y, sample_weight=sample_weight, check_input=False)
    122 
    123     return tree

...........................................................................
/home/aquemy/.local/lib/python2.7/site-packages/sklearn/tree/tree.py in fit(self=DecisionTreeClassifier(class_weight=None, criter...=False, random_state=1608637542, splitter='best'), X=array([[-2.045185  ],
       [-2.3451853 ],
    ....6548148 ],
       [ 1.3548148 ]], dtype=float32), y=array([[0.],
       [0.],
       [0.],
       [0...    [2.],
       [2.],
       [2.],
       [2.]]), sample_weight=array([3., 3., 0., 1., 1., 2., 2., 0., 1., 2., 0... 1., 0., 1., 0., 1., 1., 1., 1., 1., 1., 0., 0.]), check_input=False, X_idx_sorted=None)
    796 
    797         super(DecisionTreeClassifier, self).fit(
    798             X, y,
    799             sample_weight=sample_weight,
    800             check_input=check_input,
--> 801             X_idx_sorted=X_idx_sorted)
        X_idx_sorted = None
    802         return self
    803 
    804     def predict_proba(self, X, check_input=True):
    805         """Predict class probabilities of the input samples X.

...........................................................................
/home/aquemy/.local/lib/python2.7/site-packages/sklearn/tree/tree.py in fit(self=DecisionTreeClassifier(class_weight=None, criter...=False, random_state=1608637542, splitter='best'), X=array([[-2.045185  ],
       [-2.3451853 ],
    ....6548148 ],
       [ 1.3548148 ]], dtype=float32), y=array([[0.],
       [0.],
       [0.],
       [0...    [2.],
       [2.],
       [2.],
       [2.]]), sample_weight=array([3., 3., 0., 1., 1., 2., 2., 0., 1., 2., 0... 1., 0., 1., 0., 1., 1., 1., 1., 1., 1., 0., 0.]), check_input=False, X_idx_sorted=None)
    237         if not 0 <= self.min_weight_fraction_leaf <= 0.5:
    238             raise ValueError("min_weight_fraction_leaf must in [0, 0.5]")
    239         if max_depth <= 0:
    240             raise ValueError("max_depth must be greater than zero. ")
    241         if not (0 < max_features <= self.n_features_):
--> 242             raise ValueError("max_features must be in (0, n_features]")
    243         if not isinstance(max_leaf_nodes, (numbers.Integral, np.integer)):
    244             raise ValueError("max_leaf_nodes must be integral number but was "
    245                              "%r" % max_leaf_nodes)
    246         if -1 < max_leaf_nodes < 2:

ValueError: max_features must be in (0, n_features]
___________________________________________________________________________
Best score: 0.966666666667 (0.0333333333333) [J] | Score: 0.0 (0.0) [J]
Best score: 0.966666666667 (0.0333333333333) [J] | Score: 0.966666666667 (0.0333333333333) [J]
Best score: 0.966666666667 (0.0333333333333) [J] | Score: 0.946666666667 (0.0581186525805) [J]
Best score: 0.966666666667 (0.0333333333333) [J] | Score: 0.94 (0.0553774924195) [J]
Best score: 0.966666666667 (0.0333333333333) [J] | Score: 0.966666666667 (0.04472135955) [J]
Best score: 0.966666666667 (0.0333333333333) [J] | Score: 0.966666666667 (0.0333333333333) [J]
Best score: 0.966666666667 (0.0333333333333) [J] | Score: 0.666666666667 (1.11022302463e-16) [J]
Best score: 0.966666666667 (0.0333333333333) [J] | Score: 0.94 (0.0359010987142) [J]
Best score: 0.966666666667 (0.0333333333333) [J] | Score: 0.906666666667 (0.0853749898324) [J]
JoblibValueError
___________________________________________________________________________
...........................................................................
/home/aquemy/dev/dp_hyperparameters/extension/main.py in <module>()
     27 
     28     serializer.serialize_results(scenario, policy)
     29 
     30 if __name__ == "__main__":
     31     args = cli.parse_args()
---> 32     main(args)

...........................................................................
/home/aquemy/dev/dp_hyperparameters/extension/main.py in main(args=Namespace(customize=[(['control', 'seed'], '42')...io='./scenarios/rf_iris_joint.yaml', verbosity=0))
     21         test_size=0.4, 
     22         random_state=scenario['control']['seed']
     23     )
     24 
     25     policy = policies.initiate(scenario['setup']['policy'], config)
---> 26     policy.run(X,y)
        policy.run = <bound method Joint.run of <experiment.policies.joint.Joint object>>
        X = array([[5.1, 3.5, 1.4, 0.2],
       [4.9, 3. , 1....2, 3.4, 5.4, 2.3],
       [5.9, 3. , 5.1, 1.8]])
        y = array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,... 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2])
     27 
     28     serializer.serialize_results(scenario, policy)
     29 
     30 if __name__ == "__main__":

...........................................................................
/home/aquemy/dev/dp_hyperparameters/extension/experiment/policies/joint.py in run(self=<experiment.policies.joint.Joint object>, X=array([[5.1, 3.5, 1.4, 0.2],
       [4.9, 3. , 1....2, 3.4, 5.4, 2.3],
       [5.9, 3. , 5.1, 1.8]]), y=array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,... 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]))
     32             algo=tpe.suggest, 
     33             max_evals=None,
     34             max_time=self.config['time'],     
     35             trials=trials,
     36             show_progressbar=False,
---> 37             verbose=0
     38         )
     39 
     40         best_config = self.context['best_config']
     41         super(Joint, self).display_step_results(best_config)

...........................................................................
/home/aquemy/dev/dp_hyperparameters/extension/hyperopt/fmin.py in fmin(fn=<functools.partial object>, space={'algorithm': {'bootstrap': <hyperopt.pyll.base.Apply object>, 'criterion': <hyperopt.pyll.base.Apply object>, 'max_depth': <hyperopt.pyll.base.Apply object>, 'max_features': <hyperopt.pyll.base.Apply object>, 'max_leaf_nodes': <hyperopt.pyll.base.Apply object>, 'min_samples_split': <hyperopt.pyll.base.Apply object>, 'n_estimators': <hyperopt.pyll.base.Apply object>}, 'pipeline': {'features': <hyperopt.pyll.base.Apply object>, 'normalizer': <hyperopt.pyll.base.Apply object>, 'rebalance': <hyperopt.pyll.base.Apply object>}}, algo=<function suggest>, max_evals=9223372036854775807, max_time=300, trials=<hyperopt.base.Trials object>, rstate=<mtrand.RandomState object>, allow_trials_fmin=True, pass_expr_memo_ctrl=None, catch_eval_exceptions=False, verbose=0, return_argmin=True, points_to_evaluate=None, max_queue_len=1, show_progressbar=False)
    406             pass_expr_memo_ctrl=pass_expr_memo_ctrl,
    407             verbose=verbose,
    408             catch_eval_exceptions=catch_eval_exceptions,
    409             return_argmin=return_argmin,
    410             show_progressbar=show_progressbar,
--> 411             max_time=max_time
        max_time = 300
    412         )
    413 
    414     if trials is None:
    415         if points_to_evaluate is None:

...........................................................................
/home/aquemy/dev/dp_hyperparameters/extension/hyperopt/base.py in fmin(self=<hyperopt.base.Trials object>, fn=<functools.partial object>, space={'algorithm': {'bootstrap': <hyperopt.pyll.base.Apply object>, 'criterion': <hyperopt.pyll.base.Apply object>, 'max_depth': <hyperopt.pyll.base.Apply object>, 'max_features': <hyperopt.pyll.base.Apply object>, 'max_leaf_nodes': <hyperopt.pyll.base.Apply object>, 'min_samples_split': <hyperopt.pyll.base.Apply object>, 'n_estimators': <hyperopt.pyll.base.Apply object>}, 'pipeline': {'features': <hyperopt.pyll.base.Apply object>, 'normalizer': <hyperopt.pyll.base.Apply object>, 'rebalance': <hyperopt.pyll.base.Apply object>}}, algo=<function suggest>, max_evals=9223372036854775807, max_time=300, rstate=<mtrand.RandomState object>, verbose=0, pass_expr_memo_ctrl=None, catch_eval_exceptions=False, return_argmin=True, show_progressbar=False)
    636             verbose=verbose,
    637             allow_trials_fmin=False,  # -- prevent recursion
    638             pass_expr_memo_ctrl=pass_expr_memo_ctrl,
    639             catch_eval_exceptions=catch_eval_exceptions,
    640             return_argmin=return_argmin,
--> 641             show_progressbar=show_progressbar)
        show_progressbar = False
    642 
    643 
    644 def trials_from_docs(docs, validate=True, **kwargs):
    645     """Construct a Trials base class instance from a list of trials documents

...........................................................................
/home/aquemy/dev/dp_hyperparameters/extension/hyperopt/fmin.py in fmin(fn=<functools.partial object>, space={'algorithm': {'bootstrap': <hyperopt.pyll.base.Apply object>, 'criterion': <hyperopt.pyll.base.Apply object>, 'max_depth': <hyperopt.pyll.base.Apply object>, 'max_features': <hyperopt.pyll.base.Apply object>, 'max_leaf_nodes': <hyperopt.pyll.base.Apply object>, 'min_samples_split': <hyperopt.pyll.base.Apply object>, 'n_estimators': <hyperopt.pyll.base.Apply object>}, 'pipeline': {'features': <hyperopt.pyll.base.Apply object>, 'normalizer': <hyperopt.pyll.base.Apply object>, 'rebalance': <hyperopt.pyll.base.Apply object>}}, algo=<function suggest>, max_evals=9223372036854775807, max_time=300, trials=<hyperopt.base.Trials object>, rstate=<mtrand.RandomState object>, allow_trials_fmin=False, pass_expr_memo_ctrl=None, catch_eval_exceptions=False, verbose=0, return_argmin=True, points_to_evaluate=None, max_queue_len=1, show_progressbar=False)
    426                     verbose=verbose,
    427                     max_queue_len=max_queue_len,
    428                     show_progressbar=show_progressbar,
    429                     max_time=max_time)
    430     rval.catch_eval_exceptions = catch_eval_exceptions
--> 431     rval.exhaust()
        rval.exhaust = <bound method FMinIter.exhaust of <hyperopt.fmin.FMinIter object>>
    432     if return_argmin:
    433         return trials.argmin
    434     elif len(trials) > 0:
    435         # Only if there are some succesfull trail runs, return the best point in the evaluation space

...........................................................................
/home/aquemy/dev/dp_hyperparameters/extension/hyperopt/fmin.py in exhaust(self=<hyperopt.fmin.FMinIter object>)
    273             raise StopIteration()
    274         return self.trials
    275 
    276     def exhaust(self):
    277         n_done = len(self.trials)
--> 278         self.run(self.max_evals - n_done, block_until_done=self.asynchronous)
        self.run = <bound method FMinIter.run of <hyperopt.fmin.FMinIter object>>
        self.max_evals = 9223372036854775807
        n_done = 0
        self.asynchronous = False
    279         self.trials.refresh()
    280         return self
    281 
    282 

...........................................................................
/home/aquemy/dev/dp_hyperparameters/extension/hyperopt/fmin.py in run(self=<hyperopt.fmin.FMinIter object>, N=9223372036854775807, block_until_done=False)
    232                     if self.asynchronous:
    233                         # -- wait for workers to fill in the trials
    234                         time.sleep(self.poll_interval_secs)
    235                     else:
    236                         # -- loop over trials and do the jobs directly
--> 237                         self.serial_evaluate()
        self.serial_evaluate = <bound method FMinIter.serial_evaluate of <hyperopt.fmin.FMinIter object>>
    238                     try:
    239                         res = [d['result']['loss'] for d in
    240                                          self.trials.trials if
    241                                          d['result']['status'] == 'ok']

...........................................................................
/home/aquemy/dev/dp_hyperparameters/extension/hyperopt/fmin.py in serial_evaluate(self=<hyperopt.fmin.FMinIter object>, N=-1)
    138                 trial['book_time'] = now
    139                 trial['refresh_time'] = now
    140                 spec = base.spec_from_misc(trial['misc'])
    141                 ctrl = base.Ctrl(self.trials, current_trial=trial)
    142                 try:
--> 143                     result = self.domain.evaluate(spec, ctrl)
        result = undefined
        self.domain.evaluate = <bound method Domain.evaluate of <hyperopt.base.Domain object>>
        spec = {'bootstrap': 0, 'criterion': 0, 'features': 1, 'features_PCA_features__n_components': 1, 'max_depth': 1, 'max_features': 2, 'max_leaf_nodes': 1, 'min_samples_split': 2, 'n_estimators': 0, 'normalizer': 3, ...}
        ctrl = <hyperopt.base.Ctrl object>
    144                 except Exception as e:
    145                     logger.info('job exception: %s' % str(e))
    146                     trial['state'] = base.JOB_STATE_ERROR
    147                     trial['misc']['error'] = (str(type(e)), str(e))

...........................................................................
/home/aquemy/dev/dp_hyperparameters/extension/hyperopt/base.py in evaluate(self=<hyperopt.base.Domain object>, config={'bootstrap': 0, 'criterion': 0, 'features': 1, 'features_PCA_features__n_components': 1, 'max_depth': 1, 'max_features': 2, 'max_leaf_nodes': 1, 'min_samples_split': 2, 'n_estimators': 0, 'normalizer': 3, ...}, ctrl=<hyperopt.base.Ctrl object>, attach_attachments=True)
    841             #    or the normal Python part (self.fn)
    842             pyll_rval = pyll.rec_eval(
    843                 self.expr,
    844                 memo=memo,
    845                 print_node_on_error=self.rec_eval_print_node_on_error)
--> 846             rval = self.fn(pyll_rval)
        rval = undefined
        self.fn = <functools.partial object>
        pyll_rval = {'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': 2, 'max_features': 3, 'max_leaf_nodes': 3, 'min_samples_split': 5, 'n_estimators': 10}, 'pipeline': {'features': ('features_PCA', {'features__n_components': 2}), 'normalizer': ('normalizer_MinMaxScaler', {}), 'rebalance': ('rebalance_NearMiss', {'rebalance__n_neighbors': 3})}}
    847 
    848         if isinstance(rval, (float, int, np.number)):
    849             dict_rval = {'loss': float(rval), 'status': STATUS_OK}
    850         else:

...........................................................................
/home/aquemy/dev/dp_hyperparameters/extension/experiment/objective.py in objective_joint(wconfig={'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': 2, 'max_features': 3, 'max_leaf_nodes': 3, 'min_samples_split': 5, 'n_estimators': 10}, 'pipeline': {'features': ('features_PCA', {'features__n_components': 2}), 'normalizer': ('normalizer_MinMaxScaler', {}), 'rebalance': ('rebalance_NearMiss', {'rebalance__n_neighbors': 3})}}, algorithm='RandomForest', X=array([[5.1, 3.5, 1.4, 0.2],
       [4.9, 3. , 1....2, 3.4, 5.4, 2.3],
       [5.9, 3. , 5.1, 1.8]]), y=array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,... 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]), context={'baseline_score': 0.9466666666666667, 'baseline_score_std': 0.04988876515698587, 'best_config': {'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': 4, 'max_features': 3, 'max_leaf_nodes': 3, 'min_samples_split': 3, 'n_estimators': 10}, 'config_hash': {'algorithm': 'ffb7ff225ce3d3712c96cf87fe42202988ee2eb0', 'config': 'bae32f426be9cd6243523c023944a8c148fe4aeb', 'pipeline': 'd2a68bfda6fcdec4ae0ffc7d7b6a2122bc1cd673'}, 'duration': 0.7115809917449951, 'iteration': 113, 'loss': 0.033333333333333215, 'max_history_score': 0.9666666666666668, 'max_history_score_std': 0.033333333333333326, 'max_history_step': 'joint', 'pipeline': {'features': ('features_NoneType', {}), 'normalizer': ('normalizer_PowerTransformer', {}), 'rebalance': ('rebalance_CondensedNearestNeighbour', {'rebalance__n_neighbors': 2})}, 'score': 0.9666666666666668, ...}, 'history': [{'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': 2, 'max_features': None, 'max_leaf_nodes': 5, 'min_samples_split': 2, 'n_estimators': 75}, 'config_hash': {'algorithm': '3af5b0cce71c8fe2545246ca24ff5bc3dd516e06', 'config': 'db6ac7e6d348155757e4794bb5f88fe2b4f63d50', 'pipeline': '8d59f4b94cef6be9306ed86a22a9570fa670d567'}, 'duration': 1.149928092956543, 'iteration': 0, 'loss': 0.046666666666666634, 'max_history_score': 0.9533333333333334, 'max_history_score_std': 0.059999999999999984, 'max_history_step': 'joint', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 4, 'features__selectkbest__k': 3}), 'normalizer': ('normalizer_StandardScaler', {'normalizer__with_mean': True, 'normalizer__with_std': True}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 6})}, 'score': 0.9533333333333334, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': 1, 'max_features': 2, 'max_leaf_nodes': 2, 'min_samples_split': 5, 'n_estimators': 100}, 'config_hash': {'algorithm': 'e13eb05fd9a62d2f63bbb1c1deff0cd620d5e6ab', 'config': '4db6fb84d85f52659f780e682ffac5712c3d8a94', 'pipeline': '64c9a1ca9d53ae67244bdd942f4db36a3c05218c'}, 'duration': 1.7678282260894775, 'iteration': 1, 'loss': 0.18000000000000005, 'max_history_score': 0.9533333333333334, 'max_history_score_std': 0.059999999999999984, 'max_history_step': 'joint', 'pipeline': {'features': ('features_NoneType', {}), 'normalizer': ('normalizer_PowerTransformer', {}), 'rebalance': ('rebalance_NearMiss', {'rebalance__n_neighbors': 1})}, 'score': 0.82, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': 1, 'max_features': None, 'max_leaf_nodes': None, 'min_samples_split': 5, 'n_estimators': 75}, 'config_hash': {'algorithm': '94b0d7a654c508cc63643f78fe4f0f07e6f07c1e', 'config': '4403c5a85e951938d3c454e961d3a412780722f6', 'pipeline': '3e47444880d8367fbac2faaba2e52a917274aa58'}, 'duration': 0.8397619724273682, 'iteration': 2, 'loss': 0.03333333333333344, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_PCA', {'features__n_components': 3}), 'normalizer': ('normalizer_MinMaxScaler', {}), 'rebalance': ('rebalance_NoneType', {})}, 'score': 0.9666666666666666, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': None, 'max_features': None, 'max_leaf_nodes': 3, 'min_samples_split': 3, 'n_estimators': 75}, 'config_hash': {'algorithm': 'e8332f0a8902bda03bf70e7978cc5d52affb29d3', 'config': 'a064e2df18ab98d44dabcefbc7bed94913f1d0be', 'pipeline': '7eea819c2a8c103c4b1e9e9c1e224aebba95081f'}, 'duration': 0.8501448631286621, 'iteration': 3, 'loss': 0.053333333333333344, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 2, 'features__selectkbest__k': 4}), 'normalizer': ('normalizer_NoneType', {}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 7})}, 'score': 0.9466666666666667, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'entropy', 'max_depth': 3, 'max_features': 3, 'max_leaf_nodes': None, 'min_samples_split': 5, 'n_estimators': 75}, 'config_hash': {'algorithm': '7a4491035bc6bd737fe9a8cda8a79a02d02d5c74', 'config': '0ddb6f5cab3db4dddd7682966a57205f3e329ad4', 'pipeline': 'a9ae03fe38334f6868cbf84cdd3d629d4bbe3fb0'}, 'duration': 1.1026010513305664, 'iteration': 4, 'loss': 0.05999999999999994, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 2, 'features__selectkbest__k': 1}), 'normalizer': ('normalizer_NoneType', {}), 'rebalance': ('rebalance_NoneType', {})}, 'score': 0.9400000000000001, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'gini', 'max_depth': 3, 'max_features': 1, 'max_leaf_nodes': 5, 'min_samples_split': 2, 'n_estimators': 25}, 'config_hash': {'algorithm': '9826d20b2d6a0f559cf7f16450ce7526f07e8434', 'config': '49f25751bca61cdd461a8cbd2923689b642f98ed', 'pipeline': '19b249664c5bf067de1fed4334a296f947ce774a'}, 'duration': 0.35647010803222656, 'iteration': 5, 'loss': 0.046666666666666634, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_NoneType', {}), 'normalizer': ('normalizer_NoneType', {}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 6})}, 'score': 0.9533333333333334, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'gini', 'max_depth': 2, 'max_features': 1, 'max_leaf_nodes': 2, 'min_samples_split': 2, 'n_estimators': 50}, 'config_hash': {'algorithm': '0a4f6fbb07e0f32c6f675489a0fc82eee05bd8e1', 'config': '5c3a2b6f5e63fb45f10e41e0318b354912ec44f6', 'pipeline': 'dc3b9f176f090005e38b142f11d80e93a7dc5d5e'}, 'duration': 0.7213859558105469, 'iteration': 6, 'loss': 0.31333333333333324, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 1, 'features__selectkbest__k': 4}), 'normalizer': ('normalizer_PowerTransformer', {}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 7})}, 'score': 0.6866666666666668, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'entropy', 'max_depth': 4, 'max_features': 3, 'max_leaf_nodes': 5, 'min_samples_split': 5, 'n_estimators': 10}, 'config_hash': {'algorithm': 'b8112b97ecfc10f00a195af661dcc861cac21289', 'config': 'd3b129b397350f1b6572651c67c01de49b4b174c', 'pipeline': '5b0357ed7072c37b3d6f458bb5d49ff7d825f603'}, 'duration': 0.8299109935760498, 'iteration': 7, 'loss': 1.0, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_PCA', {'features__n_components': 2}), 'normalizer': ('normalizer_StandardScaler', {'normalizer__with_mean': True, 'normalizer__with_std': False}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 6})}, 'score': 0.0, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'gini', 'max_depth': 4, 'max_features': None, 'max_leaf_nodes': 2, 'min_samples_split': 5, 'n_estimators': 100}, 'config_hash': {'algorithm': '40ca24df19b8d164d9d098a6bed1ce056fbbb961', 'config': '813bde1108cc3c4b9bfb3a22cbb421bda7eac671', 'pipeline': '74a7b8705a1c22f7dea5e44e4ebda8f1e48add71'}, 'duration': 2.2111589908599854, 'iteration': 8, 'loss': 0.33333333333333326, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_PCA', {'features__n_components': 2}), 'normalizer': ('normalizer_StandardScaler', {'normalizer__with_mean': False, 'normalizer__with_std': True}), 'rebalance': ('rebalance_NearMiss', {'rebalance__n_neighbors': 2})}, 'score': 0.6666666666666667, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'entropy', 'max_depth': 2, 'max_features': 1, 'max_leaf_nodes': 5, 'min_samples_split': 2, 'n_estimators': 100}, 'config_hash': {'algorithm': '331418a5c12cf1453876eef85e9d98fc8e54fa11', 'config': '31930b6860ed406d59bf7e59ba1925d94704bd3b', 'pipeline': '054bef356f90ec6f644ef3ffc688766744db51c2'}, 'duration': 1.0501940250396729, 'iteration': 9, 'loss': 0.053333333333333344, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_SelectKBest', {'features__k': 1}), 'normalizer': ('normalizer_RobustScaler', {'normalizer__quantile_range': (...), 'normalizer__with_centering': True, 'normalizer__with_scaling': True}), 'rebalance': ('rebalance_NearMiss', {'rebalance__n_neighbors': 2})}, 'score': 0.9466666666666667, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'entropy', 'max_depth': 3, 'max_features': None, 'max_leaf_nodes': 3, 'min_samples_split': 2, 'n_estimators': 100}, 'config_hash': {'algorithm': 'dbc1b8126649fe93dce5fbb37e4015b0acfb179e', 'config': '9913cd550615a9d0946ab4a755a8b9f619e442fd', 'pipeline': 'dd626121cea079ebb32e184ca65483ec7a6d7f59'}, 'duration': 1.120617151260376, 'iteration': 10, 'loss': 0.046666666666666634, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 2, 'features__selectkbest__k': 1}), 'normalizer': ('normalizer_MinMaxScaler', {}), 'rebalance': ('rebalance_NoneType', {})}, 'score': 0.9533333333333334, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'gini', 'max_depth': 3, 'max_features': 3, 'max_leaf_nodes': None, 'min_samples_split': 3, 'n_estimators': 75}, 'config_hash': {'algorithm': '34917a130df5a975f78bd7ec1a0c7b1ffdc787a9', 'config': '95fc8cadc088141290b7de9c388977e4685f0108', 'pipeline': '550d10faf2f08db48516cc3501558816d6a99bc0'}, 'duration': 1.4287099838256836, 'iteration': 11, 'loss': 0.19333333333333313, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 3, 'features__selectkbest__k': 4}), 'normalizer': ('normalizer_StandardScaler', {'normalizer__with_mean': False, 'normalizer__with_std': False}), 'rebalance': ('rebalance_CondensedNearestNeighbour', {'rebalance__n_neighbors': 1})}, 'score': 0.8066666666666669, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'entropy', 'max_depth': 1, 'max_features': 2, 'max_leaf_nodes': 5, 'min_samples_split': 2, 'n_estimators': 75}, 'config_hash': {'algorithm': '33f9abb4aee44a395a9f3b3ffa9ce80a8cdaed7c', 'config': '40fa726f0360cf6af55f9b5902d399d02f61f157', 'pipeline': 'cfd1d20841fe2153da762c95e79f95a3fb1e426a'}, 'duration': 1.2978079319000244, 'iteration': 12, 'loss': 0.053333333333333344, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_PCA', {'features__n_components': 4}), 'normalizer': ('normalizer_MinMaxScaler', {}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 7})}, 'score': 0.9466666666666667, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'entropy', 'max_depth': 4, 'max_features': 2, 'max_leaf_nodes': 5, 'min_samples_split': 3, 'n_estimators': 25}, 'config_hash': {'algorithm': '210111ec6562d09eb093e98ed69ef1c662e11a50', 'config': '0fb8e77c7bd9a58b72f1b33c21a59a09a8c676ba', 'pipeline': '5d269d759e0c7926a685a14b263ace8ae0071e4b'}, 'duration': 0.36649012565612793, 'iteration': 13, 'loss': 0.040000000000000036, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 2, 'features__selectkbest__k': 2}), 'normalizer': ('normalizer_NoneType', {}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 7})}, 'score': 0.96, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'entropy', 'max_depth': 3, 'max_features': 1, 'max_leaf_nodes': 5, 'min_samples_split': 2, 'n_estimators': 25}, 'config_hash': {'algorithm': '0e989a03980101fabf79eda3326ed2870e11d690', 'config': 'f4bffd5d8c67a9c5321a9943c4a99678f59a02b7', 'pipeline': '865ee1e3fe8334c3d5ecb2038d5a5d1b3ba50e75'}, 'duration': 0.35639500617980957, 'iteration': 14, 'loss': 0.046666666666666634, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_NoneType', {}), 'normalizer': ('normalizer_RobustScaler', {'normalizer__quantile_range': (...), 'normalizer__with_centering': True, 'normalizer__with_scaling': False}), 'rebalance': ('rebalance_NoneType', {})}, 'score': 0.9533333333333334, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'entropy', 'max_depth': None, 'max_features': 3, 'max_leaf_nodes': 3, 'min_samples_split': 5, 'n_estimators': 10}, 'config_hash': {'algorithm': '9c592e876c13de5e23e6de5b868e01755d63e72e', 'config': '1e6a68cd1eeac886d90724d78b1cb5fb76a3cde4', 'pipeline': '5a1ca4d82f21b7de0d2c918630a42510673fa36e'}, 'duration': 0.18141412734985352, 'iteration': 15, 'loss': 0.046666666666666634, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_SelectKBest', {'features__k': 3}), 'normalizer': ('normalizer_RobustScaler', {'normalizer__quantile_range': (...), 'normalizer__with_centering': True, 'normalizer__with_scaling': True}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 6})}, 'score': 0.9533333333333334, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': 1, 'max_features': None, 'max_leaf_nodes': None, 'min_samples_split': 5, 'n_estimators': 10}, 'config_hash': {'algorithm': '8bed77aef289bfd453b2858bd288ae5ba7160f2b', 'config': '781185bcb8999045de8d489f253a1a1ba4247932', 'pipeline': '1ece7eabedc2be9e5b0a1be65c570d08ffa3eb54'}, 'duration': 0.1636829376220703, 'iteration': 16, 'loss': 0.053333333333333344, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_NoneType', {}), 'normalizer': ('normalizer_NoneType', {}), 'rebalance': ('rebalance_NearMiss', {'rebalance__n_neighbors': 1})}, 'score': 0.9466666666666667, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'gini', 'max_depth': 3, 'max_features': 2, 'max_leaf_nodes': 2, 'min_samples_split': 5, 'n_estimators': 75}, 'config_hash': {'algorithm': '617b97d9ba21d3373bc51ffa9cccf9c6f91a77b3', 'config': '99fb425b4e8c5d80228cab94202252aa25cdf77c', 'pipeline': 'd6242929c3b515c7719e60423023ac604311afc3'}, 'duration': 0.8468999862670898, 'iteration': 17, 'loss': 0.24, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_PCA', {'features__n_components': 4}), 'normalizer': ('normalizer_PowerTransformer', {}), 'rebalance': ('rebalance_NearMiss', {'rebalance__n_neighbors': 2})}, 'score': 0.76, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': 1, 'max_features': 1, 'max_leaf_nodes': 2, 'min_samples_split': 5, 'n_estimators': 50}, 'config_hash': {'algorithm': 'b92d2697cdd4979da443369d6596229ec091626a', 'config': 'c513a3e13281206ad76187dd817b1fff93d54fe1', 'pipeline': 'c4b4f914a3ca8df967cade997a90366d85a371b9'}, 'duration': 0.6724588871002197, 'iteration': 18, 'loss': 0.23333333333333328, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 1, 'features__selectkbest__k': 3}), 'normalizer': ('normalizer_StandardScaler', {'normalizer__with_mean': True, 'normalizer__with_std': True}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 5})}, 'score': 0.7666666666666667, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'entropy', 'max_depth': None, 'max_features': None, 'max_leaf_nodes': 5, 'min_samples_split': 5, 'n_estimators': 10}, 'config_hash': {'algorithm': 'a0115de695e6cca2e81cbfb54df79bf4b43608b1', 'config': 'ba194015e20b5d67770e8c67342c3d8d0d01dc41', 'pipeline': '8d45fabfeb85ffdcabf7076bd0e65fffe97ce928'}, 'duration': 0.19424200057983398, 'iteration': 19, 'loss': 0.08666666666666667, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_PCA', {'features__n_components': 3}), 'normalizer': ('normalizer_NoneType', {}), 'rebalance': ('rebalance_NoneType', {})}, 'score': 0.9133333333333333, ...}, ...], 'history_hash': ['db6ac7e6d348155757e4794bb5f88fe2b4f63d50', '4db6fb84d85f52659f780e682ffac5712c3d8a94', '4403c5a85e951938d3c454e961d3a412780722f6', 'a064e2df18ab98d44dabcefbc7bed94913f1d0be', '0ddb6f5cab3db4dddd7682966a57205f3e329ad4', '49f25751bca61cdd461a8cbd2923689b642f98ed', '5c3a2b6f5e63fb45f10e41e0318b354912ec44f6', 'd3b129b397350f1b6572651c67c01de49b4b174c', '813bde1108cc3c4b9bfb3a22cbb421bda7eac671', '31930b6860ed406d59bf7e59ba1925d94704bd3b', '9913cd550615a9d0946ab4a755a8b9f619e442fd', '95fc8cadc088141290b7de9c388977e4685f0108', '40fa726f0360cf6af55f9b5902d399d02f61f157', '0fb8e77c7bd9a58b72f1b33c21a59a09a8c676ba', 'f4bffd5d8c67a9c5321a9943c4a99678f59a02b7', '1e6a68cd1eeac886d90724d78b1cb5fb76a3cde4', '781185bcb8999045de8d489f253a1a1ba4247932', '99fb425b4e8c5d80228cab94202252aa25cdf77c', 'c513a3e13281206ad76187dd817b1fff93d54fe1', 'ba194015e20b5d67770e8c67342c3d8d0d01dc41', ...], 'history_index': {'00f0493590a2cb5e98a35b29816f8cd9f87f96ec': 208, '01161dcc5f8ee022f65481dacf76468db745b463': 306, '013329309d510b94f19d930320402d65f953a847': 39, '038a0f515e2ec894ee8e34f9caa2889eb3ebd5ce': 66, '052ae4bf232b316187b078abae42c2be19e16a00': 111, '05e9258ebf99dd97202167ef1563fa834b0568f1': 242, '0659afebf316aafeb75612fb07081a04c28545ed': 74, '06e7cde9f3556cd01332ce389ad1d8925cd4b4a4': 120, '07ab8a30d853e39a326b7017026a20e94bc45541': 245, '0855e6ed1503da05dc544450a5da27e4b3441758': 307, ...}, 'iteration': 308, 'max_history_score': 0.9666666666666668, 'max_history_score_std': 0.033333333333333326, 'max_history_step': 'joint'}, config={'algorithm': 'RandomForest', 'seed': 42, 'time': 300})
    108 
    109 def objective_algo(algo_config, current_pipeline_config, algorithm, X, y, context, config):
    110     return objective(current_pipeline_config, algo_config, algorithm, X, y, context, config, step='algorithm')
    111 
    112 def objective_joint(wconfig, algorithm, X, y, context, config):
--> 113     return objective(wconfig['pipeline'], wconfig['algorithm'], algorithm, X, y, context, config, step='joint')
        wconfig = {'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': 2, 'max_features': 3, 'max_leaf_nodes': 3, 'min_samples_split': 5, 'n_estimators': 10}, 'pipeline': {'features': ('features_PCA', {'features__n_components': 2}), 'normalizer': ('normalizer_MinMaxScaler', {}), 'rebalance': ('rebalance_NearMiss', {'rebalance__n_neighbors': 3})}}
        algorithm = 'RandomForest'
        X = array([[5.1, 3.5, 1.4, 0.2],
       [4.9, 3. , 1....2, 3.4, 5.4, 2.3],
       [5.9, 3. , 5.1, 1.8]])
        y = array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,... 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2])
        context = {'baseline_score': 0.9466666666666667, 'baseline_score_std': 0.04988876515698587, 'best_config': {'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': 4, 'max_features': 3, 'max_leaf_nodes': 3, 'min_samples_split': 3, 'n_estimators': 10}, 'config_hash': {'algorithm': 'ffb7ff225ce3d3712c96cf87fe42202988ee2eb0', 'config': 'bae32f426be9cd6243523c023944a8c148fe4aeb', 'pipeline': 'd2a68bfda6fcdec4ae0ffc7d7b6a2122bc1cd673'}, 'duration': 0.7115809917449951, 'iteration': 113, 'loss': 0.033333333333333215, 'max_history_score': 0.9666666666666668, 'max_history_score_std': 0.033333333333333326, 'max_history_step': 'joint', 'pipeline': {'features': ('features_NoneType', {}), 'normalizer': ('normalizer_PowerTransformer', {}), 'rebalance': ('rebalance_CondensedNearestNeighbour', {'rebalance__n_neighbors': 2})}, 'score': 0.9666666666666668, ...}, 'history': [{'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': 2, 'max_features': None, 'max_leaf_nodes': 5, 'min_samples_split': 2, 'n_estimators': 75}, 'config_hash': {'algorithm': '3af5b0cce71c8fe2545246ca24ff5bc3dd516e06', 'config': 'db6ac7e6d348155757e4794bb5f88fe2b4f63d50', 'pipeline': '8d59f4b94cef6be9306ed86a22a9570fa670d567'}, 'duration': 1.149928092956543, 'iteration': 0, 'loss': 0.046666666666666634, 'max_history_score': 0.9533333333333334, 'max_history_score_std': 0.059999999999999984, 'max_history_step': 'joint', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 4, 'features__selectkbest__k': 3}), 'normalizer': ('normalizer_StandardScaler', {'normalizer__with_mean': True, 'normalizer__with_std': True}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 6})}, 'score': 0.9533333333333334, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': 1, 'max_features': 2, 'max_leaf_nodes': 2, 'min_samples_split': 5, 'n_estimators': 100}, 'config_hash': {'algorithm': 'e13eb05fd9a62d2f63bbb1c1deff0cd620d5e6ab', 'config': '4db6fb84d85f52659f780e682ffac5712c3d8a94', 'pipeline': '64c9a1ca9d53ae67244bdd942f4db36a3c05218c'}, 'duration': 1.7678282260894775, 'iteration': 1, 'loss': 0.18000000000000005, 'max_history_score': 0.9533333333333334, 'max_history_score_std': 0.059999999999999984, 'max_history_step': 'joint', 'pipeline': {'features': ('features_NoneType', {}), 'normalizer': ('normalizer_PowerTransformer', {}), 'rebalance': ('rebalance_NearMiss', {'rebalance__n_neighbors': 1})}, 'score': 0.82, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': 1, 'max_features': None, 'max_leaf_nodes': None, 'min_samples_split': 5, 'n_estimators': 75}, 'config_hash': {'algorithm': '94b0d7a654c508cc63643f78fe4f0f07e6f07c1e', 'config': '4403c5a85e951938d3c454e961d3a412780722f6', 'pipeline': '3e47444880d8367fbac2faaba2e52a917274aa58'}, 'duration': 0.8397619724273682, 'iteration': 2, 'loss': 0.03333333333333344, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_PCA', {'features__n_components': 3}), 'normalizer': ('normalizer_MinMaxScaler', {}), 'rebalance': ('rebalance_NoneType', {})}, 'score': 0.9666666666666666, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': None, 'max_features': None, 'max_leaf_nodes': 3, 'min_samples_split': 3, 'n_estimators': 75}, 'config_hash': {'algorithm': 'e8332f0a8902bda03bf70e7978cc5d52affb29d3', 'config': 'a064e2df18ab98d44dabcefbc7bed94913f1d0be', 'pipeline': '7eea819c2a8c103c4b1e9e9c1e224aebba95081f'}, 'duration': 0.8501448631286621, 'iteration': 3, 'loss': 0.053333333333333344, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 2, 'features__selectkbest__k': 4}), 'normalizer': ('normalizer_NoneType', {}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 7})}, 'score': 0.9466666666666667, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'entropy', 'max_depth': 3, 'max_features': 3, 'max_leaf_nodes': None, 'min_samples_split': 5, 'n_estimators': 75}, 'config_hash': {'algorithm': '7a4491035bc6bd737fe9a8cda8a79a02d02d5c74', 'config': '0ddb6f5cab3db4dddd7682966a57205f3e329ad4', 'pipeline': 'a9ae03fe38334f6868cbf84cdd3d629d4bbe3fb0'}, 'duration': 1.1026010513305664, 'iteration': 4, 'loss': 0.05999999999999994, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 2, 'features__selectkbest__k': 1}), 'normalizer': ('normalizer_NoneType', {}), 'rebalance': ('rebalance_NoneType', {})}, 'score': 0.9400000000000001, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'gini', 'max_depth': 3, 'max_features': 1, 'max_leaf_nodes': 5, 'min_samples_split': 2, 'n_estimators': 25}, 'config_hash': {'algorithm': '9826d20b2d6a0f559cf7f16450ce7526f07e8434', 'config': '49f25751bca61cdd461a8cbd2923689b642f98ed', 'pipeline': '19b249664c5bf067de1fed4334a296f947ce774a'}, 'duration': 0.35647010803222656, 'iteration': 5, 'loss': 0.046666666666666634, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_NoneType', {}), 'normalizer': ('normalizer_NoneType', {}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 6})}, 'score': 0.9533333333333334, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'gini', 'max_depth': 2, 'max_features': 1, 'max_leaf_nodes': 2, 'min_samples_split': 2, 'n_estimators': 50}, 'config_hash': {'algorithm': '0a4f6fbb07e0f32c6f675489a0fc82eee05bd8e1', 'config': '5c3a2b6f5e63fb45f10e41e0318b354912ec44f6', 'pipeline': 'dc3b9f176f090005e38b142f11d80e93a7dc5d5e'}, 'duration': 0.7213859558105469, 'iteration': 6, 'loss': 0.31333333333333324, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 1, 'features__selectkbest__k': 4}), 'normalizer': ('normalizer_PowerTransformer', {}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 7})}, 'score': 0.6866666666666668, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'entropy', 'max_depth': 4, 'max_features': 3, 'max_leaf_nodes': 5, 'min_samples_split': 5, 'n_estimators': 10}, 'config_hash': {'algorithm': 'b8112b97ecfc10f00a195af661dcc861cac21289', 'config': 'd3b129b397350f1b6572651c67c01de49b4b174c', 'pipeline': '5b0357ed7072c37b3d6f458bb5d49ff7d825f603'}, 'duration': 0.8299109935760498, 'iteration': 7, 'loss': 1.0, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_PCA', {'features__n_components': 2}), 'normalizer': ('normalizer_StandardScaler', {'normalizer__with_mean': True, 'normalizer__with_std': False}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 6})}, 'score': 0.0, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'gini', 'max_depth': 4, 'max_features': None, 'max_leaf_nodes': 2, 'min_samples_split': 5, 'n_estimators': 100}, 'config_hash': {'algorithm': '40ca24df19b8d164d9d098a6bed1ce056fbbb961', 'config': '813bde1108cc3c4b9bfb3a22cbb421bda7eac671', 'pipeline': '74a7b8705a1c22f7dea5e44e4ebda8f1e48add71'}, 'duration': 2.2111589908599854, 'iteration': 8, 'loss': 0.33333333333333326, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_PCA', {'features__n_components': 2}), 'normalizer': ('normalizer_StandardScaler', {'normalizer__with_mean': False, 'normalizer__with_std': True}), 'rebalance': ('rebalance_NearMiss', {'rebalance__n_neighbors': 2})}, 'score': 0.6666666666666667, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'entropy', 'max_depth': 2, 'max_features': 1, 'max_leaf_nodes': 5, 'min_samples_split': 2, 'n_estimators': 100}, 'config_hash': {'algorithm': '331418a5c12cf1453876eef85e9d98fc8e54fa11', 'config': '31930b6860ed406d59bf7e59ba1925d94704bd3b', 'pipeline': '054bef356f90ec6f644ef3ffc688766744db51c2'}, 'duration': 1.0501940250396729, 'iteration': 9, 'loss': 0.053333333333333344, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_SelectKBest', {'features__k': 1}), 'normalizer': ('normalizer_RobustScaler', {'normalizer__quantile_range': (...), 'normalizer__with_centering': True, 'normalizer__with_scaling': True}), 'rebalance': ('rebalance_NearMiss', {'rebalance__n_neighbors': 2})}, 'score': 0.9466666666666667, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'entropy', 'max_depth': 3, 'max_features': None, 'max_leaf_nodes': 3, 'min_samples_split': 2, 'n_estimators': 100}, 'config_hash': {'algorithm': 'dbc1b8126649fe93dce5fbb37e4015b0acfb179e', 'config': '9913cd550615a9d0946ab4a755a8b9f619e442fd', 'pipeline': 'dd626121cea079ebb32e184ca65483ec7a6d7f59'}, 'duration': 1.120617151260376, 'iteration': 10, 'loss': 0.046666666666666634, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 2, 'features__selectkbest__k': 1}), 'normalizer': ('normalizer_MinMaxScaler', {}), 'rebalance': ('rebalance_NoneType', {})}, 'score': 0.9533333333333334, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'gini', 'max_depth': 3, 'max_features': 3, 'max_leaf_nodes': None, 'min_samples_split': 3, 'n_estimators': 75}, 'config_hash': {'algorithm': '34917a130df5a975f78bd7ec1a0c7b1ffdc787a9', 'config': '95fc8cadc088141290b7de9c388977e4685f0108', 'pipeline': '550d10faf2f08db48516cc3501558816d6a99bc0'}, 'duration': 1.4287099838256836, 'iteration': 11, 'loss': 0.19333333333333313, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 3, 'features__selectkbest__k': 4}), 'normalizer': ('normalizer_StandardScaler', {'normalizer__with_mean': False, 'normalizer__with_std': False}), 'rebalance': ('rebalance_CondensedNearestNeighbour', {'rebalance__n_neighbors': 1})}, 'score': 0.8066666666666669, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'entropy', 'max_depth': 1, 'max_features': 2, 'max_leaf_nodes': 5, 'min_samples_split': 2, 'n_estimators': 75}, 'config_hash': {'algorithm': '33f9abb4aee44a395a9f3b3ffa9ce80a8cdaed7c', 'config': '40fa726f0360cf6af55f9b5902d399d02f61f157', 'pipeline': 'cfd1d20841fe2153da762c95e79f95a3fb1e426a'}, 'duration': 1.2978079319000244, 'iteration': 12, 'loss': 0.053333333333333344, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_PCA', {'features__n_components': 4}), 'normalizer': ('normalizer_MinMaxScaler', {}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 7})}, 'score': 0.9466666666666667, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'entropy', 'max_depth': 4, 'max_features': 2, 'max_leaf_nodes': 5, 'min_samples_split': 3, 'n_estimators': 25}, 'config_hash': {'algorithm': '210111ec6562d09eb093e98ed69ef1c662e11a50', 'config': '0fb8e77c7bd9a58b72f1b33c21a59a09a8c676ba', 'pipeline': '5d269d759e0c7926a685a14b263ace8ae0071e4b'}, 'duration': 0.36649012565612793, 'iteration': 13, 'loss': 0.040000000000000036, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 2, 'features__selectkbest__k': 2}), 'normalizer': ('normalizer_NoneType', {}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 7})}, 'score': 0.96, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'entropy', 'max_depth': 3, 'max_features': 1, 'max_leaf_nodes': 5, 'min_samples_split': 2, 'n_estimators': 25}, 'config_hash': {'algorithm': '0e989a03980101fabf79eda3326ed2870e11d690', 'config': 'f4bffd5d8c67a9c5321a9943c4a99678f59a02b7', 'pipeline': '865ee1e3fe8334c3d5ecb2038d5a5d1b3ba50e75'}, 'duration': 0.35639500617980957, 'iteration': 14, 'loss': 0.046666666666666634, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_NoneType', {}), 'normalizer': ('normalizer_RobustScaler', {'normalizer__quantile_range': (...), 'normalizer__with_centering': True, 'normalizer__with_scaling': False}), 'rebalance': ('rebalance_NoneType', {})}, 'score': 0.9533333333333334, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'entropy', 'max_depth': None, 'max_features': 3, 'max_leaf_nodes': 3, 'min_samples_split': 5, 'n_estimators': 10}, 'config_hash': {'algorithm': '9c592e876c13de5e23e6de5b868e01755d63e72e', 'config': '1e6a68cd1eeac886d90724d78b1cb5fb76a3cde4', 'pipeline': '5a1ca4d82f21b7de0d2c918630a42510673fa36e'}, 'duration': 0.18141412734985352, 'iteration': 15, 'loss': 0.046666666666666634, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_SelectKBest', {'features__k': 3}), 'normalizer': ('normalizer_RobustScaler', {'normalizer__quantile_range': (...), 'normalizer__with_centering': True, 'normalizer__with_scaling': True}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 6})}, 'score': 0.9533333333333334, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': 1, 'max_features': None, 'max_leaf_nodes': None, 'min_samples_split': 5, 'n_estimators': 10}, 'config_hash': {'algorithm': '8bed77aef289bfd453b2858bd288ae5ba7160f2b', 'config': '781185bcb8999045de8d489f253a1a1ba4247932', 'pipeline': '1ece7eabedc2be9e5b0a1be65c570d08ffa3eb54'}, 'duration': 0.1636829376220703, 'iteration': 16, 'loss': 0.053333333333333344, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_NoneType', {}), 'normalizer': ('normalizer_NoneType', {}), 'rebalance': ('rebalance_NearMiss', {'rebalance__n_neighbors': 1})}, 'score': 0.9466666666666667, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'gini', 'max_depth': 3, 'max_features': 2, 'max_leaf_nodes': 2, 'min_samples_split': 5, 'n_estimators': 75}, 'config_hash': {'algorithm': '617b97d9ba21d3373bc51ffa9cccf9c6f91a77b3', 'config': '99fb425b4e8c5d80228cab94202252aa25cdf77c', 'pipeline': 'd6242929c3b515c7719e60423023ac604311afc3'}, 'duration': 0.8468999862670898, 'iteration': 17, 'loss': 0.24, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_PCA', {'features__n_components': 4}), 'normalizer': ('normalizer_PowerTransformer', {}), 'rebalance': ('rebalance_NearMiss', {'rebalance__n_neighbors': 2})}, 'score': 0.76, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': 1, 'max_features': 1, 'max_leaf_nodes': 2, 'min_samples_split': 5, 'n_estimators': 50}, 'config_hash': {'algorithm': 'b92d2697cdd4979da443369d6596229ec091626a', 'config': 'c513a3e13281206ad76187dd817b1fff93d54fe1', 'pipeline': 'c4b4f914a3ca8df967cade997a90366d85a371b9'}, 'duration': 0.6724588871002197, 'iteration': 18, 'loss': 0.23333333333333328, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 1, 'features__selectkbest__k': 3}), 'normalizer': ('normalizer_StandardScaler', {'normalizer__with_mean': True, 'normalizer__with_std': True}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 5})}, 'score': 0.7666666666666667, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'entropy', 'max_depth': None, 'max_features': None, 'max_leaf_nodes': 5, 'min_samples_split': 5, 'n_estimators': 10}, 'config_hash': {'algorithm': 'a0115de695e6cca2e81cbfb54df79bf4b43608b1', 'config': 'ba194015e20b5d67770e8c67342c3d8d0d01dc41', 'pipeline': '8d45fabfeb85ffdcabf7076bd0e65fffe97ce928'}, 'duration': 0.19424200057983398, 'iteration': 19, 'loss': 0.08666666666666667, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_PCA', {'features__n_components': 3}), 'normalizer': ('normalizer_NoneType', {}), 'rebalance': ('rebalance_NoneType', {})}, 'score': 0.9133333333333333, ...}, ...], 'history_hash': ['db6ac7e6d348155757e4794bb5f88fe2b4f63d50', '4db6fb84d85f52659f780e682ffac5712c3d8a94', '4403c5a85e951938d3c454e961d3a412780722f6', 'a064e2df18ab98d44dabcefbc7bed94913f1d0be', '0ddb6f5cab3db4dddd7682966a57205f3e329ad4', '49f25751bca61cdd461a8cbd2923689b642f98ed', '5c3a2b6f5e63fb45f10e41e0318b354912ec44f6', 'd3b129b397350f1b6572651c67c01de49b4b174c', '813bde1108cc3c4b9bfb3a22cbb421bda7eac671', '31930b6860ed406d59bf7e59ba1925d94704bd3b', '9913cd550615a9d0946ab4a755a8b9f619e442fd', '95fc8cadc088141290b7de9c388977e4685f0108', '40fa726f0360cf6af55f9b5902d399d02f61f157', '0fb8e77c7bd9a58b72f1b33c21a59a09a8c676ba', 'f4bffd5d8c67a9c5321a9943c4a99678f59a02b7', '1e6a68cd1eeac886d90724d78b1cb5fb76a3cde4', '781185bcb8999045de8d489f253a1a1ba4247932', '99fb425b4e8c5d80228cab94202252aa25cdf77c', 'c513a3e13281206ad76187dd817b1fff93d54fe1', 'ba194015e20b5d67770e8c67342c3d8d0d01dc41', ...], 'history_index': {'00f0493590a2cb5e98a35b29816f8cd9f87f96ec': 208, '01161dcc5f8ee022f65481dacf76468db745b463': 306, '013329309d510b94f19d930320402d65f953a847': 39, '038a0f515e2ec894ee8e34f9caa2889eb3ebd5ce': 66, '052ae4bf232b316187b078abae42c2be19e16a00': 111, '05e9258ebf99dd97202167ef1563fa834b0568f1': 242, '0659afebf316aafeb75612fb07081a04c28545ed': 74, '06e7cde9f3556cd01332ce389ad1d8925cd4b4a4': 120, '07ab8a30d853e39a326b7017026a20e94bc45541': 245, '0855e6ed1503da05dc544450a5da27e4b3441758': 307, ...}, 'iteration': 308, 'max_history_score': 0.9666666666666668, 'max_history_score_std': 0.033333333333333326, 'max_history_step': 'joint'}
        config = {'algorithm': 'RandomForest', 'seed': 42, 'time': 300}
    114 
    115 
    116 def get_baseline_score(algorithm, X, y, seed):
    117     pipeline, _ = pipeline_conf_to_full_pipeline(

...........................................................................
/home/aquemy/dev/dp_hyperparameters/extension/experiment/objective.py in objective(pipeline_config={'features': ('features_PCA', {'features__n_components': 2}), 'normalizer': ('normalizer_MinMaxScaler', {}), 'rebalance': ('rebalance_NearMiss', {'rebalance__n_neighbors': 3})}, algo_config={'bootstrap': True, 'criterion': 'gini', 'max_depth': 2, 'max_features': 3, 'max_leaf_nodes': 3, 'min_samples_split': 5, 'n_estimators': 10}, algorithm='RandomForest', X=array([[5.1, 3.5, 1.4, 0.2],
       [4.9, 3. , 1....2, 3.4, 5.4, 2.3],
       [5.9, 3. , 5.1, 1.8]]), y=array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,... 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]), context={'baseline_score': 0.9466666666666667, 'baseline_score_std': 0.04988876515698587, 'best_config': {'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': 4, 'max_features': 3, 'max_leaf_nodes': 3, 'min_samples_split': 3, 'n_estimators': 10}, 'config_hash': {'algorithm': 'ffb7ff225ce3d3712c96cf87fe42202988ee2eb0', 'config': 'bae32f426be9cd6243523c023944a8c148fe4aeb', 'pipeline': 'd2a68bfda6fcdec4ae0ffc7d7b6a2122bc1cd673'}, 'duration': 0.7115809917449951, 'iteration': 113, 'loss': 0.033333333333333215, 'max_history_score': 0.9666666666666668, 'max_history_score_std': 0.033333333333333326, 'max_history_step': 'joint', 'pipeline': {'features': ('features_NoneType', {}), 'normalizer': ('normalizer_PowerTransformer', {}), 'rebalance': ('rebalance_CondensedNearestNeighbour', {'rebalance__n_neighbors': 2})}, 'score': 0.9666666666666668, ...}, 'history': [{'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': 2, 'max_features': None, 'max_leaf_nodes': 5, 'min_samples_split': 2, 'n_estimators': 75}, 'config_hash': {'algorithm': '3af5b0cce71c8fe2545246ca24ff5bc3dd516e06', 'config': 'db6ac7e6d348155757e4794bb5f88fe2b4f63d50', 'pipeline': '8d59f4b94cef6be9306ed86a22a9570fa670d567'}, 'duration': 1.149928092956543, 'iteration': 0, 'loss': 0.046666666666666634, 'max_history_score': 0.9533333333333334, 'max_history_score_std': 0.059999999999999984, 'max_history_step': 'joint', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 4, 'features__selectkbest__k': 3}), 'normalizer': ('normalizer_StandardScaler', {'normalizer__with_mean': True, 'normalizer__with_std': True}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 6})}, 'score': 0.9533333333333334, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': 1, 'max_features': 2, 'max_leaf_nodes': 2, 'min_samples_split': 5, 'n_estimators': 100}, 'config_hash': {'algorithm': 'e13eb05fd9a62d2f63bbb1c1deff0cd620d5e6ab', 'config': '4db6fb84d85f52659f780e682ffac5712c3d8a94', 'pipeline': '64c9a1ca9d53ae67244bdd942f4db36a3c05218c'}, 'duration': 1.7678282260894775, 'iteration': 1, 'loss': 0.18000000000000005, 'max_history_score': 0.9533333333333334, 'max_history_score_std': 0.059999999999999984, 'max_history_step': 'joint', 'pipeline': {'features': ('features_NoneType', {}), 'normalizer': ('normalizer_PowerTransformer', {}), 'rebalance': ('rebalance_NearMiss', {'rebalance__n_neighbors': 1})}, 'score': 0.82, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': 1, 'max_features': None, 'max_leaf_nodes': None, 'min_samples_split': 5, 'n_estimators': 75}, 'config_hash': {'algorithm': '94b0d7a654c508cc63643f78fe4f0f07e6f07c1e', 'config': '4403c5a85e951938d3c454e961d3a412780722f6', 'pipeline': '3e47444880d8367fbac2faaba2e52a917274aa58'}, 'duration': 0.8397619724273682, 'iteration': 2, 'loss': 0.03333333333333344, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_PCA', {'features__n_components': 3}), 'normalizer': ('normalizer_MinMaxScaler', {}), 'rebalance': ('rebalance_NoneType', {})}, 'score': 0.9666666666666666, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': None, 'max_features': None, 'max_leaf_nodes': 3, 'min_samples_split': 3, 'n_estimators': 75}, 'config_hash': {'algorithm': 'e8332f0a8902bda03bf70e7978cc5d52affb29d3', 'config': 'a064e2df18ab98d44dabcefbc7bed94913f1d0be', 'pipeline': '7eea819c2a8c103c4b1e9e9c1e224aebba95081f'}, 'duration': 0.8501448631286621, 'iteration': 3, 'loss': 0.053333333333333344, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 2, 'features__selectkbest__k': 4}), 'normalizer': ('normalizer_NoneType', {}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 7})}, 'score': 0.9466666666666667, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'entropy', 'max_depth': 3, 'max_features': 3, 'max_leaf_nodes': None, 'min_samples_split': 5, 'n_estimators': 75}, 'config_hash': {'algorithm': '7a4491035bc6bd737fe9a8cda8a79a02d02d5c74', 'config': '0ddb6f5cab3db4dddd7682966a57205f3e329ad4', 'pipeline': 'a9ae03fe38334f6868cbf84cdd3d629d4bbe3fb0'}, 'duration': 1.1026010513305664, 'iteration': 4, 'loss': 0.05999999999999994, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 2, 'features__selectkbest__k': 1}), 'normalizer': ('normalizer_NoneType', {}), 'rebalance': ('rebalance_NoneType', {})}, 'score': 0.9400000000000001, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'gini', 'max_depth': 3, 'max_features': 1, 'max_leaf_nodes': 5, 'min_samples_split': 2, 'n_estimators': 25}, 'config_hash': {'algorithm': '9826d20b2d6a0f559cf7f16450ce7526f07e8434', 'config': '49f25751bca61cdd461a8cbd2923689b642f98ed', 'pipeline': '19b249664c5bf067de1fed4334a296f947ce774a'}, 'duration': 0.35647010803222656, 'iteration': 5, 'loss': 0.046666666666666634, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_NoneType', {}), 'normalizer': ('normalizer_NoneType', {}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 6})}, 'score': 0.9533333333333334, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'gini', 'max_depth': 2, 'max_features': 1, 'max_leaf_nodes': 2, 'min_samples_split': 2, 'n_estimators': 50}, 'config_hash': {'algorithm': '0a4f6fbb07e0f32c6f675489a0fc82eee05bd8e1', 'config': '5c3a2b6f5e63fb45f10e41e0318b354912ec44f6', 'pipeline': 'dc3b9f176f090005e38b142f11d80e93a7dc5d5e'}, 'duration': 0.7213859558105469, 'iteration': 6, 'loss': 0.31333333333333324, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 1, 'features__selectkbest__k': 4}), 'normalizer': ('normalizer_PowerTransformer', {}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 7})}, 'score': 0.6866666666666668, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'entropy', 'max_depth': 4, 'max_features': 3, 'max_leaf_nodes': 5, 'min_samples_split': 5, 'n_estimators': 10}, 'config_hash': {'algorithm': 'b8112b97ecfc10f00a195af661dcc861cac21289', 'config': 'd3b129b397350f1b6572651c67c01de49b4b174c', 'pipeline': '5b0357ed7072c37b3d6f458bb5d49ff7d825f603'}, 'duration': 0.8299109935760498, 'iteration': 7, 'loss': 1.0, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_PCA', {'features__n_components': 2}), 'normalizer': ('normalizer_StandardScaler', {'normalizer__with_mean': True, 'normalizer__with_std': False}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 6})}, 'score': 0.0, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'gini', 'max_depth': 4, 'max_features': None, 'max_leaf_nodes': 2, 'min_samples_split': 5, 'n_estimators': 100}, 'config_hash': {'algorithm': '40ca24df19b8d164d9d098a6bed1ce056fbbb961', 'config': '813bde1108cc3c4b9bfb3a22cbb421bda7eac671', 'pipeline': '74a7b8705a1c22f7dea5e44e4ebda8f1e48add71'}, 'duration': 2.2111589908599854, 'iteration': 8, 'loss': 0.33333333333333326, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_PCA', {'features__n_components': 2}), 'normalizer': ('normalizer_StandardScaler', {'normalizer__with_mean': False, 'normalizer__with_std': True}), 'rebalance': ('rebalance_NearMiss', {'rebalance__n_neighbors': 2})}, 'score': 0.6666666666666667, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'entropy', 'max_depth': 2, 'max_features': 1, 'max_leaf_nodes': 5, 'min_samples_split': 2, 'n_estimators': 100}, 'config_hash': {'algorithm': '331418a5c12cf1453876eef85e9d98fc8e54fa11', 'config': '31930b6860ed406d59bf7e59ba1925d94704bd3b', 'pipeline': '054bef356f90ec6f644ef3ffc688766744db51c2'}, 'duration': 1.0501940250396729, 'iteration': 9, 'loss': 0.053333333333333344, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_SelectKBest', {'features__k': 1}), 'normalizer': ('normalizer_RobustScaler', {'normalizer__quantile_range': (...), 'normalizer__with_centering': True, 'normalizer__with_scaling': True}), 'rebalance': ('rebalance_NearMiss', {'rebalance__n_neighbors': 2})}, 'score': 0.9466666666666667, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'entropy', 'max_depth': 3, 'max_features': None, 'max_leaf_nodes': 3, 'min_samples_split': 2, 'n_estimators': 100}, 'config_hash': {'algorithm': 'dbc1b8126649fe93dce5fbb37e4015b0acfb179e', 'config': '9913cd550615a9d0946ab4a755a8b9f619e442fd', 'pipeline': 'dd626121cea079ebb32e184ca65483ec7a6d7f59'}, 'duration': 1.120617151260376, 'iteration': 10, 'loss': 0.046666666666666634, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 2, 'features__selectkbest__k': 1}), 'normalizer': ('normalizer_MinMaxScaler', {}), 'rebalance': ('rebalance_NoneType', {})}, 'score': 0.9533333333333334, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'gini', 'max_depth': 3, 'max_features': 3, 'max_leaf_nodes': None, 'min_samples_split': 3, 'n_estimators': 75}, 'config_hash': {'algorithm': '34917a130df5a975f78bd7ec1a0c7b1ffdc787a9', 'config': '95fc8cadc088141290b7de9c388977e4685f0108', 'pipeline': '550d10faf2f08db48516cc3501558816d6a99bc0'}, 'duration': 1.4287099838256836, 'iteration': 11, 'loss': 0.19333333333333313, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 3, 'features__selectkbest__k': 4}), 'normalizer': ('normalizer_StandardScaler', {'normalizer__with_mean': False, 'normalizer__with_std': False}), 'rebalance': ('rebalance_CondensedNearestNeighbour', {'rebalance__n_neighbors': 1})}, 'score': 0.8066666666666669, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'entropy', 'max_depth': 1, 'max_features': 2, 'max_leaf_nodes': 5, 'min_samples_split': 2, 'n_estimators': 75}, 'config_hash': {'algorithm': '33f9abb4aee44a395a9f3b3ffa9ce80a8cdaed7c', 'config': '40fa726f0360cf6af55f9b5902d399d02f61f157', 'pipeline': 'cfd1d20841fe2153da762c95e79f95a3fb1e426a'}, 'duration': 1.2978079319000244, 'iteration': 12, 'loss': 0.053333333333333344, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_PCA', {'features__n_components': 4}), 'normalizer': ('normalizer_MinMaxScaler', {}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 7})}, 'score': 0.9466666666666667, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'entropy', 'max_depth': 4, 'max_features': 2, 'max_leaf_nodes': 5, 'min_samples_split': 3, 'n_estimators': 25}, 'config_hash': {'algorithm': '210111ec6562d09eb093e98ed69ef1c662e11a50', 'config': '0fb8e77c7bd9a58b72f1b33c21a59a09a8c676ba', 'pipeline': '5d269d759e0c7926a685a14b263ace8ae0071e4b'}, 'duration': 0.36649012565612793, 'iteration': 13, 'loss': 0.040000000000000036, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 2, 'features__selectkbest__k': 2}), 'normalizer': ('normalizer_NoneType', {}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 7})}, 'score': 0.96, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'entropy', 'max_depth': 3, 'max_features': 1, 'max_leaf_nodes': 5, 'min_samples_split': 2, 'n_estimators': 25}, 'config_hash': {'algorithm': '0e989a03980101fabf79eda3326ed2870e11d690', 'config': 'f4bffd5d8c67a9c5321a9943c4a99678f59a02b7', 'pipeline': '865ee1e3fe8334c3d5ecb2038d5a5d1b3ba50e75'}, 'duration': 0.35639500617980957, 'iteration': 14, 'loss': 0.046666666666666634, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_NoneType', {}), 'normalizer': ('normalizer_RobustScaler', {'normalizer__quantile_range': (...), 'normalizer__with_centering': True, 'normalizer__with_scaling': False}), 'rebalance': ('rebalance_NoneType', {})}, 'score': 0.9533333333333334, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'entropy', 'max_depth': None, 'max_features': 3, 'max_leaf_nodes': 3, 'min_samples_split': 5, 'n_estimators': 10}, 'config_hash': {'algorithm': '9c592e876c13de5e23e6de5b868e01755d63e72e', 'config': '1e6a68cd1eeac886d90724d78b1cb5fb76a3cde4', 'pipeline': '5a1ca4d82f21b7de0d2c918630a42510673fa36e'}, 'duration': 0.18141412734985352, 'iteration': 15, 'loss': 0.046666666666666634, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_SelectKBest', {'features__k': 3}), 'normalizer': ('normalizer_RobustScaler', {'normalizer__quantile_range': (...), 'normalizer__with_centering': True, 'normalizer__with_scaling': True}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 6})}, 'score': 0.9533333333333334, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': 1, 'max_features': None, 'max_leaf_nodes': None, 'min_samples_split': 5, 'n_estimators': 10}, 'config_hash': {'algorithm': '8bed77aef289bfd453b2858bd288ae5ba7160f2b', 'config': '781185bcb8999045de8d489f253a1a1ba4247932', 'pipeline': '1ece7eabedc2be9e5b0a1be65c570d08ffa3eb54'}, 'duration': 0.1636829376220703, 'iteration': 16, 'loss': 0.053333333333333344, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_NoneType', {}), 'normalizer': ('normalizer_NoneType', {}), 'rebalance': ('rebalance_NearMiss', {'rebalance__n_neighbors': 1})}, 'score': 0.9466666666666667, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'gini', 'max_depth': 3, 'max_features': 2, 'max_leaf_nodes': 2, 'min_samples_split': 5, 'n_estimators': 75}, 'config_hash': {'algorithm': '617b97d9ba21d3373bc51ffa9cccf9c6f91a77b3', 'config': '99fb425b4e8c5d80228cab94202252aa25cdf77c', 'pipeline': 'd6242929c3b515c7719e60423023ac604311afc3'}, 'duration': 0.8468999862670898, 'iteration': 17, 'loss': 0.24, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_PCA', {'features__n_components': 4}), 'normalizer': ('normalizer_PowerTransformer', {}), 'rebalance': ('rebalance_NearMiss', {'rebalance__n_neighbors': 2})}, 'score': 0.76, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': 1, 'max_features': 1, 'max_leaf_nodes': 2, 'min_samples_split': 5, 'n_estimators': 50}, 'config_hash': {'algorithm': 'b92d2697cdd4979da443369d6596229ec091626a', 'config': 'c513a3e13281206ad76187dd817b1fff93d54fe1', 'pipeline': 'c4b4f914a3ca8df967cade997a90366d85a371b9'}, 'duration': 0.6724588871002197, 'iteration': 18, 'loss': 0.23333333333333328, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 1, 'features__selectkbest__k': 3}), 'normalizer': ('normalizer_StandardScaler', {'normalizer__with_mean': True, 'normalizer__with_std': True}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 5})}, 'score': 0.7666666666666667, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'entropy', 'max_depth': None, 'max_features': None, 'max_leaf_nodes': 5, 'min_samples_split': 5, 'n_estimators': 10}, 'config_hash': {'algorithm': 'a0115de695e6cca2e81cbfb54df79bf4b43608b1', 'config': 'ba194015e20b5d67770e8c67342c3d8d0d01dc41', 'pipeline': '8d45fabfeb85ffdcabf7076bd0e65fffe97ce928'}, 'duration': 0.19424200057983398, 'iteration': 19, 'loss': 0.08666666666666667, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_PCA', {'features__n_components': 3}), 'normalizer': ('normalizer_NoneType', {}), 'rebalance': ('rebalance_NoneType', {})}, 'score': 0.9133333333333333, ...}, ...], 'history_hash': ['db6ac7e6d348155757e4794bb5f88fe2b4f63d50', '4db6fb84d85f52659f780e682ffac5712c3d8a94', '4403c5a85e951938d3c454e961d3a412780722f6', 'a064e2df18ab98d44dabcefbc7bed94913f1d0be', '0ddb6f5cab3db4dddd7682966a57205f3e329ad4', '49f25751bca61cdd461a8cbd2923689b642f98ed', '5c3a2b6f5e63fb45f10e41e0318b354912ec44f6', 'd3b129b397350f1b6572651c67c01de49b4b174c', '813bde1108cc3c4b9bfb3a22cbb421bda7eac671', '31930b6860ed406d59bf7e59ba1925d94704bd3b', '9913cd550615a9d0946ab4a755a8b9f619e442fd', '95fc8cadc088141290b7de9c388977e4685f0108', '40fa726f0360cf6af55f9b5902d399d02f61f157', '0fb8e77c7bd9a58b72f1b33c21a59a09a8c676ba', 'f4bffd5d8c67a9c5321a9943c4a99678f59a02b7', '1e6a68cd1eeac886d90724d78b1cb5fb76a3cde4', '781185bcb8999045de8d489f253a1a1ba4247932', '99fb425b4e8c5d80228cab94202252aa25cdf77c', 'c513a3e13281206ad76187dd817b1fff93d54fe1', 'ba194015e20b5d67770e8c67342c3d8d0d01dc41', ...], 'history_index': {'00f0493590a2cb5e98a35b29816f8cd9f87f96ec': 208, '01161dcc5f8ee022f65481dacf76468db745b463': 306, '013329309d510b94f19d930320402d65f953a847': 39, '038a0f515e2ec894ee8e34f9caa2889eb3ebd5ce': 66, '052ae4bf232b316187b078abae42c2be19e16a00': 111, '05e9258ebf99dd97202167ef1563fa834b0568f1': 242, '0659afebf316aafeb75612fb07081a04c28545ed': 74, '06e7cde9f3556cd01332ce389ad1d8925cd4b4a4': 120, '07ab8a30d853e39a326b7017026a20e94bc45541': 245, '0855e6ed1503da05dc544450a5da27e4b3441758': 307, ...}, 'iteration': 308, 'max_history_score': 0.9666666666666668, 'max_history_score_std': 0.033333333333333326, 'max_history_step': 'joint'}, config={'algorithm': 'RandomForest', 'seed': 42, 'time': 300}, step='joint')
     45                 y,
     46                 cv=10,
     47                 n_jobs=-1,
     48                 return_estimator=False,
     49                 return_train_score=False,
---> 50                 verbose=0)
     51         score = np.mean(scores['test_score'])
     52         std = np.std(scores['test_score'])
     53         status = STATUS_OK
     54     except Exception as e:

...........................................................................
/home/aquemy/.local/lib/python2.7/site-packages/sklearn/model_selection/_validation.py in cross_validate(estimator=Pipeline(memory=None,
     steps=[('rebalance', ... random_state=42, verbose=0, warm_start=False))]), X=array([[5.1, 3.5, 1.4, 0.2],
       [4.9, 3. , 1....2, 3.4, 5.4, 2.3],
       [5.9, 3. , 5.1, 1.8]]), y=array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,... 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]), groups=None, scoring=None, cv=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1, verbose=0, fit_params=None, pre_dispatch='2*n_jobs', return_train_score=False, return_estimator=False, error_score='raise-deprecating')
    235         delayed(_fit_and_score)(
    236             clone(estimator), X, y, scorers, train, test, verbose, None,
    237             fit_params, return_train_score=return_train_score,
    238             return_times=True, return_estimator=return_estimator,
    239             error_score=error_score)
--> 240         for train, test in cv.split(X, y, groups))
        cv.split = <bound method StratifiedKFold.split of Stratifie...d(n_splits=10, random_state=None, shuffle=False)>
        X = array([[5.1, 3.5, 1.4, 0.2],
       [4.9, 3. , 1....2, 3.4, 5.4, 2.3],
       [5.9, 3. , 5.1, 1.8]])
        y = array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,... 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2])
        groups = None
    241 
    242     zipped_scores = list(zip(*scores))
    243     if return_train_score:
    244         train_scores = zipped_scores.pop(0)

...........................................................................
/home/aquemy/.local/lib/python2.7/site-packages/sklearn/externals/joblib/parallel.py in __call__(self=Parallel(n_jobs=-1), iterable=<generator object <genexpr>>)
    925                 # No need to wait for async callbacks to trigger to
    926                 # consumption.
    927                 self._iterating = False
    928 
    929             with self._backend.retrieval_context():
--> 930                 self.retrieve()
        self.retrieve = <bound method Parallel.retrieve of Parallel(n_jobs=-1)>
    931             # Make sure that we get a last message telling us we are done
    932             elapsed_time = time.time() - self._start_time
    933             self._print('Done %3i out of %3i | elapsed: %s finished',
    934                         (len(self._output), len(self._output),

---------------------------------------------------------------------------
Joblib worker traceback:
---------------------------------------------------------------------------
ValueError                                         Mon Jun 17 13:14:47 2019
PID: 21930                                  Python 2.7.15+: /usr/bin/python
...........................................................................
/home/aquemy/.local/lib/python2.7/site-packages/sklearn/externals/joblib/parallel.py in __call__(self=<sklearn.externals.joblib.parallel.BatchedCalls object>)
    220     def __call__(self):
    221         # Set the default nested backend to self._backend but do not set the
    222         # change the default number of processes to -1
    223         with parallel_backend(self._backend, n_jobs=self._n_jobs):
    224             return [func(*args, **kwargs)
--> 225                     for func, args, kwargs in self.items]
        func = <function _fit_and_score>
        args = (Pipeline(memory=None,
     steps=[('rebalance', ... random_state=42, verbose=0, warm_start=False))]), array([[5.1, 3.5, 1.4, 0.2],
       [4.9, 3. , 1....2, 3.4, 5.4, 2.3],
       [5.9, 3. , 5.1, 1.8]]), array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,... 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]), {'score': <function _passthrough_scorer>}, array([  5,   6,   7,   8,   9,  10,  11,  12,  ..., 142, 143, 144,
       145, 146, 147, 148, 149]), array([  0,   1,   2,   3,   4,  50,  51,  52,  53,  54, 100, 101, 102,
       103, 104]), 0, None, None)
        kwargs = {'error_score': 'raise-deprecating', 'return_estimator': False, 'return_times': True, 'return_train_score': False}
        self.items = [(<function _fit_and_score>, (Pipeline(memory=None,
     steps=[('rebalance', ... random_state=42, verbose=0, warm_start=False))]), array([[5.1, 3.5, 1.4, 0.2],
       [4.9, 3. , 1....2, 3.4, 5.4, 2.3],
       [5.9, 3. , 5.1, 1.8]]), array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,... 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]), {'score': <function _passthrough_scorer>}, array([  5,   6,   7,   8,   9,  10,  11,  12,  ..., 142, 143, 144,
       145, 146, 147, 148, 149]), array([  0,   1,   2,   3,   4,  50,  51,  52,  53,  54, 100, 101, 102,
       103, 104]), 0, None, None), {'error_score': 'raise-deprecating', 'return_estimator': False, 'return_times': True, 'return_train_score': False})]
    226 
    227     def __len__(self):
    228         return self._size
    229 

...........................................................................
/home/aquemy/.local/lib/python2.7/site-packages/sklearn/model_selection/_validation.py in _fit_and_score(estimator=Pipeline(memory=None,
     steps=[('rebalance', ... random_state=42, verbose=0, warm_start=False))]), X=array([[5.1, 3.5, 1.4, 0.2],
       [4.9, 3. , 1....2, 3.4, 5.4, 2.3],
       [5.9, 3. , 5.1, 1.8]]), y=array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,... 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]), scorer={'score': <function _passthrough_scorer>}, train=array([  5,   6,   7,   8,   9,  10,  11,  12,  ..., 142, 143, 144,
       145, 146, 147, 148, 149]), test=array([  0,   1,   2,   3,   4,  50,  51,  52,  53,  54, 100, 101, 102,
       103, 104]), verbose=0, parameters=None, fit_params={}, return_train_score=False, return_parameters=False, return_n_test_samples=False, return_times=True, return_estimator=False, error_score='raise-deprecating')
    523 
    524     try:
    525         if y_train is None:
    526             estimator.fit(X_train, **fit_params)
    527         else:
--> 528             estimator.fit(X_train, y_train, **fit_params)
        estimator.fit = <bound method Pipeline.fit of Pipeline(memory=No...random_state=42, verbose=0, warm_start=False))])>
        X_train = array([[5.4, 3.9, 1.7, 0.4],
       [4.6, 3.4, 1....2, 3.4, 5.4, 2.3],
       [5.9, 3. , 5.1, 1.8]])
        y_train = array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,
       2, 2, 2])
        fit_params = {}
    529 
    530     except Exception as e:
    531         # Note fit time as time until error
    532         fit_time = time.time() - start_time

...........................................................................
/usr/local/lib/python2.7/dist-packages/imblearn/pipeline.py in fit(self=Pipeline(memory=None,
     steps=[('rebalance', ... random_state=42, verbose=0, warm_start=False))]), X=array([[5.4, 3.9, 1.7, 0.4],
       [4.6, 3.4, 1....2, 3.4, 5.4, 2.3],
       [5.9, 3. , 5.1, 1.8]]), y=array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,
       2, 2, 2]), **fit_params={})
    234             This estimator
    235 
    236         """
    237         Xt, yt, fit_params = self._fit(X, y, **fit_params)
    238         if self._final_estimator is not None:
--> 239             self._final_estimator.fit(Xt, yt, **fit_params)
        self._final_estimator.fit = <bound method RandomForestClassifier.fit of Rand...e, random_state=42, verbose=0, warm_start=False)>
        Xt = array([[-5.33848470e-01,  2.86830144e-01],
     ...-02],
       [ 8.76361275e-01,  1.45311219e-02]])
        yt = array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,
       2, 2, 2])
        fit_params = {}
    240         return self
    241 
    242     def fit_transform(self, X, y=None, **fit_params):
    243         """Fit the model and transform with the final estimator

...........................................................................
/home/aquemy/.local/lib/python2.7/site-packages/sklearn/ensemble/forest.py in fit(self=RandomForestClassifier(bootstrap=True, class_wei...se, random_state=42, verbose=0, warm_start=False), X=array([[-5.33848464e-01,  2.86830157e-01],
     ...8.76361251e-01,  1.45311216e-02]], dtype=float32), y=array([[0.],
       [0.],
       [0.],
       [0...    [2.],
       [2.],
       [2.],
       [2.]]), sample_weight=None)
    328             trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,
    329                              **_joblib_parallel_args(prefer='threads'))(
    330                 delayed(_parallel_build_trees)(
    331                     t, self, X, y, sample_weight, i, len(trees),
    332                     verbose=self.verbose, class_weight=self.class_weight)
--> 333                 for i, t in enumerate(trees))
        i = 9
    334 
    335             # Collect newly grown trees
    336             self.estimators_.extend(trees)
    337 

...........................................................................
/home/aquemy/.local/lib/python2.7/site-packages/sklearn/externals/joblib/parallel.py in __call__(self=Parallel(n_jobs=1), iterable=<generator object <genexpr>>)
    912             # self._original_iterator is None, then this means either
    913             # that pre_dispatch == "all", n_jobs == 1 or that the first batch
    914             # was very quick and its callback already dispatched all the
    915             # remaining jobs.
    916             self._iterating = False
--> 917             if self.dispatch_one_batch(iterator):
        self.dispatch_one_batch = <bound method Parallel.dispatch_one_batch of Parallel(n_jobs=1)>
        iterator = <generator object <genexpr>>
    918                 self._iterating = self._original_iterator is not None
    919 
    920             while self.dispatch_one_batch(iterator):
    921                 pass

...........................................................................
/home/aquemy/.local/lib/python2.7/site-packages/sklearn/externals/joblib/parallel.py in dispatch_one_batch(self=Parallel(n_jobs=1), iterator=<generator object <genexpr>>)
    754                                  self._pickle_cache)
    755             if len(tasks) == 0:
    756                 # No more tasks available in the iterator: tell caller to stop.
    757                 return False
    758             else:
--> 759                 self._dispatch(tasks)
        self._dispatch = <bound method Parallel._dispatch of Parallel(n_jobs=1)>
        tasks = <sklearn.externals.joblib.parallel.BatchedCalls object>
    760                 return True
    761 
    762     def _print(self, msg, msg_args):
    763         """Display the message on stout or stderr depending on verbosity"""

...........................................................................
/home/aquemy/.local/lib/python2.7/site-packages/sklearn/externals/joblib/parallel.py in _dispatch(self=Parallel(n_jobs=1), batch=<sklearn.externals.joblib.parallel.BatchedCalls object>)
    711 
    712         dispatch_timestamp = time.time()
    713         cb = BatchCompletionCallBack(dispatch_timestamp, len(batch), self)
    714         with self._lock:
    715             job_idx = len(self._jobs)
--> 716             job = self._backend.apply_async(batch, callback=cb)
        job = undefined
        self._backend.apply_async = <bound method SequentialBackend.apply_async of <...lib._parallel_backends.SequentialBackend object>>
        batch = <sklearn.externals.joblib.parallel.BatchedCalls object>
        cb = <sklearn.externals.joblib.parallel.BatchCompletionCallBack object>
    717             # A job can complete so quickly than its callback is
    718             # called before we get here, causing self._jobs to
    719             # grow. To ensure correct results ordering, .insert is
    720             # used (rather than .append) in the following line

...........................................................................
/home/aquemy/.local/lib/python2.7/site-packages/sklearn/externals/joblib/_parallel_backends.py in apply_async(self=<sklearn.externals.joblib._parallel_backends.SequentialBackend object>, func=<sklearn.externals.joblib.parallel.BatchedCalls object>, callback=<sklearn.externals.joblib.parallel.BatchCompletionCallBack object>)
    177             raise ValueError('n_jobs == 0 in Parallel has no meaning')
    178         return 1
    179 
    180     def apply_async(self, func, callback=None):
    181         """Schedule a func to be run"""
--> 182         result = ImmediateResult(func)
        result = undefined
        func = <sklearn.externals.joblib.parallel.BatchedCalls object>
    183         if callback:
    184             callback(result)
    185         return result
    186 

...........................................................................
/home/aquemy/.local/lib/python2.7/site-packages/sklearn/externals/joblib/_parallel_backends.py in __init__(self=<sklearn.externals.joblib._parallel_backends.ImmediateResult object>, batch=<sklearn.externals.joblib.parallel.BatchedCalls object>)
    544 
    545 class ImmediateResult(object):
    546     def __init__(self, batch):
    547         # Don't delay the application, to avoid keeping the input
    548         # arguments in memory
--> 549         self.results = batch()
        self.results = undefined
        batch = <sklearn.externals.joblib.parallel.BatchedCalls object>
    550 
    551     def get(self):
    552         return self.results
    553 

...........................................................................
/home/aquemy/.local/lib/python2.7/site-packages/sklearn/externals/joblib/parallel.py in __call__(self=<sklearn.externals.joblib.parallel.BatchedCalls object>)
    220     def __call__(self):
    221         # Set the default nested backend to self._backend but do not set the
    222         # change the default number of processes to -1
    223         with parallel_backend(self._backend, n_jobs=self._n_jobs):
    224             return [func(*args, **kwargs)
--> 225                     for func, args, kwargs in self.items]
        func = <function _parallel_build_trees>
        args = (DecisionTreeClassifier(class_weight=None, criter...=False, random_state=1608637542, splitter='best'), RandomForestClassifier(bootstrap=True, class_wei...se, random_state=42, verbose=0, warm_start=False), array([[-5.33848464e-01,  2.86830157e-01],
     ...8.76361251e-01,  1.45311216e-02]], dtype=float32), array([[0.],
       [0.],
       [0.],
       [0...    [2.],
       [2.],
       [2.],
       [2.]]), None, 0, 10)
        kwargs = {'class_weight': None, 'verbose': 0}
        self.items = [(<function _parallel_build_trees>, (DecisionTreeClassifier(class_weight=None, criter...=False, random_state=1608637542, splitter='best'), RandomForestClassifier(bootstrap=True, class_wei...se, random_state=42, verbose=0, warm_start=False), array([[-5.33848464e-01,  2.86830157e-01],
     ...8.76361251e-01,  1.45311216e-02]], dtype=float32), array([[0.],
       [0.],
       [0.],
       [0...    [2.],
       [2.],
       [2.],
       [2.]]), None, 0, 10), {'class_weight': None, 'verbose': 0})]
    226 
    227     def __len__(self):
    228         return self._size
    229 

...........................................................................
/home/aquemy/.local/lib/python2.7/site-packages/sklearn/ensemble/forest.py in _parallel_build_trees(tree=DecisionTreeClassifier(class_weight=None, criter...=False, random_state=1608637542, splitter='best'), forest=RandomForestClassifier(bootstrap=True, class_wei...se, random_state=42, verbose=0, warm_start=False), X=array([[-5.33848464e-01,  2.86830157e-01],
     ...8.76361251e-01,  1.45311216e-02]], dtype=float32), y=array([[0.],
       [0.],
       [0.],
       [0...    [2.],
       [2.],
       [2.],
       [2.]]), sample_weight=None, tree_idx=0, n_trees=10, verbose=0, class_weight=None)
    114                 simplefilter('ignore', DeprecationWarning)
    115                 curr_sample_weight *= compute_sample_weight('auto', y, indices)
    116         elif class_weight == 'balanced_subsample':
    117             curr_sample_weight *= compute_sample_weight('balanced', y, indices)
    118 
--> 119         tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)
        tree.fit = <bound method DecisionTreeClassifier.fit of Deci...False, random_state=1608637542, splitter='best')>
        X = array([[-5.33848464e-01,  2.86830157e-01],
     ...8.76361251e-01,  1.45311216e-02]], dtype=float32)
        y = array([[0.],
       [0.],
       [0.],
       [0...    [2.],
       [2.],
       [2.],
       [2.]])
        sample_weight = None
        curr_sample_weight = array([3., 3., 0., 1., 1., 2., 2., 0., 1., 2., 0... 1., 0., 1., 0., 1., 1., 1., 1., 1., 1., 0., 0.])
    120     else:
    121         tree.fit(X, y, sample_weight=sample_weight, check_input=False)
    122 
    123     return tree

...........................................................................
/home/aquemy/.local/lib/python2.7/site-packages/sklearn/tree/tree.py in fit(self=DecisionTreeClassifier(class_weight=None, criter...=False, random_state=1608637542, splitter='best'), X=array([[-5.33848464e-01,  2.86830157e-01],
     ...8.76361251e-01,  1.45311216e-02]], dtype=float32), y=array([[0.],
       [0.],
       [0.],
       [0...    [2.],
       [2.],
       [2.],
       [2.]]), sample_weight=array([3., 3., 0., 1., 1., 2., 2., 0., 1., 2., 0... 1., 0., 1., 0., 1., 1., 1., 1., 1., 1., 0., 0.]), check_input=False, X_idx_sorted=None)
    796 
    797         super(DecisionTreeClassifier, self).fit(
    798             X, y,
    799             sample_weight=sample_weight,
    800             check_input=check_input,
--> 801             X_idx_sorted=X_idx_sorted)
        X_idx_sorted = None
    802         return self
    803 
    804     def predict_proba(self, X, check_input=True):
    805         """Predict class probabilities of the input samples X.

...........................................................................
/home/aquemy/.local/lib/python2.7/site-packages/sklearn/tree/tree.py in fit(self=DecisionTreeClassifier(class_weight=None, criter...=False, random_state=1608637542, splitter='best'), X=array([[-5.33848464e-01,  2.86830157e-01],
     ...8.76361251e-01,  1.45311216e-02]], dtype=float32), y=array([[0.],
       [0.],
       [0.],
       [0...    [2.],
       [2.],
       [2.],
       [2.]]), sample_weight=array([3., 3., 0., 1., 1., 2., 2., 0., 1., 2., 0... 1., 0., 1., 0., 1., 1., 1., 1., 1., 1., 0., 0.]), check_input=False, X_idx_sorted=None)
    237         if not 0 <= self.min_weight_fraction_leaf <= 0.5:
    238             raise ValueError("min_weight_fraction_leaf must in [0, 0.5]")
    239         if max_depth <= 0:
    240             raise ValueError("max_depth must be greater than zero. ")
    241         if not (0 < max_features <= self.n_features_):
--> 242             raise ValueError("max_features must be in (0, n_features]")
    243         if not isinstance(max_leaf_nodes, (numbers.Integral, np.integer)):
    244             raise ValueError("max_leaf_nodes must be integral number but was "
    245                              "%r" % max_leaf_nodes)
    246         if -1 < max_leaf_nodes < 2:

ValueError: max_features must be in (0, n_features]
___________________________________________________________________________
Best score: 0.966666666667 (0.0333333333333) [J] | Score: 0.0 (0.0) [J]
Best score: 0.966666666667 (0.0333333333333) [J] | Score: 0.566666666667 (0.0683130051064) [J]
Best score: 0.966666666667 (0.0333333333333) [J] | Score: 0.96 (0.0442216638714) [J]
Best score: 0.966666666667 (0.0333333333333) [J] | Score: 0.886666666667 (0.0733333333333) [J]
Best score: 0.966666666667 (0.0333333333333) [J] | Score: 0.826666666667 (0.0904310664417) [J]
Best score: 0.966666666667 (0.0333333333333) [J] | Score: 0.88 (0.0884433277428) [J]
Best score: 0.966666666667 (0.0333333333333) [J] | Score: 0.92 (0.0653197264742) [J]
Best score: 0.966666666667 (0.0333333333333) [J] | Score: 0.966666666667 (0.04472135955) [J]
Best score: 0.966666666667 (0.0333333333333) [J] | Score: 0.946666666667 (0.0581186525805) [J]
Best score: 0.966666666667 (0.0333333333333) [J] | Score: 0.966666666667 (0.04472135955) [J]
Best score: 0.966666666667 (0.0333333333333) [J] | Score: 0.853333333333 (0.0933333333333) [J]
Best score: 0.966666666667 (0.0333333333333) [J] | Score: 0.666666666667 (1.11022302463e-16) [J]
Best score: 0.966666666667 (0.0333333333333) [J] | Score: 0.946666666667 (0.049888765157) [J]
Best score: 0.966666666667 (0.0333333333333) [J] | Score: 0.96 (0.0442216638714) [J]
Best score: 0.966666666667 (0.0333333333333) [J] | Score: 0.946666666667 (0.0581186525805) [J]
Best score: 0.966666666667 (0.0333333333333) [J] | Score: 0.953333333333 (0.0520683311727) [J]
Best score: 0.966666666667 (0.0333333333333) [J] | Score: 0.886666666667 (0.06) [J]
Best score: 0.966666666667 (0.0333333333333) [J] | Score: 0.953333333333 (0.0426874949162) [J]
Best score: 0.966666666667 (0.0333333333333) [J] | Score: 0.953333333333 (0.0426874949162) [J]
Best score: 0.966666666667 (0.0333333333333) [J] | Score: 0.96 (0.0442216638714) [J]
Best score: 0.966666666667 (0.0333333333333) [J] | Score: 0.873333333333 (0.062893207547) [J]
Best score: 0.966666666667 (0.0333333333333) [J] | Score: 0.953333333333 (0.06) [J]
Best score: 0.966666666667 (0.0333333333333) [J] | Score: 0.953333333333 (0.0520683311727) [J]
Best score: 0.966666666667 (0.0333333333333) [J] | Score: 0.96 (0.0442216638714) [J]
Best score: 0.966666666667 (0.0333333333333) [J] | Score: 0.82 (0.126666666667) [J]
Best score: 0.966666666667 (0.0333333333333) [J] | Score: 0.666666666667 (1.11022302463e-16) [J]
Best score: 0.966666666667 (0.0333333333333) [J] | Score: 0.946666666667 (0.0581186525805) [J]
Best score: 0.966666666667 (0.0333333333333) [J] | Score: 0.96 (0.0533333333333) [J]
Best score: 0.966666666667 (0.0333333333333) [J] | Score: 0.933333333333 (0.073029674334) [J]
JoblibValueError
___________________________________________________________________________
...........................................................................
/home/aquemy/dev/dp_hyperparameters/extension/main.py in <module>()
     27 
     28     serializer.serialize_results(scenario, policy)
     29 
     30 if __name__ == "__main__":
     31     args = cli.parse_args()
---> 32     main(args)

...........................................................................
/home/aquemy/dev/dp_hyperparameters/extension/main.py in main(args=Namespace(customize=[(['control', 'seed'], '42')...io='./scenarios/rf_iris_joint.yaml', verbosity=0))
     21         test_size=0.4, 
     22         random_state=scenario['control']['seed']
     23     )
     24 
     25     policy = policies.initiate(scenario['setup']['policy'], config)
---> 26     policy.run(X,y)
        policy.run = <bound method Joint.run of <experiment.policies.joint.Joint object>>
        X = array([[5.1, 3.5, 1.4, 0.2],
       [4.9, 3. , 1....2, 3.4, 5.4, 2.3],
       [5.9, 3. , 5.1, 1.8]])
        y = array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,... 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2])
     27 
     28     serializer.serialize_results(scenario, policy)
     29 
     30 if __name__ == "__main__":

...........................................................................
/home/aquemy/dev/dp_hyperparameters/extension/experiment/policies/joint.py in run(self=<experiment.policies.joint.Joint object>, X=array([[5.1, 3.5, 1.4, 0.2],
       [4.9, 3. , 1....2, 3.4, 5.4, 2.3],
       [5.9, 3. , 5.1, 1.8]]), y=array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,... 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]))
     32             algo=tpe.suggest, 
     33             max_evals=None,
     34             max_time=self.config['time'],     
     35             trials=trials,
     36             show_progressbar=False,
---> 37             verbose=0
     38         )
     39 
     40         best_config = self.context['best_config']
     41         super(Joint, self).display_step_results(best_config)

...........................................................................
/home/aquemy/dev/dp_hyperparameters/extension/hyperopt/fmin.py in fmin(fn=<functools.partial object>, space={'algorithm': {'bootstrap': <hyperopt.pyll.base.Apply object>, 'criterion': <hyperopt.pyll.base.Apply object>, 'max_depth': <hyperopt.pyll.base.Apply object>, 'max_features': <hyperopt.pyll.base.Apply object>, 'max_leaf_nodes': <hyperopt.pyll.base.Apply object>, 'min_samples_split': <hyperopt.pyll.base.Apply object>, 'n_estimators': <hyperopt.pyll.base.Apply object>}, 'pipeline': {'features': <hyperopt.pyll.base.Apply object>, 'normalizer': <hyperopt.pyll.base.Apply object>, 'rebalance': <hyperopt.pyll.base.Apply object>}}, algo=<function suggest>, max_evals=9223372036854775807, max_time=300, trials=<hyperopt.base.Trials object>, rstate=<mtrand.RandomState object>, allow_trials_fmin=True, pass_expr_memo_ctrl=None, catch_eval_exceptions=False, verbose=0, return_argmin=True, points_to_evaluate=None, max_queue_len=1, show_progressbar=False)
    406             pass_expr_memo_ctrl=pass_expr_memo_ctrl,
    407             verbose=verbose,
    408             catch_eval_exceptions=catch_eval_exceptions,
    409             return_argmin=return_argmin,
    410             show_progressbar=show_progressbar,
--> 411             max_time=max_time
        max_time = 300
    412         )
    413 
    414     if trials is None:
    415         if points_to_evaluate is None:

...........................................................................
/home/aquemy/dev/dp_hyperparameters/extension/hyperopt/base.py in fmin(self=<hyperopt.base.Trials object>, fn=<functools.partial object>, space={'algorithm': {'bootstrap': <hyperopt.pyll.base.Apply object>, 'criterion': <hyperopt.pyll.base.Apply object>, 'max_depth': <hyperopt.pyll.base.Apply object>, 'max_features': <hyperopt.pyll.base.Apply object>, 'max_leaf_nodes': <hyperopt.pyll.base.Apply object>, 'min_samples_split': <hyperopt.pyll.base.Apply object>, 'n_estimators': <hyperopt.pyll.base.Apply object>}, 'pipeline': {'features': <hyperopt.pyll.base.Apply object>, 'normalizer': <hyperopt.pyll.base.Apply object>, 'rebalance': <hyperopt.pyll.base.Apply object>}}, algo=<function suggest>, max_evals=9223372036854775807, max_time=300, rstate=<mtrand.RandomState object>, verbose=0, pass_expr_memo_ctrl=None, catch_eval_exceptions=False, return_argmin=True, show_progressbar=False)
    636             verbose=verbose,
    637             allow_trials_fmin=False,  # -- prevent recursion
    638             pass_expr_memo_ctrl=pass_expr_memo_ctrl,
    639             catch_eval_exceptions=catch_eval_exceptions,
    640             return_argmin=return_argmin,
--> 641             show_progressbar=show_progressbar)
        show_progressbar = False
    642 
    643 
    644 def trials_from_docs(docs, validate=True, **kwargs):
    645     """Construct a Trials base class instance from a list of trials documents

...........................................................................
/home/aquemy/dev/dp_hyperparameters/extension/hyperopt/fmin.py in fmin(fn=<functools.partial object>, space={'algorithm': {'bootstrap': <hyperopt.pyll.base.Apply object>, 'criterion': <hyperopt.pyll.base.Apply object>, 'max_depth': <hyperopt.pyll.base.Apply object>, 'max_features': <hyperopt.pyll.base.Apply object>, 'max_leaf_nodes': <hyperopt.pyll.base.Apply object>, 'min_samples_split': <hyperopt.pyll.base.Apply object>, 'n_estimators': <hyperopt.pyll.base.Apply object>}, 'pipeline': {'features': <hyperopt.pyll.base.Apply object>, 'normalizer': <hyperopt.pyll.base.Apply object>, 'rebalance': <hyperopt.pyll.base.Apply object>}}, algo=<function suggest>, max_evals=9223372036854775807, max_time=300, trials=<hyperopt.base.Trials object>, rstate=<mtrand.RandomState object>, allow_trials_fmin=False, pass_expr_memo_ctrl=None, catch_eval_exceptions=False, verbose=0, return_argmin=True, points_to_evaluate=None, max_queue_len=1, show_progressbar=False)
    426                     verbose=verbose,
    427                     max_queue_len=max_queue_len,
    428                     show_progressbar=show_progressbar,
    429                     max_time=max_time)
    430     rval.catch_eval_exceptions = catch_eval_exceptions
--> 431     rval.exhaust()
        rval.exhaust = <bound method FMinIter.exhaust of <hyperopt.fmin.FMinIter object>>
    432     if return_argmin:
    433         return trials.argmin
    434     elif len(trials) > 0:
    435         # Only if there are some succesfull trail runs, return the best point in the evaluation space

...........................................................................
/home/aquemy/dev/dp_hyperparameters/extension/hyperopt/fmin.py in exhaust(self=<hyperopt.fmin.FMinIter object>)
    273             raise StopIteration()
    274         return self.trials
    275 
    276     def exhaust(self):
    277         n_done = len(self.trials)
--> 278         self.run(self.max_evals - n_done, block_until_done=self.asynchronous)
        self.run = <bound method FMinIter.run of <hyperopt.fmin.FMinIter object>>
        self.max_evals = 9223372036854775807
        n_done = 0
        self.asynchronous = False
    279         self.trials.refresh()
    280         return self
    281 
    282 

...........................................................................
/home/aquemy/dev/dp_hyperparameters/extension/hyperopt/fmin.py in run(self=<hyperopt.fmin.FMinIter object>, N=9223372036854775807, block_until_done=False)
    232                     if self.asynchronous:
    233                         # -- wait for workers to fill in the trials
    234                         time.sleep(self.poll_interval_secs)
    235                     else:
    236                         # -- loop over trials and do the jobs directly
--> 237                         self.serial_evaluate()
        self.serial_evaluate = <bound method FMinIter.serial_evaluate of <hyperopt.fmin.FMinIter object>>
    238                     try:
    239                         res = [d['result']['loss'] for d in
    240                                          self.trials.trials if
    241                                          d['result']['status'] == 'ok']

...........................................................................
/home/aquemy/dev/dp_hyperparameters/extension/hyperopt/fmin.py in serial_evaluate(self=<hyperopt.fmin.FMinIter object>, N=-1)
    138                 trial['book_time'] = now
    139                 trial['refresh_time'] = now
    140                 spec = base.spec_from_misc(trial['misc'])
    141                 ctrl = base.Ctrl(self.trials, current_trial=trial)
    142                 try:
--> 143                     result = self.domain.evaluate(spec, ctrl)
        result = undefined
        self.domain.evaluate = <bound method Domain.evaluate of <hyperopt.base.Domain object>>
        spec = {'bootstrap': 0, 'criterion': 0, 'features': 2, 'features_SelectKBest_features__k': 1, 'max_depth': 3, 'max_features': 2, 'max_leaf_nodes': 1, 'min_samples_split': 1, 'n_estimators': 2, 'normalizer': 3, ...}
        ctrl = <hyperopt.base.Ctrl object>
    144                 except Exception as e:
    145                     logger.info('job exception: %s' % str(e))
    146                     trial['state'] = base.JOB_STATE_ERROR
    147                     trial['misc']['error'] = (str(type(e)), str(e))

...........................................................................
/home/aquemy/dev/dp_hyperparameters/extension/hyperopt/base.py in evaluate(self=<hyperopt.base.Domain object>, config={'bootstrap': 0, 'criterion': 0, 'features': 2, 'features_SelectKBest_features__k': 1, 'max_depth': 3, 'max_features': 2, 'max_leaf_nodes': 1, 'min_samples_split': 1, 'n_estimators': 2, 'normalizer': 3, ...}, ctrl=<hyperopt.base.Ctrl object>, attach_attachments=True)
    841             #    or the normal Python part (self.fn)
    842             pyll_rval = pyll.rec_eval(
    843                 self.expr,
    844                 memo=memo,
    845                 print_node_on_error=self.rec_eval_print_node_on_error)
--> 846             rval = self.fn(pyll_rval)
        rval = undefined
        self.fn = <functools.partial object>
        pyll_rval = {'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': 4, 'max_features': 3, 'max_leaf_nodes': 3, 'min_samples_split': 3, 'n_estimators': 50}, 'pipeline': {'features': ('features_SelectKBest', {'features__k': 2}), 'normalizer': ('normalizer_MinMaxScaler', {}), 'rebalance': ('rebalance_NearMiss', {'rebalance__n_neighbors': 2})}}
    847 
    848         if isinstance(rval, (float, int, np.number)):
    849             dict_rval = {'loss': float(rval), 'status': STATUS_OK}
    850         else:

...........................................................................
/home/aquemy/dev/dp_hyperparameters/extension/experiment/objective.py in objective_joint(wconfig={'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': 4, 'max_features': 3, 'max_leaf_nodes': 3, 'min_samples_split': 3, 'n_estimators': 50}, 'pipeline': {'features': ('features_SelectKBest', {'features__k': 2}), 'normalizer': ('normalizer_MinMaxScaler', {}), 'rebalance': ('rebalance_NearMiss', {'rebalance__n_neighbors': 2})}}, algorithm='RandomForest', X=array([[5.1, 3.5, 1.4, 0.2],
       [4.9, 3. , 1....2, 3.4, 5.4, 2.3],
       [5.9, 3. , 5.1, 1.8]]), y=array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,... 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]), context={'baseline_score': 0.9466666666666667, 'baseline_score_std': 0.04988876515698587, 'best_config': {'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': 4, 'max_features': 3, 'max_leaf_nodes': 3, 'min_samples_split': 3, 'n_estimators': 10}, 'config_hash': {'algorithm': 'ffb7ff225ce3d3712c96cf87fe42202988ee2eb0', 'config': 'bae32f426be9cd6243523c023944a8c148fe4aeb', 'pipeline': 'd2a68bfda6fcdec4ae0ffc7d7b6a2122bc1cd673'}, 'duration': 0.7115809917449951, 'iteration': 113, 'loss': 0.033333333333333215, 'max_history_score': 0.9666666666666668, 'max_history_score_std': 0.033333333333333326, 'max_history_step': 'joint', 'pipeline': {'features': ('features_NoneType', {}), 'normalizer': ('normalizer_PowerTransformer', {}), 'rebalance': ('rebalance_CondensedNearestNeighbour', {'rebalance__n_neighbors': 2})}, 'score': 0.9666666666666668, ...}, 'history': [{'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': 2, 'max_features': None, 'max_leaf_nodes': 5, 'min_samples_split': 2, 'n_estimators': 75}, 'config_hash': {'algorithm': '3af5b0cce71c8fe2545246ca24ff5bc3dd516e06', 'config': 'db6ac7e6d348155757e4794bb5f88fe2b4f63d50', 'pipeline': '8d59f4b94cef6be9306ed86a22a9570fa670d567'}, 'duration': 1.149928092956543, 'iteration': 0, 'loss': 0.046666666666666634, 'max_history_score': 0.9533333333333334, 'max_history_score_std': 0.059999999999999984, 'max_history_step': 'joint', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 4, 'features__selectkbest__k': 3}), 'normalizer': ('normalizer_StandardScaler', {'normalizer__with_mean': True, 'normalizer__with_std': True}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 6})}, 'score': 0.9533333333333334, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': 1, 'max_features': 2, 'max_leaf_nodes': 2, 'min_samples_split': 5, 'n_estimators': 100}, 'config_hash': {'algorithm': 'e13eb05fd9a62d2f63bbb1c1deff0cd620d5e6ab', 'config': '4db6fb84d85f52659f780e682ffac5712c3d8a94', 'pipeline': '64c9a1ca9d53ae67244bdd942f4db36a3c05218c'}, 'duration': 1.7678282260894775, 'iteration': 1, 'loss': 0.18000000000000005, 'max_history_score': 0.9533333333333334, 'max_history_score_std': 0.059999999999999984, 'max_history_step': 'joint', 'pipeline': {'features': ('features_NoneType', {}), 'normalizer': ('normalizer_PowerTransformer', {}), 'rebalance': ('rebalance_NearMiss', {'rebalance__n_neighbors': 1})}, 'score': 0.82, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': 1, 'max_features': None, 'max_leaf_nodes': None, 'min_samples_split': 5, 'n_estimators': 75}, 'config_hash': {'algorithm': '94b0d7a654c508cc63643f78fe4f0f07e6f07c1e', 'config': '4403c5a85e951938d3c454e961d3a412780722f6', 'pipeline': '3e47444880d8367fbac2faaba2e52a917274aa58'}, 'duration': 0.8397619724273682, 'iteration': 2, 'loss': 0.03333333333333344, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_PCA', {'features__n_components': 3}), 'normalizer': ('normalizer_MinMaxScaler', {}), 'rebalance': ('rebalance_NoneType', {})}, 'score': 0.9666666666666666, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': None, 'max_features': None, 'max_leaf_nodes': 3, 'min_samples_split': 3, 'n_estimators': 75}, 'config_hash': {'algorithm': 'e8332f0a8902bda03bf70e7978cc5d52affb29d3', 'config': 'a064e2df18ab98d44dabcefbc7bed94913f1d0be', 'pipeline': '7eea819c2a8c103c4b1e9e9c1e224aebba95081f'}, 'duration': 0.8501448631286621, 'iteration': 3, 'loss': 0.053333333333333344, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 2, 'features__selectkbest__k': 4}), 'normalizer': ('normalizer_NoneType', {}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 7})}, 'score': 0.9466666666666667, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'entropy', 'max_depth': 3, 'max_features': 3, 'max_leaf_nodes': None, 'min_samples_split': 5, 'n_estimators': 75}, 'config_hash': {'algorithm': '7a4491035bc6bd737fe9a8cda8a79a02d02d5c74', 'config': '0ddb6f5cab3db4dddd7682966a57205f3e329ad4', 'pipeline': 'a9ae03fe38334f6868cbf84cdd3d629d4bbe3fb0'}, 'duration': 1.1026010513305664, 'iteration': 4, 'loss': 0.05999999999999994, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 2, 'features__selectkbest__k': 1}), 'normalizer': ('normalizer_NoneType', {}), 'rebalance': ('rebalance_NoneType', {})}, 'score': 0.9400000000000001, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'gini', 'max_depth': 3, 'max_features': 1, 'max_leaf_nodes': 5, 'min_samples_split': 2, 'n_estimators': 25}, 'config_hash': {'algorithm': '9826d20b2d6a0f559cf7f16450ce7526f07e8434', 'config': '49f25751bca61cdd461a8cbd2923689b642f98ed', 'pipeline': '19b249664c5bf067de1fed4334a296f947ce774a'}, 'duration': 0.35647010803222656, 'iteration': 5, 'loss': 0.046666666666666634, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_NoneType', {}), 'normalizer': ('normalizer_NoneType', {}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 6})}, 'score': 0.9533333333333334, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'gini', 'max_depth': 2, 'max_features': 1, 'max_leaf_nodes': 2, 'min_samples_split': 2, 'n_estimators': 50}, 'config_hash': {'algorithm': '0a4f6fbb07e0f32c6f675489a0fc82eee05bd8e1', 'config': '5c3a2b6f5e63fb45f10e41e0318b354912ec44f6', 'pipeline': 'dc3b9f176f090005e38b142f11d80e93a7dc5d5e'}, 'duration': 0.7213859558105469, 'iteration': 6, 'loss': 0.31333333333333324, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 1, 'features__selectkbest__k': 4}), 'normalizer': ('normalizer_PowerTransformer', {}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 7})}, 'score': 0.6866666666666668, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'entropy', 'max_depth': 4, 'max_features': 3, 'max_leaf_nodes': 5, 'min_samples_split': 5, 'n_estimators': 10}, 'config_hash': {'algorithm': 'b8112b97ecfc10f00a195af661dcc861cac21289', 'config': 'd3b129b397350f1b6572651c67c01de49b4b174c', 'pipeline': '5b0357ed7072c37b3d6f458bb5d49ff7d825f603'}, 'duration': 0.8299109935760498, 'iteration': 7, 'loss': 1.0, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_PCA', {'features__n_components': 2}), 'normalizer': ('normalizer_StandardScaler', {'normalizer__with_mean': True, 'normalizer__with_std': False}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 6})}, 'score': 0.0, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'gini', 'max_depth': 4, 'max_features': None, 'max_leaf_nodes': 2, 'min_samples_split': 5, 'n_estimators': 100}, 'config_hash': {'algorithm': '40ca24df19b8d164d9d098a6bed1ce056fbbb961', 'config': '813bde1108cc3c4b9bfb3a22cbb421bda7eac671', 'pipeline': '74a7b8705a1c22f7dea5e44e4ebda8f1e48add71'}, 'duration': 2.2111589908599854, 'iteration': 8, 'loss': 0.33333333333333326, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_PCA', {'features__n_components': 2}), 'normalizer': ('normalizer_StandardScaler', {'normalizer__with_mean': False, 'normalizer__with_std': True}), 'rebalance': ('rebalance_NearMiss', {'rebalance__n_neighbors': 2})}, 'score': 0.6666666666666667, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'entropy', 'max_depth': 2, 'max_features': 1, 'max_leaf_nodes': 5, 'min_samples_split': 2, 'n_estimators': 100}, 'config_hash': {'algorithm': '331418a5c12cf1453876eef85e9d98fc8e54fa11', 'config': '31930b6860ed406d59bf7e59ba1925d94704bd3b', 'pipeline': '054bef356f90ec6f644ef3ffc688766744db51c2'}, 'duration': 1.0501940250396729, 'iteration': 9, 'loss': 0.053333333333333344, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_SelectKBest', {'features__k': 1}), 'normalizer': ('normalizer_RobustScaler', {'normalizer__quantile_range': (...), 'normalizer__with_centering': True, 'normalizer__with_scaling': True}), 'rebalance': ('rebalance_NearMiss', {'rebalance__n_neighbors': 2})}, 'score': 0.9466666666666667, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'entropy', 'max_depth': 3, 'max_features': None, 'max_leaf_nodes': 3, 'min_samples_split': 2, 'n_estimators': 100}, 'config_hash': {'algorithm': 'dbc1b8126649fe93dce5fbb37e4015b0acfb179e', 'config': '9913cd550615a9d0946ab4a755a8b9f619e442fd', 'pipeline': 'dd626121cea079ebb32e184ca65483ec7a6d7f59'}, 'duration': 1.120617151260376, 'iteration': 10, 'loss': 0.046666666666666634, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 2, 'features__selectkbest__k': 1}), 'normalizer': ('normalizer_MinMaxScaler', {}), 'rebalance': ('rebalance_NoneType', {})}, 'score': 0.9533333333333334, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'gini', 'max_depth': 3, 'max_features': 3, 'max_leaf_nodes': None, 'min_samples_split': 3, 'n_estimators': 75}, 'config_hash': {'algorithm': '34917a130df5a975f78bd7ec1a0c7b1ffdc787a9', 'config': '95fc8cadc088141290b7de9c388977e4685f0108', 'pipeline': '550d10faf2f08db48516cc3501558816d6a99bc0'}, 'duration': 1.4287099838256836, 'iteration': 11, 'loss': 0.19333333333333313, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 3, 'features__selectkbest__k': 4}), 'normalizer': ('normalizer_StandardScaler', {'normalizer__with_mean': False, 'normalizer__with_std': False}), 'rebalance': ('rebalance_CondensedNearestNeighbour', {'rebalance__n_neighbors': 1})}, 'score': 0.8066666666666669, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'entropy', 'max_depth': 1, 'max_features': 2, 'max_leaf_nodes': 5, 'min_samples_split': 2, 'n_estimators': 75}, 'config_hash': {'algorithm': '33f9abb4aee44a395a9f3b3ffa9ce80a8cdaed7c', 'config': '40fa726f0360cf6af55f9b5902d399d02f61f157', 'pipeline': 'cfd1d20841fe2153da762c95e79f95a3fb1e426a'}, 'duration': 1.2978079319000244, 'iteration': 12, 'loss': 0.053333333333333344, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_PCA', {'features__n_components': 4}), 'normalizer': ('normalizer_MinMaxScaler', {}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 7})}, 'score': 0.9466666666666667, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'entropy', 'max_depth': 4, 'max_features': 2, 'max_leaf_nodes': 5, 'min_samples_split': 3, 'n_estimators': 25}, 'config_hash': {'algorithm': '210111ec6562d09eb093e98ed69ef1c662e11a50', 'config': '0fb8e77c7bd9a58b72f1b33c21a59a09a8c676ba', 'pipeline': '5d269d759e0c7926a685a14b263ace8ae0071e4b'}, 'duration': 0.36649012565612793, 'iteration': 13, 'loss': 0.040000000000000036, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 2, 'features__selectkbest__k': 2}), 'normalizer': ('normalizer_NoneType', {}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 7})}, 'score': 0.96, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'entropy', 'max_depth': 3, 'max_features': 1, 'max_leaf_nodes': 5, 'min_samples_split': 2, 'n_estimators': 25}, 'config_hash': {'algorithm': '0e989a03980101fabf79eda3326ed2870e11d690', 'config': 'f4bffd5d8c67a9c5321a9943c4a99678f59a02b7', 'pipeline': '865ee1e3fe8334c3d5ecb2038d5a5d1b3ba50e75'}, 'duration': 0.35639500617980957, 'iteration': 14, 'loss': 0.046666666666666634, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_NoneType', {}), 'normalizer': ('normalizer_RobustScaler', {'normalizer__quantile_range': (...), 'normalizer__with_centering': True, 'normalizer__with_scaling': False}), 'rebalance': ('rebalance_NoneType', {})}, 'score': 0.9533333333333334, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'entropy', 'max_depth': None, 'max_features': 3, 'max_leaf_nodes': 3, 'min_samples_split': 5, 'n_estimators': 10}, 'config_hash': {'algorithm': '9c592e876c13de5e23e6de5b868e01755d63e72e', 'config': '1e6a68cd1eeac886d90724d78b1cb5fb76a3cde4', 'pipeline': '5a1ca4d82f21b7de0d2c918630a42510673fa36e'}, 'duration': 0.18141412734985352, 'iteration': 15, 'loss': 0.046666666666666634, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_SelectKBest', {'features__k': 3}), 'normalizer': ('normalizer_RobustScaler', {'normalizer__quantile_range': (...), 'normalizer__with_centering': True, 'normalizer__with_scaling': True}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 6})}, 'score': 0.9533333333333334, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': 1, 'max_features': None, 'max_leaf_nodes': None, 'min_samples_split': 5, 'n_estimators': 10}, 'config_hash': {'algorithm': '8bed77aef289bfd453b2858bd288ae5ba7160f2b', 'config': '781185bcb8999045de8d489f253a1a1ba4247932', 'pipeline': '1ece7eabedc2be9e5b0a1be65c570d08ffa3eb54'}, 'duration': 0.1636829376220703, 'iteration': 16, 'loss': 0.053333333333333344, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_NoneType', {}), 'normalizer': ('normalizer_NoneType', {}), 'rebalance': ('rebalance_NearMiss', {'rebalance__n_neighbors': 1})}, 'score': 0.9466666666666667, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'gini', 'max_depth': 3, 'max_features': 2, 'max_leaf_nodes': 2, 'min_samples_split': 5, 'n_estimators': 75}, 'config_hash': {'algorithm': '617b97d9ba21d3373bc51ffa9cccf9c6f91a77b3', 'config': '99fb425b4e8c5d80228cab94202252aa25cdf77c', 'pipeline': 'd6242929c3b515c7719e60423023ac604311afc3'}, 'duration': 0.8468999862670898, 'iteration': 17, 'loss': 0.24, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_PCA', {'features__n_components': 4}), 'normalizer': ('normalizer_PowerTransformer', {}), 'rebalance': ('rebalance_NearMiss', {'rebalance__n_neighbors': 2})}, 'score': 0.76, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': 1, 'max_features': 1, 'max_leaf_nodes': 2, 'min_samples_split': 5, 'n_estimators': 50}, 'config_hash': {'algorithm': 'b92d2697cdd4979da443369d6596229ec091626a', 'config': 'c513a3e13281206ad76187dd817b1fff93d54fe1', 'pipeline': 'c4b4f914a3ca8df967cade997a90366d85a371b9'}, 'duration': 0.6724588871002197, 'iteration': 18, 'loss': 0.23333333333333328, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 1, 'features__selectkbest__k': 3}), 'normalizer': ('normalizer_StandardScaler', {'normalizer__with_mean': True, 'normalizer__with_std': True}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 5})}, 'score': 0.7666666666666667, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'entropy', 'max_depth': None, 'max_features': None, 'max_leaf_nodes': 5, 'min_samples_split': 5, 'n_estimators': 10}, 'config_hash': {'algorithm': 'a0115de695e6cca2e81cbfb54df79bf4b43608b1', 'config': 'ba194015e20b5d67770e8c67342c3d8d0d01dc41', 'pipeline': '8d45fabfeb85ffdcabf7076bd0e65fffe97ce928'}, 'duration': 0.19424200057983398, 'iteration': 19, 'loss': 0.08666666666666667, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_PCA', {'features__n_components': 3}), 'normalizer': ('normalizer_NoneType', {}), 'rebalance': ('rebalance_NoneType', {})}, 'score': 0.9133333333333333, ...}, ...], 'history_hash': ['db6ac7e6d348155757e4794bb5f88fe2b4f63d50', '4db6fb84d85f52659f780e682ffac5712c3d8a94', '4403c5a85e951938d3c454e961d3a412780722f6', 'a064e2df18ab98d44dabcefbc7bed94913f1d0be', '0ddb6f5cab3db4dddd7682966a57205f3e329ad4', '49f25751bca61cdd461a8cbd2923689b642f98ed', '5c3a2b6f5e63fb45f10e41e0318b354912ec44f6', 'd3b129b397350f1b6572651c67c01de49b4b174c', '813bde1108cc3c4b9bfb3a22cbb421bda7eac671', '31930b6860ed406d59bf7e59ba1925d94704bd3b', '9913cd550615a9d0946ab4a755a8b9f619e442fd', '95fc8cadc088141290b7de9c388977e4685f0108', '40fa726f0360cf6af55f9b5902d399d02f61f157', '0fb8e77c7bd9a58b72f1b33c21a59a09a8c676ba', 'f4bffd5d8c67a9c5321a9943c4a99678f59a02b7', '1e6a68cd1eeac886d90724d78b1cb5fb76a3cde4', '781185bcb8999045de8d489f253a1a1ba4247932', '99fb425b4e8c5d80228cab94202252aa25cdf77c', 'c513a3e13281206ad76187dd817b1fff93d54fe1', 'ba194015e20b5d67770e8c67342c3d8d0d01dc41', ...], 'history_index': {'00f0493590a2cb5e98a35b29816f8cd9f87f96ec': 208, '01161dcc5f8ee022f65481dacf76468db745b463': 306, '013329309d510b94f19d930320402d65f953a847': 39, '038a0f515e2ec894ee8e34f9caa2889eb3ebd5ce': 66, '052ae4bf232b316187b078abae42c2be19e16a00': 111, '05e9258ebf99dd97202167ef1563fa834b0568f1': 242, '0659afebf316aafeb75612fb07081a04c28545ed': 74, '06e7cde9f3556cd01332ce389ad1d8925cd4b4a4': 120, '07ab8a30d853e39a326b7017026a20e94bc45541': 245, '0855e6ed1503da05dc544450a5da27e4b3441758': 307, ...}, 'iteration': 337, 'max_history_score': 0.9666666666666668, 'max_history_score_std': 0.033333333333333326, 'max_history_step': 'joint'}, config={'algorithm': 'RandomForest', 'seed': 42, 'time': 300})
    108 
    109 def objective_algo(algo_config, current_pipeline_config, algorithm, X, y, context, config):
    110     return objective(current_pipeline_config, algo_config, algorithm, X, y, context, config, step='algorithm')
    111 
    112 def objective_joint(wconfig, algorithm, X, y, context, config):
--> 113     return objective(wconfig['pipeline'], wconfig['algorithm'], algorithm, X, y, context, config, step='joint')
        wconfig = {'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': 4, 'max_features': 3, 'max_leaf_nodes': 3, 'min_samples_split': 3, 'n_estimators': 50}, 'pipeline': {'features': ('features_SelectKBest', {'features__k': 2}), 'normalizer': ('normalizer_MinMaxScaler', {}), 'rebalance': ('rebalance_NearMiss', {'rebalance__n_neighbors': 2})}}
        algorithm = 'RandomForest'
        X = array([[5.1, 3.5, 1.4, 0.2],
       [4.9, 3. , 1....2, 3.4, 5.4, 2.3],
       [5.9, 3. , 5.1, 1.8]])
        y = array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,... 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2])
        context = {'baseline_score': 0.9466666666666667, 'baseline_score_std': 0.04988876515698587, 'best_config': {'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': 4, 'max_features': 3, 'max_leaf_nodes': 3, 'min_samples_split': 3, 'n_estimators': 10}, 'config_hash': {'algorithm': 'ffb7ff225ce3d3712c96cf87fe42202988ee2eb0', 'config': 'bae32f426be9cd6243523c023944a8c148fe4aeb', 'pipeline': 'd2a68bfda6fcdec4ae0ffc7d7b6a2122bc1cd673'}, 'duration': 0.7115809917449951, 'iteration': 113, 'loss': 0.033333333333333215, 'max_history_score': 0.9666666666666668, 'max_history_score_std': 0.033333333333333326, 'max_history_step': 'joint', 'pipeline': {'features': ('features_NoneType', {}), 'normalizer': ('normalizer_PowerTransformer', {}), 'rebalance': ('rebalance_CondensedNearestNeighbour', {'rebalance__n_neighbors': 2})}, 'score': 0.9666666666666668, ...}, 'history': [{'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': 2, 'max_features': None, 'max_leaf_nodes': 5, 'min_samples_split': 2, 'n_estimators': 75}, 'config_hash': {'algorithm': '3af5b0cce71c8fe2545246ca24ff5bc3dd516e06', 'config': 'db6ac7e6d348155757e4794bb5f88fe2b4f63d50', 'pipeline': '8d59f4b94cef6be9306ed86a22a9570fa670d567'}, 'duration': 1.149928092956543, 'iteration': 0, 'loss': 0.046666666666666634, 'max_history_score': 0.9533333333333334, 'max_history_score_std': 0.059999999999999984, 'max_history_step': 'joint', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 4, 'features__selectkbest__k': 3}), 'normalizer': ('normalizer_StandardScaler', {'normalizer__with_mean': True, 'normalizer__with_std': True}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 6})}, 'score': 0.9533333333333334, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': 1, 'max_features': 2, 'max_leaf_nodes': 2, 'min_samples_split': 5, 'n_estimators': 100}, 'config_hash': {'algorithm': 'e13eb05fd9a62d2f63bbb1c1deff0cd620d5e6ab', 'config': '4db6fb84d85f52659f780e682ffac5712c3d8a94', 'pipeline': '64c9a1ca9d53ae67244bdd942f4db36a3c05218c'}, 'duration': 1.7678282260894775, 'iteration': 1, 'loss': 0.18000000000000005, 'max_history_score': 0.9533333333333334, 'max_history_score_std': 0.059999999999999984, 'max_history_step': 'joint', 'pipeline': {'features': ('features_NoneType', {}), 'normalizer': ('normalizer_PowerTransformer', {}), 'rebalance': ('rebalance_NearMiss', {'rebalance__n_neighbors': 1})}, 'score': 0.82, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': 1, 'max_features': None, 'max_leaf_nodes': None, 'min_samples_split': 5, 'n_estimators': 75}, 'config_hash': {'algorithm': '94b0d7a654c508cc63643f78fe4f0f07e6f07c1e', 'config': '4403c5a85e951938d3c454e961d3a412780722f6', 'pipeline': '3e47444880d8367fbac2faaba2e52a917274aa58'}, 'duration': 0.8397619724273682, 'iteration': 2, 'loss': 0.03333333333333344, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_PCA', {'features__n_components': 3}), 'normalizer': ('normalizer_MinMaxScaler', {}), 'rebalance': ('rebalance_NoneType', {})}, 'score': 0.9666666666666666, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': None, 'max_features': None, 'max_leaf_nodes': 3, 'min_samples_split': 3, 'n_estimators': 75}, 'config_hash': {'algorithm': 'e8332f0a8902bda03bf70e7978cc5d52affb29d3', 'config': 'a064e2df18ab98d44dabcefbc7bed94913f1d0be', 'pipeline': '7eea819c2a8c103c4b1e9e9c1e224aebba95081f'}, 'duration': 0.8501448631286621, 'iteration': 3, 'loss': 0.053333333333333344, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 2, 'features__selectkbest__k': 4}), 'normalizer': ('normalizer_NoneType', {}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 7})}, 'score': 0.9466666666666667, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'entropy', 'max_depth': 3, 'max_features': 3, 'max_leaf_nodes': None, 'min_samples_split': 5, 'n_estimators': 75}, 'config_hash': {'algorithm': '7a4491035bc6bd737fe9a8cda8a79a02d02d5c74', 'config': '0ddb6f5cab3db4dddd7682966a57205f3e329ad4', 'pipeline': 'a9ae03fe38334f6868cbf84cdd3d629d4bbe3fb0'}, 'duration': 1.1026010513305664, 'iteration': 4, 'loss': 0.05999999999999994, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 2, 'features__selectkbest__k': 1}), 'normalizer': ('normalizer_NoneType', {}), 'rebalance': ('rebalance_NoneType', {})}, 'score': 0.9400000000000001, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'gini', 'max_depth': 3, 'max_features': 1, 'max_leaf_nodes': 5, 'min_samples_split': 2, 'n_estimators': 25}, 'config_hash': {'algorithm': '9826d20b2d6a0f559cf7f16450ce7526f07e8434', 'config': '49f25751bca61cdd461a8cbd2923689b642f98ed', 'pipeline': '19b249664c5bf067de1fed4334a296f947ce774a'}, 'duration': 0.35647010803222656, 'iteration': 5, 'loss': 0.046666666666666634, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_NoneType', {}), 'normalizer': ('normalizer_NoneType', {}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 6})}, 'score': 0.9533333333333334, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'gini', 'max_depth': 2, 'max_features': 1, 'max_leaf_nodes': 2, 'min_samples_split': 2, 'n_estimators': 50}, 'config_hash': {'algorithm': '0a4f6fbb07e0f32c6f675489a0fc82eee05bd8e1', 'config': '5c3a2b6f5e63fb45f10e41e0318b354912ec44f6', 'pipeline': 'dc3b9f176f090005e38b142f11d80e93a7dc5d5e'}, 'duration': 0.7213859558105469, 'iteration': 6, 'loss': 0.31333333333333324, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 1, 'features__selectkbest__k': 4}), 'normalizer': ('normalizer_PowerTransformer', {}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 7})}, 'score': 0.6866666666666668, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'entropy', 'max_depth': 4, 'max_features': 3, 'max_leaf_nodes': 5, 'min_samples_split': 5, 'n_estimators': 10}, 'config_hash': {'algorithm': 'b8112b97ecfc10f00a195af661dcc861cac21289', 'config': 'd3b129b397350f1b6572651c67c01de49b4b174c', 'pipeline': '5b0357ed7072c37b3d6f458bb5d49ff7d825f603'}, 'duration': 0.8299109935760498, 'iteration': 7, 'loss': 1.0, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_PCA', {'features__n_components': 2}), 'normalizer': ('normalizer_StandardScaler', {'normalizer__with_mean': True, 'normalizer__with_std': False}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 6})}, 'score': 0.0, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'gini', 'max_depth': 4, 'max_features': None, 'max_leaf_nodes': 2, 'min_samples_split': 5, 'n_estimators': 100}, 'config_hash': {'algorithm': '40ca24df19b8d164d9d098a6bed1ce056fbbb961', 'config': '813bde1108cc3c4b9bfb3a22cbb421bda7eac671', 'pipeline': '74a7b8705a1c22f7dea5e44e4ebda8f1e48add71'}, 'duration': 2.2111589908599854, 'iteration': 8, 'loss': 0.33333333333333326, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_PCA', {'features__n_components': 2}), 'normalizer': ('normalizer_StandardScaler', {'normalizer__with_mean': False, 'normalizer__with_std': True}), 'rebalance': ('rebalance_NearMiss', {'rebalance__n_neighbors': 2})}, 'score': 0.6666666666666667, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'entropy', 'max_depth': 2, 'max_features': 1, 'max_leaf_nodes': 5, 'min_samples_split': 2, 'n_estimators': 100}, 'config_hash': {'algorithm': '331418a5c12cf1453876eef85e9d98fc8e54fa11', 'config': '31930b6860ed406d59bf7e59ba1925d94704bd3b', 'pipeline': '054bef356f90ec6f644ef3ffc688766744db51c2'}, 'duration': 1.0501940250396729, 'iteration': 9, 'loss': 0.053333333333333344, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_SelectKBest', {'features__k': 1}), 'normalizer': ('normalizer_RobustScaler', {'normalizer__quantile_range': (...), 'normalizer__with_centering': True, 'normalizer__with_scaling': True}), 'rebalance': ('rebalance_NearMiss', {'rebalance__n_neighbors': 2})}, 'score': 0.9466666666666667, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'entropy', 'max_depth': 3, 'max_features': None, 'max_leaf_nodes': 3, 'min_samples_split': 2, 'n_estimators': 100}, 'config_hash': {'algorithm': 'dbc1b8126649fe93dce5fbb37e4015b0acfb179e', 'config': '9913cd550615a9d0946ab4a755a8b9f619e442fd', 'pipeline': 'dd626121cea079ebb32e184ca65483ec7a6d7f59'}, 'duration': 1.120617151260376, 'iteration': 10, 'loss': 0.046666666666666634, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 2, 'features__selectkbest__k': 1}), 'normalizer': ('normalizer_MinMaxScaler', {}), 'rebalance': ('rebalance_NoneType', {})}, 'score': 0.9533333333333334, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'gini', 'max_depth': 3, 'max_features': 3, 'max_leaf_nodes': None, 'min_samples_split': 3, 'n_estimators': 75}, 'config_hash': {'algorithm': '34917a130df5a975f78bd7ec1a0c7b1ffdc787a9', 'config': '95fc8cadc088141290b7de9c388977e4685f0108', 'pipeline': '550d10faf2f08db48516cc3501558816d6a99bc0'}, 'duration': 1.4287099838256836, 'iteration': 11, 'loss': 0.19333333333333313, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 3, 'features__selectkbest__k': 4}), 'normalizer': ('normalizer_StandardScaler', {'normalizer__with_mean': False, 'normalizer__with_std': False}), 'rebalance': ('rebalance_CondensedNearestNeighbour', {'rebalance__n_neighbors': 1})}, 'score': 0.8066666666666669, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'entropy', 'max_depth': 1, 'max_features': 2, 'max_leaf_nodes': 5, 'min_samples_split': 2, 'n_estimators': 75}, 'config_hash': {'algorithm': '33f9abb4aee44a395a9f3b3ffa9ce80a8cdaed7c', 'config': '40fa726f0360cf6af55f9b5902d399d02f61f157', 'pipeline': 'cfd1d20841fe2153da762c95e79f95a3fb1e426a'}, 'duration': 1.2978079319000244, 'iteration': 12, 'loss': 0.053333333333333344, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_PCA', {'features__n_components': 4}), 'normalizer': ('normalizer_MinMaxScaler', {}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 7})}, 'score': 0.9466666666666667, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'entropy', 'max_depth': 4, 'max_features': 2, 'max_leaf_nodes': 5, 'min_samples_split': 3, 'n_estimators': 25}, 'config_hash': {'algorithm': '210111ec6562d09eb093e98ed69ef1c662e11a50', 'config': '0fb8e77c7bd9a58b72f1b33c21a59a09a8c676ba', 'pipeline': '5d269d759e0c7926a685a14b263ace8ae0071e4b'}, 'duration': 0.36649012565612793, 'iteration': 13, 'loss': 0.040000000000000036, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 2, 'features__selectkbest__k': 2}), 'normalizer': ('normalizer_NoneType', {}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 7})}, 'score': 0.96, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'entropy', 'max_depth': 3, 'max_features': 1, 'max_leaf_nodes': 5, 'min_samples_split': 2, 'n_estimators': 25}, 'config_hash': {'algorithm': '0e989a03980101fabf79eda3326ed2870e11d690', 'config': 'f4bffd5d8c67a9c5321a9943c4a99678f59a02b7', 'pipeline': '865ee1e3fe8334c3d5ecb2038d5a5d1b3ba50e75'}, 'duration': 0.35639500617980957, 'iteration': 14, 'loss': 0.046666666666666634, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_NoneType', {}), 'normalizer': ('normalizer_RobustScaler', {'normalizer__quantile_range': (...), 'normalizer__with_centering': True, 'normalizer__with_scaling': False}), 'rebalance': ('rebalance_NoneType', {})}, 'score': 0.9533333333333334, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'entropy', 'max_depth': None, 'max_features': 3, 'max_leaf_nodes': 3, 'min_samples_split': 5, 'n_estimators': 10}, 'config_hash': {'algorithm': '9c592e876c13de5e23e6de5b868e01755d63e72e', 'config': '1e6a68cd1eeac886d90724d78b1cb5fb76a3cde4', 'pipeline': '5a1ca4d82f21b7de0d2c918630a42510673fa36e'}, 'duration': 0.18141412734985352, 'iteration': 15, 'loss': 0.046666666666666634, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_SelectKBest', {'features__k': 3}), 'normalizer': ('normalizer_RobustScaler', {'normalizer__quantile_range': (...), 'normalizer__with_centering': True, 'normalizer__with_scaling': True}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 6})}, 'score': 0.9533333333333334, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': 1, 'max_features': None, 'max_leaf_nodes': None, 'min_samples_split': 5, 'n_estimators': 10}, 'config_hash': {'algorithm': '8bed77aef289bfd453b2858bd288ae5ba7160f2b', 'config': '781185bcb8999045de8d489f253a1a1ba4247932', 'pipeline': '1ece7eabedc2be9e5b0a1be65c570d08ffa3eb54'}, 'duration': 0.1636829376220703, 'iteration': 16, 'loss': 0.053333333333333344, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_NoneType', {}), 'normalizer': ('normalizer_NoneType', {}), 'rebalance': ('rebalance_NearMiss', {'rebalance__n_neighbors': 1})}, 'score': 0.9466666666666667, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'gini', 'max_depth': 3, 'max_features': 2, 'max_leaf_nodes': 2, 'min_samples_split': 5, 'n_estimators': 75}, 'config_hash': {'algorithm': '617b97d9ba21d3373bc51ffa9cccf9c6f91a77b3', 'config': '99fb425b4e8c5d80228cab94202252aa25cdf77c', 'pipeline': 'd6242929c3b515c7719e60423023ac604311afc3'}, 'duration': 0.8468999862670898, 'iteration': 17, 'loss': 0.24, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_PCA', {'features__n_components': 4}), 'normalizer': ('normalizer_PowerTransformer', {}), 'rebalance': ('rebalance_NearMiss', {'rebalance__n_neighbors': 2})}, 'score': 0.76, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': 1, 'max_features': 1, 'max_leaf_nodes': 2, 'min_samples_split': 5, 'n_estimators': 50}, 'config_hash': {'algorithm': 'b92d2697cdd4979da443369d6596229ec091626a', 'config': 'c513a3e13281206ad76187dd817b1fff93d54fe1', 'pipeline': 'c4b4f914a3ca8df967cade997a90366d85a371b9'}, 'duration': 0.6724588871002197, 'iteration': 18, 'loss': 0.23333333333333328, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 1, 'features__selectkbest__k': 3}), 'normalizer': ('normalizer_StandardScaler', {'normalizer__with_mean': True, 'normalizer__with_std': True}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 5})}, 'score': 0.7666666666666667, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'entropy', 'max_depth': None, 'max_features': None, 'max_leaf_nodes': 5, 'min_samples_split': 5, 'n_estimators': 10}, 'config_hash': {'algorithm': 'a0115de695e6cca2e81cbfb54df79bf4b43608b1', 'config': 'ba194015e20b5d67770e8c67342c3d8d0d01dc41', 'pipeline': '8d45fabfeb85ffdcabf7076bd0e65fffe97ce928'}, 'duration': 0.19424200057983398, 'iteration': 19, 'loss': 0.08666666666666667, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_PCA', {'features__n_components': 3}), 'normalizer': ('normalizer_NoneType', {}), 'rebalance': ('rebalance_NoneType', {})}, 'score': 0.9133333333333333, ...}, ...], 'history_hash': ['db6ac7e6d348155757e4794bb5f88fe2b4f63d50', '4db6fb84d85f52659f780e682ffac5712c3d8a94', '4403c5a85e951938d3c454e961d3a412780722f6', 'a064e2df18ab98d44dabcefbc7bed94913f1d0be', '0ddb6f5cab3db4dddd7682966a57205f3e329ad4', '49f25751bca61cdd461a8cbd2923689b642f98ed', '5c3a2b6f5e63fb45f10e41e0318b354912ec44f6', 'd3b129b397350f1b6572651c67c01de49b4b174c', '813bde1108cc3c4b9bfb3a22cbb421bda7eac671', '31930b6860ed406d59bf7e59ba1925d94704bd3b', '9913cd550615a9d0946ab4a755a8b9f619e442fd', '95fc8cadc088141290b7de9c388977e4685f0108', '40fa726f0360cf6af55f9b5902d399d02f61f157', '0fb8e77c7bd9a58b72f1b33c21a59a09a8c676ba', 'f4bffd5d8c67a9c5321a9943c4a99678f59a02b7', '1e6a68cd1eeac886d90724d78b1cb5fb76a3cde4', '781185bcb8999045de8d489f253a1a1ba4247932', '99fb425b4e8c5d80228cab94202252aa25cdf77c', 'c513a3e13281206ad76187dd817b1fff93d54fe1', 'ba194015e20b5d67770e8c67342c3d8d0d01dc41', ...], 'history_index': {'00f0493590a2cb5e98a35b29816f8cd9f87f96ec': 208, '01161dcc5f8ee022f65481dacf76468db745b463': 306, '013329309d510b94f19d930320402d65f953a847': 39, '038a0f515e2ec894ee8e34f9caa2889eb3ebd5ce': 66, '052ae4bf232b316187b078abae42c2be19e16a00': 111, '05e9258ebf99dd97202167ef1563fa834b0568f1': 242, '0659afebf316aafeb75612fb07081a04c28545ed': 74, '06e7cde9f3556cd01332ce389ad1d8925cd4b4a4': 120, '07ab8a30d853e39a326b7017026a20e94bc45541': 245, '0855e6ed1503da05dc544450a5da27e4b3441758': 307, ...}, 'iteration': 337, 'max_history_score': 0.9666666666666668, 'max_history_score_std': 0.033333333333333326, 'max_history_step': 'joint'}
        config = {'algorithm': 'RandomForest', 'seed': 42, 'time': 300}
    114 
    115 
    116 def get_baseline_score(algorithm, X, y, seed):
    117     pipeline, _ = pipeline_conf_to_full_pipeline(

...........................................................................
/home/aquemy/dev/dp_hyperparameters/extension/experiment/objective.py in objective(pipeline_config={'features': ('features_SelectKBest', {'features__k': 2}), 'normalizer': ('normalizer_MinMaxScaler', {}), 'rebalance': ('rebalance_NearMiss', {'rebalance__n_neighbors': 2})}, algo_config={'bootstrap': True, 'criterion': 'gini', 'max_depth': 4, 'max_features': 3, 'max_leaf_nodes': 3, 'min_samples_split': 3, 'n_estimators': 50}, algorithm='RandomForest', X=array([[5.1, 3.5, 1.4, 0.2],
       [4.9, 3. , 1....2, 3.4, 5.4, 2.3],
       [5.9, 3. , 5.1, 1.8]]), y=array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,... 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]), context={'baseline_score': 0.9466666666666667, 'baseline_score_std': 0.04988876515698587, 'best_config': {'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': 4, 'max_features': 3, 'max_leaf_nodes': 3, 'min_samples_split': 3, 'n_estimators': 10}, 'config_hash': {'algorithm': 'ffb7ff225ce3d3712c96cf87fe42202988ee2eb0', 'config': 'bae32f426be9cd6243523c023944a8c148fe4aeb', 'pipeline': 'd2a68bfda6fcdec4ae0ffc7d7b6a2122bc1cd673'}, 'duration': 0.7115809917449951, 'iteration': 113, 'loss': 0.033333333333333215, 'max_history_score': 0.9666666666666668, 'max_history_score_std': 0.033333333333333326, 'max_history_step': 'joint', 'pipeline': {'features': ('features_NoneType', {}), 'normalizer': ('normalizer_PowerTransformer', {}), 'rebalance': ('rebalance_CondensedNearestNeighbour', {'rebalance__n_neighbors': 2})}, 'score': 0.9666666666666668, ...}, 'history': [{'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': 2, 'max_features': None, 'max_leaf_nodes': 5, 'min_samples_split': 2, 'n_estimators': 75}, 'config_hash': {'algorithm': '3af5b0cce71c8fe2545246ca24ff5bc3dd516e06', 'config': 'db6ac7e6d348155757e4794bb5f88fe2b4f63d50', 'pipeline': '8d59f4b94cef6be9306ed86a22a9570fa670d567'}, 'duration': 1.149928092956543, 'iteration': 0, 'loss': 0.046666666666666634, 'max_history_score': 0.9533333333333334, 'max_history_score_std': 0.059999999999999984, 'max_history_step': 'joint', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 4, 'features__selectkbest__k': 3}), 'normalizer': ('normalizer_StandardScaler', {'normalizer__with_mean': True, 'normalizer__with_std': True}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 6})}, 'score': 0.9533333333333334, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': 1, 'max_features': 2, 'max_leaf_nodes': 2, 'min_samples_split': 5, 'n_estimators': 100}, 'config_hash': {'algorithm': 'e13eb05fd9a62d2f63bbb1c1deff0cd620d5e6ab', 'config': '4db6fb84d85f52659f780e682ffac5712c3d8a94', 'pipeline': '64c9a1ca9d53ae67244bdd942f4db36a3c05218c'}, 'duration': 1.7678282260894775, 'iteration': 1, 'loss': 0.18000000000000005, 'max_history_score': 0.9533333333333334, 'max_history_score_std': 0.059999999999999984, 'max_history_step': 'joint', 'pipeline': {'features': ('features_NoneType', {}), 'normalizer': ('normalizer_PowerTransformer', {}), 'rebalance': ('rebalance_NearMiss', {'rebalance__n_neighbors': 1})}, 'score': 0.82, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': 1, 'max_features': None, 'max_leaf_nodes': None, 'min_samples_split': 5, 'n_estimators': 75}, 'config_hash': {'algorithm': '94b0d7a654c508cc63643f78fe4f0f07e6f07c1e', 'config': '4403c5a85e951938d3c454e961d3a412780722f6', 'pipeline': '3e47444880d8367fbac2faaba2e52a917274aa58'}, 'duration': 0.8397619724273682, 'iteration': 2, 'loss': 0.03333333333333344, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_PCA', {'features__n_components': 3}), 'normalizer': ('normalizer_MinMaxScaler', {}), 'rebalance': ('rebalance_NoneType', {})}, 'score': 0.9666666666666666, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': None, 'max_features': None, 'max_leaf_nodes': 3, 'min_samples_split': 3, 'n_estimators': 75}, 'config_hash': {'algorithm': 'e8332f0a8902bda03bf70e7978cc5d52affb29d3', 'config': 'a064e2df18ab98d44dabcefbc7bed94913f1d0be', 'pipeline': '7eea819c2a8c103c4b1e9e9c1e224aebba95081f'}, 'duration': 0.8501448631286621, 'iteration': 3, 'loss': 0.053333333333333344, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 2, 'features__selectkbest__k': 4}), 'normalizer': ('normalizer_NoneType', {}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 7})}, 'score': 0.9466666666666667, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'entropy', 'max_depth': 3, 'max_features': 3, 'max_leaf_nodes': None, 'min_samples_split': 5, 'n_estimators': 75}, 'config_hash': {'algorithm': '7a4491035bc6bd737fe9a8cda8a79a02d02d5c74', 'config': '0ddb6f5cab3db4dddd7682966a57205f3e329ad4', 'pipeline': 'a9ae03fe38334f6868cbf84cdd3d629d4bbe3fb0'}, 'duration': 1.1026010513305664, 'iteration': 4, 'loss': 0.05999999999999994, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 2, 'features__selectkbest__k': 1}), 'normalizer': ('normalizer_NoneType', {}), 'rebalance': ('rebalance_NoneType', {})}, 'score': 0.9400000000000001, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'gini', 'max_depth': 3, 'max_features': 1, 'max_leaf_nodes': 5, 'min_samples_split': 2, 'n_estimators': 25}, 'config_hash': {'algorithm': '9826d20b2d6a0f559cf7f16450ce7526f07e8434', 'config': '49f25751bca61cdd461a8cbd2923689b642f98ed', 'pipeline': '19b249664c5bf067de1fed4334a296f947ce774a'}, 'duration': 0.35647010803222656, 'iteration': 5, 'loss': 0.046666666666666634, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_NoneType', {}), 'normalizer': ('normalizer_NoneType', {}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 6})}, 'score': 0.9533333333333334, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'gini', 'max_depth': 2, 'max_features': 1, 'max_leaf_nodes': 2, 'min_samples_split': 2, 'n_estimators': 50}, 'config_hash': {'algorithm': '0a4f6fbb07e0f32c6f675489a0fc82eee05bd8e1', 'config': '5c3a2b6f5e63fb45f10e41e0318b354912ec44f6', 'pipeline': 'dc3b9f176f090005e38b142f11d80e93a7dc5d5e'}, 'duration': 0.7213859558105469, 'iteration': 6, 'loss': 0.31333333333333324, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 1, 'features__selectkbest__k': 4}), 'normalizer': ('normalizer_PowerTransformer', {}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 7})}, 'score': 0.6866666666666668, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'entropy', 'max_depth': 4, 'max_features': 3, 'max_leaf_nodes': 5, 'min_samples_split': 5, 'n_estimators': 10}, 'config_hash': {'algorithm': 'b8112b97ecfc10f00a195af661dcc861cac21289', 'config': 'd3b129b397350f1b6572651c67c01de49b4b174c', 'pipeline': '5b0357ed7072c37b3d6f458bb5d49ff7d825f603'}, 'duration': 0.8299109935760498, 'iteration': 7, 'loss': 1.0, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_PCA', {'features__n_components': 2}), 'normalizer': ('normalizer_StandardScaler', {'normalizer__with_mean': True, 'normalizer__with_std': False}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 6})}, 'score': 0.0, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'gini', 'max_depth': 4, 'max_features': None, 'max_leaf_nodes': 2, 'min_samples_split': 5, 'n_estimators': 100}, 'config_hash': {'algorithm': '40ca24df19b8d164d9d098a6bed1ce056fbbb961', 'config': '813bde1108cc3c4b9bfb3a22cbb421bda7eac671', 'pipeline': '74a7b8705a1c22f7dea5e44e4ebda8f1e48add71'}, 'duration': 2.2111589908599854, 'iteration': 8, 'loss': 0.33333333333333326, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_PCA', {'features__n_components': 2}), 'normalizer': ('normalizer_StandardScaler', {'normalizer__with_mean': False, 'normalizer__with_std': True}), 'rebalance': ('rebalance_NearMiss', {'rebalance__n_neighbors': 2})}, 'score': 0.6666666666666667, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'entropy', 'max_depth': 2, 'max_features': 1, 'max_leaf_nodes': 5, 'min_samples_split': 2, 'n_estimators': 100}, 'config_hash': {'algorithm': '331418a5c12cf1453876eef85e9d98fc8e54fa11', 'config': '31930b6860ed406d59bf7e59ba1925d94704bd3b', 'pipeline': '054bef356f90ec6f644ef3ffc688766744db51c2'}, 'duration': 1.0501940250396729, 'iteration': 9, 'loss': 0.053333333333333344, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_SelectKBest', {'features__k': 1}), 'normalizer': ('normalizer_RobustScaler', {'normalizer__quantile_range': (...), 'normalizer__with_centering': True, 'normalizer__with_scaling': True}), 'rebalance': ('rebalance_NearMiss', {'rebalance__n_neighbors': 2})}, 'score': 0.9466666666666667, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'entropy', 'max_depth': 3, 'max_features': None, 'max_leaf_nodes': 3, 'min_samples_split': 2, 'n_estimators': 100}, 'config_hash': {'algorithm': 'dbc1b8126649fe93dce5fbb37e4015b0acfb179e', 'config': '9913cd550615a9d0946ab4a755a8b9f619e442fd', 'pipeline': 'dd626121cea079ebb32e184ca65483ec7a6d7f59'}, 'duration': 1.120617151260376, 'iteration': 10, 'loss': 0.046666666666666634, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 2, 'features__selectkbest__k': 1}), 'normalizer': ('normalizer_MinMaxScaler', {}), 'rebalance': ('rebalance_NoneType', {})}, 'score': 0.9533333333333334, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'gini', 'max_depth': 3, 'max_features': 3, 'max_leaf_nodes': None, 'min_samples_split': 3, 'n_estimators': 75}, 'config_hash': {'algorithm': '34917a130df5a975f78bd7ec1a0c7b1ffdc787a9', 'config': '95fc8cadc088141290b7de9c388977e4685f0108', 'pipeline': '550d10faf2f08db48516cc3501558816d6a99bc0'}, 'duration': 1.4287099838256836, 'iteration': 11, 'loss': 0.19333333333333313, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 3, 'features__selectkbest__k': 4}), 'normalizer': ('normalizer_StandardScaler', {'normalizer__with_mean': False, 'normalizer__with_std': False}), 'rebalance': ('rebalance_CondensedNearestNeighbour', {'rebalance__n_neighbors': 1})}, 'score': 0.8066666666666669, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'entropy', 'max_depth': 1, 'max_features': 2, 'max_leaf_nodes': 5, 'min_samples_split': 2, 'n_estimators': 75}, 'config_hash': {'algorithm': '33f9abb4aee44a395a9f3b3ffa9ce80a8cdaed7c', 'config': '40fa726f0360cf6af55f9b5902d399d02f61f157', 'pipeline': 'cfd1d20841fe2153da762c95e79f95a3fb1e426a'}, 'duration': 1.2978079319000244, 'iteration': 12, 'loss': 0.053333333333333344, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_PCA', {'features__n_components': 4}), 'normalizer': ('normalizer_MinMaxScaler', {}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 7})}, 'score': 0.9466666666666667, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'entropy', 'max_depth': 4, 'max_features': 2, 'max_leaf_nodes': 5, 'min_samples_split': 3, 'n_estimators': 25}, 'config_hash': {'algorithm': '210111ec6562d09eb093e98ed69ef1c662e11a50', 'config': '0fb8e77c7bd9a58b72f1b33c21a59a09a8c676ba', 'pipeline': '5d269d759e0c7926a685a14b263ace8ae0071e4b'}, 'duration': 0.36649012565612793, 'iteration': 13, 'loss': 0.040000000000000036, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 2, 'features__selectkbest__k': 2}), 'normalizer': ('normalizer_NoneType', {}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 7})}, 'score': 0.96, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'entropy', 'max_depth': 3, 'max_features': 1, 'max_leaf_nodes': 5, 'min_samples_split': 2, 'n_estimators': 25}, 'config_hash': {'algorithm': '0e989a03980101fabf79eda3326ed2870e11d690', 'config': 'f4bffd5d8c67a9c5321a9943c4a99678f59a02b7', 'pipeline': '865ee1e3fe8334c3d5ecb2038d5a5d1b3ba50e75'}, 'duration': 0.35639500617980957, 'iteration': 14, 'loss': 0.046666666666666634, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_NoneType', {}), 'normalizer': ('normalizer_RobustScaler', {'normalizer__quantile_range': (...), 'normalizer__with_centering': True, 'normalizer__with_scaling': False}), 'rebalance': ('rebalance_NoneType', {})}, 'score': 0.9533333333333334, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'entropy', 'max_depth': None, 'max_features': 3, 'max_leaf_nodes': 3, 'min_samples_split': 5, 'n_estimators': 10}, 'config_hash': {'algorithm': '9c592e876c13de5e23e6de5b868e01755d63e72e', 'config': '1e6a68cd1eeac886d90724d78b1cb5fb76a3cde4', 'pipeline': '5a1ca4d82f21b7de0d2c918630a42510673fa36e'}, 'duration': 0.18141412734985352, 'iteration': 15, 'loss': 0.046666666666666634, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_SelectKBest', {'features__k': 3}), 'normalizer': ('normalizer_RobustScaler', {'normalizer__quantile_range': (...), 'normalizer__with_centering': True, 'normalizer__with_scaling': True}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 6})}, 'score': 0.9533333333333334, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': 1, 'max_features': None, 'max_leaf_nodes': None, 'min_samples_split': 5, 'n_estimators': 10}, 'config_hash': {'algorithm': '8bed77aef289bfd453b2858bd288ae5ba7160f2b', 'config': '781185bcb8999045de8d489f253a1a1ba4247932', 'pipeline': '1ece7eabedc2be9e5b0a1be65c570d08ffa3eb54'}, 'duration': 0.1636829376220703, 'iteration': 16, 'loss': 0.053333333333333344, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_NoneType', {}), 'normalizer': ('normalizer_NoneType', {}), 'rebalance': ('rebalance_NearMiss', {'rebalance__n_neighbors': 1})}, 'score': 0.9466666666666667, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'gini', 'max_depth': 3, 'max_features': 2, 'max_leaf_nodes': 2, 'min_samples_split': 5, 'n_estimators': 75}, 'config_hash': {'algorithm': '617b97d9ba21d3373bc51ffa9cccf9c6f91a77b3', 'config': '99fb425b4e8c5d80228cab94202252aa25cdf77c', 'pipeline': 'd6242929c3b515c7719e60423023ac604311afc3'}, 'duration': 0.8468999862670898, 'iteration': 17, 'loss': 0.24, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_PCA', {'features__n_components': 4}), 'normalizer': ('normalizer_PowerTransformer', {}), 'rebalance': ('rebalance_NearMiss', {'rebalance__n_neighbors': 2})}, 'score': 0.76, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': 1, 'max_features': 1, 'max_leaf_nodes': 2, 'min_samples_split': 5, 'n_estimators': 50}, 'config_hash': {'algorithm': 'b92d2697cdd4979da443369d6596229ec091626a', 'config': 'c513a3e13281206ad76187dd817b1fff93d54fe1', 'pipeline': 'c4b4f914a3ca8df967cade997a90366d85a371b9'}, 'duration': 0.6724588871002197, 'iteration': 18, 'loss': 0.23333333333333328, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 1, 'features__selectkbest__k': 3}), 'normalizer': ('normalizer_StandardScaler', {'normalizer__with_mean': True, 'normalizer__with_std': True}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 5})}, 'score': 0.7666666666666667, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'entropy', 'max_depth': None, 'max_features': None, 'max_leaf_nodes': 5, 'min_samples_split': 5, 'n_estimators': 10}, 'config_hash': {'algorithm': 'a0115de695e6cca2e81cbfb54df79bf4b43608b1', 'config': 'ba194015e20b5d67770e8c67342c3d8d0d01dc41', 'pipeline': '8d45fabfeb85ffdcabf7076bd0e65fffe97ce928'}, 'duration': 0.19424200057983398, 'iteration': 19, 'loss': 0.08666666666666667, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_PCA', {'features__n_components': 3}), 'normalizer': ('normalizer_NoneType', {}), 'rebalance': ('rebalance_NoneType', {})}, 'score': 0.9133333333333333, ...}, ...], 'history_hash': ['db6ac7e6d348155757e4794bb5f88fe2b4f63d50', '4db6fb84d85f52659f780e682ffac5712c3d8a94', '4403c5a85e951938d3c454e961d3a412780722f6', 'a064e2df18ab98d44dabcefbc7bed94913f1d0be', '0ddb6f5cab3db4dddd7682966a57205f3e329ad4', '49f25751bca61cdd461a8cbd2923689b642f98ed', '5c3a2b6f5e63fb45f10e41e0318b354912ec44f6', 'd3b129b397350f1b6572651c67c01de49b4b174c', '813bde1108cc3c4b9bfb3a22cbb421bda7eac671', '31930b6860ed406d59bf7e59ba1925d94704bd3b', '9913cd550615a9d0946ab4a755a8b9f619e442fd', '95fc8cadc088141290b7de9c388977e4685f0108', '40fa726f0360cf6af55f9b5902d399d02f61f157', '0fb8e77c7bd9a58b72f1b33c21a59a09a8c676ba', 'f4bffd5d8c67a9c5321a9943c4a99678f59a02b7', '1e6a68cd1eeac886d90724d78b1cb5fb76a3cde4', '781185bcb8999045de8d489f253a1a1ba4247932', '99fb425b4e8c5d80228cab94202252aa25cdf77c', 'c513a3e13281206ad76187dd817b1fff93d54fe1', 'ba194015e20b5d67770e8c67342c3d8d0d01dc41', ...], 'history_index': {'00f0493590a2cb5e98a35b29816f8cd9f87f96ec': 208, '01161dcc5f8ee022f65481dacf76468db745b463': 306, '013329309d510b94f19d930320402d65f953a847': 39, '038a0f515e2ec894ee8e34f9caa2889eb3ebd5ce': 66, '052ae4bf232b316187b078abae42c2be19e16a00': 111, '05e9258ebf99dd97202167ef1563fa834b0568f1': 242, '0659afebf316aafeb75612fb07081a04c28545ed': 74, '06e7cde9f3556cd01332ce389ad1d8925cd4b4a4': 120, '07ab8a30d853e39a326b7017026a20e94bc45541': 245, '0855e6ed1503da05dc544450a5da27e4b3441758': 307, ...}, 'iteration': 337, 'max_history_score': 0.9666666666666668, 'max_history_score_std': 0.033333333333333326, 'max_history_step': 'joint'}, config={'algorithm': 'RandomForest', 'seed': 42, 'time': 300}, step='joint')
     45                 y,
     46                 cv=10,
     47                 n_jobs=-1,
     48                 return_estimator=False,
     49                 return_train_score=False,
---> 50                 verbose=0)
     51         score = np.mean(scores['test_score'])
     52         std = np.std(scores['test_score'])
     53         status = STATUS_OK
     54     except Exception as e:

...........................................................................
/home/aquemy/.local/lib/python2.7/site-packages/sklearn/model_selection/_validation.py in cross_validate(estimator=Pipeline(memory=None,
     steps=[('rebalance', ... random_state=42, verbose=0, warm_start=False))]), X=array([[5.1, 3.5, 1.4, 0.2],
       [4.9, 3. , 1....2, 3.4, 5.4, 2.3],
       [5.9, 3. , 5.1, 1.8]]), y=array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,... 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]), groups=None, scoring=None, cv=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1, verbose=0, fit_params=None, pre_dispatch='2*n_jobs', return_train_score=False, return_estimator=False, error_score='raise-deprecating')
    235         delayed(_fit_and_score)(
    236             clone(estimator), X, y, scorers, train, test, verbose, None,
    237             fit_params, return_train_score=return_train_score,
    238             return_times=True, return_estimator=return_estimator,
    239             error_score=error_score)
--> 240         for train, test in cv.split(X, y, groups))
        cv.split = <bound method StratifiedKFold.split of Stratifie...d(n_splits=10, random_state=None, shuffle=False)>
        X = array([[5.1, 3.5, 1.4, 0.2],
       [4.9, 3. , 1....2, 3.4, 5.4, 2.3],
       [5.9, 3. , 5.1, 1.8]])
        y = array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,... 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2])
        groups = None
    241 
    242     zipped_scores = list(zip(*scores))
    243     if return_train_score:
    244         train_scores = zipped_scores.pop(0)

...........................................................................
/home/aquemy/.local/lib/python2.7/site-packages/sklearn/externals/joblib/parallel.py in __call__(self=Parallel(n_jobs=-1), iterable=<generator object <genexpr>>)
    925                 # No need to wait for async callbacks to trigger to
    926                 # consumption.
    927                 self._iterating = False
    928 
    929             with self._backend.retrieval_context():
--> 930                 self.retrieve()
        self.retrieve = <bound method Parallel.retrieve of Parallel(n_jobs=-1)>
    931             # Make sure that we get a last message telling us we are done
    932             elapsed_time = time.time() - self._start_time
    933             self._print('Done %3i out of %3i | elapsed: %s finished',
    934                         (len(self._output), len(self._output),

---------------------------------------------------------------------------
Joblib worker traceback:
---------------------------------------------------------------------------
ValueError                                         Mon Jun 17 13:15:07 2019
PID: 21977                                  Python 2.7.15+: /usr/bin/python
...........................................................................
/home/aquemy/.local/lib/python2.7/site-packages/sklearn/externals/joblib/parallel.py in __call__(self=<sklearn.externals.joblib.parallel.BatchedCalls object>)
    220     def __call__(self):
    221         # Set the default nested backend to self._backend but do not set the
    222         # change the default number of processes to -1
    223         with parallel_backend(self._backend, n_jobs=self._n_jobs):
    224             return [func(*args, **kwargs)
--> 225                     for func, args, kwargs in self.items]
        func = <function _fit_and_score>
        args = (Pipeline(memory=None,
     steps=[('rebalance', ... random_state=42, verbose=0, warm_start=False))]), array([[5.1, 3.5, 1.4, 0.2],
       [4.9, 3. , 1....2, 3.4, 5.4, 2.3],
       [5.9, 3. , 5.1, 1.8]]), array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,... 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]), {'score': <function _passthrough_scorer>}, array([  5,   6,   7,   8,   9,  10,  11,  12,  ..., 142, 143, 144,
       145, 146, 147, 148, 149]), array([  0,   1,   2,   3,   4,  50,  51,  52,  53,  54, 100, 101, 102,
       103, 104]), 0, None, None)
        kwargs = {'error_score': 'raise-deprecating', 'return_estimator': False, 'return_times': True, 'return_train_score': False}
        self.items = [(<function _fit_and_score>, (Pipeline(memory=None,
     steps=[('rebalance', ... random_state=42, verbose=0, warm_start=False))]), array([[5.1, 3.5, 1.4, 0.2],
       [4.9, 3. , 1....2, 3.4, 5.4, 2.3],
       [5.9, 3. , 5.1, 1.8]]), array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,... 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]), {'score': <function _passthrough_scorer>}, array([  5,   6,   7,   8,   9,  10,  11,  12,  ..., 142, 143, 144,
       145, 146, 147, 148, 149]), array([  0,   1,   2,   3,   4,  50,  51,  52,  53,  54, 100, 101, 102,
       103, 104]), 0, None, None), {'error_score': 'raise-deprecating', 'return_estimator': False, 'return_times': True, 'return_train_score': False})]
    226 
    227     def __len__(self):
    228         return self._size
    229 

...........................................................................
/home/aquemy/.local/lib/python2.7/site-packages/sklearn/model_selection/_validation.py in _fit_and_score(estimator=Pipeline(memory=None,
     steps=[('rebalance', ... random_state=42, verbose=0, warm_start=False))]), X=array([[5.1, 3.5, 1.4, 0.2],
       [4.9, 3. , 1....2, 3.4, 5.4, 2.3],
       [5.9, 3. , 5.1, 1.8]]), y=array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,... 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]), scorer={'score': <function _passthrough_scorer>}, train=array([  5,   6,   7,   8,   9,  10,  11,  12,  ..., 142, 143, 144,
       145, 146, 147, 148, 149]), test=array([  0,   1,   2,   3,   4,  50,  51,  52,  53,  54, 100, 101, 102,
       103, 104]), verbose=0, parameters=None, fit_params={}, return_train_score=False, return_parameters=False, return_n_test_samples=False, return_times=True, return_estimator=False, error_score='raise-deprecating')
    523 
    524     try:
    525         if y_train is None:
    526             estimator.fit(X_train, **fit_params)
    527         else:
--> 528             estimator.fit(X_train, y_train, **fit_params)
        estimator.fit = <bound method Pipeline.fit of Pipeline(memory=No...random_state=42, verbose=0, warm_start=False))])>
        X_train = array([[5.4, 3.9, 1.7, 0.4],
       [4.6, 3.4, 1....2, 3.4, 5.4, 2.3],
       [5.9, 3. , 5.1, 1.8]])
        y_train = array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,
       2, 2, 2])
        fit_params = {}
    529 
    530     except Exception as e:
    531         # Note fit time as time until error
    532         fit_time = time.time() - start_time

...........................................................................
/usr/local/lib/python2.7/dist-packages/imblearn/pipeline.py in fit(self=Pipeline(memory=None,
     steps=[('rebalance', ... random_state=42, verbose=0, warm_start=False))]), X=array([[5.4, 3.9, 1.7, 0.4],
       [4.6, 3.4, 1....2, 3.4, 5.4, 2.3],
       [5.9, 3. , 5.1, 1.8]]), y=array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,
       2, 2, 2]), **fit_params={})
    234             This estimator
    235 
    236         """
    237         Xt, yt, fit_params = self._fit(X, y, **fit_params)
    238         if self._final_estimator is not None:
--> 239             self._final_estimator.fit(Xt, yt, **fit_params)
        self._final_estimator.fit = <bound method RandomForestClassifier.fit of Rand...e, random_state=42, verbose=0, warm_start=False)>
        Xt = array([[0.11864407, 0.125     ],
       [0.06779...9, 0.79166667],
       [1.        , 0.91666667]])
        yt = array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,
       2, 2, 2])
        fit_params = {}
    240         return self
    241 
    242     def fit_transform(self, X, y=None, **fit_params):
    243         """Fit the model and transform with the final estimator

...........................................................................
/home/aquemy/.local/lib/python2.7/site-packages/sklearn/ensemble/forest.py in fit(self=RandomForestClassifier(bootstrap=True, class_wei...se, random_state=42, verbose=0, warm_start=False), X=array([[0.11864407, 0.125     ],
       [0.06779...
       [1.        , 0.9166667 ]], dtype=float32), y=array([[0.],
       [0.],
       [0.],
       [0...    [2.],
       [2.],
       [2.],
       [2.]]), sample_weight=None)
    328             trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,
    329                              **_joblib_parallel_args(prefer='threads'))(
    330                 delayed(_parallel_build_trees)(
    331                     t, self, X, y, sample_weight, i, len(trees),
    332                     verbose=self.verbose, class_weight=self.class_weight)
--> 333                 for i, t in enumerate(trees))
        i = 49
    334 
    335             # Collect newly grown trees
    336             self.estimators_.extend(trees)
    337 

...........................................................................
/home/aquemy/.local/lib/python2.7/site-packages/sklearn/externals/joblib/parallel.py in __call__(self=Parallel(n_jobs=1), iterable=<generator object <genexpr>>)
    912             # self._original_iterator is None, then this means either
    913             # that pre_dispatch == "all", n_jobs == 1 or that the first batch
    914             # was very quick and its callback already dispatched all the
    915             # remaining jobs.
    916             self._iterating = False
--> 917             if self.dispatch_one_batch(iterator):
        self.dispatch_one_batch = <bound method Parallel.dispatch_one_batch of Parallel(n_jobs=1)>
        iterator = <generator object <genexpr>>
    918                 self._iterating = self._original_iterator is not None
    919 
    920             while self.dispatch_one_batch(iterator):
    921                 pass

...........................................................................
/home/aquemy/.local/lib/python2.7/site-packages/sklearn/externals/joblib/parallel.py in dispatch_one_batch(self=Parallel(n_jobs=1), iterator=<generator object <genexpr>>)
    754                                  self._pickle_cache)
    755             if len(tasks) == 0:
    756                 # No more tasks available in the iterator: tell caller to stop.
    757                 return False
    758             else:
--> 759                 self._dispatch(tasks)
        self._dispatch = <bound method Parallel._dispatch of Parallel(n_jobs=1)>
        tasks = <sklearn.externals.joblib.parallel.BatchedCalls object>
    760                 return True
    761 
    762     def _print(self, msg, msg_args):
    763         """Display the message on stout or stderr depending on verbosity"""

...........................................................................
/home/aquemy/.local/lib/python2.7/site-packages/sklearn/externals/joblib/parallel.py in _dispatch(self=Parallel(n_jobs=1), batch=<sklearn.externals.joblib.parallel.BatchedCalls object>)
    711 
    712         dispatch_timestamp = time.time()
    713         cb = BatchCompletionCallBack(dispatch_timestamp, len(batch), self)
    714         with self._lock:
    715             job_idx = len(self._jobs)
--> 716             job = self._backend.apply_async(batch, callback=cb)
        job = undefined
        self._backend.apply_async = <bound method SequentialBackend.apply_async of <...lib._parallel_backends.SequentialBackend object>>
        batch = <sklearn.externals.joblib.parallel.BatchedCalls object>
        cb = <sklearn.externals.joblib.parallel.BatchCompletionCallBack object>
    717             # A job can complete so quickly than its callback is
    718             # called before we get here, causing self._jobs to
    719             # grow. To ensure correct results ordering, .insert is
    720             # used (rather than .append) in the following line

...........................................................................
/home/aquemy/.local/lib/python2.7/site-packages/sklearn/externals/joblib/_parallel_backends.py in apply_async(self=<sklearn.externals.joblib._parallel_backends.SequentialBackend object>, func=<sklearn.externals.joblib.parallel.BatchedCalls object>, callback=<sklearn.externals.joblib.parallel.BatchCompletionCallBack object>)
    177             raise ValueError('n_jobs == 0 in Parallel has no meaning')
    178         return 1
    179 
    180     def apply_async(self, func, callback=None):
    181         """Schedule a func to be run"""
--> 182         result = ImmediateResult(func)
        result = undefined
        func = <sklearn.externals.joblib.parallel.BatchedCalls object>
    183         if callback:
    184             callback(result)
    185         return result
    186 

...........................................................................
/home/aquemy/.local/lib/python2.7/site-packages/sklearn/externals/joblib/_parallel_backends.py in __init__(self=<sklearn.externals.joblib._parallel_backends.ImmediateResult object>, batch=<sklearn.externals.joblib.parallel.BatchedCalls object>)
    544 
    545 class ImmediateResult(object):
    546     def __init__(self, batch):
    547         # Don't delay the application, to avoid keeping the input
    548         # arguments in memory
--> 549         self.results = batch()
        self.results = undefined
        batch = <sklearn.externals.joblib.parallel.BatchedCalls object>
    550 
    551     def get(self):
    552         return self.results
    553 

...........................................................................
/home/aquemy/.local/lib/python2.7/site-packages/sklearn/externals/joblib/parallel.py in __call__(self=<sklearn.externals.joblib.parallel.BatchedCalls object>)
    220     def __call__(self):
    221         # Set the default nested backend to self._backend but do not set the
    222         # change the default number of processes to -1
    223         with parallel_backend(self._backend, n_jobs=self._n_jobs):
    224             return [func(*args, **kwargs)
--> 225                     for func, args, kwargs in self.items]
        func = <function _parallel_build_trees>
        args = (DecisionTreeClassifier(class_weight=None, criter...=False, random_state=1608637542, splitter='best'), RandomForestClassifier(bootstrap=True, class_wei...se, random_state=42, verbose=0, warm_start=False), array([[0.11864407, 0.125     ],
       [0.06779...
       [1.        , 0.9166667 ]], dtype=float32), array([[0.],
       [0.],
       [0.],
       [0...    [2.],
       [2.],
       [2.],
       [2.]]), None, 0, 50)
        kwargs = {'class_weight': None, 'verbose': 0}
        self.items = [(<function _parallel_build_trees>, (DecisionTreeClassifier(class_weight=None, criter...=False, random_state=1608637542, splitter='best'), RandomForestClassifier(bootstrap=True, class_wei...se, random_state=42, verbose=0, warm_start=False), array([[0.11864407, 0.125     ],
       [0.06779...
       [1.        , 0.9166667 ]], dtype=float32), array([[0.],
       [0.],
       [0.],
       [0...    [2.],
       [2.],
       [2.],
       [2.]]), None, 0, 50), {'class_weight': None, 'verbose': 0})]
    226 
    227     def __len__(self):
    228         return self._size
    229 

...........................................................................
/home/aquemy/.local/lib/python2.7/site-packages/sklearn/ensemble/forest.py in _parallel_build_trees(tree=DecisionTreeClassifier(class_weight=None, criter...=False, random_state=1608637542, splitter='best'), forest=RandomForestClassifier(bootstrap=True, class_wei...se, random_state=42, verbose=0, warm_start=False), X=array([[0.11864407, 0.125     ],
       [0.06779...
       [1.        , 0.9166667 ]], dtype=float32), y=array([[0.],
       [0.],
       [0.],
       [0...    [2.],
       [2.],
       [2.],
       [2.]]), sample_weight=None, tree_idx=0, n_trees=50, verbose=0, class_weight=None)
    114                 simplefilter('ignore', DeprecationWarning)
    115                 curr_sample_weight *= compute_sample_weight('auto', y, indices)
    116         elif class_weight == 'balanced_subsample':
    117             curr_sample_weight *= compute_sample_weight('balanced', y, indices)
    118 
--> 119         tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)
        tree.fit = <bound method DecisionTreeClassifier.fit of Deci...False, random_state=1608637542, splitter='best')>
        X = array([[0.11864407, 0.125     ],
       [0.06779...
       [1.        , 0.9166667 ]], dtype=float32)
        y = array([[0.],
       [0.],
       [0.],
       [0...    [2.],
       [2.],
       [2.],
       [2.]])
        sample_weight = None
        curr_sample_weight = array([3., 3., 0., 1., 1., 2., 2., 0., 1., 2., 0... 1., 0., 1., 0., 1., 1., 1., 1., 1., 1., 0., 0.])
    120     else:
    121         tree.fit(X, y, sample_weight=sample_weight, check_input=False)
    122 
    123     return tree

...........................................................................
/home/aquemy/.local/lib/python2.7/site-packages/sklearn/tree/tree.py in fit(self=DecisionTreeClassifier(class_weight=None, criter...=False, random_state=1608637542, splitter='best'), X=array([[0.11864407, 0.125     ],
       [0.06779...
       [1.        , 0.9166667 ]], dtype=float32), y=array([[0.],
       [0.],
       [0.],
       [0...    [2.],
       [2.],
       [2.],
       [2.]]), sample_weight=array([3., 3., 0., 1., 1., 2., 2., 0., 1., 2., 0... 1., 0., 1., 0., 1., 1., 1., 1., 1., 1., 0., 0.]), check_input=False, X_idx_sorted=None)
    796 
    797         super(DecisionTreeClassifier, self).fit(
    798             X, y,
    799             sample_weight=sample_weight,
    800             check_input=check_input,
--> 801             X_idx_sorted=X_idx_sorted)
        X_idx_sorted = None
    802         return self
    803 
    804     def predict_proba(self, X, check_input=True):
    805         """Predict class probabilities of the input samples X.

...........................................................................
/home/aquemy/.local/lib/python2.7/site-packages/sklearn/tree/tree.py in fit(self=DecisionTreeClassifier(class_weight=None, criter...=False, random_state=1608637542, splitter='best'), X=array([[0.11864407, 0.125     ],
       [0.06779...
       [1.        , 0.9166667 ]], dtype=float32), y=array([[0.],
       [0.],
       [0.],
       [0...    [2.],
       [2.],
       [2.],
       [2.]]), sample_weight=array([3., 3., 0., 1., 1., 2., 2., 0., 1., 2., 0... 1., 0., 1., 0., 1., 1., 1., 1., 1., 1., 0., 0.]), check_input=False, X_idx_sorted=None)
    237         if not 0 <= self.min_weight_fraction_leaf <= 0.5:
    238             raise ValueError("min_weight_fraction_leaf must in [0, 0.5]")
    239         if max_depth <= 0:
    240             raise ValueError("max_depth must be greater than zero. ")
    241         if not (0 < max_features <= self.n_features_):
--> 242             raise ValueError("max_features must be in (0, n_features]")
    243         if not isinstance(max_leaf_nodes, (numbers.Integral, np.integer)):
    244             raise ValueError("max_leaf_nodes must be integral number but was "
    245                              "%r" % max_leaf_nodes)
    246         if -1 < max_leaf_nodes < 2:

ValueError: max_features must be in (0, n_features]
___________________________________________________________________________
Best score: 0.966666666667 (0.0333333333333) [J] | Score: 0.0 (0.0) [J]
Best score: 0.966666666667 (0.0333333333333) [J] | Score: 0.92 (0.0718021974285) [J]
Best score: 0.966666666667 (0.0333333333333) [J] | Score: 0.473333333333 (0.0696020433927) [J]
Best score: 0.966666666667 (0.0333333333333) [J] | Score: 0.666666666667 (0.073029674334) [J]
Best score: 0.966666666667 (0.0333333333333) [J] | Score: 0.893333333333 (0.0679869268479) [J]
Best score: 0.966666666667 (0.0333333333333) [J] | Score: 0.94 (0.0553774924195) [J]
Best score: 0.966666666667 (0.0333333333333) [J] | Score: 0.526666666667 (0.0866666666667) [J]
Best score: 0.966666666667 (0.0333333333333) [J] | Score: 0.953333333333 (0.0426874949162) [J]
Best score: 0.966666666667 (0.0333333333333) [J] | Score: 0.906666666667 (0.0853749898324) [J]
JoblibValueError
___________________________________________________________________________
...........................................................................
/home/aquemy/dev/dp_hyperparameters/extension/main.py in <module>()
     27 
     28     serializer.serialize_results(scenario, policy)
     29 
     30 if __name__ == "__main__":
     31     args = cli.parse_args()
---> 32     main(args)

...........................................................................
/home/aquemy/dev/dp_hyperparameters/extension/main.py in main(args=Namespace(customize=[(['control', 'seed'], '42')...io='./scenarios/rf_iris_joint.yaml', verbosity=0))
     21         test_size=0.4, 
     22         random_state=scenario['control']['seed']
     23     )
     24 
     25     policy = policies.initiate(scenario['setup']['policy'], config)
---> 26     policy.run(X,y)
        policy.run = <bound method Joint.run of <experiment.policies.joint.Joint object>>
        X = array([[5.1, 3.5, 1.4, 0.2],
       [4.9, 3. , 1....2, 3.4, 5.4, 2.3],
       [5.9, 3. , 5.1, 1.8]])
        y = array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,... 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2])
     27 
     28     serializer.serialize_results(scenario, policy)
     29 
     30 if __name__ == "__main__":

...........................................................................
/home/aquemy/dev/dp_hyperparameters/extension/experiment/policies/joint.py in run(self=<experiment.policies.joint.Joint object>, X=array([[5.1, 3.5, 1.4, 0.2],
       [4.9, 3. , 1....2, 3.4, 5.4, 2.3],
       [5.9, 3. , 5.1, 1.8]]), y=array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,... 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]))
     32             algo=tpe.suggest, 
     33             max_evals=None,
     34             max_time=self.config['time'],     
     35             trials=trials,
     36             show_progressbar=False,
---> 37             verbose=0
     38         )
     39 
     40         best_config = self.context['best_config']
     41         super(Joint, self).display_step_results(best_config)

...........................................................................
/home/aquemy/dev/dp_hyperparameters/extension/hyperopt/fmin.py in fmin(fn=<functools.partial object>, space={'algorithm': {'bootstrap': <hyperopt.pyll.base.Apply object>, 'criterion': <hyperopt.pyll.base.Apply object>, 'max_depth': <hyperopt.pyll.base.Apply object>, 'max_features': <hyperopt.pyll.base.Apply object>, 'max_leaf_nodes': <hyperopt.pyll.base.Apply object>, 'min_samples_split': <hyperopt.pyll.base.Apply object>, 'n_estimators': <hyperopt.pyll.base.Apply object>}, 'pipeline': {'features': <hyperopt.pyll.base.Apply object>, 'normalizer': <hyperopt.pyll.base.Apply object>, 'rebalance': <hyperopt.pyll.base.Apply object>}}, algo=<function suggest>, max_evals=9223372036854775807, max_time=300, trials=<hyperopt.base.Trials object>, rstate=<mtrand.RandomState object>, allow_trials_fmin=True, pass_expr_memo_ctrl=None, catch_eval_exceptions=False, verbose=0, return_argmin=True, points_to_evaluate=None, max_queue_len=1, show_progressbar=False)
    406             pass_expr_memo_ctrl=pass_expr_memo_ctrl,
    407             verbose=verbose,
    408             catch_eval_exceptions=catch_eval_exceptions,
    409             return_argmin=return_argmin,
    410             show_progressbar=show_progressbar,
--> 411             max_time=max_time
        max_time = 300
    412         )
    413 
    414     if trials is None:
    415         if points_to_evaluate is None:

...........................................................................
/home/aquemy/dev/dp_hyperparameters/extension/hyperopt/base.py in fmin(self=<hyperopt.base.Trials object>, fn=<functools.partial object>, space={'algorithm': {'bootstrap': <hyperopt.pyll.base.Apply object>, 'criterion': <hyperopt.pyll.base.Apply object>, 'max_depth': <hyperopt.pyll.base.Apply object>, 'max_features': <hyperopt.pyll.base.Apply object>, 'max_leaf_nodes': <hyperopt.pyll.base.Apply object>, 'min_samples_split': <hyperopt.pyll.base.Apply object>, 'n_estimators': <hyperopt.pyll.base.Apply object>}, 'pipeline': {'features': <hyperopt.pyll.base.Apply object>, 'normalizer': <hyperopt.pyll.base.Apply object>, 'rebalance': <hyperopt.pyll.base.Apply object>}}, algo=<function suggest>, max_evals=9223372036854775807, max_time=300, rstate=<mtrand.RandomState object>, verbose=0, pass_expr_memo_ctrl=None, catch_eval_exceptions=False, return_argmin=True, show_progressbar=False)
    636             verbose=verbose,
    637             allow_trials_fmin=False,  # -- prevent recursion
    638             pass_expr_memo_ctrl=pass_expr_memo_ctrl,
    639             catch_eval_exceptions=catch_eval_exceptions,
    640             return_argmin=return_argmin,
--> 641             show_progressbar=show_progressbar)
        show_progressbar = False
    642 
    643 
    644 def trials_from_docs(docs, validate=True, **kwargs):
    645     """Construct a Trials base class instance from a list of trials documents

...........................................................................
/home/aquemy/dev/dp_hyperparameters/extension/hyperopt/fmin.py in fmin(fn=<functools.partial object>, space={'algorithm': {'bootstrap': <hyperopt.pyll.base.Apply object>, 'criterion': <hyperopt.pyll.base.Apply object>, 'max_depth': <hyperopt.pyll.base.Apply object>, 'max_features': <hyperopt.pyll.base.Apply object>, 'max_leaf_nodes': <hyperopt.pyll.base.Apply object>, 'min_samples_split': <hyperopt.pyll.base.Apply object>, 'n_estimators': <hyperopt.pyll.base.Apply object>}, 'pipeline': {'features': <hyperopt.pyll.base.Apply object>, 'normalizer': <hyperopt.pyll.base.Apply object>, 'rebalance': <hyperopt.pyll.base.Apply object>}}, algo=<function suggest>, max_evals=9223372036854775807, max_time=300, trials=<hyperopt.base.Trials object>, rstate=<mtrand.RandomState object>, allow_trials_fmin=False, pass_expr_memo_ctrl=None, catch_eval_exceptions=False, verbose=0, return_argmin=True, points_to_evaluate=None, max_queue_len=1, show_progressbar=False)
    426                     verbose=verbose,
    427                     max_queue_len=max_queue_len,
    428                     show_progressbar=show_progressbar,
    429                     max_time=max_time)
    430     rval.catch_eval_exceptions = catch_eval_exceptions
--> 431     rval.exhaust()
        rval.exhaust = <bound method FMinIter.exhaust of <hyperopt.fmin.FMinIter object>>
    432     if return_argmin:
    433         return trials.argmin
    434     elif len(trials) > 0:
    435         # Only if there are some succesfull trail runs, return the best point in the evaluation space

...........................................................................
/home/aquemy/dev/dp_hyperparameters/extension/hyperopt/fmin.py in exhaust(self=<hyperopt.fmin.FMinIter object>)
    273             raise StopIteration()
    274         return self.trials
    275 
    276     def exhaust(self):
    277         n_done = len(self.trials)
--> 278         self.run(self.max_evals - n_done, block_until_done=self.asynchronous)
        self.run = <bound method FMinIter.run of <hyperopt.fmin.FMinIter object>>
        self.max_evals = 9223372036854775807
        n_done = 0
        self.asynchronous = False
    279         self.trials.refresh()
    280         return self
    281 
    282 

...........................................................................
/home/aquemy/dev/dp_hyperparameters/extension/hyperopt/fmin.py in run(self=<hyperopt.fmin.FMinIter object>, N=9223372036854775807, block_until_done=False)
    232                     if self.asynchronous:
    233                         # -- wait for workers to fill in the trials
    234                         time.sleep(self.poll_interval_secs)
    235                     else:
    236                         # -- loop over trials and do the jobs directly
--> 237                         self.serial_evaluate()
        self.serial_evaluate = <bound method FMinIter.serial_evaluate of <hyperopt.fmin.FMinIter object>>
    238                     try:
    239                         res = [d['result']['loss'] for d in
    240                                          self.trials.trials if
    241                                          d['result']['status'] == 'ok']

...........................................................................
/home/aquemy/dev/dp_hyperparameters/extension/hyperopt/fmin.py in serial_evaluate(self=<hyperopt.fmin.FMinIter object>, N=-1)
    138                 trial['book_time'] = now
    139                 trial['refresh_time'] = now
    140                 spec = base.spec_from_misc(trial['misc'])
    141                 ctrl = base.Ctrl(self.trials, current_trial=trial)
    142                 try:
--> 143                     result = self.domain.evaluate(spec, ctrl)
        result = undefined
        self.domain.evaluate = <bound method Domain.evaluate of <hyperopt.base.Domain object>>
        spec = {'bootstrap': 0, 'criterion': 0, 'features': 1, 'features_PCA_features__n_components': 1, 'max_depth': 1, 'max_features': 2, 'max_leaf_nodes': 1, 'min_samples_split': 2, 'n_estimators': 0, 'normalizer': 1, ...}
        ctrl = <hyperopt.base.Ctrl object>
    144                 except Exception as e:
    145                     logger.info('job exception: %s' % str(e))
    146                     trial['state'] = base.JOB_STATE_ERROR
    147                     trial['misc']['error'] = (str(type(e)), str(e))

...........................................................................
/home/aquemy/dev/dp_hyperparameters/extension/hyperopt/base.py in evaluate(self=<hyperopt.base.Domain object>, config={'bootstrap': 0, 'criterion': 0, 'features': 1, 'features_PCA_features__n_components': 1, 'max_depth': 1, 'max_features': 2, 'max_leaf_nodes': 1, 'min_samples_split': 2, 'n_estimators': 0, 'normalizer': 1, ...}, ctrl=<hyperopt.base.Ctrl object>, attach_attachments=True)
    841             #    or the normal Python part (self.fn)
    842             pyll_rval = pyll.rec_eval(
    843                 self.expr,
    844                 memo=memo,
    845                 print_node_on_error=self.rec_eval_print_node_on_error)
--> 846             rval = self.fn(pyll_rval)
        rval = undefined
        self.fn = <functools.partial object>
        pyll_rval = {'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': 2, 'max_features': 3, 'max_leaf_nodes': 3, 'min_samples_split': 5, 'n_estimators': 10}, 'pipeline': {'features': ('features_PCA', {'features__n_components': 2}), 'normalizer': ('normalizer_StandardScaler', {'normalizer__with_mean': True, 'normalizer__with_std': True}), 'rebalance': ('rebalance_NearMiss', {'rebalance__n_neighbors': 1})}}
    847 
    848         if isinstance(rval, (float, int, np.number)):
    849             dict_rval = {'loss': float(rval), 'status': STATUS_OK}
    850         else:

...........................................................................
/home/aquemy/dev/dp_hyperparameters/extension/experiment/objective.py in objective_joint(wconfig={'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': 2, 'max_features': 3, 'max_leaf_nodes': 3, 'min_samples_split': 5, 'n_estimators': 10}, 'pipeline': {'features': ('features_PCA', {'features__n_components': 2}), 'normalizer': ('normalizer_StandardScaler', {'normalizer__with_mean': True, 'normalizer__with_std': True}), 'rebalance': ('rebalance_NearMiss', {'rebalance__n_neighbors': 1})}}, algorithm='RandomForest', X=array([[5.1, 3.5, 1.4, 0.2],
       [4.9, 3. , 1....2, 3.4, 5.4, 2.3],
       [5.9, 3. , 5.1, 1.8]]), y=array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,... 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]), context={'baseline_score': 0.9466666666666667, 'baseline_score_std': 0.04988876515698587, 'best_config': {'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': 4, 'max_features': 3, 'max_leaf_nodes': 3, 'min_samples_split': 3, 'n_estimators': 10}, 'config_hash': {'algorithm': 'ffb7ff225ce3d3712c96cf87fe42202988ee2eb0', 'config': 'bae32f426be9cd6243523c023944a8c148fe4aeb', 'pipeline': 'd2a68bfda6fcdec4ae0ffc7d7b6a2122bc1cd673'}, 'duration': 0.7115809917449951, 'iteration': 113, 'loss': 0.033333333333333215, 'max_history_score': 0.9666666666666668, 'max_history_score_std': 0.033333333333333326, 'max_history_step': 'joint', 'pipeline': {'features': ('features_NoneType', {}), 'normalizer': ('normalizer_PowerTransformer', {}), 'rebalance': ('rebalance_CondensedNearestNeighbour', {'rebalance__n_neighbors': 2})}, 'score': 0.9666666666666668, ...}, 'history': [{'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': 2, 'max_features': None, 'max_leaf_nodes': 5, 'min_samples_split': 2, 'n_estimators': 75}, 'config_hash': {'algorithm': '3af5b0cce71c8fe2545246ca24ff5bc3dd516e06', 'config': 'db6ac7e6d348155757e4794bb5f88fe2b4f63d50', 'pipeline': '8d59f4b94cef6be9306ed86a22a9570fa670d567'}, 'duration': 1.149928092956543, 'iteration': 0, 'loss': 0.046666666666666634, 'max_history_score': 0.9533333333333334, 'max_history_score_std': 0.059999999999999984, 'max_history_step': 'joint', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 4, 'features__selectkbest__k': 3}), 'normalizer': ('normalizer_StandardScaler', {'normalizer__with_mean': True, 'normalizer__with_std': True}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 6})}, 'score': 0.9533333333333334, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': 1, 'max_features': 2, 'max_leaf_nodes': 2, 'min_samples_split': 5, 'n_estimators': 100}, 'config_hash': {'algorithm': 'e13eb05fd9a62d2f63bbb1c1deff0cd620d5e6ab', 'config': '4db6fb84d85f52659f780e682ffac5712c3d8a94', 'pipeline': '64c9a1ca9d53ae67244bdd942f4db36a3c05218c'}, 'duration': 1.7678282260894775, 'iteration': 1, 'loss': 0.18000000000000005, 'max_history_score': 0.9533333333333334, 'max_history_score_std': 0.059999999999999984, 'max_history_step': 'joint', 'pipeline': {'features': ('features_NoneType', {}), 'normalizer': ('normalizer_PowerTransformer', {}), 'rebalance': ('rebalance_NearMiss', {'rebalance__n_neighbors': 1})}, 'score': 0.82, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': 1, 'max_features': None, 'max_leaf_nodes': None, 'min_samples_split': 5, 'n_estimators': 75}, 'config_hash': {'algorithm': '94b0d7a654c508cc63643f78fe4f0f07e6f07c1e', 'config': '4403c5a85e951938d3c454e961d3a412780722f6', 'pipeline': '3e47444880d8367fbac2faaba2e52a917274aa58'}, 'duration': 0.8397619724273682, 'iteration': 2, 'loss': 0.03333333333333344, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_PCA', {'features__n_components': 3}), 'normalizer': ('normalizer_MinMaxScaler', {}), 'rebalance': ('rebalance_NoneType', {})}, 'score': 0.9666666666666666, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': None, 'max_features': None, 'max_leaf_nodes': 3, 'min_samples_split': 3, 'n_estimators': 75}, 'config_hash': {'algorithm': 'e8332f0a8902bda03bf70e7978cc5d52affb29d3', 'config': 'a064e2df18ab98d44dabcefbc7bed94913f1d0be', 'pipeline': '7eea819c2a8c103c4b1e9e9c1e224aebba95081f'}, 'duration': 0.8501448631286621, 'iteration': 3, 'loss': 0.053333333333333344, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 2, 'features__selectkbest__k': 4}), 'normalizer': ('normalizer_NoneType', {}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 7})}, 'score': 0.9466666666666667, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'entropy', 'max_depth': 3, 'max_features': 3, 'max_leaf_nodes': None, 'min_samples_split': 5, 'n_estimators': 75}, 'config_hash': {'algorithm': '7a4491035bc6bd737fe9a8cda8a79a02d02d5c74', 'config': '0ddb6f5cab3db4dddd7682966a57205f3e329ad4', 'pipeline': 'a9ae03fe38334f6868cbf84cdd3d629d4bbe3fb0'}, 'duration': 1.1026010513305664, 'iteration': 4, 'loss': 0.05999999999999994, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 2, 'features__selectkbest__k': 1}), 'normalizer': ('normalizer_NoneType', {}), 'rebalance': ('rebalance_NoneType', {})}, 'score': 0.9400000000000001, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'gini', 'max_depth': 3, 'max_features': 1, 'max_leaf_nodes': 5, 'min_samples_split': 2, 'n_estimators': 25}, 'config_hash': {'algorithm': '9826d20b2d6a0f559cf7f16450ce7526f07e8434', 'config': '49f25751bca61cdd461a8cbd2923689b642f98ed', 'pipeline': '19b249664c5bf067de1fed4334a296f947ce774a'}, 'duration': 0.35647010803222656, 'iteration': 5, 'loss': 0.046666666666666634, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_NoneType', {}), 'normalizer': ('normalizer_NoneType', {}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 6})}, 'score': 0.9533333333333334, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'gini', 'max_depth': 2, 'max_features': 1, 'max_leaf_nodes': 2, 'min_samples_split': 2, 'n_estimators': 50}, 'config_hash': {'algorithm': '0a4f6fbb07e0f32c6f675489a0fc82eee05bd8e1', 'config': '5c3a2b6f5e63fb45f10e41e0318b354912ec44f6', 'pipeline': 'dc3b9f176f090005e38b142f11d80e93a7dc5d5e'}, 'duration': 0.7213859558105469, 'iteration': 6, 'loss': 0.31333333333333324, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 1, 'features__selectkbest__k': 4}), 'normalizer': ('normalizer_PowerTransformer', {}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 7})}, 'score': 0.6866666666666668, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'entropy', 'max_depth': 4, 'max_features': 3, 'max_leaf_nodes': 5, 'min_samples_split': 5, 'n_estimators': 10}, 'config_hash': {'algorithm': 'b8112b97ecfc10f00a195af661dcc861cac21289', 'config': 'd3b129b397350f1b6572651c67c01de49b4b174c', 'pipeline': '5b0357ed7072c37b3d6f458bb5d49ff7d825f603'}, 'duration': 0.8299109935760498, 'iteration': 7, 'loss': 1.0, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_PCA', {'features__n_components': 2}), 'normalizer': ('normalizer_StandardScaler', {'normalizer__with_mean': True, 'normalizer__with_std': False}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 6})}, 'score': 0.0, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'gini', 'max_depth': 4, 'max_features': None, 'max_leaf_nodes': 2, 'min_samples_split': 5, 'n_estimators': 100}, 'config_hash': {'algorithm': '40ca24df19b8d164d9d098a6bed1ce056fbbb961', 'config': '813bde1108cc3c4b9bfb3a22cbb421bda7eac671', 'pipeline': '74a7b8705a1c22f7dea5e44e4ebda8f1e48add71'}, 'duration': 2.2111589908599854, 'iteration': 8, 'loss': 0.33333333333333326, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_PCA', {'features__n_components': 2}), 'normalizer': ('normalizer_StandardScaler', {'normalizer__with_mean': False, 'normalizer__with_std': True}), 'rebalance': ('rebalance_NearMiss', {'rebalance__n_neighbors': 2})}, 'score': 0.6666666666666667, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'entropy', 'max_depth': 2, 'max_features': 1, 'max_leaf_nodes': 5, 'min_samples_split': 2, 'n_estimators': 100}, 'config_hash': {'algorithm': '331418a5c12cf1453876eef85e9d98fc8e54fa11', 'config': '31930b6860ed406d59bf7e59ba1925d94704bd3b', 'pipeline': '054bef356f90ec6f644ef3ffc688766744db51c2'}, 'duration': 1.0501940250396729, 'iteration': 9, 'loss': 0.053333333333333344, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_SelectKBest', {'features__k': 1}), 'normalizer': ('normalizer_RobustScaler', {'normalizer__quantile_range': (...), 'normalizer__with_centering': True, 'normalizer__with_scaling': True}), 'rebalance': ('rebalance_NearMiss', {'rebalance__n_neighbors': 2})}, 'score': 0.9466666666666667, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'entropy', 'max_depth': 3, 'max_features': None, 'max_leaf_nodes': 3, 'min_samples_split': 2, 'n_estimators': 100}, 'config_hash': {'algorithm': 'dbc1b8126649fe93dce5fbb37e4015b0acfb179e', 'config': '9913cd550615a9d0946ab4a755a8b9f619e442fd', 'pipeline': 'dd626121cea079ebb32e184ca65483ec7a6d7f59'}, 'duration': 1.120617151260376, 'iteration': 10, 'loss': 0.046666666666666634, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 2, 'features__selectkbest__k': 1}), 'normalizer': ('normalizer_MinMaxScaler', {}), 'rebalance': ('rebalance_NoneType', {})}, 'score': 0.9533333333333334, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'gini', 'max_depth': 3, 'max_features': 3, 'max_leaf_nodes': None, 'min_samples_split': 3, 'n_estimators': 75}, 'config_hash': {'algorithm': '34917a130df5a975f78bd7ec1a0c7b1ffdc787a9', 'config': '95fc8cadc088141290b7de9c388977e4685f0108', 'pipeline': '550d10faf2f08db48516cc3501558816d6a99bc0'}, 'duration': 1.4287099838256836, 'iteration': 11, 'loss': 0.19333333333333313, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 3, 'features__selectkbest__k': 4}), 'normalizer': ('normalizer_StandardScaler', {'normalizer__with_mean': False, 'normalizer__with_std': False}), 'rebalance': ('rebalance_CondensedNearestNeighbour', {'rebalance__n_neighbors': 1})}, 'score': 0.8066666666666669, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'entropy', 'max_depth': 1, 'max_features': 2, 'max_leaf_nodes': 5, 'min_samples_split': 2, 'n_estimators': 75}, 'config_hash': {'algorithm': '33f9abb4aee44a395a9f3b3ffa9ce80a8cdaed7c', 'config': '40fa726f0360cf6af55f9b5902d399d02f61f157', 'pipeline': 'cfd1d20841fe2153da762c95e79f95a3fb1e426a'}, 'duration': 1.2978079319000244, 'iteration': 12, 'loss': 0.053333333333333344, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_PCA', {'features__n_components': 4}), 'normalizer': ('normalizer_MinMaxScaler', {}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 7})}, 'score': 0.9466666666666667, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'entropy', 'max_depth': 4, 'max_features': 2, 'max_leaf_nodes': 5, 'min_samples_split': 3, 'n_estimators': 25}, 'config_hash': {'algorithm': '210111ec6562d09eb093e98ed69ef1c662e11a50', 'config': '0fb8e77c7bd9a58b72f1b33c21a59a09a8c676ba', 'pipeline': '5d269d759e0c7926a685a14b263ace8ae0071e4b'}, 'duration': 0.36649012565612793, 'iteration': 13, 'loss': 0.040000000000000036, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 2, 'features__selectkbest__k': 2}), 'normalizer': ('normalizer_NoneType', {}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 7})}, 'score': 0.96, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'entropy', 'max_depth': 3, 'max_features': 1, 'max_leaf_nodes': 5, 'min_samples_split': 2, 'n_estimators': 25}, 'config_hash': {'algorithm': '0e989a03980101fabf79eda3326ed2870e11d690', 'config': 'f4bffd5d8c67a9c5321a9943c4a99678f59a02b7', 'pipeline': '865ee1e3fe8334c3d5ecb2038d5a5d1b3ba50e75'}, 'duration': 0.35639500617980957, 'iteration': 14, 'loss': 0.046666666666666634, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_NoneType', {}), 'normalizer': ('normalizer_RobustScaler', {'normalizer__quantile_range': (...), 'normalizer__with_centering': True, 'normalizer__with_scaling': False}), 'rebalance': ('rebalance_NoneType', {})}, 'score': 0.9533333333333334, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'entropy', 'max_depth': None, 'max_features': 3, 'max_leaf_nodes': 3, 'min_samples_split': 5, 'n_estimators': 10}, 'config_hash': {'algorithm': '9c592e876c13de5e23e6de5b868e01755d63e72e', 'config': '1e6a68cd1eeac886d90724d78b1cb5fb76a3cde4', 'pipeline': '5a1ca4d82f21b7de0d2c918630a42510673fa36e'}, 'duration': 0.18141412734985352, 'iteration': 15, 'loss': 0.046666666666666634, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_SelectKBest', {'features__k': 3}), 'normalizer': ('normalizer_RobustScaler', {'normalizer__quantile_range': (...), 'normalizer__with_centering': True, 'normalizer__with_scaling': True}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 6})}, 'score': 0.9533333333333334, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': 1, 'max_features': None, 'max_leaf_nodes': None, 'min_samples_split': 5, 'n_estimators': 10}, 'config_hash': {'algorithm': '8bed77aef289bfd453b2858bd288ae5ba7160f2b', 'config': '781185bcb8999045de8d489f253a1a1ba4247932', 'pipeline': '1ece7eabedc2be9e5b0a1be65c570d08ffa3eb54'}, 'duration': 0.1636829376220703, 'iteration': 16, 'loss': 0.053333333333333344, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_NoneType', {}), 'normalizer': ('normalizer_NoneType', {}), 'rebalance': ('rebalance_NearMiss', {'rebalance__n_neighbors': 1})}, 'score': 0.9466666666666667, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'gini', 'max_depth': 3, 'max_features': 2, 'max_leaf_nodes': 2, 'min_samples_split': 5, 'n_estimators': 75}, 'config_hash': {'algorithm': '617b97d9ba21d3373bc51ffa9cccf9c6f91a77b3', 'config': '99fb425b4e8c5d80228cab94202252aa25cdf77c', 'pipeline': 'd6242929c3b515c7719e60423023ac604311afc3'}, 'duration': 0.8468999862670898, 'iteration': 17, 'loss': 0.24, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_PCA', {'features__n_components': 4}), 'normalizer': ('normalizer_PowerTransformer', {}), 'rebalance': ('rebalance_NearMiss', {'rebalance__n_neighbors': 2})}, 'score': 0.76, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': 1, 'max_features': 1, 'max_leaf_nodes': 2, 'min_samples_split': 5, 'n_estimators': 50}, 'config_hash': {'algorithm': 'b92d2697cdd4979da443369d6596229ec091626a', 'config': 'c513a3e13281206ad76187dd817b1fff93d54fe1', 'pipeline': 'c4b4f914a3ca8df967cade997a90366d85a371b9'}, 'duration': 0.6724588871002197, 'iteration': 18, 'loss': 0.23333333333333328, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 1, 'features__selectkbest__k': 3}), 'normalizer': ('normalizer_StandardScaler', {'normalizer__with_mean': True, 'normalizer__with_std': True}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 5})}, 'score': 0.7666666666666667, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'entropy', 'max_depth': None, 'max_features': None, 'max_leaf_nodes': 5, 'min_samples_split': 5, 'n_estimators': 10}, 'config_hash': {'algorithm': 'a0115de695e6cca2e81cbfb54df79bf4b43608b1', 'config': 'ba194015e20b5d67770e8c67342c3d8d0d01dc41', 'pipeline': '8d45fabfeb85ffdcabf7076bd0e65fffe97ce928'}, 'duration': 0.19424200057983398, 'iteration': 19, 'loss': 0.08666666666666667, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_PCA', {'features__n_components': 3}), 'normalizer': ('normalizer_NoneType', {}), 'rebalance': ('rebalance_NoneType', {})}, 'score': 0.9133333333333333, ...}, ...], 'history_hash': ['db6ac7e6d348155757e4794bb5f88fe2b4f63d50', '4db6fb84d85f52659f780e682ffac5712c3d8a94', '4403c5a85e951938d3c454e961d3a412780722f6', 'a064e2df18ab98d44dabcefbc7bed94913f1d0be', '0ddb6f5cab3db4dddd7682966a57205f3e329ad4', '49f25751bca61cdd461a8cbd2923689b642f98ed', '5c3a2b6f5e63fb45f10e41e0318b354912ec44f6', 'd3b129b397350f1b6572651c67c01de49b4b174c', '813bde1108cc3c4b9bfb3a22cbb421bda7eac671', '31930b6860ed406d59bf7e59ba1925d94704bd3b', '9913cd550615a9d0946ab4a755a8b9f619e442fd', '95fc8cadc088141290b7de9c388977e4685f0108', '40fa726f0360cf6af55f9b5902d399d02f61f157', '0fb8e77c7bd9a58b72f1b33c21a59a09a8c676ba', 'f4bffd5d8c67a9c5321a9943c4a99678f59a02b7', '1e6a68cd1eeac886d90724d78b1cb5fb76a3cde4', '781185bcb8999045de8d489f253a1a1ba4247932', '99fb425b4e8c5d80228cab94202252aa25cdf77c', 'c513a3e13281206ad76187dd817b1fff93d54fe1', 'ba194015e20b5d67770e8c67342c3d8d0d01dc41', ...], 'history_index': {'00f0493590a2cb5e98a35b29816f8cd9f87f96ec': 208, '01161dcc5f8ee022f65481dacf76468db745b463': 306, '013329309d510b94f19d930320402d65f953a847': 39, '038a0f515e2ec894ee8e34f9caa2889eb3ebd5ce': 66, '052ae4bf232b316187b078abae42c2be19e16a00': 111, '05e9258ebf99dd97202167ef1563fa834b0568f1': 242, '0659afebf316aafeb75612fb07081a04c28545ed': 74, '06e7cde9f3556cd01332ce389ad1d8925cd4b4a4': 120, '07ab8a30d853e39a326b7017026a20e94bc45541': 245, '0855e6ed1503da05dc544450a5da27e4b3441758': 307, ...}, 'iteration': 346, 'max_history_score': 0.9666666666666668, 'max_history_score_std': 0.033333333333333326, 'max_history_step': 'joint'}, config={'algorithm': 'RandomForest', 'seed': 42, 'time': 300})
    108 
    109 def objective_algo(algo_config, current_pipeline_config, algorithm, X, y, context, config):
    110     return objective(current_pipeline_config, algo_config, algorithm, X, y, context, config, step='algorithm')
    111 
    112 def objective_joint(wconfig, algorithm, X, y, context, config):
--> 113     return objective(wconfig['pipeline'], wconfig['algorithm'], algorithm, X, y, context, config, step='joint')
        wconfig = {'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': 2, 'max_features': 3, 'max_leaf_nodes': 3, 'min_samples_split': 5, 'n_estimators': 10}, 'pipeline': {'features': ('features_PCA', {'features__n_components': 2}), 'normalizer': ('normalizer_StandardScaler', {'normalizer__with_mean': True, 'normalizer__with_std': True}), 'rebalance': ('rebalance_NearMiss', {'rebalance__n_neighbors': 1})}}
        algorithm = 'RandomForest'
        X = array([[5.1, 3.5, 1.4, 0.2],
       [4.9, 3. , 1....2, 3.4, 5.4, 2.3],
       [5.9, 3. , 5.1, 1.8]])
        y = array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,... 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2])
        context = {'baseline_score': 0.9466666666666667, 'baseline_score_std': 0.04988876515698587, 'best_config': {'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': 4, 'max_features': 3, 'max_leaf_nodes': 3, 'min_samples_split': 3, 'n_estimators': 10}, 'config_hash': {'algorithm': 'ffb7ff225ce3d3712c96cf87fe42202988ee2eb0', 'config': 'bae32f426be9cd6243523c023944a8c148fe4aeb', 'pipeline': 'd2a68bfda6fcdec4ae0ffc7d7b6a2122bc1cd673'}, 'duration': 0.7115809917449951, 'iteration': 113, 'loss': 0.033333333333333215, 'max_history_score': 0.9666666666666668, 'max_history_score_std': 0.033333333333333326, 'max_history_step': 'joint', 'pipeline': {'features': ('features_NoneType', {}), 'normalizer': ('normalizer_PowerTransformer', {}), 'rebalance': ('rebalance_CondensedNearestNeighbour', {'rebalance__n_neighbors': 2})}, 'score': 0.9666666666666668, ...}, 'history': [{'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': 2, 'max_features': None, 'max_leaf_nodes': 5, 'min_samples_split': 2, 'n_estimators': 75}, 'config_hash': {'algorithm': '3af5b0cce71c8fe2545246ca24ff5bc3dd516e06', 'config': 'db6ac7e6d348155757e4794bb5f88fe2b4f63d50', 'pipeline': '8d59f4b94cef6be9306ed86a22a9570fa670d567'}, 'duration': 1.149928092956543, 'iteration': 0, 'loss': 0.046666666666666634, 'max_history_score': 0.9533333333333334, 'max_history_score_std': 0.059999999999999984, 'max_history_step': 'joint', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 4, 'features__selectkbest__k': 3}), 'normalizer': ('normalizer_StandardScaler', {'normalizer__with_mean': True, 'normalizer__with_std': True}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 6})}, 'score': 0.9533333333333334, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': 1, 'max_features': 2, 'max_leaf_nodes': 2, 'min_samples_split': 5, 'n_estimators': 100}, 'config_hash': {'algorithm': 'e13eb05fd9a62d2f63bbb1c1deff0cd620d5e6ab', 'config': '4db6fb84d85f52659f780e682ffac5712c3d8a94', 'pipeline': '64c9a1ca9d53ae67244bdd942f4db36a3c05218c'}, 'duration': 1.7678282260894775, 'iteration': 1, 'loss': 0.18000000000000005, 'max_history_score': 0.9533333333333334, 'max_history_score_std': 0.059999999999999984, 'max_history_step': 'joint', 'pipeline': {'features': ('features_NoneType', {}), 'normalizer': ('normalizer_PowerTransformer', {}), 'rebalance': ('rebalance_NearMiss', {'rebalance__n_neighbors': 1})}, 'score': 0.82, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': 1, 'max_features': None, 'max_leaf_nodes': None, 'min_samples_split': 5, 'n_estimators': 75}, 'config_hash': {'algorithm': '94b0d7a654c508cc63643f78fe4f0f07e6f07c1e', 'config': '4403c5a85e951938d3c454e961d3a412780722f6', 'pipeline': '3e47444880d8367fbac2faaba2e52a917274aa58'}, 'duration': 0.8397619724273682, 'iteration': 2, 'loss': 0.03333333333333344, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_PCA', {'features__n_components': 3}), 'normalizer': ('normalizer_MinMaxScaler', {}), 'rebalance': ('rebalance_NoneType', {})}, 'score': 0.9666666666666666, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': None, 'max_features': None, 'max_leaf_nodes': 3, 'min_samples_split': 3, 'n_estimators': 75}, 'config_hash': {'algorithm': 'e8332f0a8902bda03bf70e7978cc5d52affb29d3', 'config': 'a064e2df18ab98d44dabcefbc7bed94913f1d0be', 'pipeline': '7eea819c2a8c103c4b1e9e9c1e224aebba95081f'}, 'duration': 0.8501448631286621, 'iteration': 3, 'loss': 0.053333333333333344, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 2, 'features__selectkbest__k': 4}), 'normalizer': ('normalizer_NoneType', {}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 7})}, 'score': 0.9466666666666667, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'entropy', 'max_depth': 3, 'max_features': 3, 'max_leaf_nodes': None, 'min_samples_split': 5, 'n_estimators': 75}, 'config_hash': {'algorithm': '7a4491035bc6bd737fe9a8cda8a79a02d02d5c74', 'config': '0ddb6f5cab3db4dddd7682966a57205f3e329ad4', 'pipeline': 'a9ae03fe38334f6868cbf84cdd3d629d4bbe3fb0'}, 'duration': 1.1026010513305664, 'iteration': 4, 'loss': 0.05999999999999994, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 2, 'features__selectkbest__k': 1}), 'normalizer': ('normalizer_NoneType', {}), 'rebalance': ('rebalance_NoneType', {})}, 'score': 0.9400000000000001, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'gini', 'max_depth': 3, 'max_features': 1, 'max_leaf_nodes': 5, 'min_samples_split': 2, 'n_estimators': 25}, 'config_hash': {'algorithm': '9826d20b2d6a0f559cf7f16450ce7526f07e8434', 'config': '49f25751bca61cdd461a8cbd2923689b642f98ed', 'pipeline': '19b249664c5bf067de1fed4334a296f947ce774a'}, 'duration': 0.35647010803222656, 'iteration': 5, 'loss': 0.046666666666666634, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_NoneType', {}), 'normalizer': ('normalizer_NoneType', {}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 6})}, 'score': 0.9533333333333334, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'gini', 'max_depth': 2, 'max_features': 1, 'max_leaf_nodes': 2, 'min_samples_split': 2, 'n_estimators': 50}, 'config_hash': {'algorithm': '0a4f6fbb07e0f32c6f675489a0fc82eee05bd8e1', 'config': '5c3a2b6f5e63fb45f10e41e0318b354912ec44f6', 'pipeline': 'dc3b9f176f090005e38b142f11d80e93a7dc5d5e'}, 'duration': 0.7213859558105469, 'iteration': 6, 'loss': 0.31333333333333324, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 1, 'features__selectkbest__k': 4}), 'normalizer': ('normalizer_PowerTransformer', {}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 7})}, 'score': 0.6866666666666668, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'entropy', 'max_depth': 4, 'max_features': 3, 'max_leaf_nodes': 5, 'min_samples_split': 5, 'n_estimators': 10}, 'config_hash': {'algorithm': 'b8112b97ecfc10f00a195af661dcc861cac21289', 'config': 'd3b129b397350f1b6572651c67c01de49b4b174c', 'pipeline': '5b0357ed7072c37b3d6f458bb5d49ff7d825f603'}, 'duration': 0.8299109935760498, 'iteration': 7, 'loss': 1.0, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_PCA', {'features__n_components': 2}), 'normalizer': ('normalizer_StandardScaler', {'normalizer__with_mean': True, 'normalizer__with_std': False}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 6})}, 'score': 0.0, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'gini', 'max_depth': 4, 'max_features': None, 'max_leaf_nodes': 2, 'min_samples_split': 5, 'n_estimators': 100}, 'config_hash': {'algorithm': '40ca24df19b8d164d9d098a6bed1ce056fbbb961', 'config': '813bde1108cc3c4b9bfb3a22cbb421bda7eac671', 'pipeline': '74a7b8705a1c22f7dea5e44e4ebda8f1e48add71'}, 'duration': 2.2111589908599854, 'iteration': 8, 'loss': 0.33333333333333326, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_PCA', {'features__n_components': 2}), 'normalizer': ('normalizer_StandardScaler', {'normalizer__with_mean': False, 'normalizer__with_std': True}), 'rebalance': ('rebalance_NearMiss', {'rebalance__n_neighbors': 2})}, 'score': 0.6666666666666667, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'entropy', 'max_depth': 2, 'max_features': 1, 'max_leaf_nodes': 5, 'min_samples_split': 2, 'n_estimators': 100}, 'config_hash': {'algorithm': '331418a5c12cf1453876eef85e9d98fc8e54fa11', 'config': '31930b6860ed406d59bf7e59ba1925d94704bd3b', 'pipeline': '054bef356f90ec6f644ef3ffc688766744db51c2'}, 'duration': 1.0501940250396729, 'iteration': 9, 'loss': 0.053333333333333344, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_SelectKBest', {'features__k': 1}), 'normalizer': ('normalizer_RobustScaler', {'normalizer__quantile_range': (...), 'normalizer__with_centering': True, 'normalizer__with_scaling': True}), 'rebalance': ('rebalance_NearMiss', {'rebalance__n_neighbors': 2})}, 'score': 0.9466666666666667, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'entropy', 'max_depth': 3, 'max_features': None, 'max_leaf_nodes': 3, 'min_samples_split': 2, 'n_estimators': 100}, 'config_hash': {'algorithm': 'dbc1b8126649fe93dce5fbb37e4015b0acfb179e', 'config': '9913cd550615a9d0946ab4a755a8b9f619e442fd', 'pipeline': 'dd626121cea079ebb32e184ca65483ec7a6d7f59'}, 'duration': 1.120617151260376, 'iteration': 10, 'loss': 0.046666666666666634, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 2, 'features__selectkbest__k': 1}), 'normalizer': ('normalizer_MinMaxScaler', {}), 'rebalance': ('rebalance_NoneType', {})}, 'score': 0.9533333333333334, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'gini', 'max_depth': 3, 'max_features': 3, 'max_leaf_nodes': None, 'min_samples_split': 3, 'n_estimators': 75}, 'config_hash': {'algorithm': '34917a130df5a975f78bd7ec1a0c7b1ffdc787a9', 'config': '95fc8cadc088141290b7de9c388977e4685f0108', 'pipeline': '550d10faf2f08db48516cc3501558816d6a99bc0'}, 'duration': 1.4287099838256836, 'iteration': 11, 'loss': 0.19333333333333313, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 3, 'features__selectkbest__k': 4}), 'normalizer': ('normalizer_StandardScaler', {'normalizer__with_mean': False, 'normalizer__with_std': False}), 'rebalance': ('rebalance_CondensedNearestNeighbour', {'rebalance__n_neighbors': 1})}, 'score': 0.8066666666666669, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'entropy', 'max_depth': 1, 'max_features': 2, 'max_leaf_nodes': 5, 'min_samples_split': 2, 'n_estimators': 75}, 'config_hash': {'algorithm': '33f9abb4aee44a395a9f3b3ffa9ce80a8cdaed7c', 'config': '40fa726f0360cf6af55f9b5902d399d02f61f157', 'pipeline': 'cfd1d20841fe2153da762c95e79f95a3fb1e426a'}, 'duration': 1.2978079319000244, 'iteration': 12, 'loss': 0.053333333333333344, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_PCA', {'features__n_components': 4}), 'normalizer': ('normalizer_MinMaxScaler', {}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 7})}, 'score': 0.9466666666666667, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'entropy', 'max_depth': 4, 'max_features': 2, 'max_leaf_nodes': 5, 'min_samples_split': 3, 'n_estimators': 25}, 'config_hash': {'algorithm': '210111ec6562d09eb093e98ed69ef1c662e11a50', 'config': '0fb8e77c7bd9a58b72f1b33c21a59a09a8c676ba', 'pipeline': '5d269d759e0c7926a685a14b263ace8ae0071e4b'}, 'duration': 0.36649012565612793, 'iteration': 13, 'loss': 0.040000000000000036, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 2, 'features__selectkbest__k': 2}), 'normalizer': ('normalizer_NoneType', {}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 7})}, 'score': 0.96, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'entropy', 'max_depth': 3, 'max_features': 1, 'max_leaf_nodes': 5, 'min_samples_split': 2, 'n_estimators': 25}, 'config_hash': {'algorithm': '0e989a03980101fabf79eda3326ed2870e11d690', 'config': 'f4bffd5d8c67a9c5321a9943c4a99678f59a02b7', 'pipeline': '865ee1e3fe8334c3d5ecb2038d5a5d1b3ba50e75'}, 'duration': 0.35639500617980957, 'iteration': 14, 'loss': 0.046666666666666634, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_NoneType', {}), 'normalizer': ('normalizer_RobustScaler', {'normalizer__quantile_range': (...), 'normalizer__with_centering': True, 'normalizer__with_scaling': False}), 'rebalance': ('rebalance_NoneType', {})}, 'score': 0.9533333333333334, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'entropy', 'max_depth': None, 'max_features': 3, 'max_leaf_nodes': 3, 'min_samples_split': 5, 'n_estimators': 10}, 'config_hash': {'algorithm': '9c592e876c13de5e23e6de5b868e01755d63e72e', 'config': '1e6a68cd1eeac886d90724d78b1cb5fb76a3cde4', 'pipeline': '5a1ca4d82f21b7de0d2c918630a42510673fa36e'}, 'duration': 0.18141412734985352, 'iteration': 15, 'loss': 0.046666666666666634, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_SelectKBest', {'features__k': 3}), 'normalizer': ('normalizer_RobustScaler', {'normalizer__quantile_range': (...), 'normalizer__with_centering': True, 'normalizer__with_scaling': True}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 6})}, 'score': 0.9533333333333334, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': 1, 'max_features': None, 'max_leaf_nodes': None, 'min_samples_split': 5, 'n_estimators': 10}, 'config_hash': {'algorithm': '8bed77aef289bfd453b2858bd288ae5ba7160f2b', 'config': '781185bcb8999045de8d489f253a1a1ba4247932', 'pipeline': '1ece7eabedc2be9e5b0a1be65c570d08ffa3eb54'}, 'duration': 0.1636829376220703, 'iteration': 16, 'loss': 0.053333333333333344, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_NoneType', {}), 'normalizer': ('normalizer_NoneType', {}), 'rebalance': ('rebalance_NearMiss', {'rebalance__n_neighbors': 1})}, 'score': 0.9466666666666667, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'gini', 'max_depth': 3, 'max_features': 2, 'max_leaf_nodes': 2, 'min_samples_split': 5, 'n_estimators': 75}, 'config_hash': {'algorithm': '617b97d9ba21d3373bc51ffa9cccf9c6f91a77b3', 'config': '99fb425b4e8c5d80228cab94202252aa25cdf77c', 'pipeline': 'd6242929c3b515c7719e60423023ac604311afc3'}, 'duration': 0.8468999862670898, 'iteration': 17, 'loss': 0.24, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_PCA', {'features__n_components': 4}), 'normalizer': ('normalizer_PowerTransformer', {}), 'rebalance': ('rebalance_NearMiss', {'rebalance__n_neighbors': 2})}, 'score': 0.76, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': 1, 'max_features': 1, 'max_leaf_nodes': 2, 'min_samples_split': 5, 'n_estimators': 50}, 'config_hash': {'algorithm': 'b92d2697cdd4979da443369d6596229ec091626a', 'config': 'c513a3e13281206ad76187dd817b1fff93d54fe1', 'pipeline': 'c4b4f914a3ca8df967cade997a90366d85a371b9'}, 'duration': 0.6724588871002197, 'iteration': 18, 'loss': 0.23333333333333328, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 1, 'features__selectkbest__k': 3}), 'normalizer': ('normalizer_StandardScaler', {'normalizer__with_mean': True, 'normalizer__with_std': True}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 5})}, 'score': 0.7666666666666667, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'entropy', 'max_depth': None, 'max_features': None, 'max_leaf_nodes': 5, 'min_samples_split': 5, 'n_estimators': 10}, 'config_hash': {'algorithm': 'a0115de695e6cca2e81cbfb54df79bf4b43608b1', 'config': 'ba194015e20b5d67770e8c67342c3d8d0d01dc41', 'pipeline': '8d45fabfeb85ffdcabf7076bd0e65fffe97ce928'}, 'duration': 0.19424200057983398, 'iteration': 19, 'loss': 0.08666666666666667, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_PCA', {'features__n_components': 3}), 'normalizer': ('normalizer_NoneType', {}), 'rebalance': ('rebalance_NoneType', {})}, 'score': 0.9133333333333333, ...}, ...], 'history_hash': ['db6ac7e6d348155757e4794bb5f88fe2b4f63d50', '4db6fb84d85f52659f780e682ffac5712c3d8a94', '4403c5a85e951938d3c454e961d3a412780722f6', 'a064e2df18ab98d44dabcefbc7bed94913f1d0be', '0ddb6f5cab3db4dddd7682966a57205f3e329ad4', '49f25751bca61cdd461a8cbd2923689b642f98ed', '5c3a2b6f5e63fb45f10e41e0318b354912ec44f6', 'd3b129b397350f1b6572651c67c01de49b4b174c', '813bde1108cc3c4b9bfb3a22cbb421bda7eac671', '31930b6860ed406d59bf7e59ba1925d94704bd3b', '9913cd550615a9d0946ab4a755a8b9f619e442fd', '95fc8cadc088141290b7de9c388977e4685f0108', '40fa726f0360cf6af55f9b5902d399d02f61f157', '0fb8e77c7bd9a58b72f1b33c21a59a09a8c676ba', 'f4bffd5d8c67a9c5321a9943c4a99678f59a02b7', '1e6a68cd1eeac886d90724d78b1cb5fb76a3cde4', '781185bcb8999045de8d489f253a1a1ba4247932', '99fb425b4e8c5d80228cab94202252aa25cdf77c', 'c513a3e13281206ad76187dd817b1fff93d54fe1', 'ba194015e20b5d67770e8c67342c3d8d0d01dc41', ...], 'history_index': {'00f0493590a2cb5e98a35b29816f8cd9f87f96ec': 208, '01161dcc5f8ee022f65481dacf76468db745b463': 306, '013329309d510b94f19d930320402d65f953a847': 39, '038a0f515e2ec894ee8e34f9caa2889eb3ebd5ce': 66, '052ae4bf232b316187b078abae42c2be19e16a00': 111, '05e9258ebf99dd97202167ef1563fa834b0568f1': 242, '0659afebf316aafeb75612fb07081a04c28545ed': 74, '06e7cde9f3556cd01332ce389ad1d8925cd4b4a4': 120, '07ab8a30d853e39a326b7017026a20e94bc45541': 245, '0855e6ed1503da05dc544450a5da27e4b3441758': 307, ...}, 'iteration': 346, 'max_history_score': 0.9666666666666668, 'max_history_score_std': 0.033333333333333326, 'max_history_step': 'joint'}
        config = {'algorithm': 'RandomForest', 'seed': 42, 'time': 300}
    114 
    115 
    116 def get_baseline_score(algorithm, X, y, seed):
    117     pipeline, _ = pipeline_conf_to_full_pipeline(

...........................................................................
/home/aquemy/dev/dp_hyperparameters/extension/experiment/objective.py in objective(pipeline_config={'features': ('features_PCA', {'features__n_components': 2}), 'normalizer': ('normalizer_StandardScaler', {'normalizer__with_mean': True, 'normalizer__with_std': True}), 'rebalance': ('rebalance_NearMiss', {'rebalance__n_neighbors': 1})}, algo_config={'bootstrap': True, 'criterion': 'gini', 'max_depth': 2, 'max_features': 3, 'max_leaf_nodes': 3, 'min_samples_split': 5, 'n_estimators': 10}, algorithm='RandomForest', X=array([[5.1, 3.5, 1.4, 0.2],
       [4.9, 3. , 1....2, 3.4, 5.4, 2.3],
       [5.9, 3. , 5.1, 1.8]]), y=array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,... 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]), context={'baseline_score': 0.9466666666666667, 'baseline_score_std': 0.04988876515698587, 'best_config': {'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': 4, 'max_features': 3, 'max_leaf_nodes': 3, 'min_samples_split': 3, 'n_estimators': 10}, 'config_hash': {'algorithm': 'ffb7ff225ce3d3712c96cf87fe42202988ee2eb0', 'config': 'bae32f426be9cd6243523c023944a8c148fe4aeb', 'pipeline': 'd2a68bfda6fcdec4ae0ffc7d7b6a2122bc1cd673'}, 'duration': 0.7115809917449951, 'iteration': 113, 'loss': 0.033333333333333215, 'max_history_score': 0.9666666666666668, 'max_history_score_std': 0.033333333333333326, 'max_history_step': 'joint', 'pipeline': {'features': ('features_NoneType', {}), 'normalizer': ('normalizer_PowerTransformer', {}), 'rebalance': ('rebalance_CondensedNearestNeighbour', {'rebalance__n_neighbors': 2})}, 'score': 0.9666666666666668, ...}, 'history': [{'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': 2, 'max_features': None, 'max_leaf_nodes': 5, 'min_samples_split': 2, 'n_estimators': 75}, 'config_hash': {'algorithm': '3af5b0cce71c8fe2545246ca24ff5bc3dd516e06', 'config': 'db6ac7e6d348155757e4794bb5f88fe2b4f63d50', 'pipeline': '8d59f4b94cef6be9306ed86a22a9570fa670d567'}, 'duration': 1.149928092956543, 'iteration': 0, 'loss': 0.046666666666666634, 'max_history_score': 0.9533333333333334, 'max_history_score_std': 0.059999999999999984, 'max_history_step': 'joint', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 4, 'features__selectkbest__k': 3}), 'normalizer': ('normalizer_StandardScaler', {'normalizer__with_mean': True, 'normalizer__with_std': True}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 6})}, 'score': 0.9533333333333334, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': 1, 'max_features': 2, 'max_leaf_nodes': 2, 'min_samples_split': 5, 'n_estimators': 100}, 'config_hash': {'algorithm': 'e13eb05fd9a62d2f63bbb1c1deff0cd620d5e6ab', 'config': '4db6fb84d85f52659f780e682ffac5712c3d8a94', 'pipeline': '64c9a1ca9d53ae67244bdd942f4db36a3c05218c'}, 'duration': 1.7678282260894775, 'iteration': 1, 'loss': 0.18000000000000005, 'max_history_score': 0.9533333333333334, 'max_history_score_std': 0.059999999999999984, 'max_history_step': 'joint', 'pipeline': {'features': ('features_NoneType', {}), 'normalizer': ('normalizer_PowerTransformer', {}), 'rebalance': ('rebalance_NearMiss', {'rebalance__n_neighbors': 1})}, 'score': 0.82, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': 1, 'max_features': None, 'max_leaf_nodes': None, 'min_samples_split': 5, 'n_estimators': 75}, 'config_hash': {'algorithm': '94b0d7a654c508cc63643f78fe4f0f07e6f07c1e', 'config': '4403c5a85e951938d3c454e961d3a412780722f6', 'pipeline': '3e47444880d8367fbac2faaba2e52a917274aa58'}, 'duration': 0.8397619724273682, 'iteration': 2, 'loss': 0.03333333333333344, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_PCA', {'features__n_components': 3}), 'normalizer': ('normalizer_MinMaxScaler', {}), 'rebalance': ('rebalance_NoneType', {})}, 'score': 0.9666666666666666, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': None, 'max_features': None, 'max_leaf_nodes': 3, 'min_samples_split': 3, 'n_estimators': 75}, 'config_hash': {'algorithm': 'e8332f0a8902bda03bf70e7978cc5d52affb29d3', 'config': 'a064e2df18ab98d44dabcefbc7bed94913f1d0be', 'pipeline': '7eea819c2a8c103c4b1e9e9c1e224aebba95081f'}, 'duration': 0.8501448631286621, 'iteration': 3, 'loss': 0.053333333333333344, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 2, 'features__selectkbest__k': 4}), 'normalizer': ('normalizer_NoneType', {}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 7})}, 'score': 0.9466666666666667, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'entropy', 'max_depth': 3, 'max_features': 3, 'max_leaf_nodes': None, 'min_samples_split': 5, 'n_estimators': 75}, 'config_hash': {'algorithm': '7a4491035bc6bd737fe9a8cda8a79a02d02d5c74', 'config': '0ddb6f5cab3db4dddd7682966a57205f3e329ad4', 'pipeline': 'a9ae03fe38334f6868cbf84cdd3d629d4bbe3fb0'}, 'duration': 1.1026010513305664, 'iteration': 4, 'loss': 0.05999999999999994, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 2, 'features__selectkbest__k': 1}), 'normalizer': ('normalizer_NoneType', {}), 'rebalance': ('rebalance_NoneType', {})}, 'score': 0.9400000000000001, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'gini', 'max_depth': 3, 'max_features': 1, 'max_leaf_nodes': 5, 'min_samples_split': 2, 'n_estimators': 25}, 'config_hash': {'algorithm': '9826d20b2d6a0f559cf7f16450ce7526f07e8434', 'config': '49f25751bca61cdd461a8cbd2923689b642f98ed', 'pipeline': '19b249664c5bf067de1fed4334a296f947ce774a'}, 'duration': 0.35647010803222656, 'iteration': 5, 'loss': 0.046666666666666634, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_NoneType', {}), 'normalizer': ('normalizer_NoneType', {}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 6})}, 'score': 0.9533333333333334, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'gini', 'max_depth': 2, 'max_features': 1, 'max_leaf_nodes': 2, 'min_samples_split': 2, 'n_estimators': 50}, 'config_hash': {'algorithm': '0a4f6fbb07e0f32c6f675489a0fc82eee05bd8e1', 'config': '5c3a2b6f5e63fb45f10e41e0318b354912ec44f6', 'pipeline': 'dc3b9f176f090005e38b142f11d80e93a7dc5d5e'}, 'duration': 0.7213859558105469, 'iteration': 6, 'loss': 0.31333333333333324, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 1, 'features__selectkbest__k': 4}), 'normalizer': ('normalizer_PowerTransformer', {}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 7})}, 'score': 0.6866666666666668, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'entropy', 'max_depth': 4, 'max_features': 3, 'max_leaf_nodes': 5, 'min_samples_split': 5, 'n_estimators': 10}, 'config_hash': {'algorithm': 'b8112b97ecfc10f00a195af661dcc861cac21289', 'config': 'd3b129b397350f1b6572651c67c01de49b4b174c', 'pipeline': '5b0357ed7072c37b3d6f458bb5d49ff7d825f603'}, 'duration': 0.8299109935760498, 'iteration': 7, 'loss': 1.0, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_PCA', {'features__n_components': 2}), 'normalizer': ('normalizer_StandardScaler', {'normalizer__with_mean': True, 'normalizer__with_std': False}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 6})}, 'score': 0.0, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'gini', 'max_depth': 4, 'max_features': None, 'max_leaf_nodes': 2, 'min_samples_split': 5, 'n_estimators': 100}, 'config_hash': {'algorithm': '40ca24df19b8d164d9d098a6bed1ce056fbbb961', 'config': '813bde1108cc3c4b9bfb3a22cbb421bda7eac671', 'pipeline': '74a7b8705a1c22f7dea5e44e4ebda8f1e48add71'}, 'duration': 2.2111589908599854, 'iteration': 8, 'loss': 0.33333333333333326, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_PCA', {'features__n_components': 2}), 'normalizer': ('normalizer_StandardScaler', {'normalizer__with_mean': False, 'normalizer__with_std': True}), 'rebalance': ('rebalance_NearMiss', {'rebalance__n_neighbors': 2})}, 'score': 0.6666666666666667, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'entropy', 'max_depth': 2, 'max_features': 1, 'max_leaf_nodes': 5, 'min_samples_split': 2, 'n_estimators': 100}, 'config_hash': {'algorithm': '331418a5c12cf1453876eef85e9d98fc8e54fa11', 'config': '31930b6860ed406d59bf7e59ba1925d94704bd3b', 'pipeline': '054bef356f90ec6f644ef3ffc688766744db51c2'}, 'duration': 1.0501940250396729, 'iteration': 9, 'loss': 0.053333333333333344, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_SelectKBest', {'features__k': 1}), 'normalizer': ('normalizer_RobustScaler', {'normalizer__quantile_range': (...), 'normalizer__with_centering': True, 'normalizer__with_scaling': True}), 'rebalance': ('rebalance_NearMiss', {'rebalance__n_neighbors': 2})}, 'score': 0.9466666666666667, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'entropy', 'max_depth': 3, 'max_features': None, 'max_leaf_nodes': 3, 'min_samples_split': 2, 'n_estimators': 100}, 'config_hash': {'algorithm': 'dbc1b8126649fe93dce5fbb37e4015b0acfb179e', 'config': '9913cd550615a9d0946ab4a755a8b9f619e442fd', 'pipeline': 'dd626121cea079ebb32e184ca65483ec7a6d7f59'}, 'duration': 1.120617151260376, 'iteration': 10, 'loss': 0.046666666666666634, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 2, 'features__selectkbest__k': 1}), 'normalizer': ('normalizer_MinMaxScaler', {}), 'rebalance': ('rebalance_NoneType', {})}, 'score': 0.9533333333333334, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'gini', 'max_depth': 3, 'max_features': 3, 'max_leaf_nodes': None, 'min_samples_split': 3, 'n_estimators': 75}, 'config_hash': {'algorithm': '34917a130df5a975f78bd7ec1a0c7b1ffdc787a9', 'config': '95fc8cadc088141290b7de9c388977e4685f0108', 'pipeline': '550d10faf2f08db48516cc3501558816d6a99bc0'}, 'duration': 1.4287099838256836, 'iteration': 11, 'loss': 0.19333333333333313, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 3, 'features__selectkbest__k': 4}), 'normalizer': ('normalizer_StandardScaler', {'normalizer__with_mean': False, 'normalizer__with_std': False}), 'rebalance': ('rebalance_CondensedNearestNeighbour', {'rebalance__n_neighbors': 1})}, 'score': 0.8066666666666669, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'entropy', 'max_depth': 1, 'max_features': 2, 'max_leaf_nodes': 5, 'min_samples_split': 2, 'n_estimators': 75}, 'config_hash': {'algorithm': '33f9abb4aee44a395a9f3b3ffa9ce80a8cdaed7c', 'config': '40fa726f0360cf6af55f9b5902d399d02f61f157', 'pipeline': 'cfd1d20841fe2153da762c95e79f95a3fb1e426a'}, 'duration': 1.2978079319000244, 'iteration': 12, 'loss': 0.053333333333333344, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_PCA', {'features__n_components': 4}), 'normalizer': ('normalizer_MinMaxScaler', {}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 7})}, 'score': 0.9466666666666667, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'entropy', 'max_depth': 4, 'max_features': 2, 'max_leaf_nodes': 5, 'min_samples_split': 3, 'n_estimators': 25}, 'config_hash': {'algorithm': '210111ec6562d09eb093e98ed69ef1c662e11a50', 'config': '0fb8e77c7bd9a58b72f1b33c21a59a09a8c676ba', 'pipeline': '5d269d759e0c7926a685a14b263ace8ae0071e4b'}, 'duration': 0.36649012565612793, 'iteration': 13, 'loss': 0.040000000000000036, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 2, 'features__selectkbest__k': 2}), 'normalizer': ('normalizer_NoneType', {}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 7})}, 'score': 0.96, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'entropy', 'max_depth': 3, 'max_features': 1, 'max_leaf_nodes': 5, 'min_samples_split': 2, 'n_estimators': 25}, 'config_hash': {'algorithm': '0e989a03980101fabf79eda3326ed2870e11d690', 'config': 'f4bffd5d8c67a9c5321a9943c4a99678f59a02b7', 'pipeline': '865ee1e3fe8334c3d5ecb2038d5a5d1b3ba50e75'}, 'duration': 0.35639500617980957, 'iteration': 14, 'loss': 0.046666666666666634, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_NoneType', {}), 'normalizer': ('normalizer_RobustScaler', {'normalizer__quantile_range': (...), 'normalizer__with_centering': True, 'normalizer__with_scaling': False}), 'rebalance': ('rebalance_NoneType', {})}, 'score': 0.9533333333333334, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'entropy', 'max_depth': None, 'max_features': 3, 'max_leaf_nodes': 3, 'min_samples_split': 5, 'n_estimators': 10}, 'config_hash': {'algorithm': '9c592e876c13de5e23e6de5b868e01755d63e72e', 'config': '1e6a68cd1eeac886d90724d78b1cb5fb76a3cde4', 'pipeline': '5a1ca4d82f21b7de0d2c918630a42510673fa36e'}, 'duration': 0.18141412734985352, 'iteration': 15, 'loss': 0.046666666666666634, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_SelectKBest', {'features__k': 3}), 'normalizer': ('normalizer_RobustScaler', {'normalizer__quantile_range': (...), 'normalizer__with_centering': True, 'normalizer__with_scaling': True}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 6})}, 'score': 0.9533333333333334, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': 1, 'max_features': None, 'max_leaf_nodes': None, 'min_samples_split': 5, 'n_estimators': 10}, 'config_hash': {'algorithm': '8bed77aef289bfd453b2858bd288ae5ba7160f2b', 'config': '781185bcb8999045de8d489f253a1a1ba4247932', 'pipeline': '1ece7eabedc2be9e5b0a1be65c570d08ffa3eb54'}, 'duration': 0.1636829376220703, 'iteration': 16, 'loss': 0.053333333333333344, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_NoneType', {}), 'normalizer': ('normalizer_NoneType', {}), 'rebalance': ('rebalance_NearMiss', {'rebalance__n_neighbors': 1})}, 'score': 0.9466666666666667, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'gini', 'max_depth': 3, 'max_features': 2, 'max_leaf_nodes': 2, 'min_samples_split': 5, 'n_estimators': 75}, 'config_hash': {'algorithm': '617b97d9ba21d3373bc51ffa9cccf9c6f91a77b3', 'config': '99fb425b4e8c5d80228cab94202252aa25cdf77c', 'pipeline': 'd6242929c3b515c7719e60423023ac604311afc3'}, 'duration': 0.8468999862670898, 'iteration': 17, 'loss': 0.24, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_PCA', {'features__n_components': 4}), 'normalizer': ('normalizer_PowerTransformer', {}), 'rebalance': ('rebalance_NearMiss', {'rebalance__n_neighbors': 2})}, 'score': 0.76, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': 1, 'max_features': 1, 'max_leaf_nodes': 2, 'min_samples_split': 5, 'n_estimators': 50}, 'config_hash': {'algorithm': 'b92d2697cdd4979da443369d6596229ec091626a', 'config': 'c513a3e13281206ad76187dd817b1fff93d54fe1', 'pipeline': 'c4b4f914a3ca8df967cade997a90366d85a371b9'}, 'duration': 0.6724588871002197, 'iteration': 18, 'loss': 0.23333333333333328, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 1, 'features__selectkbest__k': 3}), 'normalizer': ('normalizer_StandardScaler', {'normalizer__with_mean': True, 'normalizer__with_std': True}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 5})}, 'score': 0.7666666666666667, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'entropy', 'max_depth': None, 'max_features': None, 'max_leaf_nodes': 5, 'min_samples_split': 5, 'n_estimators': 10}, 'config_hash': {'algorithm': 'a0115de695e6cca2e81cbfb54df79bf4b43608b1', 'config': 'ba194015e20b5d67770e8c67342c3d8d0d01dc41', 'pipeline': '8d45fabfeb85ffdcabf7076bd0e65fffe97ce928'}, 'duration': 0.19424200057983398, 'iteration': 19, 'loss': 0.08666666666666667, 'max_history_score': 0.9666666666666666, 'max_history_score_std': 0.04472135954999579, 'max_history_step': 'joint', 'pipeline': {'features': ('features_PCA', {'features__n_components': 3}), 'normalizer': ('normalizer_NoneType', {}), 'rebalance': ('rebalance_NoneType', {})}, 'score': 0.9133333333333333, ...}, ...], 'history_hash': ['db6ac7e6d348155757e4794bb5f88fe2b4f63d50', '4db6fb84d85f52659f780e682ffac5712c3d8a94', '4403c5a85e951938d3c454e961d3a412780722f6', 'a064e2df18ab98d44dabcefbc7bed94913f1d0be', '0ddb6f5cab3db4dddd7682966a57205f3e329ad4', '49f25751bca61cdd461a8cbd2923689b642f98ed', '5c3a2b6f5e63fb45f10e41e0318b354912ec44f6', 'd3b129b397350f1b6572651c67c01de49b4b174c', '813bde1108cc3c4b9bfb3a22cbb421bda7eac671', '31930b6860ed406d59bf7e59ba1925d94704bd3b', '9913cd550615a9d0946ab4a755a8b9f619e442fd', '95fc8cadc088141290b7de9c388977e4685f0108', '40fa726f0360cf6af55f9b5902d399d02f61f157', '0fb8e77c7bd9a58b72f1b33c21a59a09a8c676ba', 'f4bffd5d8c67a9c5321a9943c4a99678f59a02b7', '1e6a68cd1eeac886d90724d78b1cb5fb76a3cde4', '781185bcb8999045de8d489f253a1a1ba4247932', '99fb425b4e8c5d80228cab94202252aa25cdf77c', 'c513a3e13281206ad76187dd817b1fff93d54fe1', 'ba194015e20b5d67770e8c67342c3d8d0d01dc41', ...], 'history_index': {'00f0493590a2cb5e98a35b29816f8cd9f87f96ec': 208, '01161dcc5f8ee022f65481dacf76468db745b463': 306, '013329309d510b94f19d930320402d65f953a847': 39, '038a0f515e2ec894ee8e34f9caa2889eb3ebd5ce': 66, '052ae4bf232b316187b078abae42c2be19e16a00': 111, '05e9258ebf99dd97202167ef1563fa834b0568f1': 242, '0659afebf316aafeb75612fb07081a04c28545ed': 74, '06e7cde9f3556cd01332ce389ad1d8925cd4b4a4': 120, '07ab8a30d853e39a326b7017026a20e94bc45541': 245, '0855e6ed1503da05dc544450a5da27e4b3441758': 307, ...}, 'iteration': 346, 'max_history_score': 0.9666666666666668, 'max_history_score_std': 0.033333333333333326, 'max_history_step': 'joint'}, config={'algorithm': 'RandomForest', 'seed': 42, 'time': 300}, step='joint')
     45                 y,
     46                 cv=10,
     47                 n_jobs=-1,
     48                 return_estimator=False,
     49                 return_train_score=False,
---> 50                 verbose=0)
     51         score = np.mean(scores['test_score'])
     52         std = np.std(scores['test_score'])
     53         status = STATUS_OK
     54     except Exception as e:

...........................................................................
/home/aquemy/.local/lib/python2.7/site-packages/sklearn/model_selection/_validation.py in cross_validate(estimator=Pipeline(memory=None,
     steps=[('rebalance', ... random_state=42, verbose=0, warm_start=False))]), X=array([[5.1, 3.5, 1.4, 0.2],
       [4.9, 3. , 1....2, 3.4, 5.4, 2.3],
       [5.9, 3. , 5.1, 1.8]]), y=array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,... 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]), groups=None, scoring=None, cv=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1, verbose=0, fit_params=None, pre_dispatch='2*n_jobs', return_train_score=False, return_estimator=False, error_score='raise-deprecating')
    235         delayed(_fit_and_score)(
    236             clone(estimator), X, y, scorers, train, test, verbose, None,
    237             fit_params, return_train_score=return_train_score,
    238             return_times=True, return_estimator=return_estimator,
    239             error_score=error_score)
--> 240         for train, test in cv.split(X, y, groups))
        cv.split = <bound method StratifiedKFold.split of Stratifie...d(n_splits=10, random_state=None, shuffle=False)>
        X = array([[5.1, 3.5, 1.4, 0.2],
       [4.9, 3. , 1....2, 3.4, 5.4, 2.3],
       [5.9, 3. , 5.1, 1.8]])
        y = array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,... 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2])
        groups = None
    241 
    242     zipped_scores = list(zip(*scores))
    243     if return_train_score:
    244         train_scores = zipped_scores.pop(0)

...........................................................................
/home/aquemy/.local/lib/python2.7/site-packages/sklearn/externals/joblib/parallel.py in __call__(self=Parallel(n_jobs=-1), iterable=<generator object <genexpr>>)
    925                 # No need to wait for async callbacks to trigger to
    926                 # consumption.
    927                 self._iterating = False
    928 
    929             with self._backend.retrieval_context():
--> 930                 self.retrieve()
        self.retrieve = <bound method Parallel.retrieve of Parallel(n_jobs=-1)>
    931             # Make sure that we get a last message telling us we are done
    932             elapsed_time = time.time() - self._start_time
    933             self._print('Done %3i out of %3i | elapsed: %s finished',
    934                         (len(self._output), len(self._output),

---------------------------------------------------------------------------
Joblib worker traceback:
---------------------------------------------------------------------------
ValueError                                         Mon Jun 17 13:15:16 2019
PID: 22054                                  Python 2.7.15+: /usr/bin/python
...........................................................................
/home/aquemy/.local/lib/python2.7/site-packages/sklearn/externals/joblib/parallel.py in __call__(self=<sklearn.externals.joblib.parallel.BatchedCalls object>)
    220     def __call__(self):
    221         # Set the default nested backend to self._backend but do not set the
    222         # change the default number of processes to -1
    223         with parallel_backend(self._backend, n_jobs=self._n_jobs):
    224             return [func(*args, **kwargs)
--> 225                     for func, args, kwargs in self.items]
        func = <function _fit_and_score>
        args = (Pipeline(memory=None,
     steps=[('rebalance', ... random_state=42, verbose=0, warm_start=False))]), array([[5.1, 3.5, 1.4, 0.2],
       [4.9, 3. , 1....2, 3.4, 5.4, 2.3],
       [5.9, 3. , 5.1, 1.8]]), array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,... 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]), {'score': <function _passthrough_scorer>}, array([  5,   6,   7,   8,   9,  10,  11,  12,  ..., 142, 143, 144,
       145, 146, 147, 148, 149]), array([  0,   1,   2,   3,   4,  50,  51,  52,  53,  54, 100, 101, 102,
       103, 104]), 0, None, None)
        kwargs = {'error_score': 'raise-deprecating', 'return_estimator': False, 'return_times': True, 'return_train_score': False}
        self.items = [(<function _fit_and_score>, (Pipeline(memory=None,
     steps=[('rebalance', ... random_state=42, verbose=0, warm_start=False))]), array([[5.1, 3.5, 1.4, 0.2],
       [4.9, 3. , 1....2, 3.4, 5.4, 2.3],
       [5.9, 3. , 5.1, 1.8]]), array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,... 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]), {'score': <function _passthrough_scorer>}, array([  5,   6,   7,   8,   9,  10,  11,  12,  ..., 142, 143, 144,
       145, 146, 147, 148, 149]), array([  0,   1,   2,   3,   4,  50,  51,  52,  53,  54, 100, 101, 102,
       103, 104]), 0, None, None), {'error_score': 'raise-deprecating', 'return_estimator': False, 'return_times': True, 'return_train_score': False})]
    226 
    227     def __len__(self):
    228         return self._size
    229 

...........................................................................
/home/aquemy/.local/lib/python2.7/site-packages/sklearn/model_selection/_validation.py in _fit_and_score(estimator=Pipeline(memory=None,
     steps=[('rebalance', ... random_state=42, verbose=0, warm_start=False))]), X=array([[5.1, 3.5, 1.4, 0.2],
       [4.9, 3. , 1....2, 3.4, 5.4, 2.3],
       [5.9, 3. , 5.1, 1.8]]), y=array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,... 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]), scorer={'score': <function _passthrough_scorer>}, train=array([  5,   6,   7,   8,   9,  10,  11,  12,  ..., 142, 143, 144,
       145, 146, 147, 148, 149]), test=array([  0,   1,   2,   3,   4,  50,  51,  52,  53,  54, 100, 101, 102,
       103, 104]), verbose=0, parameters=None, fit_params={}, return_train_score=False, return_parameters=False, return_n_test_samples=False, return_times=True, return_estimator=False, error_score='raise-deprecating')
    523 
    524     try:
    525         if y_train is None:
    526             estimator.fit(X_train, **fit_params)
    527         else:
--> 528             estimator.fit(X_train, y_train, **fit_params)
        estimator.fit = <bound method Pipeline.fit of Pipeline(memory=No...random_state=42, verbose=0, warm_start=False))])>
        X_train = array([[5.4, 3.9, 1.7, 0.4],
       [4.6, 3.4, 1....2, 3.4, 5.4, 2.3],
       [5.9, 3. , 5.1, 1.8]])
        y_train = array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,
       2, 2, 2])
        fit_params = {}
    529 
    530     except Exception as e:
    531         # Note fit time as time until error
    532         fit_time = time.time() - start_time

...........................................................................
/usr/local/lib/python2.7/dist-packages/imblearn/pipeline.py in fit(self=Pipeline(memory=None,
     steps=[('rebalance', ... random_state=42, verbose=0, warm_start=False))]), X=array([[5.4, 3.9, 1.7, 0.4],
       [4.6, 3.4, 1....2, 3.4, 5.4, 2.3],
       [5.9, 3. , 5.1, 1.8]]), y=array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,
       2, 2, 2]), **fit_params={})
    234             This estimator
    235 
    236         """
    237         Xt, yt, fit_params = self._fit(X, y, **fit_params)
    238         if self._final_estimator is not None:
--> 239             self._final_estimator.fit(Xt, yt, **fit_params)
        self._final_estimator.fit = <bound method RandomForestClassifier.fit of Rand...e, random_state=42, verbose=0, warm_start=False)>
        Xt = array([[-2.06079719,  1.43951605],
       [-2.43... 0.4478386 ],
       [ 3.32926496,  0.06437546]])
        yt = array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,
       2, 2, 2])
        fit_params = {}
    240         return self
    241 
    242     def fit_transform(self, X, y=None, **fit_params):
    243         """Fit the model and transform with the final estimator

...........................................................................
/home/aquemy/.local/lib/python2.7/site-packages/sklearn/ensemble/forest.py in fit(self=RandomForestClassifier(bootstrap=True, class_wei...se, random_state=42, verbose=0, warm_start=False), X=array([[-2.0607972 ,  1.4395161 ],
       [-2.43...      [ 3.3292649 ,  0.06437546]], dtype=float32), y=array([[0.],
       [0.],
       [0.],
       [0...    [2.],
       [2.],
       [2.],
       [2.]]), sample_weight=None)
    328             trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,
    329                              **_joblib_parallel_args(prefer='threads'))(
    330                 delayed(_parallel_build_trees)(
    331                     t, self, X, y, sample_weight, i, len(trees),
    332                     verbose=self.verbose, class_weight=self.class_weight)
--> 333                 for i, t in enumerate(trees))
        i = 9
    334 
    335             # Collect newly grown trees
    336             self.estimators_.extend(trees)
    337 

...........................................................................
/home/aquemy/.local/lib/python2.7/site-packages/sklearn/externals/joblib/parallel.py in __call__(self=Parallel(n_jobs=1), iterable=<generator object <genexpr>>)
    912             # self._original_iterator is None, then this means either
    913             # that pre_dispatch == "all", n_jobs == 1 or that the first batch
    914             # was very quick and its callback already dispatched all the
    915             # remaining jobs.
    916             self._iterating = False
--> 917             if self.dispatch_one_batch(iterator):
        self.dispatch_one_batch = <bound method Parallel.dispatch_one_batch of Parallel(n_jobs=1)>
        iterator = <generator object <genexpr>>
    918                 self._iterating = self._original_iterator is not None
    919 
    920             while self.dispatch_one_batch(iterator):
    921                 pass

...........................................................................
/home/aquemy/.local/lib/python2.7/site-packages/sklearn/externals/joblib/parallel.py in dispatch_one_batch(self=Parallel(n_jobs=1), iterator=<generator object <genexpr>>)
    754                                  self._pickle_cache)
    755             if len(tasks) == 0:
    756                 # No more tasks available in the iterator: tell caller to stop.
    757                 return False
    758             else:
--> 759                 self._dispatch(tasks)
        self._dispatch = <bound method Parallel._dispatch of Parallel(n_jobs=1)>
        tasks = <sklearn.externals.joblib.parallel.BatchedCalls object>
    760                 return True
    761 
    762     def _print(self, msg, msg_args):
    763         """Display the message on stout or stderr depending on verbosity"""

...........................................................................
/home/aquemy/.local/lib/python2.7/site-packages/sklearn/externals/joblib/parallel.py in _dispatch(self=Parallel(n_jobs=1), batch=<sklearn.externals.joblib.parallel.BatchedCalls object>)
    711 
    712         dispatch_timestamp = time.time()
    713         cb = BatchCompletionCallBack(dispatch_timestamp, len(batch), self)
    714         with self._lock:
    715             job_idx = len(self._jobs)
--> 716             job = self._backend.apply_async(batch, callback=cb)
        job = undefined
        self._backend.apply_async = <bound method SequentialBackend.apply_async of <...lib._parallel_backends.SequentialBackend object>>
        batch = <sklearn.externals.joblib.parallel.BatchedCalls object>
        cb = <sklearn.externals.joblib.parallel.BatchCompletionCallBack object>
    717             # A job can complete so quickly than its callback is
    718             # called before we get here, causing self._jobs to
    719             # grow. To ensure correct results ordering, .insert is
    720             # used (rather than .append) in the following line

...........................................................................
/home/aquemy/.local/lib/python2.7/site-packages/sklearn/externals/joblib/_parallel_backends.py in apply_async(self=<sklearn.externals.joblib._parallel_backends.SequentialBackend object>, func=<sklearn.externals.joblib.parallel.BatchedCalls object>, callback=<sklearn.externals.joblib.parallel.BatchCompletionCallBack object>)
    177             raise ValueError('n_jobs == 0 in Parallel has no meaning')
    178         return 1
    179 
    180     def apply_async(self, func, callback=None):
    181         """Schedule a func to be run"""
--> 182         result = ImmediateResult(func)
        result = undefined
        func = <sklearn.externals.joblib.parallel.BatchedCalls object>
    183         if callback:
    184             callback(result)
    185         return result
    186 

...........................................................................
/home/aquemy/.local/lib/python2.7/site-packages/sklearn/externals/joblib/_parallel_backends.py in __init__(self=<sklearn.externals.joblib._parallel_backends.ImmediateResult object>, batch=<sklearn.externals.joblib.parallel.BatchedCalls object>)
    544 
    545 class ImmediateResult(object):
    546     def __init__(self, batch):
    547         # Don't delay the application, to avoid keeping the input
    548         # arguments in memory
--> 549         self.results = batch()
        self.results = undefined
        batch = <sklearn.externals.joblib.parallel.BatchedCalls object>
    550 
    551     def get(self):
    552         return self.results
    553 

...........................................................................
/home/aquemy/.local/lib/python2.7/site-packages/sklearn/externals/joblib/parallel.py in __call__(self=<sklearn.externals.joblib.parallel.BatchedCalls object>)
    220     def __call__(self):
    221         # Set the default nested backend to self._backend but do not set the
    222         # change the default number of processes to -1
    223         with parallel_backend(self._backend, n_jobs=self._n_jobs):
    224             return [func(*args, **kwargs)
--> 225                     for func, args, kwargs in self.items]
        func = <function _parallel_build_trees>
        args = (DecisionTreeClassifier(class_weight=None, criter...=False, random_state=1608637542, splitter='best'), RandomForestClassifier(bootstrap=True, class_wei...se, random_state=42, verbose=0, warm_start=False), array([[-2.0607972 ,  1.4395161 ],
       [-2.43...      [ 3.3292649 ,  0.06437546]], dtype=float32), array([[0.],
       [0.],
       [0.],
       [0...    [2.],
       [2.],
       [2.],
       [2.]]), None, 0, 10)
        kwargs = {'class_weight': None, 'verbose': 0}
        self.items = [(<function _parallel_build_trees>, (DecisionTreeClassifier(class_weight=None, criter...=False, random_state=1608637542, splitter='best'), RandomForestClassifier(bootstrap=True, class_wei...se, random_state=42, verbose=0, warm_start=False), array([[-2.0607972 ,  1.4395161 ],
       [-2.43...      [ 3.3292649 ,  0.06437546]], dtype=float32), array([[0.],
       [0.],
       [0.],
       [0...    [2.],
       [2.],
       [2.],
       [2.]]), None, 0, 10), {'class_weight': None, 'verbose': 0})]
    226 
    227     def __len__(self):
    228         return self._size
    229 

...........................................................................
/home/aquemy/.local/lib/python2.7/site-packages/sklearn/ensemble/forest.py in _parallel_build_trees(tree=DecisionTreeClassifier(class_weight=None, criter...=False, random_state=1608637542, splitter='best'), forest=RandomForestClassifier(bootstrap=True, class_wei...se, random_state=42, verbose=0, warm_start=False), X=array([[-2.0607972 ,  1.4395161 ],
       [-2.43...      [ 3.3292649 ,  0.06437546]], dtype=float32), y=array([[0.],
       [0.],
       [0.],
       [0...    [2.],
       [2.],
       [2.],
       [2.]]), sample_weight=None, tree_idx=0, n_trees=10, verbose=0, class_weight=None)
    114                 simplefilter('ignore', DeprecationWarning)
    115                 curr_sample_weight *= compute_sample_weight('auto', y, indices)
    116         elif class_weight == 'balanced_subsample':
    117             curr_sample_weight *= compute_sample_weight('balanced', y, indices)
    118 
--> 119         tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)
        tree.fit = <bound method DecisionTreeClassifier.fit of Deci...False, random_state=1608637542, splitter='best')>
        X = array([[-2.0607972 ,  1.4395161 ],
       [-2.43...      [ 3.3292649 ,  0.06437546]], dtype=float32)
        y = array([[0.],
       [0.],
       [0.],
       [0...    [2.],
       [2.],
       [2.],
       [2.]])
        sample_weight = None
        curr_sample_weight = array([3., 3., 0., 1., 1., 2., 2., 0., 1., 2., 0... 1., 0., 1., 0., 1., 1., 1., 1., 1., 1., 0., 0.])
    120     else:
    121         tree.fit(X, y, sample_weight=sample_weight, check_input=False)
    122 
    123     return tree

...........................................................................
/home/aquemy/.local/lib/python2.7/site-packages/sklearn/tree/tree.py in fit(self=DecisionTreeClassifier(class_weight=None, criter...=False, random_state=1608637542, splitter='best'), X=array([[-2.0607972 ,  1.4395161 ],
       [-2.43...      [ 3.3292649 ,  0.06437546]], dtype=float32), y=array([[0.],
       [0.],
       [0.],
       [0...    [2.],
       [2.],
       [2.],
       [2.]]), sample_weight=array([3., 3., 0., 1., 1., 2., 2., 0., 1., 2., 0... 1., 0., 1., 0., 1., 1., 1., 1., 1., 1., 0., 0.]), check_input=False, X_idx_sorted=None)
    796 
    797         super(DecisionTreeClassifier, self).fit(
    798             X, y,
    799             sample_weight=sample_weight,
    800             check_input=check_input,
--> 801             X_idx_sorted=X_idx_sorted)
        X_idx_sorted = None
    802         return self
    803 
    804     def predict_proba(self, X, check_input=True):
    805         """Predict class probabilities of the input samples X.

...........................................................................
/home/aquemy/.local/lib/python2.7/site-packages/sklearn/tree/tree.py in fit(self=DecisionTreeClassifier(class_weight=None, criter...=False, random_state=1608637542, splitter='best'), X=array([[-2.0607972 ,  1.4395161 ],
       [-2.43...      [ 3.3292649 ,  0.06437546]], dtype=float32), y=array([[0.],
       [0.],
       [0.],
       [0...    [2.],
       [2.],
       [2.],
       [2.]]), sample_weight=array([3., 3., 0., 1., 1., 2., 2., 0., 1., 2., 0... 1., 0., 1., 0., 1., 1., 1., 1., 1., 1., 0., 0.]), check_input=False, X_idx_sorted=None)
    237         if not 0 <= self.min_weight_fraction_leaf <= 0.5:
    238             raise ValueError("min_weight_fraction_leaf must in [0, 0.5]")
    239         if max_depth <= 0:
    240             raise ValueError("max_depth must be greater than zero. ")
    241         if not (0 < max_features <= self.n_features_):
--> 242             raise ValueError("max_features must be in (0, n_features]")
    243         if not isinstance(max_leaf_nodes, (numbers.Integral, np.integer)):
    244             raise ValueError("max_leaf_nodes must be integral number but was "
    245                              "%r" % max_leaf_nodes)
    246         if -1 < max_leaf_nodes < 2:

ValueError: max_features must be in (0, n_features]
___________________________________________________________________________
Best score: 0.966666666667 (0.0333333333333) [J] | Score: 0.0 (0.0) [J]
Best score: 0.966666666667 (0.0333333333333) [J] | Score: 0.666666666667 (1.11022302463e-16) [J]
Best score: 0.966666666667 (0.0333333333333) [J] | Score: 0.953333333333 (0.0426874949162) [J]
Best score: 0.966666666667 (0.0333333333333) [J] | Score: 0.946666666667 (0.049888765157) [J]
Best score: 0.966666666667 (0.0333333333333) [J] | Score: 0.886666666667 (0.0733333333333) [J]
Best score: 0.966666666667 (0.0333333333333) [J] | Score: 0.953333333333 (0.0520683311727) [J]
Best score: 0.966666666667 (0.0333333333333) [J] | Score: 0.966666666667 (0.04472135955) [J]
Best score: 0.966666666667 (0.0333333333333) [J] | Score: 0.793333333333 (0.075718777944) [J]
Best score: 0.966666666667 (0.0333333333333) [J] | Score: 0.9 (0.0683130051064) [J]
Best score: 0.966666666667 (0.0333333333333) [J] | Score: 0.906666666667 (0.08) [J]
Best score: 0.966666666667 (0.0333333333333) [J] | Score: 0.953333333333 (0.0669991708075) [J]
Best score: 0.966666666667 (0.0333333333333) [J] | Score: 0.9 (0.0614636297153) [J]
Best score: 0.966666666667 (0.0333333333333) [J] | Score: 0.486666666667 (0.103494497975) [J]
Best score: 0.966666666667 (0.0333333333333) [J] | Score: 0.933333333333 (0.0596284794) [J]
Best score: 0.966666666667 (0.0333333333333) [J] | Score: 0.9 (0.0537483849887) [J]
Best score: 0.966666666667 (0.0333333333333) [J] | Score: 0.886666666667 (0.0791622805803) [J]
Best score: 0.966666666667 (0.0333333333333) [J] | Score: 0.553333333333 (0.0669991708075) [J]
Best score: 0.966666666667 (0.0333333333333) [J] | Score: 0.953333333333 (0.0426874949162) [J]
Best score: 0.966666666667 (0.0333333333333) [J] | Score: 0.953333333333 (0.0426874949162) [J]
Best score: 0.966666666667 (0.0333333333333) [J] | Score: 0.9 (0.0683130051064) [J]
Best score: 0.966666666667 (0.0333333333333) [J] | Score: 0.953333333333 (0.0426874949162) [J]
Best score: 0.966666666667 (0.0333333333333) [J] | Score: 0.96 (0.0442216638714) [J]
#################### STEP RESULT ####################
BEST PIPELINE:
 {
    "features": [
        "features_NoneType", 
        {}
    ], 
    "normalizer": [
        "normalizer_PowerTransformer", 
        {}
    ], 
    "rebalance": [
        "rebalance_CondensedNearestNeighbour", 
        {
            "rebalance__n_neighbors": 2
        }
    ]
}
BEST ALGO CONFIG:
 {
    "bootstrap": true, 
    "criterion": "gini", 
    "max_depth": 4, 
    "max_features": 3, 
    "max_leaf_nodes": 3, 
    "min_samples_split": 3, 
    "n_estimators": 10
}
BEST SCORE: 0.966666666667 (0.0333333333333)
##################################################
