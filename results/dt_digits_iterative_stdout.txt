SCENARIO:
 {
    "control": {
        "seed": 42
    }, 
    "file_name": "dt_digits_iterative", 
    "policy": {
        "reset_trial": false, 
        "step_algorithm": 15, 
        "step_pipeline": 15
    }, 
    "setup": {
        "algorithm": "DecisionTree", 
        "dataset": "digits", 
        "policy": "iterative", 
        "runtime": 300
    }, 
    "title": "Decision Tree on Digits with Iterative policy"
}
## Data Pipeline
Best score: 0.114030441767 (0.0205735154133) [P] | Score: 0.114030441767 (0.0205735154133) [P]
#################### STEP RESULT ####################
BEST PIPELINE:
 {
    "features": [
        "features_PCA", 
        {
            "features__n_components": 1
        }
    ], 
    "normalizer": [
        "normalizer_StandardScaler", 
        {
            "normalizer__with_mean": true, 
            "normalizer__with_std": true
        }
    ], 
    "rebalance": [
        "rebalance_CondensedNearestNeighbour", 
        {
            "rebalance__n_neighbors": 3
        }
    ]
}
BEST ALGO CONFIG:
 {}
BEST SCORE: 0.114030441767 (0.0205735154133)
##################################################
## Algorithm
JoblibValueError
___________________________________________________________________________
...........................................................................
/home/aquemy/dev/dp_hyperparameters/extension/main.py in <module>()
     27 
     28     serializer.serialize_results(scenario, policy)
     29 
     30 if __name__ == "__main__":
     31     args = cli.parse_args()
---> 32     main(args)

...........................................................................
/home/aquemy/dev/dp_hyperparameters/extension/main.py in main(args=Namespace(customize=[(['control', 'seed'], '42')...scenarios/dt_digits_iterative.yaml', verbosity=0))
     21         test_size=0.4, 
     22         random_state=scenario['control']['seed']
     23     )
     24 
     25     policy = policies.initiate(scenario['setup']['policy'], config)
---> 26     policy.run(X,y)
        policy.run = <bound method Iterative.run of <experiment.policies.iterative.Iterative object>>
        X = array([[ 0.,  0.,  5., ...,  0.,  0.,  0.],
    ...0.],
       [ 0.,  0., 10., ..., 12.,  1.,  0.]])
        y = array([0, 1, 2, ..., 8, 9, 8])
     27 
     28     serializer.serialize_results(scenario, policy)
     29 
     30 if __name__ == "__main__":

...........................................................................
/home/aquemy/dev/dp_hyperparameters/extension/experiment/policies/iterative.py in run(self=<experiment.policies.iterative.Iterative object>, X=array([[ 0.,  0.,  5., ...,  0.,  0.,  0.],
    ...0.],
       [ 0.,  0., 10., ..., 12.,  1.,  0.]]), y=array([0, 1, 2, ..., 8, 9, 8]))
     59                 algo=tpe.suggest, 
     60                 max_evals=None,
     61                 max_time=self.config['step_algorithm'],
     62                 trials=trials_algo,
     63                 show_progressbar=False,
---> 64                 verbose=0
     65             )
     66             best_config = self.context['best_config']
     67             current_pipeline_configuration = best_config['pipeline']
     68             super(Iterative, self).display_step_results(best_config)

...........................................................................
/home/aquemy/dev/dp_hyperparameters/extension/hyperopt/fmin.py in fmin(fn=<functools.partial object>, space={'criterion': <hyperopt.pyll.base.Apply object>, 'max_depth': <hyperopt.pyll.base.Apply object>, 'max_features': <hyperopt.pyll.base.Apply object>, 'max_leaf_nodes': <hyperopt.pyll.base.Apply object>, 'min_samples_leaf': <hyperopt.pyll.base.Apply object>, 'min_samples_split': <hyperopt.pyll.base.Apply object>, 'splitter': <hyperopt.pyll.base.Apply object>}, algo=<function suggest>, max_evals=9223372036854775807, max_time=15, trials=<hyperopt.base.Trials object>, rstate=<mtrand.RandomState object>, allow_trials_fmin=True, pass_expr_memo_ctrl=None, catch_eval_exceptions=False, verbose=0, return_argmin=True, points_to_evaluate=None, max_queue_len=1, show_progressbar=False)
    406             pass_expr_memo_ctrl=pass_expr_memo_ctrl,
    407             verbose=verbose,
    408             catch_eval_exceptions=catch_eval_exceptions,
    409             return_argmin=return_argmin,
    410             show_progressbar=show_progressbar,
--> 411             max_time=max_time
        max_time = 15
    412         )
    413 
    414     if trials is None:
    415         if points_to_evaluate is None:

...........................................................................
/home/aquemy/dev/dp_hyperparameters/extension/hyperopt/base.py in fmin(self=<hyperopt.base.Trials object>, fn=<functools.partial object>, space={'criterion': <hyperopt.pyll.base.Apply object>, 'max_depth': <hyperopt.pyll.base.Apply object>, 'max_features': <hyperopt.pyll.base.Apply object>, 'max_leaf_nodes': <hyperopt.pyll.base.Apply object>, 'min_samples_leaf': <hyperopt.pyll.base.Apply object>, 'min_samples_split': <hyperopt.pyll.base.Apply object>, 'splitter': <hyperopt.pyll.base.Apply object>}, algo=<function suggest>, max_evals=9223372036854775807, max_time=15, rstate=<mtrand.RandomState object>, verbose=0, pass_expr_memo_ctrl=None, catch_eval_exceptions=False, return_argmin=True, show_progressbar=False)
    636             verbose=verbose,
    637             allow_trials_fmin=False,  # -- prevent recursion
    638             pass_expr_memo_ctrl=pass_expr_memo_ctrl,
    639             catch_eval_exceptions=catch_eval_exceptions,
    640             return_argmin=return_argmin,
--> 641             show_progressbar=show_progressbar)
        show_progressbar = False
    642 
    643 
    644 def trials_from_docs(docs, validate=True, **kwargs):
    645     """Construct a Trials base class instance from a list of trials documents

...........................................................................
/home/aquemy/dev/dp_hyperparameters/extension/hyperopt/fmin.py in fmin(fn=<functools.partial object>, space={'criterion': <hyperopt.pyll.base.Apply object>, 'max_depth': <hyperopt.pyll.base.Apply object>, 'max_features': <hyperopt.pyll.base.Apply object>, 'max_leaf_nodes': <hyperopt.pyll.base.Apply object>, 'min_samples_leaf': <hyperopt.pyll.base.Apply object>, 'min_samples_split': <hyperopt.pyll.base.Apply object>, 'splitter': <hyperopt.pyll.base.Apply object>}, algo=<function suggest>, max_evals=9223372036854775807, max_time=15, trials=<hyperopt.base.Trials object>, rstate=<mtrand.RandomState object>, allow_trials_fmin=False, pass_expr_memo_ctrl=None, catch_eval_exceptions=False, verbose=0, return_argmin=True, points_to_evaluate=None, max_queue_len=1, show_progressbar=False)
    426                     verbose=verbose,
    427                     max_queue_len=max_queue_len,
    428                     show_progressbar=show_progressbar,
    429                     max_time=max_time)
    430     rval.catch_eval_exceptions = catch_eval_exceptions
--> 431     rval.exhaust()
        rval.exhaust = <bound method FMinIter.exhaust of <hyperopt.fmin.FMinIter object>>
    432     if return_argmin:
    433         return trials.argmin
    434     elif len(trials) > 0:
    435         # Only if there are some succesfull trail runs, return the best point in the evaluation space

...........................................................................
/home/aquemy/dev/dp_hyperparameters/extension/hyperopt/fmin.py in exhaust(self=<hyperopt.fmin.FMinIter object>)
    273             raise StopIteration()
    274         return self.trials
    275 
    276     def exhaust(self):
    277         n_done = len(self.trials)
--> 278         self.run(self.max_evals - n_done, block_until_done=self.asynchronous)
        self.run = <bound method FMinIter.run of <hyperopt.fmin.FMinIter object>>
        self.max_evals = 9223372036854775807
        n_done = 0
        self.asynchronous = False
    279         self.trials.refresh()
    280         return self
    281 
    282 

...........................................................................
/home/aquemy/dev/dp_hyperparameters/extension/hyperopt/fmin.py in run(self=<hyperopt.fmin.FMinIter object>, N=9223372036854775807, block_until_done=False)
    232                     if self.asynchronous:
    233                         # -- wait for workers to fill in the trials
    234                         time.sleep(self.poll_interval_secs)
    235                     else:
    236                         # -- loop over trials and do the jobs directly
--> 237                         self.serial_evaluate()
        self.serial_evaluate = <bound method FMinIter.serial_evaluate of <hyperopt.fmin.FMinIter object>>
    238                     try:
    239                         res = [d['result']['loss'] for d in
    240                                          self.trials.trials if
    241                                          d['result']['status'] == 'ok']

...........................................................................
/home/aquemy/dev/dp_hyperparameters/extension/hyperopt/fmin.py in serial_evaluate(self=<hyperopt.fmin.FMinIter object>, N=-1)
    138                 trial['book_time'] = now
    139                 trial['refresh_time'] = now
    140                 spec = base.spec_from_misc(trial['misc'])
    141                 ctrl = base.Ctrl(self.trials, current_trial=trial)
    142                 try:
--> 143                     result = self.domain.evaluate(spec, ctrl)
        result = undefined
        self.domain.evaluate = <bound method Domain.evaluate of <hyperopt.base.Domain object>>
        spec = {'criterion': 0, 'max_depth': 1, 'max_features': 1, 'max_leaf_nodes': 3, 'min_samples_leaf': 3, 'min_samples_split': 2, 'splitter': 1}
        ctrl = <hyperopt.base.Ctrl object>
    144                 except Exception as e:
    145                     logger.info('job exception: %s' % str(e))
    146                     trial['state'] = base.JOB_STATE_ERROR
    147                     trial['misc']['error'] = (str(type(e)), str(e))

...........................................................................
/home/aquemy/dev/dp_hyperparameters/extension/hyperopt/base.py in evaluate(self=<hyperopt.base.Domain object>, config={'criterion': 0, 'max_depth': 1, 'max_features': 1, 'max_leaf_nodes': 3, 'min_samples_leaf': 3, 'min_samples_split': 2, 'splitter': 1}, ctrl=<hyperopt.base.Ctrl object>, attach_attachments=True)
    841             #    or the normal Python part (self.fn)
    842             pyll_rval = pyll.rec_eval(
    843                 self.expr,
    844                 memo=memo,
    845                 print_node_on_error=self.rec_eval_print_node_on_error)
--> 846             rval = self.fn(pyll_rval)
        rval = undefined
        self.fn = <functools.partial object>
        pyll_rval = {'criterion': 'gini', 'max_depth': 2, 'max_features': 2, 'max_leaf_nodes': None, 'min_samples_leaf': 4, 'min_samples_split': 5, 'splitter': 'random'}
    847 
    848         if isinstance(rval, (float, int, np.number)):
    849             dict_rval = {'loss': float(rval), 'status': STATUS_OK}
    850         else:

...........................................................................
/home/aquemy/dev/dp_hyperparameters/extension/experiment/objective.py in objective_algo(algo_config={'criterion': 'gini', 'max_depth': 2, 'max_features': 2, 'max_leaf_nodes': None, 'min_samples_leaf': 4, 'min_samples_split': 5, 'splitter': 'random'}, current_pipeline_config={'features': ('features_PCA', {'features__n_components': 1}), 'normalizer': ('normalizer_StandardScaler', {'normalizer__with_mean': True, 'normalizer__with_std': True}), 'rebalance': ('rebalance_CondensedNearestNeighbour', {'rebalance__n_neighbors': 3})}, algorithm='DecisionTree', X=array([[ 0.,  0.,  5., ...,  0.,  0.,  0.],
    ...0.],
       [ 0.,  0., 10., ..., 12.,  1.,  0.]]), y=array([0, 1, 2, ..., 8, 9, 8]), context={'baseline_score': 0.8370850802141552, 'baseline_score_std': 0.04023050598893108, 'best_config': {'algorithm': {}, 'config_hash': {'algorithm': 'bf21a9e8fbc5a3846fb05b4fa0859e0917b2202f', 'config': 'ca5ca4efa90c01bc7221121efcc4d9c81cc5f6d0', 'pipeline': 'e7db9df9682e59ebeb9a13264e2de218c38a3119'}, 'duration': 20.03913402557373, 'iteration': 0, 'loss': 0.8859695582333075, 'max_history_score': 0.1140304417666925, 'max_history_score_std': 0.0205735154132599, 'max_history_step': 'pipeline', 'pipeline': {'features': ('features_PCA', {'features__n_components': 1}), 'normalizer': ('normalizer_StandardScaler', {'normalizer__with_mean': True, 'normalizer__with_std': True}), 'rebalance': ('rebalance_CondensedNearestNeighbour', {'rebalance__n_neighbors': 3})}, 'score': 0.1140304417666925, ...}, 'history': [{'algorithm': {}, 'config_hash': {'algorithm': 'bf21a9e8fbc5a3846fb05b4fa0859e0917b2202f', 'config': 'ca5ca4efa90c01bc7221121efcc4d9c81cc5f6d0', 'pipeline': 'e7db9df9682e59ebeb9a13264e2de218c38a3119'}, 'duration': 20.03913402557373, 'iteration': 0, 'loss': 0.8859695582333075, 'max_history_score': 0.1140304417666925, 'max_history_score_std': 0.0205735154132599, 'max_history_step': 'pipeline', 'pipeline': {'features': ('features_PCA', {'features__n_components': 1}), 'normalizer': ('normalizer_StandardScaler', {'normalizer__with_mean': True, 'normalizer__with_std': True}), 'rebalance': ('rebalance_CondensedNearestNeighbour', {'rebalance__n_neighbors': 3})}, 'score': 0.1140304417666925, ...}], 'history_hash': ['ca5ca4efa90c01bc7221121efcc4d9c81cc5f6d0'], 'history_index': {'ca5ca4efa90c01bc7221121efcc4d9c81cc5f6d0': 0}, 'iteration': 0, 'max_history_score': 0.1140304417666925, 'max_history_score_std': 0.0205735154132599, 'max_history_step': 'pipeline'}, config={'algorithm': 'DecisionTree', 'reset_trial': False, 'seed': 42, 'step_algorithm': 15, 'step_pipeline': 15, 'time': 300})
    105 
    106 def objective_pipeline(pipeline_config, current_algo_config, algorithm, X, y, context, config):
    107     return objective(pipeline_config, current_algo_config, algorithm, X, y, context, config, step='pipeline')
    108 
    109 def objective_algo(algo_config, current_pipeline_config, algorithm, X, y, context, config):
--> 110     return objective(current_pipeline_config, algo_config, algorithm, X, y, context, config, step='algorithm')
        current_pipeline_config = {'features': ('features_PCA', {'features__n_components': 1}), 'normalizer': ('normalizer_StandardScaler', {'normalizer__with_mean': True, 'normalizer__with_std': True}), 'rebalance': ('rebalance_CondensedNearestNeighbour', {'rebalance__n_neighbors': 3})}
        algo_config = {'criterion': 'gini', 'max_depth': 2, 'max_features': 2, 'max_leaf_nodes': None, 'min_samples_leaf': 4, 'min_samples_split': 5, 'splitter': 'random'}
        algorithm = 'DecisionTree'
        X = array([[ 0.,  0.,  5., ...,  0.,  0.,  0.],
    ...0.],
       [ 0.,  0., 10., ..., 12.,  1.,  0.]])
        y = array([0, 1, 2, ..., 8, 9, 8])
        context = {'baseline_score': 0.8370850802141552, 'baseline_score_std': 0.04023050598893108, 'best_config': {'algorithm': {}, 'config_hash': {'algorithm': 'bf21a9e8fbc5a3846fb05b4fa0859e0917b2202f', 'config': 'ca5ca4efa90c01bc7221121efcc4d9c81cc5f6d0', 'pipeline': 'e7db9df9682e59ebeb9a13264e2de218c38a3119'}, 'duration': 20.03913402557373, 'iteration': 0, 'loss': 0.8859695582333075, 'max_history_score': 0.1140304417666925, 'max_history_score_std': 0.0205735154132599, 'max_history_step': 'pipeline', 'pipeline': {'features': ('features_PCA', {'features__n_components': 1}), 'normalizer': ('normalizer_StandardScaler', {'normalizer__with_mean': True, 'normalizer__with_std': True}), 'rebalance': ('rebalance_CondensedNearestNeighbour', {'rebalance__n_neighbors': 3})}, 'score': 0.1140304417666925, ...}, 'history': [{'algorithm': {}, 'config_hash': {'algorithm': 'bf21a9e8fbc5a3846fb05b4fa0859e0917b2202f', 'config': 'ca5ca4efa90c01bc7221121efcc4d9c81cc5f6d0', 'pipeline': 'e7db9df9682e59ebeb9a13264e2de218c38a3119'}, 'duration': 20.03913402557373, 'iteration': 0, 'loss': 0.8859695582333075, 'max_history_score': 0.1140304417666925, 'max_history_score_std': 0.0205735154132599, 'max_history_step': 'pipeline', 'pipeline': {'features': ('features_PCA', {'features__n_components': 1}), 'normalizer': ('normalizer_StandardScaler', {'normalizer__with_mean': True, 'normalizer__with_std': True}), 'rebalance': ('rebalance_CondensedNearestNeighbour', {'rebalance__n_neighbors': 3})}, 'score': 0.1140304417666925, ...}], 'history_hash': ['ca5ca4efa90c01bc7221121efcc4d9c81cc5f6d0'], 'history_index': {'ca5ca4efa90c01bc7221121efcc4d9c81cc5f6d0': 0}, 'iteration': 0, 'max_history_score': 0.1140304417666925, 'max_history_score_std': 0.0205735154132599, 'max_history_step': 'pipeline'}
        config = {'algorithm': 'DecisionTree', 'reset_trial': False, 'seed': 42, 'step_algorithm': 15, 'step_pipeline': 15, 'time': 300}
    111 
    112 def get_baseline_score(algorithm, X, y, seed):
    113     pipeline, _ = pipeline_conf_to_full_pipeline(
    114         get_baseline(), 

...........................................................................
/home/aquemy/dev/dp_hyperparameters/extension/experiment/objective.py in objective(pipeline_config={'features': ('features_PCA', {'features__n_components': 1}), 'normalizer': ('normalizer_StandardScaler', {'normalizer__with_mean': True, 'normalizer__with_std': True}), 'rebalance': ('rebalance_CondensedNearestNeighbour', {'rebalance__n_neighbors': 3})}, algo_config={'criterion': 'gini', 'max_depth': 2, 'max_features': 2, 'max_leaf_nodes': None, 'min_samples_leaf': 4, 'min_samples_split': 5, 'splitter': 'random'}, algorithm='DecisionTree', X=array([[ 0.,  0.,  5., ...,  0.,  0.,  0.],
    ...0.],
       [ 0.,  0., 10., ..., 12.,  1.,  0.]]), y=array([0, 1, 2, ..., 8, 9, 8]), context={'baseline_score': 0.8370850802141552, 'baseline_score_std': 0.04023050598893108, 'best_config': {'algorithm': {}, 'config_hash': {'algorithm': 'bf21a9e8fbc5a3846fb05b4fa0859e0917b2202f', 'config': 'ca5ca4efa90c01bc7221121efcc4d9c81cc5f6d0', 'pipeline': 'e7db9df9682e59ebeb9a13264e2de218c38a3119'}, 'duration': 20.03913402557373, 'iteration': 0, 'loss': 0.8859695582333075, 'max_history_score': 0.1140304417666925, 'max_history_score_std': 0.0205735154132599, 'max_history_step': 'pipeline', 'pipeline': {'features': ('features_PCA', {'features__n_components': 1}), 'normalizer': ('normalizer_StandardScaler', {'normalizer__with_mean': True, 'normalizer__with_std': True}), 'rebalance': ('rebalance_CondensedNearestNeighbour', {'rebalance__n_neighbors': 3})}, 'score': 0.1140304417666925, ...}, 'history': [{'algorithm': {}, 'config_hash': {'algorithm': 'bf21a9e8fbc5a3846fb05b4fa0859e0917b2202f', 'config': 'ca5ca4efa90c01bc7221121efcc4d9c81cc5f6d0', 'pipeline': 'e7db9df9682e59ebeb9a13264e2de218c38a3119'}, 'duration': 20.03913402557373, 'iteration': 0, 'loss': 0.8859695582333075, 'max_history_score': 0.1140304417666925, 'max_history_score_std': 0.0205735154132599, 'max_history_step': 'pipeline', 'pipeline': {'features': ('features_PCA', {'features__n_components': 1}), 'normalizer': ('normalizer_StandardScaler', {'normalizer__with_mean': True, 'normalizer__with_std': True}), 'rebalance': ('rebalance_CondensedNearestNeighbour', {'rebalance__n_neighbors': 3})}, 'score': 0.1140304417666925, ...}], 'history_hash': ['ca5ca4efa90c01bc7221121efcc4d9c81cc5f6d0'], 'history_index': {'ca5ca4efa90c01bc7221121efcc4d9c81cc5f6d0': 0}, 'iteration': 0, 'max_history_score': 0.1140304417666925, 'max_history_score_std': 0.0205735154132599, 'max_history_step': 'pipeline'}, config={'algorithm': 'DecisionTree', 'reset_trial': False, 'seed': 42, 'step_algorithm': 15, 'step_pipeline': 15, 'time': 300}, step='algorithm')
     45                 y,
     46                 cv=10,
     47                 n_jobs=-1,
     48                 return_estimator=False,
     49                 return_train_score=False,
---> 50                 verbose=0)
     51         score = np.mean(scores['test_score'])
     52         std = np.std(scores['test_score'])
     53         status = STATUS_OK
     54     except Exception as e:

...........................................................................
/home/aquemy/.local/lib/python2.7/site-packages/sklearn/model_selection/_validation.py in cross_validate(estimator=Pipeline(memory=None,
     steps=[('rebalance', ...ort=False, random_state=42, splitter='random'))]), X=array([[ 0.,  0.,  5., ...,  0.,  0.,  0.],
    ...0.],
       [ 0.,  0., 10., ..., 12.,  1.,  0.]]), y=array([0, 1, 2, ..., 8, 9, 8]), groups=None, scoring=None, cv=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1, verbose=0, fit_params=None, pre_dispatch='2*n_jobs', return_train_score=False, return_estimator=False, error_score='raise-deprecating')
    235         delayed(_fit_and_score)(
    236             clone(estimator), X, y, scorers, train, test, verbose, None,
    237             fit_params, return_train_score=return_train_score,
    238             return_times=True, return_estimator=return_estimator,
    239             error_score=error_score)
--> 240         for train, test in cv.split(X, y, groups))
        cv.split = <bound method StratifiedKFold.split of Stratifie...d(n_splits=10, random_state=None, shuffle=False)>
        X = array([[ 0.,  0.,  5., ...,  0.,  0.,  0.],
    ...0.],
       [ 0.,  0., 10., ..., 12.,  1.,  0.]])
        y = array([0, 1, 2, ..., 8, 9, 8])
        groups = None
    241 
    242     zipped_scores = list(zip(*scores))
    243     if return_train_score:
    244         train_scores = zipped_scores.pop(0)

...........................................................................
/home/aquemy/.local/lib/python2.7/site-packages/sklearn/externals/joblib/parallel.py in __call__(self=Parallel(n_jobs=-1), iterable=<generator object <genexpr>>)
    925                 # No need to wait for async callbacks to trigger to
    926                 # consumption.
    927                 self._iterating = False
    928 
    929             with self._backend.retrieval_context():
--> 930                 self.retrieve()
        self.retrieve = <bound method Parallel.retrieve of Parallel(n_jobs=-1)>
    931             # Make sure that we get a last message telling us we are done
    932             elapsed_time = time.time() - self._start_time
    933             self._print('Done %3i out of %3i | elapsed: %s finished',
    934                         (len(self._output), len(self._output),

---------------------------------------------------------------------------
Joblib worker traceback:
---------------------------------------------------------------------------
ValueError                                         Wed Jun  5 18:33:17 2019
PID: 6784                                   Python 2.7.15+: /usr/bin/python
...........................................................................
/home/aquemy/.local/lib/python2.7/site-packages/sklearn/externals/joblib/parallel.py in __call__(self=<sklearn.externals.joblib.parallel.BatchedCalls object>)
    220     def __call__(self):
    221         # Set the default nested backend to self._backend but do not set the
    222         # change the default number of processes to -1
    223         with parallel_backend(self._backend, n_jobs=self._n_jobs):
    224             return [func(*args, **kwargs)
--> 225                     for func, args, kwargs in self.items]
        func = <function _fit_and_score>
        args = (Pipeline(memory=None,
     steps=[('rebalance', ...ort=False, random_state=42, splitter='random'))]), array([[ 0.,  0.,  5., ...,  0.,  0.,  0.],
    ...0.],
       [ 0.,  0., 10., ..., 12.,  1.,  0.]]), array([0, 1, 2, ..., 8, 9, 8]), {'score': <function _passthrough_scorer>}, array([ 169,  176,  178, ..., 1794, 1795, 1796]), array([  0,   1,   2,   3,   4,   5,   6,   7,  ..., 181, 186, 188, 189, 190,
       194, 195, 198]), 0, None, None)
        kwargs = {'error_score': 'raise-deprecating', 'return_estimator': False, 'return_times': True, 'return_train_score': False}
        self.items = [(<function _fit_and_score>, (Pipeline(memory=None,
     steps=[('rebalance', ...ort=False, random_state=42, splitter='random'))]), array([[ 0.,  0.,  5., ...,  0.,  0.,  0.],
    ...0.],
       [ 0.,  0., 10., ..., 12.,  1.,  0.]]), array([0, 1, 2, ..., 8, 9, 8]), {'score': <function _passthrough_scorer>}, array([ 169,  176,  178, ..., 1794, 1795, 1796]), array([  0,   1,   2,   3,   4,   5,   6,   7,  ..., 181, 186, 188, 189, 190,
       194, 195, 198]), 0, None, None), {'error_score': 'raise-deprecating', 'return_estimator': False, 'return_times': True, 'return_train_score': False})]
    226 
    227     def __len__(self):
    228         return self._size
    229 

...........................................................................
/home/aquemy/.local/lib/python2.7/site-packages/sklearn/model_selection/_validation.py in _fit_and_score(estimator=Pipeline(memory=None,
     steps=[('rebalance', ...ort=False, random_state=42, splitter='random'))]), X=array([[ 0.,  0.,  5., ...,  0.,  0.,  0.],
    ...0.],
       [ 0.,  0., 10., ..., 12.,  1.,  0.]]), y=array([0, 1, 2, ..., 8, 9, 8]), scorer={'score': <function _passthrough_scorer>}, train=array([ 169,  176,  178, ..., 1794, 1795, 1796]), test=array([  0,   1,   2,   3,   4,   5,   6,   7,  ..., 181, 186, 188, 189, 190,
       194, 195, 198]), verbose=0, parameters=None, fit_params={}, return_train_score=False, return_parameters=False, return_n_test_samples=False, return_times=True, return_estimator=False, error_score='raise-deprecating')
    523 
    524     try:
    525         if y_train is None:
    526             estimator.fit(X_train, **fit_params)
    527         else:
--> 528             estimator.fit(X_train, y_train, **fit_params)
        estimator.fit = <bound method Pipeline.fit of Pipeline(memory=No...rt=False, random_state=42, splitter='random'))])>
        X_train = array([[ 0.,  0.,  6., ...,  9.,  4.,  0.],
    ...0.],
       [ 0.,  0., 10., ..., 12.,  1.,  0.]])
        y_train = array([9, 5, 0, ..., 8, 9, 8])
        fit_params = {}
    529 
    530     except Exception as e:
    531         # Note fit time as time until error
    532         fit_time = time.time() - start_time

...........................................................................
/usr/local/lib/python2.7/dist-packages/imblearn/pipeline.py in fit(self=Pipeline(memory=None,
     steps=[('rebalance', ...ort=False, random_state=42, splitter='random'))]), X=array([[ 0.,  0.,  6., ...,  9.,  4.,  0.],
    ...0.],
       [ 0.,  0., 10., ..., 12.,  1.,  0.]]), y=array([9, 5, 0, ..., 8, 9, 8]), **fit_params={})
    234             This estimator
    235 
    236         """
    237         Xt, yt, fit_params = self._fit(X, y, **fit_params)
    238         if self._final_estimator is not None:
--> 239             self._final_estimator.fit(Xt, yt, **fit_params)
        self._final_estimator.fit = <bound method DecisionTreeClassifier.fit of Deci...esort=False, random_state=42, splitter='random')>
        Xt = array([[ 2.37358536e+00],
       [ 2.58536572e+0...    [-7.18972222e-01],
       [-2.69868014e+00]])
        yt = array([0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1,...9, 9, 9, 9, 9,
       9, 9, 9, 9, 9, 9, 9, 9, 9])
        fit_params = {}
    240         return self
    241 
    242     def fit_transform(self, X, y=None, **fit_params):
    243         """Fit the model and transform with the final estimator

...........................................................................
/home/aquemy/.local/lib/python2.7/site-packages/sklearn/tree/tree.py in fit(self=DecisionTreeClassifier(class_weight=None, criter...resort=False, random_state=42, splitter='random'), X=array([[ 2.37358536e+00],
       [ 2.58536572e+0...    [-7.18972222e-01],
       [-2.69868014e+00]]), y=array([0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1,...9, 9, 9, 9, 9,
       9, 9, 9, 9, 9, 9, 9, 9, 9]), sample_weight=None, check_input=True, X_idx_sorted=None)
    796 
    797         super(DecisionTreeClassifier, self).fit(
    798             X, y,
    799             sample_weight=sample_weight,
    800             check_input=check_input,
--> 801             X_idx_sorted=X_idx_sorted)
        X_idx_sorted = None
    802         return self
    803 
    804     def predict_proba(self, X, check_input=True):
    805         """Predict class probabilities of the input samples X.

...........................................................................
/home/aquemy/.local/lib/python2.7/site-packages/sklearn/tree/tree.py in fit(self=DecisionTreeClassifier(class_weight=None, criter...resort=False, random_state=42, splitter='random'), X=array([[ 2.37358546e+00],
       [ 2.58536577e+0...6e-01],
       [-2.69868016e+00]], dtype=float32), y=array([[0.],
       [0.],
       [0.],
       [0...    [9.],
       [9.],
       [9.],
       [9.]]), sample_weight=None, check_input=True, X_idx_sorted=None)
    237         if not 0 <= self.min_weight_fraction_leaf <= 0.5:
    238             raise ValueError("min_weight_fraction_leaf must in [0, 0.5]")
    239         if max_depth <= 0:
    240             raise ValueError("max_depth must be greater than zero. ")
    241         if not (0 < max_features <= self.n_features_):
--> 242             raise ValueError("max_features must be in (0, n_features]")
    243         if not isinstance(max_leaf_nodes, (numbers.Integral, np.integer)):
    244             raise ValueError("max_leaf_nodes must be integral number but was "
    245                              "%r" % max_leaf_nodes)
    246         if -1 < max_leaf_nodes < 2:

ValueError: max_features must be in (0, n_features]
___________________________________________________________________________
Best score: 0.114030441767 (0.0205735154133) [P] | Score: 0.0 (0.0) [A]
Best score: 0.114030441767 (0.0205735154133) [P] | Score: 0.104631395298 (0.0211841881619) [A]
#################### STEP RESULT ####################
BEST PIPELINE:
 {
    "features": [
        "features_PCA", 
        {
            "features__n_components": 1
        }
    ], 
    "normalizer": [
        "normalizer_StandardScaler", 
        {
            "normalizer__with_mean": true, 
            "normalizer__with_std": true
        }
    ], 
    "rebalance": [
        "rebalance_CondensedNearestNeighbour", 
        {
            "rebalance__n_neighbors": 3
        }
    ]
}
BEST ALGO CONFIG:
 {}
BEST SCORE: 0.114030441767 (0.0205735154133)
##################################################
## Data Pipeline
Best score: 0.251186166993 (0.0715432526326) [P] | Score: 0.251186166993 (0.0715432526326) [P]
Best score: 0.462926431996 (0.0420554023357) [P] | Score: 0.462926431996 (0.0420554023357) [P]
#################### STEP RESULT ####################
BEST PIPELINE:
 {
    "features": [
        "features_FeatureUnion", 
        {
            "features__pca__n_components": 4, 
            "features__selectkbest__k": 2
        }
    ], 
    "normalizer": [
        "normalizer_NoneType", 
        {}
    ], 
    "rebalance": [
        "rebalance_CondensedNearestNeighbour", 
        {
            "rebalance__n_neighbors": 3
        }
    ]
}
BEST ALGO CONFIG:
 {}
BEST SCORE: 0.462926431996 (0.0420554023357)
##################################################
## Algorithm
Best score: 0.462926431996 (0.0420554023357) [P] | Score: 0.184809850273 (0.0586185170689) [A]
#################### STEP RESULT ####################
BEST PIPELINE:
 {
    "features": [
        "features_FeatureUnion", 
        {
            "features__pca__n_components": 4, 
            "features__selectkbest__k": 2
        }
    ], 
    "normalizer": [
        "normalizer_NoneType", 
        {}
    ], 
    "rebalance": [
        "rebalance_CondensedNearestNeighbour", 
        {
            "rebalance__n_neighbors": 3
        }
    ]
}
BEST ALGO CONFIG:
 {}
BEST SCORE: 0.462926431996 (0.0420554023357)
##################################################
## Data Pipeline
Best score: 0.462926431996 (0.0420554023357) [P] | Score: 0.426442142233 (0.0557414244765) [P]
Best score: 0.462926431996 (0.0420554023357) [P] | Score: 0.45260640488 (0.0453514153246) [P]
Best score: 0.546592204774 (0.0415727129458) [P] | Score: 0.546592204774 (0.0415727129458) [P]
#################### STEP RESULT ####################
BEST PIPELINE:
 {
    "features": [
        "features_PCA", 
        {
            "features__n_components": 2
        }
    ], 
    "normalizer": [
        "normalizer_MinMaxScaler", 
        {}
    ], 
    "rebalance": [
        "rebalance_NoneType", 
        {}
    ]
}
BEST ALGO CONFIG:
 {}
BEST SCORE: 0.546592204774 (0.0415727129458)
##################################################
## Algorithm
JoblibValueError
___________________________________________________________________________
...........................................................................
/home/aquemy/dev/dp_hyperparameters/extension/main.py in <module>()
     27 
     28     serializer.serialize_results(scenario, policy)
     29 
     30 if __name__ == "__main__":
     31     args = cli.parse_args()
---> 32     main(args)

...........................................................................
/home/aquemy/dev/dp_hyperparameters/extension/main.py in main(args=Namespace(customize=[(['control', 'seed'], '42')...scenarios/dt_digits_iterative.yaml', verbosity=0))
     21         test_size=0.4, 
     22         random_state=scenario['control']['seed']
     23     )
     24 
     25     policy = policies.initiate(scenario['setup']['policy'], config)
---> 26     policy.run(X,y)
        policy.run = <bound method Iterative.run of <experiment.policies.iterative.Iterative object>>
        X = array([[ 0.,  0.,  5., ...,  0.,  0.,  0.],
    ...0.],
       [ 0.,  0., 10., ..., 12.,  1.,  0.]])
        y = array([0, 1, 2, ..., 8, 9, 8])
     27 
     28     serializer.serialize_results(scenario, policy)
     29 
     30 if __name__ == "__main__":

...........................................................................
/home/aquemy/dev/dp_hyperparameters/extension/experiment/policies/iterative.py in run(self=<experiment.policies.iterative.Iterative object>, X=array([[ 0.,  0.,  5., ...,  0.,  0.,  0.],
    ...0.],
       [ 0.,  0., 10., ..., 12.,  1.,  0.]]), y=array([0, 1, 2, ..., 8, 9, 8]))
     59                 algo=tpe.suggest, 
     60                 max_evals=None,
     61                 max_time=self.config['step_algorithm'],
     62                 trials=trials_algo,
     63                 show_progressbar=False,
---> 64                 verbose=0
     65             )
     66             best_config = self.context['best_config']
     67             current_pipeline_configuration = best_config['pipeline']
     68             super(Iterative, self).display_step_results(best_config)

...........................................................................
/home/aquemy/dev/dp_hyperparameters/extension/hyperopt/fmin.py in fmin(fn=<functools.partial object>, space={'criterion': <hyperopt.pyll.base.Apply object>, 'max_depth': <hyperopt.pyll.base.Apply object>, 'max_features': <hyperopt.pyll.base.Apply object>, 'max_leaf_nodes': <hyperopt.pyll.base.Apply object>, 'min_samples_leaf': <hyperopt.pyll.base.Apply object>, 'min_samples_split': <hyperopt.pyll.base.Apply object>, 'splitter': <hyperopt.pyll.base.Apply object>}, algo=<function suggest>, max_evals=9223372036854775807, max_time=15, trials=<hyperopt.base.Trials object>, rstate=<mtrand.RandomState object>, allow_trials_fmin=True, pass_expr_memo_ctrl=None, catch_eval_exceptions=False, verbose=0, return_argmin=True, points_to_evaluate=None, max_queue_len=1, show_progressbar=False)
    406             pass_expr_memo_ctrl=pass_expr_memo_ctrl,
    407             verbose=verbose,
    408             catch_eval_exceptions=catch_eval_exceptions,
    409             return_argmin=return_argmin,
    410             show_progressbar=show_progressbar,
--> 411             max_time=max_time
        max_time = 15
    412         )
    413 
    414     if trials is None:
    415         if points_to_evaluate is None:

...........................................................................
/home/aquemy/dev/dp_hyperparameters/extension/hyperopt/base.py in fmin(self=<hyperopt.base.Trials object>, fn=<functools.partial object>, space={'criterion': <hyperopt.pyll.base.Apply object>, 'max_depth': <hyperopt.pyll.base.Apply object>, 'max_features': <hyperopt.pyll.base.Apply object>, 'max_leaf_nodes': <hyperopt.pyll.base.Apply object>, 'min_samples_leaf': <hyperopt.pyll.base.Apply object>, 'min_samples_split': <hyperopt.pyll.base.Apply object>, 'splitter': <hyperopt.pyll.base.Apply object>}, algo=<function suggest>, max_evals=9223372036854775807, max_time=15, rstate=<mtrand.RandomState object>, verbose=0, pass_expr_memo_ctrl=None, catch_eval_exceptions=False, return_argmin=True, show_progressbar=False)
    636             verbose=verbose,
    637             allow_trials_fmin=False,  # -- prevent recursion
    638             pass_expr_memo_ctrl=pass_expr_memo_ctrl,
    639             catch_eval_exceptions=catch_eval_exceptions,
    640             return_argmin=return_argmin,
--> 641             show_progressbar=show_progressbar)
        show_progressbar = False
    642 
    643 
    644 def trials_from_docs(docs, validate=True, **kwargs):
    645     """Construct a Trials base class instance from a list of trials documents

...........................................................................
/home/aquemy/dev/dp_hyperparameters/extension/hyperopt/fmin.py in fmin(fn=<functools.partial object>, space={'criterion': <hyperopt.pyll.base.Apply object>, 'max_depth': <hyperopt.pyll.base.Apply object>, 'max_features': <hyperopt.pyll.base.Apply object>, 'max_leaf_nodes': <hyperopt.pyll.base.Apply object>, 'min_samples_leaf': <hyperopt.pyll.base.Apply object>, 'min_samples_split': <hyperopt.pyll.base.Apply object>, 'splitter': <hyperopt.pyll.base.Apply object>}, algo=<function suggest>, max_evals=9223372036854775807, max_time=15, trials=<hyperopt.base.Trials object>, rstate=<mtrand.RandomState object>, allow_trials_fmin=False, pass_expr_memo_ctrl=None, catch_eval_exceptions=False, verbose=0, return_argmin=True, points_to_evaluate=None, max_queue_len=1, show_progressbar=False)
    426                     verbose=verbose,
    427                     max_queue_len=max_queue_len,
    428                     show_progressbar=show_progressbar,
    429                     max_time=max_time)
    430     rval.catch_eval_exceptions = catch_eval_exceptions
--> 431     rval.exhaust()
        rval.exhaust = <bound method FMinIter.exhaust of <hyperopt.fmin.FMinIter object>>
    432     if return_argmin:
    433         return trials.argmin
    434     elif len(trials) > 0:
    435         # Only if there are some succesfull trail runs, return the best point in the evaluation space

...........................................................................
/home/aquemy/dev/dp_hyperparameters/extension/hyperopt/fmin.py in exhaust(self=<hyperopt.fmin.FMinIter object>)
    273             raise StopIteration()
    274         return self.trials
    275 
    276     def exhaust(self):
    277         n_done = len(self.trials)
--> 278         self.run(self.max_evals - n_done, block_until_done=self.asynchronous)
        self.run = <bound method FMinIter.run of <hyperopt.fmin.FMinIter object>>
        self.max_evals = 9223372036854775807
        n_done = 3
        self.asynchronous = False
    279         self.trials.refresh()
    280         return self
    281 
    282 

...........................................................................
/home/aquemy/dev/dp_hyperparameters/extension/hyperopt/fmin.py in run(self=<hyperopt.fmin.FMinIter object>, N=9223372036854775804, block_until_done=False)
    232                     if self.asynchronous:
    233                         # -- wait for workers to fill in the trials
    234                         time.sleep(self.poll_interval_secs)
    235                     else:
    236                         # -- loop over trials and do the jobs directly
--> 237                         self.serial_evaluate()
        self.serial_evaluate = <bound method FMinIter.serial_evaluate of <hyperopt.fmin.FMinIter object>>
    238                     try:
    239                         res = [d['result']['loss'] for d in
    240                                          self.trials.trials if
    241                                          d['result']['status'] == 'ok']

...........................................................................
/home/aquemy/dev/dp_hyperparameters/extension/hyperopt/fmin.py in serial_evaluate(self=<hyperopt.fmin.FMinIter object>, N=-1)
    138                 trial['book_time'] = now
    139                 trial['refresh_time'] = now
    140                 spec = base.spec_from_misc(trial['misc'])
    141                 ctrl = base.Ctrl(self.trials, current_trial=trial)
    142                 try:
--> 143                     result = self.domain.evaluate(spec, ctrl)
        result = undefined
        self.domain.evaluate = <bound method Domain.evaluate of <hyperopt.base.Domain object>>
        spec = {'criterion': 1, 'max_depth': 3, 'max_features': 2, 'max_leaf_nodes': 3, 'min_samples_leaf': 3, 'min_samples_split': 0, 'splitter': 1}
        ctrl = <hyperopt.base.Ctrl object>
    144                 except Exception as e:
    145                     logger.info('job exception: %s' % str(e))
    146                     trial['state'] = base.JOB_STATE_ERROR
    147                     trial['misc']['error'] = (str(type(e)), str(e))

...........................................................................
/home/aquemy/dev/dp_hyperparameters/extension/hyperopt/base.py in evaluate(self=<hyperopt.base.Domain object>, config={'criterion': 1, 'max_depth': 3, 'max_features': 2, 'max_leaf_nodes': 3, 'min_samples_leaf': 3, 'min_samples_split': 0, 'splitter': 1}, ctrl=<hyperopt.base.Ctrl object>, attach_attachments=True)
    841             #    or the normal Python part (self.fn)
    842             pyll_rval = pyll.rec_eval(
    843                 self.expr,
    844                 memo=memo,
    845                 print_node_on_error=self.rec_eval_print_node_on_error)
--> 846             rval = self.fn(pyll_rval)
        rval = undefined
        self.fn = <functools.partial object>
        pyll_rval = {'criterion': 'entropy', 'max_depth': 4, 'max_features': 3, 'max_leaf_nodes': None, 'min_samples_leaf': 4, 'min_samples_split': 2, 'splitter': 'random'}
    847 
    848         if isinstance(rval, (float, int, np.number)):
    849             dict_rval = {'loss': float(rval), 'status': STATUS_OK}
    850         else:

...........................................................................
/home/aquemy/dev/dp_hyperparameters/extension/experiment/objective.py in objective_algo(algo_config={'criterion': 'entropy', 'max_depth': 4, 'max_features': 3, 'max_leaf_nodes': None, 'min_samples_leaf': 4, 'min_samples_split': 2, 'splitter': 'random'}, current_pipeline_config={'features': ('features_PCA', {'features__n_components': 2}), 'normalizer': ('normalizer_MinMaxScaler', {}), 'rebalance': ('rebalance_NoneType', {})}, algorithm='DecisionTree', X=array([[ 0.,  0.,  5., ...,  0.,  0.,  0.],
    ...0.],
       [ 0.,  0., 10., ..., 12.,  1.,  0.]]), y=array([0, 1, 2, ..., 8, 9, 8]), context={'baseline_score': 0.8370850802141552, 'baseline_score_std': 0.04023050598893108, 'best_config': {'algorithm': {}, 'config_hash': {'algorithm': 'bf21a9e8fbc5a3846fb05b4fa0859e0917b2202f', 'config': '8c4b0ea4a817610a51d42d05534a015dbcf7d6f6', 'pipeline': '78028fec3489bc1290cd6e3a5ffef640e07fd746'}, 'duration': 1.01682710647583, 'iteration': 8, 'loss': 0.45340779522638897, 'max_history_score': 0.546592204773611, 'max_history_score_std': 0.04157271294583304, 'max_history_step': 'pipeline', 'pipeline': {'features': ('features_PCA', {'features__n_components': 2}), 'normalizer': ('normalizer_MinMaxScaler', {}), 'rebalance': ('rebalance_NoneType', {})}, 'score': 0.546592204773611, ...}, 'history': [{'algorithm': {}, 'config_hash': {'algorithm': 'bf21a9e8fbc5a3846fb05b4fa0859e0917b2202f', 'config': 'ca5ca4efa90c01bc7221121efcc4d9c81cc5f6d0', 'pipeline': 'e7db9df9682e59ebeb9a13264e2de218c38a3119'}, 'duration': 20.03913402557373, 'iteration': 0, 'loss': 0.8859695582333075, 'max_history_score': 0.1140304417666925, 'max_history_score_std': 0.0205735154132599, 'max_history_step': 'pipeline', 'pipeline': {'features': ('features_PCA', {'features__n_components': 1}), 'normalizer': ('normalizer_StandardScaler', {'normalizer__with_mean': True, 'normalizer__with_std': True}), 'rebalance': ('rebalance_CondensedNearestNeighbour', {'rebalance__n_neighbors': 3})}, 'score': 0.1140304417666925, ...}, {'algorithm': {'criterion': 'gini', 'max_depth': 2, 'max_features': 2, 'max_leaf_nodes': None, 'min_samples_leaf': 4, 'min_samples_split': 5, 'splitter': 'random'}, 'config_hash': {'algorithm': 'c4587a515ec4d7862c26abb6c7b2069ec2788a3c', 'config': 'e2ef5dfe43753524001a5fcbab4886cbde2b3e42', 'pipeline': 'e7db9df9682e59ebeb9a13264e2de218c38a3119'}, 'duration': 7.673176050186157, 'iteration': 1, 'loss': 1.0, 'max_history_score': 0.1140304417666925, 'max_history_score_std': 0.0205735154132599, 'max_history_step': 'pipeline', 'pipeline': {'features': ('features_PCA', {'features__n_components': 1}), 'normalizer': ('normalizer_StandardScaler', {'normalizer__with_mean': True, 'normalizer__with_std': True}), 'rebalance': ('rebalance_CondensedNearestNeighbour', {'rebalance__n_neighbors': 3})}, 'score': 0.0, ...}, {'algorithm': {'criterion': 'gini', 'max_depth': 3, 'max_features': 1, 'max_leaf_nodes': 2, 'min_samples_leaf': 4, 'min_samples_split': 3, 'splitter': 'random'}, 'config_hash': {'algorithm': 'b8f20163e3a63f6d337affac58f19f59c1042fdf', 'config': '2c3bccf18791b309fa8b48e68103ac95d47230a3', 'pipeline': 'e7db9df9682e59ebeb9a13264e2de218c38a3119'}, 'duration': 21.382025003433228, 'iteration': 2, 'loss': 0.8953686047024499, 'max_history_score': 0.1140304417666925, 'max_history_score_std': 0.0205735154132599, 'max_history_step': 'pipeline', 'pipeline': {'features': ('features_PCA', {'features__n_components': 1}), 'normalizer': ('normalizer_StandardScaler', {'normalizer__with_mean': True, 'normalizer__with_std': True}), 'rebalance': ('rebalance_CondensedNearestNeighbour', {'rebalance__n_neighbors': 3})}, 'score': 0.10463139529755008, ...}, {'algorithm': {}, 'config_hash': {'algorithm': 'bf21a9e8fbc5a3846fb05b4fa0859e0917b2202f', 'config': '650d610fc79551ca01c9d51200374e435c9787c0', 'pipeline': '1ad3dcf81ee45846a12eb92026a29afcf2a1775b'}, 'duration': 12.787569999694824, 'iteration': 3, 'loss': 0.748813833006884, 'max_history_score': 0.251186166993116, 'max_history_score_std': 0.07154325263262472, 'max_history_step': 'pipeline', 'pipeline': {'features': ('features_SelectKBest', {'features__k': 2}), 'normalizer': ('normalizer_MinMaxScaler', {}), 'rebalance': ('rebalance_CondensedNearestNeighbour', {'rebalance__n_neighbors': 1})}, 'score': 0.251186166993116, ...}, {'algorithm': {}, 'config_hash': {'algorithm': 'bf21a9e8fbc5a3846fb05b4fa0859e0917b2202f', 'config': '1daa3503ea9eec94f212644bb7c537963ab2ac4e', 'pipeline': '2235081205d7d7fae0d7335c028eccad689bcf9c'}, 'duration': 20.381888151168823, 'iteration': 4, 'loss': 0.5370735680036086, 'max_history_score': 0.4629264319963914, 'max_history_score_std': 0.04205540233571201, 'max_history_step': 'pipeline', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 4, 'features__selectkbest__k': 2}), 'normalizer': ('normalizer_NoneType', {}), 'rebalance': ('rebalance_CondensedNearestNeighbour', {'rebalance__n_neighbors': 3})}, 'score': 0.4629264319963914, ...}, {'algorithm': {'criterion': 'entropy', 'max_depth': None, 'max_features': 1, 'max_leaf_nodes': 3, 'min_samples_leaf': 1, 'min_samples_split': 2, 'splitter': 'random'}, 'config_hash': {'algorithm': '71cd9bb7b8b0ff2a3dbdca44537bafc4f6b2c716', 'config': 'b35ef6c13761b660f5939aa43874dd8c140f716f', 'pipeline': '2235081205d7d7fae0d7335c028eccad689bcf9c'}, 'duration': 20.211046934127808, 'iteration': 5, 'loss': 0.8151901497270952, 'max_history_score': 0.4629264319963914, 'max_history_score_std': 0.04205540233571201, 'max_history_step': 'pipeline', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 4, 'features__selectkbest__k': 2}), 'normalizer': ('normalizer_NoneType', {}), 'rebalance': ('rebalance_CondensedNearestNeighbour', {'rebalance__n_neighbors': 3})}, 'score': 0.1848098502729048, ...}, {'algorithm': {}, 'config_hash': {'algorithm': 'bf21a9e8fbc5a3846fb05b4fa0859e0917b2202f', 'config': 'f74b7b5b829639de7187b0517124671171e3886c', 'pipeline': '0a79122f55ba7d73b9d4a4993303bd1034099fc4'}, 'duration': 13.524871110916138, 'iteration': 6, 'loss': 0.5735578577665785, 'max_history_score': 0.4629264319963914, 'max_history_score_std': 0.04205540233571201, 'max_history_step': 'pipeline', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 3, 'features__selectkbest__k': 4}), 'normalizer': ('normalizer_StandardScaler', {'normalizer__with_mean': True, 'normalizer__with_std': True}), 'rebalance': ('rebalance_CondensedNearestNeighbour', {'rebalance__n_neighbors': 1})}, 'score': 0.4264421422334214, ...}, {'algorithm': {}, 'config_hash': {'algorithm': 'bf21a9e8fbc5a3846fb05b4fa0859e0917b2202f', 'config': '1eabae8e59d372b076035bdac59106753d4c3143', 'pipeline': 'f671e39c7c21287c35cc86282770be08920b7211'}, 'duration': 0.7754909992218018, 'iteration': 7, 'loss': 0.5473935951203874, 'max_history_score': 0.4629264319963914, 'max_history_score_std': 0.04205540233571201, 'max_history_step': 'pipeline', 'pipeline': {'features': ('features_SelectKBest', {'features__k': 4}), 'normalizer': ('normalizer_NoneType', {}), 'rebalance': ('rebalance_NearMiss', {'rebalance__n_neighbors': 3})}, 'score': 0.4526064048796126, ...}, {'algorithm': {}, 'config_hash': {'algorithm': 'bf21a9e8fbc5a3846fb05b4fa0859e0917b2202f', 'config': '8c4b0ea4a817610a51d42d05534a015dbcf7d6f6', 'pipeline': '78028fec3489bc1290cd6e3a5ffef640e07fd746'}, 'duration': 1.01682710647583, 'iteration': 8, 'loss': 0.45340779522638897, 'max_history_score': 0.546592204773611, 'max_history_score_std': 0.04157271294583304, 'max_history_step': 'pipeline', 'pipeline': {'features': ('features_PCA', {'features__n_components': 2}), 'normalizer': ('normalizer_MinMaxScaler', {}), 'rebalance': ('rebalance_NoneType', {})}, 'score': 0.546592204773611, ...}], 'history_hash': ['ca5ca4efa90c01bc7221121efcc4d9c81cc5f6d0', 'e2ef5dfe43753524001a5fcbab4886cbde2b3e42', '2c3bccf18791b309fa8b48e68103ac95d47230a3', '650d610fc79551ca01c9d51200374e435c9787c0', '1daa3503ea9eec94f212644bb7c537963ab2ac4e', 'b35ef6c13761b660f5939aa43874dd8c140f716f', 'f74b7b5b829639de7187b0517124671171e3886c', '1eabae8e59d372b076035bdac59106753d4c3143', '8c4b0ea4a817610a51d42d05534a015dbcf7d6f6'], 'history_index': {'1daa3503ea9eec94f212644bb7c537963ab2ac4e': 4, '1eabae8e59d372b076035bdac59106753d4c3143': 7, '2c3bccf18791b309fa8b48e68103ac95d47230a3': 2, '650d610fc79551ca01c9d51200374e435c9787c0': 3, '8c4b0ea4a817610a51d42d05534a015dbcf7d6f6': 8, 'b35ef6c13761b660f5939aa43874dd8c140f716f': 5, 'ca5ca4efa90c01bc7221121efcc4d9c81cc5f6d0': 0, 'e2ef5dfe43753524001a5fcbab4886cbde2b3e42': 1, 'f74b7b5b829639de7187b0517124671171e3886c': 6}, 'iteration': 8, 'max_history_score': 0.546592204773611, 'max_history_score_std': 0.04157271294583304, 'max_history_step': 'pipeline'}, config={'algorithm': 'DecisionTree', 'reset_trial': False, 'seed': 42, 'step_algorithm': 15, 'step_pipeline': 15, 'time': 300})
    105 
    106 def objective_pipeline(pipeline_config, current_algo_config, algorithm, X, y, context, config):
    107     return objective(pipeline_config, current_algo_config, algorithm, X, y, context, config, step='pipeline')
    108 
    109 def objective_algo(algo_config, current_pipeline_config, algorithm, X, y, context, config):
--> 110     return objective(current_pipeline_config, algo_config, algorithm, X, y, context, config, step='algorithm')
        current_pipeline_config = {'features': ('features_PCA', {'features__n_components': 2}), 'normalizer': ('normalizer_MinMaxScaler', {}), 'rebalance': ('rebalance_NoneType', {})}
        algo_config = {'criterion': 'entropy', 'max_depth': 4, 'max_features': 3, 'max_leaf_nodes': None, 'min_samples_leaf': 4, 'min_samples_split': 2, 'splitter': 'random'}
        algorithm = 'DecisionTree'
        X = array([[ 0.,  0.,  5., ...,  0.,  0.,  0.],
    ...0.],
       [ 0.,  0., 10., ..., 12.,  1.,  0.]])
        y = array([0, 1, 2, ..., 8, 9, 8])
        context = {'baseline_score': 0.8370850802141552, 'baseline_score_std': 0.04023050598893108, 'best_config': {'algorithm': {}, 'config_hash': {'algorithm': 'bf21a9e8fbc5a3846fb05b4fa0859e0917b2202f', 'config': '8c4b0ea4a817610a51d42d05534a015dbcf7d6f6', 'pipeline': '78028fec3489bc1290cd6e3a5ffef640e07fd746'}, 'duration': 1.01682710647583, 'iteration': 8, 'loss': 0.45340779522638897, 'max_history_score': 0.546592204773611, 'max_history_score_std': 0.04157271294583304, 'max_history_step': 'pipeline', 'pipeline': {'features': ('features_PCA', {'features__n_components': 2}), 'normalizer': ('normalizer_MinMaxScaler', {}), 'rebalance': ('rebalance_NoneType', {})}, 'score': 0.546592204773611, ...}, 'history': [{'algorithm': {}, 'config_hash': {'algorithm': 'bf21a9e8fbc5a3846fb05b4fa0859e0917b2202f', 'config': 'ca5ca4efa90c01bc7221121efcc4d9c81cc5f6d0', 'pipeline': 'e7db9df9682e59ebeb9a13264e2de218c38a3119'}, 'duration': 20.03913402557373, 'iteration': 0, 'loss': 0.8859695582333075, 'max_history_score': 0.1140304417666925, 'max_history_score_std': 0.0205735154132599, 'max_history_step': 'pipeline', 'pipeline': {'features': ('features_PCA', {'features__n_components': 1}), 'normalizer': ('normalizer_StandardScaler', {'normalizer__with_mean': True, 'normalizer__with_std': True}), 'rebalance': ('rebalance_CondensedNearestNeighbour', {'rebalance__n_neighbors': 3})}, 'score': 0.1140304417666925, ...}, {'algorithm': {'criterion': 'gini', 'max_depth': 2, 'max_features': 2, 'max_leaf_nodes': None, 'min_samples_leaf': 4, 'min_samples_split': 5, 'splitter': 'random'}, 'config_hash': {'algorithm': 'c4587a515ec4d7862c26abb6c7b2069ec2788a3c', 'config': 'e2ef5dfe43753524001a5fcbab4886cbde2b3e42', 'pipeline': 'e7db9df9682e59ebeb9a13264e2de218c38a3119'}, 'duration': 7.673176050186157, 'iteration': 1, 'loss': 1.0, 'max_history_score': 0.1140304417666925, 'max_history_score_std': 0.0205735154132599, 'max_history_step': 'pipeline', 'pipeline': {'features': ('features_PCA', {'features__n_components': 1}), 'normalizer': ('normalizer_StandardScaler', {'normalizer__with_mean': True, 'normalizer__with_std': True}), 'rebalance': ('rebalance_CondensedNearestNeighbour', {'rebalance__n_neighbors': 3})}, 'score': 0.0, ...}, {'algorithm': {'criterion': 'gini', 'max_depth': 3, 'max_features': 1, 'max_leaf_nodes': 2, 'min_samples_leaf': 4, 'min_samples_split': 3, 'splitter': 'random'}, 'config_hash': {'algorithm': 'b8f20163e3a63f6d337affac58f19f59c1042fdf', 'config': '2c3bccf18791b309fa8b48e68103ac95d47230a3', 'pipeline': 'e7db9df9682e59ebeb9a13264e2de218c38a3119'}, 'duration': 21.382025003433228, 'iteration': 2, 'loss': 0.8953686047024499, 'max_history_score': 0.1140304417666925, 'max_history_score_std': 0.0205735154132599, 'max_history_step': 'pipeline', 'pipeline': {'features': ('features_PCA', {'features__n_components': 1}), 'normalizer': ('normalizer_StandardScaler', {'normalizer__with_mean': True, 'normalizer__with_std': True}), 'rebalance': ('rebalance_CondensedNearestNeighbour', {'rebalance__n_neighbors': 3})}, 'score': 0.10463139529755008, ...}, {'algorithm': {}, 'config_hash': {'algorithm': 'bf21a9e8fbc5a3846fb05b4fa0859e0917b2202f', 'config': '650d610fc79551ca01c9d51200374e435c9787c0', 'pipeline': '1ad3dcf81ee45846a12eb92026a29afcf2a1775b'}, 'duration': 12.787569999694824, 'iteration': 3, 'loss': 0.748813833006884, 'max_history_score': 0.251186166993116, 'max_history_score_std': 0.07154325263262472, 'max_history_step': 'pipeline', 'pipeline': {'features': ('features_SelectKBest', {'features__k': 2}), 'normalizer': ('normalizer_MinMaxScaler', {}), 'rebalance': ('rebalance_CondensedNearestNeighbour', {'rebalance__n_neighbors': 1})}, 'score': 0.251186166993116, ...}, {'algorithm': {}, 'config_hash': {'algorithm': 'bf21a9e8fbc5a3846fb05b4fa0859e0917b2202f', 'config': '1daa3503ea9eec94f212644bb7c537963ab2ac4e', 'pipeline': '2235081205d7d7fae0d7335c028eccad689bcf9c'}, 'duration': 20.381888151168823, 'iteration': 4, 'loss': 0.5370735680036086, 'max_history_score': 0.4629264319963914, 'max_history_score_std': 0.04205540233571201, 'max_history_step': 'pipeline', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 4, 'features__selectkbest__k': 2}), 'normalizer': ('normalizer_NoneType', {}), 'rebalance': ('rebalance_CondensedNearestNeighbour', {'rebalance__n_neighbors': 3})}, 'score': 0.4629264319963914, ...}, {'algorithm': {'criterion': 'entropy', 'max_depth': None, 'max_features': 1, 'max_leaf_nodes': 3, 'min_samples_leaf': 1, 'min_samples_split': 2, 'splitter': 'random'}, 'config_hash': {'algorithm': '71cd9bb7b8b0ff2a3dbdca44537bafc4f6b2c716', 'config': 'b35ef6c13761b660f5939aa43874dd8c140f716f', 'pipeline': '2235081205d7d7fae0d7335c028eccad689bcf9c'}, 'duration': 20.211046934127808, 'iteration': 5, 'loss': 0.8151901497270952, 'max_history_score': 0.4629264319963914, 'max_history_score_std': 0.04205540233571201, 'max_history_step': 'pipeline', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 4, 'features__selectkbest__k': 2}), 'normalizer': ('normalizer_NoneType', {}), 'rebalance': ('rebalance_CondensedNearestNeighbour', {'rebalance__n_neighbors': 3})}, 'score': 0.1848098502729048, ...}, {'algorithm': {}, 'config_hash': {'algorithm': 'bf21a9e8fbc5a3846fb05b4fa0859e0917b2202f', 'config': 'f74b7b5b829639de7187b0517124671171e3886c', 'pipeline': '0a79122f55ba7d73b9d4a4993303bd1034099fc4'}, 'duration': 13.524871110916138, 'iteration': 6, 'loss': 0.5735578577665785, 'max_history_score': 0.4629264319963914, 'max_history_score_std': 0.04205540233571201, 'max_history_step': 'pipeline', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 3, 'features__selectkbest__k': 4}), 'normalizer': ('normalizer_StandardScaler', {'normalizer__with_mean': True, 'normalizer__with_std': True}), 'rebalance': ('rebalance_CondensedNearestNeighbour', {'rebalance__n_neighbors': 1})}, 'score': 0.4264421422334214, ...}, {'algorithm': {}, 'config_hash': {'algorithm': 'bf21a9e8fbc5a3846fb05b4fa0859e0917b2202f', 'config': '1eabae8e59d372b076035bdac59106753d4c3143', 'pipeline': 'f671e39c7c21287c35cc86282770be08920b7211'}, 'duration': 0.7754909992218018, 'iteration': 7, 'loss': 0.5473935951203874, 'max_history_score': 0.4629264319963914, 'max_history_score_std': 0.04205540233571201, 'max_history_step': 'pipeline', 'pipeline': {'features': ('features_SelectKBest', {'features__k': 4}), 'normalizer': ('normalizer_NoneType', {}), 'rebalance': ('rebalance_NearMiss', {'rebalance__n_neighbors': 3})}, 'score': 0.4526064048796126, ...}, {'algorithm': {}, 'config_hash': {'algorithm': 'bf21a9e8fbc5a3846fb05b4fa0859e0917b2202f', 'config': '8c4b0ea4a817610a51d42d05534a015dbcf7d6f6', 'pipeline': '78028fec3489bc1290cd6e3a5ffef640e07fd746'}, 'duration': 1.01682710647583, 'iteration': 8, 'loss': 0.45340779522638897, 'max_history_score': 0.546592204773611, 'max_history_score_std': 0.04157271294583304, 'max_history_step': 'pipeline', 'pipeline': {'features': ('features_PCA', {'features__n_components': 2}), 'normalizer': ('normalizer_MinMaxScaler', {}), 'rebalance': ('rebalance_NoneType', {})}, 'score': 0.546592204773611, ...}], 'history_hash': ['ca5ca4efa90c01bc7221121efcc4d9c81cc5f6d0', 'e2ef5dfe43753524001a5fcbab4886cbde2b3e42', '2c3bccf18791b309fa8b48e68103ac95d47230a3', '650d610fc79551ca01c9d51200374e435c9787c0', '1daa3503ea9eec94f212644bb7c537963ab2ac4e', 'b35ef6c13761b660f5939aa43874dd8c140f716f', 'f74b7b5b829639de7187b0517124671171e3886c', '1eabae8e59d372b076035bdac59106753d4c3143', '8c4b0ea4a817610a51d42d05534a015dbcf7d6f6'], 'history_index': {'1daa3503ea9eec94f212644bb7c537963ab2ac4e': 4, '1eabae8e59d372b076035bdac59106753d4c3143': 7, '2c3bccf18791b309fa8b48e68103ac95d47230a3': 2, '650d610fc79551ca01c9d51200374e435c9787c0': 3, '8c4b0ea4a817610a51d42d05534a015dbcf7d6f6': 8, 'b35ef6c13761b660f5939aa43874dd8c140f716f': 5, 'ca5ca4efa90c01bc7221121efcc4d9c81cc5f6d0': 0, 'e2ef5dfe43753524001a5fcbab4886cbde2b3e42': 1, 'f74b7b5b829639de7187b0517124671171e3886c': 6}, 'iteration': 8, 'max_history_score': 0.546592204773611, 'max_history_score_std': 0.04157271294583304, 'max_history_step': 'pipeline'}
        config = {'algorithm': 'DecisionTree', 'reset_trial': False, 'seed': 42, 'step_algorithm': 15, 'step_pipeline': 15, 'time': 300}
    111 
    112 def get_baseline_score(algorithm, X, y, seed):
    113     pipeline, _ = pipeline_conf_to_full_pipeline(
    114         get_baseline(), 

...........................................................................
/home/aquemy/dev/dp_hyperparameters/extension/experiment/objective.py in objective(pipeline_config={'features': ('features_PCA', {'features__n_components': 2}), 'normalizer': ('normalizer_MinMaxScaler', {}), 'rebalance': ('rebalance_NoneType', {})}, algo_config={'criterion': 'entropy', 'max_depth': 4, 'max_features': 3, 'max_leaf_nodes': None, 'min_samples_leaf': 4, 'min_samples_split': 2, 'splitter': 'random'}, algorithm='DecisionTree', X=array([[ 0.,  0.,  5., ...,  0.,  0.,  0.],
    ...0.],
       [ 0.,  0., 10., ..., 12.,  1.,  0.]]), y=array([0, 1, 2, ..., 8, 9, 8]), context={'baseline_score': 0.8370850802141552, 'baseline_score_std': 0.04023050598893108, 'best_config': {'algorithm': {}, 'config_hash': {'algorithm': 'bf21a9e8fbc5a3846fb05b4fa0859e0917b2202f', 'config': '8c4b0ea4a817610a51d42d05534a015dbcf7d6f6', 'pipeline': '78028fec3489bc1290cd6e3a5ffef640e07fd746'}, 'duration': 1.01682710647583, 'iteration': 8, 'loss': 0.45340779522638897, 'max_history_score': 0.546592204773611, 'max_history_score_std': 0.04157271294583304, 'max_history_step': 'pipeline', 'pipeline': {'features': ('features_PCA', {'features__n_components': 2}), 'normalizer': ('normalizer_MinMaxScaler', {}), 'rebalance': ('rebalance_NoneType', {})}, 'score': 0.546592204773611, ...}, 'history': [{'algorithm': {}, 'config_hash': {'algorithm': 'bf21a9e8fbc5a3846fb05b4fa0859e0917b2202f', 'config': 'ca5ca4efa90c01bc7221121efcc4d9c81cc5f6d0', 'pipeline': 'e7db9df9682e59ebeb9a13264e2de218c38a3119'}, 'duration': 20.03913402557373, 'iteration': 0, 'loss': 0.8859695582333075, 'max_history_score': 0.1140304417666925, 'max_history_score_std': 0.0205735154132599, 'max_history_step': 'pipeline', 'pipeline': {'features': ('features_PCA', {'features__n_components': 1}), 'normalizer': ('normalizer_StandardScaler', {'normalizer__with_mean': True, 'normalizer__with_std': True}), 'rebalance': ('rebalance_CondensedNearestNeighbour', {'rebalance__n_neighbors': 3})}, 'score': 0.1140304417666925, ...}, {'algorithm': {'criterion': 'gini', 'max_depth': 2, 'max_features': 2, 'max_leaf_nodes': None, 'min_samples_leaf': 4, 'min_samples_split': 5, 'splitter': 'random'}, 'config_hash': {'algorithm': 'c4587a515ec4d7862c26abb6c7b2069ec2788a3c', 'config': 'e2ef5dfe43753524001a5fcbab4886cbde2b3e42', 'pipeline': 'e7db9df9682e59ebeb9a13264e2de218c38a3119'}, 'duration': 7.673176050186157, 'iteration': 1, 'loss': 1.0, 'max_history_score': 0.1140304417666925, 'max_history_score_std': 0.0205735154132599, 'max_history_step': 'pipeline', 'pipeline': {'features': ('features_PCA', {'features__n_components': 1}), 'normalizer': ('normalizer_StandardScaler', {'normalizer__with_mean': True, 'normalizer__with_std': True}), 'rebalance': ('rebalance_CondensedNearestNeighbour', {'rebalance__n_neighbors': 3})}, 'score': 0.0, ...}, {'algorithm': {'criterion': 'gini', 'max_depth': 3, 'max_features': 1, 'max_leaf_nodes': 2, 'min_samples_leaf': 4, 'min_samples_split': 3, 'splitter': 'random'}, 'config_hash': {'algorithm': 'b8f20163e3a63f6d337affac58f19f59c1042fdf', 'config': '2c3bccf18791b309fa8b48e68103ac95d47230a3', 'pipeline': 'e7db9df9682e59ebeb9a13264e2de218c38a3119'}, 'duration': 21.382025003433228, 'iteration': 2, 'loss': 0.8953686047024499, 'max_history_score': 0.1140304417666925, 'max_history_score_std': 0.0205735154132599, 'max_history_step': 'pipeline', 'pipeline': {'features': ('features_PCA', {'features__n_components': 1}), 'normalizer': ('normalizer_StandardScaler', {'normalizer__with_mean': True, 'normalizer__with_std': True}), 'rebalance': ('rebalance_CondensedNearestNeighbour', {'rebalance__n_neighbors': 3})}, 'score': 0.10463139529755008, ...}, {'algorithm': {}, 'config_hash': {'algorithm': 'bf21a9e8fbc5a3846fb05b4fa0859e0917b2202f', 'config': '650d610fc79551ca01c9d51200374e435c9787c0', 'pipeline': '1ad3dcf81ee45846a12eb92026a29afcf2a1775b'}, 'duration': 12.787569999694824, 'iteration': 3, 'loss': 0.748813833006884, 'max_history_score': 0.251186166993116, 'max_history_score_std': 0.07154325263262472, 'max_history_step': 'pipeline', 'pipeline': {'features': ('features_SelectKBest', {'features__k': 2}), 'normalizer': ('normalizer_MinMaxScaler', {}), 'rebalance': ('rebalance_CondensedNearestNeighbour', {'rebalance__n_neighbors': 1})}, 'score': 0.251186166993116, ...}, {'algorithm': {}, 'config_hash': {'algorithm': 'bf21a9e8fbc5a3846fb05b4fa0859e0917b2202f', 'config': '1daa3503ea9eec94f212644bb7c537963ab2ac4e', 'pipeline': '2235081205d7d7fae0d7335c028eccad689bcf9c'}, 'duration': 20.381888151168823, 'iteration': 4, 'loss': 0.5370735680036086, 'max_history_score': 0.4629264319963914, 'max_history_score_std': 0.04205540233571201, 'max_history_step': 'pipeline', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 4, 'features__selectkbest__k': 2}), 'normalizer': ('normalizer_NoneType', {}), 'rebalance': ('rebalance_CondensedNearestNeighbour', {'rebalance__n_neighbors': 3})}, 'score': 0.4629264319963914, ...}, {'algorithm': {'criterion': 'entropy', 'max_depth': None, 'max_features': 1, 'max_leaf_nodes': 3, 'min_samples_leaf': 1, 'min_samples_split': 2, 'splitter': 'random'}, 'config_hash': {'algorithm': '71cd9bb7b8b0ff2a3dbdca44537bafc4f6b2c716', 'config': 'b35ef6c13761b660f5939aa43874dd8c140f716f', 'pipeline': '2235081205d7d7fae0d7335c028eccad689bcf9c'}, 'duration': 20.211046934127808, 'iteration': 5, 'loss': 0.8151901497270952, 'max_history_score': 0.4629264319963914, 'max_history_score_std': 0.04205540233571201, 'max_history_step': 'pipeline', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 4, 'features__selectkbest__k': 2}), 'normalizer': ('normalizer_NoneType', {}), 'rebalance': ('rebalance_CondensedNearestNeighbour', {'rebalance__n_neighbors': 3})}, 'score': 0.1848098502729048, ...}, {'algorithm': {}, 'config_hash': {'algorithm': 'bf21a9e8fbc5a3846fb05b4fa0859e0917b2202f', 'config': 'f74b7b5b829639de7187b0517124671171e3886c', 'pipeline': '0a79122f55ba7d73b9d4a4993303bd1034099fc4'}, 'duration': 13.524871110916138, 'iteration': 6, 'loss': 0.5735578577665785, 'max_history_score': 0.4629264319963914, 'max_history_score_std': 0.04205540233571201, 'max_history_step': 'pipeline', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 3, 'features__selectkbest__k': 4}), 'normalizer': ('normalizer_StandardScaler', {'normalizer__with_mean': True, 'normalizer__with_std': True}), 'rebalance': ('rebalance_CondensedNearestNeighbour', {'rebalance__n_neighbors': 1})}, 'score': 0.4264421422334214, ...}, {'algorithm': {}, 'config_hash': {'algorithm': 'bf21a9e8fbc5a3846fb05b4fa0859e0917b2202f', 'config': '1eabae8e59d372b076035bdac59106753d4c3143', 'pipeline': 'f671e39c7c21287c35cc86282770be08920b7211'}, 'duration': 0.7754909992218018, 'iteration': 7, 'loss': 0.5473935951203874, 'max_history_score': 0.4629264319963914, 'max_history_score_std': 0.04205540233571201, 'max_history_step': 'pipeline', 'pipeline': {'features': ('features_SelectKBest', {'features__k': 4}), 'normalizer': ('normalizer_NoneType', {}), 'rebalance': ('rebalance_NearMiss', {'rebalance__n_neighbors': 3})}, 'score': 0.4526064048796126, ...}, {'algorithm': {}, 'config_hash': {'algorithm': 'bf21a9e8fbc5a3846fb05b4fa0859e0917b2202f', 'config': '8c4b0ea4a817610a51d42d05534a015dbcf7d6f6', 'pipeline': '78028fec3489bc1290cd6e3a5ffef640e07fd746'}, 'duration': 1.01682710647583, 'iteration': 8, 'loss': 0.45340779522638897, 'max_history_score': 0.546592204773611, 'max_history_score_std': 0.04157271294583304, 'max_history_step': 'pipeline', 'pipeline': {'features': ('features_PCA', {'features__n_components': 2}), 'normalizer': ('normalizer_MinMaxScaler', {}), 'rebalance': ('rebalance_NoneType', {})}, 'score': 0.546592204773611, ...}], 'history_hash': ['ca5ca4efa90c01bc7221121efcc4d9c81cc5f6d0', 'e2ef5dfe43753524001a5fcbab4886cbde2b3e42', '2c3bccf18791b309fa8b48e68103ac95d47230a3', '650d610fc79551ca01c9d51200374e435c9787c0', '1daa3503ea9eec94f212644bb7c537963ab2ac4e', 'b35ef6c13761b660f5939aa43874dd8c140f716f', 'f74b7b5b829639de7187b0517124671171e3886c', '1eabae8e59d372b076035bdac59106753d4c3143', '8c4b0ea4a817610a51d42d05534a015dbcf7d6f6'], 'history_index': {'1daa3503ea9eec94f212644bb7c537963ab2ac4e': 4, '1eabae8e59d372b076035bdac59106753d4c3143': 7, '2c3bccf18791b309fa8b48e68103ac95d47230a3': 2, '650d610fc79551ca01c9d51200374e435c9787c0': 3, '8c4b0ea4a817610a51d42d05534a015dbcf7d6f6': 8, 'b35ef6c13761b660f5939aa43874dd8c140f716f': 5, 'ca5ca4efa90c01bc7221121efcc4d9c81cc5f6d0': 0, 'e2ef5dfe43753524001a5fcbab4886cbde2b3e42': 1, 'f74b7b5b829639de7187b0517124671171e3886c': 6}, 'iteration': 8, 'max_history_score': 0.546592204773611, 'max_history_score_std': 0.04157271294583304, 'max_history_step': 'pipeline'}, config={'algorithm': 'DecisionTree', 'reset_trial': False, 'seed': 42, 'step_algorithm': 15, 'step_pipeline': 15, 'time': 300}, step='algorithm')
     45                 y,
     46                 cv=10,
     47                 n_jobs=-1,
     48                 return_estimator=False,
     49                 return_train_score=False,
---> 50                 verbose=0)
     51         score = np.mean(scores['test_score'])
     52         std = np.std(scores['test_score'])
     53         status = STATUS_OK
     54     except Exception as e:

...........................................................................
/home/aquemy/.local/lib/python2.7/site-packages/sklearn/model_selection/_validation.py in cross_validate(estimator=Pipeline(memory=None,
     steps=[('normalizer',...ort=False, random_state=42, splitter='random'))]), X=array([[ 0.,  0.,  5., ...,  0.,  0.,  0.],
    ...0.],
       [ 0.,  0., 10., ..., 12.,  1.,  0.]]), y=array([0, 1, 2, ..., 8, 9, 8]), groups=None, scoring=None, cv=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1, verbose=0, fit_params=None, pre_dispatch='2*n_jobs', return_train_score=False, return_estimator=False, error_score='raise-deprecating')
    235         delayed(_fit_and_score)(
    236             clone(estimator), X, y, scorers, train, test, verbose, None,
    237             fit_params, return_train_score=return_train_score,
    238             return_times=True, return_estimator=return_estimator,
    239             error_score=error_score)
--> 240         for train, test in cv.split(X, y, groups))
        cv.split = <bound method StratifiedKFold.split of Stratifie...d(n_splits=10, random_state=None, shuffle=False)>
        X = array([[ 0.,  0.,  5., ...,  0.,  0.,  0.],
    ...0.],
       [ 0.,  0., 10., ..., 12.,  1.,  0.]])
        y = array([0, 1, 2, ..., 8, 9, 8])
        groups = None
    241 
    242     zipped_scores = list(zip(*scores))
    243     if return_train_score:
    244         train_scores = zipped_scores.pop(0)

...........................................................................
/home/aquemy/.local/lib/python2.7/site-packages/sklearn/externals/joblib/parallel.py in __call__(self=Parallel(n_jobs=-1), iterable=<generator object <genexpr>>)
    925                 # No need to wait for async callbacks to trigger to
    926                 # consumption.
    927                 self._iterating = False
    928 
    929             with self._backend.retrieval_context():
--> 930                 self.retrieve()
        self.retrieve = <bound method Parallel.retrieve of Parallel(n_jobs=-1)>
    931             # Make sure that we get a last message telling us we are done
    932             elapsed_time = time.time() - self._start_time
    933             self._print('Done %3i out of %3i | elapsed: %s finished',
    934                         (len(self._output), len(self._output),

---------------------------------------------------------------------------
Joblib worker traceback:
---------------------------------------------------------------------------
ValueError                                         Wed Jun  5 18:34:49 2019
PID: 6849                                   Python 2.7.15+: /usr/bin/python
...........................................................................
/home/aquemy/.local/lib/python2.7/site-packages/sklearn/externals/joblib/parallel.py in __call__(self=<sklearn.externals.joblib.parallel.BatchedCalls object>)
    220     def __call__(self):
    221         # Set the default nested backend to self._backend but do not set the
    222         # change the default number of processes to -1
    223         with parallel_backend(self._backend, n_jobs=self._n_jobs):
    224             return [func(*args, **kwargs)
--> 225                     for func, args, kwargs in self.items]
        func = <function _fit_and_score>
        args = (Pipeline(memory=None,
     steps=[('normalizer',...ort=False, random_state=42, splitter='random'))]), array([[ 0.,  0.,  5., ...,  0.,  0.,  0.],
    ...0.],
       [ 0.,  0., 10., ..., 12.,  1.,  0.]]), array([0, 1, 2, ..., 8, 9, 8]), {'score': <function _passthrough_scorer>}, array([ 169,  176,  178, ..., 1794, 1795, 1796]), array([  0,   1,   2,   3,   4,   5,   6,   7,  ..., 181, 186, 188, 189, 190,
       194, 195, 198]), 0, None, None)
        kwargs = {'error_score': 'raise-deprecating', 'return_estimator': False, 'return_times': True, 'return_train_score': False}
        self.items = [(<function _fit_and_score>, (Pipeline(memory=None,
     steps=[('normalizer',...ort=False, random_state=42, splitter='random'))]), array([[ 0.,  0.,  5., ...,  0.,  0.,  0.],
    ...0.],
       [ 0.,  0., 10., ..., 12.,  1.,  0.]]), array([0, 1, 2, ..., 8, 9, 8]), {'score': <function _passthrough_scorer>}, array([ 169,  176,  178, ..., 1794, 1795, 1796]), array([  0,   1,   2,   3,   4,   5,   6,   7,  ..., 181, 186, 188, 189, 190,
       194, 195, 198]), 0, None, None), {'error_score': 'raise-deprecating', 'return_estimator': False, 'return_times': True, 'return_train_score': False})]
    226 
    227     def __len__(self):
    228         return self._size
    229 

...........................................................................
/home/aquemy/.local/lib/python2.7/site-packages/sklearn/model_selection/_validation.py in _fit_and_score(estimator=Pipeline(memory=None,
     steps=[('normalizer',...ort=False, random_state=42, splitter='random'))]), X=array([[ 0.,  0.,  5., ...,  0.,  0.,  0.],
    ...0.],
       [ 0.,  0., 10., ..., 12.,  1.,  0.]]), y=array([0, 1, 2, ..., 8, 9, 8]), scorer={'score': <function _passthrough_scorer>}, train=array([ 169,  176,  178, ..., 1794, 1795, 1796]), test=array([  0,   1,   2,   3,   4,   5,   6,   7,  ..., 181, 186, 188, 189, 190,
       194, 195, 198]), verbose=0, parameters=None, fit_params={}, return_train_score=False, return_parameters=False, return_n_test_samples=False, return_times=True, return_estimator=False, error_score='raise-deprecating')
    523 
    524     try:
    525         if y_train is None:
    526             estimator.fit(X_train, **fit_params)
    527         else:
--> 528             estimator.fit(X_train, y_train, **fit_params)
        estimator.fit = <bound method Pipeline.fit of Pipeline(memory=No...rt=False, random_state=42, splitter='random'))])>
        X_train = array([[ 0.,  0.,  6., ...,  9.,  4.,  0.],
    ...0.],
       [ 0.,  0., 10., ..., 12.,  1.,  0.]])
        y_train = array([9, 5, 0, ..., 8, 9, 8])
        fit_params = {}
    529 
    530     except Exception as e:
    531         # Note fit time as time until error
    532         fit_time = time.time() - start_time

...........................................................................
/usr/local/lib/python2.7/dist-packages/imblearn/pipeline.py in fit(self=Pipeline(memory=None,
     steps=[('normalizer',...ort=False, random_state=42, splitter='random'))]), X=array([[ 0.,  0.,  6., ...,  9.,  4.,  0.],
    ...0.],
       [ 0.,  0., 10., ..., 12.,  1.,  0.]]), y=array([9, 5, 0, ..., 8, 9, 8]), **fit_params={})
    234             This estimator
    235 
    236         """
    237         Xt, yt, fit_params = self._fit(X, y, **fit_params)
    238         if self._final_estimator is not None:
--> 239             self._final_estimator.fit(Xt, yt, **fit_params)
        self._final_estimator.fit = <bound method DecisionTreeClassifier.fit of Deci...esort=False, random_state=42, splitter='random')>
        Xt = array([[-0.96093868,  0.85576875],
       [-0.27... 0.84930725],
       [-0.0416989 ,  0.2488451 ]])
        yt = array([9, 5, 0, ..., 8, 9, 8])
        fit_params = {}
    240         return self
    241 
    242     def fit_transform(self, X, y=None, **fit_params):
    243         """Fit the model and transform with the final estimator

...........................................................................
/home/aquemy/.local/lib/python2.7/site-packages/sklearn/tree/tree.py in fit(self=DecisionTreeClassifier(class_weight=None, criter...resort=False, random_state=42, splitter='random'), X=array([[-0.96093868,  0.85576875],
       [-0.27... 0.84930725],
       [-0.0416989 ,  0.2488451 ]]), y=array([9, 5, 0, ..., 8, 9, 8]), sample_weight=None, check_input=True, X_idx_sorted=None)
    796 
    797         super(DecisionTreeClassifier, self).fit(
    798             X, y,
    799             sample_weight=sample_weight,
    800             check_input=check_input,
--> 801             X_idx_sorted=X_idx_sorted)
        X_idx_sorted = None
    802         return self
    803 
    804     def predict_proba(self, X, check_input=True):
    805         """Predict class probabilities of the input samples X.

...........................................................................
/home/aquemy/.local/lib/python2.7/site-packages/sklearn/tree/tree.py in fit(self=DecisionTreeClassifier(class_weight=None, criter...resort=False, random_state=42, splitter='random'), X=array([[-0.9609387 ,  0.85576874],
       [-0.27...      [-0.0416989 ,  0.2488451 ]], dtype=float32), y=array([[9.],
       [5.],
       [0.],
       ...,
       [8.],
       [9.],
       [8.]]), sample_weight=None, check_input=True, X_idx_sorted=None)
    237         if not 0 <= self.min_weight_fraction_leaf <= 0.5:
    238             raise ValueError("min_weight_fraction_leaf must in [0, 0.5]")
    239         if max_depth <= 0:
    240             raise ValueError("max_depth must be greater than zero. ")
    241         if not (0 < max_features <= self.n_features_):
--> 242             raise ValueError("max_features must be in (0, n_features]")
    243         if not isinstance(max_leaf_nodes, (numbers.Integral, np.integer)):
    244             raise ValueError("max_leaf_nodes must be integral number but was "
    245                              "%r" % max_leaf_nodes)
    246         if -1 < max_leaf_nodes < 2:

ValueError: max_features must be in (0, n_features]
___________________________________________________________________________
Best score: 0.546592204774 (0.0415727129458) [P] | Score: 0.0 (0.0) [A]
Best score: 0.546592204774 (0.0415727129458) [P] | Score: 0.280946664772 (0.00958400234056) [A]
JoblibValueError
___________________________________________________________________________
...........................................................................
/home/aquemy/dev/dp_hyperparameters/extension/main.py in <module>()
     27 
     28     serializer.serialize_results(scenario, policy)
     29 
     30 if __name__ == "__main__":
     31     args = cli.parse_args()
---> 32     main(args)

...........................................................................
/home/aquemy/dev/dp_hyperparameters/extension/main.py in main(args=Namespace(customize=[(['control', 'seed'], '42')...scenarios/dt_digits_iterative.yaml', verbosity=0))
     21         test_size=0.4, 
     22         random_state=scenario['control']['seed']
     23     )
     24 
     25     policy = policies.initiate(scenario['setup']['policy'], config)
---> 26     policy.run(X,y)
        policy.run = <bound method Iterative.run of <experiment.policies.iterative.Iterative object>>
        X = array([[ 0.,  0.,  5., ...,  0.,  0.,  0.],
    ...0.],
       [ 0.,  0., 10., ..., 12.,  1.,  0.]])
        y = array([0, 1, 2, ..., 8, 9, 8])
     27 
     28     serializer.serialize_results(scenario, policy)
     29 
     30 if __name__ == "__main__":

...........................................................................
/home/aquemy/dev/dp_hyperparameters/extension/experiment/policies/iterative.py in run(self=<experiment.policies.iterative.Iterative object>, X=array([[ 0.,  0.,  5., ...,  0.,  0.,  0.],
    ...0.],
       [ 0.,  0., 10., ..., 12.,  1.,  0.]]), y=array([0, 1, 2, ..., 8, 9, 8]))
     59                 algo=tpe.suggest, 
     60                 max_evals=None,
     61                 max_time=self.config['step_algorithm'],
     62                 trials=trials_algo,
     63                 show_progressbar=False,
---> 64                 verbose=0
     65             )
     66             best_config = self.context['best_config']
     67             current_pipeline_configuration = best_config['pipeline']
     68             super(Iterative, self).display_step_results(best_config)

...........................................................................
/home/aquemy/dev/dp_hyperparameters/extension/hyperopt/fmin.py in fmin(fn=<functools.partial object>, space={'criterion': <hyperopt.pyll.base.Apply object>, 'max_depth': <hyperopt.pyll.base.Apply object>, 'max_features': <hyperopt.pyll.base.Apply object>, 'max_leaf_nodes': <hyperopt.pyll.base.Apply object>, 'min_samples_leaf': <hyperopt.pyll.base.Apply object>, 'min_samples_split': <hyperopt.pyll.base.Apply object>, 'splitter': <hyperopt.pyll.base.Apply object>}, algo=<function suggest>, max_evals=9223372036854775807, max_time=15, trials=<hyperopt.base.Trials object>, rstate=<mtrand.RandomState object>, allow_trials_fmin=True, pass_expr_memo_ctrl=None, catch_eval_exceptions=False, verbose=0, return_argmin=True, points_to_evaluate=None, max_queue_len=1, show_progressbar=False)
    406             pass_expr_memo_ctrl=pass_expr_memo_ctrl,
    407             verbose=verbose,
    408             catch_eval_exceptions=catch_eval_exceptions,
    409             return_argmin=return_argmin,
    410             show_progressbar=show_progressbar,
--> 411             max_time=max_time
        max_time = 15
    412         )
    413 
    414     if trials is None:
    415         if points_to_evaluate is None:

...........................................................................
/home/aquemy/dev/dp_hyperparameters/extension/hyperopt/base.py in fmin(self=<hyperopt.base.Trials object>, fn=<functools.partial object>, space={'criterion': <hyperopt.pyll.base.Apply object>, 'max_depth': <hyperopt.pyll.base.Apply object>, 'max_features': <hyperopt.pyll.base.Apply object>, 'max_leaf_nodes': <hyperopt.pyll.base.Apply object>, 'min_samples_leaf': <hyperopt.pyll.base.Apply object>, 'min_samples_split': <hyperopt.pyll.base.Apply object>, 'splitter': <hyperopt.pyll.base.Apply object>}, algo=<function suggest>, max_evals=9223372036854775807, max_time=15, rstate=<mtrand.RandomState object>, verbose=0, pass_expr_memo_ctrl=None, catch_eval_exceptions=False, return_argmin=True, show_progressbar=False)
    636             verbose=verbose,
    637             allow_trials_fmin=False,  # -- prevent recursion
    638             pass_expr_memo_ctrl=pass_expr_memo_ctrl,
    639             catch_eval_exceptions=catch_eval_exceptions,
    640             return_argmin=return_argmin,
--> 641             show_progressbar=show_progressbar)
        show_progressbar = False
    642 
    643 
    644 def trials_from_docs(docs, validate=True, **kwargs):
    645     """Construct a Trials base class instance from a list of trials documents

...........................................................................
/home/aquemy/dev/dp_hyperparameters/extension/hyperopt/fmin.py in fmin(fn=<functools.partial object>, space={'criterion': <hyperopt.pyll.base.Apply object>, 'max_depth': <hyperopt.pyll.base.Apply object>, 'max_features': <hyperopt.pyll.base.Apply object>, 'max_leaf_nodes': <hyperopt.pyll.base.Apply object>, 'min_samples_leaf': <hyperopt.pyll.base.Apply object>, 'min_samples_split': <hyperopt.pyll.base.Apply object>, 'splitter': <hyperopt.pyll.base.Apply object>}, algo=<function suggest>, max_evals=9223372036854775807, max_time=15, trials=<hyperopt.base.Trials object>, rstate=<mtrand.RandomState object>, allow_trials_fmin=False, pass_expr_memo_ctrl=None, catch_eval_exceptions=False, verbose=0, return_argmin=True, points_to_evaluate=None, max_queue_len=1, show_progressbar=False)
    426                     verbose=verbose,
    427                     max_queue_len=max_queue_len,
    428                     show_progressbar=show_progressbar,
    429                     max_time=max_time)
    430     rval.catch_eval_exceptions = catch_eval_exceptions
--> 431     rval.exhaust()
        rval.exhaust = <bound method FMinIter.exhaust of <hyperopt.fmin.FMinIter object>>
    432     if return_argmin:
    433         return trials.argmin
    434     elif len(trials) > 0:
    435         # Only if there are some succesfull trail runs, return the best point in the evaluation space

...........................................................................
/home/aquemy/dev/dp_hyperparameters/extension/hyperopt/fmin.py in exhaust(self=<hyperopt.fmin.FMinIter object>)
    273             raise StopIteration()
    274         return self.trials
    275 
    276     def exhaust(self):
    277         n_done = len(self.trials)
--> 278         self.run(self.max_evals - n_done, block_until_done=self.asynchronous)
        self.run = <bound method FMinIter.run of <hyperopt.fmin.FMinIter object>>
        self.max_evals = 9223372036854775807
        n_done = 3
        self.asynchronous = False
    279         self.trials.refresh()
    280         return self
    281 
    282 

...........................................................................
/home/aquemy/dev/dp_hyperparameters/extension/hyperopt/fmin.py in run(self=<hyperopt.fmin.FMinIter object>, N=9223372036854775804, block_until_done=False)
    232                     if self.asynchronous:
    233                         # -- wait for workers to fill in the trials
    234                         time.sleep(self.poll_interval_secs)
    235                     else:
    236                         # -- loop over trials and do the jobs directly
--> 237                         self.serial_evaluate()
        self.serial_evaluate = <bound method FMinIter.serial_evaluate of <hyperopt.fmin.FMinIter object>>
    238                     try:
    239                         res = [d['result']['loss'] for d in
    240                                          self.trials.trials if
    241                                          d['result']['status'] == 'ok']

...........................................................................
/home/aquemy/dev/dp_hyperparameters/extension/hyperopt/fmin.py in serial_evaluate(self=<hyperopt.fmin.FMinIter object>, N=-1)
    138                 trial['book_time'] = now
    139                 trial['refresh_time'] = now
    140                 spec = base.spec_from_misc(trial['misc'])
    141                 ctrl = base.Ctrl(self.trials, current_trial=trial)
    142                 try:
--> 143                     result = self.domain.evaluate(spec, ctrl)
        result = undefined
        self.domain.evaluate = <bound method Domain.evaluate of <hyperopt.base.Domain object>>
        spec = {'criterion': 1, 'max_depth': 3, 'max_features': 2, 'max_leaf_nodes': 0, 'min_samples_leaf': 1, 'min_samples_split': 2, 'splitter': 1}
        ctrl = <hyperopt.base.Ctrl object>
    144                 except Exception as e:
    145                     logger.info('job exception: %s' % str(e))
    146                     trial['state'] = base.JOB_STATE_ERROR
    147                     trial['misc']['error'] = (str(type(e)), str(e))

...........................................................................
/home/aquemy/dev/dp_hyperparameters/extension/hyperopt/base.py in evaluate(self=<hyperopt.base.Domain object>, config={'criterion': 1, 'max_depth': 3, 'max_features': 2, 'max_leaf_nodes': 0, 'min_samples_leaf': 1, 'min_samples_split': 2, 'splitter': 1}, ctrl=<hyperopt.base.Ctrl object>, attach_attachments=True)
    841             #    or the normal Python part (self.fn)
    842             pyll_rval = pyll.rec_eval(
    843                 self.expr,
    844                 memo=memo,
    845                 print_node_on_error=self.rec_eval_print_node_on_error)
--> 846             rval = self.fn(pyll_rval)
        rval = undefined
        self.fn = <functools.partial object>
        pyll_rval = {'criterion': 'entropy', 'max_depth': 4, 'max_features': 3, 'max_leaf_nodes': 2, 'min_samples_leaf': 2, 'min_samples_split': 5, 'splitter': 'random'}
    847 
    848         if isinstance(rval, (float, int, np.number)):
    849             dict_rval = {'loss': float(rval), 'status': STATUS_OK}
    850         else:

...........................................................................
/home/aquemy/dev/dp_hyperparameters/extension/experiment/objective.py in objective_algo(algo_config={'criterion': 'entropy', 'max_depth': 4, 'max_features': 3, 'max_leaf_nodes': 2, 'min_samples_leaf': 2, 'min_samples_split': 5, 'splitter': 'random'}, current_pipeline_config={'features': ('features_PCA', {'features__n_components': 2}), 'normalizer': ('normalizer_MinMaxScaler', {}), 'rebalance': ('rebalance_NoneType', {})}, algorithm='DecisionTree', X=array([[ 0.,  0.,  5., ...,  0.,  0.,  0.],
    ...0.],
       [ 0.,  0., 10., ..., 12.,  1.,  0.]]), y=array([0, 1, 2, ..., 8, 9, 8]), context={'baseline_score': 0.8370850802141552, 'baseline_score_std': 0.04023050598893108, 'best_config': {'algorithm': {}, 'config_hash': {'algorithm': 'bf21a9e8fbc5a3846fb05b4fa0859e0917b2202f', 'config': '8c4b0ea4a817610a51d42d05534a015dbcf7d6f6', 'pipeline': '78028fec3489bc1290cd6e3a5ffef640e07fd746'}, 'duration': 1.01682710647583, 'iteration': 8, 'loss': 0.45340779522638897, 'max_history_score': 0.546592204773611, 'max_history_score_std': 0.04157271294583304, 'max_history_step': 'pipeline', 'pipeline': {'features': ('features_PCA', {'features__n_components': 2}), 'normalizer': ('normalizer_MinMaxScaler', {}), 'rebalance': ('rebalance_NoneType', {})}, 'score': 0.546592204773611, ...}, 'history': [{'algorithm': {}, 'config_hash': {'algorithm': 'bf21a9e8fbc5a3846fb05b4fa0859e0917b2202f', 'config': 'ca5ca4efa90c01bc7221121efcc4d9c81cc5f6d0', 'pipeline': 'e7db9df9682e59ebeb9a13264e2de218c38a3119'}, 'duration': 20.03913402557373, 'iteration': 0, 'loss': 0.8859695582333075, 'max_history_score': 0.1140304417666925, 'max_history_score_std': 0.0205735154132599, 'max_history_step': 'pipeline', 'pipeline': {'features': ('features_PCA', {'features__n_components': 1}), 'normalizer': ('normalizer_StandardScaler', {'normalizer__with_mean': True, 'normalizer__with_std': True}), 'rebalance': ('rebalance_CondensedNearestNeighbour', {'rebalance__n_neighbors': 3})}, 'score': 0.1140304417666925, ...}, {'algorithm': {'criterion': 'gini', 'max_depth': 2, 'max_features': 2, 'max_leaf_nodes': None, 'min_samples_leaf': 4, 'min_samples_split': 5, 'splitter': 'random'}, 'config_hash': {'algorithm': 'c4587a515ec4d7862c26abb6c7b2069ec2788a3c', 'config': 'e2ef5dfe43753524001a5fcbab4886cbde2b3e42', 'pipeline': 'e7db9df9682e59ebeb9a13264e2de218c38a3119'}, 'duration': 7.673176050186157, 'iteration': 1, 'loss': 1.0, 'max_history_score': 0.1140304417666925, 'max_history_score_std': 0.0205735154132599, 'max_history_step': 'pipeline', 'pipeline': {'features': ('features_PCA', {'features__n_components': 1}), 'normalizer': ('normalizer_StandardScaler', {'normalizer__with_mean': True, 'normalizer__with_std': True}), 'rebalance': ('rebalance_CondensedNearestNeighbour', {'rebalance__n_neighbors': 3})}, 'score': 0.0, ...}, {'algorithm': {'criterion': 'gini', 'max_depth': 3, 'max_features': 1, 'max_leaf_nodes': 2, 'min_samples_leaf': 4, 'min_samples_split': 3, 'splitter': 'random'}, 'config_hash': {'algorithm': 'b8f20163e3a63f6d337affac58f19f59c1042fdf', 'config': '2c3bccf18791b309fa8b48e68103ac95d47230a3', 'pipeline': 'e7db9df9682e59ebeb9a13264e2de218c38a3119'}, 'duration': 21.382025003433228, 'iteration': 2, 'loss': 0.8953686047024499, 'max_history_score': 0.1140304417666925, 'max_history_score_std': 0.0205735154132599, 'max_history_step': 'pipeline', 'pipeline': {'features': ('features_PCA', {'features__n_components': 1}), 'normalizer': ('normalizer_StandardScaler', {'normalizer__with_mean': True, 'normalizer__with_std': True}), 'rebalance': ('rebalance_CondensedNearestNeighbour', {'rebalance__n_neighbors': 3})}, 'score': 0.10463139529755008, ...}, {'algorithm': {}, 'config_hash': {'algorithm': 'bf21a9e8fbc5a3846fb05b4fa0859e0917b2202f', 'config': '650d610fc79551ca01c9d51200374e435c9787c0', 'pipeline': '1ad3dcf81ee45846a12eb92026a29afcf2a1775b'}, 'duration': 12.787569999694824, 'iteration': 3, 'loss': 0.748813833006884, 'max_history_score': 0.251186166993116, 'max_history_score_std': 0.07154325263262472, 'max_history_step': 'pipeline', 'pipeline': {'features': ('features_SelectKBest', {'features__k': 2}), 'normalizer': ('normalizer_MinMaxScaler', {}), 'rebalance': ('rebalance_CondensedNearestNeighbour', {'rebalance__n_neighbors': 1})}, 'score': 0.251186166993116, ...}, {'algorithm': {}, 'config_hash': {'algorithm': 'bf21a9e8fbc5a3846fb05b4fa0859e0917b2202f', 'config': '1daa3503ea9eec94f212644bb7c537963ab2ac4e', 'pipeline': '2235081205d7d7fae0d7335c028eccad689bcf9c'}, 'duration': 20.381888151168823, 'iteration': 4, 'loss': 0.5370735680036086, 'max_history_score': 0.4629264319963914, 'max_history_score_std': 0.04205540233571201, 'max_history_step': 'pipeline', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 4, 'features__selectkbest__k': 2}), 'normalizer': ('normalizer_NoneType', {}), 'rebalance': ('rebalance_CondensedNearestNeighbour', {'rebalance__n_neighbors': 3})}, 'score': 0.4629264319963914, ...}, {'algorithm': {'criterion': 'entropy', 'max_depth': None, 'max_features': 1, 'max_leaf_nodes': 3, 'min_samples_leaf': 1, 'min_samples_split': 2, 'splitter': 'random'}, 'config_hash': {'algorithm': '71cd9bb7b8b0ff2a3dbdca44537bafc4f6b2c716', 'config': 'b35ef6c13761b660f5939aa43874dd8c140f716f', 'pipeline': '2235081205d7d7fae0d7335c028eccad689bcf9c'}, 'duration': 20.211046934127808, 'iteration': 5, 'loss': 0.8151901497270952, 'max_history_score': 0.4629264319963914, 'max_history_score_std': 0.04205540233571201, 'max_history_step': 'pipeline', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 4, 'features__selectkbest__k': 2}), 'normalizer': ('normalizer_NoneType', {}), 'rebalance': ('rebalance_CondensedNearestNeighbour', {'rebalance__n_neighbors': 3})}, 'score': 0.1848098502729048, ...}, {'algorithm': {}, 'config_hash': {'algorithm': 'bf21a9e8fbc5a3846fb05b4fa0859e0917b2202f', 'config': 'f74b7b5b829639de7187b0517124671171e3886c', 'pipeline': '0a79122f55ba7d73b9d4a4993303bd1034099fc4'}, 'duration': 13.524871110916138, 'iteration': 6, 'loss': 0.5735578577665785, 'max_history_score': 0.4629264319963914, 'max_history_score_std': 0.04205540233571201, 'max_history_step': 'pipeline', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 3, 'features__selectkbest__k': 4}), 'normalizer': ('normalizer_StandardScaler', {'normalizer__with_mean': True, 'normalizer__with_std': True}), 'rebalance': ('rebalance_CondensedNearestNeighbour', {'rebalance__n_neighbors': 1})}, 'score': 0.4264421422334214, ...}, {'algorithm': {}, 'config_hash': {'algorithm': 'bf21a9e8fbc5a3846fb05b4fa0859e0917b2202f', 'config': '1eabae8e59d372b076035bdac59106753d4c3143', 'pipeline': 'f671e39c7c21287c35cc86282770be08920b7211'}, 'duration': 0.7754909992218018, 'iteration': 7, 'loss': 0.5473935951203874, 'max_history_score': 0.4629264319963914, 'max_history_score_std': 0.04205540233571201, 'max_history_step': 'pipeline', 'pipeline': {'features': ('features_SelectKBest', {'features__k': 4}), 'normalizer': ('normalizer_NoneType', {}), 'rebalance': ('rebalance_NearMiss', {'rebalance__n_neighbors': 3})}, 'score': 0.4526064048796126, ...}, {'algorithm': {}, 'config_hash': {'algorithm': 'bf21a9e8fbc5a3846fb05b4fa0859e0917b2202f', 'config': '8c4b0ea4a817610a51d42d05534a015dbcf7d6f6', 'pipeline': '78028fec3489bc1290cd6e3a5ffef640e07fd746'}, 'duration': 1.01682710647583, 'iteration': 8, 'loss': 0.45340779522638897, 'max_history_score': 0.546592204773611, 'max_history_score_std': 0.04157271294583304, 'max_history_step': 'pipeline', 'pipeline': {'features': ('features_PCA', {'features__n_components': 2}), 'normalizer': ('normalizer_MinMaxScaler', {}), 'rebalance': ('rebalance_NoneType', {})}, 'score': 0.546592204773611, ...}, {'algorithm': {'criterion': 'entropy', 'max_depth': 4, 'max_features': 3, 'max_leaf_nodes': None, 'min_samples_leaf': 4, 'min_samples_split': 2, 'splitter': 'random'}, 'config_hash': {'algorithm': '9a5aa4d1141074f6b9047871fcb0b33ccfcfd3d3', 'config': '92935a6b2d506658f91a16fec98aae7c7c18849e', 'pipeline': '78028fec3489bc1290cd6e3a5ffef640e07fd746'}, 'duration': 0.9999289512634277, 'iteration': 9, 'loss': 1.0, 'max_history_score': 0.546592204773611, 'max_history_score_std': 0.04157271294583304, 'max_history_step': 'pipeline', 'pipeline': {'features': ('features_PCA', {'features__n_components': 2}), 'normalizer': ('normalizer_MinMaxScaler', {}), 'rebalance': ('rebalance_NoneType', {})}, 'score': 0.0, ...}, {'algorithm': {'criterion': 'gini', 'max_depth': 1, 'max_features': None, 'max_leaf_nodes': 3, 'min_samples_leaf': 5, 'min_samples_split': 5, 'splitter': 'best'}, 'config_hash': {'algorithm': 'ecf5b568d6e3c2ab306a7bcf2b124903c3a3067b', 'config': '97df063c7bd2eed3d6c210b081267d6af4779728', 'pipeline': '78028fec3489bc1290cd6e3a5ffef640e07fd746'}, 'duration': 4.798619031906128, 'iteration': 10, 'loss': 0.71905333522791, 'max_history_score': 0.546592204773611, 'max_history_score_std': 0.04157271294583304, 'max_history_step': 'pipeline', 'pipeline': {'features': ('features_PCA', {'features__n_components': 2}), 'normalizer': ('normalizer_MinMaxScaler', {}), 'rebalance': ('rebalance_NoneType', {})}, 'score': 0.28094666477209, ...}], 'history_hash': ['ca5ca4efa90c01bc7221121efcc4d9c81cc5f6d0', 'e2ef5dfe43753524001a5fcbab4886cbde2b3e42', '2c3bccf18791b309fa8b48e68103ac95d47230a3', '650d610fc79551ca01c9d51200374e435c9787c0', '1daa3503ea9eec94f212644bb7c537963ab2ac4e', 'b35ef6c13761b660f5939aa43874dd8c140f716f', 'f74b7b5b829639de7187b0517124671171e3886c', '1eabae8e59d372b076035bdac59106753d4c3143', '8c4b0ea4a817610a51d42d05534a015dbcf7d6f6', '92935a6b2d506658f91a16fec98aae7c7c18849e', '97df063c7bd2eed3d6c210b081267d6af4779728'], 'history_index': {'1daa3503ea9eec94f212644bb7c537963ab2ac4e': 4, '1eabae8e59d372b076035bdac59106753d4c3143': 7, '2c3bccf18791b309fa8b48e68103ac95d47230a3': 2, '650d610fc79551ca01c9d51200374e435c9787c0': 3, '8c4b0ea4a817610a51d42d05534a015dbcf7d6f6': 8, '92935a6b2d506658f91a16fec98aae7c7c18849e': 9, '97df063c7bd2eed3d6c210b081267d6af4779728': 10, 'b35ef6c13761b660f5939aa43874dd8c140f716f': 5, 'ca5ca4efa90c01bc7221121efcc4d9c81cc5f6d0': 0, 'e2ef5dfe43753524001a5fcbab4886cbde2b3e42': 1, ...}, 'iteration': 10, 'max_history_score': 0.546592204773611, 'max_history_score_std': 0.04157271294583304, 'max_history_step': 'pipeline'}, config={'algorithm': 'DecisionTree', 'reset_trial': False, 'seed': 42, 'step_algorithm': 15, 'step_pipeline': 15, 'time': 300})
    105 
    106 def objective_pipeline(pipeline_config, current_algo_config, algorithm, X, y, context, config):
    107     return objective(pipeline_config, current_algo_config, algorithm, X, y, context, config, step='pipeline')
    108 
    109 def objective_algo(algo_config, current_pipeline_config, algorithm, X, y, context, config):
--> 110     return objective(current_pipeline_config, algo_config, algorithm, X, y, context, config, step='algorithm')
        current_pipeline_config = {'features': ('features_PCA', {'features__n_components': 2}), 'normalizer': ('normalizer_MinMaxScaler', {}), 'rebalance': ('rebalance_NoneType', {})}
        algo_config = {'criterion': 'entropy', 'max_depth': 4, 'max_features': 3, 'max_leaf_nodes': 2, 'min_samples_leaf': 2, 'min_samples_split': 5, 'splitter': 'random'}
        algorithm = 'DecisionTree'
        X = array([[ 0.,  0.,  5., ...,  0.,  0.,  0.],
    ...0.],
       [ 0.,  0., 10., ..., 12.,  1.,  0.]])
        y = array([0, 1, 2, ..., 8, 9, 8])
        context = {'baseline_score': 0.8370850802141552, 'baseline_score_std': 0.04023050598893108, 'best_config': {'algorithm': {}, 'config_hash': {'algorithm': 'bf21a9e8fbc5a3846fb05b4fa0859e0917b2202f', 'config': '8c4b0ea4a817610a51d42d05534a015dbcf7d6f6', 'pipeline': '78028fec3489bc1290cd6e3a5ffef640e07fd746'}, 'duration': 1.01682710647583, 'iteration': 8, 'loss': 0.45340779522638897, 'max_history_score': 0.546592204773611, 'max_history_score_std': 0.04157271294583304, 'max_history_step': 'pipeline', 'pipeline': {'features': ('features_PCA', {'features__n_components': 2}), 'normalizer': ('normalizer_MinMaxScaler', {}), 'rebalance': ('rebalance_NoneType', {})}, 'score': 0.546592204773611, ...}, 'history': [{'algorithm': {}, 'config_hash': {'algorithm': 'bf21a9e8fbc5a3846fb05b4fa0859e0917b2202f', 'config': 'ca5ca4efa90c01bc7221121efcc4d9c81cc5f6d0', 'pipeline': 'e7db9df9682e59ebeb9a13264e2de218c38a3119'}, 'duration': 20.03913402557373, 'iteration': 0, 'loss': 0.8859695582333075, 'max_history_score': 0.1140304417666925, 'max_history_score_std': 0.0205735154132599, 'max_history_step': 'pipeline', 'pipeline': {'features': ('features_PCA', {'features__n_components': 1}), 'normalizer': ('normalizer_StandardScaler', {'normalizer__with_mean': True, 'normalizer__with_std': True}), 'rebalance': ('rebalance_CondensedNearestNeighbour', {'rebalance__n_neighbors': 3})}, 'score': 0.1140304417666925, ...}, {'algorithm': {'criterion': 'gini', 'max_depth': 2, 'max_features': 2, 'max_leaf_nodes': None, 'min_samples_leaf': 4, 'min_samples_split': 5, 'splitter': 'random'}, 'config_hash': {'algorithm': 'c4587a515ec4d7862c26abb6c7b2069ec2788a3c', 'config': 'e2ef5dfe43753524001a5fcbab4886cbde2b3e42', 'pipeline': 'e7db9df9682e59ebeb9a13264e2de218c38a3119'}, 'duration': 7.673176050186157, 'iteration': 1, 'loss': 1.0, 'max_history_score': 0.1140304417666925, 'max_history_score_std': 0.0205735154132599, 'max_history_step': 'pipeline', 'pipeline': {'features': ('features_PCA', {'features__n_components': 1}), 'normalizer': ('normalizer_StandardScaler', {'normalizer__with_mean': True, 'normalizer__with_std': True}), 'rebalance': ('rebalance_CondensedNearestNeighbour', {'rebalance__n_neighbors': 3})}, 'score': 0.0, ...}, {'algorithm': {'criterion': 'gini', 'max_depth': 3, 'max_features': 1, 'max_leaf_nodes': 2, 'min_samples_leaf': 4, 'min_samples_split': 3, 'splitter': 'random'}, 'config_hash': {'algorithm': 'b8f20163e3a63f6d337affac58f19f59c1042fdf', 'config': '2c3bccf18791b309fa8b48e68103ac95d47230a3', 'pipeline': 'e7db9df9682e59ebeb9a13264e2de218c38a3119'}, 'duration': 21.382025003433228, 'iteration': 2, 'loss': 0.8953686047024499, 'max_history_score': 0.1140304417666925, 'max_history_score_std': 0.0205735154132599, 'max_history_step': 'pipeline', 'pipeline': {'features': ('features_PCA', {'features__n_components': 1}), 'normalizer': ('normalizer_StandardScaler', {'normalizer__with_mean': True, 'normalizer__with_std': True}), 'rebalance': ('rebalance_CondensedNearestNeighbour', {'rebalance__n_neighbors': 3})}, 'score': 0.10463139529755008, ...}, {'algorithm': {}, 'config_hash': {'algorithm': 'bf21a9e8fbc5a3846fb05b4fa0859e0917b2202f', 'config': '650d610fc79551ca01c9d51200374e435c9787c0', 'pipeline': '1ad3dcf81ee45846a12eb92026a29afcf2a1775b'}, 'duration': 12.787569999694824, 'iteration': 3, 'loss': 0.748813833006884, 'max_history_score': 0.251186166993116, 'max_history_score_std': 0.07154325263262472, 'max_history_step': 'pipeline', 'pipeline': {'features': ('features_SelectKBest', {'features__k': 2}), 'normalizer': ('normalizer_MinMaxScaler', {}), 'rebalance': ('rebalance_CondensedNearestNeighbour', {'rebalance__n_neighbors': 1})}, 'score': 0.251186166993116, ...}, {'algorithm': {}, 'config_hash': {'algorithm': 'bf21a9e8fbc5a3846fb05b4fa0859e0917b2202f', 'config': '1daa3503ea9eec94f212644bb7c537963ab2ac4e', 'pipeline': '2235081205d7d7fae0d7335c028eccad689bcf9c'}, 'duration': 20.381888151168823, 'iteration': 4, 'loss': 0.5370735680036086, 'max_history_score': 0.4629264319963914, 'max_history_score_std': 0.04205540233571201, 'max_history_step': 'pipeline', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 4, 'features__selectkbest__k': 2}), 'normalizer': ('normalizer_NoneType', {}), 'rebalance': ('rebalance_CondensedNearestNeighbour', {'rebalance__n_neighbors': 3})}, 'score': 0.4629264319963914, ...}, {'algorithm': {'criterion': 'entropy', 'max_depth': None, 'max_features': 1, 'max_leaf_nodes': 3, 'min_samples_leaf': 1, 'min_samples_split': 2, 'splitter': 'random'}, 'config_hash': {'algorithm': '71cd9bb7b8b0ff2a3dbdca44537bafc4f6b2c716', 'config': 'b35ef6c13761b660f5939aa43874dd8c140f716f', 'pipeline': '2235081205d7d7fae0d7335c028eccad689bcf9c'}, 'duration': 20.211046934127808, 'iteration': 5, 'loss': 0.8151901497270952, 'max_history_score': 0.4629264319963914, 'max_history_score_std': 0.04205540233571201, 'max_history_step': 'pipeline', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 4, 'features__selectkbest__k': 2}), 'normalizer': ('normalizer_NoneType', {}), 'rebalance': ('rebalance_CondensedNearestNeighbour', {'rebalance__n_neighbors': 3})}, 'score': 0.1848098502729048, ...}, {'algorithm': {}, 'config_hash': {'algorithm': 'bf21a9e8fbc5a3846fb05b4fa0859e0917b2202f', 'config': 'f74b7b5b829639de7187b0517124671171e3886c', 'pipeline': '0a79122f55ba7d73b9d4a4993303bd1034099fc4'}, 'duration': 13.524871110916138, 'iteration': 6, 'loss': 0.5735578577665785, 'max_history_score': 0.4629264319963914, 'max_history_score_std': 0.04205540233571201, 'max_history_step': 'pipeline', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 3, 'features__selectkbest__k': 4}), 'normalizer': ('normalizer_StandardScaler', {'normalizer__with_mean': True, 'normalizer__with_std': True}), 'rebalance': ('rebalance_CondensedNearestNeighbour', {'rebalance__n_neighbors': 1})}, 'score': 0.4264421422334214, ...}, {'algorithm': {}, 'config_hash': {'algorithm': 'bf21a9e8fbc5a3846fb05b4fa0859e0917b2202f', 'config': '1eabae8e59d372b076035bdac59106753d4c3143', 'pipeline': 'f671e39c7c21287c35cc86282770be08920b7211'}, 'duration': 0.7754909992218018, 'iteration': 7, 'loss': 0.5473935951203874, 'max_history_score': 0.4629264319963914, 'max_history_score_std': 0.04205540233571201, 'max_history_step': 'pipeline', 'pipeline': {'features': ('features_SelectKBest', {'features__k': 4}), 'normalizer': ('normalizer_NoneType', {}), 'rebalance': ('rebalance_NearMiss', {'rebalance__n_neighbors': 3})}, 'score': 0.4526064048796126, ...}, {'algorithm': {}, 'config_hash': {'algorithm': 'bf21a9e8fbc5a3846fb05b4fa0859e0917b2202f', 'config': '8c4b0ea4a817610a51d42d05534a015dbcf7d6f6', 'pipeline': '78028fec3489bc1290cd6e3a5ffef640e07fd746'}, 'duration': 1.01682710647583, 'iteration': 8, 'loss': 0.45340779522638897, 'max_history_score': 0.546592204773611, 'max_history_score_std': 0.04157271294583304, 'max_history_step': 'pipeline', 'pipeline': {'features': ('features_PCA', {'features__n_components': 2}), 'normalizer': ('normalizer_MinMaxScaler', {}), 'rebalance': ('rebalance_NoneType', {})}, 'score': 0.546592204773611, ...}, {'algorithm': {'criterion': 'entropy', 'max_depth': 4, 'max_features': 3, 'max_leaf_nodes': None, 'min_samples_leaf': 4, 'min_samples_split': 2, 'splitter': 'random'}, 'config_hash': {'algorithm': '9a5aa4d1141074f6b9047871fcb0b33ccfcfd3d3', 'config': '92935a6b2d506658f91a16fec98aae7c7c18849e', 'pipeline': '78028fec3489bc1290cd6e3a5ffef640e07fd746'}, 'duration': 0.9999289512634277, 'iteration': 9, 'loss': 1.0, 'max_history_score': 0.546592204773611, 'max_history_score_std': 0.04157271294583304, 'max_history_step': 'pipeline', 'pipeline': {'features': ('features_PCA', {'features__n_components': 2}), 'normalizer': ('normalizer_MinMaxScaler', {}), 'rebalance': ('rebalance_NoneType', {})}, 'score': 0.0, ...}, {'algorithm': {'criterion': 'gini', 'max_depth': 1, 'max_features': None, 'max_leaf_nodes': 3, 'min_samples_leaf': 5, 'min_samples_split': 5, 'splitter': 'best'}, 'config_hash': {'algorithm': 'ecf5b568d6e3c2ab306a7bcf2b124903c3a3067b', 'config': '97df063c7bd2eed3d6c210b081267d6af4779728', 'pipeline': '78028fec3489bc1290cd6e3a5ffef640e07fd746'}, 'duration': 4.798619031906128, 'iteration': 10, 'loss': 0.71905333522791, 'max_history_score': 0.546592204773611, 'max_history_score_std': 0.04157271294583304, 'max_history_step': 'pipeline', 'pipeline': {'features': ('features_PCA', {'features__n_components': 2}), 'normalizer': ('normalizer_MinMaxScaler', {}), 'rebalance': ('rebalance_NoneType', {})}, 'score': 0.28094666477209, ...}], 'history_hash': ['ca5ca4efa90c01bc7221121efcc4d9c81cc5f6d0', 'e2ef5dfe43753524001a5fcbab4886cbde2b3e42', '2c3bccf18791b309fa8b48e68103ac95d47230a3', '650d610fc79551ca01c9d51200374e435c9787c0', '1daa3503ea9eec94f212644bb7c537963ab2ac4e', 'b35ef6c13761b660f5939aa43874dd8c140f716f', 'f74b7b5b829639de7187b0517124671171e3886c', '1eabae8e59d372b076035bdac59106753d4c3143', '8c4b0ea4a817610a51d42d05534a015dbcf7d6f6', '92935a6b2d506658f91a16fec98aae7c7c18849e', '97df063c7bd2eed3d6c210b081267d6af4779728'], 'history_index': {'1daa3503ea9eec94f212644bb7c537963ab2ac4e': 4, '1eabae8e59d372b076035bdac59106753d4c3143': 7, '2c3bccf18791b309fa8b48e68103ac95d47230a3': 2, '650d610fc79551ca01c9d51200374e435c9787c0': 3, '8c4b0ea4a817610a51d42d05534a015dbcf7d6f6': 8, '92935a6b2d506658f91a16fec98aae7c7c18849e': 9, '97df063c7bd2eed3d6c210b081267d6af4779728': 10, 'b35ef6c13761b660f5939aa43874dd8c140f716f': 5, 'ca5ca4efa90c01bc7221121efcc4d9c81cc5f6d0': 0, 'e2ef5dfe43753524001a5fcbab4886cbde2b3e42': 1, ...}, 'iteration': 10, 'max_history_score': 0.546592204773611, 'max_history_score_std': 0.04157271294583304, 'max_history_step': 'pipeline'}
        config = {'algorithm': 'DecisionTree', 'reset_trial': False, 'seed': 42, 'step_algorithm': 15, 'step_pipeline': 15, 'time': 300}
    111 
    112 def get_baseline_score(algorithm, X, y, seed):
    113     pipeline, _ = pipeline_conf_to_full_pipeline(
    114         get_baseline(), 

...........................................................................
/home/aquemy/dev/dp_hyperparameters/extension/experiment/objective.py in objective(pipeline_config={'features': ('features_PCA', {'features__n_components': 2}), 'normalizer': ('normalizer_MinMaxScaler', {}), 'rebalance': ('rebalance_NoneType', {})}, algo_config={'criterion': 'entropy', 'max_depth': 4, 'max_features': 3, 'max_leaf_nodes': 2, 'min_samples_leaf': 2, 'min_samples_split': 5, 'splitter': 'random'}, algorithm='DecisionTree', X=array([[ 0.,  0.,  5., ...,  0.,  0.,  0.],
    ...0.],
       [ 0.,  0., 10., ..., 12.,  1.,  0.]]), y=array([0, 1, 2, ..., 8, 9, 8]), context={'baseline_score': 0.8370850802141552, 'baseline_score_std': 0.04023050598893108, 'best_config': {'algorithm': {}, 'config_hash': {'algorithm': 'bf21a9e8fbc5a3846fb05b4fa0859e0917b2202f', 'config': '8c4b0ea4a817610a51d42d05534a015dbcf7d6f6', 'pipeline': '78028fec3489bc1290cd6e3a5ffef640e07fd746'}, 'duration': 1.01682710647583, 'iteration': 8, 'loss': 0.45340779522638897, 'max_history_score': 0.546592204773611, 'max_history_score_std': 0.04157271294583304, 'max_history_step': 'pipeline', 'pipeline': {'features': ('features_PCA', {'features__n_components': 2}), 'normalizer': ('normalizer_MinMaxScaler', {}), 'rebalance': ('rebalance_NoneType', {})}, 'score': 0.546592204773611, ...}, 'history': [{'algorithm': {}, 'config_hash': {'algorithm': 'bf21a9e8fbc5a3846fb05b4fa0859e0917b2202f', 'config': 'ca5ca4efa90c01bc7221121efcc4d9c81cc5f6d0', 'pipeline': 'e7db9df9682e59ebeb9a13264e2de218c38a3119'}, 'duration': 20.03913402557373, 'iteration': 0, 'loss': 0.8859695582333075, 'max_history_score': 0.1140304417666925, 'max_history_score_std': 0.0205735154132599, 'max_history_step': 'pipeline', 'pipeline': {'features': ('features_PCA', {'features__n_components': 1}), 'normalizer': ('normalizer_StandardScaler', {'normalizer__with_mean': True, 'normalizer__with_std': True}), 'rebalance': ('rebalance_CondensedNearestNeighbour', {'rebalance__n_neighbors': 3})}, 'score': 0.1140304417666925, ...}, {'algorithm': {'criterion': 'gini', 'max_depth': 2, 'max_features': 2, 'max_leaf_nodes': None, 'min_samples_leaf': 4, 'min_samples_split': 5, 'splitter': 'random'}, 'config_hash': {'algorithm': 'c4587a515ec4d7862c26abb6c7b2069ec2788a3c', 'config': 'e2ef5dfe43753524001a5fcbab4886cbde2b3e42', 'pipeline': 'e7db9df9682e59ebeb9a13264e2de218c38a3119'}, 'duration': 7.673176050186157, 'iteration': 1, 'loss': 1.0, 'max_history_score': 0.1140304417666925, 'max_history_score_std': 0.0205735154132599, 'max_history_step': 'pipeline', 'pipeline': {'features': ('features_PCA', {'features__n_components': 1}), 'normalizer': ('normalizer_StandardScaler', {'normalizer__with_mean': True, 'normalizer__with_std': True}), 'rebalance': ('rebalance_CondensedNearestNeighbour', {'rebalance__n_neighbors': 3})}, 'score': 0.0, ...}, {'algorithm': {'criterion': 'gini', 'max_depth': 3, 'max_features': 1, 'max_leaf_nodes': 2, 'min_samples_leaf': 4, 'min_samples_split': 3, 'splitter': 'random'}, 'config_hash': {'algorithm': 'b8f20163e3a63f6d337affac58f19f59c1042fdf', 'config': '2c3bccf18791b309fa8b48e68103ac95d47230a3', 'pipeline': 'e7db9df9682e59ebeb9a13264e2de218c38a3119'}, 'duration': 21.382025003433228, 'iteration': 2, 'loss': 0.8953686047024499, 'max_history_score': 0.1140304417666925, 'max_history_score_std': 0.0205735154132599, 'max_history_step': 'pipeline', 'pipeline': {'features': ('features_PCA', {'features__n_components': 1}), 'normalizer': ('normalizer_StandardScaler', {'normalizer__with_mean': True, 'normalizer__with_std': True}), 'rebalance': ('rebalance_CondensedNearestNeighbour', {'rebalance__n_neighbors': 3})}, 'score': 0.10463139529755008, ...}, {'algorithm': {}, 'config_hash': {'algorithm': 'bf21a9e8fbc5a3846fb05b4fa0859e0917b2202f', 'config': '650d610fc79551ca01c9d51200374e435c9787c0', 'pipeline': '1ad3dcf81ee45846a12eb92026a29afcf2a1775b'}, 'duration': 12.787569999694824, 'iteration': 3, 'loss': 0.748813833006884, 'max_history_score': 0.251186166993116, 'max_history_score_std': 0.07154325263262472, 'max_history_step': 'pipeline', 'pipeline': {'features': ('features_SelectKBest', {'features__k': 2}), 'normalizer': ('normalizer_MinMaxScaler', {}), 'rebalance': ('rebalance_CondensedNearestNeighbour', {'rebalance__n_neighbors': 1})}, 'score': 0.251186166993116, ...}, {'algorithm': {}, 'config_hash': {'algorithm': 'bf21a9e8fbc5a3846fb05b4fa0859e0917b2202f', 'config': '1daa3503ea9eec94f212644bb7c537963ab2ac4e', 'pipeline': '2235081205d7d7fae0d7335c028eccad689bcf9c'}, 'duration': 20.381888151168823, 'iteration': 4, 'loss': 0.5370735680036086, 'max_history_score': 0.4629264319963914, 'max_history_score_std': 0.04205540233571201, 'max_history_step': 'pipeline', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 4, 'features__selectkbest__k': 2}), 'normalizer': ('normalizer_NoneType', {}), 'rebalance': ('rebalance_CondensedNearestNeighbour', {'rebalance__n_neighbors': 3})}, 'score': 0.4629264319963914, ...}, {'algorithm': {'criterion': 'entropy', 'max_depth': None, 'max_features': 1, 'max_leaf_nodes': 3, 'min_samples_leaf': 1, 'min_samples_split': 2, 'splitter': 'random'}, 'config_hash': {'algorithm': '71cd9bb7b8b0ff2a3dbdca44537bafc4f6b2c716', 'config': 'b35ef6c13761b660f5939aa43874dd8c140f716f', 'pipeline': '2235081205d7d7fae0d7335c028eccad689bcf9c'}, 'duration': 20.211046934127808, 'iteration': 5, 'loss': 0.8151901497270952, 'max_history_score': 0.4629264319963914, 'max_history_score_std': 0.04205540233571201, 'max_history_step': 'pipeline', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 4, 'features__selectkbest__k': 2}), 'normalizer': ('normalizer_NoneType', {}), 'rebalance': ('rebalance_CondensedNearestNeighbour', {'rebalance__n_neighbors': 3})}, 'score': 0.1848098502729048, ...}, {'algorithm': {}, 'config_hash': {'algorithm': 'bf21a9e8fbc5a3846fb05b4fa0859e0917b2202f', 'config': 'f74b7b5b829639de7187b0517124671171e3886c', 'pipeline': '0a79122f55ba7d73b9d4a4993303bd1034099fc4'}, 'duration': 13.524871110916138, 'iteration': 6, 'loss': 0.5735578577665785, 'max_history_score': 0.4629264319963914, 'max_history_score_std': 0.04205540233571201, 'max_history_step': 'pipeline', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 3, 'features__selectkbest__k': 4}), 'normalizer': ('normalizer_StandardScaler', {'normalizer__with_mean': True, 'normalizer__with_std': True}), 'rebalance': ('rebalance_CondensedNearestNeighbour', {'rebalance__n_neighbors': 1})}, 'score': 0.4264421422334214, ...}, {'algorithm': {}, 'config_hash': {'algorithm': 'bf21a9e8fbc5a3846fb05b4fa0859e0917b2202f', 'config': '1eabae8e59d372b076035bdac59106753d4c3143', 'pipeline': 'f671e39c7c21287c35cc86282770be08920b7211'}, 'duration': 0.7754909992218018, 'iteration': 7, 'loss': 0.5473935951203874, 'max_history_score': 0.4629264319963914, 'max_history_score_std': 0.04205540233571201, 'max_history_step': 'pipeline', 'pipeline': {'features': ('features_SelectKBest', {'features__k': 4}), 'normalizer': ('normalizer_NoneType', {}), 'rebalance': ('rebalance_NearMiss', {'rebalance__n_neighbors': 3})}, 'score': 0.4526064048796126, ...}, {'algorithm': {}, 'config_hash': {'algorithm': 'bf21a9e8fbc5a3846fb05b4fa0859e0917b2202f', 'config': '8c4b0ea4a817610a51d42d05534a015dbcf7d6f6', 'pipeline': '78028fec3489bc1290cd6e3a5ffef640e07fd746'}, 'duration': 1.01682710647583, 'iteration': 8, 'loss': 0.45340779522638897, 'max_history_score': 0.546592204773611, 'max_history_score_std': 0.04157271294583304, 'max_history_step': 'pipeline', 'pipeline': {'features': ('features_PCA', {'features__n_components': 2}), 'normalizer': ('normalizer_MinMaxScaler', {}), 'rebalance': ('rebalance_NoneType', {})}, 'score': 0.546592204773611, ...}, {'algorithm': {'criterion': 'entropy', 'max_depth': 4, 'max_features': 3, 'max_leaf_nodes': None, 'min_samples_leaf': 4, 'min_samples_split': 2, 'splitter': 'random'}, 'config_hash': {'algorithm': '9a5aa4d1141074f6b9047871fcb0b33ccfcfd3d3', 'config': '92935a6b2d506658f91a16fec98aae7c7c18849e', 'pipeline': '78028fec3489bc1290cd6e3a5ffef640e07fd746'}, 'duration': 0.9999289512634277, 'iteration': 9, 'loss': 1.0, 'max_history_score': 0.546592204773611, 'max_history_score_std': 0.04157271294583304, 'max_history_step': 'pipeline', 'pipeline': {'features': ('features_PCA', {'features__n_components': 2}), 'normalizer': ('normalizer_MinMaxScaler', {}), 'rebalance': ('rebalance_NoneType', {})}, 'score': 0.0, ...}, {'algorithm': {'criterion': 'gini', 'max_depth': 1, 'max_features': None, 'max_leaf_nodes': 3, 'min_samples_leaf': 5, 'min_samples_split': 5, 'splitter': 'best'}, 'config_hash': {'algorithm': 'ecf5b568d6e3c2ab306a7bcf2b124903c3a3067b', 'config': '97df063c7bd2eed3d6c210b081267d6af4779728', 'pipeline': '78028fec3489bc1290cd6e3a5ffef640e07fd746'}, 'duration': 4.798619031906128, 'iteration': 10, 'loss': 0.71905333522791, 'max_history_score': 0.546592204773611, 'max_history_score_std': 0.04157271294583304, 'max_history_step': 'pipeline', 'pipeline': {'features': ('features_PCA', {'features__n_components': 2}), 'normalizer': ('normalizer_MinMaxScaler', {}), 'rebalance': ('rebalance_NoneType', {})}, 'score': 0.28094666477209, ...}], 'history_hash': ['ca5ca4efa90c01bc7221121efcc4d9c81cc5f6d0', 'e2ef5dfe43753524001a5fcbab4886cbde2b3e42', '2c3bccf18791b309fa8b48e68103ac95d47230a3', '650d610fc79551ca01c9d51200374e435c9787c0', '1daa3503ea9eec94f212644bb7c537963ab2ac4e', 'b35ef6c13761b660f5939aa43874dd8c140f716f', 'f74b7b5b829639de7187b0517124671171e3886c', '1eabae8e59d372b076035bdac59106753d4c3143', '8c4b0ea4a817610a51d42d05534a015dbcf7d6f6', '92935a6b2d506658f91a16fec98aae7c7c18849e', '97df063c7bd2eed3d6c210b081267d6af4779728'], 'history_index': {'1daa3503ea9eec94f212644bb7c537963ab2ac4e': 4, '1eabae8e59d372b076035bdac59106753d4c3143': 7, '2c3bccf18791b309fa8b48e68103ac95d47230a3': 2, '650d610fc79551ca01c9d51200374e435c9787c0': 3, '8c4b0ea4a817610a51d42d05534a015dbcf7d6f6': 8, '92935a6b2d506658f91a16fec98aae7c7c18849e': 9, '97df063c7bd2eed3d6c210b081267d6af4779728': 10, 'b35ef6c13761b660f5939aa43874dd8c140f716f': 5, 'ca5ca4efa90c01bc7221121efcc4d9c81cc5f6d0': 0, 'e2ef5dfe43753524001a5fcbab4886cbde2b3e42': 1, ...}, 'iteration': 10, 'max_history_score': 0.546592204773611, 'max_history_score_std': 0.04157271294583304, 'max_history_step': 'pipeline'}, config={'algorithm': 'DecisionTree', 'reset_trial': False, 'seed': 42, 'step_algorithm': 15, 'step_pipeline': 15, 'time': 300}, step='algorithm')
     45                 y,
     46                 cv=10,
     47                 n_jobs=-1,
     48                 return_estimator=False,
     49                 return_train_score=False,
---> 50                 verbose=0)
     51         score = np.mean(scores['test_score'])
     52         std = np.std(scores['test_score'])
     53         status = STATUS_OK
     54     except Exception as e:

...........................................................................
/home/aquemy/.local/lib/python2.7/site-packages/sklearn/model_selection/_validation.py in cross_validate(estimator=Pipeline(memory=None,
     steps=[('normalizer',...ort=False, random_state=42, splitter='random'))]), X=array([[ 0.,  0.,  5., ...,  0.,  0.,  0.],
    ...0.],
       [ 0.,  0., 10., ..., 12.,  1.,  0.]]), y=array([0, 1, 2, ..., 8, 9, 8]), groups=None, scoring=None, cv=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1, verbose=0, fit_params=None, pre_dispatch='2*n_jobs', return_train_score=False, return_estimator=False, error_score='raise-deprecating')
    235         delayed(_fit_and_score)(
    236             clone(estimator), X, y, scorers, train, test, verbose, None,
    237             fit_params, return_train_score=return_train_score,
    238             return_times=True, return_estimator=return_estimator,
    239             error_score=error_score)
--> 240         for train, test in cv.split(X, y, groups))
        cv.split = <bound method StratifiedKFold.split of Stratifie...d(n_splits=10, random_state=None, shuffle=False)>
        X = array([[ 0.,  0.,  5., ...,  0.,  0.,  0.],
    ...0.],
       [ 0.,  0., 10., ..., 12.,  1.,  0.]])
        y = array([0, 1, 2, ..., 8, 9, 8])
        groups = None
    241 
    242     zipped_scores = list(zip(*scores))
    243     if return_train_score:
    244         train_scores = zipped_scores.pop(0)

...........................................................................
/home/aquemy/.local/lib/python2.7/site-packages/sklearn/externals/joblib/parallel.py in __call__(self=Parallel(n_jobs=-1), iterable=<generator object <genexpr>>)
    925                 # No need to wait for async callbacks to trigger to
    926                 # consumption.
    927                 self._iterating = False
    928 
    929             with self._backend.retrieval_context():
--> 930                 self.retrieve()
        self.retrieve = <bound method Parallel.retrieve of Parallel(n_jobs=-1)>
    931             # Make sure that we get a last message telling us we are done
    932             elapsed_time = time.time() - self._start_time
    933             self._print('Done %3i out of %3i | elapsed: %s finished',
    934                         (len(self._output), len(self._output),

---------------------------------------------------------------------------
Joblib worker traceback:
---------------------------------------------------------------------------
ValueError                                         Wed Jun  5 18:34:55 2019
PID: 6987                                   Python 2.7.15+: /usr/bin/python
...........................................................................
/home/aquemy/.local/lib/python2.7/site-packages/sklearn/externals/joblib/parallel.py in __call__(self=<sklearn.externals.joblib.parallel.BatchedCalls object>)
    220     def __call__(self):
    221         # Set the default nested backend to self._backend but do not set the
    222         # change the default number of processes to -1
    223         with parallel_backend(self._backend, n_jobs=self._n_jobs):
    224             return [func(*args, **kwargs)
--> 225                     for func, args, kwargs in self.items]
        func = <function _fit_and_score>
        args = (Pipeline(memory=None,
     steps=[('normalizer',...ort=False, random_state=42, splitter='random'))]), array([[ 0.,  0.,  5., ...,  0.,  0.,  0.],
    ...0.],
       [ 0.,  0., 10., ..., 12.,  1.,  0.]]), array([0, 1, 2, ..., 8, 9, 8]), {'score': <function _passthrough_scorer>}, array([ 169,  176,  178, ..., 1794, 1795, 1796]), array([  0,   1,   2,   3,   4,   5,   6,   7,  ..., 181, 186, 188, 189, 190,
       194, 195, 198]), 0, None, None)
        kwargs = {'error_score': 'raise-deprecating', 'return_estimator': False, 'return_times': True, 'return_train_score': False}
        self.items = [(<function _fit_and_score>, (Pipeline(memory=None,
     steps=[('normalizer',...ort=False, random_state=42, splitter='random'))]), array([[ 0.,  0.,  5., ...,  0.,  0.,  0.],
    ...0.],
       [ 0.,  0., 10., ..., 12.,  1.,  0.]]), array([0, 1, 2, ..., 8, 9, 8]), {'score': <function _passthrough_scorer>}, array([ 169,  176,  178, ..., 1794, 1795, 1796]), array([  0,   1,   2,   3,   4,   5,   6,   7,  ..., 181, 186, 188, 189, 190,
       194, 195, 198]), 0, None, None), {'error_score': 'raise-deprecating', 'return_estimator': False, 'return_times': True, 'return_train_score': False})]
    226 
    227     def __len__(self):
    228         return self._size
    229 

...........................................................................
/home/aquemy/.local/lib/python2.7/site-packages/sklearn/model_selection/_validation.py in _fit_and_score(estimator=Pipeline(memory=None,
     steps=[('normalizer',...ort=False, random_state=42, splitter='random'))]), X=array([[ 0.,  0.,  5., ...,  0.,  0.,  0.],
    ...0.],
       [ 0.,  0., 10., ..., 12.,  1.,  0.]]), y=array([0, 1, 2, ..., 8, 9, 8]), scorer={'score': <function _passthrough_scorer>}, train=array([ 169,  176,  178, ..., 1794, 1795, 1796]), test=array([  0,   1,   2,   3,   4,   5,   6,   7,  ..., 181, 186, 188, 189, 190,
       194, 195, 198]), verbose=0, parameters=None, fit_params={}, return_train_score=False, return_parameters=False, return_n_test_samples=False, return_times=True, return_estimator=False, error_score='raise-deprecating')
    523 
    524     try:
    525         if y_train is None:
    526             estimator.fit(X_train, **fit_params)
    527         else:
--> 528             estimator.fit(X_train, y_train, **fit_params)
        estimator.fit = <bound method Pipeline.fit of Pipeline(memory=No...rt=False, random_state=42, splitter='random'))])>
        X_train = array([[ 0.,  0.,  6., ...,  9.,  4.,  0.],
    ...0.],
       [ 0.,  0., 10., ..., 12.,  1.,  0.]])
        y_train = array([9, 5, 0, ..., 8, 9, 8])
        fit_params = {}
    529 
    530     except Exception as e:
    531         # Note fit time as time until error
    532         fit_time = time.time() - start_time

...........................................................................
/usr/local/lib/python2.7/dist-packages/imblearn/pipeline.py in fit(self=Pipeline(memory=None,
     steps=[('normalizer',...ort=False, random_state=42, splitter='random'))]), X=array([[ 0.,  0.,  6., ...,  9.,  4.,  0.],
    ...0.],
       [ 0.,  0., 10., ..., 12.,  1.,  0.]]), y=array([9, 5, 0, ..., 8, 9, 8]), **fit_params={})
    234             This estimator
    235 
    236         """
    237         Xt, yt, fit_params = self._fit(X, y, **fit_params)
    238         if self._final_estimator is not None:
--> 239             self._final_estimator.fit(Xt, yt, **fit_params)
        self._final_estimator.fit = <bound method DecisionTreeClassifier.fit of Deci...esort=False, random_state=42, splitter='random')>
        Xt = array([[-0.96093849,  0.85576824],
       [-0.27... 0.8493081 ],
       [-0.04169894,  0.24884471]])
        yt = array([9, 5, 0, ..., 8, 9, 8])
        fit_params = {}
    240         return self
    241 
    242     def fit_transform(self, X, y=None, **fit_params):
    243         """Fit the model and transform with the final estimator

...........................................................................
/home/aquemy/.local/lib/python2.7/site-packages/sklearn/tree/tree.py in fit(self=DecisionTreeClassifier(class_weight=None, criter...resort=False, random_state=42, splitter='random'), X=array([[-0.96093849,  0.85576824],
       [-0.27... 0.8493081 ],
       [-0.04169894,  0.24884471]]), y=array([9, 5, 0, ..., 8, 9, 8]), sample_weight=None, check_input=True, X_idx_sorted=None)
    796 
    797         super(DecisionTreeClassifier, self).fit(
    798             X, y,
    799             sample_weight=sample_weight,
    800             check_input=check_input,
--> 801             X_idx_sorted=X_idx_sorted)
        X_idx_sorted = None
    802         return self
    803 
    804     def predict_proba(self, X, check_input=True):
    805         """Predict class probabilities of the input samples X.

...........................................................................
/home/aquemy/.local/lib/python2.7/site-packages/sklearn/tree/tree.py in fit(self=DecisionTreeClassifier(class_weight=None, criter...resort=False, random_state=42, splitter='random'), X=array([[-0.9609385 ,  0.85576826],
       [-0.27...      [-0.04169894,  0.24884471]], dtype=float32), y=array([[9.],
       [5.],
       [0.],
       ...,
       [8.],
       [9.],
       [8.]]), sample_weight=None, check_input=True, X_idx_sorted=None)
    237         if not 0 <= self.min_weight_fraction_leaf <= 0.5:
    238             raise ValueError("min_weight_fraction_leaf must in [0, 0.5]")
    239         if max_depth <= 0:
    240             raise ValueError("max_depth must be greater than zero. ")
    241         if not (0 < max_features <= self.n_features_):
--> 242             raise ValueError("max_features must be in (0, n_features]")
    243         if not isinstance(max_leaf_nodes, (numbers.Integral, np.integer)):
    244             raise ValueError("max_leaf_nodes must be integral number but was "
    245                              "%r" % max_leaf_nodes)
    246         if -1 < max_leaf_nodes < 2:

ValueError: max_features must be in (0, n_features]
___________________________________________________________________________
Best score: 0.546592204774 (0.0415727129458) [P] | Score: 0.0 (0.0) [A]
Best score: 0.546592204774 (0.0415727129458) [P] | Score: 0.324767121223 (0.0364626179778) [A]
Best score: 0.546592204774 (0.0415727129458) [P] | Score: 0.404635762519 (0.0390247164288) [A]
JoblibValueError
___________________________________________________________________________
...........................................................................
/home/aquemy/dev/dp_hyperparameters/extension/main.py in <module>()
     27 
     28     serializer.serialize_results(scenario, policy)
     29 
     30 if __name__ == "__main__":
     31     args = cli.parse_args()
---> 32     main(args)

...........................................................................
/home/aquemy/dev/dp_hyperparameters/extension/main.py in main(args=Namespace(customize=[(['control', 'seed'], '42')...scenarios/dt_digits_iterative.yaml', verbosity=0))
     21         test_size=0.4, 
     22         random_state=scenario['control']['seed']
     23     )
     24 
     25     policy = policies.initiate(scenario['setup']['policy'], config)
---> 26     policy.run(X,y)
        policy.run = <bound method Iterative.run of <experiment.policies.iterative.Iterative object>>
        X = array([[ 0.,  0.,  5., ...,  0.,  0.,  0.],
    ...0.],
       [ 0.,  0., 10., ..., 12.,  1.,  0.]])
        y = array([0, 1, 2, ..., 8, 9, 8])
     27 
     28     serializer.serialize_results(scenario, policy)
     29 
     30 if __name__ == "__main__":

...........................................................................
/home/aquemy/dev/dp_hyperparameters/extension/experiment/policies/iterative.py in run(self=<experiment.policies.iterative.Iterative object>, X=array([[ 0.,  0.,  5., ...,  0.,  0.,  0.],
    ...0.],
       [ 0.,  0., 10., ..., 12.,  1.,  0.]]), y=array([0, 1, 2, ..., 8, 9, 8]))
     59                 algo=tpe.suggest, 
     60                 max_evals=None,
     61                 max_time=self.config['step_algorithm'],
     62                 trials=trials_algo,
     63                 show_progressbar=False,
---> 64                 verbose=0
     65             )
     66             best_config = self.context['best_config']
     67             current_pipeline_configuration = best_config['pipeline']
     68             super(Iterative, self).display_step_results(best_config)

...........................................................................
/home/aquemy/dev/dp_hyperparameters/extension/hyperopt/fmin.py in fmin(fn=<functools.partial object>, space={'criterion': <hyperopt.pyll.base.Apply object>, 'max_depth': <hyperopt.pyll.base.Apply object>, 'max_features': <hyperopt.pyll.base.Apply object>, 'max_leaf_nodes': <hyperopt.pyll.base.Apply object>, 'min_samples_leaf': <hyperopt.pyll.base.Apply object>, 'min_samples_split': <hyperopt.pyll.base.Apply object>, 'splitter': <hyperopt.pyll.base.Apply object>}, algo=<function suggest>, max_evals=9223372036854775807, max_time=15, trials=<hyperopt.base.Trials object>, rstate=<mtrand.RandomState object>, allow_trials_fmin=True, pass_expr_memo_ctrl=None, catch_eval_exceptions=False, verbose=0, return_argmin=True, points_to_evaluate=None, max_queue_len=1, show_progressbar=False)
    406             pass_expr_memo_ctrl=pass_expr_memo_ctrl,
    407             verbose=verbose,
    408             catch_eval_exceptions=catch_eval_exceptions,
    409             return_argmin=return_argmin,
    410             show_progressbar=show_progressbar,
--> 411             max_time=max_time
        max_time = 15
    412         )
    413 
    414     if trials is None:
    415         if points_to_evaluate is None:

...........................................................................
/home/aquemy/dev/dp_hyperparameters/extension/hyperopt/base.py in fmin(self=<hyperopt.base.Trials object>, fn=<functools.partial object>, space={'criterion': <hyperopt.pyll.base.Apply object>, 'max_depth': <hyperopt.pyll.base.Apply object>, 'max_features': <hyperopt.pyll.base.Apply object>, 'max_leaf_nodes': <hyperopt.pyll.base.Apply object>, 'min_samples_leaf': <hyperopt.pyll.base.Apply object>, 'min_samples_split': <hyperopt.pyll.base.Apply object>, 'splitter': <hyperopt.pyll.base.Apply object>}, algo=<function suggest>, max_evals=9223372036854775807, max_time=15, rstate=<mtrand.RandomState object>, verbose=0, pass_expr_memo_ctrl=None, catch_eval_exceptions=False, return_argmin=True, show_progressbar=False)
    636             verbose=verbose,
    637             allow_trials_fmin=False,  # -- prevent recursion
    638             pass_expr_memo_ctrl=pass_expr_memo_ctrl,
    639             catch_eval_exceptions=catch_eval_exceptions,
    640             return_argmin=return_argmin,
--> 641             show_progressbar=show_progressbar)
        show_progressbar = False
    642 
    643 
    644 def trials_from_docs(docs, validate=True, **kwargs):
    645     """Construct a Trials base class instance from a list of trials documents

...........................................................................
/home/aquemy/dev/dp_hyperparameters/extension/hyperopt/fmin.py in fmin(fn=<functools.partial object>, space={'criterion': <hyperopt.pyll.base.Apply object>, 'max_depth': <hyperopt.pyll.base.Apply object>, 'max_features': <hyperopt.pyll.base.Apply object>, 'max_leaf_nodes': <hyperopt.pyll.base.Apply object>, 'min_samples_leaf': <hyperopt.pyll.base.Apply object>, 'min_samples_split': <hyperopt.pyll.base.Apply object>, 'splitter': <hyperopt.pyll.base.Apply object>}, algo=<function suggest>, max_evals=9223372036854775807, max_time=15, trials=<hyperopt.base.Trials object>, rstate=<mtrand.RandomState object>, allow_trials_fmin=False, pass_expr_memo_ctrl=None, catch_eval_exceptions=False, verbose=0, return_argmin=True, points_to_evaluate=None, max_queue_len=1, show_progressbar=False)
    426                     verbose=verbose,
    427                     max_queue_len=max_queue_len,
    428                     show_progressbar=show_progressbar,
    429                     max_time=max_time)
    430     rval.catch_eval_exceptions = catch_eval_exceptions
--> 431     rval.exhaust()
        rval.exhaust = <bound method FMinIter.exhaust of <hyperopt.fmin.FMinIter object>>
    432     if return_argmin:
    433         return trials.argmin
    434     elif len(trials) > 0:
    435         # Only if there are some succesfull trail runs, return the best point in the evaluation space

...........................................................................
/home/aquemy/dev/dp_hyperparameters/extension/hyperopt/fmin.py in exhaust(self=<hyperopt.fmin.FMinIter object>)
    273             raise StopIteration()
    274         return self.trials
    275 
    276     def exhaust(self):
    277         n_done = len(self.trials)
--> 278         self.run(self.max_evals - n_done, block_until_done=self.asynchronous)
        self.run = <bound method FMinIter.run of <hyperopt.fmin.FMinIter object>>
        self.max_evals = 9223372036854775807
        n_done = 3
        self.asynchronous = False
    279         self.trials.refresh()
    280         return self
    281 
    282 

...........................................................................
/home/aquemy/dev/dp_hyperparameters/extension/hyperopt/fmin.py in run(self=<hyperopt.fmin.FMinIter object>, N=9223372036854775804, block_until_done=False)
    232                     if self.asynchronous:
    233                         # -- wait for workers to fill in the trials
    234                         time.sleep(self.poll_interval_secs)
    235                     else:
    236                         # -- loop over trials and do the jobs directly
--> 237                         self.serial_evaluate()
        self.serial_evaluate = <bound method FMinIter.serial_evaluate of <hyperopt.fmin.FMinIter object>>
    238                     try:
    239                         res = [d['result']['loss'] for d in
    240                                          self.trials.trials if
    241                                          d['result']['status'] == 'ok']

...........................................................................
/home/aquemy/dev/dp_hyperparameters/extension/hyperopt/fmin.py in serial_evaluate(self=<hyperopt.fmin.FMinIter object>, N=-1)
    138                 trial['book_time'] = now
    139                 trial['refresh_time'] = now
    140                 spec = base.spec_from_misc(trial['misc'])
    141                 ctrl = base.Ctrl(self.trials, current_trial=trial)
    142                 try:
--> 143                     result = self.domain.evaluate(spec, ctrl)
        result = undefined
        self.domain.evaluate = <bound method Domain.evaluate of <hyperopt.base.Domain object>>
        spec = {'criterion': 0, 'max_depth': 1, 'max_features': 2, 'max_leaf_nodes': 0, 'min_samples_leaf': 1, 'min_samples_split': 2, 'splitter': 0}
        ctrl = <hyperopt.base.Ctrl object>
    144                 except Exception as e:
    145                     logger.info('job exception: %s' % str(e))
    146                     trial['state'] = base.JOB_STATE_ERROR
    147                     trial['misc']['error'] = (str(type(e)), str(e))

...........................................................................
/home/aquemy/dev/dp_hyperparameters/extension/hyperopt/base.py in evaluate(self=<hyperopt.base.Domain object>, config={'criterion': 0, 'max_depth': 1, 'max_features': 2, 'max_leaf_nodes': 0, 'min_samples_leaf': 1, 'min_samples_split': 2, 'splitter': 0}, ctrl=<hyperopt.base.Ctrl object>, attach_attachments=True)
    841             #    or the normal Python part (self.fn)
    842             pyll_rval = pyll.rec_eval(
    843                 self.expr,
    844                 memo=memo,
    845                 print_node_on_error=self.rec_eval_print_node_on_error)
--> 846             rval = self.fn(pyll_rval)
        rval = undefined
        self.fn = <functools.partial object>
        pyll_rval = {'criterion': 'gini', 'max_depth': 2, 'max_features': 3, 'max_leaf_nodes': 2, 'min_samples_leaf': 2, 'min_samples_split': 5, 'splitter': 'best'}
    847 
    848         if isinstance(rval, (float, int, np.number)):
    849             dict_rval = {'loss': float(rval), 'status': STATUS_OK}
    850         else:

...........................................................................
/home/aquemy/dev/dp_hyperparameters/extension/experiment/objective.py in objective_algo(algo_config={'criterion': 'gini', 'max_depth': 2, 'max_features': 3, 'max_leaf_nodes': 2, 'min_samples_leaf': 2, 'min_samples_split': 5, 'splitter': 'best'}, current_pipeline_config={'features': ('features_PCA', {'features__n_components': 2}), 'normalizer': ('normalizer_MinMaxScaler', {}), 'rebalance': ('rebalance_NoneType', {})}, algorithm='DecisionTree', X=array([[ 0.,  0.,  5., ...,  0.,  0.,  0.],
    ...0.],
       [ 0.,  0., 10., ..., 12.,  1.,  0.]]), y=array([0, 1, 2, ..., 8, 9, 8]), context={'baseline_score': 0.8370850802141552, 'baseline_score_std': 0.04023050598893108, 'best_config': {'algorithm': {}, 'config_hash': {'algorithm': 'bf21a9e8fbc5a3846fb05b4fa0859e0917b2202f', 'config': '8c4b0ea4a817610a51d42d05534a015dbcf7d6f6', 'pipeline': '78028fec3489bc1290cd6e3a5ffef640e07fd746'}, 'duration': 1.01682710647583, 'iteration': 8, 'loss': 0.45340779522638897, 'max_history_score': 0.546592204773611, 'max_history_score_std': 0.04157271294583304, 'max_history_step': 'pipeline', 'pipeline': {'features': ('features_PCA', {'features__n_components': 2}), 'normalizer': ('normalizer_MinMaxScaler', {}), 'rebalance': ('rebalance_NoneType', {})}, 'score': 0.546592204773611, ...}, 'history': [{'algorithm': {}, 'config_hash': {'algorithm': 'bf21a9e8fbc5a3846fb05b4fa0859e0917b2202f', 'config': 'ca5ca4efa90c01bc7221121efcc4d9c81cc5f6d0', 'pipeline': 'e7db9df9682e59ebeb9a13264e2de218c38a3119'}, 'duration': 20.03913402557373, 'iteration': 0, 'loss': 0.8859695582333075, 'max_history_score': 0.1140304417666925, 'max_history_score_std': 0.0205735154132599, 'max_history_step': 'pipeline', 'pipeline': {'features': ('features_PCA', {'features__n_components': 1}), 'normalizer': ('normalizer_StandardScaler', {'normalizer__with_mean': True, 'normalizer__with_std': True}), 'rebalance': ('rebalance_CondensedNearestNeighbour', {'rebalance__n_neighbors': 3})}, 'score': 0.1140304417666925, ...}, {'algorithm': {'criterion': 'gini', 'max_depth': 2, 'max_features': 2, 'max_leaf_nodes': None, 'min_samples_leaf': 4, 'min_samples_split': 5, 'splitter': 'random'}, 'config_hash': {'algorithm': 'c4587a515ec4d7862c26abb6c7b2069ec2788a3c', 'config': 'e2ef5dfe43753524001a5fcbab4886cbde2b3e42', 'pipeline': 'e7db9df9682e59ebeb9a13264e2de218c38a3119'}, 'duration': 7.673176050186157, 'iteration': 1, 'loss': 1.0, 'max_history_score': 0.1140304417666925, 'max_history_score_std': 0.0205735154132599, 'max_history_step': 'pipeline', 'pipeline': {'features': ('features_PCA', {'features__n_components': 1}), 'normalizer': ('normalizer_StandardScaler', {'normalizer__with_mean': True, 'normalizer__with_std': True}), 'rebalance': ('rebalance_CondensedNearestNeighbour', {'rebalance__n_neighbors': 3})}, 'score': 0.0, ...}, {'algorithm': {'criterion': 'gini', 'max_depth': 3, 'max_features': 1, 'max_leaf_nodes': 2, 'min_samples_leaf': 4, 'min_samples_split': 3, 'splitter': 'random'}, 'config_hash': {'algorithm': 'b8f20163e3a63f6d337affac58f19f59c1042fdf', 'config': '2c3bccf18791b309fa8b48e68103ac95d47230a3', 'pipeline': 'e7db9df9682e59ebeb9a13264e2de218c38a3119'}, 'duration': 21.382025003433228, 'iteration': 2, 'loss': 0.8953686047024499, 'max_history_score': 0.1140304417666925, 'max_history_score_std': 0.0205735154132599, 'max_history_step': 'pipeline', 'pipeline': {'features': ('features_PCA', {'features__n_components': 1}), 'normalizer': ('normalizer_StandardScaler', {'normalizer__with_mean': True, 'normalizer__with_std': True}), 'rebalance': ('rebalance_CondensedNearestNeighbour', {'rebalance__n_neighbors': 3})}, 'score': 0.10463139529755008, ...}, {'algorithm': {}, 'config_hash': {'algorithm': 'bf21a9e8fbc5a3846fb05b4fa0859e0917b2202f', 'config': '650d610fc79551ca01c9d51200374e435c9787c0', 'pipeline': '1ad3dcf81ee45846a12eb92026a29afcf2a1775b'}, 'duration': 12.787569999694824, 'iteration': 3, 'loss': 0.748813833006884, 'max_history_score': 0.251186166993116, 'max_history_score_std': 0.07154325263262472, 'max_history_step': 'pipeline', 'pipeline': {'features': ('features_SelectKBest', {'features__k': 2}), 'normalizer': ('normalizer_MinMaxScaler', {}), 'rebalance': ('rebalance_CondensedNearestNeighbour', {'rebalance__n_neighbors': 1})}, 'score': 0.251186166993116, ...}, {'algorithm': {}, 'config_hash': {'algorithm': 'bf21a9e8fbc5a3846fb05b4fa0859e0917b2202f', 'config': '1daa3503ea9eec94f212644bb7c537963ab2ac4e', 'pipeline': '2235081205d7d7fae0d7335c028eccad689bcf9c'}, 'duration': 20.381888151168823, 'iteration': 4, 'loss': 0.5370735680036086, 'max_history_score': 0.4629264319963914, 'max_history_score_std': 0.04205540233571201, 'max_history_step': 'pipeline', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 4, 'features__selectkbest__k': 2}), 'normalizer': ('normalizer_NoneType', {}), 'rebalance': ('rebalance_CondensedNearestNeighbour', {'rebalance__n_neighbors': 3})}, 'score': 0.4629264319963914, ...}, {'algorithm': {'criterion': 'entropy', 'max_depth': None, 'max_features': 1, 'max_leaf_nodes': 3, 'min_samples_leaf': 1, 'min_samples_split': 2, 'splitter': 'random'}, 'config_hash': {'algorithm': '71cd9bb7b8b0ff2a3dbdca44537bafc4f6b2c716', 'config': 'b35ef6c13761b660f5939aa43874dd8c140f716f', 'pipeline': '2235081205d7d7fae0d7335c028eccad689bcf9c'}, 'duration': 20.211046934127808, 'iteration': 5, 'loss': 0.8151901497270952, 'max_history_score': 0.4629264319963914, 'max_history_score_std': 0.04205540233571201, 'max_history_step': 'pipeline', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 4, 'features__selectkbest__k': 2}), 'normalizer': ('normalizer_NoneType', {}), 'rebalance': ('rebalance_CondensedNearestNeighbour', {'rebalance__n_neighbors': 3})}, 'score': 0.1848098502729048, ...}, {'algorithm': {}, 'config_hash': {'algorithm': 'bf21a9e8fbc5a3846fb05b4fa0859e0917b2202f', 'config': 'f74b7b5b829639de7187b0517124671171e3886c', 'pipeline': '0a79122f55ba7d73b9d4a4993303bd1034099fc4'}, 'duration': 13.524871110916138, 'iteration': 6, 'loss': 0.5735578577665785, 'max_history_score': 0.4629264319963914, 'max_history_score_std': 0.04205540233571201, 'max_history_step': 'pipeline', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 3, 'features__selectkbest__k': 4}), 'normalizer': ('normalizer_StandardScaler', {'normalizer__with_mean': True, 'normalizer__with_std': True}), 'rebalance': ('rebalance_CondensedNearestNeighbour', {'rebalance__n_neighbors': 1})}, 'score': 0.4264421422334214, ...}, {'algorithm': {}, 'config_hash': {'algorithm': 'bf21a9e8fbc5a3846fb05b4fa0859e0917b2202f', 'config': '1eabae8e59d372b076035bdac59106753d4c3143', 'pipeline': 'f671e39c7c21287c35cc86282770be08920b7211'}, 'duration': 0.7754909992218018, 'iteration': 7, 'loss': 0.5473935951203874, 'max_history_score': 0.4629264319963914, 'max_history_score_std': 0.04205540233571201, 'max_history_step': 'pipeline', 'pipeline': {'features': ('features_SelectKBest', {'features__k': 4}), 'normalizer': ('normalizer_NoneType', {}), 'rebalance': ('rebalance_NearMiss', {'rebalance__n_neighbors': 3})}, 'score': 0.4526064048796126, ...}, {'algorithm': {}, 'config_hash': {'algorithm': 'bf21a9e8fbc5a3846fb05b4fa0859e0917b2202f', 'config': '8c4b0ea4a817610a51d42d05534a015dbcf7d6f6', 'pipeline': '78028fec3489bc1290cd6e3a5ffef640e07fd746'}, 'duration': 1.01682710647583, 'iteration': 8, 'loss': 0.45340779522638897, 'max_history_score': 0.546592204773611, 'max_history_score_std': 0.04157271294583304, 'max_history_step': 'pipeline', 'pipeline': {'features': ('features_PCA', {'features__n_components': 2}), 'normalizer': ('normalizer_MinMaxScaler', {}), 'rebalance': ('rebalance_NoneType', {})}, 'score': 0.546592204773611, ...}, {'algorithm': {'criterion': 'entropy', 'max_depth': 4, 'max_features': 3, 'max_leaf_nodes': None, 'min_samples_leaf': 4, 'min_samples_split': 2, 'splitter': 'random'}, 'config_hash': {'algorithm': '9a5aa4d1141074f6b9047871fcb0b33ccfcfd3d3', 'config': '92935a6b2d506658f91a16fec98aae7c7c18849e', 'pipeline': '78028fec3489bc1290cd6e3a5ffef640e07fd746'}, 'duration': 0.9999289512634277, 'iteration': 9, 'loss': 1.0, 'max_history_score': 0.546592204773611, 'max_history_score_std': 0.04157271294583304, 'max_history_step': 'pipeline', 'pipeline': {'features': ('features_PCA', {'features__n_components': 2}), 'normalizer': ('normalizer_MinMaxScaler', {}), 'rebalance': ('rebalance_NoneType', {})}, 'score': 0.0, ...}, {'algorithm': {'criterion': 'gini', 'max_depth': 1, 'max_features': None, 'max_leaf_nodes': 3, 'min_samples_leaf': 5, 'min_samples_split': 5, 'splitter': 'best'}, 'config_hash': {'algorithm': 'ecf5b568d6e3c2ab306a7bcf2b124903c3a3067b', 'config': '97df063c7bd2eed3d6c210b081267d6af4779728', 'pipeline': '78028fec3489bc1290cd6e3a5ffef640e07fd746'}, 'duration': 4.798619031906128, 'iteration': 10, 'loss': 0.71905333522791, 'max_history_score': 0.546592204773611, 'max_history_score_std': 0.04157271294583304, 'max_history_step': 'pipeline', 'pipeline': {'features': ('features_PCA', {'features__n_components': 2}), 'normalizer': ('normalizer_MinMaxScaler', {}), 'rebalance': ('rebalance_NoneType', {})}, 'score': 0.28094666477209, ...}, {'algorithm': {'criterion': 'entropy', 'max_depth': 4, 'max_features': 3, 'max_leaf_nodes': 2, 'min_samples_leaf': 2, 'min_samples_split': 5, 'splitter': 'random'}, 'config_hash': {'algorithm': '4fb15d383737c031e5da0f4a5ea707659357c7de', 'config': '27800204e73eea5d7e73e87227aea28cbc1a3643', 'pipeline': '78028fec3489bc1290cd6e3a5ffef640e07fd746'}, 'duration': 1.153088092803955, 'iteration': 11, 'loss': 1.0, 'max_history_score': 0.546592204773611, 'max_history_score_std': 0.04157271294583304, 'max_history_step': 'pipeline', 'pipeline': {'features': ('features_PCA', {'features__n_components': 2}), 'normalizer': ('normalizer_MinMaxScaler', {}), 'rebalance': ('rebalance_NoneType', {})}, 'score': 0.0, ...}, {'algorithm': {'criterion': 'entropy', 'max_depth': 2, 'max_features': 2, 'max_leaf_nodes': None, 'min_samples_leaf': 5, 'min_samples_split': 2, 'splitter': 'best'}, 'config_hash': {'algorithm': '1df5f94fef9c8f306dc10711a993990eb10ade6a', 'config': 'f868e344f6a6987c0196ca818a372520a61e72ae', 'pipeline': '78028fec3489bc1290cd6e3a5ffef640e07fd746'}, 'duration': 4.58973503112793, 'iteration': 12, 'loss': 0.6752328787766836, 'max_history_score': 0.546592204773611, 'max_history_score_std': 0.04157271294583304, 'max_history_step': 'pipeline', 'pipeline': {'features': ('features_PCA', {'features__n_components': 2}), 'normalizer': ('normalizer_MinMaxScaler', {}), 'rebalance': ('rebalance_NoneType', {})}, 'score': 0.3247671212233164, ...}, {'algorithm': {'criterion': 'entropy', 'max_depth': 3, 'max_features': 1, 'max_leaf_nodes': 5, 'min_samples_leaf': 1, 'min_samples_split': 2, 'splitter': 'best'}, 'config_hash': {'algorithm': '3de011874cc24f0836ce50f5760993711953672a', 'config': '34e85e643782e2a6fe1e54ed44b4df0dd28adf42', 'pipeline': '78028fec3489bc1290cd6e3a5ffef640e07fd746'}, 'duration': 0.9617228507995605, 'iteration': 13, 'loss': 0.5953642374812453, 'max_history_score': 0.546592204773611, 'max_history_score_std': 0.04157271294583304, 'max_history_step': 'pipeline', 'pipeline': {'features': ('features_PCA', {'features__n_components': 2}), 'normalizer': ('normalizer_MinMaxScaler', {}), 'rebalance': ('rebalance_NoneType', {})}, 'score': 0.40463576251875466, ...}], 'history_hash': ['ca5ca4efa90c01bc7221121efcc4d9c81cc5f6d0', 'e2ef5dfe43753524001a5fcbab4886cbde2b3e42', '2c3bccf18791b309fa8b48e68103ac95d47230a3', '650d610fc79551ca01c9d51200374e435c9787c0', '1daa3503ea9eec94f212644bb7c537963ab2ac4e', 'b35ef6c13761b660f5939aa43874dd8c140f716f', 'f74b7b5b829639de7187b0517124671171e3886c', '1eabae8e59d372b076035bdac59106753d4c3143', '8c4b0ea4a817610a51d42d05534a015dbcf7d6f6', '92935a6b2d506658f91a16fec98aae7c7c18849e', '97df063c7bd2eed3d6c210b081267d6af4779728', '27800204e73eea5d7e73e87227aea28cbc1a3643', 'f868e344f6a6987c0196ca818a372520a61e72ae', '34e85e643782e2a6fe1e54ed44b4df0dd28adf42'], 'history_index': {'1daa3503ea9eec94f212644bb7c537963ab2ac4e': 4, '1eabae8e59d372b076035bdac59106753d4c3143': 7, '27800204e73eea5d7e73e87227aea28cbc1a3643': 11, '2c3bccf18791b309fa8b48e68103ac95d47230a3': 2, '34e85e643782e2a6fe1e54ed44b4df0dd28adf42': 13, '650d610fc79551ca01c9d51200374e435c9787c0': 3, '8c4b0ea4a817610a51d42d05534a015dbcf7d6f6': 8, '92935a6b2d506658f91a16fec98aae7c7c18849e': 9, '97df063c7bd2eed3d6c210b081267d6af4779728': 10, 'b35ef6c13761b660f5939aa43874dd8c140f716f': 5, ...}, 'iteration': 13, 'max_history_score': 0.546592204773611, 'max_history_score_std': 0.04157271294583304, 'max_history_step': 'pipeline'}, config={'algorithm': 'DecisionTree', 'reset_trial': False, 'seed': 42, 'step_algorithm': 15, 'step_pipeline': 15, 'time': 300})
    105 
    106 def objective_pipeline(pipeline_config, current_algo_config, algorithm, X, y, context, config):
    107     return objective(pipeline_config, current_algo_config, algorithm, X, y, context, config, step='pipeline')
    108 
    109 def objective_algo(algo_config, current_pipeline_config, algorithm, X, y, context, config):
--> 110     return objective(current_pipeline_config, algo_config, algorithm, X, y, context, config, step='algorithm')
        current_pipeline_config = {'features': ('features_PCA', {'features__n_components': 2}), 'normalizer': ('normalizer_MinMaxScaler', {}), 'rebalance': ('rebalance_NoneType', {})}
        algo_config = {'criterion': 'gini', 'max_depth': 2, 'max_features': 3, 'max_leaf_nodes': 2, 'min_samples_leaf': 2, 'min_samples_split': 5, 'splitter': 'best'}
        algorithm = 'DecisionTree'
        X = array([[ 0.,  0.,  5., ...,  0.,  0.,  0.],
    ...0.],
       [ 0.,  0., 10., ..., 12.,  1.,  0.]])
        y = array([0, 1, 2, ..., 8, 9, 8])
        context = {'baseline_score': 0.8370850802141552, 'baseline_score_std': 0.04023050598893108, 'best_config': {'algorithm': {}, 'config_hash': {'algorithm': 'bf21a9e8fbc5a3846fb05b4fa0859e0917b2202f', 'config': '8c4b0ea4a817610a51d42d05534a015dbcf7d6f6', 'pipeline': '78028fec3489bc1290cd6e3a5ffef640e07fd746'}, 'duration': 1.01682710647583, 'iteration': 8, 'loss': 0.45340779522638897, 'max_history_score': 0.546592204773611, 'max_history_score_std': 0.04157271294583304, 'max_history_step': 'pipeline', 'pipeline': {'features': ('features_PCA', {'features__n_components': 2}), 'normalizer': ('normalizer_MinMaxScaler', {}), 'rebalance': ('rebalance_NoneType', {})}, 'score': 0.546592204773611, ...}, 'history': [{'algorithm': {}, 'config_hash': {'algorithm': 'bf21a9e8fbc5a3846fb05b4fa0859e0917b2202f', 'config': 'ca5ca4efa90c01bc7221121efcc4d9c81cc5f6d0', 'pipeline': 'e7db9df9682e59ebeb9a13264e2de218c38a3119'}, 'duration': 20.03913402557373, 'iteration': 0, 'loss': 0.8859695582333075, 'max_history_score': 0.1140304417666925, 'max_history_score_std': 0.0205735154132599, 'max_history_step': 'pipeline', 'pipeline': {'features': ('features_PCA', {'features__n_components': 1}), 'normalizer': ('normalizer_StandardScaler', {'normalizer__with_mean': True, 'normalizer__with_std': True}), 'rebalance': ('rebalance_CondensedNearestNeighbour', {'rebalance__n_neighbors': 3})}, 'score': 0.1140304417666925, ...}, {'algorithm': {'criterion': 'gini', 'max_depth': 2, 'max_features': 2, 'max_leaf_nodes': None, 'min_samples_leaf': 4, 'min_samples_split': 5, 'splitter': 'random'}, 'config_hash': {'algorithm': 'c4587a515ec4d7862c26abb6c7b2069ec2788a3c', 'config': 'e2ef5dfe43753524001a5fcbab4886cbde2b3e42', 'pipeline': 'e7db9df9682e59ebeb9a13264e2de218c38a3119'}, 'duration': 7.673176050186157, 'iteration': 1, 'loss': 1.0, 'max_history_score': 0.1140304417666925, 'max_history_score_std': 0.0205735154132599, 'max_history_step': 'pipeline', 'pipeline': {'features': ('features_PCA', {'features__n_components': 1}), 'normalizer': ('normalizer_StandardScaler', {'normalizer__with_mean': True, 'normalizer__with_std': True}), 'rebalance': ('rebalance_CondensedNearestNeighbour', {'rebalance__n_neighbors': 3})}, 'score': 0.0, ...}, {'algorithm': {'criterion': 'gini', 'max_depth': 3, 'max_features': 1, 'max_leaf_nodes': 2, 'min_samples_leaf': 4, 'min_samples_split': 3, 'splitter': 'random'}, 'config_hash': {'algorithm': 'b8f20163e3a63f6d337affac58f19f59c1042fdf', 'config': '2c3bccf18791b309fa8b48e68103ac95d47230a3', 'pipeline': 'e7db9df9682e59ebeb9a13264e2de218c38a3119'}, 'duration': 21.382025003433228, 'iteration': 2, 'loss': 0.8953686047024499, 'max_history_score': 0.1140304417666925, 'max_history_score_std': 0.0205735154132599, 'max_history_step': 'pipeline', 'pipeline': {'features': ('features_PCA', {'features__n_components': 1}), 'normalizer': ('normalizer_StandardScaler', {'normalizer__with_mean': True, 'normalizer__with_std': True}), 'rebalance': ('rebalance_CondensedNearestNeighbour', {'rebalance__n_neighbors': 3})}, 'score': 0.10463139529755008, ...}, {'algorithm': {}, 'config_hash': {'algorithm': 'bf21a9e8fbc5a3846fb05b4fa0859e0917b2202f', 'config': '650d610fc79551ca01c9d51200374e435c9787c0', 'pipeline': '1ad3dcf81ee45846a12eb92026a29afcf2a1775b'}, 'duration': 12.787569999694824, 'iteration': 3, 'loss': 0.748813833006884, 'max_history_score': 0.251186166993116, 'max_history_score_std': 0.07154325263262472, 'max_history_step': 'pipeline', 'pipeline': {'features': ('features_SelectKBest', {'features__k': 2}), 'normalizer': ('normalizer_MinMaxScaler', {}), 'rebalance': ('rebalance_CondensedNearestNeighbour', {'rebalance__n_neighbors': 1})}, 'score': 0.251186166993116, ...}, {'algorithm': {}, 'config_hash': {'algorithm': 'bf21a9e8fbc5a3846fb05b4fa0859e0917b2202f', 'config': '1daa3503ea9eec94f212644bb7c537963ab2ac4e', 'pipeline': '2235081205d7d7fae0d7335c028eccad689bcf9c'}, 'duration': 20.381888151168823, 'iteration': 4, 'loss': 0.5370735680036086, 'max_history_score': 0.4629264319963914, 'max_history_score_std': 0.04205540233571201, 'max_history_step': 'pipeline', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 4, 'features__selectkbest__k': 2}), 'normalizer': ('normalizer_NoneType', {}), 'rebalance': ('rebalance_CondensedNearestNeighbour', {'rebalance__n_neighbors': 3})}, 'score': 0.4629264319963914, ...}, {'algorithm': {'criterion': 'entropy', 'max_depth': None, 'max_features': 1, 'max_leaf_nodes': 3, 'min_samples_leaf': 1, 'min_samples_split': 2, 'splitter': 'random'}, 'config_hash': {'algorithm': '71cd9bb7b8b0ff2a3dbdca44537bafc4f6b2c716', 'config': 'b35ef6c13761b660f5939aa43874dd8c140f716f', 'pipeline': '2235081205d7d7fae0d7335c028eccad689bcf9c'}, 'duration': 20.211046934127808, 'iteration': 5, 'loss': 0.8151901497270952, 'max_history_score': 0.4629264319963914, 'max_history_score_std': 0.04205540233571201, 'max_history_step': 'pipeline', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 4, 'features__selectkbest__k': 2}), 'normalizer': ('normalizer_NoneType', {}), 'rebalance': ('rebalance_CondensedNearestNeighbour', {'rebalance__n_neighbors': 3})}, 'score': 0.1848098502729048, ...}, {'algorithm': {}, 'config_hash': {'algorithm': 'bf21a9e8fbc5a3846fb05b4fa0859e0917b2202f', 'config': 'f74b7b5b829639de7187b0517124671171e3886c', 'pipeline': '0a79122f55ba7d73b9d4a4993303bd1034099fc4'}, 'duration': 13.524871110916138, 'iteration': 6, 'loss': 0.5735578577665785, 'max_history_score': 0.4629264319963914, 'max_history_score_std': 0.04205540233571201, 'max_history_step': 'pipeline', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 3, 'features__selectkbest__k': 4}), 'normalizer': ('normalizer_StandardScaler', {'normalizer__with_mean': True, 'normalizer__with_std': True}), 'rebalance': ('rebalance_CondensedNearestNeighbour', {'rebalance__n_neighbors': 1})}, 'score': 0.4264421422334214, ...}, {'algorithm': {}, 'config_hash': {'algorithm': 'bf21a9e8fbc5a3846fb05b4fa0859e0917b2202f', 'config': '1eabae8e59d372b076035bdac59106753d4c3143', 'pipeline': 'f671e39c7c21287c35cc86282770be08920b7211'}, 'duration': 0.7754909992218018, 'iteration': 7, 'loss': 0.5473935951203874, 'max_history_score': 0.4629264319963914, 'max_history_score_std': 0.04205540233571201, 'max_history_step': 'pipeline', 'pipeline': {'features': ('features_SelectKBest', {'features__k': 4}), 'normalizer': ('normalizer_NoneType', {}), 'rebalance': ('rebalance_NearMiss', {'rebalance__n_neighbors': 3})}, 'score': 0.4526064048796126, ...}, {'algorithm': {}, 'config_hash': {'algorithm': 'bf21a9e8fbc5a3846fb05b4fa0859e0917b2202f', 'config': '8c4b0ea4a817610a51d42d05534a015dbcf7d6f6', 'pipeline': '78028fec3489bc1290cd6e3a5ffef640e07fd746'}, 'duration': 1.01682710647583, 'iteration': 8, 'loss': 0.45340779522638897, 'max_history_score': 0.546592204773611, 'max_history_score_std': 0.04157271294583304, 'max_history_step': 'pipeline', 'pipeline': {'features': ('features_PCA', {'features__n_components': 2}), 'normalizer': ('normalizer_MinMaxScaler', {}), 'rebalance': ('rebalance_NoneType', {})}, 'score': 0.546592204773611, ...}, {'algorithm': {'criterion': 'entropy', 'max_depth': 4, 'max_features': 3, 'max_leaf_nodes': None, 'min_samples_leaf': 4, 'min_samples_split': 2, 'splitter': 'random'}, 'config_hash': {'algorithm': '9a5aa4d1141074f6b9047871fcb0b33ccfcfd3d3', 'config': '92935a6b2d506658f91a16fec98aae7c7c18849e', 'pipeline': '78028fec3489bc1290cd6e3a5ffef640e07fd746'}, 'duration': 0.9999289512634277, 'iteration': 9, 'loss': 1.0, 'max_history_score': 0.546592204773611, 'max_history_score_std': 0.04157271294583304, 'max_history_step': 'pipeline', 'pipeline': {'features': ('features_PCA', {'features__n_components': 2}), 'normalizer': ('normalizer_MinMaxScaler', {}), 'rebalance': ('rebalance_NoneType', {})}, 'score': 0.0, ...}, {'algorithm': {'criterion': 'gini', 'max_depth': 1, 'max_features': None, 'max_leaf_nodes': 3, 'min_samples_leaf': 5, 'min_samples_split': 5, 'splitter': 'best'}, 'config_hash': {'algorithm': 'ecf5b568d6e3c2ab306a7bcf2b124903c3a3067b', 'config': '97df063c7bd2eed3d6c210b081267d6af4779728', 'pipeline': '78028fec3489bc1290cd6e3a5ffef640e07fd746'}, 'duration': 4.798619031906128, 'iteration': 10, 'loss': 0.71905333522791, 'max_history_score': 0.546592204773611, 'max_history_score_std': 0.04157271294583304, 'max_history_step': 'pipeline', 'pipeline': {'features': ('features_PCA', {'features__n_components': 2}), 'normalizer': ('normalizer_MinMaxScaler', {}), 'rebalance': ('rebalance_NoneType', {})}, 'score': 0.28094666477209, ...}, {'algorithm': {'criterion': 'entropy', 'max_depth': 4, 'max_features': 3, 'max_leaf_nodes': 2, 'min_samples_leaf': 2, 'min_samples_split': 5, 'splitter': 'random'}, 'config_hash': {'algorithm': '4fb15d383737c031e5da0f4a5ea707659357c7de', 'config': '27800204e73eea5d7e73e87227aea28cbc1a3643', 'pipeline': '78028fec3489bc1290cd6e3a5ffef640e07fd746'}, 'duration': 1.153088092803955, 'iteration': 11, 'loss': 1.0, 'max_history_score': 0.546592204773611, 'max_history_score_std': 0.04157271294583304, 'max_history_step': 'pipeline', 'pipeline': {'features': ('features_PCA', {'features__n_components': 2}), 'normalizer': ('normalizer_MinMaxScaler', {}), 'rebalance': ('rebalance_NoneType', {})}, 'score': 0.0, ...}, {'algorithm': {'criterion': 'entropy', 'max_depth': 2, 'max_features': 2, 'max_leaf_nodes': None, 'min_samples_leaf': 5, 'min_samples_split': 2, 'splitter': 'best'}, 'config_hash': {'algorithm': '1df5f94fef9c8f306dc10711a993990eb10ade6a', 'config': 'f868e344f6a6987c0196ca818a372520a61e72ae', 'pipeline': '78028fec3489bc1290cd6e3a5ffef640e07fd746'}, 'duration': 4.58973503112793, 'iteration': 12, 'loss': 0.6752328787766836, 'max_history_score': 0.546592204773611, 'max_history_score_std': 0.04157271294583304, 'max_history_step': 'pipeline', 'pipeline': {'features': ('features_PCA', {'features__n_components': 2}), 'normalizer': ('normalizer_MinMaxScaler', {}), 'rebalance': ('rebalance_NoneType', {})}, 'score': 0.3247671212233164, ...}, {'algorithm': {'criterion': 'entropy', 'max_depth': 3, 'max_features': 1, 'max_leaf_nodes': 5, 'min_samples_leaf': 1, 'min_samples_split': 2, 'splitter': 'best'}, 'config_hash': {'algorithm': '3de011874cc24f0836ce50f5760993711953672a', 'config': '34e85e643782e2a6fe1e54ed44b4df0dd28adf42', 'pipeline': '78028fec3489bc1290cd6e3a5ffef640e07fd746'}, 'duration': 0.9617228507995605, 'iteration': 13, 'loss': 0.5953642374812453, 'max_history_score': 0.546592204773611, 'max_history_score_std': 0.04157271294583304, 'max_history_step': 'pipeline', 'pipeline': {'features': ('features_PCA', {'features__n_components': 2}), 'normalizer': ('normalizer_MinMaxScaler', {}), 'rebalance': ('rebalance_NoneType', {})}, 'score': 0.40463576251875466, ...}], 'history_hash': ['ca5ca4efa90c01bc7221121efcc4d9c81cc5f6d0', 'e2ef5dfe43753524001a5fcbab4886cbde2b3e42', '2c3bccf18791b309fa8b48e68103ac95d47230a3', '650d610fc79551ca01c9d51200374e435c9787c0', '1daa3503ea9eec94f212644bb7c537963ab2ac4e', 'b35ef6c13761b660f5939aa43874dd8c140f716f', 'f74b7b5b829639de7187b0517124671171e3886c', '1eabae8e59d372b076035bdac59106753d4c3143', '8c4b0ea4a817610a51d42d05534a015dbcf7d6f6', '92935a6b2d506658f91a16fec98aae7c7c18849e', '97df063c7bd2eed3d6c210b081267d6af4779728', '27800204e73eea5d7e73e87227aea28cbc1a3643', 'f868e344f6a6987c0196ca818a372520a61e72ae', '34e85e643782e2a6fe1e54ed44b4df0dd28adf42'], 'history_index': {'1daa3503ea9eec94f212644bb7c537963ab2ac4e': 4, '1eabae8e59d372b076035bdac59106753d4c3143': 7, '27800204e73eea5d7e73e87227aea28cbc1a3643': 11, '2c3bccf18791b309fa8b48e68103ac95d47230a3': 2, '34e85e643782e2a6fe1e54ed44b4df0dd28adf42': 13, '650d610fc79551ca01c9d51200374e435c9787c0': 3, '8c4b0ea4a817610a51d42d05534a015dbcf7d6f6': 8, '92935a6b2d506658f91a16fec98aae7c7c18849e': 9, '97df063c7bd2eed3d6c210b081267d6af4779728': 10, 'b35ef6c13761b660f5939aa43874dd8c140f716f': 5, ...}, 'iteration': 13, 'max_history_score': 0.546592204773611, 'max_history_score_std': 0.04157271294583304, 'max_history_step': 'pipeline'}
        config = {'algorithm': 'DecisionTree', 'reset_trial': False, 'seed': 42, 'step_algorithm': 15, 'step_pipeline': 15, 'time': 300}
    111 
    112 def get_baseline_score(algorithm, X, y, seed):
    113     pipeline, _ = pipeline_conf_to_full_pipeline(
    114         get_baseline(), 

...........................................................................
/home/aquemy/dev/dp_hyperparameters/extension/experiment/objective.py in objective(pipeline_config={'features': ('features_PCA', {'features__n_components': 2}), 'normalizer': ('normalizer_MinMaxScaler', {}), 'rebalance': ('rebalance_NoneType', {})}, algo_config={'criterion': 'gini', 'max_depth': 2, 'max_features': 3, 'max_leaf_nodes': 2, 'min_samples_leaf': 2, 'min_samples_split': 5, 'splitter': 'best'}, algorithm='DecisionTree', X=array([[ 0.,  0.,  5., ...,  0.,  0.,  0.],
    ...0.],
       [ 0.,  0., 10., ..., 12.,  1.,  0.]]), y=array([0, 1, 2, ..., 8, 9, 8]), context={'baseline_score': 0.8370850802141552, 'baseline_score_std': 0.04023050598893108, 'best_config': {'algorithm': {}, 'config_hash': {'algorithm': 'bf21a9e8fbc5a3846fb05b4fa0859e0917b2202f', 'config': '8c4b0ea4a817610a51d42d05534a015dbcf7d6f6', 'pipeline': '78028fec3489bc1290cd6e3a5ffef640e07fd746'}, 'duration': 1.01682710647583, 'iteration': 8, 'loss': 0.45340779522638897, 'max_history_score': 0.546592204773611, 'max_history_score_std': 0.04157271294583304, 'max_history_step': 'pipeline', 'pipeline': {'features': ('features_PCA', {'features__n_components': 2}), 'normalizer': ('normalizer_MinMaxScaler', {}), 'rebalance': ('rebalance_NoneType', {})}, 'score': 0.546592204773611, ...}, 'history': [{'algorithm': {}, 'config_hash': {'algorithm': 'bf21a9e8fbc5a3846fb05b4fa0859e0917b2202f', 'config': 'ca5ca4efa90c01bc7221121efcc4d9c81cc5f6d0', 'pipeline': 'e7db9df9682e59ebeb9a13264e2de218c38a3119'}, 'duration': 20.03913402557373, 'iteration': 0, 'loss': 0.8859695582333075, 'max_history_score': 0.1140304417666925, 'max_history_score_std': 0.0205735154132599, 'max_history_step': 'pipeline', 'pipeline': {'features': ('features_PCA', {'features__n_components': 1}), 'normalizer': ('normalizer_StandardScaler', {'normalizer__with_mean': True, 'normalizer__with_std': True}), 'rebalance': ('rebalance_CondensedNearestNeighbour', {'rebalance__n_neighbors': 3})}, 'score': 0.1140304417666925, ...}, {'algorithm': {'criterion': 'gini', 'max_depth': 2, 'max_features': 2, 'max_leaf_nodes': None, 'min_samples_leaf': 4, 'min_samples_split': 5, 'splitter': 'random'}, 'config_hash': {'algorithm': 'c4587a515ec4d7862c26abb6c7b2069ec2788a3c', 'config': 'e2ef5dfe43753524001a5fcbab4886cbde2b3e42', 'pipeline': 'e7db9df9682e59ebeb9a13264e2de218c38a3119'}, 'duration': 7.673176050186157, 'iteration': 1, 'loss': 1.0, 'max_history_score': 0.1140304417666925, 'max_history_score_std': 0.0205735154132599, 'max_history_step': 'pipeline', 'pipeline': {'features': ('features_PCA', {'features__n_components': 1}), 'normalizer': ('normalizer_StandardScaler', {'normalizer__with_mean': True, 'normalizer__with_std': True}), 'rebalance': ('rebalance_CondensedNearestNeighbour', {'rebalance__n_neighbors': 3})}, 'score': 0.0, ...}, {'algorithm': {'criterion': 'gini', 'max_depth': 3, 'max_features': 1, 'max_leaf_nodes': 2, 'min_samples_leaf': 4, 'min_samples_split': 3, 'splitter': 'random'}, 'config_hash': {'algorithm': 'b8f20163e3a63f6d337affac58f19f59c1042fdf', 'config': '2c3bccf18791b309fa8b48e68103ac95d47230a3', 'pipeline': 'e7db9df9682e59ebeb9a13264e2de218c38a3119'}, 'duration': 21.382025003433228, 'iteration': 2, 'loss': 0.8953686047024499, 'max_history_score': 0.1140304417666925, 'max_history_score_std': 0.0205735154132599, 'max_history_step': 'pipeline', 'pipeline': {'features': ('features_PCA', {'features__n_components': 1}), 'normalizer': ('normalizer_StandardScaler', {'normalizer__with_mean': True, 'normalizer__with_std': True}), 'rebalance': ('rebalance_CondensedNearestNeighbour', {'rebalance__n_neighbors': 3})}, 'score': 0.10463139529755008, ...}, {'algorithm': {}, 'config_hash': {'algorithm': 'bf21a9e8fbc5a3846fb05b4fa0859e0917b2202f', 'config': '650d610fc79551ca01c9d51200374e435c9787c0', 'pipeline': '1ad3dcf81ee45846a12eb92026a29afcf2a1775b'}, 'duration': 12.787569999694824, 'iteration': 3, 'loss': 0.748813833006884, 'max_history_score': 0.251186166993116, 'max_history_score_std': 0.07154325263262472, 'max_history_step': 'pipeline', 'pipeline': {'features': ('features_SelectKBest', {'features__k': 2}), 'normalizer': ('normalizer_MinMaxScaler', {}), 'rebalance': ('rebalance_CondensedNearestNeighbour', {'rebalance__n_neighbors': 1})}, 'score': 0.251186166993116, ...}, {'algorithm': {}, 'config_hash': {'algorithm': 'bf21a9e8fbc5a3846fb05b4fa0859e0917b2202f', 'config': '1daa3503ea9eec94f212644bb7c537963ab2ac4e', 'pipeline': '2235081205d7d7fae0d7335c028eccad689bcf9c'}, 'duration': 20.381888151168823, 'iteration': 4, 'loss': 0.5370735680036086, 'max_history_score': 0.4629264319963914, 'max_history_score_std': 0.04205540233571201, 'max_history_step': 'pipeline', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 4, 'features__selectkbest__k': 2}), 'normalizer': ('normalizer_NoneType', {}), 'rebalance': ('rebalance_CondensedNearestNeighbour', {'rebalance__n_neighbors': 3})}, 'score': 0.4629264319963914, ...}, {'algorithm': {'criterion': 'entropy', 'max_depth': None, 'max_features': 1, 'max_leaf_nodes': 3, 'min_samples_leaf': 1, 'min_samples_split': 2, 'splitter': 'random'}, 'config_hash': {'algorithm': '71cd9bb7b8b0ff2a3dbdca44537bafc4f6b2c716', 'config': 'b35ef6c13761b660f5939aa43874dd8c140f716f', 'pipeline': '2235081205d7d7fae0d7335c028eccad689bcf9c'}, 'duration': 20.211046934127808, 'iteration': 5, 'loss': 0.8151901497270952, 'max_history_score': 0.4629264319963914, 'max_history_score_std': 0.04205540233571201, 'max_history_step': 'pipeline', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 4, 'features__selectkbest__k': 2}), 'normalizer': ('normalizer_NoneType', {}), 'rebalance': ('rebalance_CondensedNearestNeighbour', {'rebalance__n_neighbors': 3})}, 'score': 0.1848098502729048, ...}, {'algorithm': {}, 'config_hash': {'algorithm': 'bf21a9e8fbc5a3846fb05b4fa0859e0917b2202f', 'config': 'f74b7b5b829639de7187b0517124671171e3886c', 'pipeline': '0a79122f55ba7d73b9d4a4993303bd1034099fc4'}, 'duration': 13.524871110916138, 'iteration': 6, 'loss': 0.5735578577665785, 'max_history_score': 0.4629264319963914, 'max_history_score_std': 0.04205540233571201, 'max_history_step': 'pipeline', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 3, 'features__selectkbest__k': 4}), 'normalizer': ('normalizer_StandardScaler', {'normalizer__with_mean': True, 'normalizer__with_std': True}), 'rebalance': ('rebalance_CondensedNearestNeighbour', {'rebalance__n_neighbors': 1})}, 'score': 0.4264421422334214, ...}, {'algorithm': {}, 'config_hash': {'algorithm': 'bf21a9e8fbc5a3846fb05b4fa0859e0917b2202f', 'config': '1eabae8e59d372b076035bdac59106753d4c3143', 'pipeline': 'f671e39c7c21287c35cc86282770be08920b7211'}, 'duration': 0.7754909992218018, 'iteration': 7, 'loss': 0.5473935951203874, 'max_history_score': 0.4629264319963914, 'max_history_score_std': 0.04205540233571201, 'max_history_step': 'pipeline', 'pipeline': {'features': ('features_SelectKBest', {'features__k': 4}), 'normalizer': ('normalizer_NoneType', {}), 'rebalance': ('rebalance_NearMiss', {'rebalance__n_neighbors': 3})}, 'score': 0.4526064048796126, ...}, {'algorithm': {}, 'config_hash': {'algorithm': 'bf21a9e8fbc5a3846fb05b4fa0859e0917b2202f', 'config': '8c4b0ea4a817610a51d42d05534a015dbcf7d6f6', 'pipeline': '78028fec3489bc1290cd6e3a5ffef640e07fd746'}, 'duration': 1.01682710647583, 'iteration': 8, 'loss': 0.45340779522638897, 'max_history_score': 0.546592204773611, 'max_history_score_std': 0.04157271294583304, 'max_history_step': 'pipeline', 'pipeline': {'features': ('features_PCA', {'features__n_components': 2}), 'normalizer': ('normalizer_MinMaxScaler', {}), 'rebalance': ('rebalance_NoneType', {})}, 'score': 0.546592204773611, ...}, {'algorithm': {'criterion': 'entropy', 'max_depth': 4, 'max_features': 3, 'max_leaf_nodes': None, 'min_samples_leaf': 4, 'min_samples_split': 2, 'splitter': 'random'}, 'config_hash': {'algorithm': '9a5aa4d1141074f6b9047871fcb0b33ccfcfd3d3', 'config': '92935a6b2d506658f91a16fec98aae7c7c18849e', 'pipeline': '78028fec3489bc1290cd6e3a5ffef640e07fd746'}, 'duration': 0.9999289512634277, 'iteration': 9, 'loss': 1.0, 'max_history_score': 0.546592204773611, 'max_history_score_std': 0.04157271294583304, 'max_history_step': 'pipeline', 'pipeline': {'features': ('features_PCA', {'features__n_components': 2}), 'normalizer': ('normalizer_MinMaxScaler', {}), 'rebalance': ('rebalance_NoneType', {})}, 'score': 0.0, ...}, {'algorithm': {'criterion': 'gini', 'max_depth': 1, 'max_features': None, 'max_leaf_nodes': 3, 'min_samples_leaf': 5, 'min_samples_split': 5, 'splitter': 'best'}, 'config_hash': {'algorithm': 'ecf5b568d6e3c2ab306a7bcf2b124903c3a3067b', 'config': '97df063c7bd2eed3d6c210b081267d6af4779728', 'pipeline': '78028fec3489bc1290cd6e3a5ffef640e07fd746'}, 'duration': 4.798619031906128, 'iteration': 10, 'loss': 0.71905333522791, 'max_history_score': 0.546592204773611, 'max_history_score_std': 0.04157271294583304, 'max_history_step': 'pipeline', 'pipeline': {'features': ('features_PCA', {'features__n_components': 2}), 'normalizer': ('normalizer_MinMaxScaler', {}), 'rebalance': ('rebalance_NoneType', {})}, 'score': 0.28094666477209, ...}, {'algorithm': {'criterion': 'entropy', 'max_depth': 4, 'max_features': 3, 'max_leaf_nodes': 2, 'min_samples_leaf': 2, 'min_samples_split': 5, 'splitter': 'random'}, 'config_hash': {'algorithm': '4fb15d383737c031e5da0f4a5ea707659357c7de', 'config': '27800204e73eea5d7e73e87227aea28cbc1a3643', 'pipeline': '78028fec3489bc1290cd6e3a5ffef640e07fd746'}, 'duration': 1.153088092803955, 'iteration': 11, 'loss': 1.0, 'max_history_score': 0.546592204773611, 'max_history_score_std': 0.04157271294583304, 'max_history_step': 'pipeline', 'pipeline': {'features': ('features_PCA', {'features__n_components': 2}), 'normalizer': ('normalizer_MinMaxScaler', {}), 'rebalance': ('rebalance_NoneType', {})}, 'score': 0.0, ...}, {'algorithm': {'criterion': 'entropy', 'max_depth': 2, 'max_features': 2, 'max_leaf_nodes': None, 'min_samples_leaf': 5, 'min_samples_split': 2, 'splitter': 'best'}, 'config_hash': {'algorithm': '1df5f94fef9c8f306dc10711a993990eb10ade6a', 'config': 'f868e344f6a6987c0196ca818a372520a61e72ae', 'pipeline': '78028fec3489bc1290cd6e3a5ffef640e07fd746'}, 'duration': 4.58973503112793, 'iteration': 12, 'loss': 0.6752328787766836, 'max_history_score': 0.546592204773611, 'max_history_score_std': 0.04157271294583304, 'max_history_step': 'pipeline', 'pipeline': {'features': ('features_PCA', {'features__n_components': 2}), 'normalizer': ('normalizer_MinMaxScaler', {}), 'rebalance': ('rebalance_NoneType', {})}, 'score': 0.3247671212233164, ...}, {'algorithm': {'criterion': 'entropy', 'max_depth': 3, 'max_features': 1, 'max_leaf_nodes': 5, 'min_samples_leaf': 1, 'min_samples_split': 2, 'splitter': 'best'}, 'config_hash': {'algorithm': '3de011874cc24f0836ce50f5760993711953672a', 'config': '34e85e643782e2a6fe1e54ed44b4df0dd28adf42', 'pipeline': '78028fec3489bc1290cd6e3a5ffef640e07fd746'}, 'duration': 0.9617228507995605, 'iteration': 13, 'loss': 0.5953642374812453, 'max_history_score': 0.546592204773611, 'max_history_score_std': 0.04157271294583304, 'max_history_step': 'pipeline', 'pipeline': {'features': ('features_PCA', {'features__n_components': 2}), 'normalizer': ('normalizer_MinMaxScaler', {}), 'rebalance': ('rebalance_NoneType', {})}, 'score': 0.40463576251875466, ...}], 'history_hash': ['ca5ca4efa90c01bc7221121efcc4d9c81cc5f6d0', 'e2ef5dfe43753524001a5fcbab4886cbde2b3e42', '2c3bccf18791b309fa8b48e68103ac95d47230a3', '650d610fc79551ca01c9d51200374e435c9787c0', '1daa3503ea9eec94f212644bb7c537963ab2ac4e', 'b35ef6c13761b660f5939aa43874dd8c140f716f', 'f74b7b5b829639de7187b0517124671171e3886c', '1eabae8e59d372b076035bdac59106753d4c3143', '8c4b0ea4a817610a51d42d05534a015dbcf7d6f6', '92935a6b2d506658f91a16fec98aae7c7c18849e', '97df063c7bd2eed3d6c210b081267d6af4779728', '27800204e73eea5d7e73e87227aea28cbc1a3643', 'f868e344f6a6987c0196ca818a372520a61e72ae', '34e85e643782e2a6fe1e54ed44b4df0dd28adf42'], 'history_index': {'1daa3503ea9eec94f212644bb7c537963ab2ac4e': 4, '1eabae8e59d372b076035bdac59106753d4c3143': 7, '27800204e73eea5d7e73e87227aea28cbc1a3643': 11, '2c3bccf18791b309fa8b48e68103ac95d47230a3': 2, '34e85e643782e2a6fe1e54ed44b4df0dd28adf42': 13, '650d610fc79551ca01c9d51200374e435c9787c0': 3, '8c4b0ea4a817610a51d42d05534a015dbcf7d6f6': 8, '92935a6b2d506658f91a16fec98aae7c7c18849e': 9, '97df063c7bd2eed3d6c210b081267d6af4779728': 10, 'b35ef6c13761b660f5939aa43874dd8c140f716f': 5, ...}, 'iteration': 13, 'max_history_score': 0.546592204773611, 'max_history_score_std': 0.04157271294583304, 'max_history_step': 'pipeline'}, config={'algorithm': 'DecisionTree', 'reset_trial': False, 'seed': 42, 'step_algorithm': 15, 'step_pipeline': 15, 'time': 300}, step='algorithm')
     45                 y,
     46                 cv=10,
     47                 n_jobs=-1,
     48                 return_estimator=False,
     49                 return_train_score=False,
---> 50                 verbose=0)
     51         score = np.mean(scores['test_score'])
     52         std = np.std(scores['test_score'])
     53         status = STATUS_OK
     54     except Exception as e:

...........................................................................
/home/aquemy/.local/lib/python2.7/site-packages/sklearn/model_selection/_validation.py in cross_validate(estimator=Pipeline(memory=None,
     steps=[('normalizer',...esort=False, random_state=42, splitter='best'))]), X=array([[ 0.,  0.,  5., ...,  0.,  0.,  0.],
    ...0.],
       [ 0.,  0., 10., ..., 12.,  1.,  0.]]), y=array([0, 1, 2, ..., 8, 9, 8]), groups=None, scoring=None, cv=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1, verbose=0, fit_params=None, pre_dispatch='2*n_jobs', return_train_score=False, return_estimator=False, error_score='raise-deprecating')
    235         delayed(_fit_and_score)(
    236             clone(estimator), X, y, scorers, train, test, verbose, None,
    237             fit_params, return_train_score=return_train_score,
    238             return_times=True, return_estimator=return_estimator,
    239             error_score=error_score)
--> 240         for train, test in cv.split(X, y, groups))
        cv.split = <bound method StratifiedKFold.split of Stratifie...d(n_splits=10, random_state=None, shuffle=False)>
        X = array([[ 0.,  0.,  5., ...,  0.,  0.,  0.],
    ...0.],
       [ 0.,  0., 10., ..., 12.,  1.,  0.]])
        y = array([0, 1, 2, ..., 8, 9, 8])
        groups = None
    241 
    242     zipped_scores = list(zip(*scores))
    243     if return_train_score:
    244         train_scores = zipped_scores.pop(0)

...........................................................................
/home/aquemy/.local/lib/python2.7/site-packages/sklearn/externals/joblib/parallel.py in __call__(self=Parallel(n_jobs=-1), iterable=<generator object <genexpr>>)
    925                 # No need to wait for async callbacks to trigger to
    926                 # consumption.
    927                 self._iterating = False
    928 
    929             with self._backend.retrieval_context():
--> 930                 self.retrieve()
        self.retrieve = <bound method Parallel.retrieve of Parallel(n_jobs=-1)>
    931             # Make sure that we get a last message telling us we are done
    932             elapsed_time = time.time() - self._start_time
    933             self._print('Done %3i out of %3i | elapsed: %s finished',
    934                         (len(self._output), len(self._output),

---------------------------------------------------------------------------
Joblib worker traceback:
---------------------------------------------------------------------------
ValueError                                         Wed Jun  5 18:35:01 2019
PID: 7076                                   Python 2.7.15+: /usr/bin/python
...........................................................................
/home/aquemy/.local/lib/python2.7/site-packages/sklearn/externals/joblib/parallel.py in __call__(self=<sklearn.externals.joblib.parallel.BatchedCalls object>)
    220     def __call__(self):
    221         # Set the default nested backend to self._backend but do not set the
    222         # change the default number of processes to -1
    223         with parallel_backend(self._backend, n_jobs=self._n_jobs):
    224             return [func(*args, **kwargs)
--> 225                     for func, args, kwargs in self.items]
        func = <function _fit_and_score>
        args = (Pipeline(memory=None,
     steps=[('normalizer',...esort=False, random_state=42, splitter='best'))]), array([[ 0.,  0.,  5., ...,  0.,  0.,  0.],
    ...0.],
       [ 0.,  0., 10., ..., 12.,  1.,  0.]]), array([0, 1, 2, ..., 8, 9, 8]), {'score': <function _passthrough_scorer>}, array([ 169,  176,  178, ..., 1794, 1795, 1796]), array([  0,   1,   2,   3,   4,   5,   6,   7,  ..., 181, 186, 188, 189, 190,
       194, 195, 198]), 0, None, None)
        kwargs = {'error_score': 'raise-deprecating', 'return_estimator': False, 'return_times': True, 'return_train_score': False}
        self.items = [(<function _fit_and_score>, (Pipeline(memory=None,
     steps=[('normalizer',...esort=False, random_state=42, splitter='best'))]), array([[ 0.,  0.,  5., ...,  0.,  0.,  0.],
    ...0.],
       [ 0.,  0., 10., ..., 12.,  1.,  0.]]), array([0, 1, 2, ..., 8, 9, 8]), {'score': <function _passthrough_scorer>}, array([ 169,  176,  178, ..., 1794, 1795, 1796]), array([  0,   1,   2,   3,   4,   5,   6,   7,  ..., 181, 186, 188, 189, 190,
       194, 195, 198]), 0, None, None), {'error_score': 'raise-deprecating', 'return_estimator': False, 'return_times': True, 'return_train_score': False})]
    226 
    227     def __len__(self):
    228         return self._size
    229 

...........................................................................
/home/aquemy/.local/lib/python2.7/site-packages/sklearn/model_selection/_validation.py in _fit_and_score(estimator=Pipeline(memory=None,
     steps=[('normalizer',...esort=False, random_state=42, splitter='best'))]), X=array([[ 0.,  0.,  5., ...,  0.,  0.,  0.],
    ...0.],
       [ 0.,  0., 10., ..., 12.,  1.,  0.]]), y=array([0, 1, 2, ..., 8, 9, 8]), scorer={'score': <function _passthrough_scorer>}, train=array([ 169,  176,  178, ..., 1794, 1795, 1796]), test=array([  0,   1,   2,   3,   4,   5,   6,   7,  ..., 181, 186, 188, 189, 190,
       194, 195, 198]), verbose=0, parameters=None, fit_params={}, return_train_score=False, return_parameters=False, return_n_test_samples=False, return_times=True, return_estimator=False, error_score='raise-deprecating')
    523 
    524     try:
    525         if y_train is None:
    526             estimator.fit(X_train, **fit_params)
    527         else:
--> 528             estimator.fit(X_train, y_train, **fit_params)
        estimator.fit = <bound method Pipeline.fit of Pipeline(memory=No...sort=False, random_state=42, splitter='best'))])>
        X_train = array([[ 0.,  0.,  6., ...,  9.,  4.,  0.],
    ...0.],
       [ 0.,  0., 10., ..., 12.,  1.,  0.]])
        y_train = array([9, 5, 0, ..., 8, 9, 8])
        fit_params = {}
    529 
    530     except Exception as e:
    531         # Note fit time as time until error
    532         fit_time = time.time() - start_time

...........................................................................
/usr/local/lib/python2.7/dist-packages/imblearn/pipeline.py in fit(self=Pipeline(memory=None,
     steps=[('normalizer',...esort=False, random_state=42, splitter='best'))]), X=array([[ 0.,  0.,  6., ...,  9.,  4.,  0.],
    ...0.],
       [ 0.,  0., 10., ..., 12.,  1.,  0.]]), y=array([9, 5, 0, ..., 8, 9, 8]), **fit_params={})
    234             This estimator
    235 
    236         """
    237         Xt, yt, fit_params = self._fit(X, y, **fit_params)
    238         if self._final_estimator is not None:
--> 239             self._final_estimator.fit(Xt, yt, **fit_params)
        self._final_estimator.fit = <bound method DecisionTreeClassifier.fit of Deci...presort=False, random_state=42, splitter='best')>
        Xt = array([[-0.96093851,  0.85576893],
       [-0.27... 0.84930432],
       [-0.04169917,  0.2488521 ]])
        yt = array([9, 5, 0, ..., 8, 9, 8])
        fit_params = {}
    240         return self
    241 
    242     def fit_transform(self, X, y=None, **fit_params):
    243         """Fit the model and transform with the final estimator

...........................................................................
/home/aquemy/.local/lib/python2.7/site-packages/sklearn/tree/tree.py in fit(self=DecisionTreeClassifier(class_weight=None, criter... presort=False, random_state=42, splitter='best'), X=array([[-0.96093851,  0.85576893],
       [-0.27... 0.84930432],
       [-0.04169917,  0.2488521 ]]), y=array([9, 5, 0, ..., 8, 9, 8]), sample_weight=None, check_input=True, X_idx_sorted=None)
    796 
    797         super(DecisionTreeClassifier, self).fit(
    798             X, y,
    799             sample_weight=sample_weight,
    800             check_input=check_input,
--> 801             X_idx_sorted=X_idx_sorted)
        X_idx_sorted = None
    802         return self
    803 
    804     def predict_proba(self, X, check_input=True):
    805         """Predict class probabilities of the input samples X.

...........................................................................
/home/aquemy/.local/lib/python2.7/site-packages/sklearn/tree/tree.py in fit(self=DecisionTreeClassifier(class_weight=None, criter... presort=False, random_state=42, splitter='best'), X=array([[-0.9609385 ,  0.8557689 ],
       [-0.27...      [-0.04169917,  0.2488521 ]], dtype=float32), y=array([[9.],
       [5.],
       [0.],
       ...,
       [8.],
       [9.],
       [8.]]), sample_weight=None, check_input=True, X_idx_sorted=None)
    237         if not 0 <= self.min_weight_fraction_leaf <= 0.5:
    238             raise ValueError("min_weight_fraction_leaf must in [0, 0.5]")
    239         if max_depth <= 0:
    240             raise ValueError("max_depth must be greater than zero. ")
    241         if not (0 < max_features <= self.n_features_):
--> 242             raise ValueError("max_features must be in (0, n_features]")
    243         if not isinstance(max_leaf_nodes, (numbers.Integral, np.integer)):
    244             raise ValueError("max_leaf_nodes must be integral number but was "
    245                              "%r" % max_leaf_nodes)
    246         if -1 < max_leaf_nodes < 2:

ValueError: max_features must be in (0, n_features]
___________________________________________________________________________
Best score: 0.546592204774 (0.0415727129458) [P] | Score: 0.0 (0.0) [A]
Best score: 0.546592204774 (0.0415727129458) [P] | Score: 0.324767121223 (0.0364626179778) [A]
#################### STEP RESULT ####################
BEST PIPELINE:
 {
    "features": [
        "features_PCA", 
        {
            "features__n_components": 2
        }
    ], 
    "normalizer": [
        "normalizer_MinMaxScaler", 
        {}
    ], 
    "rebalance": [
        "rebalance_NoneType", 
        {}
    ]
}
BEST ALGO CONFIG:
 {}
BEST SCORE: 0.546592204774 (0.0415727129458)
##################################################
## Data Pipeline
Best score: 0.837085080214 (0.0402305059889) [P] | Score: 0.837085080214 (0.0402305059889) [P]
Best score: 0.837085080214 (0.0402305059889) [P] | Score: 0.281146561591 (0.0491538705561) [P]
Best score: 0.837085080214 (0.0402305059889) [P] | Score: 0.172180990223 (0.0308048428998) [P]
#################### STEP RESULT ####################
BEST PIPELINE:
 {
    "features": [
        "features_NoneType", 
        {}
    ], 
    "normalizer": [
        "normalizer_MinMaxScaler", 
        {}
    ], 
    "rebalance": [
        "rebalance_NoneType", 
        {}
    ]
}
BEST ALGO CONFIG:
 {}
BEST SCORE: 0.837085080214 (0.0402305059889)
##################################################
## Algorithm
Best score: 0.837085080214 (0.0402305059889) [P] | Score: 0.156291882371 (0.0116704442255) [A]
Best score: 0.837085080214 (0.0402305059889) [P] | Score: 0.349540613859 (0.0387454667985) [A]
Best score: 0.837085080214 (0.0402305059889) [P] | Score: 0.198051366891 (0.0277740540788) [A]
Best score: 0.837085080214 (0.0402305059889) [P] | Score: 0.144672435319 (0.01749792155) [A]
Best score: 0.837085080214 (0.0402305059889) [P] | Score: 0.411696398085 (0.0285202602321) [A]
Best score: 0.837085080214 (0.0402305059889) [P] | Score: 0.189727657697 (0.00972111779077) [A]
Best score: 0.837085080214 (0.0402305059889) [P] | Score: 0.193155597138 (0.0199460674425) [A]
Best score: 0.837085080214 (0.0402305059889) [P] | Score: 0.193155597138 (0.0199460674425) [A]
Best score: 0.837085080214 (0.0402305059889) [P] | Score: 0.383955218853 (0.0589581744567) [A]
Best score: 0.837085080214 (0.0402305059889) [P] | Score: 0.144672435319 (0.01749792155) [A]
Best score: 0.837085080214 (0.0402305059889) [P] | Score: 0.394517136569 (0.0289137053107) [A]
Best score: 0.837085080214 (0.0402305059889) [P] | Score: 0.397832053696 (0.029721061659) [A]
Best score: 0.837085080214 (0.0402305059889) [P] | Score: 0.201583268478 (0.0318961879675) [A]
Best score: 0.837085080214 (0.0402305059889) [P] | Score: 0.394517136569 (0.0289137053107) [A]
Best score: 0.837085080214 (0.0402305059889) [P] | Score: 0.394517136569 (0.0289137053107) [A]
Best score: 0.837085080214 (0.0402305059889) [P] | Score: 0.198151485454 (0.0241572211501) [A]
Best score: 0.837085080214 (0.0402305059889) [P] | Score: 0.397832053696 (0.029721061659) [A]
Best score: 0.837085080214 (0.0402305059889) [P] | Score: 0.109701223173 (0.0252627930255) [A]
Best score: 0.837085080214 (0.0402305059889) [P] | Score: 0.411696398085 (0.0285202602321) [A]
Best score: 0.837085080214 (0.0402305059889) [P] | Score: 0.411696398085 (0.0285202602321) [A]
Best score: 0.837085080214 (0.0402305059889) [P] | Score: 0.419381832305 (0.0429045277916) [A]
Best score: 0.837085080214 (0.0402305059889) [P] | Score: 0.8166806845 (0.0579396873484) [A]
Best score: 0.837085080214 (0.0402305059889) [P] | Score: 0.641435030704 (0.0722542182039) [A]
Best score: 0.837085080214 (0.0402305059889) [P] | Score: 0.194173219095 (0.00776276896474) [A]
Best score: 0.837085080214 (0.0402305059889) [P] | Score: 0.354109734117 (0.0456157983031) [A]
Best score: 0.837085080214 (0.0402305059889) [P] | Score: 0.790458910261 (0.0418050504344) [A]
Best score: 0.837085080214 (0.0402305059889) [P] | Score: 0.131482873692 (0.0147177803389) [A]
Best score: 0.837085080214 (0.0402305059889) [P] | Score: 0.144672435319 (0.01749792155) [A]
Best score: 0.837085080214 (0.0402305059889) [P] | Score: 0.101274256881 (0.00127440186725) [A]
Best score: 0.837085080214 (0.0402305059889) [P] | Score: 0.144672435319 (0.01749792155) [A]
Best score: 0.837085080214 (0.0402305059889) [P] | Score: 0.27759923144 (0.0175962797272) [A]
Best score: 0.837085080214 (0.0402305059889) [P] | Score: 0.109701223173 (0.0252627930255) [A]
Best score: 0.837085080214 (0.0402305059889) [P] | Score: 0.144672435319 (0.01749792155) [A]
Best score: 0.837085080214 (0.0402305059889) [P] | Score: 0.545113414962 (0.036705619394) [A]
Best score: 0.837085080214 (0.0402305059889) [P] | Score: 0.27759923144 (0.0175962797272) [A]
Best score: 0.837085080214 (0.0402305059889) [P] | Score: 0.223807863091 (0.0115118418874) [A]
Best score: 0.837085080214 (0.0402305059889) [P] | Score: 0.197525624407 (0.00377269031109) [A]
Best score: 0.837085080214 (0.0402305059889) [P] | Score: 0.109701223173 (0.0252627930255) [A]
Best score: 0.837085080214 (0.0402305059889) [P] | Score: 0.198051366891 (0.0277740540788) [A]
Best score: 0.837085080214 (0.0402305059889) [P] | Score: 0.194173219095 (0.00776276896474) [A]
Best score: 0.837085080214 (0.0402305059889) [P] | Score: 0.804188224431 (0.0340878917668) [A]
Best score: 0.837085080214 (0.0402305059889) [P] | Score: 0.133951407127 (0.0295825026665) [A]
Best score: 0.837085080214 (0.0402305059889) [P] | Score: 0.131482873692 (0.0147177803389) [A]
Best score: 0.837085080214 (0.0402305059889) [P] | Score: 0.492618991559 (0.0781280568206) [A]
Best score: 0.837085080214 (0.0402305059889) [P] | Score: 0.315087831957 (0.0178417828579) [A]
Best score: 0.837085080214 (0.0402305059889) [P] | Score: 0.80529792254 (0.0355373418403) [A]
Best score: 0.837085080214 (0.0402305059889) [P] | Score: 0.543484794372 (0.0572579890298) [A]
Best score: 0.837085080214 (0.0402305059889) [P] | Score: 0.805440711492 (0.0413011365926) [A]
Best score: 0.837085080214 (0.0402305059889) [P] | Score: 0.194173219095 (0.00776276896474) [A]
Best score: 0.837085080214 (0.0402305059889) [P] | Score: 0.100712459129 (0.00215265719505) [A]
Best score: 0.837085080214 (0.0402305059889) [P] | Score: 0.807523704064 (0.0412077847301) [A]
Best score: 0.837085080214 (0.0402305059889) [P] | Score: 0.223807863091 (0.0115118418874) [A]
Best score: 0.837085080214 (0.0402305059889) [P] | Score: 0.543983471459 (0.0358940162574) [A]
Best score: 0.837085080214 (0.0402305059889) [P] | Score: 0.193155597138 (0.0199460674425) [A]
Best score: 0.837085080214 (0.0402305059889) [P] | Score: 0.194173219095 (0.00776276896474) [A]
Best score: 0.837085080214 (0.0402305059889) [P] | Score: 0.8166806845 (0.0579396873484) [A]
Best score: 0.837085080214 (0.0402305059889) [P] | Score: 0.101264945316 (0.00244609326436) [A]
Best score: 0.837085080214 (0.0402305059889) [P] | Score: 0.361154405999 (0.0245016035695) [A]
#################### STEP RESULT ####################
BEST PIPELINE:
 {
    "features": [
        "features_NoneType", 
        {}
    ], 
    "normalizer": [
        "normalizer_MinMaxScaler", 
        {}
    ], 
    "rebalance": [
        "rebalance_NoneType", 
        {}
    ]
}
BEST ALGO CONFIG:
 {}
BEST SCORE: 0.837085080214 (0.0402305059889)
##################################################
## Data Pipeline
Best score: 0.837085080214 (0.0402305059889) [P] | Score: 0.795670760332 (0.0321178651682) [P]
Best score: 0.837085080214 (0.0402305059889) [P] | Score: 0.833171249328 (0.0416577622558) [P]
Best score: 0.837085080214 (0.0402305059889) [P] | Score: 0.645515385651 (0.0416332551826) [P]
Best score: 0.837085080214 (0.0402305059889) [P] | Score: 0.833801441891 (0.0437149468255) [P]
#################### STEP RESULT ####################
BEST PIPELINE:
 {
    "features": [
        "features_NoneType", 
        {}
    ], 
    "normalizer": [
        "normalizer_MinMaxScaler", 
        {}
    ], 
    "rebalance": [
        "rebalance_NoneType", 
        {}
    ]
}
BEST ALGO CONFIG:
 {}
BEST SCORE: 0.837085080214 (0.0402305059889)
##################################################
## Algorithm
Best score: 0.837085080214 (0.0402305059889) [P] | Score: 0.646964163496 (0.0430652558882) [A]
Best score: 0.837085080214 (0.0402305059889) [P] | Score: 0.539712269366 (0.0296570152478) [A]
Best score: 0.837085080214 (0.0402305059889) [P] | Score: 0.27759923144 (0.0175962797272) [A]
Best score: 0.837085080214 (0.0402305059889) [P] | Score: 0.194173219095 (0.00776276896474) [A]
Best score: 0.837085080214 (0.0402305059889) [P] | Score: 0.460504256163 (0.0344576856602) [A]
Best score: 0.837085080214 (0.0402305059889) [P] | Score: 0.109701223173 (0.0252627930255) [A]
Best score: 0.837085080214 (0.0402305059889) [P] | Score: 0.131482873692 (0.0147177803389) [A]
Best score: 0.837085080214 (0.0402305059889) [P] | Score: 0.314424300613 (0.0302061999405) [A]
Best score: 0.837085080214 (0.0402305059889) [P] | Score: 0.28880701476 (0.00864265081491) [A]
Best score: 0.837085080214 (0.0402305059889) [P] | Score: 0.194173219095 (0.00776276896474) [A]
Best score: 0.837085080214 (0.0402305059889) [P] | Score: 0.109701223173 (0.0252627930255) [A]
Best score: 0.837085080214 (0.0402305059889) [P] | Score: 0.260998428783 (0.0273585084986) [A]
Best score: 0.837085080214 (0.0402305059889) [P] | Score: 0.197525624407 (0.00377269031109) [A]
Best score: 0.837085080214 (0.0402305059889) [P] | Score: 0.625755353984 (0.0484100593037) [A]
Best score: 0.837085080214 (0.0402305059889) [P] | Score: 0.276441288578 (0.0129955254903) [A]
Best score: 0.837085080214 (0.0402305059889) [P] | Score: 0.194173219095 (0.00776276896474) [A]
Best score: 0.837085080214 (0.0402305059889) [P] | Score: 0.419381832305 (0.0429045277916) [A]
Best score: 0.837085080214 (0.0402305059889) [P] | Score: 0.156291882371 (0.0116704442255) [A]
Best score: 0.837085080214 (0.0402305059889) [P] | Score: 0.260998428783 (0.0273585084986) [A]
Best score: 0.837085080214 (0.0402305059889) [P] | Score: 0.805440711492 (0.0413011365926) [A]
Best score: 0.837085080214 (0.0402305059889) [P] | Score: 0.193155597138 (0.0199460674425) [A]
Best score: 0.837085080214 (0.0402305059889) [P] | Score: 0.197525624407 (0.00377269031109) [A]
Best score: 0.837085080214 (0.0402305059889) [P] | Score: 0.109701223173 (0.0252627930255) [A]
Best score: 0.837085080214 (0.0402305059889) [P] | Score: 0.360947200482 (0.0261410559407) [A]
Best score: 0.837085080214 (0.0402305059889) [P] | Score: 0.656732997598 (0.047110139753) [A]
Best score: 0.837085080214 (0.0402305059889) [P] | Score: 0.287762510873 (0.0254608759469) [A]
Best score: 0.837085080214 (0.0402305059889) [P] | Score: 0.27759923144 (0.0175962797272) [A]
Best score: 0.837085080214 (0.0402305059889) [P] | Score: 0.194173219095 (0.00776276896474) [A]
Best score: 0.837085080214 (0.0402305059889) [P] | Score: 0.194173219095 (0.00776276896474) [A]
Best score: 0.837085080214 (0.0402305059889) [P] | Score: 0.109701223173 (0.0252627930255) [A]
Best score: 0.837085080214 (0.0402305059889) [P] | Score: 0.194835495671 (0.0295773553573) [A]
Best score: 0.837085080214 (0.0402305059889) [P] | Score: 0.193155597138 (0.0199460674425) [A]
Best score: 0.837085080214 (0.0402305059889) [P] | Score: 0.194173219095 (0.00776276896474) [A]
Best score: 0.837085080214 (0.0402305059889) [P] | Score: 0.816976880205 (0.0372956715543) [A]
Best score: 0.837085080214 (0.0402305059889) [P] | Score: 0.195366211245 (0.0824274399851) [A]
Best score: 0.837085080214 (0.0402305059889) [P] | Score: 0.653343261915 (0.0550696605758) [A]
Best score: 0.837085080214 (0.0402305059889) [P] | Score: 0.315087831957 (0.0178417828579) [A]
Best score: 0.837085080214 (0.0402305059889) [P] | Score: 0.592520457333 (0.078261958848) [A]
Best score: 0.837085080214 (0.0402305059889) [P] | Score: 0.28880701476 (0.00864265081491) [A]
Best score: 0.837085080214 (0.0402305059889) [P] | Score: 0.196490321661 (0.00609392846874) [A]
Best score: 0.837085080214 (0.0402305059889) [P] | Score: 0.156291882371 (0.0116704442255) [A]
Best score: 0.837085080214 (0.0402305059889) [P] | Score: 0.646923265482 (0.051300639884) [A]
Best score: 0.837085080214 (0.0402305059889) [P] | Score: 0.542902390378 (0.0372579487633) [A]
Best score: 0.837085080214 (0.0402305059889) [P] | Score: 0.315087831957 (0.0178417828579) [A]
Best score: 0.837085080214 (0.0402305059889) [P] | Score: 0.189435166002 (0.0318588596011) [A]
Best score: 0.837085080214 (0.0402305059889) [P] | Score: 0.823082681072 (0.0400077149206) [A]
Best score: 0.837085080214 (0.0402305059889) [P] | Score: 0.197525624407 (0.00377269031109) [A]
Best score: 0.837085080214 (0.0402305059889) [P] | Score: 0.425861893665 (0.0313588209895) [A]
Best score: 0.837085080214 (0.0402305059889) [P] | Score: 0.100153799911 (0.00275947052357) [A]
Best score: 0.837085080214 (0.0402305059889) [P] | Score: 0.644953444395 (0.0554315966084) [A]
Best score: 0.837085080214 (0.0402305059889) [P] | Score: 0.543983471459 (0.0358940162574) [A]
Best score: 0.837085080214 (0.0402305059889) [P] | Score: 0.198051366891 (0.0277740540788) [A]
Best score: 0.837085080214 (0.0402305059889) [P] | Score: 0.315087831957 (0.0178417828579) [A]
#################### STEP RESULT ####################
BEST PIPELINE:
 {
    "features": [
        "features_NoneType", 
        {}
    ], 
    "normalizer": [
        "normalizer_MinMaxScaler", 
        {}
    ], 
    "rebalance": [
        "rebalance_NoneType", 
        {}
    ]
}
BEST ALGO CONFIG:
 {}
BEST SCORE: 0.837085080214 (0.0402305059889)
##################################################
## Data Pipeline
Best score: 0.837085080214 (0.0402305059889) [P] | Score: 0.324004519878 (0.0380021025643) [P]
Best score: 0.837085080214 (0.0402305059889) [P] | Score: 0.691673993945 (0.0241169328869) [P]
Best score: 0.837085080214 (0.0402305059889) [P] | Score: 0.243174552038 (0.0258013044368) [P]
Best score: 0.837085080214 (0.0402305059889) [P] | Score: 0.401624551629 (0.0380497753298) [P]
#################### STEP RESULT ####################
BEST PIPELINE:
 {
    "features": [
        "features_NoneType", 
        {}
    ], 
    "normalizer": [
        "normalizer_MinMaxScaler", 
        {}
    ], 
    "rebalance": [
        "rebalance_NoneType", 
        {}
    ]
}
BEST ALGO CONFIG:
 {}
BEST SCORE: 0.837085080214 (0.0402305059889)
##################################################
## Algorithm
Best score: 0.837085080214 (0.0402305059889) [P] | Score: 0.22306936708 (0.0398869637835) [A]
Best score: 0.837085080214 (0.0402305059889) [P] | Score: 0.197525624407 (0.00377269031109) [A]
Best score: 0.837085080214 (0.0402305059889) [P] | Score: 0.696016726328 (0.0656192528222) [A]
Best score: 0.837085080214 (0.0402305059889) [P] | Score: 0.28880701476 (0.00864265081491) [A]
Best score: 0.837085080214 (0.0402305059889) [P] | Score: 0.226453759663 (0.0294415516689) [A]
Best score: 0.837085080214 (0.0402305059889) [P] | Score: 0.460504256163 (0.0344576856602) [A]
Best score: 0.837085080214 (0.0402305059889) [P] | Score: 0.134222281695 (0.0259786354427) [A]
Best score: 0.837085080214 (0.0402305059889) [P] | Score: 0.833224824799 (0.0482118333351) [A]
Best score: 0.837085080214 (0.0402305059889) [P] | Score: 0.189435166002 (0.0318588596011) [A]
Best score: 0.837085080214 (0.0402305059889) [P] | Score: 0.334433200703 (0.0251488770647) [A]
Best score: 0.837085080214 (0.0402305059889) [P] | Score: 0.196490321661 (0.00609392846874) [A]
Best score: 0.837085080214 (0.0402305059889) [P] | Score: 0.394517136569 (0.0289137053107) [A]
Best score: 0.837085080214 (0.0402305059889) [P] | Score: 0.263514266399 (0.0320137574457) [A]
Best score: 0.837085080214 (0.0402305059889) [P] | Score: 0.688098128988 (0.0728426910212) [A]
Best score: 0.837085080214 (0.0402305059889) [P] | Score: 0.196490321661 (0.00609392846874) [A]
Best score: 0.837085080214 (0.0402305059889) [P] | Score: 0.610619193742 (0.0580474767737) [A]
Best score: 0.837085080214 (0.0402305059889) [P] | Score: 0.270366549932 (0.02435351636) [A]
Best score: 0.837085080214 (0.0402305059889) [P] | Score: 0.196490321661 (0.00609392846874) [A]
Best score: 0.837085080214 (0.0402305059889) [P] | Score: 0.231180210847 (0.0438244730859) [A]
Best score: 0.837085080214 (0.0402305059889) [P] | Score: 0.82861171231 (0.0416273694215) [A]
Best score: 0.837085080214 (0.0402305059889) [P] | Score: 0.498888412657 (0.0476894757469) [A]
Best score: 0.837085080214 (0.0402305059889) [P] | Score: 0.153710282795 (0.0262346566348) [A]
Best score: 0.837085080214 (0.0402305059889) [P] | Score: 0.270366549932 (0.02435351636) [A]
Best score: 0.837085080214 (0.0402305059889) [P] | Score: 0.646964163496 (0.0430652558882) [A]
Best score: 0.837085080214 (0.0402305059889) [P] | Score: 0.196490321661 (0.00609392846874) [A]
Best score: 0.837085080214 (0.0402305059889) [P] | Score: 0.334433200703 (0.0251488770647) [A]
Best score: 0.837085080214 (0.0402305059889) [P] | Score: 0.201583268478 (0.0318961879675) [A]
Best score: 0.837085080214 (0.0402305059889) [P] | Score: 0.498888412657 (0.0476894757469) [A]
Best score: 0.837085080214 (0.0402305059889) [P] | Score: 0.189435166002 (0.0318588596011) [A]
Best score: 0.837085080214 (0.0402305059889) [P] | Score: 0.196490321661 (0.00609392846874) [A]
Best score: 0.837085080214 (0.0402305059889) [P] | Score: 0.818001860114 (0.0488300048688) [A]
Best score: 0.837085080214 (0.0402305059889) [P] | Score: 0.196490321661 (0.00609392846874) [A]
Best score: 0.837085080214 (0.0402305059889) [P] | Score: 0.101274256881 (0.00127440186725) [A]
Best score: 0.837085080214 (0.0402305059889) [P] | Score: 0.658981995712 (0.0409898413653) [A]
Best score: 0.837085080214 (0.0402305059889) [P] | Score: 0.189435166002 (0.0318588596011) [A]
Best score: 0.837085080214 (0.0402305059889) [P] | Score: 0.196490321661 (0.00609392846874) [A]
Best score: 0.837085080214 (0.0402305059889) [P] | Score: 0.646964163496 (0.0430652558882) [A]
Best score: 0.837085080214 (0.0402305059889) [P] | Score: 0.195206770245 (0.0225033316817) [A]
Best score: 0.837085080214 (0.0402305059889) [P] | Score: 0.189435166002 (0.0318588596011) [A]
Best score: 0.837085080214 (0.0402305059889) [P] | Score: 0.498888412657 (0.0476894757469) [A]
Best score: 0.837085080214 (0.0402305059889) [P] | Score: 0.196490321661 (0.00609392846874) [A]
#################### STEP RESULT ####################
BEST PIPELINE:
 {
    "features": [
        "features_NoneType", 
        {}
    ], 
    "normalizer": [
        "normalizer_MinMaxScaler", 
        {}
    ], 
    "rebalance": [
        "rebalance_NoneType", 
        {}
    ]
}
BEST ALGO CONFIG:
 {}
BEST SCORE: 0.837085080214 (0.0402305059889)
##################################################
## Data Pipeline
Best score: 0.837085080214 (0.0402305059889) [P] | Score: 0.241793670226 (0.0309787687817) [P]
#################### STEP RESULT ####################
BEST PIPELINE:
 {
    "features": [
        "features_NoneType", 
        {}
    ], 
    "normalizer": [
        "normalizer_MinMaxScaler", 
        {}
    ], 
    "rebalance": [
        "rebalance_NoneType", 
        {}
    ]
}
BEST ALGO CONFIG:
 {}
BEST SCORE: 0.837085080214 (0.0402305059889)
##################################################
## Algorithm
Best score: 0.837085080214 (0.0402305059889) [P] | Score: 0.660967861442 (0.0568080424771) [A]
Best score: 0.837085080214 (0.0402305059889) [P] | Score: 0.270366549932 (0.02435351636) [A]
Best score: 0.837085080214 (0.0402305059889) [P] | Score: 0.498888412657 (0.0476894757469) [A]
Best score: 0.837085080214 (0.0402305059889) [P] | Score: 0.156291882371 (0.0116704442255) [A]
Best score: 0.837085080214 (0.0402305059889) [P] | Score: 0.350435898413 (0.0624795729056) [A]
Best score: 0.837085080214 (0.0402305059889) [P] | Score: 0.226453759663 (0.0294415516689) [A]
Best score: 0.837085080214 (0.0402305059889) [P] | Score: 0.270366549932 (0.02435351636) [A]
Best score: 0.837085080214 (0.0402305059889) [P] | Score: 0.816936284217 (0.04686126344) [A]
Best score: 0.837085080214 (0.0402305059889) [P] | Score: 0.196490321661 (0.00609392846874) [A]
Best score: 0.837085080214 (0.0402305059889) [P] | Score: 0.156291882371 (0.0116704442255) [A]
Best score: 0.837085080214 (0.0402305059889) [P] | Score: 0.376554221609 (0.0648520904477) [A]
Best score: 0.837085080214 (0.0402305059889) [P] | Score: 0.195366211245 (0.0824274399851) [A]
Best score: 0.837085080214 (0.0402305059889) [P] | Score: 0.196490321661 (0.00609392846874) [A]
Best score: 0.837085080214 (0.0402305059889) [P] | Score: 0.196490321661 (0.00609392846874) [A]
Best score: 0.837085080214 (0.0402305059889) [P] | Score: 0.631561409733 (0.051593536085) [A]
Best score: 0.837085080214 (0.0402305059889) [P] | Score: 0.196490321661 (0.00609392846874) [A]
Best score: 0.837085080214 (0.0402305059889) [P] | Score: 0.189435166002 (0.0318588596011) [A]
Best score: 0.837085080214 (0.0402305059889) [P] | Score: 0.82809343458 (0.0479216808376) [A]
Best score: 0.837085080214 (0.0402305059889) [P] | Score: 0.196490321661 (0.00609392846874) [A]
Best score: 0.837085080214 (0.0402305059889) [P] | Score: 0.589623703085 (0.0549371551556) [A]
Best score: 0.837085080214 (0.0402305059889) [P] | Score: 0.816936284217 (0.04686126344) [A]
Best score: 0.837085080214 (0.0402305059889) [P] | Score: 0.394517136569 (0.0289137053107) [A]
Best score: 0.837085080214 (0.0402305059889) [P] | Score: 0.189435166002 (0.0318588596011) [A]
Best score: 0.837085080214 (0.0402305059889) [P] | Score: 0.297123135615 (0.0337195165687) [A]
Best score: 0.837085080214 (0.0402305059889) [P] | Score: 0.270366549932 (0.02435351636) [A]
Best score: 0.837085080214 (0.0402305059889) [P] | Score: 0.195366211245 (0.0824274399851) [A]
Best score: 0.837085080214 (0.0402305059889) [P] | Score: 0.297123135615 (0.0337195165687) [A]
Best score: 0.837085080214 (0.0402305059889) [P] | Score: 0.196490321661 (0.00609392846874) [A]
Best score: 0.837085080214 (0.0402305059889) [P] | Score: 0.195366211245 (0.0824274399851) [A]
Best score: 0.837085080214 (0.0402305059889) [P] | Score: 0.194173219095 (0.00776276896474) [A]
Best score: 0.837085080214 (0.0402305059889) [P] | Score: 0.678845109577 (0.0752330604477) [A]
Best score: 0.837085080214 (0.0402305059889) [P] | Score: 0.274869274788 (0.0356669954881) [A]
#################### STEP RESULT ####################
BEST PIPELINE:
 {
    "features": [
        "features_NoneType", 
        {}
    ], 
    "normalizer": [
        "normalizer_MinMaxScaler", 
        {}
    ], 
    "rebalance": [
        "rebalance_NoneType", 
        {}
    ]
}
BEST ALGO CONFIG:
 {}
BEST SCORE: 0.837085080214 (0.0402305059889)
##################################################
## Data Pipeline
Best score: 0.837085080214 (0.0402305059889) [P] | Score: 0.823679605715 (0.0369917266072) [P]
Best score: 0.837085080214 (0.0402305059889) [P] | Score: 0.83382709815 (0.0371988304708) [P]
Best score: 0.837088218749 (0.0402923373282) [P] | Score: 0.837088218749 (0.0402923373282) [P]
Best score: 0.837088218749 (0.0402923373282) [P] | Score: 0.470270678124 (0.0452275366566) [P]
Best score: 0.837088218749 (0.0402923373282) [P] | Score: 0.833642968777 (0.0345442123413) [P]
Best score: 0.837088218749 (0.0402923373282) [P] | Score: 0.482954495474 (0.0410615744974) [P]
Best score: 0.837088218749 (0.0402923373282) [P] | Score: 0.837085080214 (0.0402305059889) [P]
Best score: 0.837088218749 (0.0402923373282) [P] | Score: 0.292773570611 (0.0317594800524) [P]
Best score: 0.837088218749 (0.0402923373282) [P] | Score: 0.323985723022 (0.0349469034957) [P]
Best score: 0.837088218749 (0.0402923373282) [P] | Score: 0.561629893498 (0.0406077463435) [P]
Best score: 0.837088218749 (0.0402923373282) [P] | Score: 0.613957918805 (0.0692142010583) [P]
#################### STEP RESULT ####################
BEST PIPELINE:
 {
    "features": [
        "features_NoneType", 
        {}
    ], 
    "normalizer": [
        "normalizer_RobustScaler", 
        {
            "normalizer__quantile_range": [
                25.0, 
                75.0
            ], 
            "normalizer__with_centering": false, 
            "normalizer__with_scaling": true
        }
    ], 
    "rebalance": [
        "rebalance_NoneType", 
        {}
    ]
}
BEST ALGO CONFIG:
 {}
BEST SCORE: 0.837088218749 (0.0402923373282)
##################################################
## Algorithm
Best score: 0.837088218749 (0.0402923373282) [P] | Score: 0.270366549932 (0.02435351636) [A]
Best score: 0.837088218749 (0.0402923373282) [P] | Score: 0.196490321661 (0.00609392846874) [A]
Best score: 0.837088218749 (0.0402923373282) [P] | Score: 0.196490321661 (0.00609392846874) [A]
Best score: 0.837088218749 (0.0402923373282) [P] | Score: 0.834315243958 (0.0435842721663) [A]
Best score: 0.837088218749 (0.0402923373282) [P] | Score: 0.205393348194 (0.0130127106024) [A]
Best score: 0.837088218749 (0.0402923373282) [P] | Score: 0.394517136569 (0.0289137053107) [A]
Best score: 0.837088218749 (0.0402923373282) [P] | Score: 0.195206770245 (0.0225033316817) [A]
Best score: 0.837088218749 (0.0402923373282) [P] | Score: 0.818536648626 (0.0443059579325) [A]
Best score: 0.837088218749 (0.0402923373282) [P] | Score: 0.189435166002 (0.0318588596011) [A]
Best score: 0.837088218749 (0.0402923373282) [P] | Score: 0.498888412657 (0.0476894757469) [A]
Best score: 0.837088218749 (0.0402923373282) [P] | Score: 0.194173219095 (0.00776276896474) [A]
Best score: 0.837088218749 (0.0402923373282) [P] | Score: 0.590731287885 (0.0547532803621) [A]
Best score: 0.837088218749 (0.0402923373282) [P] | Score: 0.394517136569 (0.0289137053107) [A]
Best score: 0.837088218749 (0.0402923373282) [P] | Score: 0.646061586773 (0.0557234326625) [A]
Best score: 0.837088218749 (0.0402923373282) [P] | Score: 0.334433200703 (0.0251488770647) [A]
Best score: 0.837088218749 (0.0402923373282) [P] | Score: 0.834315243958 (0.0435842721663) [A]
Best score: 0.837088218749 (0.0402923373282) [P] | Score: 0.193155597138 (0.0199460674425) [A]
Best score: 0.837088218749 (0.0402923373282) [P] | Score: 0.498888412657 (0.0476894757469) [A]
Best score: 0.837088218749 (0.0402923373282) [P] | Score: 0.196490321661 (0.00609392846874) [A]
Best score: 0.837088218749 (0.0402923373282) [P] | Score: 0.100153799911 (0.00275947052357) [A]
Best score: 0.837088218749 (0.0402923373282) [P] | Score: 0.394517136569 (0.0289137053107) [A]
Best score: 0.837088218749 (0.0402923373282) [P] | Score: 0.350435898413 (0.0624795729056) [A]
Best score: 0.837088218749 (0.0402923373282) [P] | Score: 0.819131997616 (0.0386460090536) [A]
Best score: 0.837088218749 (0.0402923373282) [P] | Score: 0.334433200703 (0.0251488770647) [A]
Best score: 0.837088218749 (0.0402923373282) [P] | Score: 0.189435166002 (0.0318588596011) [A]
Best score: 0.837088218749 (0.0402923373282) [P] | Score: 0.825229267555 (0.0419745026381) [A]
Best score: 0.837088218749 (0.0402923373282) [P] | Score: 0.196490321661 (0.00609392846874) [A]
Best score: 0.837088218749 (0.0402923373282) [P] | Score: 0.109701223173 (0.0252627930255) [A]
Best score: 0.837088218749 (0.0402923373282) [P] | Score: 0.646061586773 (0.0557234326625) [A]
Best score: 0.837088218749 (0.0402923373282) [P] | Score: 0.646964163496 (0.0430652558882) [A]
#################### STEP RESULT ####################
BEST PIPELINE:
 {
    "features": [
        "features_NoneType", 
        {}
    ], 
    "normalizer": [
        "normalizer_RobustScaler", 
        {
            "normalizer__quantile_range": [
                25.0, 
                75.0
            ], 
            "normalizer__with_centering": false, 
            "normalizer__with_scaling": true
        }
    ], 
    "rebalance": [
        "rebalance_NoneType", 
        {}
    ]
}
BEST ALGO CONFIG:
 {}
BEST SCORE: 0.837088218749 (0.0402923373282)
##################################################
## Data Pipeline
Best score: 0.837088218749 (0.0402923373282) [P] | Score: 0.419901144491 (0.0523288860598) [P]
Best score: 0.837088218749 (0.0402923373282) [P] | Score: 0.837085080214 (0.0402305059889) [P]
Best score: 0.837088218749 (0.0402923373282) [P] | Score: 0.290488042953 (0.0606079310323) [P]
Best score: 0.837088218749 (0.0402923373282) [P] | Score: 0.823210305968 (0.0443926459865) [P]
#################### STEP RESULT ####################
BEST PIPELINE:
 {
    "features": [
        "features_NoneType", 
        {}
    ], 
    "normalizer": [
        "normalizer_RobustScaler", 
        {
            "normalizer__quantile_range": [
                25.0, 
                75.0
            ], 
            "normalizer__with_centering": false, 
            "normalizer__with_scaling": true
        }
    ], 
    "rebalance": [
        "rebalance_NoneType", 
        {}
    ]
}
BEST ALGO CONFIG:
 {}
BEST SCORE: 0.837088218749 (0.0402923373282)
##################################################
## Algorithm
Best score: 0.837088218749 (0.0402923373282) [P] | Score: 0.577209048436 (0.0865920138318) [A]
Best score: 0.837088218749 (0.0402923373282) [P] | Score: 0.270366549932 (0.02435351636) [A]
Best score: 0.837088218749 (0.0402923373282) [P] | Score: 0.52213982638 (0.041088362152) [A]
Best score: 0.837088218749 (0.0402923373282) [P] | Score: 0.590731287885 (0.0547532803621) [A]
Best score: 0.837088218749 (0.0402923373282) [P] | Score: 0.13540885104 (0.0258565301432) [A]
Best score: 0.837088218749 (0.0402923373282) [P] | Score: 0.334433200703 (0.0251488770647) [A]
Best score: 0.837088218749 (0.0402923373282) [P] | Score: 0.194173219095 (0.00776276896474) [A]
Best score: 0.837088218749 (0.0402923373282) [P] | Score: 0.101274256881 (0.00127440186725) [A]
Best score: 0.837088218749 (0.0402923373282) [P] | Score: 0.394517136569 (0.0289137053107) [A]
Best score: 0.837088218749 (0.0402923373282) [P] | Score: 0.196490321661 (0.00609392846874) [A]
Best score: 0.837088218749 (0.0402923373282) [P] | Score: 0.189435166002 (0.0318588596011) [A]
Best score: 0.837088218749 (0.0402923373282) [P] | Score: 0.819061683983 (0.0471166139954) [A]
Best score: 0.837088218749 (0.0402923373282) [P] | Score: 0.196490321661 (0.00609392846874) [A]
Best score: 0.837088218749 (0.0402923373282) [P] | Score: 0.544366592691 (0.045993673478) [A]
Best score: 0.837088218749 (0.0402923373282) [P] | Score: 0.394517136569 (0.0289137053107) [A]
Best score: 0.837088218749 (0.0402923373282) [P] | Score: 0.52213982638 (0.041088362152) [A]
Best score: 0.837088218749 (0.0402923373282) [P] | Score: 0.196490321661 (0.00609392846874) [A]
Best score: 0.837088218749 (0.0402923373282) [P] | Score: 0.109701223173 (0.0252627930255) [A]
Best score: 0.837088218749 (0.0402923373282) [P] | Score: 0.394517136569 (0.0289137053107) [A]
Best score: 0.837088218749 (0.0402923373282) [P] | Score: 0.630480999121 (0.0506773508738) [A]
Best score: 0.837088218749 (0.0402923373282) [P] | Score: 0.196490321661 (0.00609392846874) [A]
Best score: 0.837088218749 (0.0402923373282) [P] | Score: 0.364555081713 (0.225631834758) [A]
Best score: 0.837088218749 (0.0402923373282) [P] | Score: 0.397832053696 (0.029721061659) [A]
Best score: 0.837088218749 (0.0402923373282) [P] | Score: 0.193155597138 (0.0199460674425) [A]
#################### STEP RESULT ####################
BEST PIPELINE:
 {
    "features": [
        "features_NoneType", 
        {}
    ], 
    "normalizer": [
        "normalizer_RobustScaler", 
        {
            "normalizer__quantile_range": [
                25.0, 
                75.0
            ], 
            "normalizer__with_centering": false, 
            "normalizer__with_scaling": true
        }
    ], 
    "rebalance": [
        "rebalance_NoneType", 
        {}
    ]
}
BEST ALGO CONFIG:
 {}
BEST SCORE: 0.837088218749 (0.0402923373282)
##################################################
## Data Pipeline
Best score: 0.837088218749 (0.0402923373282) [P] | Score: 0.608979546567 (0.0468482302218) [P]
Best score: 0.837088218749 (0.0402923373282) [P] | Score: 0.449850305345 (0.0521990389055) [P]
Best score: 0.837088218749 (0.0402923373282) [P] | Score: 0.305981419914 (0.0297521848127) [P]
#################### STEP RESULT ####################
BEST PIPELINE:
 {
    "features": [
        "features_NoneType", 
        {}
    ], 
    "normalizer": [
        "normalizer_RobustScaler", 
        {
            "normalizer__quantile_range": [
                25.0, 
                75.0
            ], 
            "normalizer__with_centering": false, 
            "normalizer__with_scaling": true
        }
    ], 
    "rebalance": [
        "rebalance_NoneType", 
        {}
    ]
}
BEST ALGO CONFIG:
 {}
BEST SCORE: 0.837088218749 (0.0402923373282)
##################################################
## Algorithm
Best score: 0.837088218749 (0.0402923373282) [P] | Score: 0.829736209374 (0.0451787805715) [A]
Best score: 0.837088218749 (0.0402923373282) [P] | Score: 0.156291882371 (0.0116704442255) [A]
Best score: 0.837088218749 (0.0402923373282) [P] | Score: 0.297123135615 (0.0337195165687) [A]
Best score: 0.837088218749 (0.0402923373282) [P] | Score: 0.189435166002 (0.0318588596011) [A]
Best score: 0.837088218749 (0.0402923373282) [P] | Score: 0.109701223173 (0.0252627930255) [A]
Best score: 0.837088218749 (0.0402923373282) [P] | Score: 0.610644136343 (0.0583482072112) [A]
Best score: 0.837088218749 (0.0402923373282) [P] | Score: 0.270366549932 (0.02435351636) [A]
Best score: 0.837088218749 (0.0402923373282) [P] | Score: 0.397832053696 (0.029721061659) [A]
Best score: 0.837088218749 (0.0402923373282) [P] | Score: 0.818536648626 (0.0443059579325) [A]
Best score: 0.837088218749 (0.0402923373282) [P] | Score: 0.655001501728 (0.0557375280475) [A]
Best score: 0.837088218749 (0.0402923373282) [P] | Score: 0.193155597138 (0.0199460674425) [A]
Best score: 0.837088218749 (0.0402923373282) [P] | Score: 0.196490321661 (0.00609392846874) [A]
Best score: 0.837088218749 (0.0402923373282) [P] | Score: 0.82364134029 (0.0409421431733) [A]
Best score: 0.837088218749 (0.0402923373282) [P] | Score: 0.272762104262 (0.0413274796849) [A]
Best score: 0.837088218749 (0.0402923373282) [P] | Score: 0.195206770245 (0.0225033316817) [A]
Best score: 0.837088218749 (0.0402923373282) [P] | Score: 0.189435166002 (0.0318588596011) [A]
Best score: 0.837088218749 (0.0402923373282) [P] | Score: 0.828581027257 (0.0364202307181) [A]
Best score: 0.837088218749 (0.0402923373282) [P] | Score: 0.411696398085 (0.0285202602321) [A]
Best score: 0.837088218749 (0.0402923373282) [P] | Score: 0.658969510148 (0.0398750438895) [A]
Best score: 0.837088218749 (0.0402923373282) [P] | Score: 0.226453759663 (0.0294415516689) [A]
Best score: 0.837088218749 (0.0402923373282) [P] | Score: 0.28880701476 (0.00864265081491) [A]
Best score: 0.837088218749 (0.0402923373282) [P] | Score: 0.194173219095 (0.00776276896474) [A]
Best score: 0.837088218749 (0.0402923373282) [P] | Score: 0.646964163496 (0.0430652558882) [A]
Best score: 0.837088218749 (0.0402923373282) [P] | Score: 0.696587596676 (0.0658769492878) [A]
#################### STEP RESULT ####################
BEST PIPELINE:
 {
    "features": [
        "features_NoneType", 
        {}
    ], 
    "normalizer": [
        "normalizer_RobustScaler", 
        {
            "normalizer__quantile_range": [
                25.0, 
                75.0
            ], 
            "normalizer__with_centering": false, 
            "normalizer__with_scaling": true
        }
    ], 
    "rebalance": [
        "rebalance_NoneType", 
        {}
    ]
}
BEST ALGO CONFIG:
 {}
BEST SCORE: 0.837088218749 (0.0402923373282)
##################################################
