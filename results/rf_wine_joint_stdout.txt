SCENARIO:
 {
    "control": {
        "seed": 42
    }, 
    "file_name": "rf_wine_joint", 
    "policy": null, 
    "setup": {
        "algorithm": "RandomForest", 
        "dataset": "wine", 
        "policy": "joint", 
        "runtime": 300
    }, 
    "title": "Random Forest on Wine with Joint policy"
}
JoblibValueError
___________________________________________________________________________
...........................................................................
/home/aquemy/dev/dp_hyperparameters/extension/main.py in <module>()
     27 
     28     serializer.serialize_results(scenario, policy)
     29 
     30 if __name__ == "__main__":
     31     args = cli.parse_args()
---> 32     main(args)

...........................................................................
/home/aquemy/dev/dp_hyperparameters/extension/main.py in main(args=Namespace(customize=[(['control', 'seed'], '42')...io='./scenarios/rf_wine_joint.yaml', verbosity=0))
     21         test_size=0.4, 
     22         random_state=scenario['control']['seed']
     23     )
     24 
     25     policy = policies.initiate(scenario['setup']['policy'], config)
---> 26     policy.run(X,y)
        policy.run = <bound method Joint.run of <experiment.policies.joint.Joint object>>
        X = array([[1.423e+01, 1.710e+00, 2.430e+00, ..., 1...., ..., 6.100e-01, 1.600e+00,
        5.600e+02]])
        y = array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,
       2, 2])
     27 
     28     serializer.serialize_results(scenario, policy)
     29 
     30 if __name__ == "__main__":

...........................................................................
/home/aquemy/dev/dp_hyperparameters/extension/experiment/policies/joint.py in run(self=<experiment.policies.joint.Joint object>, X=array([[1.423e+01, 1.710e+00, 2.430e+00, ..., 1...., ..., 6.100e-01, 1.600e+00,
        5.600e+02]]), y=array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,
       2, 2]))
     32             algo=tpe.suggest, 
     33             max_evals=None,
     34             max_time=self.config['time'],     
     35             trials=trials,
     36             show_progressbar=False,
---> 37             verbose=0
     38         )
     39 
     40         best_config = self.context['best_config']
     41         super(Joint, self).display_step_results(best_config)

...........................................................................
/home/aquemy/dev/dp_hyperparameters/extension/hyperopt/fmin.py in fmin(fn=<functools.partial object>, space={'algorithm': {'bootstrap': <hyperopt.pyll.base.Apply object>, 'criterion': <hyperopt.pyll.base.Apply object>, 'max_depth': <hyperopt.pyll.base.Apply object>, 'max_features': <hyperopt.pyll.base.Apply object>, 'max_leaf_nodes': <hyperopt.pyll.base.Apply object>, 'min_samples_split': <hyperopt.pyll.base.Apply object>, 'n_estimators': <hyperopt.pyll.base.Apply object>}, 'pipeline': {'features': <hyperopt.pyll.base.Apply object>, 'normalizer': <hyperopt.pyll.base.Apply object>, 'rebalance': <hyperopt.pyll.base.Apply object>}}, algo=<function suggest>, max_evals=9223372036854775807, max_time=300, trials=<hyperopt.base.Trials object>, rstate=<mtrand.RandomState object>, allow_trials_fmin=True, pass_expr_memo_ctrl=None, catch_eval_exceptions=False, verbose=0, return_argmin=True, points_to_evaluate=None, max_queue_len=1, show_progressbar=False)
    406             pass_expr_memo_ctrl=pass_expr_memo_ctrl,
    407             verbose=verbose,
    408             catch_eval_exceptions=catch_eval_exceptions,
    409             return_argmin=return_argmin,
    410             show_progressbar=show_progressbar,
--> 411             max_time=max_time
        max_time = 300
    412         )
    413 
    414     if trials is None:
    415         if points_to_evaluate is None:

...........................................................................
/home/aquemy/dev/dp_hyperparameters/extension/hyperopt/base.py in fmin(self=<hyperopt.base.Trials object>, fn=<functools.partial object>, space={'algorithm': {'bootstrap': <hyperopt.pyll.base.Apply object>, 'criterion': <hyperopt.pyll.base.Apply object>, 'max_depth': <hyperopt.pyll.base.Apply object>, 'max_features': <hyperopt.pyll.base.Apply object>, 'max_leaf_nodes': <hyperopt.pyll.base.Apply object>, 'min_samples_split': <hyperopt.pyll.base.Apply object>, 'n_estimators': <hyperopt.pyll.base.Apply object>}, 'pipeline': {'features': <hyperopt.pyll.base.Apply object>, 'normalizer': <hyperopt.pyll.base.Apply object>, 'rebalance': <hyperopt.pyll.base.Apply object>}}, algo=<function suggest>, max_evals=9223372036854775807, max_time=300, rstate=<mtrand.RandomState object>, verbose=0, pass_expr_memo_ctrl=None, catch_eval_exceptions=False, return_argmin=True, show_progressbar=False)
    636             verbose=verbose,
    637             allow_trials_fmin=False,  # -- prevent recursion
    638             pass_expr_memo_ctrl=pass_expr_memo_ctrl,
    639             catch_eval_exceptions=catch_eval_exceptions,
    640             return_argmin=return_argmin,
--> 641             show_progressbar=show_progressbar)
        show_progressbar = False
    642 
    643 
    644 def trials_from_docs(docs, validate=True, **kwargs):
    645     """Construct a Trials base class instance from a list of trials documents

...........................................................................
/home/aquemy/dev/dp_hyperparameters/extension/hyperopt/fmin.py in fmin(fn=<functools.partial object>, space={'algorithm': {'bootstrap': <hyperopt.pyll.base.Apply object>, 'criterion': <hyperopt.pyll.base.Apply object>, 'max_depth': <hyperopt.pyll.base.Apply object>, 'max_features': <hyperopt.pyll.base.Apply object>, 'max_leaf_nodes': <hyperopt.pyll.base.Apply object>, 'min_samples_split': <hyperopt.pyll.base.Apply object>, 'n_estimators': <hyperopt.pyll.base.Apply object>}, 'pipeline': {'features': <hyperopt.pyll.base.Apply object>, 'normalizer': <hyperopt.pyll.base.Apply object>, 'rebalance': <hyperopt.pyll.base.Apply object>}}, algo=<function suggest>, max_evals=9223372036854775807, max_time=300, trials=<hyperopt.base.Trials object>, rstate=<mtrand.RandomState object>, allow_trials_fmin=False, pass_expr_memo_ctrl=None, catch_eval_exceptions=False, verbose=0, return_argmin=True, points_to_evaluate=None, max_queue_len=1, show_progressbar=False)
    426                     verbose=verbose,
    427                     max_queue_len=max_queue_len,
    428                     show_progressbar=show_progressbar,
    429                     max_time=max_time)
    430     rval.catch_eval_exceptions = catch_eval_exceptions
--> 431     rval.exhaust()
        rval.exhaust = <bound method FMinIter.exhaust of <hyperopt.fmin.FMinIter object>>
    432     if return_argmin:
    433         return trials.argmin
    434     elif len(trials) > 0:
    435         # Only if there are some succesfull trail runs, return the best point in the evaluation space

...........................................................................
/home/aquemy/dev/dp_hyperparameters/extension/hyperopt/fmin.py in exhaust(self=<hyperopt.fmin.FMinIter object>)
    273             raise StopIteration()
    274         return self.trials
    275 
    276     def exhaust(self):
    277         n_done = len(self.trials)
--> 278         self.run(self.max_evals - n_done, block_until_done=self.asynchronous)
        self.run = <bound method FMinIter.run of <hyperopt.fmin.FMinIter object>>
        self.max_evals = 9223372036854775807
        n_done = 0
        self.asynchronous = False
    279         self.trials.refresh()
    280         return self
    281 
    282 

...........................................................................
/home/aquemy/dev/dp_hyperparameters/extension/hyperopt/fmin.py in run(self=<hyperopt.fmin.FMinIter object>, N=9223372036854775807, block_until_done=False)
    232                     if self.asynchronous:
    233                         # -- wait for workers to fill in the trials
    234                         time.sleep(self.poll_interval_secs)
    235                     else:
    236                         # -- loop over trials and do the jobs directly
--> 237                         self.serial_evaluate()
        self.serial_evaluate = <bound method FMinIter.serial_evaluate of <hyperopt.fmin.FMinIter object>>
    238                     try:
    239                         res = [d['result']['loss'] for d in
    240                                          self.trials.trials if
    241                                          d['result']['status'] == 'ok']

...........................................................................
/home/aquemy/dev/dp_hyperparameters/extension/hyperopt/fmin.py in serial_evaluate(self=<hyperopt.fmin.FMinIter object>, N=-1)
    138                 trial['book_time'] = now
    139                 trial['refresh_time'] = now
    140                 spec = base.spec_from_misc(trial['misc'])
    141                 ctrl = base.Ctrl(self.trials, current_trial=trial)
    142                 try:
--> 143                     result = self.domain.evaluate(spec, ctrl)
        result = undefined
        self.domain.evaluate = <bound method Domain.evaluate of <hyperopt.base.Domain object>>
        spec = {'bootstrap': 1, 'criterion': 1, 'features': 1, 'features_PCA_features__n_components': 0, 'max_depth': 4, 'max_features': 2, 'max_leaf_nodes': 2, 'min_samples_split': 0, 'n_estimators': 2, 'normalizer': 0, ...}
        ctrl = <hyperopt.base.Ctrl object>
    144                 except Exception as e:
    145                     logger.info('job exception: %s' % str(e))
    146                     trial['state'] = base.JOB_STATE_ERROR
    147                     trial['misc']['error'] = (str(type(e)), str(e))

...........................................................................
/home/aquemy/dev/dp_hyperparameters/extension/hyperopt/base.py in evaluate(self=<hyperopt.base.Domain object>, config={'bootstrap': 1, 'criterion': 1, 'features': 1, 'features_PCA_features__n_components': 0, 'max_depth': 4, 'max_features': 2, 'max_leaf_nodes': 2, 'min_samples_split': 0, 'n_estimators': 2, 'normalizer': 0, ...}, ctrl=<hyperopt.base.Ctrl object>, attach_attachments=True)
    841             #    or the normal Python part (self.fn)
    842             pyll_rval = pyll.rec_eval(
    843                 self.expr,
    844                 memo=memo,
    845                 print_node_on_error=self.rec_eval_print_node_on_error)
--> 846             rval = self.fn(pyll_rval)
        rval = undefined
        self.fn = <functools.partial object>
        pyll_rval = {'algorithm': {'bootstrap': False, 'criterion': 'entropy', 'max_depth': None, 'max_features': 3, 'max_leaf_nodes': 5, 'min_samples_split': 2, 'n_estimators': 50}, 'pipeline': {'features': ('features_PCA', {'features__n_components': 1}), 'normalizer': ('normalizer_NoneType', {}), 'rebalance': ('rebalance_CondensedNearestNeighbour', {'rebalance__n_neighbors': 3})}}
    847 
    848         if isinstance(rval, (float, int, np.number)):
    849             dict_rval = {'loss': float(rval), 'status': STATUS_OK}
    850         else:

...........................................................................
/home/aquemy/dev/dp_hyperparameters/extension/experiment/objective.py in objective_joint(wconfig={'algorithm': {'bootstrap': False, 'criterion': 'entropy', 'max_depth': None, 'max_features': 3, 'max_leaf_nodes': 5, 'min_samples_split': 2, 'n_estimators': 50}, 'pipeline': {'features': ('features_PCA', {'features__n_components': 1}), 'normalizer': ('normalizer_NoneType', {}), 'rebalance': ('rebalance_CondensedNearestNeighbour', {'rebalance__n_neighbors': 3})}}, algorithm='RandomForest', X=array([[1.423e+01, 1.710e+00, 2.430e+00, ..., 1...., ..., 6.100e-01, 1.600e+00,
        5.600e+02]]), y=array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,
       2, 2]), context={'baseline_score': 0.9444100447196423, 'baseline_score_std': 0.04305547117084885, 'best_config': {}, 'history': [], 'history_hash': [], 'history_index': {}, 'iteration': 0, 'max_history_score': 0.0, 'max_history_score_std': 0.0, 'max_history_step': 'baseline'}, config={'algorithm': 'RandomForest', 'seed': 42, 'time': 300})
    108 
    109 def objective_algo(algo_config, current_pipeline_config, algorithm, X, y, context, config):
    110     return objective(current_pipeline_config, algo_config, algorithm, X, y, context, config, step='algorithm')
    111 
    112 def objective_joint(wconfig, algorithm, X, y, context, config):
--> 113     return objective(wconfig['pipeline'], wconfig['algorithm'], algorithm, X, y, context, config, step='joint')
        wconfig = {'algorithm': {'bootstrap': False, 'criterion': 'entropy', 'max_depth': None, 'max_features': 3, 'max_leaf_nodes': 5, 'min_samples_split': 2, 'n_estimators': 50}, 'pipeline': {'features': ('features_PCA', {'features__n_components': 1}), 'normalizer': ('normalizer_NoneType', {}), 'rebalance': ('rebalance_CondensedNearestNeighbour', {'rebalance__n_neighbors': 3})}}
        algorithm = 'RandomForest'
        X = array([[1.423e+01, 1.710e+00, 2.430e+00, ..., 1...., ..., 6.100e-01, 1.600e+00,
        5.600e+02]])
        y = array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,
       2, 2])
        context = {'baseline_score': 0.9444100447196423, 'baseline_score_std': 0.04305547117084885, 'best_config': {}, 'history': [], 'history_hash': [], 'history_index': {}, 'iteration': 0, 'max_history_score': 0.0, 'max_history_score_std': 0.0, 'max_history_step': 'baseline'}
        config = {'algorithm': 'RandomForest', 'seed': 42, 'time': 300}
    114 
    115 
    116 def get_baseline_score(algorithm, X, y, seed):
    117     pipeline, _ = pipeline_conf_to_full_pipeline(

...........................................................................
/home/aquemy/dev/dp_hyperparameters/extension/experiment/objective.py in objective(pipeline_config={'features': ('features_PCA', {'features__n_components': 1}), 'normalizer': ('normalizer_NoneType', {}), 'rebalance': ('rebalance_CondensedNearestNeighbour', {'rebalance__n_neighbors': 3})}, algo_config={'bootstrap': False, 'criterion': 'entropy', 'max_depth': None, 'max_features': 3, 'max_leaf_nodes': 5, 'min_samples_split': 2, 'n_estimators': 50}, algorithm='RandomForest', X=array([[1.423e+01, 1.710e+00, 2.430e+00, ..., 1...., ..., 6.100e-01, 1.600e+00,
        5.600e+02]]), y=array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,
       2, 2]), context={'baseline_score': 0.9444100447196423, 'baseline_score_std': 0.04305547117084885, 'best_config': {}, 'history': [], 'history_hash': [], 'history_index': {}, 'iteration': 0, 'max_history_score': 0.0, 'max_history_score_std': 0.0, 'max_history_step': 'baseline'}, config={'algorithm': 'RandomForest', 'seed': 42, 'time': 300}, step='joint')
     45                 y,
     46                 cv=10,
     47                 n_jobs=-1,
     48                 return_estimator=False,
     49                 return_train_score=False,
---> 50                 verbose=0)
     51         score = np.mean(scores['test_score'])
     52         std = np.std(scores['test_score'])
     53         status = STATUS_OK
     54     except Exception as e:

...........................................................................
/home/aquemy/.local/lib/python2.7/site-packages/sklearn/model_selection/_validation.py in cross_validate(estimator=Pipeline(memory=None,
     steps=[('rebalance', ...e=42,
            verbose=0, warm_start=False))]), X=array([[1.423e+01, 1.710e+00, 2.430e+00, ..., 1...., ..., 6.100e-01, 1.600e+00,
        5.600e+02]]), y=array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,
       2, 2]), groups=None, scoring=None, cv=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1, verbose=0, fit_params=None, pre_dispatch='2*n_jobs', return_train_score=False, return_estimator=False, error_score='raise-deprecating')
    235         delayed(_fit_and_score)(
    236             clone(estimator), X, y, scorers, train, test, verbose, None,
    237             fit_params, return_train_score=return_train_score,
    238             return_times=True, return_estimator=return_estimator,
    239             error_score=error_score)
--> 240         for train, test in cv.split(X, y, groups))
        cv.split = <bound method StratifiedKFold.split of Stratifie...d(n_splits=10, random_state=None, shuffle=False)>
        X = array([[1.423e+01, 1.710e+00, 2.430e+00, ..., 1...., ..., 6.100e-01, 1.600e+00,
        5.600e+02]])
        y = array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,
       2, 2])
        groups = None
    241 
    242     zipped_scores = list(zip(*scores))
    243     if return_train_score:
    244         train_scores = zipped_scores.pop(0)

...........................................................................
/home/aquemy/.local/lib/python2.7/site-packages/sklearn/externals/joblib/parallel.py in __call__(self=Parallel(n_jobs=-1), iterable=<generator object <genexpr>>)
    925                 # No need to wait for async callbacks to trigger to
    926                 # consumption.
    927                 self._iterating = False
    928 
    929             with self._backend.retrieval_context():
--> 930                 self.retrieve()
        self.retrieve = <bound method Parallel.retrieve of Parallel(n_jobs=-1)>
    931             # Make sure that we get a last message telling us we are done
    932             elapsed_time = time.time() - self._start_time
    933             self._print('Done %3i out of %3i | elapsed: %s finished',
    934                         (len(self._output), len(self._output),

---------------------------------------------------------------------------
Joblib worker traceback:
---------------------------------------------------------------------------
ValueError                                         Mon Jun 17 12:45:13 2019
PID: 15022                                  Python 2.7.15+: /usr/bin/python
...........................................................................
/home/aquemy/.local/lib/python2.7/site-packages/sklearn/externals/joblib/parallel.py in __call__(self=<sklearn.externals.joblib.parallel.BatchedCalls object>)
    220     def __call__(self):
    221         # Set the default nested backend to self._backend but do not set the
    222         # change the default number of processes to -1
    223         with parallel_backend(self._backend, n_jobs=self._n_jobs):
    224             return [func(*args, **kwargs)
--> 225                     for func, args, kwargs in self.items]
        func = <function _fit_and_score>
        args = (Pipeline(memory=None,
     steps=[('rebalance', ...e=42,
            verbose=0, warm_start=False))]), array([[1.423e+01, 1.710e+00, 2.430e+00, ..., 1...., ..., 6.100e-01, 1.600e+00,
        5.600e+02]]), array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,
       2, 2]), {'score': <function _passthrough_scorer>}, array([  6,   7,   8,   9,  10,  11,  12,  13,  ..., 170, 171, 172, 173, 174,
       175, 176, 177]), array([  0,   1,   2,   3,   4,   5,  59,  60,  ...,  64,  65,
        66, 130, 131, 132, 133, 134]), 0, None, None)
        kwargs = {'error_score': 'raise-deprecating', 'return_estimator': False, 'return_times': True, 'return_train_score': False}
        self.items = [(<function _fit_and_score>, (Pipeline(memory=None,
     steps=[('rebalance', ...e=42,
            verbose=0, warm_start=False))]), array([[1.423e+01, 1.710e+00, 2.430e+00, ..., 1...., ..., 6.100e-01, 1.600e+00,
        5.600e+02]]), array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,
       2, 2]), {'score': <function _passthrough_scorer>}, array([  6,   7,   8,   9,  10,  11,  12,  13,  ..., 170, 171, 172, 173, 174,
       175, 176, 177]), array([  0,   1,   2,   3,   4,   5,  59,  60,  ...,  64,  65,
        66, 130, 131, 132, 133, 134]), 0, None, None), {'error_score': 'raise-deprecating', 'return_estimator': False, 'return_times': True, 'return_train_score': False})]
    226 
    227     def __len__(self):
    228         return self._size
    229 

...........................................................................
/home/aquemy/.local/lib/python2.7/site-packages/sklearn/model_selection/_validation.py in _fit_and_score(estimator=Pipeline(memory=None,
     steps=[('rebalance', ...e=42,
            verbose=0, warm_start=False))]), X=array([[1.423e+01, 1.710e+00, 2.430e+00, ..., 1...., ..., 6.100e-01, 1.600e+00,
        5.600e+02]]), y=array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,
       2, 2]), scorer={'score': <function _passthrough_scorer>}, train=array([  6,   7,   8,   9,  10,  11,  12,  13,  ..., 170, 171, 172, 173, 174,
       175, 176, 177]), test=array([  0,   1,   2,   3,   4,   5,  59,  60,  ...,  64,  65,
        66, 130, 131, 132, 133, 134]), verbose=0, parameters=None, fit_params={}, return_train_score=False, return_parameters=False, return_n_test_samples=False, return_times=True, return_estimator=False, error_score='raise-deprecating')
    523 
    524     try:
    525         if y_train is None:
    526             estimator.fit(X_train, **fit_params)
    527         else:
--> 528             estimator.fit(X_train, y_train, **fit_params)
        estimator.fit = <bound method Pipeline.fit of Pipeline(memory=No...=42,
            verbose=0, warm_start=False))])>
        X_train = array([[1.439e+01, 1.870e+00, 2.450e+00, ..., 1...., ..., 6.100e-01, 1.600e+00,
        5.600e+02]])
        y_train = array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...2, 2, 2, 2, 2, 2, 2, 2, 2,
       2, 2, 2, 2, 2])
        fit_params = {}
    529 
    530     except Exception as e:
    531         # Note fit time as time until error
    532         fit_time = time.time() - start_time

...........................................................................
/usr/local/lib/python2.7/dist-packages/imblearn/pipeline.py in fit(self=Pipeline(memory=None,
     steps=[('rebalance', ...e=42,
            verbose=0, warm_start=False))]), X=array([[1.439e+01, 1.870e+00, 2.450e+00, ..., 1...., ..., 6.100e-01, 1.600e+00,
        5.600e+02]]), y=array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...2, 2, 2, 2, 2, 2, 2, 2, 2,
       2, 2, 2, 2, 2]), **fit_params={})
    234             This estimator
    235 
    236         """
    237         Xt, yt, fit_params = self._fit(X, y, **fit_params)
    238         if self._final_estimator is not None:
--> 239             self._final_estimator.fit(Xt, yt, **fit_params)
        self._final_estimator.fit = <bound method RandomForestClassifier.fit of Rand...ate=42,
            verbose=0, warm_start=False)>
        Xt = array([[ 646.64096333],
       [ 616.80425334],
...
       [ 167.37799221],
       [-113.08381599]])
        yt = array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1,... 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2])
        fit_params = {}
    240         return self
    241 
    242     def fit_transform(self, X, y=None, **fit_params):
    243         """Fit the model and transform with the final estimator

...........................................................................
/home/aquemy/.local/lib/python2.7/site-packages/sklearn/ensemble/forest.py in fit(self=RandomForestClassifier(bootstrap=False, class_we...tate=42,
            verbose=0, warm_start=False), X=array([[ 646.641    ],
       [ 616.80426  ],
  ....37799  ],
       [-113.08382  ]], dtype=float32), y=array([[0.],
       [0.],
       [0.],
       [0...    [2.],
       [2.],
       [2.],
       [2.]]), sample_weight=None)
    328             trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,
    329                              **_joblib_parallel_args(prefer='threads'))(
    330                 delayed(_parallel_build_trees)(
    331                     t, self, X, y, sample_weight, i, len(trees),
    332                     verbose=self.verbose, class_weight=self.class_weight)
--> 333                 for i, t in enumerate(trees))
        i = 49
    334 
    335             # Collect newly grown trees
    336             self.estimators_.extend(trees)
    337 

...........................................................................
/home/aquemy/.local/lib/python2.7/site-packages/sklearn/externals/joblib/parallel.py in __call__(self=Parallel(n_jobs=1), iterable=<generator object <genexpr>>)
    912             # self._original_iterator is None, then this means either
    913             # that pre_dispatch == "all", n_jobs == 1 or that the first batch
    914             # was very quick and its callback already dispatched all the
    915             # remaining jobs.
    916             self._iterating = False
--> 917             if self.dispatch_one_batch(iterator):
        self.dispatch_one_batch = <bound method Parallel.dispatch_one_batch of Parallel(n_jobs=1)>
        iterator = <generator object <genexpr>>
    918                 self._iterating = self._original_iterator is not None
    919 
    920             while self.dispatch_one_batch(iterator):
    921                 pass

...........................................................................
/home/aquemy/.local/lib/python2.7/site-packages/sklearn/externals/joblib/parallel.py in dispatch_one_batch(self=Parallel(n_jobs=1), iterator=<generator object <genexpr>>)
    754                                  self._pickle_cache)
    755             if len(tasks) == 0:
    756                 # No more tasks available in the iterator: tell caller to stop.
    757                 return False
    758             else:
--> 759                 self._dispatch(tasks)
        self._dispatch = <bound method Parallel._dispatch of Parallel(n_jobs=1)>
        tasks = <sklearn.externals.joblib.parallel.BatchedCalls object>
    760                 return True
    761 
    762     def _print(self, msg, msg_args):
    763         """Display the message on stout or stderr depending on verbosity"""

...........................................................................
/home/aquemy/.local/lib/python2.7/site-packages/sklearn/externals/joblib/parallel.py in _dispatch(self=Parallel(n_jobs=1), batch=<sklearn.externals.joblib.parallel.BatchedCalls object>)
    711 
    712         dispatch_timestamp = time.time()
    713         cb = BatchCompletionCallBack(dispatch_timestamp, len(batch), self)
    714         with self._lock:
    715             job_idx = len(self._jobs)
--> 716             job = self._backend.apply_async(batch, callback=cb)
        job = undefined
        self._backend.apply_async = <bound method SequentialBackend.apply_async of <...lib._parallel_backends.SequentialBackend object>>
        batch = <sklearn.externals.joblib.parallel.BatchedCalls object>
        cb = <sklearn.externals.joblib.parallel.BatchCompletionCallBack object>
    717             # A job can complete so quickly than its callback is
    718             # called before we get here, causing self._jobs to
    719             # grow. To ensure correct results ordering, .insert is
    720             # used (rather than .append) in the following line

...........................................................................
/home/aquemy/.local/lib/python2.7/site-packages/sklearn/externals/joblib/_parallel_backends.py in apply_async(self=<sklearn.externals.joblib._parallel_backends.SequentialBackend object>, func=<sklearn.externals.joblib.parallel.BatchedCalls object>, callback=<sklearn.externals.joblib.parallel.BatchCompletionCallBack object>)
    177             raise ValueError('n_jobs == 0 in Parallel has no meaning')
    178         return 1
    179 
    180     def apply_async(self, func, callback=None):
    181         """Schedule a func to be run"""
--> 182         result = ImmediateResult(func)
        result = undefined
        func = <sklearn.externals.joblib.parallel.BatchedCalls object>
    183         if callback:
    184             callback(result)
    185         return result
    186 

...........................................................................
/home/aquemy/.local/lib/python2.7/site-packages/sklearn/externals/joblib/_parallel_backends.py in __init__(self=<sklearn.externals.joblib._parallel_backends.ImmediateResult object>, batch=<sklearn.externals.joblib.parallel.BatchedCalls object>)
    544 
    545 class ImmediateResult(object):
    546     def __init__(self, batch):
    547         # Don't delay the application, to avoid keeping the input
    548         # arguments in memory
--> 549         self.results = batch()
        self.results = undefined
        batch = <sklearn.externals.joblib.parallel.BatchedCalls object>
    550 
    551     def get(self):
    552         return self.results
    553 

...........................................................................
/home/aquemy/.local/lib/python2.7/site-packages/sklearn/externals/joblib/parallel.py in __call__(self=<sklearn.externals.joblib.parallel.BatchedCalls object>)
    220     def __call__(self):
    221         # Set the default nested backend to self._backend but do not set the
    222         # change the default number of processes to -1
    223         with parallel_backend(self._backend, n_jobs=self._n_jobs):
    224             return [func(*args, **kwargs)
--> 225                     for func, args, kwargs in self.items]
        func = <function _parallel_build_trees>
        args = (DecisionTreeClassifier(class_weight=None, criter...=False, random_state=1608637542, splitter='best'), RandomForestClassifier(bootstrap=False, class_we...tate=42,
            verbose=0, warm_start=False), array([[ 646.641    ],
       [ 616.80426  ],
  ....37799  ],
       [-113.08382  ]], dtype=float32), array([[0.],
       [0.],
       [0.],
       [0...    [2.],
       [2.],
       [2.],
       [2.]]), None, 0, 50)
        kwargs = {'class_weight': None, 'verbose': 0}
        self.items = [(<function _parallel_build_trees>, (DecisionTreeClassifier(class_weight=None, criter...=False, random_state=1608637542, splitter='best'), RandomForestClassifier(bootstrap=False, class_we...tate=42,
            verbose=0, warm_start=False), array([[ 646.641    ],
       [ 616.80426  ],
  ....37799  ],
       [-113.08382  ]], dtype=float32), array([[0.],
       [0.],
       [0.],
       [0...    [2.],
       [2.],
       [2.],
       [2.]]), None, 0, 50), {'class_weight': None, 'verbose': 0})]
    226 
    227     def __len__(self):
    228         return self._size
    229 

...........................................................................
/home/aquemy/.local/lib/python2.7/site-packages/sklearn/ensemble/forest.py in _parallel_build_trees(tree=DecisionTreeClassifier(class_weight=None, criter...=False, random_state=1608637542, splitter='best'), forest=RandomForestClassifier(bootstrap=False, class_we...tate=42,
            verbose=0, warm_start=False), X=array([[ 646.641    ],
       [ 616.80426  ],
  ....37799  ],
       [-113.08382  ]], dtype=float32), y=array([[0.],
       [0.],
       [0.],
       [0...    [2.],
       [2.],
       [2.],
       [2.]]), sample_weight=None, tree_idx=0, n_trees=50, verbose=0, class_weight=None)
    116         elif class_weight == 'balanced_subsample':
    117             curr_sample_weight *= compute_sample_weight('balanced', y, indices)
    118 
    119         tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)
    120     else:
--> 121         tree.fit(X, y, sample_weight=sample_weight, check_input=False)
        tree.fit = <bound method DecisionTreeClassifier.fit of Deci...False, random_state=1608637542, splitter='best')>
        X = array([[ 646.641    ],
       [ 616.80426  ],
  ....37799  ],
       [-113.08382  ]], dtype=float32)
        y = array([[0.],
       [0.],
       [0.],
       [0...    [2.],
       [2.],
       [2.],
       [2.]])
        sample_weight = None
    122 
    123     return tree
    124 
    125 

...........................................................................
/home/aquemy/.local/lib/python2.7/site-packages/sklearn/tree/tree.py in fit(self=DecisionTreeClassifier(class_weight=None, criter...=False, random_state=1608637542, splitter='best'), X=array([[ 646.641    ],
       [ 616.80426  ],
  ....37799  ],
       [-113.08382  ]], dtype=float32), y=array([[0.],
       [0.],
       [0.],
       [0...    [2.],
       [2.],
       [2.],
       [2.]]), sample_weight=None, check_input=False, X_idx_sorted=None)
    796 
    797         super(DecisionTreeClassifier, self).fit(
    798             X, y,
    799             sample_weight=sample_weight,
    800             check_input=check_input,
--> 801             X_idx_sorted=X_idx_sorted)
        X_idx_sorted = None
    802         return self
    803 
    804     def predict_proba(self, X, check_input=True):
    805         """Predict class probabilities of the input samples X.

...........................................................................
/home/aquemy/.local/lib/python2.7/site-packages/sklearn/tree/tree.py in fit(self=DecisionTreeClassifier(class_weight=None, criter...=False, random_state=1608637542, splitter='best'), X=array([[ 646.641    ],
       [ 616.80426  ],
  ....37799  ],
       [-113.08382  ]], dtype=float32), y=array([[0.],
       [0.],
       [0.],
       [0...    [2.],
       [2.],
       [2.],
       [2.]]), sample_weight=None, check_input=False, X_idx_sorted=None)
    237         if not 0 <= self.min_weight_fraction_leaf <= 0.5:
    238             raise ValueError("min_weight_fraction_leaf must in [0, 0.5]")
    239         if max_depth <= 0:
    240             raise ValueError("max_depth must be greater than zero. ")
    241         if not (0 < max_features <= self.n_features_):
--> 242             raise ValueError("max_features must be in (0, n_features]")
    243         if not isinstance(max_leaf_nodes, (numbers.Integral, np.integer)):
    244             raise ValueError("max_leaf_nodes must be integral number but was "
    245                              "%r" % max_leaf_nodes)
    246         if -1 < max_leaf_nodes < 2:

ValueError: max_features must be in (0, n_features]
___________________________________________________________________________
Best score: 0.0 (0.0) [B] | Score: 0.0 (0.0) [J]
Best score: 0.596136480908 (0.0535146321003) [J] | Score: 0.596136480908 (0.0535146321003) [J]
Best score: 0.926722136223 (0.0439202073737) [J] | Score: 0.926722136223 (0.0439202073737) [J]
Best score: 0.928001375989 (0.065183675359) [J] | Score: 0.928001375989 (0.065183675359) [J]
Best score: 0.928001375989 (0.065183675359) [J] | Score: 0.833481682147 (0.0944558628459) [J]
Best score: 0.928001375989 (0.065183675359) [J] | Score: 0.798357413141 (0.0746829636857) [J]
Best score: 0.928001375989 (0.065183675359) [J] | Score: 0.856725146199 (0.102213791187) [J]
Best score: 0.960784313725 (0.0435266638321) [J] | Score: 0.960784313725 (0.0435266638321) [J]
Best score: 0.960784313725 (0.0435266638321) [J] | Score: 0.900440746474 (0.0855436133759) [J]
Best score: 0.983625730994 (0.0250235004624) [J] | Score: 0.983625730994 (0.0250235004624) [J]
JoblibValueError
___________________________________________________________________________
...........................................................................
/home/aquemy/dev/dp_hyperparameters/extension/main.py in <module>()
     27 
     28     serializer.serialize_results(scenario, policy)
     29 
     30 if __name__ == "__main__":
     31     args = cli.parse_args()
---> 32     main(args)

...........................................................................
/home/aquemy/dev/dp_hyperparameters/extension/main.py in main(args=Namespace(customize=[(['control', 'seed'], '42')...io='./scenarios/rf_wine_joint.yaml', verbosity=0))
     21         test_size=0.4, 
     22         random_state=scenario['control']['seed']
     23     )
     24 
     25     policy = policies.initiate(scenario['setup']['policy'], config)
---> 26     policy.run(X,y)
        policy.run = <bound method Joint.run of <experiment.policies.joint.Joint object>>
        X = array([[1.423e+01, 1.710e+00, 2.430e+00, ..., 1...., ..., 6.100e-01, 1.600e+00,
        5.600e+02]])
        y = array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,
       2, 2])
     27 
     28     serializer.serialize_results(scenario, policy)
     29 
     30 if __name__ == "__main__":

...........................................................................
/home/aquemy/dev/dp_hyperparameters/extension/experiment/policies/joint.py in run(self=<experiment.policies.joint.Joint object>, X=array([[1.423e+01, 1.710e+00, 2.430e+00, ..., 1...., ..., 6.100e-01, 1.600e+00,
        5.600e+02]]), y=array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,
       2, 2]))
     32             algo=tpe.suggest, 
     33             max_evals=None,
     34             max_time=self.config['time'],     
     35             trials=trials,
     36             show_progressbar=False,
---> 37             verbose=0
     38         )
     39 
     40         best_config = self.context['best_config']
     41         super(Joint, self).display_step_results(best_config)

...........................................................................
/home/aquemy/dev/dp_hyperparameters/extension/hyperopt/fmin.py in fmin(fn=<functools.partial object>, space={'algorithm': {'bootstrap': <hyperopt.pyll.base.Apply object>, 'criterion': <hyperopt.pyll.base.Apply object>, 'max_depth': <hyperopt.pyll.base.Apply object>, 'max_features': <hyperopt.pyll.base.Apply object>, 'max_leaf_nodes': <hyperopt.pyll.base.Apply object>, 'min_samples_split': <hyperopt.pyll.base.Apply object>, 'n_estimators': <hyperopt.pyll.base.Apply object>}, 'pipeline': {'features': <hyperopt.pyll.base.Apply object>, 'normalizer': <hyperopt.pyll.base.Apply object>, 'rebalance': <hyperopt.pyll.base.Apply object>}}, algo=<function suggest>, max_evals=9223372036854775807, max_time=300, trials=<hyperopt.base.Trials object>, rstate=<mtrand.RandomState object>, allow_trials_fmin=True, pass_expr_memo_ctrl=None, catch_eval_exceptions=False, verbose=0, return_argmin=True, points_to_evaluate=None, max_queue_len=1, show_progressbar=False)
    406             pass_expr_memo_ctrl=pass_expr_memo_ctrl,
    407             verbose=verbose,
    408             catch_eval_exceptions=catch_eval_exceptions,
    409             return_argmin=return_argmin,
    410             show_progressbar=show_progressbar,
--> 411             max_time=max_time
        max_time = 300
    412         )
    413 
    414     if trials is None:
    415         if points_to_evaluate is None:

...........................................................................
/home/aquemy/dev/dp_hyperparameters/extension/hyperopt/base.py in fmin(self=<hyperopt.base.Trials object>, fn=<functools.partial object>, space={'algorithm': {'bootstrap': <hyperopt.pyll.base.Apply object>, 'criterion': <hyperopt.pyll.base.Apply object>, 'max_depth': <hyperopt.pyll.base.Apply object>, 'max_features': <hyperopt.pyll.base.Apply object>, 'max_leaf_nodes': <hyperopt.pyll.base.Apply object>, 'min_samples_split': <hyperopt.pyll.base.Apply object>, 'n_estimators': <hyperopt.pyll.base.Apply object>}, 'pipeline': {'features': <hyperopt.pyll.base.Apply object>, 'normalizer': <hyperopt.pyll.base.Apply object>, 'rebalance': <hyperopt.pyll.base.Apply object>}}, algo=<function suggest>, max_evals=9223372036854775807, max_time=300, rstate=<mtrand.RandomState object>, verbose=0, pass_expr_memo_ctrl=None, catch_eval_exceptions=False, return_argmin=True, show_progressbar=False)
    636             verbose=verbose,
    637             allow_trials_fmin=False,  # -- prevent recursion
    638             pass_expr_memo_ctrl=pass_expr_memo_ctrl,
    639             catch_eval_exceptions=catch_eval_exceptions,
    640             return_argmin=return_argmin,
--> 641             show_progressbar=show_progressbar)
        show_progressbar = False
    642 
    643 
    644 def trials_from_docs(docs, validate=True, **kwargs):
    645     """Construct a Trials base class instance from a list of trials documents

...........................................................................
/home/aquemy/dev/dp_hyperparameters/extension/hyperopt/fmin.py in fmin(fn=<functools.partial object>, space={'algorithm': {'bootstrap': <hyperopt.pyll.base.Apply object>, 'criterion': <hyperopt.pyll.base.Apply object>, 'max_depth': <hyperopt.pyll.base.Apply object>, 'max_features': <hyperopt.pyll.base.Apply object>, 'max_leaf_nodes': <hyperopt.pyll.base.Apply object>, 'min_samples_split': <hyperopt.pyll.base.Apply object>, 'n_estimators': <hyperopt.pyll.base.Apply object>}, 'pipeline': {'features': <hyperopt.pyll.base.Apply object>, 'normalizer': <hyperopt.pyll.base.Apply object>, 'rebalance': <hyperopt.pyll.base.Apply object>}}, algo=<function suggest>, max_evals=9223372036854775807, max_time=300, trials=<hyperopt.base.Trials object>, rstate=<mtrand.RandomState object>, allow_trials_fmin=False, pass_expr_memo_ctrl=None, catch_eval_exceptions=False, verbose=0, return_argmin=True, points_to_evaluate=None, max_queue_len=1, show_progressbar=False)
    426                     verbose=verbose,
    427                     max_queue_len=max_queue_len,
    428                     show_progressbar=show_progressbar,
    429                     max_time=max_time)
    430     rval.catch_eval_exceptions = catch_eval_exceptions
--> 431     rval.exhaust()
        rval.exhaust = <bound method FMinIter.exhaust of <hyperopt.fmin.FMinIter object>>
    432     if return_argmin:
    433         return trials.argmin
    434     elif len(trials) > 0:
    435         # Only if there are some succesfull trail runs, return the best point in the evaluation space

...........................................................................
/home/aquemy/dev/dp_hyperparameters/extension/hyperopt/fmin.py in exhaust(self=<hyperopt.fmin.FMinIter object>)
    273             raise StopIteration()
    274         return self.trials
    275 
    276     def exhaust(self):
    277         n_done = len(self.trials)
--> 278         self.run(self.max_evals - n_done, block_until_done=self.asynchronous)
        self.run = <bound method FMinIter.run of <hyperopt.fmin.FMinIter object>>
        self.max_evals = 9223372036854775807
        n_done = 0
        self.asynchronous = False
    279         self.trials.refresh()
    280         return self
    281 
    282 

...........................................................................
/home/aquemy/dev/dp_hyperparameters/extension/hyperopt/fmin.py in run(self=<hyperopt.fmin.FMinIter object>, N=9223372036854775807, block_until_done=False)
    232                     if self.asynchronous:
    233                         # -- wait for workers to fill in the trials
    234                         time.sleep(self.poll_interval_secs)
    235                     else:
    236                         # -- loop over trials and do the jobs directly
--> 237                         self.serial_evaluate()
        self.serial_evaluate = <bound method FMinIter.serial_evaluate of <hyperopt.fmin.FMinIter object>>
    238                     try:
    239                         res = [d['result']['loss'] for d in
    240                                          self.trials.trials if
    241                                          d['result']['status'] == 'ok']

...........................................................................
/home/aquemy/dev/dp_hyperparameters/extension/hyperopt/fmin.py in serial_evaluate(self=<hyperopt.fmin.FMinIter object>, N=-1)
    138                 trial['book_time'] = now
    139                 trial['refresh_time'] = now
    140                 spec = base.spec_from_misc(trial['misc'])
    141                 ctrl = base.Ctrl(self.trials, current_trial=trial)
    142                 try:
--> 143                     result = self.domain.evaluate(spec, ctrl)
        result = undefined
        self.domain.evaluate = <bound method Domain.evaluate of <hyperopt.base.Domain object>>
        spec = {'bootstrap': 0, 'criterion': 0, 'features': 1, 'features_PCA_features__n_components': 0, 'max_depth': 0, 'max_features': 2, 'max_leaf_nodes': 0, 'min_samples_split': 1, 'n_estimators': 0, 'normalizer': 0, ...}
        ctrl = <hyperopt.base.Ctrl object>
    144                 except Exception as e:
    145                     logger.info('job exception: %s' % str(e))
    146                     trial['state'] = base.JOB_STATE_ERROR
    147                     trial['misc']['error'] = (str(type(e)), str(e))

...........................................................................
/home/aquemy/dev/dp_hyperparameters/extension/hyperopt/base.py in evaluate(self=<hyperopt.base.Domain object>, config={'bootstrap': 0, 'criterion': 0, 'features': 1, 'features_PCA_features__n_components': 0, 'max_depth': 0, 'max_features': 2, 'max_leaf_nodes': 0, 'min_samples_split': 1, 'n_estimators': 0, 'normalizer': 0, ...}, ctrl=<hyperopt.base.Ctrl object>, attach_attachments=True)
    841             #    or the normal Python part (self.fn)
    842             pyll_rval = pyll.rec_eval(
    843                 self.expr,
    844                 memo=memo,
    845                 print_node_on_error=self.rec_eval_print_node_on_error)
--> 846             rval = self.fn(pyll_rval)
        rval = undefined
        self.fn = <functools.partial object>
        pyll_rval = {'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': 1, 'max_features': 3, 'max_leaf_nodes': 2, 'min_samples_split': 3, 'n_estimators': 10}, 'pipeline': {'features': ('features_PCA', {'features__n_components': 1}), 'normalizer': ('normalizer_NoneType', {}), 'rebalance': ('rebalance_CondensedNearestNeighbour', {'rebalance__n_neighbors': 3})}}
    847 
    848         if isinstance(rval, (float, int, np.number)):
    849             dict_rval = {'loss': float(rval), 'status': STATUS_OK}
    850         else:

...........................................................................
/home/aquemy/dev/dp_hyperparameters/extension/experiment/objective.py in objective_joint(wconfig={'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': 1, 'max_features': 3, 'max_leaf_nodes': 2, 'min_samples_split': 3, 'n_estimators': 10}, 'pipeline': {'features': ('features_PCA', {'features__n_components': 1}), 'normalizer': ('normalizer_NoneType', {}), 'rebalance': ('rebalance_CondensedNearestNeighbour', {'rebalance__n_neighbors': 3})}}, algorithm='RandomForest', X=array([[1.423e+01, 1.710e+00, 2.430e+00, ..., 1...., ..., 6.100e-01, 1.600e+00,
        5.600e+02]]), y=array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,
       2, 2]), context={'baseline_score': 0.9444100447196423, 'baseline_score_std': 0.04305547117084885, 'best_config': {'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': 2, 'max_features': 1, 'max_leaf_nodes': None, 'min_samples_split': 3, 'n_estimators': 75}, 'config_hash': {'algorithm': '42185be98371e99ac896d2c6c2d69c451cb983ff', 'config': '6609280032189b59de1afbe36f3acb1d5c273693', 'pipeline': '8aab2941fc84d84f86fa56134e50909dbf9e19f5'}, 'duration': 0.9665219783782959, 'iteration': 9, 'loss': 0.01637426900584804, 'max_history_score': 0.983625730994152, 'max_history_score_std': 0.025023500462379746, 'max_history_step': 'joint', 'pipeline': {'features': ('features_NoneType', {}), 'normalizer': ('normalizer_PowerTransformer', {}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 5})}, 'score': 0.983625730994152, ...}, 'history': [{'algorithm': {'bootstrap': False, 'criterion': 'entropy', 'max_depth': None, 'max_features': 3, 'max_leaf_nodes': 5, 'min_samples_split': 2, 'n_estimators': 50}, 'config_hash': {'algorithm': 'b2c6464add7a35ce8048653a39338c9994de9a4f', 'config': '2e6648b63441361b4398cb94f81d2e04a830b2ef', 'pipeline': '3d44d7482e468d08c4f94457a205f3dac74084c1'}, 'duration': 0.737678050994873, 'iteration': 0, 'loss': 1.0, 'max_history_score': 0.0, 'max_history_score_std': 0.0, 'max_history_step': 'baseline', 'pipeline': {'features': ('features_PCA', {'features__n_components': 1}), 'normalizer': ('normalizer_NoneType', {}), 'rebalance': ('rebalance_CondensedNearestNeighbour', {'rebalance__n_neighbors': 3})}, 'score': 0.0, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'gini', 'max_depth': 1, 'max_features': None, 'max_leaf_nodes': 2, 'min_samples_split': 3, 'n_estimators': 25}, 'config_hash': {'algorithm': '7f71bbbfdb4e8da52b6fc33a43224183117de15e', 'config': '584343bc020d2d7bc89bd0856bc7770dae1c84fc', 'pipeline': '466ffa7ace0e442beb7c311eb214b17a4c6832b3'}, 'duration': 1.5976769924163818, 'iteration': 1, 'loss': 0.40386351909184726, 'max_history_score': 0.5961364809081527, 'max_history_score_std': 0.05351463210025494, 'max_history_step': 'joint', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 3, 'features__selectkbest__k': 3}), 'normalizer': ('normalizer_StandardScaler', {'normalizer__with_mean': True, 'normalizer__with_std': True}), 'rebalance': ('rebalance_NearMiss', {'rebalance__n_neighbors': 2})}, 'score': 0.5961364809081527, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'entropy', 'max_depth': 1, 'max_features': 2, 'max_leaf_nodes': 2, 'min_samples_split': 5, 'n_estimators': 25}, 'config_hash': {'algorithm': '897745a20d929d43e760cacee0a764bd8070daa5', 'config': 'de121d053e65def047cc8947f505578d5c5eab67', 'pipeline': '63040b39b48626a8232e847e8327bdca5cd88611'}, 'duration': 0.815453052520752, 'iteration': 2, 'loss': 0.07327786377708967, 'max_history_score': 0.9267221362229103, 'max_history_score_std': 0.043920207373658794, 'max_history_step': 'joint', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 3, 'features__selectkbest__k': 2}), 'normalizer': ('normalizer_StandardScaler', {'normalizer__with_mean': True, 'normalizer__with_std': True}), 'rebalance': ('rebalance_NoneType', {})}, 'score': 0.9267221362229103, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'entropy', 'max_depth': 4, 'max_features': 3, 'max_leaf_nodes': None, 'min_samples_split': 2, 'n_estimators': 100}, 'config_hash': {'algorithm': 'dbd92c75280ec06b66ca4ad9b135cf36957031a4', 'config': 'b21c9d15a389baa5bfea4c8ddcec129259f37540', 'pipeline': '38866720d2f120c863351493b9b4e23b9a4506dc'}, 'duration': 1.2293269634246826, 'iteration': 3, 'loss': 0.07199862401100798, 'max_history_score': 0.928001375988992, 'max_history_score_std': 0.06518367535896959, 'max_history_step': 'joint', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 2, 'features__selectkbest__k': 4}), 'normalizer': ('normalizer_NoneType', {}), 'rebalance': ('rebalance_NoneType', {})}, 'score': 0.928001375988992, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': 2, 'max_features': None, 'max_leaf_nodes': None, 'min_samples_split': 5, 'n_estimators': 100}, 'config_hash': {'algorithm': 'f455eefd9fdd03ece88892c3f440c580bdf27ddb', 'config': 'edd3456355d80775739c31515c832ca7b4e5e094', 'pipeline': '1d1034f9f0871e43f896c1db4ed6fd572ed0a6ef'}, 'duration': 1.6186630725860596, 'iteration': 4, 'loss': 0.16651831785345705, 'max_history_score': 0.928001375988992, 'max_history_score_std': 0.06518367535896959, 'max_history_step': 'joint', 'pipeline': {'features': ('features_SelectKBest', {'features__k': 4}), 'normalizer': ('normalizer_MinMaxScaler', {}), 'rebalance': ('rebalance_CondensedNearestNeighbour', {'rebalance__n_neighbors': 1})}, 'score': 0.833481682146543, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'entropy', 'max_depth': 1, 'max_features': 2, 'max_leaf_nodes': None, 'min_samples_split': 2, 'n_estimators': 10}, 'config_hash': {'algorithm': '29906eaa0712a68ea145b12821d54ba445726fbf', 'config': '0800d7d2c8c10d2f9e7b4e5127b343e916eb742c', 'pipeline': '2e0f188ae61600352a7159285e0f542b4587a403'}, 'duration': 0.19410085678100586, 'iteration': 5, 'loss': 0.20164258685930514, 'max_history_score': 0.928001375988992, 'max_history_score_std': 0.06518367535896959, 'max_history_step': 'joint', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 3, 'features__selectkbest__k': 4}), 'normalizer': ('normalizer_StandardScaler', {'normalizer__with_mean': True, 'normalizer__with_std': False}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 7})}, 'score': 0.7983574131406949, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': 1, 'max_features': 1, 'max_leaf_nodes': 5, 'min_samples_split': 2, 'n_estimators': 25}, 'config_hash': {'algorithm': 'fbb7d57e38cfc08240f0af985282da418cb33556', 'config': 'd98b641879b4754f2169335626a90575e945fd7c', 'pipeline': '62463de065924498cdcd2f2f1f7e68535cdb33a5'}, 'duration': 0.3625810146331787, 'iteration': 6, 'loss': 0.14327485380116955, 'max_history_score': 0.928001375988992, 'max_history_score_std': 0.06518367535896959, 'max_history_step': 'joint', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 1, 'features__selectkbest__k': 2}), 'normalizer': ('normalizer_NoneType', {}), 'rebalance': ('rebalance_NoneType', {})}, 'score': 0.8567251461988304, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'entropy', 'max_depth': 3, 'max_features': 1, 'max_leaf_nodes': None, 'min_samples_split': 2, 'n_estimators': 75}, 'config_hash': {'algorithm': 'fb2f5d4c4d636edac929e1454ce3d02a4fb134c1', 'config': '3f83df36a6abbdf7ea4a4bdcaf6727f23529c2bb', 'pipeline': '8377b93e334656d1a93d266493b58ef9a6a1786f'}, 'duration': 0.8223779201507568, 'iteration': 7, 'loss': 0.03921568627450989, 'max_history_score': 0.9607843137254901, 'max_history_score_std': 0.043526663832084804, 'max_history_step': 'joint', 'pipeline': {'features': ('features_PCA', {'features__n_components': 3}), 'normalizer': ('normalizer_MinMaxScaler', {}), 'rebalance': ('rebalance_NearMiss', {'rebalance__n_neighbors': 1})}, 'score': 0.9607843137254901, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'gini', 'max_depth': 3, 'max_features': 3, 'max_leaf_nodes': 2, 'min_samples_split': 2, 'n_estimators': 100}, 'config_hash': {'algorithm': '3c3fde6559b918694de4668d025d5418342db1b1', 'config': '037fd5c655b39cc7922fb394d736496befcc747b', 'pipeline': '2a5032814c6c7ed21dd5bd9686923d7fc2f8acc9'}, 'duration': 1.0435099601745605, 'iteration': 8, 'loss': 0.09955925352597172, 'max_history_score': 0.9607843137254901, 'max_history_score_std': 0.043526663832084804, 'max_history_step': 'joint', 'pipeline': {'features': ('features_NoneType', {}), 'normalizer': ('normalizer_RobustScaler', {'normalizer__quantile_range': (...), 'normalizer__with_centering': True, 'normalizer__with_scaling': True}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 7})}, 'score': 0.9004407464740283, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': 2, 'max_features': 1, 'max_leaf_nodes': None, 'min_samples_split': 3, 'n_estimators': 75}, 'config_hash': {'algorithm': '42185be98371e99ac896d2c6c2d69c451cb983ff', 'config': '6609280032189b59de1afbe36f3acb1d5c273693', 'pipeline': '8aab2941fc84d84f86fa56134e50909dbf9e19f5'}, 'duration': 0.9665219783782959, 'iteration': 9, 'loss': 0.01637426900584804, 'max_history_score': 0.983625730994152, 'max_history_score_std': 0.025023500462379746, 'max_history_step': 'joint', 'pipeline': {'features': ('features_NoneType', {}), 'normalizer': ('normalizer_PowerTransformer', {}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 5})}, 'score': 0.983625730994152, ...}], 'history_hash': ['2e6648b63441361b4398cb94f81d2e04a830b2ef', '584343bc020d2d7bc89bd0856bc7770dae1c84fc', 'de121d053e65def047cc8947f505578d5c5eab67', 'b21c9d15a389baa5bfea4c8ddcec129259f37540', 'edd3456355d80775739c31515c832ca7b4e5e094', '0800d7d2c8c10d2f9e7b4e5127b343e916eb742c', 'd98b641879b4754f2169335626a90575e945fd7c', '3f83df36a6abbdf7ea4a4bdcaf6727f23529c2bb', '037fd5c655b39cc7922fb394d736496befcc747b', '6609280032189b59de1afbe36f3acb1d5c273693'], 'history_index': {'037fd5c655b39cc7922fb394d736496befcc747b': 8, '0800d7d2c8c10d2f9e7b4e5127b343e916eb742c': 5, '2e6648b63441361b4398cb94f81d2e04a830b2ef': 0, '3f83df36a6abbdf7ea4a4bdcaf6727f23529c2bb': 7, '584343bc020d2d7bc89bd0856bc7770dae1c84fc': 1, '6609280032189b59de1afbe36f3acb1d5c273693': 9, 'b21c9d15a389baa5bfea4c8ddcec129259f37540': 3, 'd98b641879b4754f2169335626a90575e945fd7c': 6, 'de121d053e65def047cc8947f505578d5c5eab67': 2, 'edd3456355d80775739c31515c832ca7b4e5e094': 4}, 'iteration': 9, 'max_history_score': 0.983625730994152, 'max_history_score_std': 0.025023500462379746, 'max_history_step': 'joint'}, config={'algorithm': 'RandomForest', 'seed': 42, 'time': 300})
    108 
    109 def objective_algo(algo_config, current_pipeline_config, algorithm, X, y, context, config):
    110     return objective(current_pipeline_config, algo_config, algorithm, X, y, context, config, step='algorithm')
    111 
    112 def objective_joint(wconfig, algorithm, X, y, context, config):
--> 113     return objective(wconfig['pipeline'], wconfig['algorithm'], algorithm, X, y, context, config, step='joint')
        wconfig = {'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': 1, 'max_features': 3, 'max_leaf_nodes': 2, 'min_samples_split': 3, 'n_estimators': 10}, 'pipeline': {'features': ('features_PCA', {'features__n_components': 1}), 'normalizer': ('normalizer_NoneType', {}), 'rebalance': ('rebalance_CondensedNearestNeighbour', {'rebalance__n_neighbors': 3})}}
        algorithm = 'RandomForest'
        X = array([[1.423e+01, 1.710e+00, 2.430e+00, ..., 1...., ..., 6.100e-01, 1.600e+00,
        5.600e+02]])
        y = array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,
       2, 2])
        context = {'baseline_score': 0.9444100447196423, 'baseline_score_std': 0.04305547117084885, 'best_config': {'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': 2, 'max_features': 1, 'max_leaf_nodes': None, 'min_samples_split': 3, 'n_estimators': 75}, 'config_hash': {'algorithm': '42185be98371e99ac896d2c6c2d69c451cb983ff', 'config': '6609280032189b59de1afbe36f3acb1d5c273693', 'pipeline': '8aab2941fc84d84f86fa56134e50909dbf9e19f5'}, 'duration': 0.9665219783782959, 'iteration': 9, 'loss': 0.01637426900584804, 'max_history_score': 0.983625730994152, 'max_history_score_std': 0.025023500462379746, 'max_history_step': 'joint', 'pipeline': {'features': ('features_NoneType', {}), 'normalizer': ('normalizer_PowerTransformer', {}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 5})}, 'score': 0.983625730994152, ...}, 'history': [{'algorithm': {'bootstrap': False, 'criterion': 'entropy', 'max_depth': None, 'max_features': 3, 'max_leaf_nodes': 5, 'min_samples_split': 2, 'n_estimators': 50}, 'config_hash': {'algorithm': 'b2c6464add7a35ce8048653a39338c9994de9a4f', 'config': '2e6648b63441361b4398cb94f81d2e04a830b2ef', 'pipeline': '3d44d7482e468d08c4f94457a205f3dac74084c1'}, 'duration': 0.737678050994873, 'iteration': 0, 'loss': 1.0, 'max_history_score': 0.0, 'max_history_score_std': 0.0, 'max_history_step': 'baseline', 'pipeline': {'features': ('features_PCA', {'features__n_components': 1}), 'normalizer': ('normalizer_NoneType', {}), 'rebalance': ('rebalance_CondensedNearestNeighbour', {'rebalance__n_neighbors': 3})}, 'score': 0.0, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'gini', 'max_depth': 1, 'max_features': None, 'max_leaf_nodes': 2, 'min_samples_split': 3, 'n_estimators': 25}, 'config_hash': {'algorithm': '7f71bbbfdb4e8da52b6fc33a43224183117de15e', 'config': '584343bc020d2d7bc89bd0856bc7770dae1c84fc', 'pipeline': '466ffa7ace0e442beb7c311eb214b17a4c6832b3'}, 'duration': 1.5976769924163818, 'iteration': 1, 'loss': 0.40386351909184726, 'max_history_score': 0.5961364809081527, 'max_history_score_std': 0.05351463210025494, 'max_history_step': 'joint', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 3, 'features__selectkbest__k': 3}), 'normalizer': ('normalizer_StandardScaler', {'normalizer__with_mean': True, 'normalizer__with_std': True}), 'rebalance': ('rebalance_NearMiss', {'rebalance__n_neighbors': 2})}, 'score': 0.5961364809081527, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'entropy', 'max_depth': 1, 'max_features': 2, 'max_leaf_nodes': 2, 'min_samples_split': 5, 'n_estimators': 25}, 'config_hash': {'algorithm': '897745a20d929d43e760cacee0a764bd8070daa5', 'config': 'de121d053e65def047cc8947f505578d5c5eab67', 'pipeline': '63040b39b48626a8232e847e8327bdca5cd88611'}, 'duration': 0.815453052520752, 'iteration': 2, 'loss': 0.07327786377708967, 'max_history_score': 0.9267221362229103, 'max_history_score_std': 0.043920207373658794, 'max_history_step': 'joint', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 3, 'features__selectkbest__k': 2}), 'normalizer': ('normalizer_StandardScaler', {'normalizer__with_mean': True, 'normalizer__with_std': True}), 'rebalance': ('rebalance_NoneType', {})}, 'score': 0.9267221362229103, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'entropy', 'max_depth': 4, 'max_features': 3, 'max_leaf_nodes': None, 'min_samples_split': 2, 'n_estimators': 100}, 'config_hash': {'algorithm': 'dbd92c75280ec06b66ca4ad9b135cf36957031a4', 'config': 'b21c9d15a389baa5bfea4c8ddcec129259f37540', 'pipeline': '38866720d2f120c863351493b9b4e23b9a4506dc'}, 'duration': 1.2293269634246826, 'iteration': 3, 'loss': 0.07199862401100798, 'max_history_score': 0.928001375988992, 'max_history_score_std': 0.06518367535896959, 'max_history_step': 'joint', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 2, 'features__selectkbest__k': 4}), 'normalizer': ('normalizer_NoneType', {}), 'rebalance': ('rebalance_NoneType', {})}, 'score': 0.928001375988992, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': 2, 'max_features': None, 'max_leaf_nodes': None, 'min_samples_split': 5, 'n_estimators': 100}, 'config_hash': {'algorithm': 'f455eefd9fdd03ece88892c3f440c580bdf27ddb', 'config': 'edd3456355d80775739c31515c832ca7b4e5e094', 'pipeline': '1d1034f9f0871e43f896c1db4ed6fd572ed0a6ef'}, 'duration': 1.6186630725860596, 'iteration': 4, 'loss': 0.16651831785345705, 'max_history_score': 0.928001375988992, 'max_history_score_std': 0.06518367535896959, 'max_history_step': 'joint', 'pipeline': {'features': ('features_SelectKBest', {'features__k': 4}), 'normalizer': ('normalizer_MinMaxScaler', {}), 'rebalance': ('rebalance_CondensedNearestNeighbour', {'rebalance__n_neighbors': 1})}, 'score': 0.833481682146543, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'entropy', 'max_depth': 1, 'max_features': 2, 'max_leaf_nodes': None, 'min_samples_split': 2, 'n_estimators': 10}, 'config_hash': {'algorithm': '29906eaa0712a68ea145b12821d54ba445726fbf', 'config': '0800d7d2c8c10d2f9e7b4e5127b343e916eb742c', 'pipeline': '2e0f188ae61600352a7159285e0f542b4587a403'}, 'duration': 0.19410085678100586, 'iteration': 5, 'loss': 0.20164258685930514, 'max_history_score': 0.928001375988992, 'max_history_score_std': 0.06518367535896959, 'max_history_step': 'joint', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 3, 'features__selectkbest__k': 4}), 'normalizer': ('normalizer_StandardScaler', {'normalizer__with_mean': True, 'normalizer__with_std': False}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 7})}, 'score': 0.7983574131406949, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': 1, 'max_features': 1, 'max_leaf_nodes': 5, 'min_samples_split': 2, 'n_estimators': 25}, 'config_hash': {'algorithm': 'fbb7d57e38cfc08240f0af985282da418cb33556', 'config': 'd98b641879b4754f2169335626a90575e945fd7c', 'pipeline': '62463de065924498cdcd2f2f1f7e68535cdb33a5'}, 'duration': 0.3625810146331787, 'iteration': 6, 'loss': 0.14327485380116955, 'max_history_score': 0.928001375988992, 'max_history_score_std': 0.06518367535896959, 'max_history_step': 'joint', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 1, 'features__selectkbest__k': 2}), 'normalizer': ('normalizer_NoneType', {}), 'rebalance': ('rebalance_NoneType', {})}, 'score': 0.8567251461988304, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'entropy', 'max_depth': 3, 'max_features': 1, 'max_leaf_nodes': None, 'min_samples_split': 2, 'n_estimators': 75}, 'config_hash': {'algorithm': 'fb2f5d4c4d636edac929e1454ce3d02a4fb134c1', 'config': '3f83df36a6abbdf7ea4a4bdcaf6727f23529c2bb', 'pipeline': '8377b93e334656d1a93d266493b58ef9a6a1786f'}, 'duration': 0.8223779201507568, 'iteration': 7, 'loss': 0.03921568627450989, 'max_history_score': 0.9607843137254901, 'max_history_score_std': 0.043526663832084804, 'max_history_step': 'joint', 'pipeline': {'features': ('features_PCA', {'features__n_components': 3}), 'normalizer': ('normalizer_MinMaxScaler', {}), 'rebalance': ('rebalance_NearMiss', {'rebalance__n_neighbors': 1})}, 'score': 0.9607843137254901, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'gini', 'max_depth': 3, 'max_features': 3, 'max_leaf_nodes': 2, 'min_samples_split': 2, 'n_estimators': 100}, 'config_hash': {'algorithm': '3c3fde6559b918694de4668d025d5418342db1b1', 'config': '037fd5c655b39cc7922fb394d736496befcc747b', 'pipeline': '2a5032814c6c7ed21dd5bd9686923d7fc2f8acc9'}, 'duration': 1.0435099601745605, 'iteration': 8, 'loss': 0.09955925352597172, 'max_history_score': 0.9607843137254901, 'max_history_score_std': 0.043526663832084804, 'max_history_step': 'joint', 'pipeline': {'features': ('features_NoneType', {}), 'normalizer': ('normalizer_RobustScaler', {'normalizer__quantile_range': (...), 'normalizer__with_centering': True, 'normalizer__with_scaling': True}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 7})}, 'score': 0.9004407464740283, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': 2, 'max_features': 1, 'max_leaf_nodes': None, 'min_samples_split': 3, 'n_estimators': 75}, 'config_hash': {'algorithm': '42185be98371e99ac896d2c6c2d69c451cb983ff', 'config': '6609280032189b59de1afbe36f3acb1d5c273693', 'pipeline': '8aab2941fc84d84f86fa56134e50909dbf9e19f5'}, 'duration': 0.9665219783782959, 'iteration': 9, 'loss': 0.01637426900584804, 'max_history_score': 0.983625730994152, 'max_history_score_std': 0.025023500462379746, 'max_history_step': 'joint', 'pipeline': {'features': ('features_NoneType', {}), 'normalizer': ('normalizer_PowerTransformer', {}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 5})}, 'score': 0.983625730994152, ...}], 'history_hash': ['2e6648b63441361b4398cb94f81d2e04a830b2ef', '584343bc020d2d7bc89bd0856bc7770dae1c84fc', 'de121d053e65def047cc8947f505578d5c5eab67', 'b21c9d15a389baa5bfea4c8ddcec129259f37540', 'edd3456355d80775739c31515c832ca7b4e5e094', '0800d7d2c8c10d2f9e7b4e5127b343e916eb742c', 'd98b641879b4754f2169335626a90575e945fd7c', '3f83df36a6abbdf7ea4a4bdcaf6727f23529c2bb', '037fd5c655b39cc7922fb394d736496befcc747b', '6609280032189b59de1afbe36f3acb1d5c273693'], 'history_index': {'037fd5c655b39cc7922fb394d736496befcc747b': 8, '0800d7d2c8c10d2f9e7b4e5127b343e916eb742c': 5, '2e6648b63441361b4398cb94f81d2e04a830b2ef': 0, '3f83df36a6abbdf7ea4a4bdcaf6727f23529c2bb': 7, '584343bc020d2d7bc89bd0856bc7770dae1c84fc': 1, '6609280032189b59de1afbe36f3acb1d5c273693': 9, 'b21c9d15a389baa5bfea4c8ddcec129259f37540': 3, 'd98b641879b4754f2169335626a90575e945fd7c': 6, 'de121d053e65def047cc8947f505578d5c5eab67': 2, 'edd3456355d80775739c31515c832ca7b4e5e094': 4}, 'iteration': 9, 'max_history_score': 0.983625730994152, 'max_history_score_std': 0.025023500462379746, 'max_history_step': 'joint'}
        config = {'algorithm': 'RandomForest', 'seed': 42, 'time': 300}
    114 
    115 
    116 def get_baseline_score(algorithm, X, y, seed):
    117     pipeline, _ = pipeline_conf_to_full_pipeline(

...........................................................................
/home/aquemy/dev/dp_hyperparameters/extension/experiment/objective.py in objective(pipeline_config={'features': ('features_PCA', {'features__n_components': 1}), 'normalizer': ('normalizer_NoneType', {}), 'rebalance': ('rebalance_CondensedNearestNeighbour', {'rebalance__n_neighbors': 3})}, algo_config={'bootstrap': True, 'criterion': 'gini', 'max_depth': 1, 'max_features': 3, 'max_leaf_nodes': 2, 'min_samples_split': 3, 'n_estimators': 10}, algorithm='RandomForest', X=array([[1.423e+01, 1.710e+00, 2.430e+00, ..., 1...., ..., 6.100e-01, 1.600e+00,
        5.600e+02]]), y=array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,
       2, 2]), context={'baseline_score': 0.9444100447196423, 'baseline_score_std': 0.04305547117084885, 'best_config': {'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': 2, 'max_features': 1, 'max_leaf_nodes': None, 'min_samples_split': 3, 'n_estimators': 75}, 'config_hash': {'algorithm': '42185be98371e99ac896d2c6c2d69c451cb983ff', 'config': '6609280032189b59de1afbe36f3acb1d5c273693', 'pipeline': '8aab2941fc84d84f86fa56134e50909dbf9e19f5'}, 'duration': 0.9665219783782959, 'iteration': 9, 'loss': 0.01637426900584804, 'max_history_score': 0.983625730994152, 'max_history_score_std': 0.025023500462379746, 'max_history_step': 'joint', 'pipeline': {'features': ('features_NoneType', {}), 'normalizer': ('normalizer_PowerTransformer', {}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 5})}, 'score': 0.983625730994152, ...}, 'history': [{'algorithm': {'bootstrap': False, 'criterion': 'entropy', 'max_depth': None, 'max_features': 3, 'max_leaf_nodes': 5, 'min_samples_split': 2, 'n_estimators': 50}, 'config_hash': {'algorithm': 'b2c6464add7a35ce8048653a39338c9994de9a4f', 'config': '2e6648b63441361b4398cb94f81d2e04a830b2ef', 'pipeline': '3d44d7482e468d08c4f94457a205f3dac74084c1'}, 'duration': 0.737678050994873, 'iteration': 0, 'loss': 1.0, 'max_history_score': 0.0, 'max_history_score_std': 0.0, 'max_history_step': 'baseline', 'pipeline': {'features': ('features_PCA', {'features__n_components': 1}), 'normalizer': ('normalizer_NoneType', {}), 'rebalance': ('rebalance_CondensedNearestNeighbour', {'rebalance__n_neighbors': 3})}, 'score': 0.0, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'gini', 'max_depth': 1, 'max_features': None, 'max_leaf_nodes': 2, 'min_samples_split': 3, 'n_estimators': 25}, 'config_hash': {'algorithm': '7f71bbbfdb4e8da52b6fc33a43224183117de15e', 'config': '584343bc020d2d7bc89bd0856bc7770dae1c84fc', 'pipeline': '466ffa7ace0e442beb7c311eb214b17a4c6832b3'}, 'duration': 1.5976769924163818, 'iteration': 1, 'loss': 0.40386351909184726, 'max_history_score': 0.5961364809081527, 'max_history_score_std': 0.05351463210025494, 'max_history_step': 'joint', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 3, 'features__selectkbest__k': 3}), 'normalizer': ('normalizer_StandardScaler', {'normalizer__with_mean': True, 'normalizer__with_std': True}), 'rebalance': ('rebalance_NearMiss', {'rebalance__n_neighbors': 2})}, 'score': 0.5961364809081527, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'entropy', 'max_depth': 1, 'max_features': 2, 'max_leaf_nodes': 2, 'min_samples_split': 5, 'n_estimators': 25}, 'config_hash': {'algorithm': '897745a20d929d43e760cacee0a764bd8070daa5', 'config': 'de121d053e65def047cc8947f505578d5c5eab67', 'pipeline': '63040b39b48626a8232e847e8327bdca5cd88611'}, 'duration': 0.815453052520752, 'iteration': 2, 'loss': 0.07327786377708967, 'max_history_score': 0.9267221362229103, 'max_history_score_std': 0.043920207373658794, 'max_history_step': 'joint', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 3, 'features__selectkbest__k': 2}), 'normalizer': ('normalizer_StandardScaler', {'normalizer__with_mean': True, 'normalizer__with_std': True}), 'rebalance': ('rebalance_NoneType', {})}, 'score': 0.9267221362229103, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'entropy', 'max_depth': 4, 'max_features': 3, 'max_leaf_nodes': None, 'min_samples_split': 2, 'n_estimators': 100}, 'config_hash': {'algorithm': 'dbd92c75280ec06b66ca4ad9b135cf36957031a4', 'config': 'b21c9d15a389baa5bfea4c8ddcec129259f37540', 'pipeline': '38866720d2f120c863351493b9b4e23b9a4506dc'}, 'duration': 1.2293269634246826, 'iteration': 3, 'loss': 0.07199862401100798, 'max_history_score': 0.928001375988992, 'max_history_score_std': 0.06518367535896959, 'max_history_step': 'joint', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 2, 'features__selectkbest__k': 4}), 'normalizer': ('normalizer_NoneType', {}), 'rebalance': ('rebalance_NoneType', {})}, 'score': 0.928001375988992, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': 2, 'max_features': None, 'max_leaf_nodes': None, 'min_samples_split': 5, 'n_estimators': 100}, 'config_hash': {'algorithm': 'f455eefd9fdd03ece88892c3f440c580bdf27ddb', 'config': 'edd3456355d80775739c31515c832ca7b4e5e094', 'pipeline': '1d1034f9f0871e43f896c1db4ed6fd572ed0a6ef'}, 'duration': 1.6186630725860596, 'iteration': 4, 'loss': 0.16651831785345705, 'max_history_score': 0.928001375988992, 'max_history_score_std': 0.06518367535896959, 'max_history_step': 'joint', 'pipeline': {'features': ('features_SelectKBest', {'features__k': 4}), 'normalizer': ('normalizer_MinMaxScaler', {}), 'rebalance': ('rebalance_CondensedNearestNeighbour', {'rebalance__n_neighbors': 1})}, 'score': 0.833481682146543, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'entropy', 'max_depth': 1, 'max_features': 2, 'max_leaf_nodes': None, 'min_samples_split': 2, 'n_estimators': 10}, 'config_hash': {'algorithm': '29906eaa0712a68ea145b12821d54ba445726fbf', 'config': '0800d7d2c8c10d2f9e7b4e5127b343e916eb742c', 'pipeline': '2e0f188ae61600352a7159285e0f542b4587a403'}, 'duration': 0.19410085678100586, 'iteration': 5, 'loss': 0.20164258685930514, 'max_history_score': 0.928001375988992, 'max_history_score_std': 0.06518367535896959, 'max_history_step': 'joint', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 3, 'features__selectkbest__k': 4}), 'normalizer': ('normalizer_StandardScaler', {'normalizer__with_mean': True, 'normalizer__with_std': False}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 7})}, 'score': 0.7983574131406949, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': 1, 'max_features': 1, 'max_leaf_nodes': 5, 'min_samples_split': 2, 'n_estimators': 25}, 'config_hash': {'algorithm': 'fbb7d57e38cfc08240f0af985282da418cb33556', 'config': 'd98b641879b4754f2169335626a90575e945fd7c', 'pipeline': '62463de065924498cdcd2f2f1f7e68535cdb33a5'}, 'duration': 0.3625810146331787, 'iteration': 6, 'loss': 0.14327485380116955, 'max_history_score': 0.928001375988992, 'max_history_score_std': 0.06518367535896959, 'max_history_step': 'joint', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 1, 'features__selectkbest__k': 2}), 'normalizer': ('normalizer_NoneType', {}), 'rebalance': ('rebalance_NoneType', {})}, 'score': 0.8567251461988304, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'entropy', 'max_depth': 3, 'max_features': 1, 'max_leaf_nodes': None, 'min_samples_split': 2, 'n_estimators': 75}, 'config_hash': {'algorithm': 'fb2f5d4c4d636edac929e1454ce3d02a4fb134c1', 'config': '3f83df36a6abbdf7ea4a4bdcaf6727f23529c2bb', 'pipeline': '8377b93e334656d1a93d266493b58ef9a6a1786f'}, 'duration': 0.8223779201507568, 'iteration': 7, 'loss': 0.03921568627450989, 'max_history_score': 0.9607843137254901, 'max_history_score_std': 0.043526663832084804, 'max_history_step': 'joint', 'pipeline': {'features': ('features_PCA', {'features__n_components': 3}), 'normalizer': ('normalizer_MinMaxScaler', {}), 'rebalance': ('rebalance_NearMiss', {'rebalance__n_neighbors': 1})}, 'score': 0.9607843137254901, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'gini', 'max_depth': 3, 'max_features': 3, 'max_leaf_nodes': 2, 'min_samples_split': 2, 'n_estimators': 100}, 'config_hash': {'algorithm': '3c3fde6559b918694de4668d025d5418342db1b1', 'config': '037fd5c655b39cc7922fb394d736496befcc747b', 'pipeline': '2a5032814c6c7ed21dd5bd9686923d7fc2f8acc9'}, 'duration': 1.0435099601745605, 'iteration': 8, 'loss': 0.09955925352597172, 'max_history_score': 0.9607843137254901, 'max_history_score_std': 0.043526663832084804, 'max_history_step': 'joint', 'pipeline': {'features': ('features_NoneType', {}), 'normalizer': ('normalizer_RobustScaler', {'normalizer__quantile_range': (...), 'normalizer__with_centering': True, 'normalizer__with_scaling': True}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 7})}, 'score': 0.9004407464740283, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': 2, 'max_features': 1, 'max_leaf_nodes': None, 'min_samples_split': 3, 'n_estimators': 75}, 'config_hash': {'algorithm': '42185be98371e99ac896d2c6c2d69c451cb983ff', 'config': '6609280032189b59de1afbe36f3acb1d5c273693', 'pipeline': '8aab2941fc84d84f86fa56134e50909dbf9e19f5'}, 'duration': 0.9665219783782959, 'iteration': 9, 'loss': 0.01637426900584804, 'max_history_score': 0.983625730994152, 'max_history_score_std': 0.025023500462379746, 'max_history_step': 'joint', 'pipeline': {'features': ('features_NoneType', {}), 'normalizer': ('normalizer_PowerTransformer', {}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 5})}, 'score': 0.983625730994152, ...}], 'history_hash': ['2e6648b63441361b4398cb94f81d2e04a830b2ef', '584343bc020d2d7bc89bd0856bc7770dae1c84fc', 'de121d053e65def047cc8947f505578d5c5eab67', 'b21c9d15a389baa5bfea4c8ddcec129259f37540', 'edd3456355d80775739c31515c832ca7b4e5e094', '0800d7d2c8c10d2f9e7b4e5127b343e916eb742c', 'd98b641879b4754f2169335626a90575e945fd7c', '3f83df36a6abbdf7ea4a4bdcaf6727f23529c2bb', '037fd5c655b39cc7922fb394d736496befcc747b', '6609280032189b59de1afbe36f3acb1d5c273693'], 'history_index': {'037fd5c655b39cc7922fb394d736496befcc747b': 8, '0800d7d2c8c10d2f9e7b4e5127b343e916eb742c': 5, '2e6648b63441361b4398cb94f81d2e04a830b2ef': 0, '3f83df36a6abbdf7ea4a4bdcaf6727f23529c2bb': 7, '584343bc020d2d7bc89bd0856bc7770dae1c84fc': 1, '6609280032189b59de1afbe36f3acb1d5c273693': 9, 'b21c9d15a389baa5bfea4c8ddcec129259f37540': 3, 'd98b641879b4754f2169335626a90575e945fd7c': 6, 'de121d053e65def047cc8947f505578d5c5eab67': 2, 'edd3456355d80775739c31515c832ca7b4e5e094': 4}, 'iteration': 9, 'max_history_score': 0.983625730994152, 'max_history_score_std': 0.025023500462379746, 'max_history_step': 'joint'}, config={'algorithm': 'RandomForest', 'seed': 42, 'time': 300}, step='joint')
     45                 y,
     46                 cv=10,
     47                 n_jobs=-1,
     48                 return_estimator=False,
     49                 return_train_score=False,
---> 50                 verbose=0)
     51         score = np.mean(scores['test_score'])
     52         std = np.std(scores['test_score'])
     53         status = STATUS_OK
     54     except Exception as e:

...........................................................................
/home/aquemy/.local/lib/python2.7/site-packages/sklearn/model_selection/_validation.py in cross_validate(estimator=Pipeline(memory=None,
     steps=[('rebalance', ... random_state=42, verbose=0, warm_start=False))]), X=array([[1.423e+01, 1.710e+00, 2.430e+00, ..., 1...., ..., 6.100e-01, 1.600e+00,
        5.600e+02]]), y=array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,
       2, 2]), groups=None, scoring=None, cv=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1, verbose=0, fit_params=None, pre_dispatch='2*n_jobs', return_train_score=False, return_estimator=False, error_score='raise-deprecating')
    235         delayed(_fit_and_score)(
    236             clone(estimator), X, y, scorers, train, test, verbose, None,
    237             fit_params, return_train_score=return_train_score,
    238             return_times=True, return_estimator=return_estimator,
    239             error_score=error_score)
--> 240         for train, test in cv.split(X, y, groups))
        cv.split = <bound method StratifiedKFold.split of Stratifie...d(n_splits=10, random_state=None, shuffle=False)>
        X = array([[1.423e+01, 1.710e+00, 2.430e+00, ..., 1...., ..., 6.100e-01, 1.600e+00,
        5.600e+02]])
        y = array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,
       2, 2])
        groups = None
    241 
    242     zipped_scores = list(zip(*scores))
    243     if return_train_score:
    244         train_scores = zipped_scores.pop(0)

...........................................................................
/home/aquemy/.local/lib/python2.7/site-packages/sklearn/externals/joblib/parallel.py in __call__(self=Parallel(n_jobs=-1), iterable=<generator object <genexpr>>)
    925                 # No need to wait for async callbacks to trigger to
    926                 # consumption.
    927                 self._iterating = False
    928 
    929             with self._backend.retrieval_context():
--> 930                 self.retrieve()
        self.retrieve = <bound method Parallel.retrieve of Parallel(n_jobs=-1)>
    931             # Make sure that we get a last message telling us we are done
    932             elapsed_time = time.time() - self._start_time
    933             self._print('Done %3i out of %3i | elapsed: %s finished',
    934                         (len(self._output), len(self._output),

---------------------------------------------------------------------------
Joblib worker traceback:
---------------------------------------------------------------------------
ValueError                                         Mon Jun 17 12:45:22 2019
PID: 15070                                  Python 2.7.15+: /usr/bin/python
...........................................................................
/home/aquemy/.local/lib/python2.7/site-packages/sklearn/externals/joblib/parallel.py in __call__(self=<sklearn.externals.joblib.parallel.BatchedCalls object>)
    220     def __call__(self):
    221         # Set the default nested backend to self._backend but do not set the
    222         # change the default number of processes to -1
    223         with parallel_backend(self._backend, n_jobs=self._n_jobs):
    224             return [func(*args, **kwargs)
--> 225                     for func, args, kwargs in self.items]
        func = <function _fit_and_score>
        args = (Pipeline(memory=None,
     steps=[('rebalance', ... random_state=42, verbose=0, warm_start=False))]), array([[1.423e+01, 1.710e+00, 2.430e+00, ..., 1...., ..., 6.100e-01, 1.600e+00,
        5.600e+02]]), array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,
       2, 2]), {'score': <function _passthrough_scorer>}, array([  6,   7,   8,   9,  10,  11,  12,  13,  ..., 170, 171, 172, 173, 174,
       175, 176, 177]), array([  0,   1,   2,   3,   4,   5,  59,  60,  ...,  64,  65,
        66, 130, 131, 132, 133, 134]), 0, None, None)
        kwargs = {'error_score': 'raise-deprecating', 'return_estimator': False, 'return_times': True, 'return_train_score': False}
        self.items = [(<function _fit_and_score>, (Pipeline(memory=None,
     steps=[('rebalance', ... random_state=42, verbose=0, warm_start=False))]), array([[1.423e+01, 1.710e+00, 2.430e+00, ..., 1...., ..., 6.100e-01, 1.600e+00,
        5.600e+02]]), array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,
       2, 2]), {'score': <function _passthrough_scorer>}, array([  6,   7,   8,   9,  10,  11,  12,  13,  ..., 170, 171, 172, 173, 174,
       175, 176, 177]), array([  0,   1,   2,   3,   4,   5,  59,  60,  ...,  64,  65,
        66, 130, 131, 132, 133, 134]), 0, None, None), {'error_score': 'raise-deprecating', 'return_estimator': False, 'return_times': True, 'return_train_score': False})]
    226 
    227     def __len__(self):
    228         return self._size
    229 

...........................................................................
/home/aquemy/.local/lib/python2.7/site-packages/sklearn/model_selection/_validation.py in _fit_and_score(estimator=Pipeline(memory=None,
     steps=[('rebalance', ... random_state=42, verbose=0, warm_start=False))]), X=array([[1.423e+01, 1.710e+00, 2.430e+00, ..., 1...., ..., 6.100e-01, 1.600e+00,
        5.600e+02]]), y=array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,
       2, 2]), scorer={'score': <function _passthrough_scorer>}, train=array([  6,   7,   8,   9,  10,  11,  12,  13,  ..., 170, 171, 172, 173, 174,
       175, 176, 177]), test=array([  0,   1,   2,   3,   4,   5,  59,  60,  ...,  64,  65,
        66, 130, 131, 132, 133, 134]), verbose=0, parameters=None, fit_params={}, return_train_score=False, return_parameters=False, return_n_test_samples=False, return_times=True, return_estimator=False, error_score='raise-deprecating')
    523 
    524     try:
    525         if y_train is None:
    526             estimator.fit(X_train, **fit_params)
    527         else:
--> 528             estimator.fit(X_train, y_train, **fit_params)
        estimator.fit = <bound method Pipeline.fit of Pipeline(memory=No...random_state=42, verbose=0, warm_start=False))])>
        X_train = array([[1.439e+01, 1.870e+00, 2.450e+00, ..., 1...., ..., 6.100e-01, 1.600e+00,
        5.600e+02]])
        y_train = array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...2, 2, 2, 2, 2, 2, 2, 2, 2,
       2, 2, 2, 2, 2])
        fit_params = {}
    529 
    530     except Exception as e:
    531         # Note fit time as time until error
    532         fit_time = time.time() - start_time

...........................................................................
/usr/local/lib/python2.7/dist-packages/imblearn/pipeline.py in fit(self=Pipeline(memory=None,
     steps=[('rebalance', ... random_state=42, verbose=0, warm_start=False))]), X=array([[1.439e+01, 1.870e+00, 2.450e+00, ..., 1...., ..., 6.100e-01, 1.600e+00,
        5.600e+02]]), y=array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...2, 2, 2, 2, 2, 2, 2, 2, 2,
       2, 2, 2, 2, 2]), **fit_params={})
    234             This estimator
    235 
    236         """
    237         Xt, yt, fit_params = self._fit(X, y, **fit_params)
    238         if self._final_estimator is not None:
--> 239             self._final_estimator.fit(Xt, yt, **fit_params)
        self._final_estimator.fit = <bound method RandomForestClassifier.fit of Rand...e, random_state=42, verbose=0, warm_start=False)>
        Xt = array([[ 484.53094538],
       [ 624.57117788],
...
       [ 175.28622396],
       [-105.24644289]])
        yt = array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1,... 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2])
        fit_params = {}
    240         return self
    241 
    242     def fit_transform(self, X, y=None, **fit_params):
    243         """Fit the model and transform with the final estimator

...........................................................................
/home/aquemy/.local/lib/python2.7/site-packages/sklearn/ensemble/forest.py in fit(self=RandomForestClassifier(bootstrap=True, class_wei...se, random_state=42, verbose=0, warm_start=False), X=array([[ 484.53094  ],
       [ 624.57117  ],
  ....28622  ],
       [-105.246445 ]], dtype=float32), y=array([[0.],
       [0.],
       [0.],
       [0...    [2.],
       [2.],
       [2.],
       [2.]]), sample_weight=None)
    328             trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,
    329                              **_joblib_parallel_args(prefer='threads'))(
    330                 delayed(_parallel_build_trees)(
    331                     t, self, X, y, sample_weight, i, len(trees),
    332                     verbose=self.verbose, class_weight=self.class_weight)
--> 333                 for i, t in enumerate(trees))
        i = 9
    334 
    335             # Collect newly grown trees
    336             self.estimators_.extend(trees)
    337 

...........................................................................
/home/aquemy/.local/lib/python2.7/site-packages/sklearn/externals/joblib/parallel.py in __call__(self=Parallel(n_jobs=1), iterable=<generator object <genexpr>>)
    912             # self._original_iterator is None, then this means either
    913             # that pre_dispatch == "all", n_jobs == 1 or that the first batch
    914             # was very quick and its callback already dispatched all the
    915             # remaining jobs.
    916             self._iterating = False
--> 917             if self.dispatch_one_batch(iterator):
        self.dispatch_one_batch = <bound method Parallel.dispatch_one_batch of Parallel(n_jobs=1)>
        iterator = <generator object <genexpr>>
    918                 self._iterating = self._original_iterator is not None
    919 
    920             while self.dispatch_one_batch(iterator):
    921                 pass

...........................................................................
/home/aquemy/.local/lib/python2.7/site-packages/sklearn/externals/joblib/parallel.py in dispatch_one_batch(self=Parallel(n_jobs=1), iterator=<generator object <genexpr>>)
    754                                  self._pickle_cache)
    755             if len(tasks) == 0:
    756                 # No more tasks available in the iterator: tell caller to stop.
    757                 return False
    758             else:
--> 759                 self._dispatch(tasks)
        self._dispatch = <bound method Parallel._dispatch of Parallel(n_jobs=1)>
        tasks = <sklearn.externals.joblib.parallel.BatchedCalls object>
    760                 return True
    761 
    762     def _print(self, msg, msg_args):
    763         """Display the message on stout or stderr depending on verbosity"""

...........................................................................
/home/aquemy/.local/lib/python2.7/site-packages/sklearn/externals/joblib/parallel.py in _dispatch(self=Parallel(n_jobs=1), batch=<sklearn.externals.joblib.parallel.BatchedCalls object>)
    711 
    712         dispatch_timestamp = time.time()
    713         cb = BatchCompletionCallBack(dispatch_timestamp, len(batch), self)
    714         with self._lock:
    715             job_idx = len(self._jobs)
--> 716             job = self._backend.apply_async(batch, callback=cb)
        job = undefined
        self._backend.apply_async = <bound method SequentialBackend.apply_async of <...lib._parallel_backends.SequentialBackend object>>
        batch = <sklearn.externals.joblib.parallel.BatchedCalls object>
        cb = <sklearn.externals.joblib.parallel.BatchCompletionCallBack object>
    717             # A job can complete so quickly than its callback is
    718             # called before we get here, causing self._jobs to
    719             # grow. To ensure correct results ordering, .insert is
    720             # used (rather than .append) in the following line

...........................................................................
/home/aquemy/.local/lib/python2.7/site-packages/sklearn/externals/joblib/_parallel_backends.py in apply_async(self=<sklearn.externals.joblib._parallel_backends.SequentialBackend object>, func=<sklearn.externals.joblib.parallel.BatchedCalls object>, callback=<sklearn.externals.joblib.parallel.BatchCompletionCallBack object>)
    177             raise ValueError('n_jobs == 0 in Parallel has no meaning')
    178         return 1
    179 
    180     def apply_async(self, func, callback=None):
    181         """Schedule a func to be run"""
--> 182         result = ImmediateResult(func)
        result = undefined
        func = <sklearn.externals.joblib.parallel.BatchedCalls object>
    183         if callback:
    184             callback(result)
    185         return result
    186 

...........................................................................
/home/aquemy/.local/lib/python2.7/site-packages/sklearn/externals/joblib/_parallel_backends.py in __init__(self=<sklearn.externals.joblib._parallel_backends.ImmediateResult object>, batch=<sklearn.externals.joblib.parallel.BatchedCalls object>)
    544 
    545 class ImmediateResult(object):
    546     def __init__(self, batch):
    547         # Don't delay the application, to avoid keeping the input
    548         # arguments in memory
--> 549         self.results = batch()
        self.results = undefined
        batch = <sklearn.externals.joblib.parallel.BatchedCalls object>
    550 
    551     def get(self):
    552         return self.results
    553 

...........................................................................
/home/aquemy/.local/lib/python2.7/site-packages/sklearn/externals/joblib/parallel.py in __call__(self=<sklearn.externals.joblib.parallel.BatchedCalls object>)
    220     def __call__(self):
    221         # Set the default nested backend to self._backend but do not set the
    222         # change the default number of processes to -1
    223         with parallel_backend(self._backend, n_jobs=self._n_jobs):
    224             return [func(*args, **kwargs)
--> 225                     for func, args, kwargs in self.items]
        func = <function _parallel_build_trees>
        args = (DecisionTreeClassifier(class_weight=None, criter...=False, random_state=1608637542, splitter='best'), RandomForestClassifier(bootstrap=True, class_wei...se, random_state=42, verbose=0, warm_start=False), array([[ 484.53094  ],
       [ 624.57117  ],
  ....28622  ],
       [-105.246445 ]], dtype=float32), array([[0.],
       [0.],
       [0.],
       [0...    [2.],
       [2.],
       [2.],
       [2.]]), None, 0, 10)
        kwargs = {'class_weight': None, 'verbose': 0}
        self.items = [(<function _parallel_build_trees>, (DecisionTreeClassifier(class_weight=None, criter...=False, random_state=1608637542, splitter='best'), RandomForestClassifier(bootstrap=True, class_wei...se, random_state=42, verbose=0, warm_start=False), array([[ 484.53094  ],
       [ 624.57117  ],
  ....28622  ],
       [-105.246445 ]], dtype=float32), array([[0.],
       [0.],
       [0.],
       [0...    [2.],
       [2.],
       [2.],
       [2.]]), None, 0, 10), {'class_weight': None, 'verbose': 0})]
    226 
    227     def __len__(self):
    228         return self._size
    229 

...........................................................................
/home/aquemy/.local/lib/python2.7/site-packages/sklearn/ensemble/forest.py in _parallel_build_trees(tree=DecisionTreeClassifier(class_weight=None, criter...=False, random_state=1608637542, splitter='best'), forest=RandomForestClassifier(bootstrap=True, class_wei...se, random_state=42, verbose=0, warm_start=False), X=array([[ 484.53094  ],
       [ 624.57117  ],
  ....28622  ],
       [-105.246445 ]], dtype=float32), y=array([[0.],
       [0.],
       [0.],
       [0...    [2.],
       [2.],
       [2.],
       [2.]]), sample_weight=None, tree_idx=0, n_trees=10, verbose=0, class_weight=None)
    114                 simplefilter('ignore', DeprecationWarning)
    115                 curr_sample_weight *= compute_sample_weight('auto', y, indices)
    116         elif class_weight == 'balanced_subsample':
    117             curr_sample_weight *= compute_sample_weight('balanced', y, indices)
    118 
--> 119         tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)
        tree.fit = <bound method DecisionTreeClassifier.fit of Deci...False, random_state=1608637542, splitter='best')>
        X = array([[ 484.53094  ],
       [ 624.57117  ],
  ....28622  ],
       [-105.246445 ]], dtype=float32)
        y = array([[0.],
       [0.],
       [0.],
       [0...    [2.],
       [2.],
       [2.],
       [2.]])
        sample_weight = None
        curr_sample_weight = array([2., 1., 1., 1., 2., 1., 1., 0., 1., 2., 0... 1., 1., 2., 2., 1., 2., 0., 0., 1., 3., 2., 0.])
    120     else:
    121         tree.fit(X, y, sample_weight=sample_weight, check_input=False)
    122 
    123     return tree

...........................................................................
/home/aquemy/.local/lib/python2.7/site-packages/sklearn/tree/tree.py in fit(self=DecisionTreeClassifier(class_weight=None, criter...=False, random_state=1608637542, splitter='best'), X=array([[ 484.53094  ],
       [ 624.57117  ],
  ....28622  ],
       [-105.246445 ]], dtype=float32), y=array([[0.],
       [0.],
       [0.],
       [0...    [2.],
       [2.],
       [2.],
       [2.]]), sample_weight=array([2., 1., 1., 1., 2., 1., 1., 0., 1., 2., 0... 1., 1., 2., 2., 1., 2., 0., 0., 1., 3., 2., 0.]), check_input=False, X_idx_sorted=None)
    796 
    797         super(DecisionTreeClassifier, self).fit(
    798             X, y,
    799             sample_weight=sample_weight,
    800             check_input=check_input,
--> 801             X_idx_sorted=X_idx_sorted)
        X_idx_sorted = None
    802         return self
    803 
    804     def predict_proba(self, X, check_input=True):
    805         """Predict class probabilities of the input samples X.

...........................................................................
/home/aquemy/.local/lib/python2.7/site-packages/sklearn/tree/tree.py in fit(self=DecisionTreeClassifier(class_weight=None, criter...=False, random_state=1608637542, splitter='best'), X=array([[ 484.53094  ],
       [ 624.57117  ],
  ....28622  ],
       [-105.246445 ]], dtype=float32), y=array([[0.],
       [0.],
       [0.],
       [0...    [2.],
       [2.],
       [2.],
       [2.]]), sample_weight=array([2., 1., 1., 1., 2., 1., 1., 0., 1., 2., 0... 1., 1., 2., 2., 1., 2., 0., 0., 1., 3., 2., 0.]), check_input=False, X_idx_sorted=None)
    237         if not 0 <= self.min_weight_fraction_leaf <= 0.5:
    238             raise ValueError("min_weight_fraction_leaf must in [0, 0.5]")
    239         if max_depth <= 0:
    240             raise ValueError("max_depth must be greater than zero. ")
    241         if not (0 < max_features <= self.n_features_):
--> 242             raise ValueError("max_features must be in (0, n_features]")
    243         if not isinstance(max_leaf_nodes, (numbers.Integral, np.integer)):
    244             raise ValueError("max_leaf_nodes must be integral number but was "
    245                              "%r" % max_leaf_nodes)
    246         if -1 < max_leaf_nodes < 2:

ValueError: max_features must be in (0, n_features]
___________________________________________________________________________
Best score: 0.983625730994 (0.0250235004624) [J] | Score: 0.0 (0.0) [J]
Best score: 0.983625730994 (0.0250235004624) [J] | Score: 0.845287237702 (0.0877152595575) [J]
Best score: 0.983625730994 (0.0250235004624) [J] | Score: 0.922153422773 (0.0510378899068) [J]
Best score: 0.983625730994 (0.0250235004624) [J] | Score: 0.961369109047 (0.0425859145526) [J]
JoblibValueError
___________________________________________________________________________
...........................................................................
/home/aquemy/dev/dp_hyperparameters/extension/main.py in <module>()
     27 
     28     serializer.serialize_results(scenario, policy)
     29 
     30 if __name__ == "__main__":
     31     args = cli.parse_args()
---> 32     main(args)

...........................................................................
/home/aquemy/dev/dp_hyperparameters/extension/main.py in main(args=Namespace(customize=[(['control', 'seed'], '42')...io='./scenarios/rf_wine_joint.yaml', verbosity=0))
     21         test_size=0.4, 
     22         random_state=scenario['control']['seed']
     23     )
     24 
     25     policy = policies.initiate(scenario['setup']['policy'], config)
---> 26     policy.run(X,y)
        policy.run = <bound method Joint.run of <experiment.policies.joint.Joint object>>
        X = array([[1.423e+01, 1.710e+00, 2.430e+00, ..., 1...., ..., 6.100e-01, 1.600e+00,
        5.600e+02]])
        y = array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,
       2, 2])
     27 
     28     serializer.serialize_results(scenario, policy)
     29 
     30 if __name__ == "__main__":

...........................................................................
/home/aquemy/dev/dp_hyperparameters/extension/experiment/policies/joint.py in run(self=<experiment.policies.joint.Joint object>, X=array([[1.423e+01, 1.710e+00, 2.430e+00, ..., 1...., ..., 6.100e-01, 1.600e+00,
        5.600e+02]]), y=array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,
       2, 2]))
     32             algo=tpe.suggest, 
     33             max_evals=None,
     34             max_time=self.config['time'],     
     35             trials=trials,
     36             show_progressbar=False,
---> 37             verbose=0
     38         )
     39 
     40         best_config = self.context['best_config']
     41         super(Joint, self).display_step_results(best_config)

...........................................................................
/home/aquemy/dev/dp_hyperparameters/extension/hyperopt/fmin.py in fmin(fn=<functools.partial object>, space={'algorithm': {'bootstrap': <hyperopt.pyll.base.Apply object>, 'criterion': <hyperopt.pyll.base.Apply object>, 'max_depth': <hyperopt.pyll.base.Apply object>, 'max_features': <hyperopt.pyll.base.Apply object>, 'max_leaf_nodes': <hyperopt.pyll.base.Apply object>, 'min_samples_split': <hyperopt.pyll.base.Apply object>, 'n_estimators': <hyperopt.pyll.base.Apply object>}, 'pipeline': {'features': <hyperopt.pyll.base.Apply object>, 'normalizer': <hyperopt.pyll.base.Apply object>, 'rebalance': <hyperopt.pyll.base.Apply object>}}, algo=<function suggest>, max_evals=9223372036854775807, max_time=300, trials=<hyperopt.base.Trials object>, rstate=<mtrand.RandomState object>, allow_trials_fmin=True, pass_expr_memo_ctrl=None, catch_eval_exceptions=False, verbose=0, return_argmin=True, points_to_evaluate=None, max_queue_len=1, show_progressbar=False)
    406             pass_expr_memo_ctrl=pass_expr_memo_ctrl,
    407             verbose=verbose,
    408             catch_eval_exceptions=catch_eval_exceptions,
    409             return_argmin=return_argmin,
    410             show_progressbar=show_progressbar,
--> 411             max_time=max_time
        max_time = 300
    412         )
    413 
    414     if trials is None:
    415         if points_to_evaluate is None:

...........................................................................
/home/aquemy/dev/dp_hyperparameters/extension/hyperopt/base.py in fmin(self=<hyperopt.base.Trials object>, fn=<functools.partial object>, space={'algorithm': {'bootstrap': <hyperopt.pyll.base.Apply object>, 'criterion': <hyperopt.pyll.base.Apply object>, 'max_depth': <hyperopt.pyll.base.Apply object>, 'max_features': <hyperopt.pyll.base.Apply object>, 'max_leaf_nodes': <hyperopt.pyll.base.Apply object>, 'min_samples_split': <hyperopt.pyll.base.Apply object>, 'n_estimators': <hyperopt.pyll.base.Apply object>}, 'pipeline': {'features': <hyperopt.pyll.base.Apply object>, 'normalizer': <hyperopt.pyll.base.Apply object>, 'rebalance': <hyperopt.pyll.base.Apply object>}}, algo=<function suggest>, max_evals=9223372036854775807, max_time=300, rstate=<mtrand.RandomState object>, verbose=0, pass_expr_memo_ctrl=None, catch_eval_exceptions=False, return_argmin=True, show_progressbar=False)
    636             verbose=verbose,
    637             allow_trials_fmin=False,  # -- prevent recursion
    638             pass_expr_memo_ctrl=pass_expr_memo_ctrl,
    639             catch_eval_exceptions=catch_eval_exceptions,
    640             return_argmin=return_argmin,
--> 641             show_progressbar=show_progressbar)
        show_progressbar = False
    642 
    643 
    644 def trials_from_docs(docs, validate=True, **kwargs):
    645     """Construct a Trials base class instance from a list of trials documents

...........................................................................
/home/aquemy/dev/dp_hyperparameters/extension/hyperopt/fmin.py in fmin(fn=<functools.partial object>, space={'algorithm': {'bootstrap': <hyperopt.pyll.base.Apply object>, 'criterion': <hyperopt.pyll.base.Apply object>, 'max_depth': <hyperopt.pyll.base.Apply object>, 'max_features': <hyperopt.pyll.base.Apply object>, 'max_leaf_nodes': <hyperopt.pyll.base.Apply object>, 'min_samples_split': <hyperopt.pyll.base.Apply object>, 'n_estimators': <hyperopt.pyll.base.Apply object>}, 'pipeline': {'features': <hyperopt.pyll.base.Apply object>, 'normalizer': <hyperopt.pyll.base.Apply object>, 'rebalance': <hyperopt.pyll.base.Apply object>}}, algo=<function suggest>, max_evals=9223372036854775807, max_time=300, trials=<hyperopt.base.Trials object>, rstate=<mtrand.RandomState object>, allow_trials_fmin=False, pass_expr_memo_ctrl=None, catch_eval_exceptions=False, verbose=0, return_argmin=True, points_to_evaluate=None, max_queue_len=1, show_progressbar=False)
    426                     verbose=verbose,
    427                     max_queue_len=max_queue_len,
    428                     show_progressbar=show_progressbar,
    429                     max_time=max_time)
    430     rval.catch_eval_exceptions = catch_eval_exceptions
--> 431     rval.exhaust()
        rval.exhaust = <bound method FMinIter.exhaust of <hyperopt.fmin.FMinIter object>>
    432     if return_argmin:
    433         return trials.argmin
    434     elif len(trials) > 0:
    435         # Only if there are some succesfull trail runs, return the best point in the evaluation space

...........................................................................
/home/aquemy/dev/dp_hyperparameters/extension/hyperopt/fmin.py in exhaust(self=<hyperopt.fmin.FMinIter object>)
    273             raise StopIteration()
    274         return self.trials
    275 
    276     def exhaust(self):
    277         n_done = len(self.trials)
--> 278         self.run(self.max_evals - n_done, block_until_done=self.asynchronous)
        self.run = <bound method FMinIter.run of <hyperopt.fmin.FMinIter object>>
        self.max_evals = 9223372036854775807
        n_done = 0
        self.asynchronous = False
    279         self.trials.refresh()
    280         return self
    281 
    282 

...........................................................................
/home/aquemy/dev/dp_hyperparameters/extension/hyperopt/fmin.py in run(self=<hyperopt.fmin.FMinIter object>, N=9223372036854775807, block_until_done=False)
    232                     if self.asynchronous:
    233                         # -- wait for workers to fill in the trials
    234                         time.sleep(self.poll_interval_secs)
    235                     else:
    236                         # -- loop over trials and do the jobs directly
--> 237                         self.serial_evaluate()
        self.serial_evaluate = <bound method FMinIter.serial_evaluate of <hyperopt.fmin.FMinIter object>>
    238                     try:
    239                         res = [d['result']['loss'] for d in
    240                                          self.trials.trials if
    241                                          d['result']['status'] == 'ok']

...........................................................................
/home/aquemy/dev/dp_hyperparameters/extension/hyperopt/fmin.py in serial_evaluate(self=<hyperopt.fmin.FMinIter object>, N=-1)
    138                 trial['book_time'] = now
    139                 trial['refresh_time'] = now
    140                 spec = base.spec_from_misc(trial['misc'])
    141                 ctrl = base.Ctrl(self.trials, current_trial=trial)
    142                 try:
--> 143                     result = self.domain.evaluate(spec, ctrl)
        result = undefined
        self.domain.evaluate = <bound method Domain.evaluate of <hyperopt.base.Domain object>>
        spec = {'bootstrap': 1, 'criterion': 1, 'features': 1, 'features_PCA_features__n_components': 0, 'max_depth': 3, 'max_features': 1, 'max_leaf_nodes': 1, 'min_samples_split': 0, 'n_estimators': 1, 'normalizer': 4, ...}
        ctrl = <hyperopt.base.Ctrl object>
    144                 except Exception as e:
    145                     logger.info('job exception: %s' % str(e))
    146                     trial['state'] = base.JOB_STATE_ERROR
    147                     trial['misc']['error'] = (str(type(e)), str(e))

...........................................................................
/home/aquemy/dev/dp_hyperparameters/extension/hyperopt/base.py in evaluate(self=<hyperopt.base.Domain object>, config={'bootstrap': 1, 'criterion': 1, 'features': 1, 'features_PCA_features__n_components': 0, 'max_depth': 3, 'max_features': 1, 'max_leaf_nodes': 1, 'min_samples_split': 0, 'n_estimators': 1, 'normalizer': 4, ...}, ctrl=<hyperopt.base.Ctrl object>, attach_attachments=True)
    841             #    or the normal Python part (self.fn)
    842             pyll_rval = pyll.rec_eval(
    843                 self.expr,
    844                 memo=memo,
    845                 print_node_on_error=self.rec_eval_print_node_on_error)
--> 846             rval = self.fn(pyll_rval)
        rval = undefined
        self.fn = <functools.partial object>
        pyll_rval = {'algorithm': {'bootstrap': False, 'criterion': 'entropy', 'max_depth': 4, 'max_features': 2, 'max_leaf_nodes': 3, 'min_samples_split': 2, 'n_estimators': 25}, 'pipeline': {'features': ('features_PCA', {'features__n_components': 1}), 'normalizer': ('normalizer_RobustScaler', {'normalizer__quantile_range': (25.0, 75.0), 'normalizer__with_centering': False, 'normalizer__with_scaling': False}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 7})}}
    847 
    848         if isinstance(rval, (float, int, np.number)):
    849             dict_rval = {'loss': float(rval), 'status': STATUS_OK}
    850         else:

...........................................................................
/home/aquemy/dev/dp_hyperparameters/extension/experiment/objective.py in objective_joint(wconfig={'algorithm': {'bootstrap': False, 'criterion': 'entropy', 'max_depth': 4, 'max_features': 2, 'max_leaf_nodes': 3, 'min_samples_split': 2, 'n_estimators': 25}, 'pipeline': {'features': ('features_PCA', {'features__n_components': 1}), 'normalizer': ('normalizer_RobustScaler', {'normalizer__quantile_range': (25.0, 75.0), 'normalizer__with_centering': False, 'normalizer__with_scaling': False}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 7})}}, algorithm='RandomForest', X=array([[1.423e+01, 1.710e+00, 2.430e+00, ..., 1...., ..., 6.100e-01, 1.600e+00,
        5.600e+02]]), y=array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,
       2, 2]), context={'baseline_score': 0.9444100447196423, 'baseline_score_std': 0.04305547117084885, 'best_config': {'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': 2, 'max_features': 1, 'max_leaf_nodes': None, 'min_samples_split': 3, 'n_estimators': 75}, 'config_hash': {'algorithm': '42185be98371e99ac896d2c6c2d69c451cb983ff', 'config': '6609280032189b59de1afbe36f3acb1d5c273693', 'pipeline': '8aab2941fc84d84f86fa56134e50909dbf9e19f5'}, 'duration': 0.9665219783782959, 'iteration': 9, 'loss': 0.01637426900584804, 'max_history_score': 0.983625730994152, 'max_history_score_std': 0.025023500462379746, 'max_history_step': 'joint', 'pipeline': {'features': ('features_NoneType', {}), 'normalizer': ('normalizer_PowerTransformer', {}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 5})}, 'score': 0.983625730994152, ...}, 'history': [{'algorithm': {'bootstrap': False, 'criterion': 'entropy', 'max_depth': None, 'max_features': 3, 'max_leaf_nodes': 5, 'min_samples_split': 2, 'n_estimators': 50}, 'config_hash': {'algorithm': 'b2c6464add7a35ce8048653a39338c9994de9a4f', 'config': '2e6648b63441361b4398cb94f81d2e04a830b2ef', 'pipeline': '3d44d7482e468d08c4f94457a205f3dac74084c1'}, 'duration': 0.737678050994873, 'iteration': 0, 'loss': 1.0, 'max_history_score': 0.0, 'max_history_score_std': 0.0, 'max_history_step': 'baseline', 'pipeline': {'features': ('features_PCA', {'features__n_components': 1}), 'normalizer': ('normalizer_NoneType', {}), 'rebalance': ('rebalance_CondensedNearestNeighbour', {'rebalance__n_neighbors': 3})}, 'score': 0.0, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'gini', 'max_depth': 1, 'max_features': None, 'max_leaf_nodes': 2, 'min_samples_split': 3, 'n_estimators': 25}, 'config_hash': {'algorithm': '7f71bbbfdb4e8da52b6fc33a43224183117de15e', 'config': '584343bc020d2d7bc89bd0856bc7770dae1c84fc', 'pipeline': '466ffa7ace0e442beb7c311eb214b17a4c6832b3'}, 'duration': 1.5976769924163818, 'iteration': 1, 'loss': 0.40386351909184726, 'max_history_score': 0.5961364809081527, 'max_history_score_std': 0.05351463210025494, 'max_history_step': 'joint', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 3, 'features__selectkbest__k': 3}), 'normalizer': ('normalizer_StandardScaler', {'normalizer__with_mean': True, 'normalizer__with_std': True}), 'rebalance': ('rebalance_NearMiss', {'rebalance__n_neighbors': 2})}, 'score': 0.5961364809081527, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'entropy', 'max_depth': 1, 'max_features': 2, 'max_leaf_nodes': 2, 'min_samples_split': 5, 'n_estimators': 25}, 'config_hash': {'algorithm': '897745a20d929d43e760cacee0a764bd8070daa5', 'config': 'de121d053e65def047cc8947f505578d5c5eab67', 'pipeline': '63040b39b48626a8232e847e8327bdca5cd88611'}, 'duration': 0.815453052520752, 'iteration': 2, 'loss': 0.07327786377708967, 'max_history_score': 0.9267221362229103, 'max_history_score_std': 0.043920207373658794, 'max_history_step': 'joint', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 3, 'features__selectkbest__k': 2}), 'normalizer': ('normalizer_StandardScaler', {'normalizer__with_mean': True, 'normalizer__with_std': True}), 'rebalance': ('rebalance_NoneType', {})}, 'score': 0.9267221362229103, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'entropy', 'max_depth': 4, 'max_features': 3, 'max_leaf_nodes': None, 'min_samples_split': 2, 'n_estimators': 100}, 'config_hash': {'algorithm': 'dbd92c75280ec06b66ca4ad9b135cf36957031a4', 'config': 'b21c9d15a389baa5bfea4c8ddcec129259f37540', 'pipeline': '38866720d2f120c863351493b9b4e23b9a4506dc'}, 'duration': 1.2293269634246826, 'iteration': 3, 'loss': 0.07199862401100798, 'max_history_score': 0.928001375988992, 'max_history_score_std': 0.06518367535896959, 'max_history_step': 'joint', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 2, 'features__selectkbest__k': 4}), 'normalizer': ('normalizer_NoneType', {}), 'rebalance': ('rebalance_NoneType', {})}, 'score': 0.928001375988992, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': 2, 'max_features': None, 'max_leaf_nodes': None, 'min_samples_split': 5, 'n_estimators': 100}, 'config_hash': {'algorithm': 'f455eefd9fdd03ece88892c3f440c580bdf27ddb', 'config': 'edd3456355d80775739c31515c832ca7b4e5e094', 'pipeline': '1d1034f9f0871e43f896c1db4ed6fd572ed0a6ef'}, 'duration': 1.6186630725860596, 'iteration': 4, 'loss': 0.16651831785345705, 'max_history_score': 0.928001375988992, 'max_history_score_std': 0.06518367535896959, 'max_history_step': 'joint', 'pipeline': {'features': ('features_SelectKBest', {'features__k': 4}), 'normalizer': ('normalizer_MinMaxScaler', {}), 'rebalance': ('rebalance_CondensedNearestNeighbour', {'rebalance__n_neighbors': 1})}, 'score': 0.833481682146543, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'entropy', 'max_depth': 1, 'max_features': 2, 'max_leaf_nodes': None, 'min_samples_split': 2, 'n_estimators': 10}, 'config_hash': {'algorithm': '29906eaa0712a68ea145b12821d54ba445726fbf', 'config': '0800d7d2c8c10d2f9e7b4e5127b343e916eb742c', 'pipeline': '2e0f188ae61600352a7159285e0f542b4587a403'}, 'duration': 0.19410085678100586, 'iteration': 5, 'loss': 0.20164258685930514, 'max_history_score': 0.928001375988992, 'max_history_score_std': 0.06518367535896959, 'max_history_step': 'joint', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 3, 'features__selectkbest__k': 4}), 'normalizer': ('normalizer_StandardScaler', {'normalizer__with_mean': True, 'normalizer__with_std': False}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 7})}, 'score': 0.7983574131406949, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': 1, 'max_features': 1, 'max_leaf_nodes': 5, 'min_samples_split': 2, 'n_estimators': 25}, 'config_hash': {'algorithm': 'fbb7d57e38cfc08240f0af985282da418cb33556', 'config': 'd98b641879b4754f2169335626a90575e945fd7c', 'pipeline': '62463de065924498cdcd2f2f1f7e68535cdb33a5'}, 'duration': 0.3625810146331787, 'iteration': 6, 'loss': 0.14327485380116955, 'max_history_score': 0.928001375988992, 'max_history_score_std': 0.06518367535896959, 'max_history_step': 'joint', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 1, 'features__selectkbest__k': 2}), 'normalizer': ('normalizer_NoneType', {}), 'rebalance': ('rebalance_NoneType', {})}, 'score': 0.8567251461988304, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'entropy', 'max_depth': 3, 'max_features': 1, 'max_leaf_nodes': None, 'min_samples_split': 2, 'n_estimators': 75}, 'config_hash': {'algorithm': 'fb2f5d4c4d636edac929e1454ce3d02a4fb134c1', 'config': '3f83df36a6abbdf7ea4a4bdcaf6727f23529c2bb', 'pipeline': '8377b93e334656d1a93d266493b58ef9a6a1786f'}, 'duration': 0.8223779201507568, 'iteration': 7, 'loss': 0.03921568627450989, 'max_history_score': 0.9607843137254901, 'max_history_score_std': 0.043526663832084804, 'max_history_step': 'joint', 'pipeline': {'features': ('features_PCA', {'features__n_components': 3}), 'normalizer': ('normalizer_MinMaxScaler', {}), 'rebalance': ('rebalance_NearMiss', {'rebalance__n_neighbors': 1})}, 'score': 0.9607843137254901, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'gini', 'max_depth': 3, 'max_features': 3, 'max_leaf_nodes': 2, 'min_samples_split': 2, 'n_estimators': 100}, 'config_hash': {'algorithm': '3c3fde6559b918694de4668d025d5418342db1b1', 'config': '037fd5c655b39cc7922fb394d736496befcc747b', 'pipeline': '2a5032814c6c7ed21dd5bd9686923d7fc2f8acc9'}, 'duration': 1.0435099601745605, 'iteration': 8, 'loss': 0.09955925352597172, 'max_history_score': 0.9607843137254901, 'max_history_score_std': 0.043526663832084804, 'max_history_step': 'joint', 'pipeline': {'features': ('features_NoneType', {}), 'normalizer': ('normalizer_RobustScaler', {'normalizer__quantile_range': (...), 'normalizer__with_centering': True, 'normalizer__with_scaling': True}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 7})}, 'score': 0.9004407464740283, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': 2, 'max_features': 1, 'max_leaf_nodes': None, 'min_samples_split': 3, 'n_estimators': 75}, 'config_hash': {'algorithm': '42185be98371e99ac896d2c6c2d69c451cb983ff', 'config': '6609280032189b59de1afbe36f3acb1d5c273693', 'pipeline': '8aab2941fc84d84f86fa56134e50909dbf9e19f5'}, 'duration': 0.9665219783782959, 'iteration': 9, 'loss': 0.01637426900584804, 'max_history_score': 0.983625730994152, 'max_history_score_std': 0.025023500462379746, 'max_history_step': 'joint', 'pipeline': {'features': ('features_NoneType', {}), 'normalizer': ('normalizer_PowerTransformer', {}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 5})}, 'score': 0.983625730994152, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': 1, 'max_features': 3, 'max_leaf_nodes': 2, 'min_samples_split': 3, 'n_estimators': 10}, 'config_hash': {'algorithm': '62a9fe705e4cd96e762bcc9543c4a456a5a9f188', 'config': '8e1c17ac9f6e03740f380fccb833c9c3931ffc35', 'pipeline': '3d44d7482e468d08c4f94457a205f3dac74084c1'}, 'duration': 0.46930503845214844, 'iteration': 10, 'loss': 1.0, 'max_history_score': 0.983625730994152, 'max_history_score_std': 0.025023500462379746, 'max_history_step': 'joint', 'pipeline': {'features': ('features_PCA', {'features__n_components': 1}), 'normalizer': ('normalizer_NoneType', {}), 'rebalance': ('rebalance_CondensedNearestNeighbour', {'rebalance__n_neighbors': 3})}, 'score': 0.0, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'gini', 'max_depth': 4, 'max_features': 1, 'max_leaf_nodes': 3, 'min_samples_split': 2, 'n_estimators': 100}, 'config_hash': {'algorithm': '086d6ca939a757bb32edb113a567f9d38744f061', 'config': '87c03d0cb8e8500e58cacc1a0f27ce54c41a2937', 'pipeline': '8f28ef0f35d97142278f9dacb4e9d1ff082e470f'}, 'duration': 2.1196961402893066, 'iteration': 11, 'loss': 0.15471276229790154, 'max_history_score': 0.983625730994152, 'max_history_score_std': 0.025023500462379746, 'max_history_step': 'joint', 'pipeline': {'features': ('features_PCA', {'features__n_components': 1}), 'normalizer': ('normalizer_StandardScaler', {'normalizer__with_mean': True, 'normalizer__with_std': True}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 7})}, 'score': 0.8452872377020985, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'entropy', 'max_depth': 3, 'max_features': 1, 'max_leaf_nodes': 2, 'min_samples_split': 2, 'n_estimators': 25}, 'config_hash': {'algorithm': '59f64a966796648c7bebade1127fa05541b391ad', 'config': '2ab964abffa0a277a9e2ee9b5570cd258e428b62', 'pipeline': 'eef3f702fd2fed761fa6744c1640d0bf320f1d00'}, 'duration': 0.9828321933746338, 'iteration': 12, 'loss': 0.0778465772273822, 'max_history_score': 0.983625730994152, 'max_history_score_std': 0.025023500462379746, 'max_history_step': 'joint', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 3, 'features__selectkbest__k': 1}), 'normalizer': ('normalizer_PowerTransformer', {}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 6})}, 'score': 0.9221534227726178, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'gini', 'max_depth': 4, 'max_features': 2, 'max_leaf_nodes': 3, 'min_samples_split': 3, 'n_estimators': 75}, 'config_hash': {'algorithm': '6f75c2a196eb9836df2b424e095051192eaed6ea', 'config': '5c95db3ad238063227f1b36e6a006d70c834c5da', 'pipeline': '1eae01a1128bee425c4d4ca0ee97a9afd409680e'}, 'duration': 0.8217771053314209, 'iteration': 13, 'loss': 0.03863089095287242, 'max_history_score': 0.983625730994152, 'max_history_score_std': 0.025023500462379746, 'max_history_step': 'joint', 'pipeline': {'features': ('features_NoneType', {}), 'normalizer': ('normalizer_StandardScaler', {'normalizer__with_mean': False, 'normalizer__with_std': False}), 'rebalance': ('rebalance_NearMiss', {'rebalance__n_neighbors': 1})}, 'score': 0.9613691090471276, ...}], 'history_hash': ['2e6648b63441361b4398cb94f81d2e04a830b2ef', '584343bc020d2d7bc89bd0856bc7770dae1c84fc', 'de121d053e65def047cc8947f505578d5c5eab67', 'b21c9d15a389baa5bfea4c8ddcec129259f37540', 'edd3456355d80775739c31515c832ca7b4e5e094', '0800d7d2c8c10d2f9e7b4e5127b343e916eb742c', 'd98b641879b4754f2169335626a90575e945fd7c', '3f83df36a6abbdf7ea4a4bdcaf6727f23529c2bb', '037fd5c655b39cc7922fb394d736496befcc747b', '6609280032189b59de1afbe36f3acb1d5c273693', '8e1c17ac9f6e03740f380fccb833c9c3931ffc35', '87c03d0cb8e8500e58cacc1a0f27ce54c41a2937', '2ab964abffa0a277a9e2ee9b5570cd258e428b62', '5c95db3ad238063227f1b36e6a006d70c834c5da'], 'history_index': {'037fd5c655b39cc7922fb394d736496befcc747b': 8, '0800d7d2c8c10d2f9e7b4e5127b343e916eb742c': 5, '2ab964abffa0a277a9e2ee9b5570cd258e428b62': 12, '2e6648b63441361b4398cb94f81d2e04a830b2ef': 0, '3f83df36a6abbdf7ea4a4bdcaf6727f23529c2bb': 7, '584343bc020d2d7bc89bd0856bc7770dae1c84fc': 1, '5c95db3ad238063227f1b36e6a006d70c834c5da': 13, '6609280032189b59de1afbe36f3acb1d5c273693': 9, '87c03d0cb8e8500e58cacc1a0f27ce54c41a2937': 11, '8e1c17ac9f6e03740f380fccb833c9c3931ffc35': 10, ...}, 'iteration': 13, 'max_history_score': 0.983625730994152, 'max_history_score_std': 0.025023500462379746, 'max_history_step': 'joint'}, config={'algorithm': 'RandomForest', 'seed': 42, 'time': 300})
    108 
    109 def objective_algo(algo_config, current_pipeline_config, algorithm, X, y, context, config):
    110     return objective(current_pipeline_config, algo_config, algorithm, X, y, context, config, step='algorithm')
    111 
    112 def objective_joint(wconfig, algorithm, X, y, context, config):
--> 113     return objective(wconfig['pipeline'], wconfig['algorithm'], algorithm, X, y, context, config, step='joint')
        wconfig = {'algorithm': {'bootstrap': False, 'criterion': 'entropy', 'max_depth': 4, 'max_features': 2, 'max_leaf_nodes': 3, 'min_samples_split': 2, 'n_estimators': 25}, 'pipeline': {'features': ('features_PCA', {'features__n_components': 1}), 'normalizer': ('normalizer_RobustScaler', {'normalizer__quantile_range': (25.0, 75.0), 'normalizer__with_centering': False, 'normalizer__with_scaling': False}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 7})}}
        algorithm = 'RandomForest'
        X = array([[1.423e+01, 1.710e+00, 2.430e+00, ..., 1...., ..., 6.100e-01, 1.600e+00,
        5.600e+02]])
        y = array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,
       2, 2])
        context = {'baseline_score': 0.9444100447196423, 'baseline_score_std': 0.04305547117084885, 'best_config': {'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': 2, 'max_features': 1, 'max_leaf_nodes': None, 'min_samples_split': 3, 'n_estimators': 75}, 'config_hash': {'algorithm': '42185be98371e99ac896d2c6c2d69c451cb983ff', 'config': '6609280032189b59de1afbe36f3acb1d5c273693', 'pipeline': '8aab2941fc84d84f86fa56134e50909dbf9e19f5'}, 'duration': 0.9665219783782959, 'iteration': 9, 'loss': 0.01637426900584804, 'max_history_score': 0.983625730994152, 'max_history_score_std': 0.025023500462379746, 'max_history_step': 'joint', 'pipeline': {'features': ('features_NoneType', {}), 'normalizer': ('normalizer_PowerTransformer', {}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 5})}, 'score': 0.983625730994152, ...}, 'history': [{'algorithm': {'bootstrap': False, 'criterion': 'entropy', 'max_depth': None, 'max_features': 3, 'max_leaf_nodes': 5, 'min_samples_split': 2, 'n_estimators': 50}, 'config_hash': {'algorithm': 'b2c6464add7a35ce8048653a39338c9994de9a4f', 'config': '2e6648b63441361b4398cb94f81d2e04a830b2ef', 'pipeline': '3d44d7482e468d08c4f94457a205f3dac74084c1'}, 'duration': 0.737678050994873, 'iteration': 0, 'loss': 1.0, 'max_history_score': 0.0, 'max_history_score_std': 0.0, 'max_history_step': 'baseline', 'pipeline': {'features': ('features_PCA', {'features__n_components': 1}), 'normalizer': ('normalizer_NoneType', {}), 'rebalance': ('rebalance_CondensedNearestNeighbour', {'rebalance__n_neighbors': 3})}, 'score': 0.0, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'gini', 'max_depth': 1, 'max_features': None, 'max_leaf_nodes': 2, 'min_samples_split': 3, 'n_estimators': 25}, 'config_hash': {'algorithm': '7f71bbbfdb4e8da52b6fc33a43224183117de15e', 'config': '584343bc020d2d7bc89bd0856bc7770dae1c84fc', 'pipeline': '466ffa7ace0e442beb7c311eb214b17a4c6832b3'}, 'duration': 1.5976769924163818, 'iteration': 1, 'loss': 0.40386351909184726, 'max_history_score': 0.5961364809081527, 'max_history_score_std': 0.05351463210025494, 'max_history_step': 'joint', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 3, 'features__selectkbest__k': 3}), 'normalizer': ('normalizer_StandardScaler', {'normalizer__with_mean': True, 'normalizer__with_std': True}), 'rebalance': ('rebalance_NearMiss', {'rebalance__n_neighbors': 2})}, 'score': 0.5961364809081527, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'entropy', 'max_depth': 1, 'max_features': 2, 'max_leaf_nodes': 2, 'min_samples_split': 5, 'n_estimators': 25}, 'config_hash': {'algorithm': '897745a20d929d43e760cacee0a764bd8070daa5', 'config': 'de121d053e65def047cc8947f505578d5c5eab67', 'pipeline': '63040b39b48626a8232e847e8327bdca5cd88611'}, 'duration': 0.815453052520752, 'iteration': 2, 'loss': 0.07327786377708967, 'max_history_score': 0.9267221362229103, 'max_history_score_std': 0.043920207373658794, 'max_history_step': 'joint', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 3, 'features__selectkbest__k': 2}), 'normalizer': ('normalizer_StandardScaler', {'normalizer__with_mean': True, 'normalizer__with_std': True}), 'rebalance': ('rebalance_NoneType', {})}, 'score': 0.9267221362229103, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'entropy', 'max_depth': 4, 'max_features': 3, 'max_leaf_nodes': None, 'min_samples_split': 2, 'n_estimators': 100}, 'config_hash': {'algorithm': 'dbd92c75280ec06b66ca4ad9b135cf36957031a4', 'config': 'b21c9d15a389baa5bfea4c8ddcec129259f37540', 'pipeline': '38866720d2f120c863351493b9b4e23b9a4506dc'}, 'duration': 1.2293269634246826, 'iteration': 3, 'loss': 0.07199862401100798, 'max_history_score': 0.928001375988992, 'max_history_score_std': 0.06518367535896959, 'max_history_step': 'joint', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 2, 'features__selectkbest__k': 4}), 'normalizer': ('normalizer_NoneType', {}), 'rebalance': ('rebalance_NoneType', {})}, 'score': 0.928001375988992, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': 2, 'max_features': None, 'max_leaf_nodes': None, 'min_samples_split': 5, 'n_estimators': 100}, 'config_hash': {'algorithm': 'f455eefd9fdd03ece88892c3f440c580bdf27ddb', 'config': 'edd3456355d80775739c31515c832ca7b4e5e094', 'pipeline': '1d1034f9f0871e43f896c1db4ed6fd572ed0a6ef'}, 'duration': 1.6186630725860596, 'iteration': 4, 'loss': 0.16651831785345705, 'max_history_score': 0.928001375988992, 'max_history_score_std': 0.06518367535896959, 'max_history_step': 'joint', 'pipeline': {'features': ('features_SelectKBest', {'features__k': 4}), 'normalizer': ('normalizer_MinMaxScaler', {}), 'rebalance': ('rebalance_CondensedNearestNeighbour', {'rebalance__n_neighbors': 1})}, 'score': 0.833481682146543, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'entropy', 'max_depth': 1, 'max_features': 2, 'max_leaf_nodes': None, 'min_samples_split': 2, 'n_estimators': 10}, 'config_hash': {'algorithm': '29906eaa0712a68ea145b12821d54ba445726fbf', 'config': '0800d7d2c8c10d2f9e7b4e5127b343e916eb742c', 'pipeline': '2e0f188ae61600352a7159285e0f542b4587a403'}, 'duration': 0.19410085678100586, 'iteration': 5, 'loss': 0.20164258685930514, 'max_history_score': 0.928001375988992, 'max_history_score_std': 0.06518367535896959, 'max_history_step': 'joint', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 3, 'features__selectkbest__k': 4}), 'normalizer': ('normalizer_StandardScaler', {'normalizer__with_mean': True, 'normalizer__with_std': False}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 7})}, 'score': 0.7983574131406949, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': 1, 'max_features': 1, 'max_leaf_nodes': 5, 'min_samples_split': 2, 'n_estimators': 25}, 'config_hash': {'algorithm': 'fbb7d57e38cfc08240f0af985282da418cb33556', 'config': 'd98b641879b4754f2169335626a90575e945fd7c', 'pipeline': '62463de065924498cdcd2f2f1f7e68535cdb33a5'}, 'duration': 0.3625810146331787, 'iteration': 6, 'loss': 0.14327485380116955, 'max_history_score': 0.928001375988992, 'max_history_score_std': 0.06518367535896959, 'max_history_step': 'joint', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 1, 'features__selectkbest__k': 2}), 'normalizer': ('normalizer_NoneType', {}), 'rebalance': ('rebalance_NoneType', {})}, 'score': 0.8567251461988304, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'entropy', 'max_depth': 3, 'max_features': 1, 'max_leaf_nodes': None, 'min_samples_split': 2, 'n_estimators': 75}, 'config_hash': {'algorithm': 'fb2f5d4c4d636edac929e1454ce3d02a4fb134c1', 'config': '3f83df36a6abbdf7ea4a4bdcaf6727f23529c2bb', 'pipeline': '8377b93e334656d1a93d266493b58ef9a6a1786f'}, 'duration': 0.8223779201507568, 'iteration': 7, 'loss': 0.03921568627450989, 'max_history_score': 0.9607843137254901, 'max_history_score_std': 0.043526663832084804, 'max_history_step': 'joint', 'pipeline': {'features': ('features_PCA', {'features__n_components': 3}), 'normalizer': ('normalizer_MinMaxScaler', {}), 'rebalance': ('rebalance_NearMiss', {'rebalance__n_neighbors': 1})}, 'score': 0.9607843137254901, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'gini', 'max_depth': 3, 'max_features': 3, 'max_leaf_nodes': 2, 'min_samples_split': 2, 'n_estimators': 100}, 'config_hash': {'algorithm': '3c3fde6559b918694de4668d025d5418342db1b1', 'config': '037fd5c655b39cc7922fb394d736496befcc747b', 'pipeline': '2a5032814c6c7ed21dd5bd9686923d7fc2f8acc9'}, 'duration': 1.0435099601745605, 'iteration': 8, 'loss': 0.09955925352597172, 'max_history_score': 0.9607843137254901, 'max_history_score_std': 0.043526663832084804, 'max_history_step': 'joint', 'pipeline': {'features': ('features_NoneType', {}), 'normalizer': ('normalizer_RobustScaler', {'normalizer__quantile_range': (...), 'normalizer__with_centering': True, 'normalizer__with_scaling': True}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 7})}, 'score': 0.9004407464740283, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': 2, 'max_features': 1, 'max_leaf_nodes': None, 'min_samples_split': 3, 'n_estimators': 75}, 'config_hash': {'algorithm': '42185be98371e99ac896d2c6c2d69c451cb983ff', 'config': '6609280032189b59de1afbe36f3acb1d5c273693', 'pipeline': '8aab2941fc84d84f86fa56134e50909dbf9e19f5'}, 'duration': 0.9665219783782959, 'iteration': 9, 'loss': 0.01637426900584804, 'max_history_score': 0.983625730994152, 'max_history_score_std': 0.025023500462379746, 'max_history_step': 'joint', 'pipeline': {'features': ('features_NoneType', {}), 'normalizer': ('normalizer_PowerTransformer', {}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 5})}, 'score': 0.983625730994152, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': 1, 'max_features': 3, 'max_leaf_nodes': 2, 'min_samples_split': 3, 'n_estimators': 10}, 'config_hash': {'algorithm': '62a9fe705e4cd96e762bcc9543c4a456a5a9f188', 'config': '8e1c17ac9f6e03740f380fccb833c9c3931ffc35', 'pipeline': '3d44d7482e468d08c4f94457a205f3dac74084c1'}, 'duration': 0.46930503845214844, 'iteration': 10, 'loss': 1.0, 'max_history_score': 0.983625730994152, 'max_history_score_std': 0.025023500462379746, 'max_history_step': 'joint', 'pipeline': {'features': ('features_PCA', {'features__n_components': 1}), 'normalizer': ('normalizer_NoneType', {}), 'rebalance': ('rebalance_CondensedNearestNeighbour', {'rebalance__n_neighbors': 3})}, 'score': 0.0, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'gini', 'max_depth': 4, 'max_features': 1, 'max_leaf_nodes': 3, 'min_samples_split': 2, 'n_estimators': 100}, 'config_hash': {'algorithm': '086d6ca939a757bb32edb113a567f9d38744f061', 'config': '87c03d0cb8e8500e58cacc1a0f27ce54c41a2937', 'pipeline': '8f28ef0f35d97142278f9dacb4e9d1ff082e470f'}, 'duration': 2.1196961402893066, 'iteration': 11, 'loss': 0.15471276229790154, 'max_history_score': 0.983625730994152, 'max_history_score_std': 0.025023500462379746, 'max_history_step': 'joint', 'pipeline': {'features': ('features_PCA', {'features__n_components': 1}), 'normalizer': ('normalizer_StandardScaler', {'normalizer__with_mean': True, 'normalizer__with_std': True}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 7})}, 'score': 0.8452872377020985, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'entropy', 'max_depth': 3, 'max_features': 1, 'max_leaf_nodes': 2, 'min_samples_split': 2, 'n_estimators': 25}, 'config_hash': {'algorithm': '59f64a966796648c7bebade1127fa05541b391ad', 'config': '2ab964abffa0a277a9e2ee9b5570cd258e428b62', 'pipeline': 'eef3f702fd2fed761fa6744c1640d0bf320f1d00'}, 'duration': 0.9828321933746338, 'iteration': 12, 'loss': 0.0778465772273822, 'max_history_score': 0.983625730994152, 'max_history_score_std': 0.025023500462379746, 'max_history_step': 'joint', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 3, 'features__selectkbest__k': 1}), 'normalizer': ('normalizer_PowerTransformer', {}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 6})}, 'score': 0.9221534227726178, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'gini', 'max_depth': 4, 'max_features': 2, 'max_leaf_nodes': 3, 'min_samples_split': 3, 'n_estimators': 75}, 'config_hash': {'algorithm': '6f75c2a196eb9836df2b424e095051192eaed6ea', 'config': '5c95db3ad238063227f1b36e6a006d70c834c5da', 'pipeline': '1eae01a1128bee425c4d4ca0ee97a9afd409680e'}, 'duration': 0.8217771053314209, 'iteration': 13, 'loss': 0.03863089095287242, 'max_history_score': 0.983625730994152, 'max_history_score_std': 0.025023500462379746, 'max_history_step': 'joint', 'pipeline': {'features': ('features_NoneType', {}), 'normalizer': ('normalizer_StandardScaler', {'normalizer__with_mean': False, 'normalizer__with_std': False}), 'rebalance': ('rebalance_NearMiss', {'rebalance__n_neighbors': 1})}, 'score': 0.9613691090471276, ...}], 'history_hash': ['2e6648b63441361b4398cb94f81d2e04a830b2ef', '584343bc020d2d7bc89bd0856bc7770dae1c84fc', 'de121d053e65def047cc8947f505578d5c5eab67', 'b21c9d15a389baa5bfea4c8ddcec129259f37540', 'edd3456355d80775739c31515c832ca7b4e5e094', '0800d7d2c8c10d2f9e7b4e5127b343e916eb742c', 'd98b641879b4754f2169335626a90575e945fd7c', '3f83df36a6abbdf7ea4a4bdcaf6727f23529c2bb', '037fd5c655b39cc7922fb394d736496befcc747b', '6609280032189b59de1afbe36f3acb1d5c273693', '8e1c17ac9f6e03740f380fccb833c9c3931ffc35', '87c03d0cb8e8500e58cacc1a0f27ce54c41a2937', '2ab964abffa0a277a9e2ee9b5570cd258e428b62', '5c95db3ad238063227f1b36e6a006d70c834c5da'], 'history_index': {'037fd5c655b39cc7922fb394d736496befcc747b': 8, '0800d7d2c8c10d2f9e7b4e5127b343e916eb742c': 5, '2ab964abffa0a277a9e2ee9b5570cd258e428b62': 12, '2e6648b63441361b4398cb94f81d2e04a830b2ef': 0, '3f83df36a6abbdf7ea4a4bdcaf6727f23529c2bb': 7, '584343bc020d2d7bc89bd0856bc7770dae1c84fc': 1, '5c95db3ad238063227f1b36e6a006d70c834c5da': 13, '6609280032189b59de1afbe36f3acb1d5c273693': 9, '87c03d0cb8e8500e58cacc1a0f27ce54c41a2937': 11, '8e1c17ac9f6e03740f380fccb833c9c3931ffc35': 10, ...}, 'iteration': 13, 'max_history_score': 0.983625730994152, 'max_history_score_std': 0.025023500462379746, 'max_history_step': 'joint'}
        config = {'algorithm': 'RandomForest', 'seed': 42, 'time': 300}
    114 
    115 
    116 def get_baseline_score(algorithm, X, y, seed):
    117     pipeline, _ = pipeline_conf_to_full_pipeline(

...........................................................................
/home/aquemy/dev/dp_hyperparameters/extension/experiment/objective.py in objective(pipeline_config={'features': ('features_PCA', {'features__n_components': 1}), 'normalizer': ('normalizer_RobustScaler', {'normalizer__quantile_range': (25.0, 75.0), 'normalizer__with_centering': False, 'normalizer__with_scaling': False}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 7})}, algo_config={'bootstrap': False, 'criterion': 'entropy', 'max_depth': 4, 'max_features': 2, 'max_leaf_nodes': 3, 'min_samples_split': 2, 'n_estimators': 25}, algorithm='RandomForest', X=array([[1.423e+01, 1.710e+00, 2.430e+00, ..., 1...., ..., 6.100e-01, 1.600e+00,
        5.600e+02]]), y=array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,
       2, 2]), context={'baseline_score': 0.9444100447196423, 'baseline_score_std': 0.04305547117084885, 'best_config': {'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': 2, 'max_features': 1, 'max_leaf_nodes': None, 'min_samples_split': 3, 'n_estimators': 75}, 'config_hash': {'algorithm': '42185be98371e99ac896d2c6c2d69c451cb983ff', 'config': '6609280032189b59de1afbe36f3acb1d5c273693', 'pipeline': '8aab2941fc84d84f86fa56134e50909dbf9e19f5'}, 'duration': 0.9665219783782959, 'iteration': 9, 'loss': 0.01637426900584804, 'max_history_score': 0.983625730994152, 'max_history_score_std': 0.025023500462379746, 'max_history_step': 'joint', 'pipeline': {'features': ('features_NoneType', {}), 'normalizer': ('normalizer_PowerTransformer', {}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 5})}, 'score': 0.983625730994152, ...}, 'history': [{'algorithm': {'bootstrap': False, 'criterion': 'entropy', 'max_depth': None, 'max_features': 3, 'max_leaf_nodes': 5, 'min_samples_split': 2, 'n_estimators': 50}, 'config_hash': {'algorithm': 'b2c6464add7a35ce8048653a39338c9994de9a4f', 'config': '2e6648b63441361b4398cb94f81d2e04a830b2ef', 'pipeline': '3d44d7482e468d08c4f94457a205f3dac74084c1'}, 'duration': 0.737678050994873, 'iteration': 0, 'loss': 1.0, 'max_history_score': 0.0, 'max_history_score_std': 0.0, 'max_history_step': 'baseline', 'pipeline': {'features': ('features_PCA', {'features__n_components': 1}), 'normalizer': ('normalizer_NoneType', {}), 'rebalance': ('rebalance_CondensedNearestNeighbour', {'rebalance__n_neighbors': 3})}, 'score': 0.0, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'gini', 'max_depth': 1, 'max_features': None, 'max_leaf_nodes': 2, 'min_samples_split': 3, 'n_estimators': 25}, 'config_hash': {'algorithm': '7f71bbbfdb4e8da52b6fc33a43224183117de15e', 'config': '584343bc020d2d7bc89bd0856bc7770dae1c84fc', 'pipeline': '466ffa7ace0e442beb7c311eb214b17a4c6832b3'}, 'duration': 1.5976769924163818, 'iteration': 1, 'loss': 0.40386351909184726, 'max_history_score': 0.5961364809081527, 'max_history_score_std': 0.05351463210025494, 'max_history_step': 'joint', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 3, 'features__selectkbest__k': 3}), 'normalizer': ('normalizer_StandardScaler', {'normalizer__with_mean': True, 'normalizer__with_std': True}), 'rebalance': ('rebalance_NearMiss', {'rebalance__n_neighbors': 2})}, 'score': 0.5961364809081527, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'entropy', 'max_depth': 1, 'max_features': 2, 'max_leaf_nodes': 2, 'min_samples_split': 5, 'n_estimators': 25}, 'config_hash': {'algorithm': '897745a20d929d43e760cacee0a764bd8070daa5', 'config': 'de121d053e65def047cc8947f505578d5c5eab67', 'pipeline': '63040b39b48626a8232e847e8327bdca5cd88611'}, 'duration': 0.815453052520752, 'iteration': 2, 'loss': 0.07327786377708967, 'max_history_score': 0.9267221362229103, 'max_history_score_std': 0.043920207373658794, 'max_history_step': 'joint', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 3, 'features__selectkbest__k': 2}), 'normalizer': ('normalizer_StandardScaler', {'normalizer__with_mean': True, 'normalizer__with_std': True}), 'rebalance': ('rebalance_NoneType', {})}, 'score': 0.9267221362229103, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'entropy', 'max_depth': 4, 'max_features': 3, 'max_leaf_nodes': None, 'min_samples_split': 2, 'n_estimators': 100}, 'config_hash': {'algorithm': 'dbd92c75280ec06b66ca4ad9b135cf36957031a4', 'config': 'b21c9d15a389baa5bfea4c8ddcec129259f37540', 'pipeline': '38866720d2f120c863351493b9b4e23b9a4506dc'}, 'duration': 1.2293269634246826, 'iteration': 3, 'loss': 0.07199862401100798, 'max_history_score': 0.928001375988992, 'max_history_score_std': 0.06518367535896959, 'max_history_step': 'joint', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 2, 'features__selectkbest__k': 4}), 'normalizer': ('normalizer_NoneType', {}), 'rebalance': ('rebalance_NoneType', {})}, 'score': 0.928001375988992, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': 2, 'max_features': None, 'max_leaf_nodes': None, 'min_samples_split': 5, 'n_estimators': 100}, 'config_hash': {'algorithm': 'f455eefd9fdd03ece88892c3f440c580bdf27ddb', 'config': 'edd3456355d80775739c31515c832ca7b4e5e094', 'pipeline': '1d1034f9f0871e43f896c1db4ed6fd572ed0a6ef'}, 'duration': 1.6186630725860596, 'iteration': 4, 'loss': 0.16651831785345705, 'max_history_score': 0.928001375988992, 'max_history_score_std': 0.06518367535896959, 'max_history_step': 'joint', 'pipeline': {'features': ('features_SelectKBest', {'features__k': 4}), 'normalizer': ('normalizer_MinMaxScaler', {}), 'rebalance': ('rebalance_CondensedNearestNeighbour', {'rebalance__n_neighbors': 1})}, 'score': 0.833481682146543, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'entropy', 'max_depth': 1, 'max_features': 2, 'max_leaf_nodes': None, 'min_samples_split': 2, 'n_estimators': 10}, 'config_hash': {'algorithm': '29906eaa0712a68ea145b12821d54ba445726fbf', 'config': '0800d7d2c8c10d2f9e7b4e5127b343e916eb742c', 'pipeline': '2e0f188ae61600352a7159285e0f542b4587a403'}, 'duration': 0.19410085678100586, 'iteration': 5, 'loss': 0.20164258685930514, 'max_history_score': 0.928001375988992, 'max_history_score_std': 0.06518367535896959, 'max_history_step': 'joint', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 3, 'features__selectkbest__k': 4}), 'normalizer': ('normalizer_StandardScaler', {'normalizer__with_mean': True, 'normalizer__with_std': False}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 7})}, 'score': 0.7983574131406949, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': 1, 'max_features': 1, 'max_leaf_nodes': 5, 'min_samples_split': 2, 'n_estimators': 25}, 'config_hash': {'algorithm': 'fbb7d57e38cfc08240f0af985282da418cb33556', 'config': 'd98b641879b4754f2169335626a90575e945fd7c', 'pipeline': '62463de065924498cdcd2f2f1f7e68535cdb33a5'}, 'duration': 0.3625810146331787, 'iteration': 6, 'loss': 0.14327485380116955, 'max_history_score': 0.928001375988992, 'max_history_score_std': 0.06518367535896959, 'max_history_step': 'joint', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 1, 'features__selectkbest__k': 2}), 'normalizer': ('normalizer_NoneType', {}), 'rebalance': ('rebalance_NoneType', {})}, 'score': 0.8567251461988304, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'entropy', 'max_depth': 3, 'max_features': 1, 'max_leaf_nodes': None, 'min_samples_split': 2, 'n_estimators': 75}, 'config_hash': {'algorithm': 'fb2f5d4c4d636edac929e1454ce3d02a4fb134c1', 'config': '3f83df36a6abbdf7ea4a4bdcaf6727f23529c2bb', 'pipeline': '8377b93e334656d1a93d266493b58ef9a6a1786f'}, 'duration': 0.8223779201507568, 'iteration': 7, 'loss': 0.03921568627450989, 'max_history_score': 0.9607843137254901, 'max_history_score_std': 0.043526663832084804, 'max_history_step': 'joint', 'pipeline': {'features': ('features_PCA', {'features__n_components': 3}), 'normalizer': ('normalizer_MinMaxScaler', {}), 'rebalance': ('rebalance_NearMiss', {'rebalance__n_neighbors': 1})}, 'score': 0.9607843137254901, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'gini', 'max_depth': 3, 'max_features': 3, 'max_leaf_nodes': 2, 'min_samples_split': 2, 'n_estimators': 100}, 'config_hash': {'algorithm': '3c3fde6559b918694de4668d025d5418342db1b1', 'config': '037fd5c655b39cc7922fb394d736496befcc747b', 'pipeline': '2a5032814c6c7ed21dd5bd9686923d7fc2f8acc9'}, 'duration': 1.0435099601745605, 'iteration': 8, 'loss': 0.09955925352597172, 'max_history_score': 0.9607843137254901, 'max_history_score_std': 0.043526663832084804, 'max_history_step': 'joint', 'pipeline': {'features': ('features_NoneType', {}), 'normalizer': ('normalizer_RobustScaler', {'normalizer__quantile_range': (...), 'normalizer__with_centering': True, 'normalizer__with_scaling': True}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 7})}, 'score': 0.9004407464740283, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': 2, 'max_features': 1, 'max_leaf_nodes': None, 'min_samples_split': 3, 'n_estimators': 75}, 'config_hash': {'algorithm': '42185be98371e99ac896d2c6c2d69c451cb983ff', 'config': '6609280032189b59de1afbe36f3acb1d5c273693', 'pipeline': '8aab2941fc84d84f86fa56134e50909dbf9e19f5'}, 'duration': 0.9665219783782959, 'iteration': 9, 'loss': 0.01637426900584804, 'max_history_score': 0.983625730994152, 'max_history_score_std': 0.025023500462379746, 'max_history_step': 'joint', 'pipeline': {'features': ('features_NoneType', {}), 'normalizer': ('normalizer_PowerTransformer', {}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 5})}, 'score': 0.983625730994152, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': 1, 'max_features': 3, 'max_leaf_nodes': 2, 'min_samples_split': 3, 'n_estimators': 10}, 'config_hash': {'algorithm': '62a9fe705e4cd96e762bcc9543c4a456a5a9f188', 'config': '8e1c17ac9f6e03740f380fccb833c9c3931ffc35', 'pipeline': '3d44d7482e468d08c4f94457a205f3dac74084c1'}, 'duration': 0.46930503845214844, 'iteration': 10, 'loss': 1.0, 'max_history_score': 0.983625730994152, 'max_history_score_std': 0.025023500462379746, 'max_history_step': 'joint', 'pipeline': {'features': ('features_PCA', {'features__n_components': 1}), 'normalizer': ('normalizer_NoneType', {}), 'rebalance': ('rebalance_CondensedNearestNeighbour', {'rebalance__n_neighbors': 3})}, 'score': 0.0, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'gini', 'max_depth': 4, 'max_features': 1, 'max_leaf_nodes': 3, 'min_samples_split': 2, 'n_estimators': 100}, 'config_hash': {'algorithm': '086d6ca939a757bb32edb113a567f9d38744f061', 'config': '87c03d0cb8e8500e58cacc1a0f27ce54c41a2937', 'pipeline': '8f28ef0f35d97142278f9dacb4e9d1ff082e470f'}, 'duration': 2.1196961402893066, 'iteration': 11, 'loss': 0.15471276229790154, 'max_history_score': 0.983625730994152, 'max_history_score_std': 0.025023500462379746, 'max_history_step': 'joint', 'pipeline': {'features': ('features_PCA', {'features__n_components': 1}), 'normalizer': ('normalizer_StandardScaler', {'normalizer__with_mean': True, 'normalizer__with_std': True}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 7})}, 'score': 0.8452872377020985, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'entropy', 'max_depth': 3, 'max_features': 1, 'max_leaf_nodes': 2, 'min_samples_split': 2, 'n_estimators': 25}, 'config_hash': {'algorithm': '59f64a966796648c7bebade1127fa05541b391ad', 'config': '2ab964abffa0a277a9e2ee9b5570cd258e428b62', 'pipeline': 'eef3f702fd2fed761fa6744c1640d0bf320f1d00'}, 'duration': 0.9828321933746338, 'iteration': 12, 'loss': 0.0778465772273822, 'max_history_score': 0.983625730994152, 'max_history_score_std': 0.025023500462379746, 'max_history_step': 'joint', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 3, 'features__selectkbest__k': 1}), 'normalizer': ('normalizer_PowerTransformer', {}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 6})}, 'score': 0.9221534227726178, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'gini', 'max_depth': 4, 'max_features': 2, 'max_leaf_nodes': 3, 'min_samples_split': 3, 'n_estimators': 75}, 'config_hash': {'algorithm': '6f75c2a196eb9836df2b424e095051192eaed6ea', 'config': '5c95db3ad238063227f1b36e6a006d70c834c5da', 'pipeline': '1eae01a1128bee425c4d4ca0ee97a9afd409680e'}, 'duration': 0.8217771053314209, 'iteration': 13, 'loss': 0.03863089095287242, 'max_history_score': 0.983625730994152, 'max_history_score_std': 0.025023500462379746, 'max_history_step': 'joint', 'pipeline': {'features': ('features_NoneType', {}), 'normalizer': ('normalizer_StandardScaler', {'normalizer__with_mean': False, 'normalizer__with_std': False}), 'rebalance': ('rebalance_NearMiss', {'rebalance__n_neighbors': 1})}, 'score': 0.9613691090471276, ...}], 'history_hash': ['2e6648b63441361b4398cb94f81d2e04a830b2ef', '584343bc020d2d7bc89bd0856bc7770dae1c84fc', 'de121d053e65def047cc8947f505578d5c5eab67', 'b21c9d15a389baa5bfea4c8ddcec129259f37540', 'edd3456355d80775739c31515c832ca7b4e5e094', '0800d7d2c8c10d2f9e7b4e5127b343e916eb742c', 'd98b641879b4754f2169335626a90575e945fd7c', '3f83df36a6abbdf7ea4a4bdcaf6727f23529c2bb', '037fd5c655b39cc7922fb394d736496befcc747b', '6609280032189b59de1afbe36f3acb1d5c273693', '8e1c17ac9f6e03740f380fccb833c9c3931ffc35', '87c03d0cb8e8500e58cacc1a0f27ce54c41a2937', '2ab964abffa0a277a9e2ee9b5570cd258e428b62', '5c95db3ad238063227f1b36e6a006d70c834c5da'], 'history_index': {'037fd5c655b39cc7922fb394d736496befcc747b': 8, '0800d7d2c8c10d2f9e7b4e5127b343e916eb742c': 5, '2ab964abffa0a277a9e2ee9b5570cd258e428b62': 12, '2e6648b63441361b4398cb94f81d2e04a830b2ef': 0, '3f83df36a6abbdf7ea4a4bdcaf6727f23529c2bb': 7, '584343bc020d2d7bc89bd0856bc7770dae1c84fc': 1, '5c95db3ad238063227f1b36e6a006d70c834c5da': 13, '6609280032189b59de1afbe36f3acb1d5c273693': 9, '87c03d0cb8e8500e58cacc1a0f27ce54c41a2937': 11, '8e1c17ac9f6e03740f380fccb833c9c3931ffc35': 10, ...}, 'iteration': 13, 'max_history_score': 0.983625730994152, 'max_history_score_std': 0.025023500462379746, 'max_history_step': 'joint'}, config={'algorithm': 'RandomForest', 'seed': 42, 'time': 300}, step='joint')
     45                 y,
     46                 cv=10,
     47                 n_jobs=-1,
     48                 return_estimator=False,
     49                 return_train_score=False,
---> 50                 verbose=0)
     51         score = np.mean(scores['test_score'])
     52         std = np.std(scores['test_score'])
     53         status = STATUS_OK
     54     except Exception as e:

...........................................................................
/home/aquemy/.local/lib/python2.7/site-packages/sklearn/model_selection/_validation.py in cross_validate(estimator=Pipeline(memory=None,
     steps=[('rebalance', ...e=42,
            verbose=0, warm_start=False))]), X=array([[1.423e+01, 1.710e+00, 2.430e+00, ..., 1...., ..., 6.100e-01, 1.600e+00,
        5.600e+02]]), y=array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,
       2, 2]), groups=None, scoring=None, cv=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1, verbose=0, fit_params=None, pre_dispatch='2*n_jobs', return_train_score=False, return_estimator=False, error_score='raise-deprecating')
    235         delayed(_fit_and_score)(
    236             clone(estimator), X, y, scorers, train, test, verbose, None,
    237             fit_params, return_train_score=return_train_score,
    238             return_times=True, return_estimator=return_estimator,
    239             error_score=error_score)
--> 240         for train, test in cv.split(X, y, groups))
        cv.split = <bound method StratifiedKFold.split of Stratifie...d(n_splits=10, random_state=None, shuffle=False)>
        X = array([[1.423e+01, 1.710e+00, 2.430e+00, ..., 1...., ..., 6.100e-01, 1.600e+00,
        5.600e+02]])
        y = array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,
       2, 2])
        groups = None
    241 
    242     zipped_scores = list(zip(*scores))
    243     if return_train_score:
    244         train_scores = zipped_scores.pop(0)

...........................................................................
/home/aquemy/.local/lib/python2.7/site-packages/sklearn/externals/joblib/parallel.py in __call__(self=Parallel(n_jobs=-1), iterable=<generator object <genexpr>>)
    925                 # No need to wait for async callbacks to trigger to
    926                 # consumption.
    927                 self._iterating = False
    928 
    929             with self._backend.retrieval_context():
--> 930                 self.retrieve()
        self.retrieve = <bound method Parallel.retrieve of Parallel(n_jobs=-1)>
    931             # Make sure that we get a last message telling us we are done
    932             elapsed_time = time.time() - self._start_time
    933             self._print('Done %3i out of %3i | elapsed: %s finished',
    934                         (len(self._output), len(self._output),

---------------------------------------------------------------------------
Joblib worker traceback:
---------------------------------------------------------------------------
ValueError                                         Mon Jun 17 12:45:27 2019
PID: 15114                                  Python 2.7.15+: /usr/bin/python
...........................................................................
/home/aquemy/.local/lib/python2.7/site-packages/sklearn/externals/joblib/parallel.py in __call__(self=<sklearn.externals.joblib.parallel.BatchedCalls object>)
    220     def __call__(self):
    221         # Set the default nested backend to self._backend but do not set the
    222         # change the default number of processes to -1
    223         with parallel_backend(self._backend, n_jobs=self._n_jobs):
    224             return [func(*args, **kwargs)
--> 225                     for func, args, kwargs in self.items]
        func = <function _fit_and_score>
        args = (Pipeline(memory=None,
     steps=[('rebalance', ...e=42,
            verbose=0, warm_start=False))]), array([[1.423e+01, 1.710e+00, 2.430e+00, ..., 1...., ..., 6.100e-01, 1.600e+00,
        5.600e+02]]), array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,
       2, 2]), {'score': <function _passthrough_scorer>}, array([  6,   7,   8,   9,  10,  11,  12,  13,  ..., 170, 171, 172, 173, 174,
       175, 176, 177]), array([  0,   1,   2,   3,   4,   5,  59,  60,  ...,  64,  65,
        66, 130, 131, 132, 133, 134]), 0, None, None)
        kwargs = {'error_score': 'raise-deprecating', 'return_estimator': False, 'return_times': True, 'return_train_score': False}
        self.items = [(<function _fit_and_score>, (Pipeline(memory=None,
     steps=[('rebalance', ...e=42,
            verbose=0, warm_start=False))]), array([[1.423e+01, 1.710e+00, 2.430e+00, ..., 1...., ..., 6.100e-01, 1.600e+00,
        5.600e+02]]), array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,
       2, 2]), {'score': <function _passthrough_scorer>}, array([  6,   7,   8,   9,  10,  11,  12,  13,  ..., 170, 171, 172, 173, 174,
       175, 176, 177]), array([  0,   1,   2,   3,   4,   5,  59,  60,  ...,  64,  65,
        66, 130, 131, 132, 133, 134]), 0, None, None), {'error_score': 'raise-deprecating', 'return_estimator': False, 'return_times': True, 'return_train_score': False})]
    226 
    227     def __len__(self):
    228         return self._size
    229 

...........................................................................
/home/aquemy/.local/lib/python2.7/site-packages/sklearn/model_selection/_validation.py in _fit_and_score(estimator=Pipeline(memory=None,
     steps=[('rebalance', ...e=42,
            verbose=0, warm_start=False))]), X=array([[1.423e+01, 1.710e+00, 2.430e+00, ..., 1...., ..., 6.100e-01, 1.600e+00,
        5.600e+02]]), y=array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,
       2, 2]), scorer={'score': <function _passthrough_scorer>}, train=array([  6,   7,   8,   9,  10,  11,  12,  13,  ..., 170, 171, 172, 173, 174,
       175, 176, 177]), test=array([  0,   1,   2,   3,   4,   5,  59,  60,  ...,  64,  65,
        66, 130, 131, 132, 133, 134]), verbose=0, parameters=None, fit_params={}, return_train_score=False, return_parameters=False, return_n_test_samples=False, return_times=True, return_estimator=False, error_score='raise-deprecating')
    523 
    524     try:
    525         if y_train is None:
    526             estimator.fit(X_train, **fit_params)
    527         else:
--> 528             estimator.fit(X_train, y_train, **fit_params)
        estimator.fit = <bound method Pipeline.fit of Pipeline(memory=No...=42,
            verbose=0, warm_start=False))])>
        X_train = array([[1.439e+01, 1.870e+00, 2.450e+00, ..., 1...., ..., 6.100e-01, 1.600e+00,
        5.600e+02]])
        y_train = array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...2, 2, 2, 2, 2, 2, 2, 2, 2,
       2, 2, 2, 2, 2])
        fit_params = {}
    529 
    530     except Exception as e:
    531         # Note fit time as time until error
    532         fit_time = time.time() - start_time

...........................................................................
/usr/local/lib/python2.7/dist-packages/imblearn/pipeline.py in fit(self=Pipeline(memory=None,
     steps=[('rebalance', ...e=42,
            verbose=0, warm_start=False))]), X=array([[1.439e+01, 1.870e+00, 2.450e+00, ..., 1...., ..., 6.100e-01, 1.600e+00,
        5.600e+02]]), y=array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...2, 2, 2, 2, 2, 2, 2, 2, 2,
       2, 2, 2, 2, 2]), **fit_params={})
    234             This estimator
    235 
    236         """
    237         Xt, yt, fit_params = self._fit(X, y, **fit_params)
    238         if self._final_estimator is not None:
--> 239             self._final_estimator.fit(Xt, yt, **fit_params)
        self._final_estimator.fit = <bound method RandomForestClassifier.fit of Rand...ate=42,
            verbose=0, warm_start=False)>
        Xt = array([[ 533.23988139],
       [ 538.62826221],
...
       [ -11.83393839],
       [ -81.26189607]])
        yt = array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...2,
       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2])
        fit_params = {}
    240         return self
    241 
    242     def fit_transform(self, X, y=None, **fit_params):
    243         """Fit the model and transform with the final estimator

...........................................................................
/home/aquemy/.local/lib/python2.7/site-packages/sklearn/ensemble/forest.py in fit(self=RandomForestClassifier(bootstrap=False, class_we...tate=42,
            verbose=0, warm_start=False), X=array([[ 533.23987  ],
       [ 538.62823  ],
  ....833939 ],
       [ -81.261894 ]], dtype=float32), y=array([[0.],
       [0.],
       [0.],
       [0...    [2.],
       [2.],
       [2.],
       [2.]]), sample_weight=None)
    328             trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,
    329                              **_joblib_parallel_args(prefer='threads'))(
    330                 delayed(_parallel_build_trees)(
    331                     t, self, X, y, sample_weight, i, len(trees),
    332                     verbose=self.verbose, class_weight=self.class_weight)
--> 333                 for i, t in enumerate(trees))
        i = 24
    334 
    335             # Collect newly grown trees
    336             self.estimators_.extend(trees)
    337 

...........................................................................
/home/aquemy/.local/lib/python2.7/site-packages/sklearn/externals/joblib/parallel.py in __call__(self=Parallel(n_jobs=1), iterable=<generator object <genexpr>>)
    912             # self._original_iterator is None, then this means either
    913             # that pre_dispatch == "all", n_jobs == 1 or that the first batch
    914             # was very quick and its callback already dispatched all the
    915             # remaining jobs.
    916             self._iterating = False
--> 917             if self.dispatch_one_batch(iterator):
        self.dispatch_one_batch = <bound method Parallel.dispatch_one_batch of Parallel(n_jobs=1)>
        iterator = <generator object <genexpr>>
    918                 self._iterating = self._original_iterator is not None
    919 
    920             while self.dispatch_one_batch(iterator):
    921                 pass

...........................................................................
/home/aquemy/.local/lib/python2.7/site-packages/sklearn/externals/joblib/parallel.py in dispatch_one_batch(self=Parallel(n_jobs=1), iterator=<generator object <genexpr>>)
    754                                  self._pickle_cache)
    755             if len(tasks) == 0:
    756                 # No more tasks available in the iterator: tell caller to stop.
    757                 return False
    758             else:
--> 759                 self._dispatch(tasks)
        self._dispatch = <bound method Parallel._dispatch of Parallel(n_jobs=1)>
        tasks = <sklearn.externals.joblib.parallel.BatchedCalls object>
    760                 return True
    761 
    762     def _print(self, msg, msg_args):
    763         """Display the message on stout or stderr depending on verbosity"""

...........................................................................
/home/aquemy/.local/lib/python2.7/site-packages/sklearn/externals/joblib/parallel.py in _dispatch(self=Parallel(n_jobs=1), batch=<sklearn.externals.joblib.parallel.BatchedCalls object>)
    711 
    712         dispatch_timestamp = time.time()
    713         cb = BatchCompletionCallBack(dispatch_timestamp, len(batch), self)
    714         with self._lock:
    715             job_idx = len(self._jobs)
--> 716             job = self._backend.apply_async(batch, callback=cb)
        job = undefined
        self._backend.apply_async = <bound method SequentialBackend.apply_async of <...lib._parallel_backends.SequentialBackend object>>
        batch = <sklearn.externals.joblib.parallel.BatchedCalls object>
        cb = <sklearn.externals.joblib.parallel.BatchCompletionCallBack object>
    717             # A job can complete so quickly than its callback is
    718             # called before we get here, causing self._jobs to
    719             # grow. To ensure correct results ordering, .insert is
    720             # used (rather than .append) in the following line

...........................................................................
/home/aquemy/.local/lib/python2.7/site-packages/sklearn/externals/joblib/_parallel_backends.py in apply_async(self=<sklearn.externals.joblib._parallel_backends.SequentialBackend object>, func=<sklearn.externals.joblib.parallel.BatchedCalls object>, callback=<sklearn.externals.joblib.parallel.BatchCompletionCallBack object>)
    177             raise ValueError('n_jobs == 0 in Parallel has no meaning')
    178         return 1
    179 
    180     def apply_async(self, func, callback=None):
    181         """Schedule a func to be run"""
--> 182         result = ImmediateResult(func)
        result = undefined
        func = <sklearn.externals.joblib.parallel.BatchedCalls object>
    183         if callback:
    184             callback(result)
    185         return result
    186 

...........................................................................
/home/aquemy/.local/lib/python2.7/site-packages/sklearn/externals/joblib/_parallel_backends.py in __init__(self=<sklearn.externals.joblib._parallel_backends.ImmediateResult object>, batch=<sklearn.externals.joblib.parallel.BatchedCalls object>)
    544 
    545 class ImmediateResult(object):
    546     def __init__(self, batch):
    547         # Don't delay the application, to avoid keeping the input
    548         # arguments in memory
--> 549         self.results = batch()
        self.results = undefined
        batch = <sklearn.externals.joblib.parallel.BatchedCalls object>
    550 
    551     def get(self):
    552         return self.results
    553 

...........................................................................
/home/aquemy/.local/lib/python2.7/site-packages/sklearn/externals/joblib/parallel.py in __call__(self=<sklearn.externals.joblib.parallel.BatchedCalls object>)
    220     def __call__(self):
    221         # Set the default nested backend to self._backend but do not set the
    222         # change the default number of processes to -1
    223         with parallel_backend(self._backend, n_jobs=self._n_jobs):
    224             return [func(*args, **kwargs)
--> 225                     for func, args, kwargs in self.items]
        func = <function _parallel_build_trees>
        args = (DecisionTreeClassifier(class_weight=None, criter...=False, random_state=1608637542, splitter='best'), RandomForestClassifier(bootstrap=False, class_we...tate=42,
            verbose=0, warm_start=False), array([[ 533.23987  ],
       [ 538.62823  ],
  ....833939 ],
       [ -81.261894 ]], dtype=float32), array([[0.],
       [0.],
       [0.],
       [0...    [2.],
       [2.],
       [2.],
       [2.]]), None, 0, 25)
        kwargs = {'class_weight': None, 'verbose': 0}
        self.items = [(<function _parallel_build_trees>, (DecisionTreeClassifier(class_weight=None, criter...=False, random_state=1608637542, splitter='best'), RandomForestClassifier(bootstrap=False, class_we...tate=42,
            verbose=0, warm_start=False), array([[ 533.23987  ],
       [ 538.62823  ],
  ....833939 ],
       [ -81.261894 ]], dtype=float32), array([[0.],
       [0.],
       [0.],
       [0...    [2.],
       [2.],
       [2.],
       [2.]]), None, 0, 25), {'class_weight': None, 'verbose': 0})]
    226 
    227     def __len__(self):
    228         return self._size
    229 

...........................................................................
/home/aquemy/.local/lib/python2.7/site-packages/sklearn/ensemble/forest.py in _parallel_build_trees(tree=DecisionTreeClassifier(class_weight=None, criter...=False, random_state=1608637542, splitter='best'), forest=RandomForestClassifier(bootstrap=False, class_we...tate=42,
            verbose=0, warm_start=False), X=array([[ 533.23987  ],
       [ 538.62823  ],
  ....833939 ],
       [ -81.261894 ]], dtype=float32), y=array([[0.],
       [0.],
       [0.],
       [0...    [2.],
       [2.],
       [2.],
       [2.]]), sample_weight=None, tree_idx=0, n_trees=25, verbose=0, class_weight=None)
    116         elif class_weight == 'balanced_subsample':
    117             curr_sample_weight *= compute_sample_weight('balanced', y, indices)
    118 
    119         tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)
    120     else:
--> 121         tree.fit(X, y, sample_weight=sample_weight, check_input=False)
        tree.fit = <bound method DecisionTreeClassifier.fit of Deci...False, random_state=1608637542, splitter='best')>
        X = array([[ 533.23987  ],
       [ 538.62823  ],
  ....833939 ],
       [ -81.261894 ]], dtype=float32)
        y = array([[0.],
       [0.],
       [0.],
       [0...    [2.],
       [2.],
       [2.],
       [2.]])
        sample_weight = None
    122 
    123     return tree
    124 
    125 

...........................................................................
/home/aquemy/.local/lib/python2.7/site-packages/sklearn/tree/tree.py in fit(self=DecisionTreeClassifier(class_weight=None, criter...=False, random_state=1608637542, splitter='best'), X=array([[ 533.23987  ],
       [ 538.62823  ],
  ....833939 ],
       [ -81.261894 ]], dtype=float32), y=array([[0.],
       [0.],
       [0.],
       [0...    [2.],
       [2.],
       [2.],
       [2.]]), sample_weight=None, check_input=False, X_idx_sorted=None)
    796 
    797         super(DecisionTreeClassifier, self).fit(
    798             X, y,
    799             sample_weight=sample_weight,
    800             check_input=check_input,
--> 801             X_idx_sorted=X_idx_sorted)
        X_idx_sorted = None
    802         return self
    803 
    804     def predict_proba(self, X, check_input=True):
    805         """Predict class probabilities of the input samples X.

...........................................................................
/home/aquemy/.local/lib/python2.7/site-packages/sklearn/tree/tree.py in fit(self=DecisionTreeClassifier(class_weight=None, criter...=False, random_state=1608637542, splitter='best'), X=array([[ 533.23987  ],
       [ 538.62823  ],
  ....833939 ],
       [ -81.261894 ]], dtype=float32), y=array([[0.],
       [0.],
       [0.],
       [0...    [2.],
       [2.],
       [2.],
       [2.]]), sample_weight=None, check_input=False, X_idx_sorted=None)
    237         if not 0 <= self.min_weight_fraction_leaf <= 0.5:
    238             raise ValueError("min_weight_fraction_leaf must in [0, 0.5]")
    239         if max_depth <= 0:
    240             raise ValueError("max_depth must be greater than zero. ")
    241         if not (0 < max_features <= self.n_features_):
--> 242             raise ValueError("max_features must be in (0, n_features]")
    243         if not isinstance(max_leaf_nodes, (numbers.Integral, np.integer)):
    244             raise ValueError("max_leaf_nodes must be integral number but was "
    245                              "%r" % max_leaf_nodes)
    246         if -1 < max_leaf_nodes < 2:

ValueError: max_features must be in (0, n_features]
___________________________________________________________________________
Best score: 0.983625730994 (0.0250235004624) [J] | Score: 0.0 (0.0) [J]
Best score: 0.988888888889 (0.0222222222222) [J] | Score: 0.988888888889 (0.0222222222222) [J]
JoblibValueError
___________________________________________________________________________
...........................................................................
/home/aquemy/dev/dp_hyperparameters/extension/main.py in <module>()
     27 
     28     serializer.serialize_results(scenario, policy)
     29 
     30 if __name__ == "__main__":
     31     args = cli.parse_args()
---> 32     main(args)

...........................................................................
/home/aquemy/dev/dp_hyperparameters/extension/main.py in main(args=Namespace(customize=[(['control', 'seed'], '42')...io='./scenarios/rf_wine_joint.yaml', verbosity=0))
     21         test_size=0.4, 
     22         random_state=scenario['control']['seed']
     23     )
     24 
     25     policy = policies.initiate(scenario['setup']['policy'], config)
---> 26     policy.run(X,y)
        policy.run = <bound method Joint.run of <experiment.policies.joint.Joint object>>
        X = array([[1.423e+01, 1.710e+00, 2.430e+00, ..., 1...., ..., 6.100e-01, 1.600e+00,
        5.600e+02]])
        y = array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,
       2, 2])
     27 
     28     serializer.serialize_results(scenario, policy)
     29 
     30 if __name__ == "__main__":

...........................................................................
/home/aquemy/dev/dp_hyperparameters/extension/experiment/policies/joint.py in run(self=<experiment.policies.joint.Joint object>, X=array([[1.423e+01, 1.710e+00, 2.430e+00, ..., 1...., ..., 6.100e-01, 1.600e+00,
        5.600e+02]]), y=array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,
       2, 2]))
     32             algo=tpe.suggest, 
     33             max_evals=None,
     34             max_time=self.config['time'],     
     35             trials=trials,
     36             show_progressbar=False,
---> 37             verbose=0
     38         )
     39 
     40         best_config = self.context['best_config']
     41         super(Joint, self).display_step_results(best_config)

...........................................................................
/home/aquemy/dev/dp_hyperparameters/extension/hyperopt/fmin.py in fmin(fn=<functools.partial object>, space={'algorithm': {'bootstrap': <hyperopt.pyll.base.Apply object>, 'criterion': <hyperopt.pyll.base.Apply object>, 'max_depth': <hyperopt.pyll.base.Apply object>, 'max_features': <hyperopt.pyll.base.Apply object>, 'max_leaf_nodes': <hyperopt.pyll.base.Apply object>, 'min_samples_split': <hyperopt.pyll.base.Apply object>, 'n_estimators': <hyperopt.pyll.base.Apply object>}, 'pipeline': {'features': <hyperopt.pyll.base.Apply object>, 'normalizer': <hyperopt.pyll.base.Apply object>, 'rebalance': <hyperopt.pyll.base.Apply object>}}, algo=<function suggest>, max_evals=9223372036854775807, max_time=300, trials=<hyperopt.base.Trials object>, rstate=<mtrand.RandomState object>, allow_trials_fmin=True, pass_expr_memo_ctrl=None, catch_eval_exceptions=False, verbose=0, return_argmin=True, points_to_evaluate=None, max_queue_len=1, show_progressbar=False)
    406             pass_expr_memo_ctrl=pass_expr_memo_ctrl,
    407             verbose=verbose,
    408             catch_eval_exceptions=catch_eval_exceptions,
    409             return_argmin=return_argmin,
    410             show_progressbar=show_progressbar,
--> 411             max_time=max_time
        max_time = 300
    412         )
    413 
    414     if trials is None:
    415         if points_to_evaluate is None:

...........................................................................
/home/aquemy/dev/dp_hyperparameters/extension/hyperopt/base.py in fmin(self=<hyperopt.base.Trials object>, fn=<functools.partial object>, space={'algorithm': {'bootstrap': <hyperopt.pyll.base.Apply object>, 'criterion': <hyperopt.pyll.base.Apply object>, 'max_depth': <hyperopt.pyll.base.Apply object>, 'max_features': <hyperopt.pyll.base.Apply object>, 'max_leaf_nodes': <hyperopt.pyll.base.Apply object>, 'min_samples_split': <hyperopt.pyll.base.Apply object>, 'n_estimators': <hyperopt.pyll.base.Apply object>}, 'pipeline': {'features': <hyperopt.pyll.base.Apply object>, 'normalizer': <hyperopt.pyll.base.Apply object>, 'rebalance': <hyperopt.pyll.base.Apply object>}}, algo=<function suggest>, max_evals=9223372036854775807, max_time=300, rstate=<mtrand.RandomState object>, verbose=0, pass_expr_memo_ctrl=None, catch_eval_exceptions=False, return_argmin=True, show_progressbar=False)
    636             verbose=verbose,
    637             allow_trials_fmin=False,  # -- prevent recursion
    638             pass_expr_memo_ctrl=pass_expr_memo_ctrl,
    639             catch_eval_exceptions=catch_eval_exceptions,
    640             return_argmin=return_argmin,
--> 641             show_progressbar=show_progressbar)
        show_progressbar = False
    642 
    643 
    644 def trials_from_docs(docs, validate=True, **kwargs):
    645     """Construct a Trials base class instance from a list of trials documents

...........................................................................
/home/aquemy/dev/dp_hyperparameters/extension/hyperopt/fmin.py in fmin(fn=<functools.partial object>, space={'algorithm': {'bootstrap': <hyperopt.pyll.base.Apply object>, 'criterion': <hyperopt.pyll.base.Apply object>, 'max_depth': <hyperopt.pyll.base.Apply object>, 'max_features': <hyperopt.pyll.base.Apply object>, 'max_leaf_nodes': <hyperopt.pyll.base.Apply object>, 'min_samples_split': <hyperopt.pyll.base.Apply object>, 'n_estimators': <hyperopt.pyll.base.Apply object>}, 'pipeline': {'features': <hyperopt.pyll.base.Apply object>, 'normalizer': <hyperopt.pyll.base.Apply object>, 'rebalance': <hyperopt.pyll.base.Apply object>}}, algo=<function suggest>, max_evals=9223372036854775807, max_time=300, trials=<hyperopt.base.Trials object>, rstate=<mtrand.RandomState object>, allow_trials_fmin=False, pass_expr_memo_ctrl=None, catch_eval_exceptions=False, verbose=0, return_argmin=True, points_to_evaluate=None, max_queue_len=1, show_progressbar=False)
    426                     verbose=verbose,
    427                     max_queue_len=max_queue_len,
    428                     show_progressbar=show_progressbar,
    429                     max_time=max_time)
    430     rval.catch_eval_exceptions = catch_eval_exceptions
--> 431     rval.exhaust()
        rval.exhaust = <bound method FMinIter.exhaust of <hyperopt.fmin.FMinIter object>>
    432     if return_argmin:
    433         return trials.argmin
    434     elif len(trials) > 0:
    435         # Only if there are some succesfull trail runs, return the best point in the evaluation space

...........................................................................
/home/aquemy/dev/dp_hyperparameters/extension/hyperopt/fmin.py in exhaust(self=<hyperopt.fmin.FMinIter object>)
    273             raise StopIteration()
    274         return self.trials
    275 
    276     def exhaust(self):
    277         n_done = len(self.trials)
--> 278         self.run(self.max_evals - n_done, block_until_done=self.asynchronous)
        self.run = <bound method FMinIter.run of <hyperopt.fmin.FMinIter object>>
        self.max_evals = 9223372036854775807
        n_done = 0
        self.asynchronous = False
    279         self.trials.refresh()
    280         return self
    281 
    282 

...........................................................................
/home/aquemy/dev/dp_hyperparameters/extension/hyperopt/fmin.py in run(self=<hyperopt.fmin.FMinIter object>, N=9223372036854775807, block_until_done=False)
    232                     if self.asynchronous:
    233                         # -- wait for workers to fill in the trials
    234                         time.sleep(self.poll_interval_secs)
    235                     else:
    236                         # -- loop over trials and do the jobs directly
--> 237                         self.serial_evaluate()
        self.serial_evaluate = <bound method FMinIter.serial_evaluate of <hyperopt.fmin.FMinIter object>>
    238                     try:
    239                         res = [d['result']['loss'] for d in
    240                                          self.trials.trials if
    241                                          d['result']['status'] == 'ok']

...........................................................................
/home/aquemy/dev/dp_hyperparameters/extension/hyperopt/fmin.py in serial_evaluate(self=<hyperopt.fmin.FMinIter object>, N=-1)
    138                 trial['book_time'] = now
    139                 trial['refresh_time'] = now
    140                 spec = base.spec_from_misc(trial['misc'])
    141                 ctrl = base.Ctrl(self.trials, current_trial=trial)
    142                 try:
--> 143                     result = self.domain.evaluate(spec, ctrl)
        result = undefined
        self.domain.evaluate = <bound method Domain.evaluate of <hyperopt.base.Domain object>>
        spec = {'bootstrap': 0, 'criterion': 1, 'features': 1, 'features_PCA_features__n_components': 0, 'max_depth': 4, 'max_features': 2, 'max_leaf_nodes': 3, 'min_samples_split': 0, 'n_estimators': 4, 'normalizer': 2, ...}
        ctrl = <hyperopt.base.Ctrl object>
    144                 except Exception as e:
    145                     logger.info('job exception: %s' % str(e))
    146                     trial['state'] = base.JOB_STATE_ERROR
    147                     trial['misc']['error'] = (str(type(e)), str(e))

...........................................................................
/home/aquemy/dev/dp_hyperparameters/extension/hyperopt/base.py in evaluate(self=<hyperopt.base.Domain object>, config={'bootstrap': 0, 'criterion': 1, 'features': 1, 'features_PCA_features__n_components': 0, 'max_depth': 4, 'max_features': 2, 'max_leaf_nodes': 3, 'min_samples_split': 0, 'n_estimators': 4, 'normalizer': 2, ...}, ctrl=<hyperopt.base.Ctrl object>, attach_attachments=True)
    841             #    or the normal Python part (self.fn)
    842             pyll_rval = pyll.rec_eval(
    843                 self.expr,
    844                 memo=memo,
    845                 print_node_on_error=self.rec_eval_print_node_on_error)
--> 846             rval = self.fn(pyll_rval)
        rval = undefined
        self.fn = <functools.partial object>
        pyll_rval = {'algorithm': {'bootstrap': True, 'criterion': 'entropy', 'max_depth': None, 'max_features': 3, 'max_leaf_nodes': None, 'min_samples_split': 2, 'n_estimators': 100}, 'pipeline': {'features': ('features_PCA', {'features__n_components': 1}), 'normalizer': ('normalizer_PowerTransformer', {}), 'rebalance': ('rebalance_NearMiss', {'rebalance__n_neighbors': 1})}}
    847 
    848         if isinstance(rval, (float, int, np.number)):
    849             dict_rval = {'loss': float(rval), 'status': STATUS_OK}
    850         else:

...........................................................................
/home/aquemy/dev/dp_hyperparameters/extension/experiment/objective.py in objective_joint(wconfig={'algorithm': {'bootstrap': True, 'criterion': 'entropy', 'max_depth': None, 'max_features': 3, 'max_leaf_nodes': None, 'min_samples_split': 2, 'n_estimators': 100}, 'pipeline': {'features': ('features_PCA', {'features__n_components': 1}), 'normalizer': ('normalizer_PowerTransformer', {}), 'rebalance': ('rebalance_NearMiss', {'rebalance__n_neighbors': 1})}}, algorithm='RandomForest', X=array([[1.423e+01, 1.710e+00, 2.430e+00, ..., 1...., ..., 6.100e-01, 1.600e+00,
        5.600e+02]]), y=array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,
       2, 2]), context={'baseline_score': 0.9444100447196423, 'baseline_score_std': 0.04305547117084885, 'best_config': {'algorithm': {'bootstrap': False, 'criterion': 'gini', 'max_depth': 1, 'max_features': 1, 'max_leaf_nodes': 3, 'min_samples_split': 3, 'n_estimators': 50}, 'config_hash': {'algorithm': '37be8b6737f4b5d5ae35da51886f302b07ba6001', 'config': 'a05b6d2ffd65d4d937c0b178655d857bf4d61410', 'pipeline': 'cfef88e895db321122f2f7b813d9267b973c2468'}, 'duration': 1.7094659805297852, 'iteration': 15, 'loss': 0.011111111111111072, 'max_history_score': 0.9888888888888889, 'max_history_score_std': 0.022222222222222233, 'max_history_step': 'joint', 'pipeline': {'features': ('features_NoneType', {}), 'normalizer': ('normalizer_NoneType', {}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 5})}, 'score': 0.9888888888888889, ...}, 'history': [{'algorithm': {'bootstrap': False, 'criterion': 'entropy', 'max_depth': None, 'max_features': 3, 'max_leaf_nodes': 5, 'min_samples_split': 2, 'n_estimators': 50}, 'config_hash': {'algorithm': 'b2c6464add7a35ce8048653a39338c9994de9a4f', 'config': '2e6648b63441361b4398cb94f81d2e04a830b2ef', 'pipeline': '3d44d7482e468d08c4f94457a205f3dac74084c1'}, 'duration': 0.737678050994873, 'iteration': 0, 'loss': 1.0, 'max_history_score': 0.0, 'max_history_score_std': 0.0, 'max_history_step': 'baseline', 'pipeline': {'features': ('features_PCA', {'features__n_components': 1}), 'normalizer': ('normalizer_NoneType', {}), 'rebalance': ('rebalance_CondensedNearestNeighbour', {'rebalance__n_neighbors': 3})}, 'score': 0.0, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'gini', 'max_depth': 1, 'max_features': None, 'max_leaf_nodes': 2, 'min_samples_split': 3, 'n_estimators': 25}, 'config_hash': {'algorithm': '7f71bbbfdb4e8da52b6fc33a43224183117de15e', 'config': '584343bc020d2d7bc89bd0856bc7770dae1c84fc', 'pipeline': '466ffa7ace0e442beb7c311eb214b17a4c6832b3'}, 'duration': 1.5976769924163818, 'iteration': 1, 'loss': 0.40386351909184726, 'max_history_score': 0.5961364809081527, 'max_history_score_std': 0.05351463210025494, 'max_history_step': 'joint', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 3, 'features__selectkbest__k': 3}), 'normalizer': ('normalizer_StandardScaler', {'normalizer__with_mean': True, 'normalizer__with_std': True}), 'rebalance': ('rebalance_NearMiss', {'rebalance__n_neighbors': 2})}, 'score': 0.5961364809081527, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'entropy', 'max_depth': 1, 'max_features': 2, 'max_leaf_nodes': 2, 'min_samples_split': 5, 'n_estimators': 25}, 'config_hash': {'algorithm': '897745a20d929d43e760cacee0a764bd8070daa5', 'config': 'de121d053e65def047cc8947f505578d5c5eab67', 'pipeline': '63040b39b48626a8232e847e8327bdca5cd88611'}, 'duration': 0.815453052520752, 'iteration': 2, 'loss': 0.07327786377708967, 'max_history_score': 0.9267221362229103, 'max_history_score_std': 0.043920207373658794, 'max_history_step': 'joint', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 3, 'features__selectkbest__k': 2}), 'normalizer': ('normalizer_StandardScaler', {'normalizer__with_mean': True, 'normalizer__with_std': True}), 'rebalance': ('rebalance_NoneType', {})}, 'score': 0.9267221362229103, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'entropy', 'max_depth': 4, 'max_features': 3, 'max_leaf_nodes': None, 'min_samples_split': 2, 'n_estimators': 100}, 'config_hash': {'algorithm': 'dbd92c75280ec06b66ca4ad9b135cf36957031a4', 'config': 'b21c9d15a389baa5bfea4c8ddcec129259f37540', 'pipeline': '38866720d2f120c863351493b9b4e23b9a4506dc'}, 'duration': 1.2293269634246826, 'iteration': 3, 'loss': 0.07199862401100798, 'max_history_score': 0.928001375988992, 'max_history_score_std': 0.06518367535896959, 'max_history_step': 'joint', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 2, 'features__selectkbest__k': 4}), 'normalizer': ('normalizer_NoneType', {}), 'rebalance': ('rebalance_NoneType', {})}, 'score': 0.928001375988992, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': 2, 'max_features': None, 'max_leaf_nodes': None, 'min_samples_split': 5, 'n_estimators': 100}, 'config_hash': {'algorithm': 'f455eefd9fdd03ece88892c3f440c580bdf27ddb', 'config': 'edd3456355d80775739c31515c832ca7b4e5e094', 'pipeline': '1d1034f9f0871e43f896c1db4ed6fd572ed0a6ef'}, 'duration': 1.6186630725860596, 'iteration': 4, 'loss': 0.16651831785345705, 'max_history_score': 0.928001375988992, 'max_history_score_std': 0.06518367535896959, 'max_history_step': 'joint', 'pipeline': {'features': ('features_SelectKBest', {'features__k': 4}), 'normalizer': ('normalizer_MinMaxScaler', {}), 'rebalance': ('rebalance_CondensedNearestNeighbour', {'rebalance__n_neighbors': 1})}, 'score': 0.833481682146543, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'entropy', 'max_depth': 1, 'max_features': 2, 'max_leaf_nodes': None, 'min_samples_split': 2, 'n_estimators': 10}, 'config_hash': {'algorithm': '29906eaa0712a68ea145b12821d54ba445726fbf', 'config': '0800d7d2c8c10d2f9e7b4e5127b343e916eb742c', 'pipeline': '2e0f188ae61600352a7159285e0f542b4587a403'}, 'duration': 0.19410085678100586, 'iteration': 5, 'loss': 0.20164258685930514, 'max_history_score': 0.928001375988992, 'max_history_score_std': 0.06518367535896959, 'max_history_step': 'joint', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 3, 'features__selectkbest__k': 4}), 'normalizer': ('normalizer_StandardScaler', {'normalizer__with_mean': True, 'normalizer__with_std': False}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 7})}, 'score': 0.7983574131406949, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': 1, 'max_features': 1, 'max_leaf_nodes': 5, 'min_samples_split': 2, 'n_estimators': 25}, 'config_hash': {'algorithm': 'fbb7d57e38cfc08240f0af985282da418cb33556', 'config': 'd98b641879b4754f2169335626a90575e945fd7c', 'pipeline': '62463de065924498cdcd2f2f1f7e68535cdb33a5'}, 'duration': 0.3625810146331787, 'iteration': 6, 'loss': 0.14327485380116955, 'max_history_score': 0.928001375988992, 'max_history_score_std': 0.06518367535896959, 'max_history_step': 'joint', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 1, 'features__selectkbest__k': 2}), 'normalizer': ('normalizer_NoneType', {}), 'rebalance': ('rebalance_NoneType', {})}, 'score': 0.8567251461988304, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'entropy', 'max_depth': 3, 'max_features': 1, 'max_leaf_nodes': None, 'min_samples_split': 2, 'n_estimators': 75}, 'config_hash': {'algorithm': 'fb2f5d4c4d636edac929e1454ce3d02a4fb134c1', 'config': '3f83df36a6abbdf7ea4a4bdcaf6727f23529c2bb', 'pipeline': '8377b93e334656d1a93d266493b58ef9a6a1786f'}, 'duration': 0.8223779201507568, 'iteration': 7, 'loss': 0.03921568627450989, 'max_history_score': 0.9607843137254901, 'max_history_score_std': 0.043526663832084804, 'max_history_step': 'joint', 'pipeline': {'features': ('features_PCA', {'features__n_components': 3}), 'normalizer': ('normalizer_MinMaxScaler', {}), 'rebalance': ('rebalance_NearMiss', {'rebalance__n_neighbors': 1})}, 'score': 0.9607843137254901, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'gini', 'max_depth': 3, 'max_features': 3, 'max_leaf_nodes': 2, 'min_samples_split': 2, 'n_estimators': 100}, 'config_hash': {'algorithm': '3c3fde6559b918694de4668d025d5418342db1b1', 'config': '037fd5c655b39cc7922fb394d736496befcc747b', 'pipeline': '2a5032814c6c7ed21dd5bd9686923d7fc2f8acc9'}, 'duration': 1.0435099601745605, 'iteration': 8, 'loss': 0.09955925352597172, 'max_history_score': 0.9607843137254901, 'max_history_score_std': 0.043526663832084804, 'max_history_step': 'joint', 'pipeline': {'features': ('features_NoneType', {}), 'normalizer': ('normalizer_RobustScaler', {'normalizer__quantile_range': (...), 'normalizer__with_centering': True, 'normalizer__with_scaling': True}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 7})}, 'score': 0.9004407464740283, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': 2, 'max_features': 1, 'max_leaf_nodes': None, 'min_samples_split': 3, 'n_estimators': 75}, 'config_hash': {'algorithm': '42185be98371e99ac896d2c6c2d69c451cb983ff', 'config': '6609280032189b59de1afbe36f3acb1d5c273693', 'pipeline': '8aab2941fc84d84f86fa56134e50909dbf9e19f5'}, 'duration': 0.9665219783782959, 'iteration': 9, 'loss': 0.01637426900584804, 'max_history_score': 0.983625730994152, 'max_history_score_std': 0.025023500462379746, 'max_history_step': 'joint', 'pipeline': {'features': ('features_NoneType', {}), 'normalizer': ('normalizer_PowerTransformer', {}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 5})}, 'score': 0.983625730994152, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': 1, 'max_features': 3, 'max_leaf_nodes': 2, 'min_samples_split': 3, 'n_estimators': 10}, 'config_hash': {'algorithm': '62a9fe705e4cd96e762bcc9543c4a456a5a9f188', 'config': '8e1c17ac9f6e03740f380fccb833c9c3931ffc35', 'pipeline': '3d44d7482e468d08c4f94457a205f3dac74084c1'}, 'duration': 0.46930503845214844, 'iteration': 10, 'loss': 1.0, 'max_history_score': 0.983625730994152, 'max_history_score_std': 0.025023500462379746, 'max_history_step': 'joint', 'pipeline': {'features': ('features_PCA', {'features__n_components': 1}), 'normalizer': ('normalizer_NoneType', {}), 'rebalance': ('rebalance_CondensedNearestNeighbour', {'rebalance__n_neighbors': 3})}, 'score': 0.0, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'gini', 'max_depth': 4, 'max_features': 1, 'max_leaf_nodes': 3, 'min_samples_split': 2, 'n_estimators': 100}, 'config_hash': {'algorithm': '086d6ca939a757bb32edb113a567f9d38744f061', 'config': '87c03d0cb8e8500e58cacc1a0f27ce54c41a2937', 'pipeline': '8f28ef0f35d97142278f9dacb4e9d1ff082e470f'}, 'duration': 2.1196961402893066, 'iteration': 11, 'loss': 0.15471276229790154, 'max_history_score': 0.983625730994152, 'max_history_score_std': 0.025023500462379746, 'max_history_step': 'joint', 'pipeline': {'features': ('features_PCA', {'features__n_components': 1}), 'normalizer': ('normalizer_StandardScaler', {'normalizer__with_mean': True, 'normalizer__with_std': True}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 7})}, 'score': 0.8452872377020985, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'entropy', 'max_depth': 3, 'max_features': 1, 'max_leaf_nodes': 2, 'min_samples_split': 2, 'n_estimators': 25}, 'config_hash': {'algorithm': '59f64a966796648c7bebade1127fa05541b391ad', 'config': '2ab964abffa0a277a9e2ee9b5570cd258e428b62', 'pipeline': 'eef3f702fd2fed761fa6744c1640d0bf320f1d00'}, 'duration': 0.9828321933746338, 'iteration': 12, 'loss': 0.0778465772273822, 'max_history_score': 0.983625730994152, 'max_history_score_std': 0.025023500462379746, 'max_history_step': 'joint', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 3, 'features__selectkbest__k': 1}), 'normalizer': ('normalizer_PowerTransformer', {}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 6})}, 'score': 0.9221534227726178, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'gini', 'max_depth': 4, 'max_features': 2, 'max_leaf_nodes': 3, 'min_samples_split': 3, 'n_estimators': 75}, 'config_hash': {'algorithm': '6f75c2a196eb9836df2b424e095051192eaed6ea', 'config': '5c95db3ad238063227f1b36e6a006d70c834c5da', 'pipeline': '1eae01a1128bee425c4d4ca0ee97a9afd409680e'}, 'duration': 0.8217771053314209, 'iteration': 13, 'loss': 0.03863089095287242, 'max_history_score': 0.983625730994152, 'max_history_score_std': 0.025023500462379746, 'max_history_step': 'joint', 'pipeline': {'features': ('features_NoneType', {}), 'normalizer': ('normalizer_StandardScaler', {'normalizer__with_mean': False, 'normalizer__with_std': False}), 'rebalance': ('rebalance_NearMiss', {'rebalance__n_neighbors': 1})}, 'score': 0.9613691090471276, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'entropy', 'max_depth': 4, 'max_features': 2, 'max_leaf_nodes': 3, 'min_samples_split': 2, 'n_estimators': 25}, 'config_hash': {'algorithm': '8aef3174f6b8020de06b825e0424c1e54d690afd', 'config': '50fd1169b8e42190600f25152654254b5d0e3ed1', 'pipeline': '9ceaa544911dc6c687e336cb8e9dd4d15ff1ceaf'}, 'duration': 0.40307188034057617, 'iteration': 14, 'loss': 1.0, 'max_history_score': 0.983625730994152, 'max_history_score_std': 0.025023500462379746, 'max_history_step': 'joint', 'pipeline': {'features': ('features_PCA', {'features__n_components': 1}), 'normalizer': ('normalizer_RobustScaler', {'normalizer__quantile_range': (...), 'normalizer__with_centering': False, 'normalizer__with_scaling': False}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 7})}, 'score': 0.0, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'gini', 'max_depth': 1, 'max_features': 1, 'max_leaf_nodes': 3, 'min_samples_split': 3, 'n_estimators': 50}, 'config_hash': {'algorithm': '37be8b6737f4b5d5ae35da51886f302b07ba6001', 'config': 'a05b6d2ffd65d4d937c0b178655d857bf4d61410', 'pipeline': 'cfef88e895db321122f2f7b813d9267b973c2468'}, 'duration': 1.7094659805297852, 'iteration': 15, 'loss': 0.011111111111111072, 'max_history_score': 0.9888888888888889, 'max_history_score_std': 0.022222222222222233, 'max_history_step': 'joint', 'pipeline': {'features': ('features_NoneType', {}), 'normalizer': ('normalizer_NoneType', {}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 5})}, 'score': 0.9888888888888889, ...}], 'history_hash': ['2e6648b63441361b4398cb94f81d2e04a830b2ef', '584343bc020d2d7bc89bd0856bc7770dae1c84fc', 'de121d053e65def047cc8947f505578d5c5eab67', 'b21c9d15a389baa5bfea4c8ddcec129259f37540', 'edd3456355d80775739c31515c832ca7b4e5e094', '0800d7d2c8c10d2f9e7b4e5127b343e916eb742c', 'd98b641879b4754f2169335626a90575e945fd7c', '3f83df36a6abbdf7ea4a4bdcaf6727f23529c2bb', '037fd5c655b39cc7922fb394d736496befcc747b', '6609280032189b59de1afbe36f3acb1d5c273693', '8e1c17ac9f6e03740f380fccb833c9c3931ffc35', '87c03d0cb8e8500e58cacc1a0f27ce54c41a2937', '2ab964abffa0a277a9e2ee9b5570cd258e428b62', '5c95db3ad238063227f1b36e6a006d70c834c5da', '50fd1169b8e42190600f25152654254b5d0e3ed1', 'a05b6d2ffd65d4d937c0b178655d857bf4d61410'], 'history_index': {'037fd5c655b39cc7922fb394d736496befcc747b': 8, '0800d7d2c8c10d2f9e7b4e5127b343e916eb742c': 5, '2ab964abffa0a277a9e2ee9b5570cd258e428b62': 12, '2e6648b63441361b4398cb94f81d2e04a830b2ef': 0, '3f83df36a6abbdf7ea4a4bdcaf6727f23529c2bb': 7, '50fd1169b8e42190600f25152654254b5d0e3ed1': 14, '584343bc020d2d7bc89bd0856bc7770dae1c84fc': 1, '5c95db3ad238063227f1b36e6a006d70c834c5da': 13, '6609280032189b59de1afbe36f3acb1d5c273693': 9, '87c03d0cb8e8500e58cacc1a0f27ce54c41a2937': 11, ...}, 'iteration': 15, 'max_history_score': 0.9888888888888889, 'max_history_score_std': 0.022222222222222233, 'max_history_step': 'joint'}, config={'algorithm': 'RandomForest', 'seed': 42, 'time': 300})
    108 
    109 def objective_algo(algo_config, current_pipeline_config, algorithm, X, y, context, config):
    110     return objective(current_pipeline_config, algo_config, algorithm, X, y, context, config, step='algorithm')
    111 
    112 def objective_joint(wconfig, algorithm, X, y, context, config):
--> 113     return objective(wconfig['pipeline'], wconfig['algorithm'], algorithm, X, y, context, config, step='joint')
        wconfig = {'algorithm': {'bootstrap': True, 'criterion': 'entropy', 'max_depth': None, 'max_features': 3, 'max_leaf_nodes': None, 'min_samples_split': 2, 'n_estimators': 100}, 'pipeline': {'features': ('features_PCA', {'features__n_components': 1}), 'normalizer': ('normalizer_PowerTransformer', {}), 'rebalance': ('rebalance_NearMiss', {'rebalance__n_neighbors': 1})}}
        algorithm = 'RandomForest'
        X = array([[1.423e+01, 1.710e+00, 2.430e+00, ..., 1...., ..., 6.100e-01, 1.600e+00,
        5.600e+02]])
        y = array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,
       2, 2])
        context = {'baseline_score': 0.9444100447196423, 'baseline_score_std': 0.04305547117084885, 'best_config': {'algorithm': {'bootstrap': False, 'criterion': 'gini', 'max_depth': 1, 'max_features': 1, 'max_leaf_nodes': 3, 'min_samples_split': 3, 'n_estimators': 50}, 'config_hash': {'algorithm': '37be8b6737f4b5d5ae35da51886f302b07ba6001', 'config': 'a05b6d2ffd65d4d937c0b178655d857bf4d61410', 'pipeline': 'cfef88e895db321122f2f7b813d9267b973c2468'}, 'duration': 1.7094659805297852, 'iteration': 15, 'loss': 0.011111111111111072, 'max_history_score': 0.9888888888888889, 'max_history_score_std': 0.022222222222222233, 'max_history_step': 'joint', 'pipeline': {'features': ('features_NoneType', {}), 'normalizer': ('normalizer_NoneType', {}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 5})}, 'score': 0.9888888888888889, ...}, 'history': [{'algorithm': {'bootstrap': False, 'criterion': 'entropy', 'max_depth': None, 'max_features': 3, 'max_leaf_nodes': 5, 'min_samples_split': 2, 'n_estimators': 50}, 'config_hash': {'algorithm': 'b2c6464add7a35ce8048653a39338c9994de9a4f', 'config': '2e6648b63441361b4398cb94f81d2e04a830b2ef', 'pipeline': '3d44d7482e468d08c4f94457a205f3dac74084c1'}, 'duration': 0.737678050994873, 'iteration': 0, 'loss': 1.0, 'max_history_score': 0.0, 'max_history_score_std': 0.0, 'max_history_step': 'baseline', 'pipeline': {'features': ('features_PCA', {'features__n_components': 1}), 'normalizer': ('normalizer_NoneType', {}), 'rebalance': ('rebalance_CondensedNearestNeighbour', {'rebalance__n_neighbors': 3})}, 'score': 0.0, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'gini', 'max_depth': 1, 'max_features': None, 'max_leaf_nodes': 2, 'min_samples_split': 3, 'n_estimators': 25}, 'config_hash': {'algorithm': '7f71bbbfdb4e8da52b6fc33a43224183117de15e', 'config': '584343bc020d2d7bc89bd0856bc7770dae1c84fc', 'pipeline': '466ffa7ace0e442beb7c311eb214b17a4c6832b3'}, 'duration': 1.5976769924163818, 'iteration': 1, 'loss': 0.40386351909184726, 'max_history_score': 0.5961364809081527, 'max_history_score_std': 0.05351463210025494, 'max_history_step': 'joint', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 3, 'features__selectkbest__k': 3}), 'normalizer': ('normalizer_StandardScaler', {'normalizer__with_mean': True, 'normalizer__with_std': True}), 'rebalance': ('rebalance_NearMiss', {'rebalance__n_neighbors': 2})}, 'score': 0.5961364809081527, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'entropy', 'max_depth': 1, 'max_features': 2, 'max_leaf_nodes': 2, 'min_samples_split': 5, 'n_estimators': 25}, 'config_hash': {'algorithm': '897745a20d929d43e760cacee0a764bd8070daa5', 'config': 'de121d053e65def047cc8947f505578d5c5eab67', 'pipeline': '63040b39b48626a8232e847e8327bdca5cd88611'}, 'duration': 0.815453052520752, 'iteration': 2, 'loss': 0.07327786377708967, 'max_history_score': 0.9267221362229103, 'max_history_score_std': 0.043920207373658794, 'max_history_step': 'joint', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 3, 'features__selectkbest__k': 2}), 'normalizer': ('normalizer_StandardScaler', {'normalizer__with_mean': True, 'normalizer__with_std': True}), 'rebalance': ('rebalance_NoneType', {})}, 'score': 0.9267221362229103, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'entropy', 'max_depth': 4, 'max_features': 3, 'max_leaf_nodes': None, 'min_samples_split': 2, 'n_estimators': 100}, 'config_hash': {'algorithm': 'dbd92c75280ec06b66ca4ad9b135cf36957031a4', 'config': 'b21c9d15a389baa5bfea4c8ddcec129259f37540', 'pipeline': '38866720d2f120c863351493b9b4e23b9a4506dc'}, 'duration': 1.2293269634246826, 'iteration': 3, 'loss': 0.07199862401100798, 'max_history_score': 0.928001375988992, 'max_history_score_std': 0.06518367535896959, 'max_history_step': 'joint', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 2, 'features__selectkbest__k': 4}), 'normalizer': ('normalizer_NoneType', {}), 'rebalance': ('rebalance_NoneType', {})}, 'score': 0.928001375988992, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': 2, 'max_features': None, 'max_leaf_nodes': None, 'min_samples_split': 5, 'n_estimators': 100}, 'config_hash': {'algorithm': 'f455eefd9fdd03ece88892c3f440c580bdf27ddb', 'config': 'edd3456355d80775739c31515c832ca7b4e5e094', 'pipeline': '1d1034f9f0871e43f896c1db4ed6fd572ed0a6ef'}, 'duration': 1.6186630725860596, 'iteration': 4, 'loss': 0.16651831785345705, 'max_history_score': 0.928001375988992, 'max_history_score_std': 0.06518367535896959, 'max_history_step': 'joint', 'pipeline': {'features': ('features_SelectKBest', {'features__k': 4}), 'normalizer': ('normalizer_MinMaxScaler', {}), 'rebalance': ('rebalance_CondensedNearestNeighbour', {'rebalance__n_neighbors': 1})}, 'score': 0.833481682146543, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'entropy', 'max_depth': 1, 'max_features': 2, 'max_leaf_nodes': None, 'min_samples_split': 2, 'n_estimators': 10}, 'config_hash': {'algorithm': '29906eaa0712a68ea145b12821d54ba445726fbf', 'config': '0800d7d2c8c10d2f9e7b4e5127b343e916eb742c', 'pipeline': '2e0f188ae61600352a7159285e0f542b4587a403'}, 'duration': 0.19410085678100586, 'iteration': 5, 'loss': 0.20164258685930514, 'max_history_score': 0.928001375988992, 'max_history_score_std': 0.06518367535896959, 'max_history_step': 'joint', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 3, 'features__selectkbest__k': 4}), 'normalizer': ('normalizer_StandardScaler', {'normalizer__with_mean': True, 'normalizer__with_std': False}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 7})}, 'score': 0.7983574131406949, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': 1, 'max_features': 1, 'max_leaf_nodes': 5, 'min_samples_split': 2, 'n_estimators': 25}, 'config_hash': {'algorithm': 'fbb7d57e38cfc08240f0af985282da418cb33556', 'config': 'd98b641879b4754f2169335626a90575e945fd7c', 'pipeline': '62463de065924498cdcd2f2f1f7e68535cdb33a5'}, 'duration': 0.3625810146331787, 'iteration': 6, 'loss': 0.14327485380116955, 'max_history_score': 0.928001375988992, 'max_history_score_std': 0.06518367535896959, 'max_history_step': 'joint', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 1, 'features__selectkbest__k': 2}), 'normalizer': ('normalizer_NoneType', {}), 'rebalance': ('rebalance_NoneType', {})}, 'score': 0.8567251461988304, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'entropy', 'max_depth': 3, 'max_features': 1, 'max_leaf_nodes': None, 'min_samples_split': 2, 'n_estimators': 75}, 'config_hash': {'algorithm': 'fb2f5d4c4d636edac929e1454ce3d02a4fb134c1', 'config': '3f83df36a6abbdf7ea4a4bdcaf6727f23529c2bb', 'pipeline': '8377b93e334656d1a93d266493b58ef9a6a1786f'}, 'duration': 0.8223779201507568, 'iteration': 7, 'loss': 0.03921568627450989, 'max_history_score': 0.9607843137254901, 'max_history_score_std': 0.043526663832084804, 'max_history_step': 'joint', 'pipeline': {'features': ('features_PCA', {'features__n_components': 3}), 'normalizer': ('normalizer_MinMaxScaler', {}), 'rebalance': ('rebalance_NearMiss', {'rebalance__n_neighbors': 1})}, 'score': 0.9607843137254901, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'gini', 'max_depth': 3, 'max_features': 3, 'max_leaf_nodes': 2, 'min_samples_split': 2, 'n_estimators': 100}, 'config_hash': {'algorithm': '3c3fde6559b918694de4668d025d5418342db1b1', 'config': '037fd5c655b39cc7922fb394d736496befcc747b', 'pipeline': '2a5032814c6c7ed21dd5bd9686923d7fc2f8acc9'}, 'duration': 1.0435099601745605, 'iteration': 8, 'loss': 0.09955925352597172, 'max_history_score': 0.9607843137254901, 'max_history_score_std': 0.043526663832084804, 'max_history_step': 'joint', 'pipeline': {'features': ('features_NoneType', {}), 'normalizer': ('normalizer_RobustScaler', {'normalizer__quantile_range': (...), 'normalizer__with_centering': True, 'normalizer__with_scaling': True}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 7})}, 'score': 0.9004407464740283, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': 2, 'max_features': 1, 'max_leaf_nodes': None, 'min_samples_split': 3, 'n_estimators': 75}, 'config_hash': {'algorithm': '42185be98371e99ac896d2c6c2d69c451cb983ff', 'config': '6609280032189b59de1afbe36f3acb1d5c273693', 'pipeline': '8aab2941fc84d84f86fa56134e50909dbf9e19f5'}, 'duration': 0.9665219783782959, 'iteration': 9, 'loss': 0.01637426900584804, 'max_history_score': 0.983625730994152, 'max_history_score_std': 0.025023500462379746, 'max_history_step': 'joint', 'pipeline': {'features': ('features_NoneType', {}), 'normalizer': ('normalizer_PowerTransformer', {}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 5})}, 'score': 0.983625730994152, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': 1, 'max_features': 3, 'max_leaf_nodes': 2, 'min_samples_split': 3, 'n_estimators': 10}, 'config_hash': {'algorithm': '62a9fe705e4cd96e762bcc9543c4a456a5a9f188', 'config': '8e1c17ac9f6e03740f380fccb833c9c3931ffc35', 'pipeline': '3d44d7482e468d08c4f94457a205f3dac74084c1'}, 'duration': 0.46930503845214844, 'iteration': 10, 'loss': 1.0, 'max_history_score': 0.983625730994152, 'max_history_score_std': 0.025023500462379746, 'max_history_step': 'joint', 'pipeline': {'features': ('features_PCA', {'features__n_components': 1}), 'normalizer': ('normalizer_NoneType', {}), 'rebalance': ('rebalance_CondensedNearestNeighbour', {'rebalance__n_neighbors': 3})}, 'score': 0.0, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'gini', 'max_depth': 4, 'max_features': 1, 'max_leaf_nodes': 3, 'min_samples_split': 2, 'n_estimators': 100}, 'config_hash': {'algorithm': '086d6ca939a757bb32edb113a567f9d38744f061', 'config': '87c03d0cb8e8500e58cacc1a0f27ce54c41a2937', 'pipeline': '8f28ef0f35d97142278f9dacb4e9d1ff082e470f'}, 'duration': 2.1196961402893066, 'iteration': 11, 'loss': 0.15471276229790154, 'max_history_score': 0.983625730994152, 'max_history_score_std': 0.025023500462379746, 'max_history_step': 'joint', 'pipeline': {'features': ('features_PCA', {'features__n_components': 1}), 'normalizer': ('normalizer_StandardScaler', {'normalizer__with_mean': True, 'normalizer__with_std': True}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 7})}, 'score': 0.8452872377020985, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'entropy', 'max_depth': 3, 'max_features': 1, 'max_leaf_nodes': 2, 'min_samples_split': 2, 'n_estimators': 25}, 'config_hash': {'algorithm': '59f64a966796648c7bebade1127fa05541b391ad', 'config': '2ab964abffa0a277a9e2ee9b5570cd258e428b62', 'pipeline': 'eef3f702fd2fed761fa6744c1640d0bf320f1d00'}, 'duration': 0.9828321933746338, 'iteration': 12, 'loss': 0.0778465772273822, 'max_history_score': 0.983625730994152, 'max_history_score_std': 0.025023500462379746, 'max_history_step': 'joint', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 3, 'features__selectkbest__k': 1}), 'normalizer': ('normalizer_PowerTransformer', {}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 6})}, 'score': 0.9221534227726178, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'gini', 'max_depth': 4, 'max_features': 2, 'max_leaf_nodes': 3, 'min_samples_split': 3, 'n_estimators': 75}, 'config_hash': {'algorithm': '6f75c2a196eb9836df2b424e095051192eaed6ea', 'config': '5c95db3ad238063227f1b36e6a006d70c834c5da', 'pipeline': '1eae01a1128bee425c4d4ca0ee97a9afd409680e'}, 'duration': 0.8217771053314209, 'iteration': 13, 'loss': 0.03863089095287242, 'max_history_score': 0.983625730994152, 'max_history_score_std': 0.025023500462379746, 'max_history_step': 'joint', 'pipeline': {'features': ('features_NoneType', {}), 'normalizer': ('normalizer_StandardScaler', {'normalizer__with_mean': False, 'normalizer__with_std': False}), 'rebalance': ('rebalance_NearMiss', {'rebalance__n_neighbors': 1})}, 'score': 0.9613691090471276, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'entropy', 'max_depth': 4, 'max_features': 2, 'max_leaf_nodes': 3, 'min_samples_split': 2, 'n_estimators': 25}, 'config_hash': {'algorithm': '8aef3174f6b8020de06b825e0424c1e54d690afd', 'config': '50fd1169b8e42190600f25152654254b5d0e3ed1', 'pipeline': '9ceaa544911dc6c687e336cb8e9dd4d15ff1ceaf'}, 'duration': 0.40307188034057617, 'iteration': 14, 'loss': 1.0, 'max_history_score': 0.983625730994152, 'max_history_score_std': 0.025023500462379746, 'max_history_step': 'joint', 'pipeline': {'features': ('features_PCA', {'features__n_components': 1}), 'normalizer': ('normalizer_RobustScaler', {'normalizer__quantile_range': (...), 'normalizer__with_centering': False, 'normalizer__with_scaling': False}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 7})}, 'score': 0.0, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'gini', 'max_depth': 1, 'max_features': 1, 'max_leaf_nodes': 3, 'min_samples_split': 3, 'n_estimators': 50}, 'config_hash': {'algorithm': '37be8b6737f4b5d5ae35da51886f302b07ba6001', 'config': 'a05b6d2ffd65d4d937c0b178655d857bf4d61410', 'pipeline': 'cfef88e895db321122f2f7b813d9267b973c2468'}, 'duration': 1.7094659805297852, 'iteration': 15, 'loss': 0.011111111111111072, 'max_history_score': 0.9888888888888889, 'max_history_score_std': 0.022222222222222233, 'max_history_step': 'joint', 'pipeline': {'features': ('features_NoneType', {}), 'normalizer': ('normalizer_NoneType', {}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 5})}, 'score': 0.9888888888888889, ...}], 'history_hash': ['2e6648b63441361b4398cb94f81d2e04a830b2ef', '584343bc020d2d7bc89bd0856bc7770dae1c84fc', 'de121d053e65def047cc8947f505578d5c5eab67', 'b21c9d15a389baa5bfea4c8ddcec129259f37540', 'edd3456355d80775739c31515c832ca7b4e5e094', '0800d7d2c8c10d2f9e7b4e5127b343e916eb742c', 'd98b641879b4754f2169335626a90575e945fd7c', '3f83df36a6abbdf7ea4a4bdcaf6727f23529c2bb', '037fd5c655b39cc7922fb394d736496befcc747b', '6609280032189b59de1afbe36f3acb1d5c273693', '8e1c17ac9f6e03740f380fccb833c9c3931ffc35', '87c03d0cb8e8500e58cacc1a0f27ce54c41a2937', '2ab964abffa0a277a9e2ee9b5570cd258e428b62', '5c95db3ad238063227f1b36e6a006d70c834c5da', '50fd1169b8e42190600f25152654254b5d0e3ed1', 'a05b6d2ffd65d4d937c0b178655d857bf4d61410'], 'history_index': {'037fd5c655b39cc7922fb394d736496befcc747b': 8, '0800d7d2c8c10d2f9e7b4e5127b343e916eb742c': 5, '2ab964abffa0a277a9e2ee9b5570cd258e428b62': 12, '2e6648b63441361b4398cb94f81d2e04a830b2ef': 0, '3f83df36a6abbdf7ea4a4bdcaf6727f23529c2bb': 7, '50fd1169b8e42190600f25152654254b5d0e3ed1': 14, '584343bc020d2d7bc89bd0856bc7770dae1c84fc': 1, '5c95db3ad238063227f1b36e6a006d70c834c5da': 13, '6609280032189b59de1afbe36f3acb1d5c273693': 9, '87c03d0cb8e8500e58cacc1a0f27ce54c41a2937': 11, ...}, 'iteration': 15, 'max_history_score': 0.9888888888888889, 'max_history_score_std': 0.022222222222222233, 'max_history_step': 'joint'}
        config = {'algorithm': 'RandomForest', 'seed': 42, 'time': 300}
    114 
    115 
    116 def get_baseline_score(algorithm, X, y, seed):
    117     pipeline, _ = pipeline_conf_to_full_pipeline(

...........................................................................
/home/aquemy/dev/dp_hyperparameters/extension/experiment/objective.py in objective(pipeline_config={'features': ('features_PCA', {'features__n_components': 1}), 'normalizer': ('normalizer_PowerTransformer', {}), 'rebalance': ('rebalance_NearMiss', {'rebalance__n_neighbors': 1})}, algo_config={'bootstrap': True, 'criterion': 'entropy', 'max_depth': None, 'max_features': 3, 'max_leaf_nodes': None, 'min_samples_split': 2, 'n_estimators': 100}, algorithm='RandomForest', X=array([[1.423e+01, 1.710e+00, 2.430e+00, ..., 1...., ..., 6.100e-01, 1.600e+00,
        5.600e+02]]), y=array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,
       2, 2]), context={'baseline_score': 0.9444100447196423, 'baseline_score_std': 0.04305547117084885, 'best_config': {'algorithm': {'bootstrap': False, 'criterion': 'gini', 'max_depth': 1, 'max_features': 1, 'max_leaf_nodes': 3, 'min_samples_split': 3, 'n_estimators': 50}, 'config_hash': {'algorithm': '37be8b6737f4b5d5ae35da51886f302b07ba6001', 'config': 'a05b6d2ffd65d4d937c0b178655d857bf4d61410', 'pipeline': 'cfef88e895db321122f2f7b813d9267b973c2468'}, 'duration': 1.7094659805297852, 'iteration': 15, 'loss': 0.011111111111111072, 'max_history_score': 0.9888888888888889, 'max_history_score_std': 0.022222222222222233, 'max_history_step': 'joint', 'pipeline': {'features': ('features_NoneType', {}), 'normalizer': ('normalizer_NoneType', {}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 5})}, 'score': 0.9888888888888889, ...}, 'history': [{'algorithm': {'bootstrap': False, 'criterion': 'entropy', 'max_depth': None, 'max_features': 3, 'max_leaf_nodes': 5, 'min_samples_split': 2, 'n_estimators': 50}, 'config_hash': {'algorithm': 'b2c6464add7a35ce8048653a39338c9994de9a4f', 'config': '2e6648b63441361b4398cb94f81d2e04a830b2ef', 'pipeline': '3d44d7482e468d08c4f94457a205f3dac74084c1'}, 'duration': 0.737678050994873, 'iteration': 0, 'loss': 1.0, 'max_history_score': 0.0, 'max_history_score_std': 0.0, 'max_history_step': 'baseline', 'pipeline': {'features': ('features_PCA', {'features__n_components': 1}), 'normalizer': ('normalizer_NoneType', {}), 'rebalance': ('rebalance_CondensedNearestNeighbour', {'rebalance__n_neighbors': 3})}, 'score': 0.0, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'gini', 'max_depth': 1, 'max_features': None, 'max_leaf_nodes': 2, 'min_samples_split': 3, 'n_estimators': 25}, 'config_hash': {'algorithm': '7f71bbbfdb4e8da52b6fc33a43224183117de15e', 'config': '584343bc020d2d7bc89bd0856bc7770dae1c84fc', 'pipeline': '466ffa7ace0e442beb7c311eb214b17a4c6832b3'}, 'duration': 1.5976769924163818, 'iteration': 1, 'loss': 0.40386351909184726, 'max_history_score': 0.5961364809081527, 'max_history_score_std': 0.05351463210025494, 'max_history_step': 'joint', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 3, 'features__selectkbest__k': 3}), 'normalizer': ('normalizer_StandardScaler', {'normalizer__with_mean': True, 'normalizer__with_std': True}), 'rebalance': ('rebalance_NearMiss', {'rebalance__n_neighbors': 2})}, 'score': 0.5961364809081527, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'entropy', 'max_depth': 1, 'max_features': 2, 'max_leaf_nodes': 2, 'min_samples_split': 5, 'n_estimators': 25}, 'config_hash': {'algorithm': '897745a20d929d43e760cacee0a764bd8070daa5', 'config': 'de121d053e65def047cc8947f505578d5c5eab67', 'pipeline': '63040b39b48626a8232e847e8327bdca5cd88611'}, 'duration': 0.815453052520752, 'iteration': 2, 'loss': 0.07327786377708967, 'max_history_score': 0.9267221362229103, 'max_history_score_std': 0.043920207373658794, 'max_history_step': 'joint', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 3, 'features__selectkbest__k': 2}), 'normalizer': ('normalizer_StandardScaler', {'normalizer__with_mean': True, 'normalizer__with_std': True}), 'rebalance': ('rebalance_NoneType', {})}, 'score': 0.9267221362229103, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'entropy', 'max_depth': 4, 'max_features': 3, 'max_leaf_nodes': None, 'min_samples_split': 2, 'n_estimators': 100}, 'config_hash': {'algorithm': 'dbd92c75280ec06b66ca4ad9b135cf36957031a4', 'config': 'b21c9d15a389baa5bfea4c8ddcec129259f37540', 'pipeline': '38866720d2f120c863351493b9b4e23b9a4506dc'}, 'duration': 1.2293269634246826, 'iteration': 3, 'loss': 0.07199862401100798, 'max_history_score': 0.928001375988992, 'max_history_score_std': 0.06518367535896959, 'max_history_step': 'joint', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 2, 'features__selectkbest__k': 4}), 'normalizer': ('normalizer_NoneType', {}), 'rebalance': ('rebalance_NoneType', {})}, 'score': 0.928001375988992, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': 2, 'max_features': None, 'max_leaf_nodes': None, 'min_samples_split': 5, 'n_estimators': 100}, 'config_hash': {'algorithm': 'f455eefd9fdd03ece88892c3f440c580bdf27ddb', 'config': 'edd3456355d80775739c31515c832ca7b4e5e094', 'pipeline': '1d1034f9f0871e43f896c1db4ed6fd572ed0a6ef'}, 'duration': 1.6186630725860596, 'iteration': 4, 'loss': 0.16651831785345705, 'max_history_score': 0.928001375988992, 'max_history_score_std': 0.06518367535896959, 'max_history_step': 'joint', 'pipeline': {'features': ('features_SelectKBest', {'features__k': 4}), 'normalizer': ('normalizer_MinMaxScaler', {}), 'rebalance': ('rebalance_CondensedNearestNeighbour', {'rebalance__n_neighbors': 1})}, 'score': 0.833481682146543, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'entropy', 'max_depth': 1, 'max_features': 2, 'max_leaf_nodes': None, 'min_samples_split': 2, 'n_estimators': 10}, 'config_hash': {'algorithm': '29906eaa0712a68ea145b12821d54ba445726fbf', 'config': '0800d7d2c8c10d2f9e7b4e5127b343e916eb742c', 'pipeline': '2e0f188ae61600352a7159285e0f542b4587a403'}, 'duration': 0.19410085678100586, 'iteration': 5, 'loss': 0.20164258685930514, 'max_history_score': 0.928001375988992, 'max_history_score_std': 0.06518367535896959, 'max_history_step': 'joint', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 3, 'features__selectkbest__k': 4}), 'normalizer': ('normalizer_StandardScaler', {'normalizer__with_mean': True, 'normalizer__with_std': False}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 7})}, 'score': 0.7983574131406949, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': 1, 'max_features': 1, 'max_leaf_nodes': 5, 'min_samples_split': 2, 'n_estimators': 25}, 'config_hash': {'algorithm': 'fbb7d57e38cfc08240f0af985282da418cb33556', 'config': 'd98b641879b4754f2169335626a90575e945fd7c', 'pipeline': '62463de065924498cdcd2f2f1f7e68535cdb33a5'}, 'duration': 0.3625810146331787, 'iteration': 6, 'loss': 0.14327485380116955, 'max_history_score': 0.928001375988992, 'max_history_score_std': 0.06518367535896959, 'max_history_step': 'joint', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 1, 'features__selectkbest__k': 2}), 'normalizer': ('normalizer_NoneType', {}), 'rebalance': ('rebalance_NoneType', {})}, 'score': 0.8567251461988304, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'entropy', 'max_depth': 3, 'max_features': 1, 'max_leaf_nodes': None, 'min_samples_split': 2, 'n_estimators': 75}, 'config_hash': {'algorithm': 'fb2f5d4c4d636edac929e1454ce3d02a4fb134c1', 'config': '3f83df36a6abbdf7ea4a4bdcaf6727f23529c2bb', 'pipeline': '8377b93e334656d1a93d266493b58ef9a6a1786f'}, 'duration': 0.8223779201507568, 'iteration': 7, 'loss': 0.03921568627450989, 'max_history_score': 0.9607843137254901, 'max_history_score_std': 0.043526663832084804, 'max_history_step': 'joint', 'pipeline': {'features': ('features_PCA', {'features__n_components': 3}), 'normalizer': ('normalizer_MinMaxScaler', {}), 'rebalance': ('rebalance_NearMiss', {'rebalance__n_neighbors': 1})}, 'score': 0.9607843137254901, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'gini', 'max_depth': 3, 'max_features': 3, 'max_leaf_nodes': 2, 'min_samples_split': 2, 'n_estimators': 100}, 'config_hash': {'algorithm': '3c3fde6559b918694de4668d025d5418342db1b1', 'config': '037fd5c655b39cc7922fb394d736496befcc747b', 'pipeline': '2a5032814c6c7ed21dd5bd9686923d7fc2f8acc9'}, 'duration': 1.0435099601745605, 'iteration': 8, 'loss': 0.09955925352597172, 'max_history_score': 0.9607843137254901, 'max_history_score_std': 0.043526663832084804, 'max_history_step': 'joint', 'pipeline': {'features': ('features_NoneType', {}), 'normalizer': ('normalizer_RobustScaler', {'normalizer__quantile_range': (...), 'normalizer__with_centering': True, 'normalizer__with_scaling': True}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 7})}, 'score': 0.9004407464740283, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': 2, 'max_features': 1, 'max_leaf_nodes': None, 'min_samples_split': 3, 'n_estimators': 75}, 'config_hash': {'algorithm': '42185be98371e99ac896d2c6c2d69c451cb983ff', 'config': '6609280032189b59de1afbe36f3acb1d5c273693', 'pipeline': '8aab2941fc84d84f86fa56134e50909dbf9e19f5'}, 'duration': 0.9665219783782959, 'iteration': 9, 'loss': 0.01637426900584804, 'max_history_score': 0.983625730994152, 'max_history_score_std': 0.025023500462379746, 'max_history_step': 'joint', 'pipeline': {'features': ('features_NoneType', {}), 'normalizer': ('normalizer_PowerTransformer', {}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 5})}, 'score': 0.983625730994152, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': 1, 'max_features': 3, 'max_leaf_nodes': 2, 'min_samples_split': 3, 'n_estimators': 10}, 'config_hash': {'algorithm': '62a9fe705e4cd96e762bcc9543c4a456a5a9f188', 'config': '8e1c17ac9f6e03740f380fccb833c9c3931ffc35', 'pipeline': '3d44d7482e468d08c4f94457a205f3dac74084c1'}, 'duration': 0.46930503845214844, 'iteration': 10, 'loss': 1.0, 'max_history_score': 0.983625730994152, 'max_history_score_std': 0.025023500462379746, 'max_history_step': 'joint', 'pipeline': {'features': ('features_PCA', {'features__n_components': 1}), 'normalizer': ('normalizer_NoneType', {}), 'rebalance': ('rebalance_CondensedNearestNeighbour', {'rebalance__n_neighbors': 3})}, 'score': 0.0, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'gini', 'max_depth': 4, 'max_features': 1, 'max_leaf_nodes': 3, 'min_samples_split': 2, 'n_estimators': 100}, 'config_hash': {'algorithm': '086d6ca939a757bb32edb113a567f9d38744f061', 'config': '87c03d0cb8e8500e58cacc1a0f27ce54c41a2937', 'pipeline': '8f28ef0f35d97142278f9dacb4e9d1ff082e470f'}, 'duration': 2.1196961402893066, 'iteration': 11, 'loss': 0.15471276229790154, 'max_history_score': 0.983625730994152, 'max_history_score_std': 0.025023500462379746, 'max_history_step': 'joint', 'pipeline': {'features': ('features_PCA', {'features__n_components': 1}), 'normalizer': ('normalizer_StandardScaler', {'normalizer__with_mean': True, 'normalizer__with_std': True}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 7})}, 'score': 0.8452872377020985, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'entropy', 'max_depth': 3, 'max_features': 1, 'max_leaf_nodes': 2, 'min_samples_split': 2, 'n_estimators': 25}, 'config_hash': {'algorithm': '59f64a966796648c7bebade1127fa05541b391ad', 'config': '2ab964abffa0a277a9e2ee9b5570cd258e428b62', 'pipeline': 'eef3f702fd2fed761fa6744c1640d0bf320f1d00'}, 'duration': 0.9828321933746338, 'iteration': 12, 'loss': 0.0778465772273822, 'max_history_score': 0.983625730994152, 'max_history_score_std': 0.025023500462379746, 'max_history_step': 'joint', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 3, 'features__selectkbest__k': 1}), 'normalizer': ('normalizer_PowerTransformer', {}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 6})}, 'score': 0.9221534227726178, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'gini', 'max_depth': 4, 'max_features': 2, 'max_leaf_nodes': 3, 'min_samples_split': 3, 'n_estimators': 75}, 'config_hash': {'algorithm': '6f75c2a196eb9836df2b424e095051192eaed6ea', 'config': '5c95db3ad238063227f1b36e6a006d70c834c5da', 'pipeline': '1eae01a1128bee425c4d4ca0ee97a9afd409680e'}, 'duration': 0.8217771053314209, 'iteration': 13, 'loss': 0.03863089095287242, 'max_history_score': 0.983625730994152, 'max_history_score_std': 0.025023500462379746, 'max_history_step': 'joint', 'pipeline': {'features': ('features_NoneType', {}), 'normalizer': ('normalizer_StandardScaler', {'normalizer__with_mean': False, 'normalizer__with_std': False}), 'rebalance': ('rebalance_NearMiss', {'rebalance__n_neighbors': 1})}, 'score': 0.9613691090471276, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'entropy', 'max_depth': 4, 'max_features': 2, 'max_leaf_nodes': 3, 'min_samples_split': 2, 'n_estimators': 25}, 'config_hash': {'algorithm': '8aef3174f6b8020de06b825e0424c1e54d690afd', 'config': '50fd1169b8e42190600f25152654254b5d0e3ed1', 'pipeline': '9ceaa544911dc6c687e336cb8e9dd4d15ff1ceaf'}, 'duration': 0.40307188034057617, 'iteration': 14, 'loss': 1.0, 'max_history_score': 0.983625730994152, 'max_history_score_std': 0.025023500462379746, 'max_history_step': 'joint', 'pipeline': {'features': ('features_PCA', {'features__n_components': 1}), 'normalizer': ('normalizer_RobustScaler', {'normalizer__quantile_range': (...), 'normalizer__with_centering': False, 'normalizer__with_scaling': False}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 7})}, 'score': 0.0, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'gini', 'max_depth': 1, 'max_features': 1, 'max_leaf_nodes': 3, 'min_samples_split': 3, 'n_estimators': 50}, 'config_hash': {'algorithm': '37be8b6737f4b5d5ae35da51886f302b07ba6001', 'config': 'a05b6d2ffd65d4d937c0b178655d857bf4d61410', 'pipeline': 'cfef88e895db321122f2f7b813d9267b973c2468'}, 'duration': 1.7094659805297852, 'iteration': 15, 'loss': 0.011111111111111072, 'max_history_score': 0.9888888888888889, 'max_history_score_std': 0.022222222222222233, 'max_history_step': 'joint', 'pipeline': {'features': ('features_NoneType', {}), 'normalizer': ('normalizer_NoneType', {}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 5})}, 'score': 0.9888888888888889, ...}], 'history_hash': ['2e6648b63441361b4398cb94f81d2e04a830b2ef', '584343bc020d2d7bc89bd0856bc7770dae1c84fc', 'de121d053e65def047cc8947f505578d5c5eab67', 'b21c9d15a389baa5bfea4c8ddcec129259f37540', 'edd3456355d80775739c31515c832ca7b4e5e094', '0800d7d2c8c10d2f9e7b4e5127b343e916eb742c', 'd98b641879b4754f2169335626a90575e945fd7c', '3f83df36a6abbdf7ea4a4bdcaf6727f23529c2bb', '037fd5c655b39cc7922fb394d736496befcc747b', '6609280032189b59de1afbe36f3acb1d5c273693', '8e1c17ac9f6e03740f380fccb833c9c3931ffc35', '87c03d0cb8e8500e58cacc1a0f27ce54c41a2937', '2ab964abffa0a277a9e2ee9b5570cd258e428b62', '5c95db3ad238063227f1b36e6a006d70c834c5da', '50fd1169b8e42190600f25152654254b5d0e3ed1', 'a05b6d2ffd65d4d937c0b178655d857bf4d61410'], 'history_index': {'037fd5c655b39cc7922fb394d736496befcc747b': 8, '0800d7d2c8c10d2f9e7b4e5127b343e916eb742c': 5, '2ab964abffa0a277a9e2ee9b5570cd258e428b62': 12, '2e6648b63441361b4398cb94f81d2e04a830b2ef': 0, '3f83df36a6abbdf7ea4a4bdcaf6727f23529c2bb': 7, '50fd1169b8e42190600f25152654254b5d0e3ed1': 14, '584343bc020d2d7bc89bd0856bc7770dae1c84fc': 1, '5c95db3ad238063227f1b36e6a006d70c834c5da': 13, '6609280032189b59de1afbe36f3acb1d5c273693': 9, '87c03d0cb8e8500e58cacc1a0f27ce54c41a2937': 11, ...}, 'iteration': 15, 'max_history_score': 0.9888888888888889, 'max_history_score_std': 0.022222222222222233, 'max_history_step': 'joint'}, config={'algorithm': 'RandomForest', 'seed': 42, 'time': 300}, step='joint')
     45                 y,
     46                 cv=10,
     47                 n_jobs=-1,
     48                 return_estimator=False,
     49                 return_train_score=False,
---> 50                 verbose=0)
     51         score = np.mean(scores['test_score'])
     52         std = np.std(scores['test_score'])
     53         status = STATUS_OK
     54     except Exception as e:

...........................................................................
/home/aquemy/.local/lib/python2.7/site-packages/sklearn/model_selection/_validation.py in cross_validate(estimator=Pipeline(memory=None,
     steps=[('rebalance', ... random_state=42, verbose=0, warm_start=False))]), X=array([[1.423e+01, 1.710e+00, 2.430e+00, ..., 1...., ..., 6.100e-01, 1.600e+00,
        5.600e+02]]), y=array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,
       2, 2]), groups=None, scoring=None, cv=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1, verbose=0, fit_params=None, pre_dispatch='2*n_jobs', return_train_score=False, return_estimator=False, error_score='raise-deprecating')
    235         delayed(_fit_and_score)(
    236             clone(estimator), X, y, scorers, train, test, verbose, None,
    237             fit_params, return_train_score=return_train_score,
    238             return_times=True, return_estimator=return_estimator,
    239             error_score=error_score)
--> 240         for train, test in cv.split(X, y, groups))
        cv.split = <bound method StratifiedKFold.split of Stratifie...d(n_splits=10, random_state=None, shuffle=False)>
        X = array([[1.423e+01, 1.710e+00, 2.430e+00, ..., 1...., ..., 6.100e-01, 1.600e+00,
        5.600e+02]])
        y = array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,
       2, 2])
        groups = None
    241 
    242     zipped_scores = list(zip(*scores))
    243     if return_train_score:
    244         train_scores = zipped_scores.pop(0)

...........................................................................
/home/aquemy/.local/lib/python2.7/site-packages/sklearn/externals/joblib/parallel.py in __call__(self=Parallel(n_jobs=-1), iterable=<generator object <genexpr>>)
    925                 # No need to wait for async callbacks to trigger to
    926                 # consumption.
    927                 self._iterating = False
    928 
    929             with self._backend.retrieval_context():
--> 930                 self.retrieve()
        self.retrieve = <bound method Parallel.retrieve of Parallel(n_jobs=-1)>
    931             # Make sure that we get a last message telling us we are done
    932             elapsed_time = time.time() - self._start_time
    933             self._print('Done %3i out of %3i | elapsed: %s finished',
    934                         (len(self._output), len(self._output),

---------------------------------------------------------------------------
Joblib worker traceback:
---------------------------------------------------------------------------
ValueError                                         Mon Jun 17 12:45:29 2019
PID: 15160                                  Python 2.7.15+: /usr/bin/python
...........................................................................
/home/aquemy/.local/lib/python2.7/site-packages/sklearn/externals/joblib/parallel.py in __call__(self=<sklearn.externals.joblib.parallel.BatchedCalls object>)
    220     def __call__(self):
    221         # Set the default nested backend to self._backend but do not set the
    222         # change the default number of processes to -1
    223         with parallel_backend(self._backend, n_jobs=self._n_jobs):
    224             return [func(*args, **kwargs)
--> 225                     for func, args, kwargs in self.items]
        func = <function _fit_and_score>
        args = (Pipeline(memory=None,
     steps=[('rebalance', ... random_state=42, verbose=0, warm_start=False))]), array([[1.423e+01, 1.710e+00, 2.430e+00, ..., 1...., ..., 6.100e-01, 1.600e+00,
        5.600e+02]]), array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,
       2, 2]), {'score': <function _passthrough_scorer>}, array([  6,   7,   8,   9,  10,  11,  12,  13,  ..., 170, 171, 172, 173, 174,
       175, 176, 177]), array([  0,   1,   2,   3,   4,   5,  59,  60,  ...,  64,  65,
        66, 130, 131, 132, 133, 134]), 0, None, None)
        kwargs = {'error_score': 'raise-deprecating', 'return_estimator': False, 'return_times': True, 'return_train_score': False}
        self.items = [(<function _fit_and_score>, (Pipeline(memory=None,
     steps=[('rebalance', ... random_state=42, verbose=0, warm_start=False))]), array([[1.423e+01, 1.710e+00, 2.430e+00, ..., 1...., ..., 6.100e-01, 1.600e+00,
        5.600e+02]]), array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,
       2, 2]), {'score': <function _passthrough_scorer>}, array([  6,   7,   8,   9,  10,  11,  12,  13,  ..., 170, 171, 172, 173, 174,
       175, 176, 177]), array([  0,   1,   2,   3,   4,   5,  59,  60,  ...,  64,  65,
        66, 130, 131, 132, 133, 134]), 0, None, None), {'error_score': 'raise-deprecating', 'return_estimator': False, 'return_times': True, 'return_train_score': False})]
    226 
    227     def __len__(self):
    228         return self._size
    229 

...........................................................................
/home/aquemy/.local/lib/python2.7/site-packages/sklearn/model_selection/_validation.py in _fit_and_score(estimator=Pipeline(memory=None,
     steps=[('rebalance', ... random_state=42, verbose=0, warm_start=False))]), X=array([[1.423e+01, 1.710e+00, 2.430e+00, ..., 1...., ..., 6.100e-01, 1.600e+00,
        5.600e+02]]), y=array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,
       2, 2]), scorer={'score': <function _passthrough_scorer>}, train=array([  6,   7,   8,   9,  10,  11,  12,  13,  ..., 170, 171, 172, 173, 174,
       175, 176, 177]), test=array([  0,   1,   2,   3,   4,   5,  59,  60,  ...,  64,  65,
        66, 130, 131, 132, 133, 134]), verbose=0, parameters=None, fit_params={}, return_train_score=False, return_parameters=False, return_n_test_samples=False, return_times=True, return_estimator=False, error_score='raise-deprecating')
    523 
    524     try:
    525         if y_train is None:
    526             estimator.fit(X_train, **fit_params)
    527         else:
--> 528             estimator.fit(X_train, y_train, **fit_params)
        estimator.fit = <bound method Pipeline.fit of Pipeline(memory=No...random_state=42, verbose=0, warm_start=False))])>
        X_train = array([[1.439e+01, 1.870e+00, 2.450e+00, ..., 1...., ..., 6.100e-01, 1.600e+00,
        5.600e+02]])
        y_train = array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...2, 2, 2, 2, 2, 2, 2, 2, 2,
       2, 2, 2, 2, 2])
        fit_params = {}
    529 
    530     except Exception as e:
    531         # Note fit time as time until error
    532         fit_time = time.time() - start_time

...........................................................................
/usr/local/lib/python2.7/dist-packages/imblearn/pipeline.py in fit(self=Pipeline(memory=None,
     steps=[('rebalance', ... random_state=42, verbose=0, warm_start=False))]), X=array([[1.439e+01, 1.870e+00, 2.450e+00, ..., 1...., ..., 6.100e-01, 1.600e+00,
        5.600e+02]]), y=array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...2, 2, 2, 2, 2, 2, 2, 2, 2,
       2, 2, 2, 2, 2]), **fit_params={})
    234             This estimator
    235 
    236         """
    237         Xt, yt, fit_params = self._fit(X, y, **fit_params)
    238         if self._final_estimator is not None:
--> 239             self._final_estimator.fit(Xt, yt, **fit_params)
        self._final_estimator.fit = <bound method RandomForestClassifier.fit of Rand...e, random_state=42, verbose=0, warm_start=False)>
        Xt = array([[-0.86256321],
       [-2.39958772],
    ...33],
       [ 2.24127059],
       [ 3.05674271]])
        yt = array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,... 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2])
        fit_params = {}
    240         return self
    241 
    242     def fit_transform(self, X, y=None, **fit_params):
    243         """Fit the model and transform with the final estimator

...........................................................................
/home/aquemy/.local/lib/python2.7/site-packages/sklearn/ensemble/forest.py in fit(self=RandomForestClassifier(bootstrap=True, class_wei...se, random_state=42, verbose=0, warm_start=False), X=array([[-0.8625632 ],
       [-2.3995876 ],
    ....2412705 ],
       [ 3.0567427 ]], dtype=float32), y=array([[0.],
       [0.],
       [0.],
       [0...    [2.],
       [2.],
       [2.],
       [2.]]), sample_weight=None)
    328             trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,
    329                              **_joblib_parallel_args(prefer='threads'))(
    330                 delayed(_parallel_build_trees)(
    331                     t, self, X, y, sample_weight, i, len(trees),
    332                     verbose=self.verbose, class_weight=self.class_weight)
--> 333                 for i, t in enumerate(trees))
        i = 99
    334 
    335             # Collect newly grown trees
    336             self.estimators_.extend(trees)
    337 

...........................................................................
/home/aquemy/.local/lib/python2.7/site-packages/sklearn/externals/joblib/parallel.py in __call__(self=Parallel(n_jobs=1), iterable=<generator object <genexpr>>)
    912             # self._original_iterator is None, then this means either
    913             # that pre_dispatch == "all", n_jobs == 1 or that the first batch
    914             # was very quick and its callback already dispatched all the
    915             # remaining jobs.
    916             self._iterating = False
--> 917             if self.dispatch_one_batch(iterator):
        self.dispatch_one_batch = <bound method Parallel.dispatch_one_batch of Parallel(n_jobs=1)>
        iterator = <generator object <genexpr>>
    918                 self._iterating = self._original_iterator is not None
    919 
    920             while self.dispatch_one_batch(iterator):
    921                 pass

...........................................................................
/home/aquemy/.local/lib/python2.7/site-packages/sklearn/externals/joblib/parallel.py in dispatch_one_batch(self=Parallel(n_jobs=1), iterator=<generator object <genexpr>>)
    754                                  self._pickle_cache)
    755             if len(tasks) == 0:
    756                 # No more tasks available in the iterator: tell caller to stop.
    757                 return False
    758             else:
--> 759                 self._dispatch(tasks)
        self._dispatch = <bound method Parallel._dispatch of Parallel(n_jobs=1)>
        tasks = <sklearn.externals.joblib.parallel.BatchedCalls object>
    760                 return True
    761 
    762     def _print(self, msg, msg_args):
    763         """Display the message on stout or stderr depending on verbosity"""

...........................................................................
/home/aquemy/.local/lib/python2.7/site-packages/sklearn/externals/joblib/parallel.py in _dispatch(self=Parallel(n_jobs=1), batch=<sklearn.externals.joblib.parallel.BatchedCalls object>)
    711 
    712         dispatch_timestamp = time.time()
    713         cb = BatchCompletionCallBack(dispatch_timestamp, len(batch), self)
    714         with self._lock:
    715             job_idx = len(self._jobs)
--> 716             job = self._backend.apply_async(batch, callback=cb)
        job = undefined
        self._backend.apply_async = <bound method SequentialBackend.apply_async of <...lib._parallel_backends.SequentialBackend object>>
        batch = <sklearn.externals.joblib.parallel.BatchedCalls object>
        cb = <sklearn.externals.joblib.parallel.BatchCompletionCallBack object>
    717             # A job can complete so quickly than its callback is
    718             # called before we get here, causing self._jobs to
    719             # grow. To ensure correct results ordering, .insert is
    720             # used (rather than .append) in the following line

...........................................................................
/home/aquemy/.local/lib/python2.7/site-packages/sklearn/externals/joblib/_parallel_backends.py in apply_async(self=<sklearn.externals.joblib._parallel_backends.SequentialBackend object>, func=<sklearn.externals.joblib.parallel.BatchedCalls object>, callback=<sklearn.externals.joblib.parallel.BatchCompletionCallBack object>)
    177             raise ValueError('n_jobs == 0 in Parallel has no meaning')
    178         return 1
    179 
    180     def apply_async(self, func, callback=None):
    181         """Schedule a func to be run"""
--> 182         result = ImmediateResult(func)
        result = undefined
        func = <sklearn.externals.joblib.parallel.BatchedCalls object>
    183         if callback:
    184             callback(result)
    185         return result
    186 

...........................................................................
/home/aquemy/.local/lib/python2.7/site-packages/sklearn/externals/joblib/_parallel_backends.py in __init__(self=<sklearn.externals.joblib._parallel_backends.ImmediateResult object>, batch=<sklearn.externals.joblib.parallel.BatchedCalls object>)
    544 
    545 class ImmediateResult(object):
    546     def __init__(self, batch):
    547         # Don't delay the application, to avoid keeping the input
    548         # arguments in memory
--> 549         self.results = batch()
        self.results = undefined
        batch = <sklearn.externals.joblib.parallel.BatchedCalls object>
    550 
    551     def get(self):
    552         return self.results
    553 

...........................................................................
/home/aquemy/.local/lib/python2.7/site-packages/sklearn/externals/joblib/parallel.py in __call__(self=<sklearn.externals.joblib.parallel.BatchedCalls object>)
    220     def __call__(self):
    221         # Set the default nested backend to self._backend but do not set the
    222         # change the default number of processes to -1
    223         with parallel_backend(self._backend, n_jobs=self._n_jobs):
    224             return [func(*args, **kwargs)
--> 225                     for func, args, kwargs in self.items]
        func = <function _parallel_build_trees>
        args = (DecisionTreeClassifier(class_weight=None, criter...=False, random_state=1608637542, splitter='best'), RandomForestClassifier(bootstrap=True, class_wei...se, random_state=42, verbose=0, warm_start=False), array([[-0.8625632 ],
       [-2.3995876 ],
    ....2412705 ],
       [ 3.0567427 ]], dtype=float32), array([[0.],
       [0.],
       [0.],
       [0...    [2.],
       [2.],
       [2.],
       [2.]]), None, 0, 100)
        kwargs = {'class_weight': None, 'verbose': 0}
        self.items = [(<function _parallel_build_trees>, (DecisionTreeClassifier(class_weight=None, criter...=False, random_state=1608637542, splitter='best'), RandomForestClassifier(bootstrap=True, class_wei...se, random_state=42, verbose=0, warm_start=False), array([[-0.8625632 ],
       [-2.3995876 ],
    ....2412705 ],
       [ 3.0567427 ]], dtype=float32), array([[0.],
       [0.],
       [0.],
       [0...    [2.],
       [2.],
       [2.],
       [2.]]), None, 0, 100), {'class_weight': None, 'verbose': 0})]
    226 
    227     def __len__(self):
    228         return self._size
    229 

...........................................................................
/home/aquemy/.local/lib/python2.7/site-packages/sklearn/ensemble/forest.py in _parallel_build_trees(tree=DecisionTreeClassifier(class_weight=None, criter...=False, random_state=1608637542, splitter='best'), forest=RandomForestClassifier(bootstrap=True, class_wei...se, random_state=42, verbose=0, warm_start=False), X=array([[-0.8625632 ],
       [-2.3995876 ],
    ....2412705 ],
       [ 3.0567427 ]], dtype=float32), y=array([[0.],
       [0.],
       [0.],
       [0...    [2.],
       [2.],
       [2.],
       [2.]]), sample_weight=None, tree_idx=0, n_trees=100, verbose=0, class_weight=None)
    114                 simplefilter('ignore', DeprecationWarning)
    115                 curr_sample_weight *= compute_sample_weight('auto', y, indices)
    116         elif class_weight == 'balanced_subsample':
    117             curr_sample_weight *= compute_sample_weight('balanced', y, indices)
    118 
--> 119         tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)
        tree.fit = <bound method DecisionTreeClassifier.fit of Deci...False, random_state=1608637542, splitter='best')>
        X = array([[-0.8625632 ],
       [-2.3995876 ],
    ....2412705 ],
       [ 3.0567427 ]], dtype=float32)
        y = array([[0.],
       [0.],
       [0.],
       [0...    [2.],
       [2.],
       [2.],
       [2.]])
        sample_weight = None
        curr_sample_weight = array([3., 3., 0., 1., 1., 2., 2., 0., 1., 2., 0...,
       1., 2., 1., 3., 1., 0., 1., 0., 1., 1.])
    120     else:
    121         tree.fit(X, y, sample_weight=sample_weight, check_input=False)
    122 
    123     return tree

...........................................................................
/home/aquemy/.local/lib/python2.7/site-packages/sklearn/tree/tree.py in fit(self=DecisionTreeClassifier(class_weight=None, criter...=False, random_state=1608637542, splitter='best'), X=array([[-0.8625632 ],
       [-2.3995876 ],
    ....2412705 ],
       [ 3.0567427 ]], dtype=float32), y=array([[0.],
       [0.],
       [0.],
       [0...    [2.],
       [2.],
       [2.],
       [2.]]), sample_weight=array([3., 3., 0., 1., 1., 2., 2., 0., 1., 2., 0...,
       1., 2., 1., 3., 1., 0., 1., 0., 1., 1.]), check_input=False, X_idx_sorted=None)
    796 
    797         super(DecisionTreeClassifier, self).fit(
    798             X, y,
    799             sample_weight=sample_weight,
    800             check_input=check_input,
--> 801             X_idx_sorted=X_idx_sorted)
        X_idx_sorted = None
    802         return self
    803 
    804     def predict_proba(self, X, check_input=True):
    805         """Predict class probabilities of the input samples X.

...........................................................................
/home/aquemy/.local/lib/python2.7/site-packages/sklearn/tree/tree.py in fit(self=DecisionTreeClassifier(class_weight=None, criter...=False, random_state=1608637542, splitter='best'), X=array([[-0.8625632 ],
       [-2.3995876 ],
    ....2412705 ],
       [ 3.0567427 ]], dtype=float32), y=array([[0.],
       [0.],
       [0.],
       [0...    [2.],
       [2.],
       [2.],
       [2.]]), sample_weight=array([3., 3., 0., 1., 1., 2., 2., 0., 1., 2., 0...,
       1., 2., 1., 3., 1., 0., 1., 0., 1., 1.]), check_input=False, X_idx_sorted=None)
    237         if not 0 <= self.min_weight_fraction_leaf <= 0.5:
    238             raise ValueError("min_weight_fraction_leaf must in [0, 0.5]")
    239         if max_depth <= 0:
    240             raise ValueError("max_depth must be greater than zero. ")
    241         if not (0 < max_features <= self.n_features_):
--> 242             raise ValueError("max_features must be in (0, n_features]")
    243         if not isinstance(max_leaf_nodes, (numbers.Integral, np.integer)):
    244             raise ValueError("max_leaf_nodes must be integral number but was "
    245                              "%r" % max_leaf_nodes)
    246         if -1 < max_leaf_nodes < 2:

ValueError: max_features must be in (0, n_features]
___________________________________________________________________________
Best score: 0.988888888889 (0.0222222222222) [J] | Score: 0.0 (0.0) [J]
Best score: 0.988888888889 (0.0222222222222) [J] | Score: 0.679327915377 (0.0718237558865) [J]
Best score: 0.988888888889 (0.0222222222222) [J] | Score: 0.819523993808 (0.0970377487287) [J]
Best score: 0.988888888889 (0.0222222222222) [J] | Score: 0.900842793258 (0.0835645804951) [J]
Best score: 0.988888888889 (0.0222222222222) [J] | Score: 0.977450980392 (0.0371587453033) [J]
Best score: 0.988888888889 (0.0222222222222) [J] | Score: 0.978070175439 (0.0268703745951) [J]
Best score: 0.988888888889 (0.0222222222222) [J] | Score: 0.977743378053 (0.0272938784642) [J]
Best score: 0.988888888889 (0.0222222222222) [J] | Score: 0.988888888889 (0.0222222222222) [J]
Best score: 0.994444444444 (0.0166666666667) [J] | Score: 0.994444444444 (0.0166666666667) [J]
Best score: 0.994444444444 (0.0166666666667) [J] | Score: 0.805301857585 (0.103639648169) [J]
Best score: 0.994444444444 (0.0166666666667) [J] | Score: 0.994444444444 (0.0166666666667) [J]
Best score: 0.994444444444 (0.0166666666667) [J] | Score: 0.943530701754 (0.0793863098788) [J]
Best score: 0.994444444444 (0.0166666666667) [J] | Score: 0.845579635363 (0.0866005402807) [J]
JoblibValueError
___________________________________________________________________________
...........................................................................
/home/aquemy/dev/dp_hyperparameters/extension/main.py in <module>()
     27 
     28     serializer.serialize_results(scenario, policy)
     29 
     30 if __name__ == "__main__":
     31     args = cli.parse_args()
---> 32     main(args)

...........................................................................
/home/aquemy/dev/dp_hyperparameters/extension/main.py in main(args=Namespace(customize=[(['control', 'seed'], '42')...io='./scenarios/rf_wine_joint.yaml', verbosity=0))
     21         test_size=0.4, 
     22         random_state=scenario['control']['seed']
     23     )
     24 
     25     policy = policies.initiate(scenario['setup']['policy'], config)
---> 26     policy.run(X,y)
        policy.run = <bound method Joint.run of <experiment.policies.joint.Joint object>>
        X = array([[1.423e+01, 1.710e+00, 2.430e+00, ..., 1...., ..., 6.100e-01, 1.600e+00,
        5.600e+02]])
        y = array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,
       2, 2])
     27 
     28     serializer.serialize_results(scenario, policy)
     29 
     30 if __name__ == "__main__":

...........................................................................
/home/aquemy/dev/dp_hyperparameters/extension/experiment/policies/joint.py in run(self=<experiment.policies.joint.Joint object>, X=array([[1.423e+01, 1.710e+00, 2.430e+00, ..., 1...., ..., 6.100e-01, 1.600e+00,
        5.600e+02]]), y=array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,
       2, 2]))
     32             algo=tpe.suggest, 
     33             max_evals=None,
     34             max_time=self.config['time'],     
     35             trials=trials,
     36             show_progressbar=False,
---> 37             verbose=0
     38         )
     39 
     40         best_config = self.context['best_config']
     41         super(Joint, self).display_step_results(best_config)

...........................................................................
/home/aquemy/dev/dp_hyperparameters/extension/hyperopt/fmin.py in fmin(fn=<functools.partial object>, space={'algorithm': {'bootstrap': <hyperopt.pyll.base.Apply object>, 'criterion': <hyperopt.pyll.base.Apply object>, 'max_depth': <hyperopt.pyll.base.Apply object>, 'max_features': <hyperopt.pyll.base.Apply object>, 'max_leaf_nodes': <hyperopt.pyll.base.Apply object>, 'min_samples_split': <hyperopt.pyll.base.Apply object>, 'n_estimators': <hyperopt.pyll.base.Apply object>}, 'pipeline': {'features': <hyperopt.pyll.base.Apply object>, 'normalizer': <hyperopt.pyll.base.Apply object>, 'rebalance': <hyperopt.pyll.base.Apply object>}}, algo=<function suggest>, max_evals=9223372036854775807, max_time=300, trials=<hyperopt.base.Trials object>, rstate=<mtrand.RandomState object>, allow_trials_fmin=True, pass_expr_memo_ctrl=None, catch_eval_exceptions=False, verbose=0, return_argmin=True, points_to_evaluate=None, max_queue_len=1, show_progressbar=False)
    406             pass_expr_memo_ctrl=pass_expr_memo_ctrl,
    407             verbose=verbose,
    408             catch_eval_exceptions=catch_eval_exceptions,
    409             return_argmin=return_argmin,
    410             show_progressbar=show_progressbar,
--> 411             max_time=max_time
        max_time = 300
    412         )
    413 
    414     if trials is None:
    415         if points_to_evaluate is None:

...........................................................................
/home/aquemy/dev/dp_hyperparameters/extension/hyperopt/base.py in fmin(self=<hyperopt.base.Trials object>, fn=<functools.partial object>, space={'algorithm': {'bootstrap': <hyperopt.pyll.base.Apply object>, 'criterion': <hyperopt.pyll.base.Apply object>, 'max_depth': <hyperopt.pyll.base.Apply object>, 'max_features': <hyperopt.pyll.base.Apply object>, 'max_leaf_nodes': <hyperopt.pyll.base.Apply object>, 'min_samples_split': <hyperopt.pyll.base.Apply object>, 'n_estimators': <hyperopt.pyll.base.Apply object>}, 'pipeline': {'features': <hyperopt.pyll.base.Apply object>, 'normalizer': <hyperopt.pyll.base.Apply object>, 'rebalance': <hyperopt.pyll.base.Apply object>}}, algo=<function suggest>, max_evals=9223372036854775807, max_time=300, rstate=<mtrand.RandomState object>, verbose=0, pass_expr_memo_ctrl=None, catch_eval_exceptions=False, return_argmin=True, show_progressbar=False)
    636             verbose=verbose,
    637             allow_trials_fmin=False,  # -- prevent recursion
    638             pass_expr_memo_ctrl=pass_expr_memo_ctrl,
    639             catch_eval_exceptions=catch_eval_exceptions,
    640             return_argmin=return_argmin,
--> 641             show_progressbar=show_progressbar)
        show_progressbar = False
    642 
    643 
    644 def trials_from_docs(docs, validate=True, **kwargs):
    645     """Construct a Trials base class instance from a list of trials documents

...........................................................................
/home/aquemy/dev/dp_hyperparameters/extension/hyperopt/fmin.py in fmin(fn=<functools.partial object>, space={'algorithm': {'bootstrap': <hyperopt.pyll.base.Apply object>, 'criterion': <hyperopt.pyll.base.Apply object>, 'max_depth': <hyperopt.pyll.base.Apply object>, 'max_features': <hyperopt.pyll.base.Apply object>, 'max_leaf_nodes': <hyperopt.pyll.base.Apply object>, 'min_samples_split': <hyperopt.pyll.base.Apply object>, 'n_estimators': <hyperopt.pyll.base.Apply object>}, 'pipeline': {'features': <hyperopt.pyll.base.Apply object>, 'normalizer': <hyperopt.pyll.base.Apply object>, 'rebalance': <hyperopt.pyll.base.Apply object>}}, algo=<function suggest>, max_evals=9223372036854775807, max_time=300, trials=<hyperopt.base.Trials object>, rstate=<mtrand.RandomState object>, allow_trials_fmin=False, pass_expr_memo_ctrl=None, catch_eval_exceptions=False, verbose=0, return_argmin=True, points_to_evaluate=None, max_queue_len=1, show_progressbar=False)
    426                     verbose=verbose,
    427                     max_queue_len=max_queue_len,
    428                     show_progressbar=show_progressbar,
    429                     max_time=max_time)
    430     rval.catch_eval_exceptions = catch_eval_exceptions
--> 431     rval.exhaust()
        rval.exhaust = <bound method FMinIter.exhaust of <hyperopt.fmin.FMinIter object>>
    432     if return_argmin:
    433         return trials.argmin
    434     elif len(trials) > 0:
    435         # Only if there are some succesfull trail runs, return the best point in the evaluation space

...........................................................................
/home/aquemy/dev/dp_hyperparameters/extension/hyperopt/fmin.py in exhaust(self=<hyperopt.fmin.FMinIter object>)
    273             raise StopIteration()
    274         return self.trials
    275 
    276     def exhaust(self):
    277         n_done = len(self.trials)
--> 278         self.run(self.max_evals - n_done, block_until_done=self.asynchronous)
        self.run = <bound method FMinIter.run of <hyperopt.fmin.FMinIter object>>
        self.max_evals = 9223372036854775807
        n_done = 0
        self.asynchronous = False
    279         self.trials.refresh()
    280         return self
    281 
    282 

...........................................................................
/home/aquemy/dev/dp_hyperparameters/extension/hyperopt/fmin.py in run(self=<hyperopt.fmin.FMinIter object>, N=9223372036854775807, block_until_done=False)
    232                     if self.asynchronous:
    233                         # -- wait for workers to fill in the trials
    234                         time.sleep(self.poll_interval_secs)
    235                     else:
    236                         # -- loop over trials and do the jobs directly
--> 237                         self.serial_evaluate()
        self.serial_evaluate = <bound method FMinIter.serial_evaluate of <hyperopt.fmin.FMinIter object>>
    238                     try:
    239                         res = [d['result']['loss'] for d in
    240                                          self.trials.trials if
    241                                          d['result']['status'] == 'ok']

...........................................................................
/home/aquemy/dev/dp_hyperparameters/extension/hyperopt/fmin.py in serial_evaluate(self=<hyperopt.fmin.FMinIter object>, N=-1)
    138                 trial['book_time'] = now
    139                 trial['refresh_time'] = now
    140                 spec = base.spec_from_misc(trial['misc'])
    141                 ctrl = base.Ctrl(self.trials, current_trial=trial)
    142                 try:
--> 143                     result = self.domain.evaluate(spec, ctrl)
        result = undefined
        self.domain.evaluate = <bound method Domain.evaluate of <hyperopt.base.Domain object>>
        spec = {'bootstrap': 1, 'criterion': 1, 'features': 2, 'features_SelectKBest_features__k': 0, 'max_depth': 0, 'max_features': 1, 'max_leaf_nodes': 2, 'min_samples_split': 2, 'n_estimators': 2, 'normalizer': 3, ...}
        ctrl = <hyperopt.base.Ctrl object>
    144                 except Exception as e:
    145                     logger.info('job exception: %s' % str(e))
    146                     trial['state'] = base.JOB_STATE_ERROR
    147                     trial['misc']['error'] = (str(type(e)), str(e))

...........................................................................
/home/aquemy/dev/dp_hyperparameters/extension/hyperopt/base.py in evaluate(self=<hyperopt.base.Domain object>, config={'bootstrap': 1, 'criterion': 1, 'features': 2, 'features_SelectKBest_features__k': 0, 'max_depth': 0, 'max_features': 1, 'max_leaf_nodes': 2, 'min_samples_split': 2, 'n_estimators': 2, 'normalizer': 3, ...}, ctrl=<hyperopt.base.Ctrl object>, attach_attachments=True)
    841             #    or the normal Python part (self.fn)
    842             pyll_rval = pyll.rec_eval(
    843                 self.expr,
    844                 memo=memo,
    845                 print_node_on_error=self.rec_eval_print_node_on_error)
--> 846             rval = self.fn(pyll_rval)
        rval = undefined
        self.fn = <functools.partial object>
        pyll_rval = {'algorithm': {'bootstrap': False, 'criterion': 'entropy', 'max_depth': 1, 'max_features': 2, 'max_leaf_nodes': 5, 'min_samples_split': 5, 'n_estimators': 50}, 'pipeline': {'features': ('features_SelectKBest', {'features__k': 1}), 'normalizer': ('normalizer_MinMaxScaler', {}), 'rebalance': ('rebalance_NoneType', {})}}
    847 
    848         if isinstance(rval, (float, int, np.number)):
    849             dict_rval = {'loss': float(rval), 'status': STATUS_OK}
    850         else:

...........................................................................
/home/aquemy/dev/dp_hyperparameters/extension/experiment/objective.py in objective_joint(wconfig={'algorithm': {'bootstrap': False, 'criterion': 'entropy', 'max_depth': 1, 'max_features': 2, 'max_leaf_nodes': 5, 'min_samples_split': 5, 'n_estimators': 50}, 'pipeline': {'features': ('features_SelectKBest', {'features__k': 1}), 'normalizer': ('normalizer_MinMaxScaler', {}), 'rebalance': ('rebalance_NoneType', {})}}, algorithm='RandomForest', X=array([[1.423e+01, 1.710e+00, 2.430e+00, ..., 1...., ..., 6.100e-01, 1.600e+00,
        5.600e+02]]), y=array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,
       2, 2]), context={'baseline_score': 0.9444100447196423, 'baseline_score_std': 0.04305547117084885, 'best_config': {'algorithm': {'bootstrap': False, 'criterion': 'gini', 'max_depth': 1, 'max_features': 1, 'max_leaf_nodes': 3, 'min_samples_split': 5, 'n_estimators': 50}, 'config_hash': {'algorithm': 'cefc05c6c759dc564d289289fe401e0f8737951d', 'config': '7a1c40755d84d62f5d2ab1ed021e7dff93dfce45', 'pipeline': '3ee6a915db2d8d71f204c103803fb8eabea0d54f'}, 'duration': 0.6908998489379883, 'iteration': 24, 'loss': 0.005555555555555536, 'max_history_score': 0.9944444444444445, 'max_history_score_std': 0.016666666666666673, 'max_history_step': 'joint', 'pipeline': {'features': ('features_NoneType', {}), 'normalizer': ('normalizer_MinMaxScaler', {}), 'rebalance': ('rebalance_NoneType', {})}, 'score': 0.9944444444444445, ...}, 'history': [{'algorithm': {'bootstrap': False, 'criterion': 'entropy', 'max_depth': None, 'max_features': 3, 'max_leaf_nodes': 5, 'min_samples_split': 2, 'n_estimators': 50}, 'config_hash': {'algorithm': 'b2c6464add7a35ce8048653a39338c9994de9a4f', 'config': '2e6648b63441361b4398cb94f81d2e04a830b2ef', 'pipeline': '3d44d7482e468d08c4f94457a205f3dac74084c1'}, 'duration': 0.737678050994873, 'iteration': 0, 'loss': 1.0, 'max_history_score': 0.0, 'max_history_score_std': 0.0, 'max_history_step': 'baseline', 'pipeline': {'features': ('features_PCA', {'features__n_components': 1}), 'normalizer': ('normalizer_NoneType', {}), 'rebalance': ('rebalance_CondensedNearestNeighbour', {'rebalance__n_neighbors': 3})}, 'score': 0.0, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'gini', 'max_depth': 1, 'max_features': None, 'max_leaf_nodes': 2, 'min_samples_split': 3, 'n_estimators': 25}, 'config_hash': {'algorithm': '7f71bbbfdb4e8da52b6fc33a43224183117de15e', 'config': '584343bc020d2d7bc89bd0856bc7770dae1c84fc', 'pipeline': '466ffa7ace0e442beb7c311eb214b17a4c6832b3'}, 'duration': 1.5976769924163818, 'iteration': 1, 'loss': 0.40386351909184726, 'max_history_score': 0.5961364809081527, 'max_history_score_std': 0.05351463210025494, 'max_history_step': 'joint', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 3, 'features__selectkbest__k': 3}), 'normalizer': ('normalizer_StandardScaler', {'normalizer__with_mean': True, 'normalizer__with_std': True}), 'rebalance': ('rebalance_NearMiss', {'rebalance__n_neighbors': 2})}, 'score': 0.5961364809081527, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'entropy', 'max_depth': 1, 'max_features': 2, 'max_leaf_nodes': 2, 'min_samples_split': 5, 'n_estimators': 25}, 'config_hash': {'algorithm': '897745a20d929d43e760cacee0a764bd8070daa5', 'config': 'de121d053e65def047cc8947f505578d5c5eab67', 'pipeline': '63040b39b48626a8232e847e8327bdca5cd88611'}, 'duration': 0.815453052520752, 'iteration': 2, 'loss': 0.07327786377708967, 'max_history_score': 0.9267221362229103, 'max_history_score_std': 0.043920207373658794, 'max_history_step': 'joint', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 3, 'features__selectkbest__k': 2}), 'normalizer': ('normalizer_StandardScaler', {'normalizer__with_mean': True, 'normalizer__with_std': True}), 'rebalance': ('rebalance_NoneType', {})}, 'score': 0.9267221362229103, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'entropy', 'max_depth': 4, 'max_features': 3, 'max_leaf_nodes': None, 'min_samples_split': 2, 'n_estimators': 100}, 'config_hash': {'algorithm': 'dbd92c75280ec06b66ca4ad9b135cf36957031a4', 'config': 'b21c9d15a389baa5bfea4c8ddcec129259f37540', 'pipeline': '38866720d2f120c863351493b9b4e23b9a4506dc'}, 'duration': 1.2293269634246826, 'iteration': 3, 'loss': 0.07199862401100798, 'max_history_score': 0.928001375988992, 'max_history_score_std': 0.06518367535896959, 'max_history_step': 'joint', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 2, 'features__selectkbest__k': 4}), 'normalizer': ('normalizer_NoneType', {}), 'rebalance': ('rebalance_NoneType', {})}, 'score': 0.928001375988992, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': 2, 'max_features': None, 'max_leaf_nodes': None, 'min_samples_split': 5, 'n_estimators': 100}, 'config_hash': {'algorithm': 'f455eefd9fdd03ece88892c3f440c580bdf27ddb', 'config': 'edd3456355d80775739c31515c832ca7b4e5e094', 'pipeline': '1d1034f9f0871e43f896c1db4ed6fd572ed0a6ef'}, 'duration': 1.6186630725860596, 'iteration': 4, 'loss': 0.16651831785345705, 'max_history_score': 0.928001375988992, 'max_history_score_std': 0.06518367535896959, 'max_history_step': 'joint', 'pipeline': {'features': ('features_SelectKBest', {'features__k': 4}), 'normalizer': ('normalizer_MinMaxScaler', {}), 'rebalance': ('rebalance_CondensedNearestNeighbour', {'rebalance__n_neighbors': 1})}, 'score': 0.833481682146543, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'entropy', 'max_depth': 1, 'max_features': 2, 'max_leaf_nodes': None, 'min_samples_split': 2, 'n_estimators': 10}, 'config_hash': {'algorithm': '29906eaa0712a68ea145b12821d54ba445726fbf', 'config': '0800d7d2c8c10d2f9e7b4e5127b343e916eb742c', 'pipeline': '2e0f188ae61600352a7159285e0f542b4587a403'}, 'duration': 0.19410085678100586, 'iteration': 5, 'loss': 0.20164258685930514, 'max_history_score': 0.928001375988992, 'max_history_score_std': 0.06518367535896959, 'max_history_step': 'joint', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 3, 'features__selectkbest__k': 4}), 'normalizer': ('normalizer_StandardScaler', {'normalizer__with_mean': True, 'normalizer__with_std': False}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 7})}, 'score': 0.7983574131406949, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': 1, 'max_features': 1, 'max_leaf_nodes': 5, 'min_samples_split': 2, 'n_estimators': 25}, 'config_hash': {'algorithm': 'fbb7d57e38cfc08240f0af985282da418cb33556', 'config': 'd98b641879b4754f2169335626a90575e945fd7c', 'pipeline': '62463de065924498cdcd2f2f1f7e68535cdb33a5'}, 'duration': 0.3625810146331787, 'iteration': 6, 'loss': 0.14327485380116955, 'max_history_score': 0.928001375988992, 'max_history_score_std': 0.06518367535896959, 'max_history_step': 'joint', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 1, 'features__selectkbest__k': 2}), 'normalizer': ('normalizer_NoneType', {}), 'rebalance': ('rebalance_NoneType', {})}, 'score': 0.8567251461988304, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'entropy', 'max_depth': 3, 'max_features': 1, 'max_leaf_nodes': None, 'min_samples_split': 2, 'n_estimators': 75}, 'config_hash': {'algorithm': 'fb2f5d4c4d636edac929e1454ce3d02a4fb134c1', 'config': '3f83df36a6abbdf7ea4a4bdcaf6727f23529c2bb', 'pipeline': '8377b93e334656d1a93d266493b58ef9a6a1786f'}, 'duration': 0.8223779201507568, 'iteration': 7, 'loss': 0.03921568627450989, 'max_history_score': 0.9607843137254901, 'max_history_score_std': 0.043526663832084804, 'max_history_step': 'joint', 'pipeline': {'features': ('features_PCA', {'features__n_components': 3}), 'normalizer': ('normalizer_MinMaxScaler', {}), 'rebalance': ('rebalance_NearMiss', {'rebalance__n_neighbors': 1})}, 'score': 0.9607843137254901, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'gini', 'max_depth': 3, 'max_features': 3, 'max_leaf_nodes': 2, 'min_samples_split': 2, 'n_estimators': 100}, 'config_hash': {'algorithm': '3c3fde6559b918694de4668d025d5418342db1b1', 'config': '037fd5c655b39cc7922fb394d736496befcc747b', 'pipeline': '2a5032814c6c7ed21dd5bd9686923d7fc2f8acc9'}, 'duration': 1.0435099601745605, 'iteration': 8, 'loss': 0.09955925352597172, 'max_history_score': 0.9607843137254901, 'max_history_score_std': 0.043526663832084804, 'max_history_step': 'joint', 'pipeline': {'features': ('features_NoneType', {}), 'normalizer': ('normalizer_RobustScaler', {'normalizer__quantile_range': (...), 'normalizer__with_centering': True, 'normalizer__with_scaling': True}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 7})}, 'score': 0.9004407464740283, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': 2, 'max_features': 1, 'max_leaf_nodes': None, 'min_samples_split': 3, 'n_estimators': 75}, 'config_hash': {'algorithm': '42185be98371e99ac896d2c6c2d69c451cb983ff', 'config': '6609280032189b59de1afbe36f3acb1d5c273693', 'pipeline': '8aab2941fc84d84f86fa56134e50909dbf9e19f5'}, 'duration': 0.9665219783782959, 'iteration': 9, 'loss': 0.01637426900584804, 'max_history_score': 0.983625730994152, 'max_history_score_std': 0.025023500462379746, 'max_history_step': 'joint', 'pipeline': {'features': ('features_NoneType', {}), 'normalizer': ('normalizer_PowerTransformer', {}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 5})}, 'score': 0.983625730994152, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': 1, 'max_features': 3, 'max_leaf_nodes': 2, 'min_samples_split': 3, 'n_estimators': 10}, 'config_hash': {'algorithm': '62a9fe705e4cd96e762bcc9543c4a456a5a9f188', 'config': '8e1c17ac9f6e03740f380fccb833c9c3931ffc35', 'pipeline': '3d44d7482e468d08c4f94457a205f3dac74084c1'}, 'duration': 0.46930503845214844, 'iteration': 10, 'loss': 1.0, 'max_history_score': 0.983625730994152, 'max_history_score_std': 0.025023500462379746, 'max_history_step': 'joint', 'pipeline': {'features': ('features_PCA', {'features__n_components': 1}), 'normalizer': ('normalizer_NoneType', {}), 'rebalance': ('rebalance_CondensedNearestNeighbour', {'rebalance__n_neighbors': 3})}, 'score': 0.0, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'gini', 'max_depth': 4, 'max_features': 1, 'max_leaf_nodes': 3, 'min_samples_split': 2, 'n_estimators': 100}, 'config_hash': {'algorithm': '086d6ca939a757bb32edb113a567f9d38744f061', 'config': '87c03d0cb8e8500e58cacc1a0f27ce54c41a2937', 'pipeline': '8f28ef0f35d97142278f9dacb4e9d1ff082e470f'}, 'duration': 2.1196961402893066, 'iteration': 11, 'loss': 0.15471276229790154, 'max_history_score': 0.983625730994152, 'max_history_score_std': 0.025023500462379746, 'max_history_step': 'joint', 'pipeline': {'features': ('features_PCA', {'features__n_components': 1}), 'normalizer': ('normalizer_StandardScaler', {'normalizer__with_mean': True, 'normalizer__with_std': True}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 7})}, 'score': 0.8452872377020985, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'entropy', 'max_depth': 3, 'max_features': 1, 'max_leaf_nodes': 2, 'min_samples_split': 2, 'n_estimators': 25}, 'config_hash': {'algorithm': '59f64a966796648c7bebade1127fa05541b391ad', 'config': '2ab964abffa0a277a9e2ee9b5570cd258e428b62', 'pipeline': 'eef3f702fd2fed761fa6744c1640d0bf320f1d00'}, 'duration': 0.9828321933746338, 'iteration': 12, 'loss': 0.0778465772273822, 'max_history_score': 0.983625730994152, 'max_history_score_std': 0.025023500462379746, 'max_history_step': 'joint', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 3, 'features__selectkbest__k': 1}), 'normalizer': ('normalizer_PowerTransformer', {}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 6})}, 'score': 0.9221534227726178, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'gini', 'max_depth': 4, 'max_features': 2, 'max_leaf_nodes': 3, 'min_samples_split': 3, 'n_estimators': 75}, 'config_hash': {'algorithm': '6f75c2a196eb9836df2b424e095051192eaed6ea', 'config': '5c95db3ad238063227f1b36e6a006d70c834c5da', 'pipeline': '1eae01a1128bee425c4d4ca0ee97a9afd409680e'}, 'duration': 0.8217771053314209, 'iteration': 13, 'loss': 0.03863089095287242, 'max_history_score': 0.983625730994152, 'max_history_score_std': 0.025023500462379746, 'max_history_step': 'joint', 'pipeline': {'features': ('features_NoneType', {}), 'normalizer': ('normalizer_StandardScaler', {'normalizer__with_mean': False, 'normalizer__with_std': False}), 'rebalance': ('rebalance_NearMiss', {'rebalance__n_neighbors': 1})}, 'score': 0.9613691090471276, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'entropy', 'max_depth': 4, 'max_features': 2, 'max_leaf_nodes': 3, 'min_samples_split': 2, 'n_estimators': 25}, 'config_hash': {'algorithm': '8aef3174f6b8020de06b825e0424c1e54d690afd', 'config': '50fd1169b8e42190600f25152654254b5d0e3ed1', 'pipeline': '9ceaa544911dc6c687e336cb8e9dd4d15ff1ceaf'}, 'duration': 0.40307188034057617, 'iteration': 14, 'loss': 1.0, 'max_history_score': 0.983625730994152, 'max_history_score_std': 0.025023500462379746, 'max_history_step': 'joint', 'pipeline': {'features': ('features_PCA', {'features__n_components': 1}), 'normalizer': ('normalizer_RobustScaler', {'normalizer__quantile_range': (...), 'normalizer__with_centering': False, 'normalizer__with_scaling': False}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 7})}, 'score': 0.0, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'gini', 'max_depth': 1, 'max_features': 1, 'max_leaf_nodes': 3, 'min_samples_split': 3, 'n_estimators': 50}, 'config_hash': {'algorithm': '37be8b6737f4b5d5ae35da51886f302b07ba6001', 'config': 'a05b6d2ffd65d4d937c0b178655d857bf4d61410', 'pipeline': 'cfef88e895db321122f2f7b813d9267b973c2468'}, 'duration': 1.7094659805297852, 'iteration': 15, 'loss': 0.011111111111111072, 'max_history_score': 0.9888888888888889, 'max_history_score_std': 0.022222222222222233, 'max_history_step': 'joint', 'pipeline': {'features': ('features_NoneType', {}), 'normalizer': ('normalizer_NoneType', {}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 5})}, 'score': 0.9888888888888889, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'entropy', 'max_depth': None, 'max_features': 3, 'max_leaf_nodes': None, 'min_samples_split': 2, 'n_estimators': 100}, 'config_hash': {'algorithm': 'c40543ce91793e367c1892c886bc49621c22ecfb', 'config': 'ebebb7a93116f14f470e062e37582a59f4aeb0df', 'pipeline': 'b50c63e800574e8b760f55f7c4ff1fcae8816dd8'}, 'duration': 0.6425540447235107, 'iteration': 16, 'loss': 1.0, 'max_history_score': 0.9888888888888889, 'max_history_score_std': 0.022222222222222233, 'max_history_step': 'joint', 'pipeline': {'features': ('features_PCA', {'features__n_components': 1}), 'normalizer': ('normalizer_PowerTransformer', {}), 'rebalance': ('rebalance_NearMiss', {'rebalance__n_neighbors': 1})}, 'score': 0.0, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'gini', 'max_depth': None, 'max_features': 1, 'max_leaf_nodes': 3, 'min_samples_split': 2, 'n_estimators': 50}, 'config_hash': {'algorithm': '0c69b9601237c20664085fa05764d855e28f98f7', 'config': 'a2c21314ddbba47ddbfe416e0aa14853a71179e0', 'pipeline': '914f81fa4fbb61db251201f32bd8ea11bfeea2a5'}, 'duration': 2.2209739685058594, 'iteration': 17, 'loss': 0.3206720846233231, 'max_history_score': 0.9888888888888889, 'max_history_score_std': 0.022222222222222233, 'max_history_step': 'joint', 'pipeline': {'features': ('features_SelectKBest', {'features__k': 4}), 'normalizer': ('normalizer_PowerTransformer', {}), 'rebalance': ('rebalance_CondensedNearestNeighbour', {'rebalance__n_neighbors': 1})}, 'score': 0.6793279153766769, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': 4, 'max_features': None, 'max_leaf_nodes': None, 'min_samples_split': 3, 'n_estimators': 25}, 'config_hash': {'algorithm': '1aae0f1fce5cab293ffdd4581c4838c8051ac815', 'config': '6c8a721218e7c550a98c5ba72ad9ff86afd5e3a4', 'pipeline': '77189452469cef9c840643f2babe0f825c6667c8'}, 'duration': 0.3951280117034912, 'iteration': 18, 'loss': 0.1804760061919506, 'max_history_score': 0.9888888888888889, 'max_history_score_std': 0.022222222222222233, 'max_history_step': 'joint', 'pipeline': {'features': ('features_SelectKBest', {'features__k': 2}), 'normalizer': ('normalizer_NoneType', {}), 'rebalance': ('rebalance_NearMiss', {'rebalance__n_neighbors': 1})}, 'score': 0.8195239938080494, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': None, 'max_features': 3, 'max_leaf_nodes': 5, 'min_samples_split': 3, 'n_estimators': 50}, 'config_hash': {'algorithm': '0129970b8c7fe034ac8283fb518a06cfbead63d2', 'config': '61bcd2f64860b3dfe2503be88a6bbec165db0754', 'pipeline': '359f2473075ecfd9ae3ce526da96143918517601'}, 'duration': 0.7467091083526611, 'iteration': 19, 'loss': 0.09915720674234607, 'max_history_score': 0.9888888888888889, 'max_history_score_std': 0.022222222222222233, 'max_history_step': 'joint', 'pipeline': {'features': ('features_SelectKBest', {'features__k': 3}), 'normalizer': ('normalizer_RobustScaler', {'normalizer__quantile_range': (...), 'normalizer__with_centering': True, 'normalizer__with_scaling': False}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 7})}, 'score': 0.9008427932576539, ...}, ...], 'history_hash': ['2e6648b63441361b4398cb94f81d2e04a830b2ef', '584343bc020d2d7bc89bd0856bc7770dae1c84fc', 'de121d053e65def047cc8947f505578d5c5eab67', 'b21c9d15a389baa5bfea4c8ddcec129259f37540', 'edd3456355d80775739c31515c832ca7b4e5e094', '0800d7d2c8c10d2f9e7b4e5127b343e916eb742c', 'd98b641879b4754f2169335626a90575e945fd7c', '3f83df36a6abbdf7ea4a4bdcaf6727f23529c2bb', '037fd5c655b39cc7922fb394d736496befcc747b', '6609280032189b59de1afbe36f3acb1d5c273693', '8e1c17ac9f6e03740f380fccb833c9c3931ffc35', '87c03d0cb8e8500e58cacc1a0f27ce54c41a2937', '2ab964abffa0a277a9e2ee9b5570cd258e428b62', '5c95db3ad238063227f1b36e6a006d70c834c5da', '50fd1169b8e42190600f25152654254b5d0e3ed1', 'a05b6d2ffd65d4d937c0b178655d857bf4d61410', 'ebebb7a93116f14f470e062e37582a59f4aeb0df', 'a2c21314ddbba47ddbfe416e0aa14853a71179e0', '6c8a721218e7c550a98c5ba72ad9ff86afd5e3a4', '61bcd2f64860b3dfe2503be88a6bbec165db0754', ...], 'history_index': {'037fd5c655b39cc7922fb394d736496befcc747b': 8, '07fdf9d0d0248a4b0215a633c75a2dd101dcf465': 22, '0800d7d2c8c10d2f9e7b4e5127b343e916eb742c': 5, '2ab964abffa0a277a9e2ee9b5570cd258e428b62': 12, '2e6648b63441361b4398cb94f81d2e04a830b2ef': 0, '3876a387c01c8d5fb746f320f2cc4d1168f512a0': 21, '3f83df36a6abbdf7ea4a4bdcaf6727f23529c2bb': 7, '50fd1169b8e42190600f25152654254b5d0e3ed1': 14, '584343bc020d2d7bc89bd0856bc7770dae1c84fc': 1, '5c95db3ad238063227f1b36e6a006d70c834c5da': 13, ...}, 'iteration': 28, 'max_history_score': 0.9944444444444445, 'max_history_score_std': 0.016666666666666673, 'max_history_step': 'joint'}, config={'algorithm': 'RandomForest', 'seed': 42, 'time': 300})
    108 
    109 def objective_algo(algo_config, current_pipeline_config, algorithm, X, y, context, config):
    110     return objective(current_pipeline_config, algo_config, algorithm, X, y, context, config, step='algorithm')
    111 
    112 def objective_joint(wconfig, algorithm, X, y, context, config):
--> 113     return objective(wconfig['pipeline'], wconfig['algorithm'], algorithm, X, y, context, config, step='joint')
        wconfig = {'algorithm': {'bootstrap': False, 'criterion': 'entropy', 'max_depth': 1, 'max_features': 2, 'max_leaf_nodes': 5, 'min_samples_split': 5, 'n_estimators': 50}, 'pipeline': {'features': ('features_SelectKBest', {'features__k': 1}), 'normalizer': ('normalizer_MinMaxScaler', {}), 'rebalance': ('rebalance_NoneType', {})}}
        algorithm = 'RandomForest'
        X = array([[1.423e+01, 1.710e+00, 2.430e+00, ..., 1...., ..., 6.100e-01, 1.600e+00,
        5.600e+02]])
        y = array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,
       2, 2])
        context = {'baseline_score': 0.9444100447196423, 'baseline_score_std': 0.04305547117084885, 'best_config': {'algorithm': {'bootstrap': False, 'criterion': 'gini', 'max_depth': 1, 'max_features': 1, 'max_leaf_nodes': 3, 'min_samples_split': 5, 'n_estimators': 50}, 'config_hash': {'algorithm': 'cefc05c6c759dc564d289289fe401e0f8737951d', 'config': '7a1c40755d84d62f5d2ab1ed021e7dff93dfce45', 'pipeline': '3ee6a915db2d8d71f204c103803fb8eabea0d54f'}, 'duration': 0.6908998489379883, 'iteration': 24, 'loss': 0.005555555555555536, 'max_history_score': 0.9944444444444445, 'max_history_score_std': 0.016666666666666673, 'max_history_step': 'joint', 'pipeline': {'features': ('features_NoneType', {}), 'normalizer': ('normalizer_MinMaxScaler', {}), 'rebalance': ('rebalance_NoneType', {})}, 'score': 0.9944444444444445, ...}, 'history': [{'algorithm': {'bootstrap': False, 'criterion': 'entropy', 'max_depth': None, 'max_features': 3, 'max_leaf_nodes': 5, 'min_samples_split': 2, 'n_estimators': 50}, 'config_hash': {'algorithm': 'b2c6464add7a35ce8048653a39338c9994de9a4f', 'config': '2e6648b63441361b4398cb94f81d2e04a830b2ef', 'pipeline': '3d44d7482e468d08c4f94457a205f3dac74084c1'}, 'duration': 0.737678050994873, 'iteration': 0, 'loss': 1.0, 'max_history_score': 0.0, 'max_history_score_std': 0.0, 'max_history_step': 'baseline', 'pipeline': {'features': ('features_PCA', {'features__n_components': 1}), 'normalizer': ('normalizer_NoneType', {}), 'rebalance': ('rebalance_CondensedNearestNeighbour', {'rebalance__n_neighbors': 3})}, 'score': 0.0, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'gini', 'max_depth': 1, 'max_features': None, 'max_leaf_nodes': 2, 'min_samples_split': 3, 'n_estimators': 25}, 'config_hash': {'algorithm': '7f71bbbfdb4e8da52b6fc33a43224183117de15e', 'config': '584343bc020d2d7bc89bd0856bc7770dae1c84fc', 'pipeline': '466ffa7ace0e442beb7c311eb214b17a4c6832b3'}, 'duration': 1.5976769924163818, 'iteration': 1, 'loss': 0.40386351909184726, 'max_history_score': 0.5961364809081527, 'max_history_score_std': 0.05351463210025494, 'max_history_step': 'joint', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 3, 'features__selectkbest__k': 3}), 'normalizer': ('normalizer_StandardScaler', {'normalizer__with_mean': True, 'normalizer__with_std': True}), 'rebalance': ('rebalance_NearMiss', {'rebalance__n_neighbors': 2})}, 'score': 0.5961364809081527, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'entropy', 'max_depth': 1, 'max_features': 2, 'max_leaf_nodes': 2, 'min_samples_split': 5, 'n_estimators': 25}, 'config_hash': {'algorithm': '897745a20d929d43e760cacee0a764bd8070daa5', 'config': 'de121d053e65def047cc8947f505578d5c5eab67', 'pipeline': '63040b39b48626a8232e847e8327bdca5cd88611'}, 'duration': 0.815453052520752, 'iteration': 2, 'loss': 0.07327786377708967, 'max_history_score': 0.9267221362229103, 'max_history_score_std': 0.043920207373658794, 'max_history_step': 'joint', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 3, 'features__selectkbest__k': 2}), 'normalizer': ('normalizer_StandardScaler', {'normalizer__with_mean': True, 'normalizer__with_std': True}), 'rebalance': ('rebalance_NoneType', {})}, 'score': 0.9267221362229103, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'entropy', 'max_depth': 4, 'max_features': 3, 'max_leaf_nodes': None, 'min_samples_split': 2, 'n_estimators': 100}, 'config_hash': {'algorithm': 'dbd92c75280ec06b66ca4ad9b135cf36957031a4', 'config': 'b21c9d15a389baa5bfea4c8ddcec129259f37540', 'pipeline': '38866720d2f120c863351493b9b4e23b9a4506dc'}, 'duration': 1.2293269634246826, 'iteration': 3, 'loss': 0.07199862401100798, 'max_history_score': 0.928001375988992, 'max_history_score_std': 0.06518367535896959, 'max_history_step': 'joint', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 2, 'features__selectkbest__k': 4}), 'normalizer': ('normalizer_NoneType', {}), 'rebalance': ('rebalance_NoneType', {})}, 'score': 0.928001375988992, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': 2, 'max_features': None, 'max_leaf_nodes': None, 'min_samples_split': 5, 'n_estimators': 100}, 'config_hash': {'algorithm': 'f455eefd9fdd03ece88892c3f440c580bdf27ddb', 'config': 'edd3456355d80775739c31515c832ca7b4e5e094', 'pipeline': '1d1034f9f0871e43f896c1db4ed6fd572ed0a6ef'}, 'duration': 1.6186630725860596, 'iteration': 4, 'loss': 0.16651831785345705, 'max_history_score': 0.928001375988992, 'max_history_score_std': 0.06518367535896959, 'max_history_step': 'joint', 'pipeline': {'features': ('features_SelectKBest', {'features__k': 4}), 'normalizer': ('normalizer_MinMaxScaler', {}), 'rebalance': ('rebalance_CondensedNearestNeighbour', {'rebalance__n_neighbors': 1})}, 'score': 0.833481682146543, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'entropy', 'max_depth': 1, 'max_features': 2, 'max_leaf_nodes': None, 'min_samples_split': 2, 'n_estimators': 10}, 'config_hash': {'algorithm': '29906eaa0712a68ea145b12821d54ba445726fbf', 'config': '0800d7d2c8c10d2f9e7b4e5127b343e916eb742c', 'pipeline': '2e0f188ae61600352a7159285e0f542b4587a403'}, 'duration': 0.19410085678100586, 'iteration': 5, 'loss': 0.20164258685930514, 'max_history_score': 0.928001375988992, 'max_history_score_std': 0.06518367535896959, 'max_history_step': 'joint', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 3, 'features__selectkbest__k': 4}), 'normalizer': ('normalizer_StandardScaler', {'normalizer__with_mean': True, 'normalizer__with_std': False}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 7})}, 'score': 0.7983574131406949, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': 1, 'max_features': 1, 'max_leaf_nodes': 5, 'min_samples_split': 2, 'n_estimators': 25}, 'config_hash': {'algorithm': 'fbb7d57e38cfc08240f0af985282da418cb33556', 'config': 'd98b641879b4754f2169335626a90575e945fd7c', 'pipeline': '62463de065924498cdcd2f2f1f7e68535cdb33a5'}, 'duration': 0.3625810146331787, 'iteration': 6, 'loss': 0.14327485380116955, 'max_history_score': 0.928001375988992, 'max_history_score_std': 0.06518367535896959, 'max_history_step': 'joint', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 1, 'features__selectkbest__k': 2}), 'normalizer': ('normalizer_NoneType', {}), 'rebalance': ('rebalance_NoneType', {})}, 'score': 0.8567251461988304, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'entropy', 'max_depth': 3, 'max_features': 1, 'max_leaf_nodes': None, 'min_samples_split': 2, 'n_estimators': 75}, 'config_hash': {'algorithm': 'fb2f5d4c4d636edac929e1454ce3d02a4fb134c1', 'config': '3f83df36a6abbdf7ea4a4bdcaf6727f23529c2bb', 'pipeline': '8377b93e334656d1a93d266493b58ef9a6a1786f'}, 'duration': 0.8223779201507568, 'iteration': 7, 'loss': 0.03921568627450989, 'max_history_score': 0.9607843137254901, 'max_history_score_std': 0.043526663832084804, 'max_history_step': 'joint', 'pipeline': {'features': ('features_PCA', {'features__n_components': 3}), 'normalizer': ('normalizer_MinMaxScaler', {}), 'rebalance': ('rebalance_NearMiss', {'rebalance__n_neighbors': 1})}, 'score': 0.9607843137254901, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'gini', 'max_depth': 3, 'max_features': 3, 'max_leaf_nodes': 2, 'min_samples_split': 2, 'n_estimators': 100}, 'config_hash': {'algorithm': '3c3fde6559b918694de4668d025d5418342db1b1', 'config': '037fd5c655b39cc7922fb394d736496befcc747b', 'pipeline': '2a5032814c6c7ed21dd5bd9686923d7fc2f8acc9'}, 'duration': 1.0435099601745605, 'iteration': 8, 'loss': 0.09955925352597172, 'max_history_score': 0.9607843137254901, 'max_history_score_std': 0.043526663832084804, 'max_history_step': 'joint', 'pipeline': {'features': ('features_NoneType', {}), 'normalizer': ('normalizer_RobustScaler', {'normalizer__quantile_range': (...), 'normalizer__with_centering': True, 'normalizer__with_scaling': True}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 7})}, 'score': 0.9004407464740283, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': 2, 'max_features': 1, 'max_leaf_nodes': None, 'min_samples_split': 3, 'n_estimators': 75}, 'config_hash': {'algorithm': '42185be98371e99ac896d2c6c2d69c451cb983ff', 'config': '6609280032189b59de1afbe36f3acb1d5c273693', 'pipeline': '8aab2941fc84d84f86fa56134e50909dbf9e19f5'}, 'duration': 0.9665219783782959, 'iteration': 9, 'loss': 0.01637426900584804, 'max_history_score': 0.983625730994152, 'max_history_score_std': 0.025023500462379746, 'max_history_step': 'joint', 'pipeline': {'features': ('features_NoneType', {}), 'normalizer': ('normalizer_PowerTransformer', {}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 5})}, 'score': 0.983625730994152, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': 1, 'max_features': 3, 'max_leaf_nodes': 2, 'min_samples_split': 3, 'n_estimators': 10}, 'config_hash': {'algorithm': '62a9fe705e4cd96e762bcc9543c4a456a5a9f188', 'config': '8e1c17ac9f6e03740f380fccb833c9c3931ffc35', 'pipeline': '3d44d7482e468d08c4f94457a205f3dac74084c1'}, 'duration': 0.46930503845214844, 'iteration': 10, 'loss': 1.0, 'max_history_score': 0.983625730994152, 'max_history_score_std': 0.025023500462379746, 'max_history_step': 'joint', 'pipeline': {'features': ('features_PCA', {'features__n_components': 1}), 'normalizer': ('normalizer_NoneType', {}), 'rebalance': ('rebalance_CondensedNearestNeighbour', {'rebalance__n_neighbors': 3})}, 'score': 0.0, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'gini', 'max_depth': 4, 'max_features': 1, 'max_leaf_nodes': 3, 'min_samples_split': 2, 'n_estimators': 100}, 'config_hash': {'algorithm': '086d6ca939a757bb32edb113a567f9d38744f061', 'config': '87c03d0cb8e8500e58cacc1a0f27ce54c41a2937', 'pipeline': '8f28ef0f35d97142278f9dacb4e9d1ff082e470f'}, 'duration': 2.1196961402893066, 'iteration': 11, 'loss': 0.15471276229790154, 'max_history_score': 0.983625730994152, 'max_history_score_std': 0.025023500462379746, 'max_history_step': 'joint', 'pipeline': {'features': ('features_PCA', {'features__n_components': 1}), 'normalizer': ('normalizer_StandardScaler', {'normalizer__with_mean': True, 'normalizer__with_std': True}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 7})}, 'score': 0.8452872377020985, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'entropy', 'max_depth': 3, 'max_features': 1, 'max_leaf_nodes': 2, 'min_samples_split': 2, 'n_estimators': 25}, 'config_hash': {'algorithm': '59f64a966796648c7bebade1127fa05541b391ad', 'config': '2ab964abffa0a277a9e2ee9b5570cd258e428b62', 'pipeline': 'eef3f702fd2fed761fa6744c1640d0bf320f1d00'}, 'duration': 0.9828321933746338, 'iteration': 12, 'loss': 0.0778465772273822, 'max_history_score': 0.983625730994152, 'max_history_score_std': 0.025023500462379746, 'max_history_step': 'joint', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 3, 'features__selectkbest__k': 1}), 'normalizer': ('normalizer_PowerTransformer', {}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 6})}, 'score': 0.9221534227726178, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'gini', 'max_depth': 4, 'max_features': 2, 'max_leaf_nodes': 3, 'min_samples_split': 3, 'n_estimators': 75}, 'config_hash': {'algorithm': '6f75c2a196eb9836df2b424e095051192eaed6ea', 'config': '5c95db3ad238063227f1b36e6a006d70c834c5da', 'pipeline': '1eae01a1128bee425c4d4ca0ee97a9afd409680e'}, 'duration': 0.8217771053314209, 'iteration': 13, 'loss': 0.03863089095287242, 'max_history_score': 0.983625730994152, 'max_history_score_std': 0.025023500462379746, 'max_history_step': 'joint', 'pipeline': {'features': ('features_NoneType', {}), 'normalizer': ('normalizer_StandardScaler', {'normalizer__with_mean': False, 'normalizer__with_std': False}), 'rebalance': ('rebalance_NearMiss', {'rebalance__n_neighbors': 1})}, 'score': 0.9613691090471276, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'entropy', 'max_depth': 4, 'max_features': 2, 'max_leaf_nodes': 3, 'min_samples_split': 2, 'n_estimators': 25}, 'config_hash': {'algorithm': '8aef3174f6b8020de06b825e0424c1e54d690afd', 'config': '50fd1169b8e42190600f25152654254b5d0e3ed1', 'pipeline': '9ceaa544911dc6c687e336cb8e9dd4d15ff1ceaf'}, 'duration': 0.40307188034057617, 'iteration': 14, 'loss': 1.0, 'max_history_score': 0.983625730994152, 'max_history_score_std': 0.025023500462379746, 'max_history_step': 'joint', 'pipeline': {'features': ('features_PCA', {'features__n_components': 1}), 'normalizer': ('normalizer_RobustScaler', {'normalizer__quantile_range': (...), 'normalizer__with_centering': False, 'normalizer__with_scaling': False}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 7})}, 'score': 0.0, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'gini', 'max_depth': 1, 'max_features': 1, 'max_leaf_nodes': 3, 'min_samples_split': 3, 'n_estimators': 50}, 'config_hash': {'algorithm': '37be8b6737f4b5d5ae35da51886f302b07ba6001', 'config': 'a05b6d2ffd65d4d937c0b178655d857bf4d61410', 'pipeline': 'cfef88e895db321122f2f7b813d9267b973c2468'}, 'duration': 1.7094659805297852, 'iteration': 15, 'loss': 0.011111111111111072, 'max_history_score': 0.9888888888888889, 'max_history_score_std': 0.022222222222222233, 'max_history_step': 'joint', 'pipeline': {'features': ('features_NoneType', {}), 'normalizer': ('normalizer_NoneType', {}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 5})}, 'score': 0.9888888888888889, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'entropy', 'max_depth': None, 'max_features': 3, 'max_leaf_nodes': None, 'min_samples_split': 2, 'n_estimators': 100}, 'config_hash': {'algorithm': 'c40543ce91793e367c1892c886bc49621c22ecfb', 'config': 'ebebb7a93116f14f470e062e37582a59f4aeb0df', 'pipeline': 'b50c63e800574e8b760f55f7c4ff1fcae8816dd8'}, 'duration': 0.6425540447235107, 'iteration': 16, 'loss': 1.0, 'max_history_score': 0.9888888888888889, 'max_history_score_std': 0.022222222222222233, 'max_history_step': 'joint', 'pipeline': {'features': ('features_PCA', {'features__n_components': 1}), 'normalizer': ('normalizer_PowerTransformer', {}), 'rebalance': ('rebalance_NearMiss', {'rebalance__n_neighbors': 1})}, 'score': 0.0, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'gini', 'max_depth': None, 'max_features': 1, 'max_leaf_nodes': 3, 'min_samples_split': 2, 'n_estimators': 50}, 'config_hash': {'algorithm': '0c69b9601237c20664085fa05764d855e28f98f7', 'config': 'a2c21314ddbba47ddbfe416e0aa14853a71179e0', 'pipeline': '914f81fa4fbb61db251201f32bd8ea11bfeea2a5'}, 'duration': 2.2209739685058594, 'iteration': 17, 'loss': 0.3206720846233231, 'max_history_score': 0.9888888888888889, 'max_history_score_std': 0.022222222222222233, 'max_history_step': 'joint', 'pipeline': {'features': ('features_SelectKBest', {'features__k': 4}), 'normalizer': ('normalizer_PowerTransformer', {}), 'rebalance': ('rebalance_CondensedNearestNeighbour', {'rebalance__n_neighbors': 1})}, 'score': 0.6793279153766769, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': 4, 'max_features': None, 'max_leaf_nodes': None, 'min_samples_split': 3, 'n_estimators': 25}, 'config_hash': {'algorithm': '1aae0f1fce5cab293ffdd4581c4838c8051ac815', 'config': '6c8a721218e7c550a98c5ba72ad9ff86afd5e3a4', 'pipeline': '77189452469cef9c840643f2babe0f825c6667c8'}, 'duration': 0.3951280117034912, 'iteration': 18, 'loss': 0.1804760061919506, 'max_history_score': 0.9888888888888889, 'max_history_score_std': 0.022222222222222233, 'max_history_step': 'joint', 'pipeline': {'features': ('features_SelectKBest', {'features__k': 2}), 'normalizer': ('normalizer_NoneType', {}), 'rebalance': ('rebalance_NearMiss', {'rebalance__n_neighbors': 1})}, 'score': 0.8195239938080494, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': None, 'max_features': 3, 'max_leaf_nodes': 5, 'min_samples_split': 3, 'n_estimators': 50}, 'config_hash': {'algorithm': '0129970b8c7fe034ac8283fb518a06cfbead63d2', 'config': '61bcd2f64860b3dfe2503be88a6bbec165db0754', 'pipeline': '359f2473075ecfd9ae3ce526da96143918517601'}, 'duration': 0.7467091083526611, 'iteration': 19, 'loss': 0.09915720674234607, 'max_history_score': 0.9888888888888889, 'max_history_score_std': 0.022222222222222233, 'max_history_step': 'joint', 'pipeline': {'features': ('features_SelectKBest', {'features__k': 3}), 'normalizer': ('normalizer_RobustScaler', {'normalizer__quantile_range': (...), 'normalizer__with_centering': True, 'normalizer__with_scaling': False}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 7})}, 'score': 0.9008427932576539, ...}, ...], 'history_hash': ['2e6648b63441361b4398cb94f81d2e04a830b2ef', '584343bc020d2d7bc89bd0856bc7770dae1c84fc', 'de121d053e65def047cc8947f505578d5c5eab67', 'b21c9d15a389baa5bfea4c8ddcec129259f37540', 'edd3456355d80775739c31515c832ca7b4e5e094', '0800d7d2c8c10d2f9e7b4e5127b343e916eb742c', 'd98b641879b4754f2169335626a90575e945fd7c', '3f83df36a6abbdf7ea4a4bdcaf6727f23529c2bb', '037fd5c655b39cc7922fb394d736496befcc747b', '6609280032189b59de1afbe36f3acb1d5c273693', '8e1c17ac9f6e03740f380fccb833c9c3931ffc35', '87c03d0cb8e8500e58cacc1a0f27ce54c41a2937', '2ab964abffa0a277a9e2ee9b5570cd258e428b62', '5c95db3ad238063227f1b36e6a006d70c834c5da', '50fd1169b8e42190600f25152654254b5d0e3ed1', 'a05b6d2ffd65d4d937c0b178655d857bf4d61410', 'ebebb7a93116f14f470e062e37582a59f4aeb0df', 'a2c21314ddbba47ddbfe416e0aa14853a71179e0', '6c8a721218e7c550a98c5ba72ad9ff86afd5e3a4', '61bcd2f64860b3dfe2503be88a6bbec165db0754', ...], 'history_index': {'037fd5c655b39cc7922fb394d736496befcc747b': 8, '07fdf9d0d0248a4b0215a633c75a2dd101dcf465': 22, '0800d7d2c8c10d2f9e7b4e5127b343e916eb742c': 5, '2ab964abffa0a277a9e2ee9b5570cd258e428b62': 12, '2e6648b63441361b4398cb94f81d2e04a830b2ef': 0, '3876a387c01c8d5fb746f320f2cc4d1168f512a0': 21, '3f83df36a6abbdf7ea4a4bdcaf6727f23529c2bb': 7, '50fd1169b8e42190600f25152654254b5d0e3ed1': 14, '584343bc020d2d7bc89bd0856bc7770dae1c84fc': 1, '5c95db3ad238063227f1b36e6a006d70c834c5da': 13, ...}, 'iteration': 28, 'max_history_score': 0.9944444444444445, 'max_history_score_std': 0.016666666666666673, 'max_history_step': 'joint'}
        config = {'algorithm': 'RandomForest', 'seed': 42, 'time': 300}
    114 
    115 
    116 def get_baseline_score(algorithm, X, y, seed):
    117     pipeline, _ = pipeline_conf_to_full_pipeline(

...........................................................................
/home/aquemy/dev/dp_hyperparameters/extension/experiment/objective.py in objective(pipeline_config={'features': ('features_SelectKBest', {'features__k': 1}), 'normalizer': ('normalizer_MinMaxScaler', {}), 'rebalance': ('rebalance_NoneType', {})}, algo_config={'bootstrap': False, 'criterion': 'entropy', 'max_depth': 1, 'max_features': 2, 'max_leaf_nodes': 5, 'min_samples_split': 5, 'n_estimators': 50}, algorithm='RandomForest', X=array([[1.423e+01, 1.710e+00, 2.430e+00, ..., 1...., ..., 6.100e-01, 1.600e+00,
        5.600e+02]]), y=array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,
       2, 2]), context={'baseline_score': 0.9444100447196423, 'baseline_score_std': 0.04305547117084885, 'best_config': {'algorithm': {'bootstrap': False, 'criterion': 'gini', 'max_depth': 1, 'max_features': 1, 'max_leaf_nodes': 3, 'min_samples_split': 5, 'n_estimators': 50}, 'config_hash': {'algorithm': 'cefc05c6c759dc564d289289fe401e0f8737951d', 'config': '7a1c40755d84d62f5d2ab1ed021e7dff93dfce45', 'pipeline': '3ee6a915db2d8d71f204c103803fb8eabea0d54f'}, 'duration': 0.6908998489379883, 'iteration': 24, 'loss': 0.005555555555555536, 'max_history_score': 0.9944444444444445, 'max_history_score_std': 0.016666666666666673, 'max_history_step': 'joint', 'pipeline': {'features': ('features_NoneType', {}), 'normalizer': ('normalizer_MinMaxScaler', {}), 'rebalance': ('rebalance_NoneType', {})}, 'score': 0.9944444444444445, ...}, 'history': [{'algorithm': {'bootstrap': False, 'criterion': 'entropy', 'max_depth': None, 'max_features': 3, 'max_leaf_nodes': 5, 'min_samples_split': 2, 'n_estimators': 50}, 'config_hash': {'algorithm': 'b2c6464add7a35ce8048653a39338c9994de9a4f', 'config': '2e6648b63441361b4398cb94f81d2e04a830b2ef', 'pipeline': '3d44d7482e468d08c4f94457a205f3dac74084c1'}, 'duration': 0.737678050994873, 'iteration': 0, 'loss': 1.0, 'max_history_score': 0.0, 'max_history_score_std': 0.0, 'max_history_step': 'baseline', 'pipeline': {'features': ('features_PCA', {'features__n_components': 1}), 'normalizer': ('normalizer_NoneType', {}), 'rebalance': ('rebalance_CondensedNearestNeighbour', {'rebalance__n_neighbors': 3})}, 'score': 0.0, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'gini', 'max_depth': 1, 'max_features': None, 'max_leaf_nodes': 2, 'min_samples_split': 3, 'n_estimators': 25}, 'config_hash': {'algorithm': '7f71bbbfdb4e8da52b6fc33a43224183117de15e', 'config': '584343bc020d2d7bc89bd0856bc7770dae1c84fc', 'pipeline': '466ffa7ace0e442beb7c311eb214b17a4c6832b3'}, 'duration': 1.5976769924163818, 'iteration': 1, 'loss': 0.40386351909184726, 'max_history_score': 0.5961364809081527, 'max_history_score_std': 0.05351463210025494, 'max_history_step': 'joint', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 3, 'features__selectkbest__k': 3}), 'normalizer': ('normalizer_StandardScaler', {'normalizer__with_mean': True, 'normalizer__with_std': True}), 'rebalance': ('rebalance_NearMiss', {'rebalance__n_neighbors': 2})}, 'score': 0.5961364809081527, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'entropy', 'max_depth': 1, 'max_features': 2, 'max_leaf_nodes': 2, 'min_samples_split': 5, 'n_estimators': 25}, 'config_hash': {'algorithm': '897745a20d929d43e760cacee0a764bd8070daa5', 'config': 'de121d053e65def047cc8947f505578d5c5eab67', 'pipeline': '63040b39b48626a8232e847e8327bdca5cd88611'}, 'duration': 0.815453052520752, 'iteration': 2, 'loss': 0.07327786377708967, 'max_history_score': 0.9267221362229103, 'max_history_score_std': 0.043920207373658794, 'max_history_step': 'joint', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 3, 'features__selectkbest__k': 2}), 'normalizer': ('normalizer_StandardScaler', {'normalizer__with_mean': True, 'normalizer__with_std': True}), 'rebalance': ('rebalance_NoneType', {})}, 'score': 0.9267221362229103, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'entropy', 'max_depth': 4, 'max_features': 3, 'max_leaf_nodes': None, 'min_samples_split': 2, 'n_estimators': 100}, 'config_hash': {'algorithm': 'dbd92c75280ec06b66ca4ad9b135cf36957031a4', 'config': 'b21c9d15a389baa5bfea4c8ddcec129259f37540', 'pipeline': '38866720d2f120c863351493b9b4e23b9a4506dc'}, 'duration': 1.2293269634246826, 'iteration': 3, 'loss': 0.07199862401100798, 'max_history_score': 0.928001375988992, 'max_history_score_std': 0.06518367535896959, 'max_history_step': 'joint', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 2, 'features__selectkbest__k': 4}), 'normalizer': ('normalizer_NoneType', {}), 'rebalance': ('rebalance_NoneType', {})}, 'score': 0.928001375988992, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': 2, 'max_features': None, 'max_leaf_nodes': None, 'min_samples_split': 5, 'n_estimators': 100}, 'config_hash': {'algorithm': 'f455eefd9fdd03ece88892c3f440c580bdf27ddb', 'config': 'edd3456355d80775739c31515c832ca7b4e5e094', 'pipeline': '1d1034f9f0871e43f896c1db4ed6fd572ed0a6ef'}, 'duration': 1.6186630725860596, 'iteration': 4, 'loss': 0.16651831785345705, 'max_history_score': 0.928001375988992, 'max_history_score_std': 0.06518367535896959, 'max_history_step': 'joint', 'pipeline': {'features': ('features_SelectKBest', {'features__k': 4}), 'normalizer': ('normalizer_MinMaxScaler', {}), 'rebalance': ('rebalance_CondensedNearestNeighbour', {'rebalance__n_neighbors': 1})}, 'score': 0.833481682146543, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'entropy', 'max_depth': 1, 'max_features': 2, 'max_leaf_nodes': None, 'min_samples_split': 2, 'n_estimators': 10}, 'config_hash': {'algorithm': '29906eaa0712a68ea145b12821d54ba445726fbf', 'config': '0800d7d2c8c10d2f9e7b4e5127b343e916eb742c', 'pipeline': '2e0f188ae61600352a7159285e0f542b4587a403'}, 'duration': 0.19410085678100586, 'iteration': 5, 'loss': 0.20164258685930514, 'max_history_score': 0.928001375988992, 'max_history_score_std': 0.06518367535896959, 'max_history_step': 'joint', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 3, 'features__selectkbest__k': 4}), 'normalizer': ('normalizer_StandardScaler', {'normalizer__with_mean': True, 'normalizer__with_std': False}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 7})}, 'score': 0.7983574131406949, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': 1, 'max_features': 1, 'max_leaf_nodes': 5, 'min_samples_split': 2, 'n_estimators': 25}, 'config_hash': {'algorithm': 'fbb7d57e38cfc08240f0af985282da418cb33556', 'config': 'd98b641879b4754f2169335626a90575e945fd7c', 'pipeline': '62463de065924498cdcd2f2f1f7e68535cdb33a5'}, 'duration': 0.3625810146331787, 'iteration': 6, 'loss': 0.14327485380116955, 'max_history_score': 0.928001375988992, 'max_history_score_std': 0.06518367535896959, 'max_history_step': 'joint', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 1, 'features__selectkbest__k': 2}), 'normalizer': ('normalizer_NoneType', {}), 'rebalance': ('rebalance_NoneType', {})}, 'score': 0.8567251461988304, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'entropy', 'max_depth': 3, 'max_features': 1, 'max_leaf_nodes': None, 'min_samples_split': 2, 'n_estimators': 75}, 'config_hash': {'algorithm': 'fb2f5d4c4d636edac929e1454ce3d02a4fb134c1', 'config': '3f83df36a6abbdf7ea4a4bdcaf6727f23529c2bb', 'pipeline': '8377b93e334656d1a93d266493b58ef9a6a1786f'}, 'duration': 0.8223779201507568, 'iteration': 7, 'loss': 0.03921568627450989, 'max_history_score': 0.9607843137254901, 'max_history_score_std': 0.043526663832084804, 'max_history_step': 'joint', 'pipeline': {'features': ('features_PCA', {'features__n_components': 3}), 'normalizer': ('normalizer_MinMaxScaler', {}), 'rebalance': ('rebalance_NearMiss', {'rebalance__n_neighbors': 1})}, 'score': 0.9607843137254901, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'gini', 'max_depth': 3, 'max_features': 3, 'max_leaf_nodes': 2, 'min_samples_split': 2, 'n_estimators': 100}, 'config_hash': {'algorithm': '3c3fde6559b918694de4668d025d5418342db1b1', 'config': '037fd5c655b39cc7922fb394d736496befcc747b', 'pipeline': '2a5032814c6c7ed21dd5bd9686923d7fc2f8acc9'}, 'duration': 1.0435099601745605, 'iteration': 8, 'loss': 0.09955925352597172, 'max_history_score': 0.9607843137254901, 'max_history_score_std': 0.043526663832084804, 'max_history_step': 'joint', 'pipeline': {'features': ('features_NoneType', {}), 'normalizer': ('normalizer_RobustScaler', {'normalizer__quantile_range': (...), 'normalizer__with_centering': True, 'normalizer__with_scaling': True}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 7})}, 'score': 0.9004407464740283, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': 2, 'max_features': 1, 'max_leaf_nodes': None, 'min_samples_split': 3, 'n_estimators': 75}, 'config_hash': {'algorithm': '42185be98371e99ac896d2c6c2d69c451cb983ff', 'config': '6609280032189b59de1afbe36f3acb1d5c273693', 'pipeline': '8aab2941fc84d84f86fa56134e50909dbf9e19f5'}, 'duration': 0.9665219783782959, 'iteration': 9, 'loss': 0.01637426900584804, 'max_history_score': 0.983625730994152, 'max_history_score_std': 0.025023500462379746, 'max_history_step': 'joint', 'pipeline': {'features': ('features_NoneType', {}), 'normalizer': ('normalizer_PowerTransformer', {}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 5})}, 'score': 0.983625730994152, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': 1, 'max_features': 3, 'max_leaf_nodes': 2, 'min_samples_split': 3, 'n_estimators': 10}, 'config_hash': {'algorithm': '62a9fe705e4cd96e762bcc9543c4a456a5a9f188', 'config': '8e1c17ac9f6e03740f380fccb833c9c3931ffc35', 'pipeline': '3d44d7482e468d08c4f94457a205f3dac74084c1'}, 'duration': 0.46930503845214844, 'iteration': 10, 'loss': 1.0, 'max_history_score': 0.983625730994152, 'max_history_score_std': 0.025023500462379746, 'max_history_step': 'joint', 'pipeline': {'features': ('features_PCA', {'features__n_components': 1}), 'normalizer': ('normalizer_NoneType', {}), 'rebalance': ('rebalance_CondensedNearestNeighbour', {'rebalance__n_neighbors': 3})}, 'score': 0.0, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'gini', 'max_depth': 4, 'max_features': 1, 'max_leaf_nodes': 3, 'min_samples_split': 2, 'n_estimators': 100}, 'config_hash': {'algorithm': '086d6ca939a757bb32edb113a567f9d38744f061', 'config': '87c03d0cb8e8500e58cacc1a0f27ce54c41a2937', 'pipeline': '8f28ef0f35d97142278f9dacb4e9d1ff082e470f'}, 'duration': 2.1196961402893066, 'iteration': 11, 'loss': 0.15471276229790154, 'max_history_score': 0.983625730994152, 'max_history_score_std': 0.025023500462379746, 'max_history_step': 'joint', 'pipeline': {'features': ('features_PCA', {'features__n_components': 1}), 'normalizer': ('normalizer_StandardScaler', {'normalizer__with_mean': True, 'normalizer__with_std': True}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 7})}, 'score': 0.8452872377020985, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'entropy', 'max_depth': 3, 'max_features': 1, 'max_leaf_nodes': 2, 'min_samples_split': 2, 'n_estimators': 25}, 'config_hash': {'algorithm': '59f64a966796648c7bebade1127fa05541b391ad', 'config': '2ab964abffa0a277a9e2ee9b5570cd258e428b62', 'pipeline': 'eef3f702fd2fed761fa6744c1640d0bf320f1d00'}, 'duration': 0.9828321933746338, 'iteration': 12, 'loss': 0.0778465772273822, 'max_history_score': 0.983625730994152, 'max_history_score_std': 0.025023500462379746, 'max_history_step': 'joint', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 3, 'features__selectkbest__k': 1}), 'normalizer': ('normalizer_PowerTransformer', {}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 6})}, 'score': 0.9221534227726178, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'gini', 'max_depth': 4, 'max_features': 2, 'max_leaf_nodes': 3, 'min_samples_split': 3, 'n_estimators': 75}, 'config_hash': {'algorithm': '6f75c2a196eb9836df2b424e095051192eaed6ea', 'config': '5c95db3ad238063227f1b36e6a006d70c834c5da', 'pipeline': '1eae01a1128bee425c4d4ca0ee97a9afd409680e'}, 'duration': 0.8217771053314209, 'iteration': 13, 'loss': 0.03863089095287242, 'max_history_score': 0.983625730994152, 'max_history_score_std': 0.025023500462379746, 'max_history_step': 'joint', 'pipeline': {'features': ('features_NoneType', {}), 'normalizer': ('normalizer_StandardScaler', {'normalizer__with_mean': False, 'normalizer__with_std': False}), 'rebalance': ('rebalance_NearMiss', {'rebalance__n_neighbors': 1})}, 'score': 0.9613691090471276, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'entropy', 'max_depth': 4, 'max_features': 2, 'max_leaf_nodes': 3, 'min_samples_split': 2, 'n_estimators': 25}, 'config_hash': {'algorithm': '8aef3174f6b8020de06b825e0424c1e54d690afd', 'config': '50fd1169b8e42190600f25152654254b5d0e3ed1', 'pipeline': '9ceaa544911dc6c687e336cb8e9dd4d15ff1ceaf'}, 'duration': 0.40307188034057617, 'iteration': 14, 'loss': 1.0, 'max_history_score': 0.983625730994152, 'max_history_score_std': 0.025023500462379746, 'max_history_step': 'joint', 'pipeline': {'features': ('features_PCA', {'features__n_components': 1}), 'normalizer': ('normalizer_RobustScaler', {'normalizer__quantile_range': (...), 'normalizer__with_centering': False, 'normalizer__with_scaling': False}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 7})}, 'score': 0.0, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'gini', 'max_depth': 1, 'max_features': 1, 'max_leaf_nodes': 3, 'min_samples_split': 3, 'n_estimators': 50}, 'config_hash': {'algorithm': '37be8b6737f4b5d5ae35da51886f302b07ba6001', 'config': 'a05b6d2ffd65d4d937c0b178655d857bf4d61410', 'pipeline': 'cfef88e895db321122f2f7b813d9267b973c2468'}, 'duration': 1.7094659805297852, 'iteration': 15, 'loss': 0.011111111111111072, 'max_history_score': 0.9888888888888889, 'max_history_score_std': 0.022222222222222233, 'max_history_step': 'joint', 'pipeline': {'features': ('features_NoneType', {}), 'normalizer': ('normalizer_NoneType', {}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 5})}, 'score': 0.9888888888888889, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'entropy', 'max_depth': None, 'max_features': 3, 'max_leaf_nodes': None, 'min_samples_split': 2, 'n_estimators': 100}, 'config_hash': {'algorithm': 'c40543ce91793e367c1892c886bc49621c22ecfb', 'config': 'ebebb7a93116f14f470e062e37582a59f4aeb0df', 'pipeline': 'b50c63e800574e8b760f55f7c4ff1fcae8816dd8'}, 'duration': 0.6425540447235107, 'iteration': 16, 'loss': 1.0, 'max_history_score': 0.9888888888888889, 'max_history_score_std': 0.022222222222222233, 'max_history_step': 'joint', 'pipeline': {'features': ('features_PCA', {'features__n_components': 1}), 'normalizer': ('normalizer_PowerTransformer', {}), 'rebalance': ('rebalance_NearMiss', {'rebalance__n_neighbors': 1})}, 'score': 0.0, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'gini', 'max_depth': None, 'max_features': 1, 'max_leaf_nodes': 3, 'min_samples_split': 2, 'n_estimators': 50}, 'config_hash': {'algorithm': '0c69b9601237c20664085fa05764d855e28f98f7', 'config': 'a2c21314ddbba47ddbfe416e0aa14853a71179e0', 'pipeline': '914f81fa4fbb61db251201f32bd8ea11bfeea2a5'}, 'duration': 2.2209739685058594, 'iteration': 17, 'loss': 0.3206720846233231, 'max_history_score': 0.9888888888888889, 'max_history_score_std': 0.022222222222222233, 'max_history_step': 'joint', 'pipeline': {'features': ('features_SelectKBest', {'features__k': 4}), 'normalizer': ('normalizer_PowerTransformer', {}), 'rebalance': ('rebalance_CondensedNearestNeighbour', {'rebalance__n_neighbors': 1})}, 'score': 0.6793279153766769, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': 4, 'max_features': None, 'max_leaf_nodes': None, 'min_samples_split': 3, 'n_estimators': 25}, 'config_hash': {'algorithm': '1aae0f1fce5cab293ffdd4581c4838c8051ac815', 'config': '6c8a721218e7c550a98c5ba72ad9ff86afd5e3a4', 'pipeline': '77189452469cef9c840643f2babe0f825c6667c8'}, 'duration': 0.3951280117034912, 'iteration': 18, 'loss': 0.1804760061919506, 'max_history_score': 0.9888888888888889, 'max_history_score_std': 0.022222222222222233, 'max_history_step': 'joint', 'pipeline': {'features': ('features_SelectKBest', {'features__k': 2}), 'normalizer': ('normalizer_NoneType', {}), 'rebalance': ('rebalance_NearMiss', {'rebalance__n_neighbors': 1})}, 'score': 0.8195239938080494, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': None, 'max_features': 3, 'max_leaf_nodes': 5, 'min_samples_split': 3, 'n_estimators': 50}, 'config_hash': {'algorithm': '0129970b8c7fe034ac8283fb518a06cfbead63d2', 'config': '61bcd2f64860b3dfe2503be88a6bbec165db0754', 'pipeline': '359f2473075ecfd9ae3ce526da96143918517601'}, 'duration': 0.7467091083526611, 'iteration': 19, 'loss': 0.09915720674234607, 'max_history_score': 0.9888888888888889, 'max_history_score_std': 0.022222222222222233, 'max_history_step': 'joint', 'pipeline': {'features': ('features_SelectKBest', {'features__k': 3}), 'normalizer': ('normalizer_RobustScaler', {'normalizer__quantile_range': (...), 'normalizer__with_centering': True, 'normalizer__with_scaling': False}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 7})}, 'score': 0.9008427932576539, ...}, ...], 'history_hash': ['2e6648b63441361b4398cb94f81d2e04a830b2ef', '584343bc020d2d7bc89bd0856bc7770dae1c84fc', 'de121d053e65def047cc8947f505578d5c5eab67', 'b21c9d15a389baa5bfea4c8ddcec129259f37540', 'edd3456355d80775739c31515c832ca7b4e5e094', '0800d7d2c8c10d2f9e7b4e5127b343e916eb742c', 'd98b641879b4754f2169335626a90575e945fd7c', '3f83df36a6abbdf7ea4a4bdcaf6727f23529c2bb', '037fd5c655b39cc7922fb394d736496befcc747b', '6609280032189b59de1afbe36f3acb1d5c273693', '8e1c17ac9f6e03740f380fccb833c9c3931ffc35', '87c03d0cb8e8500e58cacc1a0f27ce54c41a2937', '2ab964abffa0a277a9e2ee9b5570cd258e428b62', '5c95db3ad238063227f1b36e6a006d70c834c5da', '50fd1169b8e42190600f25152654254b5d0e3ed1', 'a05b6d2ffd65d4d937c0b178655d857bf4d61410', 'ebebb7a93116f14f470e062e37582a59f4aeb0df', 'a2c21314ddbba47ddbfe416e0aa14853a71179e0', '6c8a721218e7c550a98c5ba72ad9ff86afd5e3a4', '61bcd2f64860b3dfe2503be88a6bbec165db0754', ...], 'history_index': {'037fd5c655b39cc7922fb394d736496befcc747b': 8, '07fdf9d0d0248a4b0215a633c75a2dd101dcf465': 22, '0800d7d2c8c10d2f9e7b4e5127b343e916eb742c': 5, '2ab964abffa0a277a9e2ee9b5570cd258e428b62': 12, '2e6648b63441361b4398cb94f81d2e04a830b2ef': 0, '3876a387c01c8d5fb746f320f2cc4d1168f512a0': 21, '3f83df36a6abbdf7ea4a4bdcaf6727f23529c2bb': 7, '50fd1169b8e42190600f25152654254b5d0e3ed1': 14, '584343bc020d2d7bc89bd0856bc7770dae1c84fc': 1, '5c95db3ad238063227f1b36e6a006d70c834c5da': 13, ...}, 'iteration': 28, 'max_history_score': 0.9944444444444445, 'max_history_score_std': 0.016666666666666673, 'max_history_step': 'joint'}, config={'algorithm': 'RandomForest', 'seed': 42, 'time': 300}, step='joint')
     45                 y,
     46                 cv=10,
     47                 n_jobs=-1,
     48                 return_estimator=False,
     49                 return_train_score=False,
---> 50                 verbose=0)
     51         score = np.mean(scores['test_score'])
     52         std = np.std(scores['test_score'])
     53         status = STATUS_OK
     54     except Exception as e:

...........................................................................
/home/aquemy/.local/lib/python2.7/site-packages/sklearn/model_selection/_validation.py in cross_validate(estimator=Pipeline(memory=None,
     steps=[('normalizer',...e=42,
            verbose=0, warm_start=False))]), X=array([[1.423e+01, 1.710e+00, 2.430e+00, ..., 1...., ..., 6.100e-01, 1.600e+00,
        5.600e+02]]), y=array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,
       2, 2]), groups=None, scoring=None, cv=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1, verbose=0, fit_params=None, pre_dispatch='2*n_jobs', return_train_score=False, return_estimator=False, error_score='raise-deprecating')
    235         delayed(_fit_and_score)(
    236             clone(estimator), X, y, scorers, train, test, verbose, None,
    237             fit_params, return_train_score=return_train_score,
    238             return_times=True, return_estimator=return_estimator,
    239             error_score=error_score)
--> 240         for train, test in cv.split(X, y, groups))
        cv.split = <bound method StratifiedKFold.split of Stratifie...d(n_splits=10, random_state=None, shuffle=False)>
        X = array([[1.423e+01, 1.710e+00, 2.430e+00, ..., 1...., ..., 6.100e-01, 1.600e+00,
        5.600e+02]])
        y = array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,
       2, 2])
        groups = None
    241 
    242     zipped_scores = list(zip(*scores))
    243     if return_train_score:
    244         train_scores = zipped_scores.pop(0)

...........................................................................
/home/aquemy/.local/lib/python2.7/site-packages/sklearn/externals/joblib/parallel.py in __call__(self=Parallel(n_jobs=-1), iterable=<generator object <genexpr>>)
    925                 # No need to wait for async callbacks to trigger to
    926                 # consumption.
    927                 self._iterating = False
    928 
    929             with self._backend.retrieval_context():
--> 930                 self.retrieve()
        self.retrieve = <bound method Parallel.retrieve of Parallel(n_jobs=-1)>
    931             # Make sure that we get a last message telling us we are done
    932             elapsed_time = time.time() - self._start_time
    933             self._print('Done %3i out of %3i | elapsed: %s finished',
    934                         (len(self._output), len(self._output),

---------------------------------------------------------------------------
Joblib worker traceback:
---------------------------------------------------------------------------
ValueError                                         Mon Jun 17 12:45:40 2019
PID: 15205                                  Python 2.7.15+: /usr/bin/python
...........................................................................
/home/aquemy/.local/lib/python2.7/site-packages/sklearn/externals/joblib/parallel.py in __call__(self=<sklearn.externals.joblib.parallel.BatchedCalls object>)
    220     def __call__(self):
    221         # Set the default nested backend to self._backend but do not set the
    222         # change the default number of processes to -1
    223         with parallel_backend(self._backend, n_jobs=self._n_jobs):
    224             return [func(*args, **kwargs)
--> 225                     for func, args, kwargs in self.items]
        func = <function _fit_and_score>
        args = (Pipeline(memory=None,
     steps=[('normalizer',...e=42,
            verbose=0, warm_start=False))]), array([[1.423e+01, 1.710e+00, 2.430e+00, ..., 1...., ..., 6.100e-01, 1.600e+00,
        5.600e+02]]), array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,
       2, 2]), {'score': <function _passthrough_scorer>}, array([  6,   7,   8,   9,  10,  11,  12,  13,  ..., 170, 171, 172, 173, 174,
       175, 176, 177]), array([  0,   1,   2,   3,   4,   5,  59,  60,  ...,  64,  65,
        66, 130, 131, 132, 133, 134]), 0, None, None)
        kwargs = {'error_score': 'raise-deprecating', 'return_estimator': False, 'return_times': True, 'return_train_score': False}
        self.items = [(<function _fit_and_score>, (Pipeline(memory=None,
     steps=[('normalizer',...e=42,
            verbose=0, warm_start=False))]), array([[1.423e+01, 1.710e+00, 2.430e+00, ..., 1...., ..., 6.100e-01, 1.600e+00,
        5.600e+02]]), array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,
       2, 2]), {'score': <function _passthrough_scorer>}, array([  6,   7,   8,   9,  10,  11,  12,  13,  ..., 170, 171, 172, 173, 174,
       175, 176, 177]), array([  0,   1,   2,   3,   4,   5,  59,  60,  ...,  64,  65,
        66, 130, 131, 132, 133, 134]), 0, None, None), {'error_score': 'raise-deprecating', 'return_estimator': False, 'return_times': True, 'return_train_score': False})]
    226 
    227     def __len__(self):
    228         return self._size
    229 

...........................................................................
/home/aquemy/.local/lib/python2.7/site-packages/sklearn/model_selection/_validation.py in _fit_and_score(estimator=Pipeline(memory=None,
     steps=[('normalizer',...e=42,
            verbose=0, warm_start=False))]), X=array([[1.423e+01, 1.710e+00, 2.430e+00, ..., 1...., ..., 6.100e-01, 1.600e+00,
        5.600e+02]]), y=array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,
       2, 2]), scorer={'score': <function _passthrough_scorer>}, train=array([  6,   7,   8,   9,  10,  11,  12,  13,  ..., 170, 171, 172, 173, 174,
       175, 176, 177]), test=array([  0,   1,   2,   3,   4,   5,  59,  60,  ...,  64,  65,
        66, 130, 131, 132, 133, 134]), verbose=0, parameters=None, fit_params={}, return_train_score=False, return_parameters=False, return_n_test_samples=False, return_times=True, return_estimator=False, error_score='raise-deprecating')
    523 
    524     try:
    525         if y_train is None:
    526             estimator.fit(X_train, **fit_params)
    527         else:
--> 528             estimator.fit(X_train, y_train, **fit_params)
        estimator.fit = <bound method Pipeline.fit of Pipeline(memory=No...=42,
            verbose=0, warm_start=False))])>
        X_train = array([[1.439e+01, 1.870e+00, 2.450e+00, ..., 1...., ..., 6.100e-01, 1.600e+00,
        5.600e+02]])
        y_train = array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...2, 2, 2, 2, 2, 2, 2, 2, 2,
       2, 2, 2, 2, 2])
        fit_params = {}
    529 
    530     except Exception as e:
    531         # Note fit time as time until error
    532         fit_time = time.time() - start_time

...........................................................................
/usr/local/lib/python2.7/dist-packages/imblearn/pipeline.py in fit(self=Pipeline(memory=None,
     steps=[('normalizer',...e=42,
            verbose=0, warm_start=False))]), X=array([[1.439e+01, 1.870e+00, 2.450e+00, ..., 1...., ..., 6.100e-01, 1.600e+00,
        5.600e+02]]), y=array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...2, 2, 2, 2, 2, 2, 2, 2, 2,
       2, 2, 2, 2, 2]), **fit_params={})
    234             This estimator
    235 
    236         """
    237         Xt, yt, fit_params = self._fit(X, y, **fit_params)
    238         if self._final_estimator is not None:
--> 239             self._final_estimator.fit(Xt, yt, **fit_params)
        self._final_estimator.fit = <bound method RandomForestClassifier.fit of Rand...ate=42,
            verbose=0, warm_start=False)>
        Xt = array([[0.45991561],
       [0.45780591],
      ...3966],
       [0.07172996],
       [0.08860759]])
        yt = array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...2, 2, 2, 2, 2, 2, 2, 2, 2,
       2, 2, 2, 2, 2])
        fit_params = {}
    240         return self
    241 
    242     def fit_transform(self, X, y=None, **fit_params):
    243         """Fit the model and transform with the final estimator

...........................................................................
/home/aquemy/.local/lib/python2.7/site-packages/sklearn/ensemble/forest.py in fit(self=RandomForestClassifier(bootstrap=False, class_we...tate=42,
            verbose=0, warm_start=False), X=array([[0.4599156 ],
       [0.4578059 ],
      ...0.07172996],
       [0.08860759]], dtype=float32), y=array([[0.],
       [0.],
       [0.],
       [0...    [2.],
       [2.],
       [2.],
       [2.]]), sample_weight=None)
    328             trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,
    329                              **_joblib_parallel_args(prefer='threads'))(
    330                 delayed(_parallel_build_trees)(
    331                     t, self, X, y, sample_weight, i, len(trees),
    332                     verbose=self.verbose, class_weight=self.class_weight)
--> 333                 for i, t in enumerate(trees))
        i = 49
    334 
    335             # Collect newly grown trees
    336             self.estimators_.extend(trees)
    337 

...........................................................................
/home/aquemy/.local/lib/python2.7/site-packages/sklearn/externals/joblib/parallel.py in __call__(self=Parallel(n_jobs=1), iterable=<generator object <genexpr>>)
    912             # self._original_iterator is None, then this means either
    913             # that pre_dispatch == "all", n_jobs == 1 or that the first batch
    914             # was very quick and its callback already dispatched all the
    915             # remaining jobs.
    916             self._iterating = False
--> 917             if self.dispatch_one_batch(iterator):
        self.dispatch_one_batch = <bound method Parallel.dispatch_one_batch of Parallel(n_jobs=1)>
        iterator = <generator object <genexpr>>
    918                 self._iterating = self._original_iterator is not None
    919 
    920             while self.dispatch_one_batch(iterator):
    921                 pass

...........................................................................
/home/aquemy/.local/lib/python2.7/site-packages/sklearn/externals/joblib/parallel.py in dispatch_one_batch(self=Parallel(n_jobs=1), iterator=<generator object <genexpr>>)
    754                                  self._pickle_cache)
    755             if len(tasks) == 0:
    756                 # No more tasks available in the iterator: tell caller to stop.
    757                 return False
    758             else:
--> 759                 self._dispatch(tasks)
        self._dispatch = <bound method Parallel._dispatch of Parallel(n_jobs=1)>
        tasks = <sklearn.externals.joblib.parallel.BatchedCalls object>
    760                 return True
    761 
    762     def _print(self, msg, msg_args):
    763         """Display the message on stout or stderr depending on verbosity"""

...........................................................................
/home/aquemy/.local/lib/python2.7/site-packages/sklearn/externals/joblib/parallel.py in _dispatch(self=Parallel(n_jobs=1), batch=<sklearn.externals.joblib.parallel.BatchedCalls object>)
    711 
    712         dispatch_timestamp = time.time()
    713         cb = BatchCompletionCallBack(dispatch_timestamp, len(batch), self)
    714         with self._lock:
    715             job_idx = len(self._jobs)
--> 716             job = self._backend.apply_async(batch, callback=cb)
        job = undefined
        self._backend.apply_async = <bound method SequentialBackend.apply_async of <...lib._parallel_backends.SequentialBackend object>>
        batch = <sklearn.externals.joblib.parallel.BatchedCalls object>
        cb = <sklearn.externals.joblib.parallel.BatchCompletionCallBack object>
    717             # A job can complete so quickly than its callback is
    718             # called before we get here, causing self._jobs to
    719             # grow. To ensure correct results ordering, .insert is
    720             # used (rather than .append) in the following line

...........................................................................
/home/aquemy/.local/lib/python2.7/site-packages/sklearn/externals/joblib/_parallel_backends.py in apply_async(self=<sklearn.externals.joblib._parallel_backends.SequentialBackend object>, func=<sklearn.externals.joblib.parallel.BatchedCalls object>, callback=<sklearn.externals.joblib.parallel.BatchCompletionCallBack object>)
    177             raise ValueError('n_jobs == 0 in Parallel has no meaning')
    178         return 1
    179 
    180     def apply_async(self, func, callback=None):
    181         """Schedule a func to be run"""
--> 182         result = ImmediateResult(func)
        result = undefined
        func = <sklearn.externals.joblib.parallel.BatchedCalls object>
    183         if callback:
    184             callback(result)
    185         return result
    186 

...........................................................................
/home/aquemy/.local/lib/python2.7/site-packages/sklearn/externals/joblib/_parallel_backends.py in __init__(self=<sklearn.externals.joblib._parallel_backends.ImmediateResult object>, batch=<sklearn.externals.joblib.parallel.BatchedCalls object>)
    544 
    545 class ImmediateResult(object):
    546     def __init__(self, batch):
    547         # Don't delay the application, to avoid keeping the input
    548         # arguments in memory
--> 549         self.results = batch()
        self.results = undefined
        batch = <sklearn.externals.joblib.parallel.BatchedCalls object>
    550 
    551     def get(self):
    552         return self.results
    553 

...........................................................................
/home/aquemy/.local/lib/python2.7/site-packages/sklearn/externals/joblib/parallel.py in __call__(self=<sklearn.externals.joblib.parallel.BatchedCalls object>)
    220     def __call__(self):
    221         # Set the default nested backend to self._backend but do not set the
    222         # change the default number of processes to -1
    223         with parallel_backend(self._backend, n_jobs=self._n_jobs):
    224             return [func(*args, **kwargs)
--> 225                     for func, args, kwargs in self.items]
        func = <function _parallel_build_trees>
        args = (DecisionTreeClassifier(class_weight=None, criter...=False, random_state=1608637542, splitter='best'), RandomForestClassifier(bootstrap=False, class_we...tate=42,
            verbose=0, warm_start=False), array([[0.4599156 ],
       [0.4578059 ],
      ...0.07172996],
       [0.08860759]], dtype=float32), array([[0.],
       [0.],
       [0.],
       [0...    [2.],
       [2.],
       [2.],
       [2.]]), None, 0, 50)
        kwargs = {'class_weight': None, 'verbose': 0}
        self.items = [(<function _parallel_build_trees>, (DecisionTreeClassifier(class_weight=None, criter...=False, random_state=1608637542, splitter='best'), RandomForestClassifier(bootstrap=False, class_we...tate=42,
            verbose=0, warm_start=False), array([[0.4599156 ],
       [0.4578059 ],
      ...0.07172996],
       [0.08860759]], dtype=float32), array([[0.],
       [0.],
       [0.],
       [0...    [2.],
       [2.],
       [2.],
       [2.]]), None, 0, 50), {'class_weight': None, 'verbose': 0})]
    226 
    227     def __len__(self):
    228         return self._size
    229 

...........................................................................
/home/aquemy/.local/lib/python2.7/site-packages/sklearn/ensemble/forest.py in _parallel_build_trees(tree=DecisionTreeClassifier(class_weight=None, criter...=False, random_state=1608637542, splitter='best'), forest=RandomForestClassifier(bootstrap=False, class_we...tate=42,
            verbose=0, warm_start=False), X=array([[0.4599156 ],
       [0.4578059 ],
      ...0.07172996],
       [0.08860759]], dtype=float32), y=array([[0.],
       [0.],
       [0.],
       [0...    [2.],
       [2.],
       [2.],
       [2.]]), sample_weight=None, tree_idx=0, n_trees=50, verbose=0, class_weight=None)
    116         elif class_weight == 'balanced_subsample':
    117             curr_sample_weight *= compute_sample_weight('balanced', y, indices)
    118 
    119         tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)
    120     else:
--> 121         tree.fit(X, y, sample_weight=sample_weight, check_input=False)
        tree.fit = <bound method DecisionTreeClassifier.fit of Deci...False, random_state=1608637542, splitter='best')>
        X = array([[0.4599156 ],
       [0.4578059 ],
      ...0.07172996],
       [0.08860759]], dtype=float32)
        y = array([[0.],
       [0.],
       [0.],
       [0...    [2.],
       [2.],
       [2.],
       [2.]])
        sample_weight = None
    122 
    123     return tree
    124 
    125 

...........................................................................
/home/aquemy/.local/lib/python2.7/site-packages/sklearn/tree/tree.py in fit(self=DecisionTreeClassifier(class_weight=None, criter...=False, random_state=1608637542, splitter='best'), X=array([[0.4599156 ],
       [0.4578059 ],
      ...0.07172996],
       [0.08860759]], dtype=float32), y=array([[0.],
       [0.],
       [0.],
       [0...    [2.],
       [2.],
       [2.],
       [2.]]), sample_weight=None, check_input=False, X_idx_sorted=None)
    796 
    797         super(DecisionTreeClassifier, self).fit(
    798             X, y,
    799             sample_weight=sample_weight,
    800             check_input=check_input,
--> 801             X_idx_sorted=X_idx_sorted)
        X_idx_sorted = None
    802         return self
    803 
    804     def predict_proba(self, X, check_input=True):
    805         """Predict class probabilities of the input samples X.

...........................................................................
/home/aquemy/.local/lib/python2.7/site-packages/sklearn/tree/tree.py in fit(self=DecisionTreeClassifier(class_weight=None, criter...=False, random_state=1608637542, splitter='best'), X=array([[0.4599156 ],
       [0.4578059 ],
      ...0.07172996],
       [0.08860759]], dtype=float32), y=array([[0.],
       [0.],
       [0.],
       [0...    [2.],
       [2.],
       [2.],
       [2.]]), sample_weight=None, check_input=False, X_idx_sorted=None)
    237         if not 0 <= self.min_weight_fraction_leaf <= 0.5:
    238             raise ValueError("min_weight_fraction_leaf must in [0, 0.5]")
    239         if max_depth <= 0:
    240             raise ValueError("max_depth must be greater than zero. ")
    241         if not (0 < max_features <= self.n_features_):
--> 242             raise ValueError("max_features must be in (0, n_features]")
    243         if not isinstance(max_leaf_nodes, (numbers.Integral, np.integer)):
    244             raise ValueError("max_leaf_nodes must be integral number but was "
    245                              "%r" % max_leaf_nodes)
    246         if -1 < max_leaf_nodes < 2:

ValueError: max_features must be in (0, n_features]
___________________________________________________________________________
Best score: 0.994444444444 (0.0166666666667) [J] | Score: 0.0 (0.0) [J]
Best score: 0.994444444444 (0.0166666666667) [J] | Score: 0.889146886825 (0.0743213696926) [J]
Best score: 0.994444444444 (0.0166666666667) [J] | Score: 0.955153508772 (0.041747398576) [J]
Best score: 0.994444444444 (0.0166666666667) [J] | Score: 0.988888888889 (0.0222222222222) [J]
JoblibValueError
___________________________________________________________________________
...........................................................................
/home/aquemy/dev/dp_hyperparameters/extension/main.py in <module>()
     27 
     28     serializer.serialize_results(scenario, policy)
     29 
     30 if __name__ == "__main__":
     31     args = cli.parse_args()
---> 32     main(args)

...........................................................................
/home/aquemy/dev/dp_hyperparameters/extension/main.py in main(args=Namespace(customize=[(['control', 'seed'], '42')...io='./scenarios/rf_wine_joint.yaml', verbosity=0))
     21         test_size=0.4, 
     22         random_state=scenario['control']['seed']
     23     )
     24 
     25     policy = policies.initiate(scenario['setup']['policy'], config)
---> 26     policy.run(X,y)
        policy.run = <bound method Joint.run of <experiment.policies.joint.Joint object>>
        X = array([[1.423e+01, 1.710e+00, 2.430e+00, ..., 1...., ..., 6.100e-01, 1.600e+00,
        5.600e+02]])
        y = array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,
       2, 2])
     27 
     28     serializer.serialize_results(scenario, policy)
     29 
     30 if __name__ == "__main__":

...........................................................................
/home/aquemy/dev/dp_hyperparameters/extension/experiment/policies/joint.py in run(self=<experiment.policies.joint.Joint object>, X=array([[1.423e+01, 1.710e+00, 2.430e+00, ..., 1...., ..., 6.100e-01, 1.600e+00,
        5.600e+02]]), y=array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,
       2, 2]))
     32             algo=tpe.suggest, 
     33             max_evals=None,
     34             max_time=self.config['time'],     
     35             trials=trials,
     36             show_progressbar=False,
---> 37             verbose=0
     38         )
     39 
     40         best_config = self.context['best_config']
     41         super(Joint, self).display_step_results(best_config)

...........................................................................
/home/aquemy/dev/dp_hyperparameters/extension/hyperopt/fmin.py in fmin(fn=<functools.partial object>, space={'algorithm': {'bootstrap': <hyperopt.pyll.base.Apply object>, 'criterion': <hyperopt.pyll.base.Apply object>, 'max_depth': <hyperopt.pyll.base.Apply object>, 'max_features': <hyperopt.pyll.base.Apply object>, 'max_leaf_nodes': <hyperopt.pyll.base.Apply object>, 'min_samples_split': <hyperopt.pyll.base.Apply object>, 'n_estimators': <hyperopt.pyll.base.Apply object>}, 'pipeline': {'features': <hyperopt.pyll.base.Apply object>, 'normalizer': <hyperopt.pyll.base.Apply object>, 'rebalance': <hyperopt.pyll.base.Apply object>}}, algo=<function suggest>, max_evals=9223372036854775807, max_time=300, trials=<hyperopt.base.Trials object>, rstate=<mtrand.RandomState object>, allow_trials_fmin=True, pass_expr_memo_ctrl=None, catch_eval_exceptions=False, verbose=0, return_argmin=True, points_to_evaluate=None, max_queue_len=1, show_progressbar=False)
    406             pass_expr_memo_ctrl=pass_expr_memo_ctrl,
    407             verbose=verbose,
    408             catch_eval_exceptions=catch_eval_exceptions,
    409             return_argmin=return_argmin,
    410             show_progressbar=show_progressbar,
--> 411             max_time=max_time
        max_time = 300
    412         )
    413 
    414     if trials is None:
    415         if points_to_evaluate is None:

...........................................................................
/home/aquemy/dev/dp_hyperparameters/extension/hyperopt/base.py in fmin(self=<hyperopt.base.Trials object>, fn=<functools.partial object>, space={'algorithm': {'bootstrap': <hyperopt.pyll.base.Apply object>, 'criterion': <hyperopt.pyll.base.Apply object>, 'max_depth': <hyperopt.pyll.base.Apply object>, 'max_features': <hyperopt.pyll.base.Apply object>, 'max_leaf_nodes': <hyperopt.pyll.base.Apply object>, 'min_samples_split': <hyperopt.pyll.base.Apply object>, 'n_estimators': <hyperopt.pyll.base.Apply object>}, 'pipeline': {'features': <hyperopt.pyll.base.Apply object>, 'normalizer': <hyperopt.pyll.base.Apply object>, 'rebalance': <hyperopt.pyll.base.Apply object>}}, algo=<function suggest>, max_evals=9223372036854775807, max_time=300, rstate=<mtrand.RandomState object>, verbose=0, pass_expr_memo_ctrl=None, catch_eval_exceptions=False, return_argmin=True, show_progressbar=False)
    636             verbose=verbose,
    637             allow_trials_fmin=False,  # -- prevent recursion
    638             pass_expr_memo_ctrl=pass_expr_memo_ctrl,
    639             catch_eval_exceptions=catch_eval_exceptions,
    640             return_argmin=return_argmin,
--> 641             show_progressbar=show_progressbar)
        show_progressbar = False
    642 
    643 
    644 def trials_from_docs(docs, validate=True, **kwargs):
    645     """Construct a Trials base class instance from a list of trials documents

...........................................................................
/home/aquemy/dev/dp_hyperparameters/extension/hyperopt/fmin.py in fmin(fn=<functools.partial object>, space={'algorithm': {'bootstrap': <hyperopt.pyll.base.Apply object>, 'criterion': <hyperopt.pyll.base.Apply object>, 'max_depth': <hyperopt.pyll.base.Apply object>, 'max_features': <hyperopt.pyll.base.Apply object>, 'max_leaf_nodes': <hyperopt.pyll.base.Apply object>, 'min_samples_split': <hyperopt.pyll.base.Apply object>, 'n_estimators': <hyperopt.pyll.base.Apply object>}, 'pipeline': {'features': <hyperopt.pyll.base.Apply object>, 'normalizer': <hyperopt.pyll.base.Apply object>, 'rebalance': <hyperopt.pyll.base.Apply object>}}, algo=<function suggest>, max_evals=9223372036854775807, max_time=300, trials=<hyperopt.base.Trials object>, rstate=<mtrand.RandomState object>, allow_trials_fmin=False, pass_expr_memo_ctrl=None, catch_eval_exceptions=False, verbose=0, return_argmin=True, points_to_evaluate=None, max_queue_len=1, show_progressbar=False)
    426                     verbose=verbose,
    427                     max_queue_len=max_queue_len,
    428                     show_progressbar=show_progressbar,
    429                     max_time=max_time)
    430     rval.catch_eval_exceptions = catch_eval_exceptions
--> 431     rval.exhaust()
        rval.exhaust = <bound method FMinIter.exhaust of <hyperopt.fmin.FMinIter object>>
    432     if return_argmin:
    433         return trials.argmin
    434     elif len(trials) > 0:
    435         # Only if there are some succesfull trail runs, return the best point in the evaluation space

...........................................................................
/home/aquemy/dev/dp_hyperparameters/extension/hyperopt/fmin.py in exhaust(self=<hyperopt.fmin.FMinIter object>)
    273             raise StopIteration()
    274         return self.trials
    275 
    276     def exhaust(self):
    277         n_done = len(self.trials)
--> 278         self.run(self.max_evals - n_done, block_until_done=self.asynchronous)
        self.run = <bound method FMinIter.run of <hyperopt.fmin.FMinIter object>>
        self.max_evals = 9223372036854775807
        n_done = 0
        self.asynchronous = False
    279         self.trials.refresh()
    280         return self
    281 
    282 

...........................................................................
/home/aquemy/dev/dp_hyperparameters/extension/hyperopt/fmin.py in run(self=<hyperopt.fmin.FMinIter object>, N=9223372036854775807, block_until_done=False)
    232                     if self.asynchronous:
    233                         # -- wait for workers to fill in the trials
    234                         time.sleep(self.poll_interval_secs)
    235                     else:
    236                         # -- loop over trials and do the jobs directly
--> 237                         self.serial_evaluate()
        self.serial_evaluate = <bound method FMinIter.serial_evaluate of <hyperopt.fmin.FMinIter object>>
    238                     try:
    239                         res = [d['result']['loss'] for d in
    240                                          self.trials.trials if
    241                                          d['result']['status'] == 'ok']

...........................................................................
/home/aquemy/dev/dp_hyperparameters/extension/hyperopt/fmin.py in serial_evaluate(self=<hyperopt.fmin.FMinIter object>, N=-1)
    138                 trial['book_time'] = now
    139                 trial['refresh_time'] = now
    140                 spec = base.spec_from_misc(trial['misc'])
    141                 ctrl = base.Ctrl(self.trials, current_trial=trial)
    142                 try:
--> 143                     result = self.domain.evaluate(spec, ctrl)
        result = undefined
        self.domain.evaluate = <bound method Domain.evaluate of <hyperopt.base.Domain object>>
        spec = {'bootstrap': 1, 'criterion': 0, 'features': 3, 'features_FeatureUnion_features__pca__n_components': 0, 'features_FeatureUnion_features__selectkbest__k': 0, 'max_depth': 0, 'max_features': 2, 'max_leaf_nodes': 2, 'min_samples_split': 2, 'n_estimators': 2, ...}
        ctrl = <hyperopt.base.Ctrl object>
    144                 except Exception as e:
    145                     logger.info('job exception: %s' % str(e))
    146                     trial['state'] = base.JOB_STATE_ERROR
    147                     trial['misc']['error'] = (str(type(e)), str(e))

...........................................................................
/home/aquemy/dev/dp_hyperparameters/extension/hyperopt/base.py in evaluate(self=<hyperopt.base.Domain object>, config={'bootstrap': 1, 'criterion': 0, 'features': 3, 'features_FeatureUnion_features__pca__n_components': 0, 'features_FeatureUnion_features__selectkbest__k': 0, 'max_depth': 0, 'max_features': 2, 'max_leaf_nodes': 2, 'min_samples_split': 2, 'n_estimators': 2, ...}, ctrl=<hyperopt.base.Ctrl object>, attach_attachments=True)
    841             #    or the normal Python part (self.fn)
    842             pyll_rval = pyll.rec_eval(
    843                 self.expr,
    844                 memo=memo,
    845                 print_node_on_error=self.rec_eval_print_node_on_error)
--> 846             rval = self.fn(pyll_rval)
        rval = undefined
        self.fn = <functools.partial object>
        pyll_rval = {'algorithm': {'bootstrap': False, 'criterion': 'gini', 'max_depth': 1, 'max_features': 3, 'max_leaf_nodes': 5, 'min_samples_split': 5, 'n_estimators': 50}, 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 1, 'features__selectkbest__k': 1}), 'normalizer': ('normalizer_RobustScaler', {'normalizer__quantile_range': (5.0, 95.0), 'normalizer__with_centering': False, 'normalizer__with_scaling': True}), 'rebalance': ('rebalance_CondensedNearestNeighbour', {'rebalance__n_neighbors': 2})}}
    847 
    848         if isinstance(rval, (float, int, np.number)):
    849             dict_rval = {'loss': float(rval), 'status': STATUS_OK}
    850         else:

...........................................................................
/home/aquemy/dev/dp_hyperparameters/extension/experiment/objective.py in objective_joint(wconfig={'algorithm': {'bootstrap': False, 'criterion': 'gini', 'max_depth': 1, 'max_features': 3, 'max_leaf_nodes': 5, 'min_samples_split': 5, 'n_estimators': 50}, 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 1, 'features__selectkbest__k': 1}), 'normalizer': ('normalizer_RobustScaler', {'normalizer__quantile_range': (5.0, 95.0), 'normalizer__with_centering': False, 'normalizer__with_scaling': True}), 'rebalance': ('rebalance_CondensedNearestNeighbour', {'rebalance__n_neighbors': 2})}}, algorithm='RandomForest', X=array([[1.423e+01, 1.710e+00, 2.430e+00, ..., 1...., ..., 6.100e-01, 1.600e+00,
        5.600e+02]]), y=array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,
       2, 2]), context={'baseline_score': 0.9444100447196423, 'baseline_score_std': 0.04305547117084885, 'best_config': {'algorithm': {'bootstrap': False, 'criterion': 'gini', 'max_depth': 1, 'max_features': 1, 'max_leaf_nodes': 3, 'min_samples_split': 5, 'n_estimators': 50}, 'config_hash': {'algorithm': 'cefc05c6c759dc564d289289fe401e0f8737951d', 'config': '7a1c40755d84d62f5d2ab1ed021e7dff93dfce45', 'pipeline': '3ee6a915db2d8d71f204c103803fb8eabea0d54f'}, 'duration': 0.6908998489379883, 'iteration': 24, 'loss': 0.005555555555555536, 'max_history_score': 0.9944444444444445, 'max_history_score_std': 0.016666666666666673, 'max_history_step': 'joint', 'pipeline': {'features': ('features_NoneType', {}), 'normalizer': ('normalizer_MinMaxScaler', {}), 'rebalance': ('rebalance_NoneType', {})}, 'score': 0.9944444444444445, ...}, 'history': [{'algorithm': {'bootstrap': False, 'criterion': 'entropy', 'max_depth': None, 'max_features': 3, 'max_leaf_nodes': 5, 'min_samples_split': 2, 'n_estimators': 50}, 'config_hash': {'algorithm': 'b2c6464add7a35ce8048653a39338c9994de9a4f', 'config': '2e6648b63441361b4398cb94f81d2e04a830b2ef', 'pipeline': '3d44d7482e468d08c4f94457a205f3dac74084c1'}, 'duration': 0.737678050994873, 'iteration': 0, 'loss': 1.0, 'max_history_score': 0.0, 'max_history_score_std': 0.0, 'max_history_step': 'baseline', 'pipeline': {'features': ('features_PCA', {'features__n_components': 1}), 'normalizer': ('normalizer_NoneType', {}), 'rebalance': ('rebalance_CondensedNearestNeighbour', {'rebalance__n_neighbors': 3})}, 'score': 0.0, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'gini', 'max_depth': 1, 'max_features': None, 'max_leaf_nodes': 2, 'min_samples_split': 3, 'n_estimators': 25}, 'config_hash': {'algorithm': '7f71bbbfdb4e8da52b6fc33a43224183117de15e', 'config': '584343bc020d2d7bc89bd0856bc7770dae1c84fc', 'pipeline': '466ffa7ace0e442beb7c311eb214b17a4c6832b3'}, 'duration': 1.5976769924163818, 'iteration': 1, 'loss': 0.40386351909184726, 'max_history_score': 0.5961364809081527, 'max_history_score_std': 0.05351463210025494, 'max_history_step': 'joint', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 3, 'features__selectkbest__k': 3}), 'normalizer': ('normalizer_StandardScaler', {'normalizer__with_mean': True, 'normalizer__with_std': True}), 'rebalance': ('rebalance_NearMiss', {'rebalance__n_neighbors': 2})}, 'score': 0.5961364809081527, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'entropy', 'max_depth': 1, 'max_features': 2, 'max_leaf_nodes': 2, 'min_samples_split': 5, 'n_estimators': 25}, 'config_hash': {'algorithm': '897745a20d929d43e760cacee0a764bd8070daa5', 'config': 'de121d053e65def047cc8947f505578d5c5eab67', 'pipeline': '63040b39b48626a8232e847e8327bdca5cd88611'}, 'duration': 0.815453052520752, 'iteration': 2, 'loss': 0.07327786377708967, 'max_history_score': 0.9267221362229103, 'max_history_score_std': 0.043920207373658794, 'max_history_step': 'joint', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 3, 'features__selectkbest__k': 2}), 'normalizer': ('normalizer_StandardScaler', {'normalizer__with_mean': True, 'normalizer__with_std': True}), 'rebalance': ('rebalance_NoneType', {})}, 'score': 0.9267221362229103, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'entropy', 'max_depth': 4, 'max_features': 3, 'max_leaf_nodes': None, 'min_samples_split': 2, 'n_estimators': 100}, 'config_hash': {'algorithm': 'dbd92c75280ec06b66ca4ad9b135cf36957031a4', 'config': 'b21c9d15a389baa5bfea4c8ddcec129259f37540', 'pipeline': '38866720d2f120c863351493b9b4e23b9a4506dc'}, 'duration': 1.2293269634246826, 'iteration': 3, 'loss': 0.07199862401100798, 'max_history_score': 0.928001375988992, 'max_history_score_std': 0.06518367535896959, 'max_history_step': 'joint', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 2, 'features__selectkbest__k': 4}), 'normalizer': ('normalizer_NoneType', {}), 'rebalance': ('rebalance_NoneType', {})}, 'score': 0.928001375988992, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': 2, 'max_features': None, 'max_leaf_nodes': None, 'min_samples_split': 5, 'n_estimators': 100}, 'config_hash': {'algorithm': 'f455eefd9fdd03ece88892c3f440c580bdf27ddb', 'config': 'edd3456355d80775739c31515c832ca7b4e5e094', 'pipeline': '1d1034f9f0871e43f896c1db4ed6fd572ed0a6ef'}, 'duration': 1.6186630725860596, 'iteration': 4, 'loss': 0.16651831785345705, 'max_history_score': 0.928001375988992, 'max_history_score_std': 0.06518367535896959, 'max_history_step': 'joint', 'pipeline': {'features': ('features_SelectKBest', {'features__k': 4}), 'normalizer': ('normalizer_MinMaxScaler', {}), 'rebalance': ('rebalance_CondensedNearestNeighbour', {'rebalance__n_neighbors': 1})}, 'score': 0.833481682146543, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'entropy', 'max_depth': 1, 'max_features': 2, 'max_leaf_nodes': None, 'min_samples_split': 2, 'n_estimators': 10}, 'config_hash': {'algorithm': '29906eaa0712a68ea145b12821d54ba445726fbf', 'config': '0800d7d2c8c10d2f9e7b4e5127b343e916eb742c', 'pipeline': '2e0f188ae61600352a7159285e0f542b4587a403'}, 'duration': 0.19410085678100586, 'iteration': 5, 'loss': 0.20164258685930514, 'max_history_score': 0.928001375988992, 'max_history_score_std': 0.06518367535896959, 'max_history_step': 'joint', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 3, 'features__selectkbest__k': 4}), 'normalizer': ('normalizer_StandardScaler', {'normalizer__with_mean': True, 'normalizer__with_std': False}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 7})}, 'score': 0.7983574131406949, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': 1, 'max_features': 1, 'max_leaf_nodes': 5, 'min_samples_split': 2, 'n_estimators': 25}, 'config_hash': {'algorithm': 'fbb7d57e38cfc08240f0af985282da418cb33556', 'config': 'd98b641879b4754f2169335626a90575e945fd7c', 'pipeline': '62463de065924498cdcd2f2f1f7e68535cdb33a5'}, 'duration': 0.3625810146331787, 'iteration': 6, 'loss': 0.14327485380116955, 'max_history_score': 0.928001375988992, 'max_history_score_std': 0.06518367535896959, 'max_history_step': 'joint', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 1, 'features__selectkbest__k': 2}), 'normalizer': ('normalizer_NoneType', {}), 'rebalance': ('rebalance_NoneType', {})}, 'score': 0.8567251461988304, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'entropy', 'max_depth': 3, 'max_features': 1, 'max_leaf_nodes': None, 'min_samples_split': 2, 'n_estimators': 75}, 'config_hash': {'algorithm': 'fb2f5d4c4d636edac929e1454ce3d02a4fb134c1', 'config': '3f83df36a6abbdf7ea4a4bdcaf6727f23529c2bb', 'pipeline': '8377b93e334656d1a93d266493b58ef9a6a1786f'}, 'duration': 0.8223779201507568, 'iteration': 7, 'loss': 0.03921568627450989, 'max_history_score': 0.9607843137254901, 'max_history_score_std': 0.043526663832084804, 'max_history_step': 'joint', 'pipeline': {'features': ('features_PCA', {'features__n_components': 3}), 'normalizer': ('normalizer_MinMaxScaler', {}), 'rebalance': ('rebalance_NearMiss', {'rebalance__n_neighbors': 1})}, 'score': 0.9607843137254901, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'gini', 'max_depth': 3, 'max_features': 3, 'max_leaf_nodes': 2, 'min_samples_split': 2, 'n_estimators': 100}, 'config_hash': {'algorithm': '3c3fde6559b918694de4668d025d5418342db1b1', 'config': '037fd5c655b39cc7922fb394d736496befcc747b', 'pipeline': '2a5032814c6c7ed21dd5bd9686923d7fc2f8acc9'}, 'duration': 1.0435099601745605, 'iteration': 8, 'loss': 0.09955925352597172, 'max_history_score': 0.9607843137254901, 'max_history_score_std': 0.043526663832084804, 'max_history_step': 'joint', 'pipeline': {'features': ('features_NoneType', {}), 'normalizer': ('normalizer_RobustScaler', {'normalizer__quantile_range': (...), 'normalizer__with_centering': True, 'normalizer__with_scaling': True}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 7})}, 'score': 0.9004407464740283, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': 2, 'max_features': 1, 'max_leaf_nodes': None, 'min_samples_split': 3, 'n_estimators': 75}, 'config_hash': {'algorithm': '42185be98371e99ac896d2c6c2d69c451cb983ff', 'config': '6609280032189b59de1afbe36f3acb1d5c273693', 'pipeline': '8aab2941fc84d84f86fa56134e50909dbf9e19f5'}, 'duration': 0.9665219783782959, 'iteration': 9, 'loss': 0.01637426900584804, 'max_history_score': 0.983625730994152, 'max_history_score_std': 0.025023500462379746, 'max_history_step': 'joint', 'pipeline': {'features': ('features_NoneType', {}), 'normalizer': ('normalizer_PowerTransformer', {}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 5})}, 'score': 0.983625730994152, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': 1, 'max_features': 3, 'max_leaf_nodes': 2, 'min_samples_split': 3, 'n_estimators': 10}, 'config_hash': {'algorithm': '62a9fe705e4cd96e762bcc9543c4a456a5a9f188', 'config': '8e1c17ac9f6e03740f380fccb833c9c3931ffc35', 'pipeline': '3d44d7482e468d08c4f94457a205f3dac74084c1'}, 'duration': 0.46930503845214844, 'iteration': 10, 'loss': 1.0, 'max_history_score': 0.983625730994152, 'max_history_score_std': 0.025023500462379746, 'max_history_step': 'joint', 'pipeline': {'features': ('features_PCA', {'features__n_components': 1}), 'normalizer': ('normalizer_NoneType', {}), 'rebalance': ('rebalance_CondensedNearestNeighbour', {'rebalance__n_neighbors': 3})}, 'score': 0.0, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'gini', 'max_depth': 4, 'max_features': 1, 'max_leaf_nodes': 3, 'min_samples_split': 2, 'n_estimators': 100}, 'config_hash': {'algorithm': '086d6ca939a757bb32edb113a567f9d38744f061', 'config': '87c03d0cb8e8500e58cacc1a0f27ce54c41a2937', 'pipeline': '8f28ef0f35d97142278f9dacb4e9d1ff082e470f'}, 'duration': 2.1196961402893066, 'iteration': 11, 'loss': 0.15471276229790154, 'max_history_score': 0.983625730994152, 'max_history_score_std': 0.025023500462379746, 'max_history_step': 'joint', 'pipeline': {'features': ('features_PCA', {'features__n_components': 1}), 'normalizer': ('normalizer_StandardScaler', {'normalizer__with_mean': True, 'normalizer__with_std': True}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 7})}, 'score': 0.8452872377020985, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'entropy', 'max_depth': 3, 'max_features': 1, 'max_leaf_nodes': 2, 'min_samples_split': 2, 'n_estimators': 25}, 'config_hash': {'algorithm': '59f64a966796648c7bebade1127fa05541b391ad', 'config': '2ab964abffa0a277a9e2ee9b5570cd258e428b62', 'pipeline': 'eef3f702fd2fed761fa6744c1640d0bf320f1d00'}, 'duration': 0.9828321933746338, 'iteration': 12, 'loss': 0.0778465772273822, 'max_history_score': 0.983625730994152, 'max_history_score_std': 0.025023500462379746, 'max_history_step': 'joint', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 3, 'features__selectkbest__k': 1}), 'normalizer': ('normalizer_PowerTransformer', {}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 6})}, 'score': 0.9221534227726178, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'gini', 'max_depth': 4, 'max_features': 2, 'max_leaf_nodes': 3, 'min_samples_split': 3, 'n_estimators': 75}, 'config_hash': {'algorithm': '6f75c2a196eb9836df2b424e095051192eaed6ea', 'config': '5c95db3ad238063227f1b36e6a006d70c834c5da', 'pipeline': '1eae01a1128bee425c4d4ca0ee97a9afd409680e'}, 'duration': 0.8217771053314209, 'iteration': 13, 'loss': 0.03863089095287242, 'max_history_score': 0.983625730994152, 'max_history_score_std': 0.025023500462379746, 'max_history_step': 'joint', 'pipeline': {'features': ('features_NoneType', {}), 'normalizer': ('normalizer_StandardScaler', {'normalizer__with_mean': False, 'normalizer__with_std': False}), 'rebalance': ('rebalance_NearMiss', {'rebalance__n_neighbors': 1})}, 'score': 0.9613691090471276, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'entropy', 'max_depth': 4, 'max_features': 2, 'max_leaf_nodes': 3, 'min_samples_split': 2, 'n_estimators': 25}, 'config_hash': {'algorithm': '8aef3174f6b8020de06b825e0424c1e54d690afd', 'config': '50fd1169b8e42190600f25152654254b5d0e3ed1', 'pipeline': '9ceaa544911dc6c687e336cb8e9dd4d15ff1ceaf'}, 'duration': 0.40307188034057617, 'iteration': 14, 'loss': 1.0, 'max_history_score': 0.983625730994152, 'max_history_score_std': 0.025023500462379746, 'max_history_step': 'joint', 'pipeline': {'features': ('features_PCA', {'features__n_components': 1}), 'normalizer': ('normalizer_RobustScaler', {'normalizer__quantile_range': (...), 'normalizer__with_centering': False, 'normalizer__with_scaling': False}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 7})}, 'score': 0.0, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'gini', 'max_depth': 1, 'max_features': 1, 'max_leaf_nodes': 3, 'min_samples_split': 3, 'n_estimators': 50}, 'config_hash': {'algorithm': '37be8b6737f4b5d5ae35da51886f302b07ba6001', 'config': 'a05b6d2ffd65d4d937c0b178655d857bf4d61410', 'pipeline': 'cfef88e895db321122f2f7b813d9267b973c2468'}, 'duration': 1.7094659805297852, 'iteration': 15, 'loss': 0.011111111111111072, 'max_history_score': 0.9888888888888889, 'max_history_score_std': 0.022222222222222233, 'max_history_step': 'joint', 'pipeline': {'features': ('features_NoneType', {}), 'normalizer': ('normalizer_NoneType', {}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 5})}, 'score': 0.9888888888888889, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'entropy', 'max_depth': None, 'max_features': 3, 'max_leaf_nodes': None, 'min_samples_split': 2, 'n_estimators': 100}, 'config_hash': {'algorithm': 'c40543ce91793e367c1892c886bc49621c22ecfb', 'config': 'ebebb7a93116f14f470e062e37582a59f4aeb0df', 'pipeline': 'b50c63e800574e8b760f55f7c4ff1fcae8816dd8'}, 'duration': 0.6425540447235107, 'iteration': 16, 'loss': 1.0, 'max_history_score': 0.9888888888888889, 'max_history_score_std': 0.022222222222222233, 'max_history_step': 'joint', 'pipeline': {'features': ('features_PCA', {'features__n_components': 1}), 'normalizer': ('normalizer_PowerTransformer', {}), 'rebalance': ('rebalance_NearMiss', {'rebalance__n_neighbors': 1})}, 'score': 0.0, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'gini', 'max_depth': None, 'max_features': 1, 'max_leaf_nodes': 3, 'min_samples_split': 2, 'n_estimators': 50}, 'config_hash': {'algorithm': '0c69b9601237c20664085fa05764d855e28f98f7', 'config': 'a2c21314ddbba47ddbfe416e0aa14853a71179e0', 'pipeline': '914f81fa4fbb61db251201f32bd8ea11bfeea2a5'}, 'duration': 2.2209739685058594, 'iteration': 17, 'loss': 0.3206720846233231, 'max_history_score': 0.9888888888888889, 'max_history_score_std': 0.022222222222222233, 'max_history_step': 'joint', 'pipeline': {'features': ('features_SelectKBest', {'features__k': 4}), 'normalizer': ('normalizer_PowerTransformer', {}), 'rebalance': ('rebalance_CondensedNearestNeighbour', {'rebalance__n_neighbors': 1})}, 'score': 0.6793279153766769, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': 4, 'max_features': None, 'max_leaf_nodes': None, 'min_samples_split': 3, 'n_estimators': 25}, 'config_hash': {'algorithm': '1aae0f1fce5cab293ffdd4581c4838c8051ac815', 'config': '6c8a721218e7c550a98c5ba72ad9ff86afd5e3a4', 'pipeline': '77189452469cef9c840643f2babe0f825c6667c8'}, 'duration': 0.3951280117034912, 'iteration': 18, 'loss': 0.1804760061919506, 'max_history_score': 0.9888888888888889, 'max_history_score_std': 0.022222222222222233, 'max_history_step': 'joint', 'pipeline': {'features': ('features_SelectKBest', {'features__k': 2}), 'normalizer': ('normalizer_NoneType', {}), 'rebalance': ('rebalance_NearMiss', {'rebalance__n_neighbors': 1})}, 'score': 0.8195239938080494, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': None, 'max_features': 3, 'max_leaf_nodes': 5, 'min_samples_split': 3, 'n_estimators': 50}, 'config_hash': {'algorithm': '0129970b8c7fe034ac8283fb518a06cfbead63d2', 'config': '61bcd2f64860b3dfe2503be88a6bbec165db0754', 'pipeline': '359f2473075ecfd9ae3ce526da96143918517601'}, 'duration': 0.7467091083526611, 'iteration': 19, 'loss': 0.09915720674234607, 'max_history_score': 0.9888888888888889, 'max_history_score_std': 0.022222222222222233, 'max_history_step': 'joint', 'pipeline': {'features': ('features_SelectKBest', {'features__k': 3}), 'normalizer': ('normalizer_RobustScaler', {'normalizer__quantile_range': (...), 'normalizer__with_centering': True, 'normalizer__with_scaling': False}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 7})}, 'score': 0.9008427932576539, ...}, ...], 'history_hash': ['2e6648b63441361b4398cb94f81d2e04a830b2ef', '584343bc020d2d7bc89bd0856bc7770dae1c84fc', 'de121d053e65def047cc8947f505578d5c5eab67', 'b21c9d15a389baa5bfea4c8ddcec129259f37540', 'edd3456355d80775739c31515c832ca7b4e5e094', '0800d7d2c8c10d2f9e7b4e5127b343e916eb742c', 'd98b641879b4754f2169335626a90575e945fd7c', '3f83df36a6abbdf7ea4a4bdcaf6727f23529c2bb', '037fd5c655b39cc7922fb394d736496befcc747b', '6609280032189b59de1afbe36f3acb1d5c273693', '8e1c17ac9f6e03740f380fccb833c9c3931ffc35', '87c03d0cb8e8500e58cacc1a0f27ce54c41a2937', '2ab964abffa0a277a9e2ee9b5570cd258e428b62', '5c95db3ad238063227f1b36e6a006d70c834c5da', '50fd1169b8e42190600f25152654254b5d0e3ed1', 'a05b6d2ffd65d4d937c0b178655d857bf4d61410', 'ebebb7a93116f14f470e062e37582a59f4aeb0df', 'a2c21314ddbba47ddbfe416e0aa14853a71179e0', '6c8a721218e7c550a98c5ba72ad9ff86afd5e3a4', '61bcd2f64860b3dfe2503be88a6bbec165db0754', ...], 'history_index': {'037fd5c655b39cc7922fb394d736496befcc747b': 8, '07fdf9d0d0248a4b0215a633c75a2dd101dcf465': 22, '0800d7d2c8c10d2f9e7b4e5127b343e916eb742c': 5, '0e45095dfe50d5be759b179b50e63384925c7027': 32, '28944b74104bc5bb782512b0eefa3167fe189355': 30, '2a317f1667c0a37724743084ca5dcbf14ff107f0': 29, '2ab964abffa0a277a9e2ee9b5570cd258e428b62': 12, '2e6648b63441361b4398cb94f81d2e04a830b2ef': 0, '3876a387c01c8d5fb746f320f2cc4d1168f512a0': 21, '3f83df36a6abbdf7ea4a4bdcaf6727f23529c2bb': 7, ...}, 'iteration': 32, 'max_history_score': 0.9944444444444445, 'max_history_score_std': 0.016666666666666673, 'max_history_step': 'joint'}, config={'algorithm': 'RandomForest', 'seed': 42, 'time': 300})
    108 
    109 def objective_algo(algo_config, current_pipeline_config, algorithm, X, y, context, config):
    110     return objective(current_pipeline_config, algo_config, algorithm, X, y, context, config, step='algorithm')
    111 
    112 def objective_joint(wconfig, algorithm, X, y, context, config):
--> 113     return objective(wconfig['pipeline'], wconfig['algorithm'], algorithm, X, y, context, config, step='joint')
        wconfig = {'algorithm': {'bootstrap': False, 'criterion': 'gini', 'max_depth': 1, 'max_features': 3, 'max_leaf_nodes': 5, 'min_samples_split': 5, 'n_estimators': 50}, 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 1, 'features__selectkbest__k': 1}), 'normalizer': ('normalizer_RobustScaler', {'normalizer__quantile_range': (5.0, 95.0), 'normalizer__with_centering': False, 'normalizer__with_scaling': True}), 'rebalance': ('rebalance_CondensedNearestNeighbour', {'rebalance__n_neighbors': 2})}}
        algorithm = 'RandomForest'
        X = array([[1.423e+01, 1.710e+00, 2.430e+00, ..., 1...., ..., 6.100e-01, 1.600e+00,
        5.600e+02]])
        y = array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,
       2, 2])
        context = {'baseline_score': 0.9444100447196423, 'baseline_score_std': 0.04305547117084885, 'best_config': {'algorithm': {'bootstrap': False, 'criterion': 'gini', 'max_depth': 1, 'max_features': 1, 'max_leaf_nodes': 3, 'min_samples_split': 5, 'n_estimators': 50}, 'config_hash': {'algorithm': 'cefc05c6c759dc564d289289fe401e0f8737951d', 'config': '7a1c40755d84d62f5d2ab1ed021e7dff93dfce45', 'pipeline': '3ee6a915db2d8d71f204c103803fb8eabea0d54f'}, 'duration': 0.6908998489379883, 'iteration': 24, 'loss': 0.005555555555555536, 'max_history_score': 0.9944444444444445, 'max_history_score_std': 0.016666666666666673, 'max_history_step': 'joint', 'pipeline': {'features': ('features_NoneType', {}), 'normalizer': ('normalizer_MinMaxScaler', {}), 'rebalance': ('rebalance_NoneType', {})}, 'score': 0.9944444444444445, ...}, 'history': [{'algorithm': {'bootstrap': False, 'criterion': 'entropy', 'max_depth': None, 'max_features': 3, 'max_leaf_nodes': 5, 'min_samples_split': 2, 'n_estimators': 50}, 'config_hash': {'algorithm': 'b2c6464add7a35ce8048653a39338c9994de9a4f', 'config': '2e6648b63441361b4398cb94f81d2e04a830b2ef', 'pipeline': '3d44d7482e468d08c4f94457a205f3dac74084c1'}, 'duration': 0.737678050994873, 'iteration': 0, 'loss': 1.0, 'max_history_score': 0.0, 'max_history_score_std': 0.0, 'max_history_step': 'baseline', 'pipeline': {'features': ('features_PCA', {'features__n_components': 1}), 'normalizer': ('normalizer_NoneType', {}), 'rebalance': ('rebalance_CondensedNearestNeighbour', {'rebalance__n_neighbors': 3})}, 'score': 0.0, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'gini', 'max_depth': 1, 'max_features': None, 'max_leaf_nodes': 2, 'min_samples_split': 3, 'n_estimators': 25}, 'config_hash': {'algorithm': '7f71bbbfdb4e8da52b6fc33a43224183117de15e', 'config': '584343bc020d2d7bc89bd0856bc7770dae1c84fc', 'pipeline': '466ffa7ace0e442beb7c311eb214b17a4c6832b3'}, 'duration': 1.5976769924163818, 'iteration': 1, 'loss': 0.40386351909184726, 'max_history_score': 0.5961364809081527, 'max_history_score_std': 0.05351463210025494, 'max_history_step': 'joint', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 3, 'features__selectkbest__k': 3}), 'normalizer': ('normalizer_StandardScaler', {'normalizer__with_mean': True, 'normalizer__with_std': True}), 'rebalance': ('rebalance_NearMiss', {'rebalance__n_neighbors': 2})}, 'score': 0.5961364809081527, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'entropy', 'max_depth': 1, 'max_features': 2, 'max_leaf_nodes': 2, 'min_samples_split': 5, 'n_estimators': 25}, 'config_hash': {'algorithm': '897745a20d929d43e760cacee0a764bd8070daa5', 'config': 'de121d053e65def047cc8947f505578d5c5eab67', 'pipeline': '63040b39b48626a8232e847e8327bdca5cd88611'}, 'duration': 0.815453052520752, 'iteration': 2, 'loss': 0.07327786377708967, 'max_history_score': 0.9267221362229103, 'max_history_score_std': 0.043920207373658794, 'max_history_step': 'joint', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 3, 'features__selectkbest__k': 2}), 'normalizer': ('normalizer_StandardScaler', {'normalizer__with_mean': True, 'normalizer__with_std': True}), 'rebalance': ('rebalance_NoneType', {})}, 'score': 0.9267221362229103, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'entropy', 'max_depth': 4, 'max_features': 3, 'max_leaf_nodes': None, 'min_samples_split': 2, 'n_estimators': 100}, 'config_hash': {'algorithm': 'dbd92c75280ec06b66ca4ad9b135cf36957031a4', 'config': 'b21c9d15a389baa5bfea4c8ddcec129259f37540', 'pipeline': '38866720d2f120c863351493b9b4e23b9a4506dc'}, 'duration': 1.2293269634246826, 'iteration': 3, 'loss': 0.07199862401100798, 'max_history_score': 0.928001375988992, 'max_history_score_std': 0.06518367535896959, 'max_history_step': 'joint', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 2, 'features__selectkbest__k': 4}), 'normalizer': ('normalizer_NoneType', {}), 'rebalance': ('rebalance_NoneType', {})}, 'score': 0.928001375988992, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': 2, 'max_features': None, 'max_leaf_nodes': None, 'min_samples_split': 5, 'n_estimators': 100}, 'config_hash': {'algorithm': 'f455eefd9fdd03ece88892c3f440c580bdf27ddb', 'config': 'edd3456355d80775739c31515c832ca7b4e5e094', 'pipeline': '1d1034f9f0871e43f896c1db4ed6fd572ed0a6ef'}, 'duration': 1.6186630725860596, 'iteration': 4, 'loss': 0.16651831785345705, 'max_history_score': 0.928001375988992, 'max_history_score_std': 0.06518367535896959, 'max_history_step': 'joint', 'pipeline': {'features': ('features_SelectKBest', {'features__k': 4}), 'normalizer': ('normalizer_MinMaxScaler', {}), 'rebalance': ('rebalance_CondensedNearestNeighbour', {'rebalance__n_neighbors': 1})}, 'score': 0.833481682146543, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'entropy', 'max_depth': 1, 'max_features': 2, 'max_leaf_nodes': None, 'min_samples_split': 2, 'n_estimators': 10}, 'config_hash': {'algorithm': '29906eaa0712a68ea145b12821d54ba445726fbf', 'config': '0800d7d2c8c10d2f9e7b4e5127b343e916eb742c', 'pipeline': '2e0f188ae61600352a7159285e0f542b4587a403'}, 'duration': 0.19410085678100586, 'iteration': 5, 'loss': 0.20164258685930514, 'max_history_score': 0.928001375988992, 'max_history_score_std': 0.06518367535896959, 'max_history_step': 'joint', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 3, 'features__selectkbest__k': 4}), 'normalizer': ('normalizer_StandardScaler', {'normalizer__with_mean': True, 'normalizer__with_std': False}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 7})}, 'score': 0.7983574131406949, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': 1, 'max_features': 1, 'max_leaf_nodes': 5, 'min_samples_split': 2, 'n_estimators': 25}, 'config_hash': {'algorithm': 'fbb7d57e38cfc08240f0af985282da418cb33556', 'config': 'd98b641879b4754f2169335626a90575e945fd7c', 'pipeline': '62463de065924498cdcd2f2f1f7e68535cdb33a5'}, 'duration': 0.3625810146331787, 'iteration': 6, 'loss': 0.14327485380116955, 'max_history_score': 0.928001375988992, 'max_history_score_std': 0.06518367535896959, 'max_history_step': 'joint', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 1, 'features__selectkbest__k': 2}), 'normalizer': ('normalizer_NoneType', {}), 'rebalance': ('rebalance_NoneType', {})}, 'score': 0.8567251461988304, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'entropy', 'max_depth': 3, 'max_features': 1, 'max_leaf_nodes': None, 'min_samples_split': 2, 'n_estimators': 75}, 'config_hash': {'algorithm': 'fb2f5d4c4d636edac929e1454ce3d02a4fb134c1', 'config': '3f83df36a6abbdf7ea4a4bdcaf6727f23529c2bb', 'pipeline': '8377b93e334656d1a93d266493b58ef9a6a1786f'}, 'duration': 0.8223779201507568, 'iteration': 7, 'loss': 0.03921568627450989, 'max_history_score': 0.9607843137254901, 'max_history_score_std': 0.043526663832084804, 'max_history_step': 'joint', 'pipeline': {'features': ('features_PCA', {'features__n_components': 3}), 'normalizer': ('normalizer_MinMaxScaler', {}), 'rebalance': ('rebalance_NearMiss', {'rebalance__n_neighbors': 1})}, 'score': 0.9607843137254901, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'gini', 'max_depth': 3, 'max_features': 3, 'max_leaf_nodes': 2, 'min_samples_split': 2, 'n_estimators': 100}, 'config_hash': {'algorithm': '3c3fde6559b918694de4668d025d5418342db1b1', 'config': '037fd5c655b39cc7922fb394d736496befcc747b', 'pipeline': '2a5032814c6c7ed21dd5bd9686923d7fc2f8acc9'}, 'duration': 1.0435099601745605, 'iteration': 8, 'loss': 0.09955925352597172, 'max_history_score': 0.9607843137254901, 'max_history_score_std': 0.043526663832084804, 'max_history_step': 'joint', 'pipeline': {'features': ('features_NoneType', {}), 'normalizer': ('normalizer_RobustScaler', {'normalizer__quantile_range': (...), 'normalizer__with_centering': True, 'normalizer__with_scaling': True}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 7})}, 'score': 0.9004407464740283, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': 2, 'max_features': 1, 'max_leaf_nodes': None, 'min_samples_split': 3, 'n_estimators': 75}, 'config_hash': {'algorithm': '42185be98371e99ac896d2c6c2d69c451cb983ff', 'config': '6609280032189b59de1afbe36f3acb1d5c273693', 'pipeline': '8aab2941fc84d84f86fa56134e50909dbf9e19f5'}, 'duration': 0.9665219783782959, 'iteration': 9, 'loss': 0.01637426900584804, 'max_history_score': 0.983625730994152, 'max_history_score_std': 0.025023500462379746, 'max_history_step': 'joint', 'pipeline': {'features': ('features_NoneType', {}), 'normalizer': ('normalizer_PowerTransformer', {}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 5})}, 'score': 0.983625730994152, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': 1, 'max_features': 3, 'max_leaf_nodes': 2, 'min_samples_split': 3, 'n_estimators': 10}, 'config_hash': {'algorithm': '62a9fe705e4cd96e762bcc9543c4a456a5a9f188', 'config': '8e1c17ac9f6e03740f380fccb833c9c3931ffc35', 'pipeline': '3d44d7482e468d08c4f94457a205f3dac74084c1'}, 'duration': 0.46930503845214844, 'iteration': 10, 'loss': 1.0, 'max_history_score': 0.983625730994152, 'max_history_score_std': 0.025023500462379746, 'max_history_step': 'joint', 'pipeline': {'features': ('features_PCA', {'features__n_components': 1}), 'normalizer': ('normalizer_NoneType', {}), 'rebalance': ('rebalance_CondensedNearestNeighbour', {'rebalance__n_neighbors': 3})}, 'score': 0.0, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'gini', 'max_depth': 4, 'max_features': 1, 'max_leaf_nodes': 3, 'min_samples_split': 2, 'n_estimators': 100}, 'config_hash': {'algorithm': '086d6ca939a757bb32edb113a567f9d38744f061', 'config': '87c03d0cb8e8500e58cacc1a0f27ce54c41a2937', 'pipeline': '8f28ef0f35d97142278f9dacb4e9d1ff082e470f'}, 'duration': 2.1196961402893066, 'iteration': 11, 'loss': 0.15471276229790154, 'max_history_score': 0.983625730994152, 'max_history_score_std': 0.025023500462379746, 'max_history_step': 'joint', 'pipeline': {'features': ('features_PCA', {'features__n_components': 1}), 'normalizer': ('normalizer_StandardScaler', {'normalizer__with_mean': True, 'normalizer__with_std': True}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 7})}, 'score': 0.8452872377020985, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'entropy', 'max_depth': 3, 'max_features': 1, 'max_leaf_nodes': 2, 'min_samples_split': 2, 'n_estimators': 25}, 'config_hash': {'algorithm': '59f64a966796648c7bebade1127fa05541b391ad', 'config': '2ab964abffa0a277a9e2ee9b5570cd258e428b62', 'pipeline': 'eef3f702fd2fed761fa6744c1640d0bf320f1d00'}, 'duration': 0.9828321933746338, 'iteration': 12, 'loss': 0.0778465772273822, 'max_history_score': 0.983625730994152, 'max_history_score_std': 0.025023500462379746, 'max_history_step': 'joint', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 3, 'features__selectkbest__k': 1}), 'normalizer': ('normalizer_PowerTransformer', {}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 6})}, 'score': 0.9221534227726178, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'gini', 'max_depth': 4, 'max_features': 2, 'max_leaf_nodes': 3, 'min_samples_split': 3, 'n_estimators': 75}, 'config_hash': {'algorithm': '6f75c2a196eb9836df2b424e095051192eaed6ea', 'config': '5c95db3ad238063227f1b36e6a006d70c834c5da', 'pipeline': '1eae01a1128bee425c4d4ca0ee97a9afd409680e'}, 'duration': 0.8217771053314209, 'iteration': 13, 'loss': 0.03863089095287242, 'max_history_score': 0.983625730994152, 'max_history_score_std': 0.025023500462379746, 'max_history_step': 'joint', 'pipeline': {'features': ('features_NoneType', {}), 'normalizer': ('normalizer_StandardScaler', {'normalizer__with_mean': False, 'normalizer__with_std': False}), 'rebalance': ('rebalance_NearMiss', {'rebalance__n_neighbors': 1})}, 'score': 0.9613691090471276, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'entropy', 'max_depth': 4, 'max_features': 2, 'max_leaf_nodes': 3, 'min_samples_split': 2, 'n_estimators': 25}, 'config_hash': {'algorithm': '8aef3174f6b8020de06b825e0424c1e54d690afd', 'config': '50fd1169b8e42190600f25152654254b5d0e3ed1', 'pipeline': '9ceaa544911dc6c687e336cb8e9dd4d15ff1ceaf'}, 'duration': 0.40307188034057617, 'iteration': 14, 'loss': 1.0, 'max_history_score': 0.983625730994152, 'max_history_score_std': 0.025023500462379746, 'max_history_step': 'joint', 'pipeline': {'features': ('features_PCA', {'features__n_components': 1}), 'normalizer': ('normalizer_RobustScaler', {'normalizer__quantile_range': (...), 'normalizer__with_centering': False, 'normalizer__with_scaling': False}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 7})}, 'score': 0.0, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'gini', 'max_depth': 1, 'max_features': 1, 'max_leaf_nodes': 3, 'min_samples_split': 3, 'n_estimators': 50}, 'config_hash': {'algorithm': '37be8b6737f4b5d5ae35da51886f302b07ba6001', 'config': 'a05b6d2ffd65d4d937c0b178655d857bf4d61410', 'pipeline': 'cfef88e895db321122f2f7b813d9267b973c2468'}, 'duration': 1.7094659805297852, 'iteration': 15, 'loss': 0.011111111111111072, 'max_history_score': 0.9888888888888889, 'max_history_score_std': 0.022222222222222233, 'max_history_step': 'joint', 'pipeline': {'features': ('features_NoneType', {}), 'normalizer': ('normalizer_NoneType', {}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 5})}, 'score': 0.9888888888888889, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'entropy', 'max_depth': None, 'max_features': 3, 'max_leaf_nodes': None, 'min_samples_split': 2, 'n_estimators': 100}, 'config_hash': {'algorithm': 'c40543ce91793e367c1892c886bc49621c22ecfb', 'config': 'ebebb7a93116f14f470e062e37582a59f4aeb0df', 'pipeline': 'b50c63e800574e8b760f55f7c4ff1fcae8816dd8'}, 'duration': 0.6425540447235107, 'iteration': 16, 'loss': 1.0, 'max_history_score': 0.9888888888888889, 'max_history_score_std': 0.022222222222222233, 'max_history_step': 'joint', 'pipeline': {'features': ('features_PCA', {'features__n_components': 1}), 'normalizer': ('normalizer_PowerTransformer', {}), 'rebalance': ('rebalance_NearMiss', {'rebalance__n_neighbors': 1})}, 'score': 0.0, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'gini', 'max_depth': None, 'max_features': 1, 'max_leaf_nodes': 3, 'min_samples_split': 2, 'n_estimators': 50}, 'config_hash': {'algorithm': '0c69b9601237c20664085fa05764d855e28f98f7', 'config': 'a2c21314ddbba47ddbfe416e0aa14853a71179e0', 'pipeline': '914f81fa4fbb61db251201f32bd8ea11bfeea2a5'}, 'duration': 2.2209739685058594, 'iteration': 17, 'loss': 0.3206720846233231, 'max_history_score': 0.9888888888888889, 'max_history_score_std': 0.022222222222222233, 'max_history_step': 'joint', 'pipeline': {'features': ('features_SelectKBest', {'features__k': 4}), 'normalizer': ('normalizer_PowerTransformer', {}), 'rebalance': ('rebalance_CondensedNearestNeighbour', {'rebalance__n_neighbors': 1})}, 'score': 0.6793279153766769, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': 4, 'max_features': None, 'max_leaf_nodes': None, 'min_samples_split': 3, 'n_estimators': 25}, 'config_hash': {'algorithm': '1aae0f1fce5cab293ffdd4581c4838c8051ac815', 'config': '6c8a721218e7c550a98c5ba72ad9ff86afd5e3a4', 'pipeline': '77189452469cef9c840643f2babe0f825c6667c8'}, 'duration': 0.3951280117034912, 'iteration': 18, 'loss': 0.1804760061919506, 'max_history_score': 0.9888888888888889, 'max_history_score_std': 0.022222222222222233, 'max_history_step': 'joint', 'pipeline': {'features': ('features_SelectKBest', {'features__k': 2}), 'normalizer': ('normalizer_NoneType', {}), 'rebalance': ('rebalance_NearMiss', {'rebalance__n_neighbors': 1})}, 'score': 0.8195239938080494, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': None, 'max_features': 3, 'max_leaf_nodes': 5, 'min_samples_split': 3, 'n_estimators': 50}, 'config_hash': {'algorithm': '0129970b8c7fe034ac8283fb518a06cfbead63d2', 'config': '61bcd2f64860b3dfe2503be88a6bbec165db0754', 'pipeline': '359f2473075ecfd9ae3ce526da96143918517601'}, 'duration': 0.7467091083526611, 'iteration': 19, 'loss': 0.09915720674234607, 'max_history_score': 0.9888888888888889, 'max_history_score_std': 0.022222222222222233, 'max_history_step': 'joint', 'pipeline': {'features': ('features_SelectKBest', {'features__k': 3}), 'normalizer': ('normalizer_RobustScaler', {'normalizer__quantile_range': (...), 'normalizer__with_centering': True, 'normalizer__with_scaling': False}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 7})}, 'score': 0.9008427932576539, ...}, ...], 'history_hash': ['2e6648b63441361b4398cb94f81d2e04a830b2ef', '584343bc020d2d7bc89bd0856bc7770dae1c84fc', 'de121d053e65def047cc8947f505578d5c5eab67', 'b21c9d15a389baa5bfea4c8ddcec129259f37540', 'edd3456355d80775739c31515c832ca7b4e5e094', '0800d7d2c8c10d2f9e7b4e5127b343e916eb742c', 'd98b641879b4754f2169335626a90575e945fd7c', '3f83df36a6abbdf7ea4a4bdcaf6727f23529c2bb', '037fd5c655b39cc7922fb394d736496befcc747b', '6609280032189b59de1afbe36f3acb1d5c273693', '8e1c17ac9f6e03740f380fccb833c9c3931ffc35', '87c03d0cb8e8500e58cacc1a0f27ce54c41a2937', '2ab964abffa0a277a9e2ee9b5570cd258e428b62', '5c95db3ad238063227f1b36e6a006d70c834c5da', '50fd1169b8e42190600f25152654254b5d0e3ed1', 'a05b6d2ffd65d4d937c0b178655d857bf4d61410', 'ebebb7a93116f14f470e062e37582a59f4aeb0df', 'a2c21314ddbba47ddbfe416e0aa14853a71179e0', '6c8a721218e7c550a98c5ba72ad9ff86afd5e3a4', '61bcd2f64860b3dfe2503be88a6bbec165db0754', ...], 'history_index': {'037fd5c655b39cc7922fb394d736496befcc747b': 8, '07fdf9d0d0248a4b0215a633c75a2dd101dcf465': 22, '0800d7d2c8c10d2f9e7b4e5127b343e916eb742c': 5, '0e45095dfe50d5be759b179b50e63384925c7027': 32, '28944b74104bc5bb782512b0eefa3167fe189355': 30, '2a317f1667c0a37724743084ca5dcbf14ff107f0': 29, '2ab964abffa0a277a9e2ee9b5570cd258e428b62': 12, '2e6648b63441361b4398cb94f81d2e04a830b2ef': 0, '3876a387c01c8d5fb746f320f2cc4d1168f512a0': 21, '3f83df36a6abbdf7ea4a4bdcaf6727f23529c2bb': 7, ...}, 'iteration': 32, 'max_history_score': 0.9944444444444445, 'max_history_score_std': 0.016666666666666673, 'max_history_step': 'joint'}
        config = {'algorithm': 'RandomForest', 'seed': 42, 'time': 300}
    114 
    115 
    116 def get_baseline_score(algorithm, X, y, seed):
    117     pipeline, _ = pipeline_conf_to_full_pipeline(

...........................................................................
/home/aquemy/dev/dp_hyperparameters/extension/experiment/objective.py in objective(pipeline_config={'features': ('features_FeatureUnion', {'features__pca__n_components': 1, 'features__selectkbest__k': 1}), 'normalizer': ('normalizer_RobustScaler', {'normalizer__quantile_range': (5.0, 95.0), 'normalizer__with_centering': False, 'normalizer__with_scaling': True}), 'rebalance': ('rebalance_CondensedNearestNeighbour', {'rebalance__n_neighbors': 2})}, algo_config={'bootstrap': False, 'criterion': 'gini', 'max_depth': 1, 'max_features': 3, 'max_leaf_nodes': 5, 'min_samples_split': 5, 'n_estimators': 50}, algorithm='RandomForest', X=array([[1.423e+01, 1.710e+00, 2.430e+00, ..., 1...., ..., 6.100e-01, 1.600e+00,
        5.600e+02]]), y=array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,
       2, 2]), context={'baseline_score': 0.9444100447196423, 'baseline_score_std': 0.04305547117084885, 'best_config': {'algorithm': {'bootstrap': False, 'criterion': 'gini', 'max_depth': 1, 'max_features': 1, 'max_leaf_nodes': 3, 'min_samples_split': 5, 'n_estimators': 50}, 'config_hash': {'algorithm': 'cefc05c6c759dc564d289289fe401e0f8737951d', 'config': '7a1c40755d84d62f5d2ab1ed021e7dff93dfce45', 'pipeline': '3ee6a915db2d8d71f204c103803fb8eabea0d54f'}, 'duration': 0.6908998489379883, 'iteration': 24, 'loss': 0.005555555555555536, 'max_history_score': 0.9944444444444445, 'max_history_score_std': 0.016666666666666673, 'max_history_step': 'joint', 'pipeline': {'features': ('features_NoneType', {}), 'normalizer': ('normalizer_MinMaxScaler', {}), 'rebalance': ('rebalance_NoneType', {})}, 'score': 0.9944444444444445, ...}, 'history': [{'algorithm': {'bootstrap': False, 'criterion': 'entropy', 'max_depth': None, 'max_features': 3, 'max_leaf_nodes': 5, 'min_samples_split': 2, 'n_estimators': 50}, 'config_hash': {'algorithm': 'b2c6464add7a35ce8048653a39338c9994de9a4f', 'config': '2e6648b63441361b4398cb94f81d2e04a830b2ef', 'pipeline': '3d44d7482e468d08c4f94457a205f3dac74084c1'}, 'duration': 0.737678050994873, 'iteration': 0, 'loss': 1.0, 'max_history_score': 0.0, 'max_history_score_std': 0.0, 'max_history_step': 'baseline', 'pipeline': {'features': ('features_PCA', {'features__n_components': 1}), 'normalizer': ('normalizer_NoneType', {}), 'rebalance': ('rebalance_CondensedNearestNeighbour', {'rebalance__n_neighbors': 3})}, 'score': 0.0, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'gini', 'max_depth': 1, 'max_features': None, 'max_leaf_nodes': 2, 'min_samples_split': 3, 'n_estimators': 25}, 'config_hash': {'algorithm': '7f71bbbfdb4e8da52b6fc33a43224183117de15e', 'config': '584343bc020d2d7bc89bd0856bc7770dae1c84fc', 'pipeline': '466ffa7ace0e442beb7c311eb214b17a4c6832b3'}, 'duration': 1.5976769924163818, 'iteration': 1, 'loss': 0.40386351909184726, 'max_history_score': 0.5961364809081527, 'max_history_score_std': 0.05351463210025494, 'max_history_step': 'joint', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 3, 'features__selectkbest__k': 3}), 'normalizer': ('normalizer_StandardScaler', {'normalizer__with_mean': True, 'normalizer__with_std': True}), 'rebalance': ('rebalance_NearMiss', {'rebalance__n_neighbors': 2})}, 'score': 0.5961364809081527, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'entropy', 'max_depth': 1, 'max_features': 2, 'max_leaf_nodes': 2, 'min_samples_split': 5, 'n_estimators': 25}, 'config_hash': {'algorithm': '897745a20d929d43e760cacee0a764bd8070daa5', 'config': 'de121d053e65def047cc8947f505578d5c5eab67', 'pipeline': '63040b39b48626a8232e847e8327bdca5cd88611'}, 'duration': 0.815453052520752, 'iteration': 2, 'loss': 0.07327786377708967, 'max_history_score': 0.9267221362229103, 'max_history_score_std': 0.043920207373658794, 'max_history_step': 'joint', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 3, 'features__selectkbest__k': 2}), 'normalizer': ('normalizer_StandardScaler', {'normalizer__with_mean': True, 'normalizer__with_std': True}), 'rebalance': ('rebalance_NoneType', {})}, 'score': 0.9267221362229103, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'entropy', 'max_depth': 4, 'max_features': 3, 'max_leaf_nodes': None, 'min_samples_split': 2, 'n_estimators': 100}, 'config_hash': {'algorithm': 'dbd92c75280ec06b66ca4ad9b135cf36957031a4', 'config': 'b21c9d15a389baa5bfea4c8ddcec129259f37540', 'pipeline': '38866720d2f120c863351493b9b4e23b9a4506dc'}, 'duration': 1.2293269634246826, 'iteration': 3, 'loss': 0.07199862401100798, 'max_history_score': 0.928001375988992, 'max_history_score_std': 0.06518367535896959, 'max_history_step': 'joint', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 2, 'features__selectkbest__k': 4}), 'normalizer': ('normalizer_NoneType', {}), 'rebalance': ('rebalance_NoneType', {})}, 'score': 0.928001375988992, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': 2, 'max_features': None, 'max_leaf_nodes': None, 'min_samples_split': 5, 'n_estimators': 100}, 'config_hash': {'algorithm': 'f455eefd9fdd03ece88892c3f440c580bdf27ddb', 'config': 'edd3456355d80775739c31515c832ca7b4e5e094', 'pipeline': '1d1034f9f0871e43f896c1db4ed6fd572ed0a6ef'}, 'duration': 1.6186630725860596, 'iteration': 4, 'loss': 0.16651831785345705, 'max_history_score': 0.928001375988992, 'max_history_score_std': 0.06518367535896959, 'max_history_step': 'joint', 'pipeline': {'features': ('features_SelectKBest', {'features__k': 4}), 'normalizer': ('normalizer_MinMaxScaler', {}), 'rebalance': ('rebalance_CondensedNearestNeighbour', {'rebalance__n_neighbors': 1})}, 'score': 0.833481682146543, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'entropy', 'max_depth': 1, 'max_features': 2, 'max_leaf_nodes': None, 'min_samples_split': 2, 'n_estimators': 10}, 'config_hash': {'algorithm': '29906eaa0712a68ea145b12821d54ba445726fbf', 'config': '0800d7d2c8c10d2f9e7b4e5127b343e916eb742c', 'pipeline': '2e0f188ae61600352a7159285e0f542b4587a403'}, 'duration': 0.19410085678100586, 'iteration': 5, 'loss': 0.20164258685930514, 'max_history_score': 0.928001375988992, 'max_history_score_std': 0.06518367535896959, 'max_history_step': 'joint', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 3, 'features__selectkbest__k': 4}), 'normalizer': ('normalizer_StandardScaler', {'normalizer__with_mean': True, 'normalizer__with_std': False}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 7})}, 'score': 0.7983574131406949, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': 1, 'max_features': 1, 'max_leaf_nodes': 5, 'min_samples_split': 2, 'n_estimators': 25}, 'config_hash': {'algorithm': 'fbb7d57e38cfc08240f0af985282da418cb33556', 'config': 'd98b641879b4754f2169335626a90575e945fd7c', 'pipeline': '62463de065924498cdcd2f2f1f7e68535cdb33a5'}, 'duration': 0.3625810146331787, 'iteration': 6, 'loss': 0.14327485380116955, 'max_history_score': 0.928001375988992, 'max_history_score_std': 0.06518367535896959, 'max_history_step': 'joint', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 1, 'features__selectkbest__k': 2}), 'normalizer': ('normalizer_NoneType', {}), 'rebalance': ('rebalance_NoneType', {})}, 'score': 0.8567251461988304, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'entropy', 'max_depth': 3, 'max_features': 1, 'max_leaf_nodes': None, 'min_samples_split': 2, 'n_estimators': 75}, 'config_hash': {'algorithm': 'fb2f5d4c4d636edac929e1454ce3d02a4fb134c1', 'config': '3f83df36a6abbdf7ea4a4bdcaf6727f23529c2bb', 'pipeline': '8377b93e334656d1a93d266493b58ef9a6a1786f'}, 'duration': 0.8223779201507568, 'iteration': 7, 'loss': 0.03921568627450989, 'max_history_score': 0.9607843137254901, 'max_history_score_std': 0.043526663832084804, 'max_history_step': 'joint', 'pipeline': {'features': ('features_PCA', {'features__n_components': 3}), 'normalizer': ('normalizer_MinMaxScaler', {}), 'rebalance': ('rebalance_NearMiss', {'rebalance__n_neighbors': 1})}, 'score': 0.9607843137254901, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'gini', 'max_depth': 3, 'max_features': 3, 'max_leaf_nodes': 2, 'min_samples_split': 2, 'n_estimators': 100}, 'config_hash': {'algorithm': '3c3fde6559b918694de4668d025d5418342db1b1', 'config': '037fd5c655b39cc7922fb394d736496befcc747b', 'pipeline': '2a5032814c6c7ed21dd5bd9686923d7fc2f8acc9'}, 'duration': 1.0435099601745605, 'iteration': 8, 'loss': 0.09955925352597172, 'max_history_score': 0.9607843137254901, 'max_history_score_std': 0.043526663832084804, 'max_history_step': 'joint', 'pipeline': {'features': ('features_NoneType', {}), 'normalizer': ('normalizer_RobustScaler', {'normalizer__quantile_range': (...), 'normalizer__with_centering': True, 'normalizer__with_scaling': True}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 7})}, 'score': 0.9004407464740283, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': 2, 'max_features': 1, 'max_leaf_nodes': None, 'min_samples_split': 3, 'n_estimators': 75}, 'config_hash': {'algorithm': '42185be98371e99ac896d2c6c2d69c451cb983ff', 'config': '6609280032189b59de1afbe36f3acb1d5c273693', 'pipeline': '8aab2941fc84d84f86fa56134e50909dbf9e19f5'}, 'duration': 0.9665219783782959, 'iteration': 9, 'loss': 0.01637426900584804, 'max_history_score': 0.983625730994152, 'max_history_score_std': 0.025023500462379746, 'max_history_step': 'joint', 'pipeline': {'features': ('features_NoneType', {}), 'normalizer': ('normalizer_PowerTransformer', {}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 5})}, 'score': 0.983625730994152, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': 1, 'max_features': 3, 'max_leaf_nodes': 2, 'min_samples_split': 3, 'n_estimators': 10}, 'config_hash': {'algorithm': '62a9fe705e4cd96e762bcc9543c4a456a5a9f188', 'config': '8e1c17ac9f6e03740f380fccb833c9c3931ffc35', 'pipeline': '3d44d7482e468d08c4f94457a205f3dac74084c1'}, 'duration': 0.46930503845214844, 'iteration': 10, 'loss': 1.0, 'max_history_score': 0.983625730994152, 'max_history_score_std': 0.025023500462379746, 'max_history_step': 'joint', 'pipeline': {'features': ('features_PCA', {'features__n_components': 1}), 'normalizer': ('normalizer_NoneType', {}), 'rebalance': ('rebalance_CondensedNearestNeighbour', {'rebalance__n_neighbors': 3})}, 'score': 0.0, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'gini', 'max_depth': 4, 'max_features': 1, 'max_leaf_nodes': 3, 'min_samples_split': 2, 'n_estimators': 100}, 'config_hash': {'algorithm': '086d6ca939a757bb32edb113a567f9d38744f061', 'config': '87c03d0cb8e8500e58cacc1a0f27ce54c41a2937', 'pipeline': '8f28ef0f35d97142278f9dacb4e9d1ff082e470f'}, 'duration': 2.1196961402893066, 'iteration': 11, 'loss': 0.15471276229790154, 'max_history_score': 0.983625730994152, 'max_history_score_std': 0.025023500462379746, 'max_history_step': 'joint', 'pipeline': {'features': ('features_PCA', {'features__n_components': 1}), 'normalizer': ('normalizer_StandardScaler', {'normalizer__with_mean': True, 'normalizer__with_std': True}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 7})}, 'score': 0.8452872377020985, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'entropy', 'max_depth': 3, 'max_features': 1, 'max_leaf_nodes': 2, 'min_samples_split': 2, 'n_estimators': 25}, 'config_hash': {'algorithm': '59f64a966796648c7bebade1127fa05541b391ad', 'config': '2ab964abffa0a277a9e2ee9b5570cd258e428b62', 'pipeline': 'eef3f702fd2fed761fa6744c1640d0bf320f1d00'}, 'duration': 0.9828321933746338, 'iteration': 12, 'loss': 0.0778465772273822, 'max_history_score': 0.983625730994152, 'max_history_score_std': 0.025023500462379746, 'max_history_step': 'joint', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 3, 'features__selectkbest__k': 1}), 'normalizer': ('normalizer_PowerTransformer', {}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 6})}, 'score': 0.9221534227726178, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'gini', 'max_depth': 4, 'max_features': 2, 'max_leaf_nodes': 3, 'min_samples_split': 3, 'n_estimators': 75}, 'config_hash': {'algorithm': '6f75c2a196eb9836df2b424e095051192eaed6ea', 'config': '5c95db3ad238063227f1b36e6a006d70c834c5da', 'pipeline': '1eae01a1128bee425c4d4ca0ee97a9afd409680e'}, 'duration': 0.8217771053314209, 'iteration': 13, 'loss': 0.03863089095287242, 'max_history_score': 0.983625730994152, 'max_history_score_std': 0.025023500462379746, 'max_history_step': 'joint', 'pipeline': {'features': ('features_NoneType', {}), 'normalizer': ('normalizer_StandardScaler', {'normalizer__with_mean': False, 'normalizer__with_std': False}), 'rebalance': ('rebalance_NearMiss', {'rebalance__n_neighbors': 1})}, 'score': 0.9613691090471276, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'entropy', 'max_depth': 4, 'max_features': 2, 'max_leaf_nodes': 3, 'min_samples_split': 2, 'n_estimators': 25}, 'config_hash': {'algorithm': '8aef3174f6b8020de06b825e0424c1e54d690afd', 'config': '50fd1169b8e42190600f25152654254b5d0e3ed1', 'pipeline': '9ceaa544911dc6c687e336cb8e9dd4d15ff1ceaf'}, 'duration': 0.40307188034057617, 'iteration': 14, 'loss': 1.0, 'max_history_score': 0.983625730994152, 'max_history_score_std': 0.025023500462379746, 'max_history_step': 'joint', 'pipeline': {'features': ('features_PCA', {'features__n_components': 1}), 'normalizer': ('normalizer_RobustScaler', {'normalizer__quantile_range': (...), 'normalizer__with_centering': False, 'normalizer__with_scaling': False}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 7})}, 'score': 0.0, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'gini', 'max_depth': 1, 'max_features': 1, 'max_leaf_nodes': 3, 'min_samples_split': 3, 'n_estimators': 50}, 'config_hash': {'algorithm': '37be8b6737f4b5d5ae35da51886f302b07ba6001', 'config': 'a05b6d2ffd65d4d937c0b178655d857bf4d61410', 'pipeline': 'cfef88e895db321122f2f7b813d9267b973c2468'}, 'duration': 1.7094659805297852, 'iteration': 15, 'loss': 0.011111111111111072, 'max_history_score': 0.9888888888888889, 'max_history_score_std': 0.022222222222222233, 'max_history_step': 'joint', 'pipeline': {'features': ('features_NoneType', {}), 'normalizer': ('normalizer_NoneType', {}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 5})}, 'score': 0.9888888888888889, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'entropy', 'max_depth': None, 'max_features': 3, 'max_leaf_nodes': None, 'min_samples_split': 2, 'n_estimators': 100}, 'config_hash': {'algorithm': 'c40543ce91793e367c1892c886bc49621c22ecfb', 'config': 'ebebb7a93116f14f470e062e37582a59f4aeb0df', 'pipeline': 'b50c63e800574e8b760f55f7c4ff1fcae8816dd8'}, 'duration': 0.6425540447235107, 'iteration': 16, 'loss': 1.0, 'max_history_score': 0.9888888888888889, 'max_history_score_std': 0.022222222222222233, 'max_history_step': 'joint', 'pipeline': {'features': ('features_PCA', {'features__n_components': 1}), 'normalizer': ('normalizer_PowerTransformer', {}), 'rebalance': ('rebalance_NearMiss', {'rebalance__n_neighbors': 1})}, 'score': 0.0, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'gini', 'max_depth': None, 'max_features': 1, 'max_leaf_nodes': 3, 'min_samples_split': 2, 'n_estimators': 50}, 'config_hash': {'algorithm': '0c69b9601237c20664085fa05764d855e28f98f7', 'config': 'a2c21314ddbba47ddbfe416e0aa14853a71179e0', 'pipeline': '914f81fa4fbb61db251201f32bd8ea11bfeea2a5'}, 'duration': 2.2209739685058594, 'iteration': 17, 'loss': 0.3206720846233231, 'max_history_score': 0.9888888888888889, 'max_history_score_std': 0.022222222222222233, 'max_history_step': 'joint', 'pipeline': {'features': ('features_SelectKBest', {'features__k': 4}), 'normalizer': ('normalizer_PowerTransformer', {}), 'rebalance': ('rebalance_CondensedNearestNeighbour', {'rebalance__n_neighbors': 1})}, 'score': 0.6793279153766769, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': 4, 'max_features': None, 'max_leaf_nodes': None, 'min_samples_split': 3, 'n_estimators': 25}, 'config_hash': {'algorithm': '1aae0f1fce5cab293ffdd4581c4838c8051ac815', 'config': '6c8a721218e7c550a98c5ba72ad9ff86afd5e3a4', 'pipeline': '77189452469cef9c840643f2babe0f825c6667c8'}, 'duration': 0.3951280117034912, 'iteration': 18, 'loss': 0.1804760061919506, 'max_history_score': 0.9888888888888889, 'max_history_score_std': 0.022222222222222233, 'max_history_step': 'joint', 'pipeline': {'features': ('features_SelectKBest', {'features__k': 2}), 'normalizer': ('normalizer_NoneType', {}), 'rebalance': ('rebalance_NearMiss', {'rebalance__n_neighbors': 1})}, 'score': 0.8195239938080494, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': None, 'max_features': 3, 'max_leaf_nodes': 5, 'min_samples_split': 3, 'n_estimators': 50}, 'config_hash': {'algorithm': '0129970b8c7fe034ac8283fb518a06cfbead63d2', 'config': '61bcd2f64860b3dfe2503be88a6bbec165db0754', 'pipeline': '359f2473075ecfd9ae3ce526da96143918517601'}, 'duration': 0.7467091083526611, 'iteration': 19, 'loss': 0.09915720674234607, 'max_history_score': 0.9888888888888889, 'max_history_score_std': 0.022222222222222233, 'max_history_step': 'joint', 'pipeline': {'features': ('features_SelectKBest', {'features__k': 3}), 'normalizer': ('normalizer_RobustScaler', {'normalizer__quantile_range': (...), 'normalizer__with_centering': True, 'normalizer__with_scaling': False}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 7})}, 'score': 0.9008427932576539, ...}, ...], 'history_hash': ['2e6648b63441361b4398cb94f81d2e04a830b2ef', '584343bc020d2d7bc89bd0856bc7770dae1c84fc', 'de121d053e65def047cc8947f505578d5c5eab67', 'b21c9d15a389baa5bfea4c8ddcec129259f37540', 'edd3456355d80775739c31515c832ca7b4e5e094', '0800d7d2c8c10d2f9e7b4e5127b343e916eb742c', 'd98b641879b4754f2169335626a90575e945fd7c', '3f83df36a6abbdf7ea4a4bdcaf6727f23529c2bb', '037fd5c655b39cc7922fb394d736496befcc747b', '6609280032189b59de1afbe36f3acb1d5c273693', '8e1c17ac9f6e03740f380fccb833c9c3931ffc35', '87c03d0cb8e8500e58cacc1a0f27ce54c41a2937', '2ab964abffa0a277a9e2ee9b5570cd258e428b62', '5c95db3ad238063227f1b36e6a006d70c834c5da', '50fd1169b8e42190600f25152654254b5d0e3ed1', 'a05b6d2ffd65d4d937c0b178655d857bf4d61410', 'ebebb7a93116f14f470e062e37582a59f4aeb0df', 'a2c21314ddbba47ddbfe416e0aa14853a71179e0', '6c8a721218e7c550a98c5ba72ad9ff86afd5e3a4', '61bcd2f64860b3dfe2503be88a6bbec165db0754', ...], 'history_index': {'037fd5c655b39cc7922fb394d736496befcc747b': 8, '07fdf9d0d0248a4b0215a633c75a2dd101dcf465': 22, '0800d7d2c8c10d2f9e7b4e5127b343e916eb742c': 5, '0e45095dfe50d5be759b179b50e63384925c7027': 32, '28944b74104bc5bb782512b0eefa3167fe189355': 30, '2a317f1667c0a37724743084ca5dcbf14ff107f0': 29, '2ab964abffa0a277a9e2ee9b5570cd258e428b62': 12, '2e6648b63441361b4398cb94f81d2e04a830b2ef': 0, '3876a387c01c8d5fb746f320f2cc4d1168f512a0': 21, '3f83df36a6abbdf7ea4a4bdcaf6727f23529c2bb': 7, ...}, 'iteration': 32, 'max_history_score': 0.9944444444444445, 'max_history_score_std': 0.016666666666666673, 'max_history_step': 'joint'}, config={'algorithm': 'RandomForest', 'seed': 42, 'time': 300}, step='joint')
     45                 y,
     46                 cv=10,
     47                 n_jobs=-1,
     48                 return_estimator=False,
     49                 return_train_score=False,
---> 50                 verbose=0)
     51         score = np.mean(scores['test_score'])
     52         std = np.std(scores['test_score'])
     53         status = STATUS_OK
     54     except Exception as e:

...........................................................................
/home/aquemy/.local/lib/python2.7/site-packages/sklearn/model_selection/_validation.py in cross_validate(estimator=Pipeline(memory=None,
     steps=[('rebalance', ... random_state=42, verbose=0, warm_start=False))]), X=array([[1.423e+01, 1.710e+00, 2.430e+00, ..., 1...., ..., 6.100e-01, 1.600e+00,
        5.600e+02]]), y=array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,
       2, 2]), groups=None, scoring=None, cv=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1, verbose=0, fit_params=None, pre_dispatch='2*n_jobs', return_train_score=False, return_estimator=False, error_score='raise-deprecating')
    235         delayed(_fit_and_score)(
    236             clone(estimator), X, y, scorers, train, test, verbose, None,
    237             fit_params, return_train_score=return_train_score,
    238             return_times=True, return_estimator=return_estimator,
    239             error_score=error_score)
--> 240         for train, test in cv.split(X, y, groups))
        cv.split = <bound method StratifiedKFold.split of Stratifie...d(n_splits=10, random_state=None, shuffle=False)>
        X = array([[1.423e+01, 1.710e+00, 2.430e+00, ..., 1...., ..., 6.100e-01, 1.600e+00,
        5.600e+02]])
        y = array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,
       2, 2])
        groups = None
    241 
    242     zipped_scores = list(zip(*scores))
    243     if return_train_score:
    244         train_scores = zipped_scores.pop(0)

...........................................................................
/home/aquemy/.local/lib/python2.7/site-packages/sklearn/externals/joblib/parallel.py in __call__(self=Parallel(n_jobs=-1), iterable=<generator object <genexpr>>)
    925                 # No need to wait for async callbacks to trigger to
    926                 # consumption.
    927                 self._iterating = False
    928 
    929             with self._backend.retrieval_context():
--> 930                 self.retrieve()
        self.retrieve = <bound method Parallel.retrieve of Parallel(n_jobs=-1)>
    931             # Make sure that we get a last message telling us we are done
    932             elapsed_time = time.time() - self._start_time
    933             self._print('Done %3i out of %3i | elapsed: %s finished',
    934                         (len(self._output), len(self._output),

---------------------------------------------------------------------------
Joblib worker traceback:
---------------------------------------------------------------------------
ValueError                                         Mon Jun 17 12:45:44 2019
PID: 15252                                  Python 2.7.15+: /usr/bin/python
...........................................................................
/home/aquemy/.local/lib/python2.7/site-packages/sklearn/externals/joblib/parallel.py in __call__(self=<sklearn.externals.joblib.parallel.BatchedCalls object>)
    220     def __call__(self):
    221         # Set the default nested backend to self._backend but do not set the
    222         # change the default number of processes to -1
    223         with parallel_backend(self._backend, n_jobs=self._n_jobs):
    224             return [func(*args, **kwargs)
--> 225                     for func, args, kwargs in self.items]
        func = <function _fit_and_score>
        args = (Pipeline(memory=None,
     steps=[('rebalance', ... random_state=42, verbose=0, warm_start=False))]), array([[1.423e+01, 1.710e+00, 2.430e+00, ..., 1...., ..., 6.100e-01, 1.600e+00,
        5.600e+02]]), array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,
       2, 2]), {'score': <function _passthrough_scorer>}, array([  6,   7,   8,   9,  10,  11,  12,  13,  ..., 170, 171, 172, 173, 174,
       175, 176, 177]), array([  0,   1,   2,   3,   4,   5,  59,  60,  ...,  64,  65,
        66, 130, 131, 132, 133, 134]), 0, None, None)
        kwargs = {'error_score': 'raise-deprecating', 'return_estimator': False, 'return_times': True, 'return_train_score': False}
        self.items = [(<function _fit_and_score>, (Pipeline(memory=None,
     steps=[('rebalance', ... random_state=42, verbose=0, warm_start=False))]), array([[1.423e+01, 1.710e+00, 2.430e+00, ..., 1...., ..., 6.100e-01, 1.600e+00,
        5.600e+02]]), array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,
       2, 2]), {'score': <function _passthrough_scorer>}, array([  6,   7,   8,   9,  10,  11,  12,  13,  ..., 170, 171, 172, 173, 174,
       175, 176, 177]), array([  0,   1,   2,   3,   4,   5,  59,  60,  ...,  64,  65,
        66, 130, 131, 132, 133, 134]), 0, None, None), {'error_score': 'raise-deprecating', 'return_estimator': False, 'return_times': True, 'return_train_score': False})]
    226 
    227     def __len__(self):
    228         return self._size
    229 

...........................................................................
/home/aquemy/.local/lib/python2.7/site-packages/sklearn/model_selection/_validation.py in _fit_and_score(estimator=Pipeline(memory=None,
     steps=[('rebalance', ... random_state=42, verbose=0, warm_start=False))]), X=array([[1.423e+01, 1.710e+00, 2.430e+00, ..., 1...., ..., 6.100e-01, 1.600e+00,
        5.600e+02]]), y=array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,
       2, 2]), scorer={'score': <function _passthrough_scorer>}, train=array([  6,   7,   8,   9,  10,  11,  12,  13,  ..., 170, 171, 172, 173, 174,
       175, 176, 177]), test=array([  0,   1,   2,   3,   4,   5,  59,  60,  ...,  64,  65,
        66, 130, 131, 132, 133, 134]), verbose=0, parameters=None, fit_params={}, return_train_score=False, return_parameters=False, return_n_test_samples=False, return_times=True, return_estimator=False, error_score='raise-deprecating')
    523 
    524     try:
    525         if y_train is None:
    526             estimator.fit(X_train, **fit_params)
    527         else:
--> 528             estimator.fit(X_train, y_train, **fit_params)
        estimator.fit = <bound method Pipeline.fit of Pipeline(memory=No...random_state=42, verbose=0, warm_start=False))])>
        X_train = array([[1.439e+01, 1.870e+00, 2.450e+00, ..., 1...., ..., 6.100e-01, 1.600e+00,
        5.600e+02]])
        y_train = array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...2, 2, 2, 2, 2, 2, 2, 2, 2,
       2, 2, 2, 2, 2])
        fit_params = {}
    529 
    530     except Exception as e:
    531         # Note fit time as time until error
    532         fit_time = time.time() - start_time

...........................................................................
/usr/local/lib/python2.7/dist-packages/imblearn/pipeline.py in fit(self=Pipeline(memory=None,
     steps=[('rebalance', ... random_state=42, verbose=0, warm_start=False))]), X=array([[1.439e+01, 1.870e+00, 2.450e+00, ..., 1...., ..., 6.100e-01, 1.600e+00,
        5.600e+02]]), y=array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...2, 2, 2, 2, 2, 2, 2, 2, 2,
       2, 2, 2, 2, 2]), **fit_params={})
    234             This estimator
    235 
    236         """
    237         Xt, yt, fit_params = self._fit(X, y, **fit_params)
    238         if self._final_estimator is not None:
--> 239             self._final_estimator.fit(Xt, yt, **fit_params)
        self._final_estimator.fit = <bound method RandomForestClassifier.fit of Rand...e, random_state=42, verbose=0, warm_start=False)>
        Xt = array([[ 1.1001642 ,  0.81336356],
       [ 1.24...-0.46638079],
       [ 0.31198686, -0.70435456]])
        yt = array([0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1,...2, 2, 2, 2, 2, 2, 2, 2, 2, 2,
       2, 2, 2, 2])
        fit_params = {}
    240         return self
    241 
    242     def fit_transform(self, X, y=None, **fit_params):
    243         """Fit the model and transform with the final estimator

...........................................................................
/home/aquemy/.local/lib/python2.7/site-packages/sklearn/ensemble/forest.py in fit(self=RandomForestClassifier(bootstrap=False, class_we...se, random_state=42, verbose=0, warm_start=False), X=array([[ 1.1001642 ,  0.81336355],
       [ 1.24...      [ 0.31198686, -0.7043546 ]], dtype=float32), y=array([[0.],
       [0.],
       [0.],
       [0...    [2.],
       [2.],
       [2.],
       [2.]]), sample_weight=None)
    328             trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,
    329                              **_joblib_parallel_args(prefer='threads'))(
    330                 delayed(_parallel_build_trees)(
    331                     t, self, X, y, sample_weight, i, len(trees),
    332                     verbose=self.verbose, class_weight=self.class_weight)
--> 333                 for i, t in enumerate(trees))
        i = 49
    334 
    335             # Collect newly grown trees
    336             self.estimators_.extend(trees)
    337 

...........................................................................
/home/aquemy/.local/lib/python2.7/site-packages/sklearn/externals/joblib/parallel.py in __call__(self=Parallel(n_jobs=1), iterable=<generator object <genexpr>>)
    912             # self._original_iterator is None, then this means either
    913             # that pre_dispatch == "all", n_jobs == 1 or that the first batch
    914             # was very quick and its callback already dispatched all the
    915             # remaining jobs.
    916             self._iterating = False
--> 917             if self.dispatch_one_batch(iterator):
        self.dispatch_one_batch = <bound method Parallel.dispatch_one_batch of Parallel(n_jobs=1)>
        iterator = <generator object <genexpr>>
    918                 self._iterating = self._original_iterator is not None
    919 
    920             while self.dispatch_one_batch(iterator):
    921                 pass

...........................................................................
/home/aquemy/.local/lib/python2.7/site-packages/sklearn/externals/joblib/parallel.py in dispatch_one_batch(self=Parallel(n_jobs=1), iterator=<generator object <genexpr>>)
    754                                  self._pickle_cache)
    755             if len(tasks) == 0:
    756                 # No more tasks available in the iterator: tell caller to stop.
    757                 return False
    758             else:
--> 759                 self._dispatch(tasks)
        self._dispatch = <bound method Parallel._dispatch of Parallel(n_jobs=1)>
        tasks = <sklearn.externals.joblib.parallel.BatchedCalls object>
    760                 return True
    761 
    762     def _print(self, msg, msg_args):
    763         """Display the message on stout or stderr depending on verbosity"""

...........................................................................
/home/aquemy/.local/lib/python2.7/site-packages/sklearn/externals/joblib/parallel.py in _dispatch(self=Parallel(n_jobs=1), batch=<sklearn.externals.joblib.parallel.BatchedCalls object>)
    711 
    712         dispatch_timestamp = time.time()
    713         cb = BatchCompletionCallBack(dispatch_timestamp, len(batch), self)
    714         with self._lock:
    715             job_idx = len(self._jobs)
--> 716             job = self._backend.apply_async(batch, callback=cb)
        job = undefined
        self._backend.apply_async = <bound method SequentialBackend.apply_async of <...lib._parallel_backends.SequentialBackend object>>
        batch = <sklearn.externals.joblib.parallel.BatchedCalls object>
        cb = <sklearn.externals.joblib.parallel.BatchCompletionCallBack object>
    717             # A job can complete so quickly than its callback is
    718             # called before we get here, causing self._jobs to
    719             # grow. To ensure correct results ordering, .insert is
    720             # used (rather than .append) in the following line

...........................................................................
/home/aquemy/.local/lib/python2.7/site-packages/sklearn/externals/joblib/_parallel_backends.py in apply_async(self=<sklearn.externals.joblib._parallel_backends.SequentialBackend object>, func=<sklearn.externals.joblib.parallel.BatchedCalls object>, callback=<sklearn.externals.joblib.parallel.BatchCompletionCallBack object>)
    177             raise ValueError('n_jobs == 0 in Parallel has no meaning')
    178         return 1
    179 
    180     def apply_async(self, func, callback=None):
    181         """Schedule a func to be run"""
--> 182         result = ImmediateResult(func)
        result = undefined
        func = <sklearn.externals.joblib.parallel.BatchedCalls object>
    183         if callback:
    184             callback(result)
    185         return result
    186 

...........................................................................
/home/aquemy/.local/lib/python2.7/site-packages/sklearn/externals/joblib/_parallel_backends.py in __init__(self=<sklearn.externals.joblib._parallel_backends.ImmediateResult object>, batch=<sklearn.externals.joblib.parallel.BatchedCalls object>)
    544 
    545 class ImmediateResult(object):
    546     def __init__(self, batch):
    547         # Don't delay the application, to avoid keeping the input
    548         # arguments in memory
--> 549         self.results = batch()
        self.results = undefined
        batch = <sklearn.externals.joblib.parallel.BatchedCalls object>
    550 
    551     def get(self):
    552         return self.results
    553 

...........................................................................
/home/aquemy/.local/lib/python2.7/site-packages/sklearn/externals/joblib/parallel.py in __call__(self=<sklearn.externals.joblib.parallel.BatchedCalls object>)
    220     def __call__(self):
    221         # Set the default nested backend to self._backend but do not set the
    222         # change the default number of processes to -1
    223         with parallel_backend(self._backend, n_jobs=self._n_jobs):
    224             return [func(*args, **kwargs)
--> 225                     for func, args, kwargs in self.items]
        func = <function _parallel_build_trees>
        args = (DecisionTreeClassifier(class_weight=None, criter...=False, random_state=1608637542, splitter='best'), RandomForestClassifier(bootstrap=False, class_we...se, random_state=42, verbose=0, warm_start=False), array([[ 1.1001642 ,  0.81336355],
       [ 1.24...      [ 0.31198686, -0.7043546 ]], dtype=float32), array([[0.],
       [0.],
       [0.],
       [0...    [2.],
       [2.],
       [2.],
       [2.]]), None, 0, 50)
        kwargs = {'class_weight': None, 'verbose': 0}
        self.items = [(<function _parallel_build_trees>, (DecisionTreeClassifier(class_weight=None, criter...=False, random_state=1608637542, splitter='best'), RandomForestClassifier(bootstrap=False, class_we...se, random_state=42, verbose=0, warm_start=False), array([[ 1.1001642 ,  0.81336355],
       [ 1.24...      [ 0.31198686, -0.7043546 ]], dtype=float32), array([[0.],
       [0.],
       [0.],
       [0...    [2.],
       [2.],
       [2.],
       [2.]]), None, 0, 50), {'class_weight': None, 'verbose': 0})]
    226 
    227     def __len__(self):
    228         return self._size
    229 

...........................................................................
/home/aquemy/.local/lib/python2.7/site-packages/sklearn/ensemble/forest.py in _parallel_build_trees(tree=DecisionTreeClassifier(class_weight=None, criter...=False, random_state=1608637542, splitter='best'), forest=RandomForestClassifier(bootstrap=False, class_we...se, random_state=42, verbose=0, warm_start=False), X=array([[ 1.1001642 ,  0.81336355],
       [ 1.24...      [ 0.31198686, -0.7043546 ]], dtype=float32), y=array([[0.],
       [0.],
       [0.],
       [0...    [2.],
       [2.],
       [2.],
       [2.]]), sample_weight=None, tree_idx=0, n_trees=50, verbose=0, class_weight=None)
    116         elif class_weight == 'balanced_subsample':
    117             curr_sample_weight *= compute_sample_weight('balanced', y, indices)
    118 
    119         tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)
    120     else:
--> 121         tree.fit(X, y, sample_weight=sample_weight, check_input=False)
        tree.fit = <bound method DecisionTreeClassifier.fit of Deci...False, random_state=1608637542, splitter='best')>
        X = array([[ 1.1001642 ,  0.81336355],
       [ 1.24...      [ 0.31198686, -0.7043546 ]], dtype=float32)
        y = array([[0.],
       [0.],
       [0.],
       [0...    [2.],
       [2.],
       [2.],
       [2.]])
        sample_weight = None
    122 
    123     return tree
    124 
    125 

...........................................................................
/home/aquemy/.local/lib/python2.7/site-packages/sklearn/tree/tree.py in fit(self=DecisionTreeClassifier(class_weight=None, criter...=False, random_state=1608637542, splitter='best'), X=array([[ 1.1001642 ,  0.81336355],
       [ 1.24...      [ 0.31198686, -0.7043546 ]], dtype=float32), y=array([[0.],
       [0.],
       [0.],
       [0...    [2.],
       [2.],
       [2.],
       [2.]]), sample_weight=None, check_input=False, X_idx_sorted=None)
    796 
    797         super(DecisionTreeClassifier, self).fit(
    798             X, y,
    799             sample_weight=sample_weight,
    800             check_input=check_input,
--> 801             X_idx_sorted=X_idx_sorted)
        X_idx_sorted = None
    802         return self
    803 
    804     def predict_proba(self, X, check_input=True):
    805         """Predict class probabilities of the input samples X.

...........................................................................
/home/aquemy/.local/lib/python2.7/site-packages/sklearn/tree/tree.py in fit(self=DecisionTreeClassifier(class_weight=None, criter...=False, random_state=1608637542, splitter='best'), X=array([[ 1.1001642 ,  0.81336355],
       [ 1.24...      [ 0.31198686, -0.7043546 ]], dtype=float32), y=array([[0.],
       [0.],
       [0.],
       [0...    [2.],
       [2.],
       [2.],
       [2.]]), sample_weight=None, check_input=False, X_idx_sorted=None)
    237         if not 0 <= self.min_weight_fraction_leaf <= 0.5:
    238             raise ValueError("min_weight_fraction_leaf must in [0, 0.5]")
    239         if max_depth <= 0:
    240             raise ValueError("max_depth must be greater than zero. ")
    241         if not (0 < max_features <= self.n_features_):
--> 242             raise ValueError("max_features must be in (0, n_features]")
    243         if not isinstance(max_leaf_nodes, (numbers.Integral, np.integer)):
    244             raise ValueError("max_leaf_nodes must be integral number but was "
    245                              "%r" % max_leaf_nodes)
    246         if -1 < max_leaf_nodes < 2:

ValueError: max_features must be in (0, n_features]
___________________________________________________________________________
Best score: 0.994444444444 (0.0166666666667) [J] | Score: 0.0 (0.0) [J]
Best score: 0.994444444444 (0.0166666666667) [J] | Score: 0.595190488476 (0.054003671169) [J]
Best score: 0.994444444444 (0.0166666666667) [J] | Score: 0.889146886825 (0.0743213696926) [J]
Best score: 0.994444444444 (0.0166666666667) [J] | Score: 0.65184253526 (0.0295051301584) [J]
Best score: 0.994444444444 (0.0166666666667) [J] | Score: 0.917509459924 (0.0920178878466) [J]
Best score: 0.994444444444 (0.0166666666667) [J] | Score: 0.934176126591 (0.0712390415734) [J]
Best score: 0.994444444444 (0.0166666666667) [J] | Score: 0.920839783282 (0.0581349961851) [J]
Best score: 0.994444444444 (0.0166666666667) [J] | Score: 0.966959064327 (0.0443066886363) [J]
Best score: 0.994444444444 (0.0166666666667) [J] | Score: 0.910715514276 (0.0522683669409) [J]
Best score: 0.994444444444 (0.0166666666667) [J] | Score: 0.955194358445 (0.0425915445511) [J]
JoblibValueError
___________________________________________________________________________
...........................................................................
/home/aquemy/dev/dp_hyperparameters/extension/main.py in <module>()
     27 
     28     serializer.serialize_results(scenario, policy)
     29 
     30 if __name__ == "__main__":
     31     args = cli.parse_args()
---> 32     main(args)

...........................................................................
/home/aquemy/dev/dp_hyperparameters/extension/main.py in main(args=Namespace(customize=[(['control', 'seed'], '42')...io='./scenarios/rf_wine_joint.yaml', verbosity=0))
     21         test_size=0.4, 
     22         random_state=scenario['control']['seed']
     23     )
     24 
     25     policy = policies.initiate(scenario['setup']['policy'], config)
---> 26     policy.run(X,y)
        policy.run = <bound method Joint.run of <experiment.policies.joint.Joint object>>
        X = array([[1.423e+01, 1.710e+00, 2.430e+00, ..., 1...., ..., 6.100e-01, 1.600e+00,
        5.600e+02]])
        y = array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,
       2, 2])
     27 
     28     serializer.serialize_results(scenario, policy)
     29 
     30 if __name__ == "__main__":

...........................................................................
/home/aquemy/dev/dp_hyperparameters/extension/experiment/policies/joint.py in run(self=<experiment.policies.joint.Joint object>, X=array([[1.423e+01, 1.710e+00, 2.430e+00, ..., 1...., ..., 6.100e-01, 1.600e+00,
        5.600e+02]]), y=array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,
       2, 2]))
     32             algo=tpe.suggest, 
     33             max_evals=None,
     34             max_time=self.config['time'],     
     35             trials=trials,
     36             show_progressbar=False,
---> 37             verbose=0
     38         )
     39 
     40         best_config = self.context['best_config']
     41         super(Joint, self).display_step_results(best_config)

...........................................................................
/home/aquemy/dev/dp_hyperparameters/extension/hyperopt/fmin.py in fmin(fn=<functools.partial object>, space={'algorithm': {'bootstrap': <hyperopt.pyll.base.Apply object>, 'criterion': <hyperopt.pyll.base.Apply object>, 'max_depth': <hyperopt.pyll.base.Apply object>, 'max_features': <hyperopt.pyll.base.Apply object>, 'max_leaf_nodes': <hyperopt.pyll.base.Apply object>, 'min_samples_split': <hyperopt.pyll.base.Apply object>, 'n_estimators': <hyperopt.pyll.base.Apply object>}, 'pipeline': {'features': <hyperopt.pyll.base.Apply object>, 'normalizer': <hyperopt.pyll.base.Apply object>, 'rebalance': <hyperopt.pyll.base.Apply object>}}, algo=<function suggest>, max_evals=9223372036854775807, max_time=300, trials=<hyperopt.base.Trials object>, rstate=<mtrand.RandomState object>, allow_trials_fmin=True, pass_expr_memo_ctrl=None, catch_eval_exceptions=False, verbose=0, return_argmin=True, points_to_evaluate=None, max_queue_len=1, show_progressbar=False)
    406             pass_expr_memo_ctrl=pass_expr_memo_ctrl,
    407             verbose=verbose,
    408             catch_eval_exceptions=catch_eval_exceptions,
    409             return_argmin=return_argmin,
    410             show_progressbar=show_progressbar,
--> 411             max_time=max_time
        max_time = 300
    412         )
    413 
    414     if trials is None:
    415         if points_to_evaluate is None:

...........................................................................
/home/aquemy/dev/dp_hyperparameters/extension/hyperopt/base.py in fmin(self=<hyperopt.base.Trials object>, fn=<functools.partial object>, space={'algorithm': {'bootstrap': <hyperopt.pyll.base.Apply object>, 'criterion': <hyperopt.pyll.base.Apply object>, 'max_depth': <hyperopt.pyll.base.Apply object>, 'max_features': <hyperopt.pyll.base.Apply object>, 'max_leaf_nodes': <hyperopt.pyll.base.Apply object>, 'min_samples_split': <hyperopt.pyll.base.Apply object>, 'n_estimators': <hyperopt.pyll.base.Apply object>}, 'pipeline': {'features': <hyperopt.pyll.base.Apply object>, 'normalizer': <hyperopt.pyll.base.Apply object>, 'rebalance': <hyperopt.pyll.base.Apply object>}}, algo=<function suggest>, max_evals=9223372036854775807, max_time=300, rstate=<mtrand.RandomState object>, verbose=0, pass_expr_memo_ctrl=None, catch_eval_exceptions=False, return_argmin=True, show_progressbar=False)
    636             verbose=verbose,
    637             allow_trials_fmin=False,  # -- prevent recursion
    638             pass_expr_memo_ctrl=pass_expr_memo_ctrl,
    639             catch_eval_exceptions=catch_eval_exceptions,
    640             return_argmin=return_argmin,
--> 641             show_progressbar=show_progressbar)
        show_progressbar = False
    642 
    643 
    644 def trials_from_docs(docs, validate=True, **kwargs):
    645     """Construct a Trials base class instance from a list of trials documents

...........................................................................
/home/aquemy/dev/dp_hyperparameters/extension/hyperopt/fmin.py in fmin(fn=<functools.partial object>, space={'algorithm': {'bootstrap': <hyperopt.pyll.base.Apply object>, 'criterion': <hyperopt.pyll.base.Apply object>, 'max_depth': <hyperopt.pyll.base.Apply object>, 'max_features': <hyperopt.pyll.base.Apply object>, 'max_leaf_nodes': <hyperopt.pyll.base.Apply object>, 'min_samples_split': <hyperopt.pyll.base.Apply object>, 'n_estimators': <hyperopt.pyll.base.Apply object>}, 'pipeline': {'features': <hyperopt.pyll.base.Apply object>, 'normalizer': <hyperopt.pyll.base.Apply object>, 'rebalance': <hyperopt.pyll.base.Apply object>}}, algo=<function suggest>, max_evals=9223372036854775807, max_time=300, trials=<hyperopt.base.Trials object>, rstate=<mtrand.RandomState object>, allow_trials_fmin=False, pass_expr_memo_ctrl=None, catch_eval_exceptions=False, verbose=0, return_argmin=True, points_to_evaluate=None, max_queue_len=1, show_progressbar=False)
    426                     verbose=verbose,
    427                     max_queue_len=max_queue_len,
    428                     show_progressbar=show_progressbar,
    429                     max_time=max_time)
    430     rval.catch_eval_exceptions = catch_eval_exceptions
--> 431     rval.exhaust()
        rval.exhaust = <bound method FMinIter.exhaust of <hyperopt.fmin.FMinIter object>>
    432     if return_argmin:
    433         return trials.argmin
    434     elif len(trials) > 0:
    435         # Only if there are some succesfull trail runs, return the best point in the evaluation space

...........................................................................
/home/aquemy/dev/dp_hyperparameters/extension/hyperopt/fmin.py in exhaust(self=<hyperopt.fmin.FMinIter object>)
    273             raise StopIteration()
    274         return self.trials
    275 
    276     def exhaust(self):
    277         n_done = len(self.trials)
--> 278         self.run(self.max_evals - n_done, block_until_done=self.asynchronous)
        self.run = <bound method FMinIter.run of <hyperopt.fmin.FMinIter object>>
        self.max_evals = 9223372036854775807
        n_done = 0
        self.asynchronous = False
    279         self.trials.refresh()
    280         return self
    281 
    282 

...........................................................................
/home/aquemy/dev/dp_hyperparameters/extension/hyperopt/fmin.py in run(self=<hyperopt.fmin.FMinIter object>, N=9223372036854775807, block_until_done=False)
    232                     if self.asynchronous:
    233                         # -- wait for workers to fill in the trials
    234                         time.sleep(self.poll_interval_secs)
    235                     else:
    236                         # -- loop over trials and do the jobs directly
--> 237                         self.serial_evaluate()
        self.serial_evaluate = <bound method FMinIter.serial_evaluate of <hyperopt.fmin.FMinIter object>>
    238                     try:
    239                         res = [d['result']['loss'] for d in
    240                                          self.trials.trials if
    241                                          d['result']['status'] == 'ok']

...........................................................................
/home/aquemy/dev/dp_hyperparameters/extension/hyperopt/fmin.py in serial_evaluate(self=<hyperopt.fmin.FMinIter object>, N=-1)
    138                 trial['book_time'] = now
    139                 trial['refresh_time'] = now
    140                 spec = base.spec_from_misc(trial['misc'])
    141                 ctrl = base.Ctrl(self.trials, current_trial=trial)
    142                 try:
--> 143                     result = self.domain.evaluate(spec, ctrl)
        result = undefined
        self.domain.evaluate = <bound method Domain.evaluate of <hyperopt.base.Domain object>>
        spec = {'bootstrap': 1, 'criterion': 0, 'features': 2, 'features_SelectKBest_features__k': 1, 'max_depth': 0, 'max_features': 2, 'max_leaf_nodes': 2, 'min_samples_split': 0, 'n_estimators': 4, 'normalizer': 3, ...}
        ctrl = <hyperopt.base.Ctrl object>
    144                 except Exception as e:
    145                     logger.info('job exception: %s' % str(e))
    146                     trial['state'] = base.JOB_STATE_ERROR
    147                     trial['misc']['error'] = (str(type(e)), str(e))

...........................................................................
/home/aquemy/dev/dp_hyperparameters/extension/hyperopt/base.py in evaluate(self=<hyperopt.base.Domain object>, config={'bootstrap': 1, 'criterion': 0, 'features': 2, 'features_SelectKBest_features__k': 1, 'max_depth': 0, 'max_features': 2, 'max_leaf_nodes': 2, 'min_samples_split': 0, 'n_estimators': 4, 'normalizer': 3, ...}, ctrl=<hyperopt.base.Ctrl object>, attach_attachments=True)
    841             #    or the normal Python part (self.fn)
    842             pyll_rval = pyll.rec_eval(
    843                 self.expr,
    844                 memo=memo,
    845                 print_node_on_error=self.rec_eval_print_node_on_error)
--> 846             rval = self.fn(pyll_rval)
        rval = undefined
        self.fn = <functools.partial object>
        pyll_rval = {'algorithm': {'bootstrap': False, 'criterion': 'gini', 'max_depth': 1, 'max_features': 3, 'max_leaf_nodes': 5, 'min_samples_split': 2, 'n_estimators': 100}, 'pipeline': {'features': ('features_SelectKBest', {'features__k': 2}), 'normalizer': ('normalizer_MinMaxScaler', {}), 'rebalance': ('rebalance_NoneType', {})}}
    847 
    848         if isinstance(rval, (float, int, np.number)):
    849             dict_rval = {'loss': float(rval), 'status': STATUS_OK}
    850         else:

...........................................................................
/home/aquemy/dev/dp_hyperparameters/extension/experiment/objective.py in objective_joint(wconfig={'algorithm': {'bootstrap': False, 'criterion': 'gini', 'max_depth': 1, 'max_features': 3, 'max_leaf_nodes': 5, 'min_samples_split': 2, 'n_estimators': 100}, 'pipeline': {'features': ('features_SelectKBest', {'features__k': 2}), 'normalizer': ('normalizer_MinMaxScaler', {}), 'rebalance': ('rebalance_NoneType', {})}}, algorithm='RandomForest', X=array([[1.423e+01, 1.710e+00, 2.430e+00, ..., 1...., ..., 6.100e-01, 1.600e+00,
        5.600e+02]]), y=array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,
       2, 2]), context={'baseline_score': 0.9444100447196423, 'baseline_score_std': 0.04305547117084885, 'best_config': {'algorithm': {'bootstrap': False, 'criterion': 'gini', 'max_depth': 1, 'max_features': 1, 'max_leaf_nodes': 3, 'min_samples_split': 5, 'n_estimators': 50}, 'config_hash': {'algorithm': 'cefc05c6c759dc564d289289fe401e0f8737951d', 'config': '7a1c40755d84d62f5d2ab1ed021e7dff93dfce45', 'pipeline': '3ee6a915db2d8d71f204c103803fb8eabea0d54f'}, 'duration': 0.6908998489379883, 'iteration': 24, 'loss': 0.005555555555555536, 'max_history_score': 0.9944444444444445, 'max_history_score_std': 0.016666666666666673, 'max_history_step': 'joint', 'pipeline': {'features': ('features_NoneType', {}), 'normalizer': ('normalizer_MinMaxScaler', {}), 'rebalance': ('rebalance_NoneType', {})}, 'score': 0.9944444444444445, ...}, 'history': [{'algorithm': {'bootstrap': False, 'criterion': 'entropy', 'max_depth': None, 'max_features': 3, 'max_leaf_nodes': 5, 'min_samples_split': 2, 'n_estimators': 50}, 'config_hash': {'algorithm': 'b2c6464add7a35ce8048653a39338c9994de9a4f', 'config': '2e6648b63441361b4398cb94f81d2e04a830b2ef', 'pipeline': '3d44d7482e468d08c4f94457a205f3dac74084c1'}, 'duration': 0.737678050994873, 'iteration': 0, 'loss': 1.0, 'max_history_score': 0.0, 'max_history_score_std': 0.0, 'max_history_step': 'baseline', 'pipeline': {'features': ('features_PCA', {'features__n_components': 1}), 'normalizer': ('normalizer_NoneType', {}), 'rebalance': ('rebalance_CondensedNearestNeighbour', {'rebalance__n_neighbors': 3})}, 'score': 0.0, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'gini', 'max_depth': 1, 'max_features': None, 'max_leaf_nodes': 2, 'min_samples_split': 3, 'n_estimators': 25}, 'config_hash': {'algorithm': '7f71bbbfdb4e8da52b6fc33a43224183117de15e', 'config': '584343bc020d2d7bc89bd0856bc7770dae1c84fc', 'pipeline': '466ffa7ace0e442beb7c311eb214b17a4c6832b3'}, 'duration': 1.5976769924163818, 'iteration': 1, 'loss': 0.40386351909184726, 'max_history_score': 0.5961364809081527, 'max_history_score_std': 0.05351463210025494, 'max_history_step': 'joint', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 3, 'features__selectkbest__k': 3}), 'normalizer': ('normalizer_StandardScaler', {'normalizer__with_mean': True, 'normalizer__with_std': True}), 'rebalance': ('rebalance_NearMiss', {'rebalance__n_neighbors': 2})}, 'score': 0.5961364809081527, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'entropy', 'max_depth': 1, 'max_features': 2, 'max_leaf_nodes': 2, 'min_samples_split': 5, 'n_estimators': 25}, 'config_hash': {'algorithm': '897745a20d929d43e760cacee0a764bd8070daa5', 'config': 'de121d053e65def047cc8947f505578d5c5eab67', 'pipeline': '63040b39b48626a8232e847e8327bdca5cd88611'}, 'duration': 0.815453052520752, 'iteration': 2, 'loss': 0.07327786377708967, 'max_history_score': 0.9267221362229103, 'max_history_score_std': 0.043920207373658794, 'max_history_step': 'joint', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 3, 'features__selectkbest__k': 2}), 'normalizer': ('normalizer_StandardScaler', {'normalizer__with_mean': True, 'normalizer__with_std': True}), 'rebalance': ('rebalance_NoneType', {})}, 'score': 0.9267221362229103, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'entropy', 'max_depth': 4, 'max_features': 3, 'max_leaf_nodes': None, 'min_samples_split': 2, 'n_estimators': 100}, 'config_hash': {'algorithm': 'dbd92c75280ec06b66ca4ad9b135cf36957031a4', 'config': 'b21c9d15a389baa5bfea4c8ddcec129259f37540', 'pipeline': '38866720d2f120c863351493b9b4e23b9a4506dc'}, 'duration': 1.2293269634246826, 'iteration': 3, 'loss': 0.07199862401100798, 'max_history_score': 0.928001375988992, 'max_history_score_std': 0.06518367535896959, 'max_history_step': 'joint', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 2, 'features__selectkbest__k': 4}), 'normalizer': ('normalizer_NoneType', {}), 'rebalance': ('rebalance_NoneType', {})}, 'score': 0.928001375988992, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': 2, 'max_features': None, 'max_leaf_nodes': None, 'min_samples_split': 5, 'n_estimators': 100}, 'config_hash': {'algorithm': 'f455eefd9fdd03ece88892c3f440c580bdf27ddb', 'config': 'edd3456355d80775739c31515c832ca7b4e5e094', 'pipeline': '1d1034f9f0871e43f896c1db4ed6fd572ed0a6ef'}, 'duration': 1.6186630725860596, 'iteration': 4, 'loss': 0.16651831785345705, 'max_history_score': 0.928001375988992, 'max_history_score_std': 0.06518367535896959, 'max_history_step': 'joint', 'pipeline': {'features': ('features_SelectKBest', {'features__k': 4}), 'normalizer': ('normalizer_MinMaxScaler', {}), 'rebalance': ('rebalance_CondensedNearestNeighbour', {'rebalance__n_neighbors': 1})}, 'score': 0.833481682146543, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'entropy', 'max_depth': 1, 'max_features': 2, 'max_leaf_nodes': None, 'min_samples_split': 2, 'n_estimators': 10}, 'config_hash': {'algorithm': '29906eaa0712a68ea145b12821d54ba445726fbf', 'config': '0800d7d2c8c10d2f9e7b4e5127b343e916eb742c', 'pipeline': '2e0f188ae61600352a7159285e0f542b4587a403'}, 'duration': 0.19410085678100586, 'iteration': 5, 'loss': 0.20164258685930514, 'max_history_score': 0.928001375988992, 'max_history_score_std': 0.06518367535896959, 'max_history_step': 'joint', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 3, 'features__selectkbest__k': 4}), 'normalizer': ('normalizer_StandardScaler', {'normalizer__with_mean': True, 'normalizer__with_std': False}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 7})}, 'score': 0.7983574131406949, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': 1, 'max_features': 1, 'max_leaf_nodes': 5, 'min_samples_split': 2, 'n_estimators': 25}, 'config_hash': {'algorithm': 'fbb7d57e38cfc08240f0af985282da418cb33556', 'config': 'd98b641879b4754f2169335626a90575e945fd7c', 'pipeline': '62463de065924498cdcd2f2f1f7e68535cdb33a5'}, 'duration': 0.3625810146331787, 'iteration': 6, 'loss': 0.14327485380116955, 'max_history_score': 0.928001375988992, 'max_history_score_std': 0.06518367535896959, 'max_history_step': 'joint', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 1, 'features__selectkbest__k': 2}), 'normalizer': ('normalizer_NoneType', {}), 'rebalance': ('rebalance_NoneType', {})}, 'score': 0.8567251461988304, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'entropy', 'max_depth': 3, 'max_features': 1, 'max_leaf_nodes': None, 'min_samples_split': 2, 'n_estimators': 75}, 'config_hash': {'algorithm': 'fb2f5d4c4d636edac929e1454ce3d02a4fb134c1', 'config': '3f83df36a6abbdf7ea4a4bdcaf6727f23529c2bb', 'pipeline': '8377b93e334656d1a93d266493b58ef9a6a1786f'}, 'duration': 0.8223779201507568, 'iteration': 7, 'loss': 0.03921568627450989, 'max_history_score': 0.9607843137254901, 'max_history_score_std': 0.043526663832084804, 'max_history_step': 'joint', 'pipeline': {'features': ('features_PCA', {'features__n_components': 3}), 'normalizer': ('normalizer_MinMaxScaler', {}), 'rebalance': ('rebalance_NearMiss', {'rebalance__n_neighbors': 1})}, 'score': 0.9607843137254901, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'gini', 'max_depth': 3, 'max_features': 3, 'max_leaf_nodes': 2, 'min_samples_split': 2, 'n_estimators': 100}, 'config_hash': {'algorithm': '3c3fde6559b918694de4668d025d5418342db1b1', 'config': '037fd5c655b39cc7922fb394d736496befcc747b', 'pipeline': '2a5032814c6c7ed21dd5bd9686923d7fc2f8acc9'}, 'duration': 1.0435099601745605, 'iteration': 8, 'loss': 0.09955925352597172, 'max_history_score': 0.9607843137254901, 'max_history_score_std': 0.043526663832084804, 'max_history_step': 'joint', 'pipeline': {'features': ('features_NoneType', {}), 'normalizer': ('normalizer_RobustScaler', {'normalizer__quantile_range': (...), 'normalizer__with_centering': True, 'normalizer__with_scaling': True}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 7})}, 'score': 0.9004407464740283, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': 2, 'max_features': 1, 'max_leaf_nodes': None, 'min_samples_split': 3, 'n_estimators': 75}, 'config_hash': {'algorithm': '42185be98371e99ac896d2c6c2d69c451cb983ff', 'config': '6609280032189b59de1afbe36f3acb1d5c273693', 'pipeline': '8aab2941fc84d84f86fa56134e50909dbf9e19f5'}, 'duration': 0.9665219783782959, 'iteration': 9, 'loss': 0.01637426900584804, 'max_history_score': 0.983625730994152, 'max_history_score_std': 0.025023500462379746, 'max_history_step': 'joint', 'pipeline': {'features': ('features_NoneType', {}), 'normalizer': ('normalizer_PowerTransformer', {}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 5})}, 'score': 0.983625730994152, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': 1, 'max_features': 3, 'max_leaf_nodes': 2, 'min_samples_split': 3, 'n_estimators': 10}, 'config_hash': {'algorithm': '62a9fe705e4cd96e762bcc9543c4a456a5a9f188', 'config': '8e1c17ac9f6e03740f380fccb833c9c3931ffc35', 'pipeline': '3d44d7482e468d08c4f94457a205f3dac74084c1'}, 'duration': 0.46930503845214844, 'iteration': 10, 'loss': 1.0, 'max_history_score': 0.983625730994152, 'max_history_score_std': 0.025023500462379746, 'max_history_step': 'joint', 'pipeline': {'features': ('features_PCA', {'features__n_components': 1}), 'normalizer': ('normalizer_NoneType', {}), 'rebalance': ('rebalance_CondensedNearestNeighbour', {'rebalance__n_neighbors': 3})}, 'score': 0.0, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'gini', 'max_depth': 4, 'max_features': 1, 'max_leaf_nodes': 3, 'min_samples_split': 2, 'n_estimators': 100}, 'config_hash': {'algorithm': '086d6ca939a757bb32edb113a567f9d38744f061', 'config': '87c03d0cb8e8500e58cacc1a0f27ce54c41a2937', 'pipeline': '8f28ef0f35d97142278f9dacb4e9d1ff082e470f'}, 'duration': 2.1196961402893066, 'iteration': 11, 'loss': 0.15471276229790154, 'max_history_score': 0.983625730994152, 'max_history_score_std': 0.025023500462379746, 'max_history_step': 'joint', 'pipeline': {'features': ('features_PCA', {'features__n_components': 1}), 'normalizer': ('normalizer_StandardScaler', {'normalizer__with_mean': True, 'normalizer__with_std': True}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 7})}, 'score': 0.8452872377020985, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'entropy', 'max_depth': 3, 'max_features': 1, 'max_leaf_nodes': 2, 'min_samples_split': 2, 'n_estimators': 25}, 'config_hash': {'algorithm': '59f64a966796648c7bebade1127fa05541b391ad', 'config': '2ab964abffa0a277a9e2ee9b5570cd258e428b62', 'pipeline': 'eef3f702fd2fed761fa6744c1640d0bf320f1d00'}, 'duration': 0.9828321933746338, 'iteration': 12, 'loss': 0.0778465772273822, 'max_history_score': 0.983625730994152, 'max_history_score_std': 0.025023500462379746, 'max_history_step': 'joint', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 3, 'features__selectkbest__k': 1}), 'normalizer': ('normalizer_PowerTransformer', {}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 6})}, 'score': 0.9221534227726178, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'gini', 'max_depth': 4, 'max_features': 2, 'max_leaf_nodes': 3, 'min_samples_split': 3, 'n_estimators': 75}, 'config_hash': {'algorithm': '6f75c2a196eb9836df2b424e095051192eaed6ea', 'config': '5c95db3ad238063227f1b36e6a006d70c834c5da', 'pipeline': '1eae01a1128bee425c4d4ca0ee97a9afd409680e'}, 'duration': 0.8217771053314209, 'iteration': 13, 'loss': 0.03863089095287242, 'max_history_score': 0.983625730994152, 'max_history_score_std': 0.025023500462379746, 'max_history_step': 'joint', 'pipeline': {'features': ('features_NoneType', {}), 'normalizer': ('normalizer_StandardScaler', {'normalizer__with_mean': False, 'normalizer__with_std': False}), 'rebalance': ('rebalance_NearMiss', {'rebalance__n_neighbors': 1})}, 'score': 0.9613691090471276, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'entropy', 'max_depth': 4, 'max_features': 2, 'max_leaf_nodes': 3, 'min_samples_split': 2, 'n_estimators': 25}, 'config_hash': {'algorithm': '8aef3174f6b8020de06b825e0424c1e54d690afd', 'config': '50fd1169b8e42190600f25152654254b5d0e3ed1', 'pipeline': '9ceaa544911dc6c687e336cb8e9dd4d15ff1ceaf'}, 'duration': 0.40307188034057617, 'iteration': 14, 'loss': 1.0, 'max_history_score': 0.983625730994152, 'max_history_score_std': 0.025023500462379746, 'max_history_step': 'joint', 'pipeline': {'features': ('features_PCA', {'features__n_components': 1}), 'normalizer': ('normalizer_RobustScaler', {'normalizer__quantile_range': (...), 'normalizer__with_centering': False, 'normalizer__with_scaling': False}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 7})}, 'score': 0.0, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'gini', 'max_depth': 1, 'max_features': 1, 'max_leaf_nodes': 3, 'min_samples_split': 3, 'n_estimators': 50}, 'config_hash': {'algorithm': '37be8b6737f4b5d5ae35da51886f302b07ba6001', 'config': 'a05b6d2ffd65d4d937c0b178655d857bf4d61410', 'pipeline': 'cfef88e895db321122f2f7b813d9267b973c2468'}, 'duration': 1.7094659805297852, 'iteration': 15, 'loss': 0.011111111111111072, 'max_history_score': 0.9888888888888889, 'max_history_score_std': 0.022222222222222233, 'max_history_step': 'joint', 'pipeline': {'features': ('features_NoneType', {}), 'normalizer': ('normalizer_NoneType', {}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 5})}, 'score': 0.9888888888888889, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'entropy', 'max_depth': None, 'max_features': 3, 'max_leaf_nodes': None, 'min_samples_split': 2, 'n_estimators': 100}, 'config_hash': {'algorithm': 'c40543ce91793e367c1892c886bc49621c22ecfb', 'config': 'ebebb7a93116f14f470e062e37582a59f4aeb0df', 'pipeline': 'b50c63e800574e8b760f55f7c4ff1fcae8816dd8'}, 'duration': 0.6425540447235107, 'iteration': 16, 'loss': 1.0, 'max_history_score': 0.9888888888888889, 'max_history_score_std': 0.022222222222222233, 'max_history_step': 'joint', 'pipeline': {'features': ('features_PCA', {'features__n_components': 1}), 'normalizer': ('normalizer_PowerTransformer', {}), 'rebalance': ('rebalance_NearMiss', {'rebalance__n_neighbors': 1})}, 'score': 0.0, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'gini', 'max_depth': None, 'max_features': 1, 'max_leaf_nodes': 3, 'min_samples_split': 2, 'n_estimators': 50}, 'config_hash': {'algorithm': '0c69b9601237c20664085fa05764d855e28f98f7', 'config': 'a2c21314ddbba47ddbfe416e0aa14853a71179e0', 'pipeline': '914f81fa4fbb61db251201f32bd8ea11bfeea2a5'}, 'duration': 2.2209739685058594, 'iteration': 17, 'loss': 0.3206720846233231, 'max_history_score': 0.9888888888888889, 'max_history_score_std': 0.022222222222222233, 'max_history_step': 'joint', 'pipeline': {'features': ('features_SelectKBest', {'features__k': 4}), 'normalizer': ('normalizer_PowerTransformer', {}), 'rebalance': ('rebalance_CondensedNearestNeighbour', {'rebalance__n_neighbors': 1})}, 'score': 0.6793279153766769, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': 4, 'max_features': None, 'max_leaf_nodes': None, 'min_samples_split': 3, 'n_estimators': 25}, 'config_hash': {'algorithm': '1aae0f1fce5cab293ffdd4581c4838c8051ac815', 'config': '6c8a721218e7c550a98c5ba72ad9ff86afd5e3a4', 'pipeline': '77189452469cef9c840643f2babe0f825c6667c8'}, 'duration': 0.3951280117034912, 'iteration': 18, 'loss': 0.1804760061919506, 'max_history_score': 0.9888888888888889, 'max_history_score_std': 0.022222222222222233, 'max_history_step': 'joint', 'pipeline': {'features': ('features_SelectKBest', {'features__k': 2}), 'normalizer': ('normalizer_NoneType', {}), 'rebalance': ('rebalance_NearMiss', {'rebalance__n_neighbors': 1})}, 'score': 0.8195239938080494, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': None, 'max_features': 3, 'max_leaf_nodes': 5, 'min_samples_split': 3, 'n_estimators': 50}, 'config_hash': {'algorithm': '0129970b8c7fe034ac8283fb518a06cfbead63d2', 'config': '61bcd2f64860b3dfe2503be88a6bbec165db0754', 'pipeline': '359f2473075ecfd9ae3ce526da96143918517601'}, 'duration': 0.7467091083526611, 'iteration': 19, 'loss': 0.09915720674234607, 'max_history_score': 0.9888888888888889, 'max_history_score_std': 0.022222222222222233, 'max_history_step': 'joint', 'pipeline': {'features': ('features_SelectKBest', {'features__k': 3}), 'normalizer': ('normalizer_RobustScaler', {'normalizer__quantile_range': (...), 'normalizer__with_centering': True, 'normalizer__with_scaling': False}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 7})}, 'score': 0.9008427932576539, ...}, ...], 'history_hash': ['2e6648b63441361b4398cb94f81d2e04a830b2ef', '584343bc020d2d7bc89bd0856bc7770dae1c84fc', 'de121d053e65def047cc8947f505578d5c5eab67', 'b21c9d15a389baa5bfea4c8ddcec129259f37540', 'edd3456355d80775739c31515c832ca7b4e5e094', '0800d7d2c8c10d2f9e7b4e5127b343e916eb742c', 'd98b641879b4754f2169335626a90575e945fd7c', '3f83df36a6abbdf7ea4a4bdcaf6727f23529c2bb', '037fd5c655b39cc7922fb394d736496befcc747b', '6609280032189b59de1afbe36f3acb1d5c273693', '8e1c17ac9f6e03740f380fccb833c9c3931ffc35', '87c03d0cb8e8500e58cacc1a0f27ce54c41a2937', '2ab964abffa0a277a9e2ee9b5570cd258e428b62', '5c95db3ad238063227f1b36e6a006d70c834c5da', '50fd1169b8e42190600f25152654254b5d0e3ed1', 'a05b6d2ffd65d4d937c0b178655d857bf4d61410', 'ebebb7a93116f14f470e062e37582a59f4aeb0df', 'a2c21314ddbba47ddbfe416e0aa14853a71179e0', '6c8a721218e7c550a98c5ba72ad9ff86afd5e3a4', '61bcd2f64860b3dfe2503be88a6bbec165db0754', ...], 'history_index': {'037fd5c655b39cc7922fb394d736496befcc747b': 8, '07fdf9d0d0248a4b0215a633c75a2dd101dcf465': 22, '0800d7d2c8c10d2f9e7b4e5127b343e916eb742c': 5, '0babf362e2373c001d4eb84f3c4eda27e56fe02d': 33, '0e45095dfe50d5be759b179b50e63384925c7027': 32, '2323c40e4e6c5f4aa333620a6b998b510ca41854': 35, '26ed0b67cf1046a22e2baba31b70ce3b6e762a03': 40, '28944b74104bc5bb782512b0eefa3167fe189355': 30, '2a317f1667c0a37724743084ca5dcbf14ff107f0': 29, '2ab964abffa0a277a9e2ee9b5570cd258e428b62': 12, ...}, 'iteration': 42, 'max_history_score': 0.9944444444444445, 'max_history_score_std': 0.016666666666666673, 'max_history_step': 'joint'}, config={'algorithm': 'RandomForest', 'seed': 42, 'time': 300})
    108 
    109 def objective_algo(algo_config, current_pipeline_config, algorithm, X, y, context, config):
    110     return objective(current_pipeline_config, algo_config, algorithm, X, y, context, config, step='algorithm')
    111 
    112 def objective_joint(wconfig, algorithm, X, y, context, config):
--> 113     return objective(wconfig['pipeline'], wconfig['algorithm'], algorithm, X, y, context, config, step='joint')
        wconfig = {'algorithm': {'bootstrap': False, 'criterion': 'gini', 'max_depth': 1, 'max_features': 3, 'max_leaf_nodes': 5, 'min_samples_split': 2, 'n_estimators': 100}, 'pipeline': {'features': ('features_SelectKBest', {'features__k': 2}), 'normalizer': ('normalizer_MinMaxScaler', {}), 'rebalance': ('rebalance_NoneType', {})}}
        algorithm = 'RandomForest'
        X = array([[1.423e+01, 1.710e+00, 2.430e+00, ..., 1...., ..., 6.100e-01, 1.600e+00,
        5.600e+02]])
        y = array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,
       2, 2])
        context = {'baseline_score': 0.9444100447196423, 'baseline_score_std': 0.04305547117084885, 'best_config': {'algorithm': {'bootstrap': False, 'criterion': 'gini', 'max_depth': 1, 'max_features': 1, 'max_leaf_nodes': 3, 'min_samples_split': 5, 'n_estimators': 50}, 'config_hash': {'algorithm': 'cefc05c6c759dc564d289289fe401e0f8737951d', 'config': '7a1c40755d84d62f5d2ab1ed021e7dff93dfce45', 'pipeline': '3ee6a915db2d8d71f204c103803fb8eabea0d54f'}, 'duration': 0.6908998489379883, 'iteration': 24, 'loss': 0.005555555555555536, 'max_history_score': 0.9944444444444445, 'max_history_score_std': 0.016666666666666673, 'max_history_step': 'joint', 'pipeline': {'features': ('features_NoneType', {}), 'normalizer': ('normalizer_MinMaxScaler', {}), 'rebalance': ('rebalance_NoneType', {})}, 'score': 0.9944444444444445, ...}, 'history': [{'algorithm': {'bootstrap': False, 'criterion': 'entropy', 'max_depth': None, 'max_features': 3, 'max_leaf_nodes': 5, 'min_samples_split': 2, 'n_estimators': 50}, 'config_hash': {'algorithm': 'b2c6464add7a35ce8048653a39338c9994de9a4f', 'config': '2e6648b63441361b4398cb94f81d2e04a830b2ef', 'pipeline': '3d44d7482e468d08c4f94457a205f3dac74084c1'}, 'duration': 0.737678050994873, 'iteration': 0, 'loss': 1.0, 'max_history_score': 0.0, 'max_history_score_std': 0.0, 'max_history_step': 'baseline', 'pipeline': {'features': ('features_PCA', {'features__n_components': 1}), 'normalizer': ('normalizer_NoneType', {}), 'rebalance': ('rebalance_CondensedNearestNeighbour', {'rebalance__n_neighbors': 3})}, 'score': 0.0, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'gini', 'max_depth': 1, 'max_features': None, 'max_leaf_nodes': 2, 'min_samples_split': 3, 'n_estimators': 25}, 'config_hash': {'algorithm': '7f71bbbfdb4e8da52b6fc33a43224183117de15e', 'config': '584343bc020d2d7bc89bd0856bc7770dae1c84fc', 'pipeline': '466ffa7ace0e442beb7c311eb214b17a4c6832b3'}, 'duration': 1.5976769924163818, 'iteration': 1, 'loss': 0.40386351909184726, 'max_history_score': 0.5961364809081527, 'max_history_score_std': 0.05351463210025494, 'max_history_step': 'joint', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 3, 'features__selectkbest__k': 3}), 'normalizer': ('normalizer_StandardScaler', {'normalizer__with_mean': True, 'normalizer__with_std': True}), 'rebalance': ('rebalance_NearMiss', {'rebalance__n_neighbors': 2})}, 'score': 0.5961364809081527, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'entropy', 'max_depth': 1, 'max_features': 2, 'max_leaf_nodes': 2, 'min_samples_split': 5, 'n_estimators': 25}, 'config_hash': {'algorithm': '897745a20d929d43e760cacee0a764bd8070daa5', 'config': 'de121d053e65def047cc8947f505578d5c5eab67', 'pipeline': '63040b39b48626a8232e847e8327bdca5cd88611'}, 'duration': 0.815453052520752, 'iteration': 2, 'loss': 0.07327786377708967, 'max_history_score': 0.9267221362229103, 'max_history_score_std': 0.043920207373658794, 'max_history_step': 'joint', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 3, 'features__selectkbest__k': 2}), 'normalizer': ('normalizer_StandardScaler', {'normalizer__with_mean': True, 'normalizer__with_std': True}), 'rebalance': ('rebalance_NoneType', {})}, 'score': 0.9267221362229103, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'entropy', 'max_depth': 4, 'max_features': 3, 'max_leaf_nodes': None, 'min_samples_split': 2, 'n_estimators': 100}, 'config_hash': {'algorithm': 'dbd92c75280ec06b66ca4ad9b135cf36957031a4', 'config': 'b21c9d15a389baa5bfea4c8ddcec129259f37540', 'pipeline': '38866720d2f120c863351493b9b4e23b9a4506dc'}, 'duration': 1.2293269634246826, 'iteration': 3, 'loss': 0.07199862401100798, 'max_history_score': 0.928001375988992, 'max_history_score_std': 0.06518367535896959, 'max_history_step': 'joint', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 2, 'features__selectkbest__k': 4}), 'normalizer': ('normalizer_NoneType', {}), 'rebalance': ('rebalance_NoneType', {})}, 'score': 0.928001375988992, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': 2, 'max_features': None, 'max_leaf_nodes': None, 'min_samples_split': 5, 'n_estimators': 100}, 'config_hash': {'algorithm': 'f455eefd9fdd03ece88892c3f440c580bdf27ddb', 'config': 'edd3456355d80775739c31515c832ca7b4e5e094', 'pipeline': '1d1034f9f0871e43f896c1db4ed6fd572ed0a6ef'}, 'duration': 1.6186630725860596, 'iteration': 4, 'loss': 0.16651831785345705, 'max_history_score': 0.928001375988992, 'max_history_score_std': 0.06518367535896959, 'max_history_step': 'joint', 'pipeline': {'features': ('features_SelectKBest', {'features__k': 4}), 'normalizer': ('normalizer_MinMaxScaler', {}), 'rebalance': ('rebalance_CondensedNearestNeighbour', {'rebalance__n_neighbors': 1})}, 'score': 0.833481682146543, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'entropy', 'max_depth': 1, 'max_features': 2, 'max_leaf_nodes': None, 'min_samples_split': 2, 'n_estimators': 10}, 'config_hash': {'algorithm': '29906eaa0712a68ea145b12821d54ba445726fbf', 'config': '0800d7d2c8c10d2f9e7b4e5127b343e916eb742c', 'pipeline': '2e0f188ae61600352a7159285e0f542b4587a403'}, 'duration': 0.19410085678100586, 'iteration': 5, 'loss': 0.20164258685930514, 'max_history_score': 0.928001375988992, 'max_history_score_std': 0.06518367535896959, 'max_history_step': 'joint', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 3, 'features__selectkbest__k': 4}), 'normalizer': ('normalizer_StandardScaler', {'normalizer__with_mean': True, 'normalizer__with_std': False}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 7})}, 'score': 0.7983574131406949, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': 1, 'max_features': 1, 'max_leaf_nodes': 5, 'min_samples_split': 2, 'n_estimators': 25}, 'config_hash': {'algorithm': 'fbb7d57e38cfc08240f0af985282da418cb33556', 'config': 'd98b641879b4754f2169335626a90575e945fd7c', 'pipeline': '62463de065924498cdcd2f2f1f7e68535cdb33a5'}, 'duration': 0.3625810146331787, 'iteration': 6, 'loss': 0.14327485380116955, 'max_history_score': 0.928001375988992, 'max_history_score_std': 0.06518367535896959, 'max_history_step': 'joint', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 1, 'features__selectkbest__k': 2}), 'normalizer': ('normalizer_NoneType', {}), 'rebalance': ('rebalance_NoneType', {})}, 'score': 0.8567251461988304, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'entropy', 'max_depth': 3, 'max_features': 1, 'max_leaf_nodes': None, 'min_samples_split': 2, 'n_estimators': 75}, 'config_hash': {'algorithm': 'fb2f5d4c4d636edac929e1454ce3d02a4fb134c1', 'config': '3f83df36a6abbdf7ea4a4bdcaf6727f23529c2bb', 'pipeline': '8377b93e334656d1a93d266493b58ef9a6a1786f'}, 'duration': 0.8223779201507568, 'iteration': 7, 'loss': 0.03921568627450989, 'max_history_score': 0.9607843137254901, 'max_history_score_std': 0.043526663832084804, 'max_history_step': 'joint', 'pipeline': {'features': ('features_PCA', {'features__n_components': 3}), 'normalizer': ('normalizer_MinMaxScaler', {}), 'rebalance': ('rebalance_NearMiss', {'rebalance__n_neighbors': 1})}, 'score': 0.9607843137254901, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'gini', 'max_depth': 3, 'max_features': 3, 'max_leaf_nodes': 2, 'min_samples_split': 2, 'n_estimators': 100}, 'config_hash': {'algorithm': '3c3fde6559b918694de4668d025d5418342db1b1', 'config': '037fd5c655b39cc7922fb394d736496befcc747b', 'pipeline': '2a5032814c6c7ed21dd5bd9686923d7fc2f8acc9'}, 'duration': 1.0435099601745605, 'iteration': 8, 'loss': 0.09955925352597172, 'max_history_score': 0.9607843137254901, 'max_history_score_std': 0.043526663832084804, 'max_history_step': 'joint', 'pipeline': {'features': ('features_NoneType', {}), 'normalizer': ('normalizer_RobustScaler', {'normalizer__quantile_range': (...), 'normalizer__with_centering': True, 'normalizer__with_scaling': True}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 7})}, 'score': 0.9004407464740283, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': 2, 'max_features': 1, 'max_leaf_nodes': None, 'min_samples_split': 3, 'n_estimators': 75}, 'config_hash': {'algorithm': '42185be98371e99ac896d2c6c2d69c451cb983ff', 'config': '6609280032189b59de1afbe36f3acb1d5c273693', 'pipeline': '8aab2941fc84d84f86fa56134e50909dbf9e19f5'}, 'duration': 0.9665219783782959, 'iteration': 9, 'loss': 0.01637426900584804, 'max_history_score': 0.983625730994152, 'max_history_score_std': 0.025023500462379746, 'max_history_step': 'joint', 'pipeline': {'features': ('features_NoneType', {}), 'normalizer': ('normalizer_PowerTransformer', {}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 5})}, 'score': 0.983625730994152, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': 1, 'max_features': 3, 'max_leaf_nodes': 2, 'min_samples_split': 3, 'n_estimators': 10}, 'config_hash': {'algorithm': '62a9fe705e4cd96e762bcc9543c4a456a5a9f188', 'config': '8e1c17ac9f6e03740f380fccb833c9c3931ffc35', 'pipeline': '3d44d7482e468d08c4f94457a205f3dac74084c1'}, 'duration': 0.46930503845214844, 'iteration': 10, 'loss': 1.0, 'max_history_score': 0.983625730994152, 'max_history_score_std': 0.025023500462379746, 'max_history_step': 'joint', 'pipeline': {'features': ('features_PCA', {'features__n_components': 1}), 'normalizer': ('normalizer_NoneType', {}), 'rebalance': ('rebalance_CondensedNearestNeighbour', {'rebalance__n_neighbors': 3})}, 'score': 0.0, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'gini', 'max_depth': 4, 'max_features': 1, 'max_leaf_nodes': 3, 'min_samples_split': 2, 'n_estimators': 100}, 'config_hash': {'algorithm': '086d6ca939a757bb32edb113a567f9d38744f061', 'config': '87c03d0cb8e8500e58cacc1a0f27ce54c41a2937', 'pipeline': '8f28ef0f35d97142278f9dacb4e9d1ff082e470f'}, 'duration': 2.1196961402893066, 'iteration': 11, 'loss': 0.15471276229790154, 'max_history_score': 0.983625730994152, 'max_history_score_std': 0.025023500462379746, 'max_history_step': 'joint', 'pipeline': {'features': ('features_PCA', {'features__n_components': 1}), 'normalizer': ('normalizer_StandardScaler', {'normalizer__with_mean': True, 'normalizer__with_std': True}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 7})}, 'score': 0.8452872377020985, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'entropy', 'max_depth': 3, 'max_features': 1, 'max_leaf_nodes': 2, 'min_samples_split': 2, 'n_estimators': 25}, 'config_hash': {'algorithm': '59f64a966796648c7bebade1127fa05541b391ad', 'config': '2ab964abffa0a277a9e2ee9b5570cd258e428b62', 'pipeline': 'eef3f702fd2fed761fa6744c1640d0bf320f1d00'}, 'duration': 0.9828321933746338, 'iteration': 12, 'loss': 0.0778465772273822, 'max_history_score': 0.983625730994152, 'max_history_score_std': 0.025023500462379746, 'max_history_step': 'joint', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 3, 'features__selectkbest__k': 1}), 'normalizer': ('normalizer_PowerTransformer', {}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 6})}, 'score': 0.9221534227726178, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'gini', 'max_depth': 4, 'max_features': 2, 'max_leaf_nodes': 3, 'min_samples_split': 3, 'n_estimators': 75}, 'config_hash': {'algorithm': '6f75c2a196eb9836df2b424e095051192eaed6ea', 'config': '5c95db3ad238063227f1b36e6a006d70c834c5da', 'pipeline': '1eae01a1128bee425c4d4ca0ee97a9afd409680e'}, 'duration': 0.8217771053314209, 'iteration': 13, 'loss': 0.03863089095287242, 'max_history_score': 0.983625730994152, 'max_history_score_std': 0.025023500462379746, 'max_history_step': 'joint', 'pipeline': {'features': ('features_NoneType', {}), 'normalizer': ('normalizer_StandardScaler', {'normalizer__with_mean': False, 'normalizer__with_std': False}), 'rebalance': ('rebalance_NearMiss', {'rebalance__n_neighbors': 1})}, 'score': 0.9613691090471276, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'entropy', 'max_depth': 4, 'max_features': 2, 'max_leaf_nodes': 3, 'min_samples_split': 2, 'n_estimators': 25}, 'config_hash': {'algorithm': '8aef3174f6b8020de06b825e0424c1e54d690afd', 'config': '50fd1169b8e42190600f25152654254b5d0e3ed1', 'pipeline': '9ceaa544911dc6c687e336cb8e9dd4d15ff1ceaf'}, 'duration': 0.40307188034057617, 'iteration': 14, 'loss': 1.0, 'max_history_score': 0.983625730994152, 'max_history_score_std': 0.025023500462379746, 'max_history_step': 'joint', 'pipeline': {'features': ('features_PCA', {'features__n_components': 1}), 'normalizer': ('normalizer_RobustScaler', {'normalizer__quantile_range': (...), 'normalizer__with_centering': False, 'normalizer__with_scaling': False}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 7})}, 'score': 0.0, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'gini', 'max_depth': 1, 'max_features': 1, 'max_leaf_nodes': 3, 'min_samples_split': 3, 'n_estimators': 50}, 'config_hash': {'algorithm': '37be8b6737f4b5d5ae35da51886f302b07ba6001', 'config': 'a05b6d2ffd65d4d937c0b178655d857bf4d61410', 'pipeline': 'cfef88e895db321122f2f7b813d9267b973c2468'}, 'duration': 1.7094659805297852, 'iteration': 15, 'loss': 0.011111111111111072, 'max_history_score': 0.9888888888888889, 'max_history_score_std': 0.022222222222222233, 'max_history_step': 'joint', 'pipeline': {'features': ('features_NoneType', {}), 'normalizer': ('normalizer_NoneType', {}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 5})}, 'score': 0.9888888888888889, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'entropy', 'max_depth': None, 'max_features': 3, 'max_leaf_nodes': None, 'min_samples_split': 2, 'n_estimators': 100}, 'config_hash': {'algorithm': 'c40543ce91793e367c1892c886bc49621c22ecfb', 'config': 'ebebb7a93116f14f470e062e37582a59f4aeb0df', 'pipeline': 'b50c63e800574e8b760f55f7c4ff1fcae8816dd8'}, 'duration': 0.6425540447235107, 'iteration': 16, 'loss': 1.0, 'max_history_score': 0.9888888888888889, 'max_history_score_std': 0.022222222222222233, 'max_history_step': 'joint', 'pipeline': {'features': ('features_PCA', {'features__n_components': 1}), 'normalizer': ('normalizer_PowerTransformer', {}), 'rebalance': ('rebalance_NearMiss', {'rebalance__n_neighbors': 1})}, 'score': 0.0, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'gini', 'max_depth': None, 'max_features': 1, 'max_leaf_nodes': 3, 'min_samples_split': 2, 'n_estimators': 50}, 'config_hash': {'algorithm': '0c69b9601237c20664085fa05764d855e28f98f7', 'config': 'a2c21314ddbba47ddbfe416e0aa14853a71179e0', 'pipeline': '914f81fa4fbb61db251201f32bd8ea11bfeea2a5'}, 'duration': 2.2209739685058594, 'iteration': 17, 'loss': 0.3206720846233231, 'max_history_score': 0.9888888888888889, 'max_history_score_std': 0.022222222222222233, 'max_history_step': 'joint', 'pipeline': {'features': ('features_SelectKBest', {'features__k': 4}), 'normalizer': ('normalizer_PowerTransformer', {}), 'rebalance': ('rebalance_CondensedNearestNeighbour', {'rebalance__n_neighbors': 1})}, 'score': 0.6793279153766769, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': 4, 'max_features': None, 'max_leaf_nodes': None, 'min_samples_split': 3, 'n_estimators': 25}, 'config_hash': {'algorithm': '1aae0f1fce5cab293ffdd4581c4838c8051ac815', 'config': '6c8a721218e7c550a98c5ba72ad9ff86afd5e3a4', 'pipeline': '77189452469cef9c840643f2babe0f825c6667c8'}, 'duration': 0.3951280117034912, 'iteration': 18, 'loss': 0.1804760061919506, 'max_history_score': 0.9888888888888889, 'max_history_score_std': 0.022222222222222233, 'max_history_step': 'joint', 'pipeline': {'features': ('features_SelectKBest', {'features__k': 2}), 'normalizer': ('normalizer_NoneType', {}), 'rebalance': ('rebalance_NearMiss', {'rebalance__n_neighbors': 1})}, 'score': 0.8195239938080494, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': None, 'max_features': 3, 'max_leaf_nodes': 5, 'min_samples_split': 3, 'n_estimators': 50}, 'config_hash': {'algorithm': '0129970b8c7fe034ac8283fb518a06cfbead63d2', 'config': '61bcd2f64860b3dfe2503be88a6bbec165db0754', 'pipeline': '359f2473075ecfd9ae3ce526da96143918517601'}, 'duration': 0.7467091083526611, 'iteration': 19, 'loss': 0.09915720674234607, 'max_history_score': 0.9888888888888889, 'max_history_score_std': 0.022222222222222233, 'max_history_step': 'joint', 'pipeline': {'features': ('features_SelectKBest', {'features__k': 3}), 'normalizer': ('normalizer_RobustScaler', {'normalizer__quantile_range': (...), 'normalizer__with_centering': True, 'normalizer__with_scaling': False}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 7})}, 'score': 0.9008427932576539, ...}, ...], 'history_hash': ['2e6648b63441361b4398cb94f81d2e04a830b2ef', '584343bc020d2d7bc89bd0856bc7770dae1c84fc', 'de121d053e65def047cc8947f505578d5c5eab67', 'b21c9d15a389baa5bfea4c8ddcec129259f37540', 'edd3456355d80775739c31515c832ca7b4e5e094', '0800d7d2c8c10d2f9e7b4e5127b343e916eb742c', 'd98b641879b4754f2169335626a90575e945fd7c', '3f83df36a6abbdf7ea4a4bdcaf6727f23529c2bb', '037fd5c655b39cc7922fb394d736496befcc747b', '6609280032189b59de1afbe36f3acb1d5c273693', '8e1c17ac9f6e03740f380fccb833c9c3931ffc35', '87c03d0cb8e8500e58cacc1a0f27ce54c41a2937', '2ab964abffa0a277a9e2ee9b5570cd258e428b62', '5c95db3ad238063227f1b36e6a006d70c834c5da', '50fd1169b8e42190600f25152654254b5d0e3ed1', 'a05b6d2ffd65d4d937c0b178655d857bf4d61410', 'ebebb7a93116f14f470e062e37582a59f4aeb0df', 'a2c21314ddbba47ddbfe416e0aa14853a71179e0', '6c8a721218e7c550a98c5ba72ad9ff86afd5e3a4', '61bcd2f64860b3dfe2503be88a6bbec165db0754', ...], 'history_index': {'037fd5c655b39cc7922fb394d736496befcc747b': 8, '07fdf9d0d0248a4b0215a633c75a2dd101dcf465': 22, '0800d7d2c8c10d2f9e7b4e5127b343e916eb742c': 5, '0babf362e2373c001d4eb84f3c4eda27e56fe02d': 33, '0e45095dfe50d5be759b179b50e63384925c7027': 32, '2323c40e4e6c5f4aa333620a6b998b510ca41854': 35, '26ed0b67cf1046a22e2baba31b70ce3b6e762a03': 40, '28944b74104bc5bb782512b0eefa3167fe189355': 30, '2a317f1667c0a37724743084ca5dcbf14ff107f0': 29, '2ab964abffa0a277a9e2ee9b5570cd258e428b62': 12, ...}, 'iteration': 42, 'max_history_score': 0.9944444444444445, 'max_history_score_std': 0.016666666666666673, 'max_history_step': 'joint'}
        config = {'algorithm': 'RandomForest', 'seed': 42, 'time': 300}
    114 
    115 
    116 def get_baseline_score(algorithm, X, y, seed):
    117     pipeline, _ = pipeline_conf_to_full_pipeline(

...........................................................................
/home/aquemy/dev/dp_hyperparameters/extension/experiment/objective.py in objective(pipeline_config={'features': ('features_SelectKBest', {'features__k': 2}), 'normalizer': ('normalizer_MinMaxScaler', {}), 'rebalance': ('rebalance_NoneType', {})}, algo_config={'bootstrap': False, 'criterion': 'gini', 'max_depth': 1, 'max_features': 3, 'max_leaf_nodes': 5, 'min_samples_split': 2, 'n_estimators': 100}, algorithm='RandomForest', X=array([[1.423e+01, 1.710e+00, 2.430e+00, ..., 1...., ..., 6.100e-01, 1.600e+00,
        5.600e+02]]), y=array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,
       2, 2]), context={'baseline_score': 0.9444100447196423, 'baseline_score_std': 0.04305547117084885, 'best_config': {'algorithm': {'bootstrap': False, 'criterion': 'gini', 'max_depth': 1, 'max_features': 1, 'max_leaf_nodes': 3, 'min_samples_split': 5, 'n_estimators': 50}, 'config_hash': {'algorithm': 'cefc05c6c759dc564d289289fe401e0f8737951d', 'config': '7a1c40755d84d62f5d2ab1ed021e7dff93dfce45', 'pipeline': '3ee6a915db2d8d71f204c103803fb8eabea0d54f'}, 'duration': 0.6908998489379883, 'iteration': 24, 'loss': 0.005555555555555536, 'max_history_score': 0.9944444444444445, 'max_history_score_std': 0.016666666666666673, 'max_history_step': 'joint', 'pipeline': {'features': ('features_NoneType', {}), 'normalizer': ('normalizer_MinMaxScaler', {}), 'rebalance': ('rebalance_NoneType', {})}, 'score': 0.9944444444444445, ...}, 'history': [{'algorithm': {'bootstrap': False, 'criterion': 'entropy', 'max_depth': None, 'max_features': 3, 'max_leaf_nodes': 5, 'min_samples_split': 2, 'n_estimators': 50}, 'config_hash': {'algorithm': 'b2c6464add7a35ce8048653a39338c9994de9a4f', 'config': '2e6648b63441361b4398cb94f81d2e04a830b2ef', 'pipeline': '3d44d7482e468d08c4f94457a205f3dac74084c1'}, 'duration': 0.737678050994873, 'iteration': 0, 'loss': 1.0, 'max_history_score': 0.0, 'max_history_score_std': 0.0, 'max_history_step': 'baseline', 'pipeline': {'features': ('features_PCA', {'features__n_components': 1}), 'normalizer': ('normalizer_NoneType', {}), 'rebalance': ('rebalance_CondensedNearestNeighbour', {'rebalance__n_neighbors': 3})}, 'score': 0.0, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'gini', 'max_depth': 1, 'max_features': None, 'max_leaf_nodes': 2, 'min_samples_split': 3, 'n_estimators': 25}, 'config_hash': {'algorithm': '7f71bbbfdb4e8da52b6fc33a43224183117de15e', 'config': '584343bc020d2d7bc89bd0856bc7770dae1c84fc', 'pipeline': '466ffa7ace0e442beb7c311eb214b17a4c6832b3'}, 'duration': 1.5976769924163818, 'iteration': 1, 'loss': 0.40386351909184726, 'max_history_score': 0.5961364809081527, 'max_history_score_std': 0.05351463210025494, 'max_history_step': 'joint', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 3, 'features__selectkbest__k': 3}), 'normalizer': ('normalizer_StandardScaler', {'normalizer__with_mean': True, 'normalizer__with_std': True}), 'rebalance': ('rebalance_NearMiss', {'rebalance__n_neighbors': 2})}, 'score': 0.5961364809081527, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'entropy', 'max_depth': 1, 'max_features': 2, 'max_leaf_nodes': 2, 'min_samples_split': 5, 'n_estimators': 25}, 'config_hash': {'algorithm': '897745a20d929d43e760cacee0a764bd8070daa5', 'config': 'de121d053e65def047cc8947f505578d5c5eab67', 'pipeline': '63040b39b48626a8232e847e8327bdca5cd88611'}, 'duration': 0.815453052520752, 'iteration': 2, 'loss': 0.07327786377708967, 'max_history_score': 0.9267221362229103, 'max_history_score_std': 0.043920207373658794, 'max_history_step': 'joint', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 3, 'features__selectkbest__k': 2}), 'normalizer': ('normalizer_StandardScaler', {'normalizer__with_mean': True, 'normalizer__with_std': True}), 'rebalance': ('rebalance_NoneType', {})}, 'score': 0.9267221362229103, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'entropy', 'max_depth': 4, 'max_features': 3, 'max_leaf_nodes': None, 'min_samples_split': 2, 'n_estimators': 100}, 'config_hash': {'algorithm': 'dbd92c75280ec06b66ca4ad9b135cf36957031a4', 'config': 'b21c9d15a389baa5bfea4c8ddcec129259f37540', 'pipeline': '38866720d2f120c863351493b9b4e23b9a4506dc'}, 'duration': 1.2293269634246826, 'iteration': 3, 'loss': 0.07199862401100798, 'max_history_score': 0.928001375988992, 'max_history_score_std': 0.06518367535896959, 'max_history_step': 'joint', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 2, 'features__selectkbest__k': 4}), 'normalizer': ('normalizer_NoneType', {}), 'rebalance': ('rebalance_NoneType', {})}, 'score': 0.928001375988992, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': 2, 'max_features': None, 'max_leaf_nodes': None, 'min_samples_split': 5, 'n_estimators': 100}, 'config_hash': {'algorithm': 'f455eefd9fdd03ece88892c3f440c580bdf27ddb', 'config': 'edd3456355d80775739c31515c832ca7b4e5e094', 'pipeline': '1d1034f9f0871e43f896c1db4ed6fd572ed0a6ef'}, 'duration': 1.6186630725860596, 'iteration': 4, 'loss': 0.16651831785345705, 'max_history_score': 0.928001375988992, 'max_history_score_std': 0.06518367535896959, 'max_history_step': 'joint', 'pipeline': {'features': ('features_SelectKBest', {'features__k': 4}), 'normalizer': ('normalizer_MinMaxScaler', {}), 'rebalance': ('rebalance_CondensedNearestNeighbour', {'rebalance__n_neighbors': 1})}, 'score': 0.833481682146543, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'entropy', 'max_depth': 1, 'max_features': 2, 'max_leaf_nodes': None, 'min_samples_split': 2, 'n_estimators': 10}, 'config_hash': {'algorithm': '29906eaa0712a68ea145b12821d54ba445726fbf', 'config': '0800d7d2c8c10d2f9e7b4e5127b343e916eb742c', 'pipeline': '2e0f188ae61600352a7159285e0f542b4587a403'}, 'duration': 0.19410085678100586, 'iteration': 5, 'loss': 0.20164258685930514, 'max_history_score': 0.928001375988992, 'max_history_score_std': 0.06518367535896959, 'max_history_step': 'joint', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 3, 'features__selectkbest__k': 4}), 'normalizer': ('normalizer_StandardScaler', {'normalizer__with_mean': True, 'normalizer__with_std': False}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 7})}, 'score': 0.7983574131406949, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': 1, 'max_features': 1, 'max_leaf_nodes': 5, 'min_samples_split': 2, 'n_estimators': 25}, 'config_hash': {'algorithm': 'fbb7d57e38cfc08240f0af985282da418cb33556', 'config': 'd98b641879b4754f2169335626a90575e945fd7c', 'pipeline': '62463de065924498cdcd2f2f1f7e68535cdb33a5'}, 'duration': 0.3625810146331787, 'iteration': 6, 'loss': 0.14327485380116955, 'max_history_score': 0.928001375988992, 'max_history_score_std': 0.06518367535896959, 'max_history_step': 'joint', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 1, 'features__selectkbest__k': 2}), 'normalizer': ('normalizer_NoneType', {}), 'rebalance': ('rebalance_NoneType', {})}, 'score': 0.8567251461988304, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'entropy', 'max_depth': 3, 'max_features': 1, 'max_leaf_nodes': None, 'min_samples_split': 2, 'n_estimators': 75}, 'config_hash': {'algorithm': 'fb2f5d4c4d636edac929e1454ce3d02a4fb134c1', 'config': '3f83df36a6abbdf7ea4a4bdcaf6727f23529c2bb', 'pipeline': '8377b93e334656d1a93d266493b58ef9a6a1786f'}, 'duration': 0.8223779201507568, 'iteration': 7, 'loss': 0.03921568627450989, 'max_history_score': 0.9607843137254901, 'max_history_score_std': 0.043526663832084804, 'max_history_step': 'joint', 'pipeline': {'features': ('features_PCA', {'features__n_components': 3}), 'normalizer': ('normalizer_MinMaxScaler', {}), 'rebalance': ('rebalance_NearMiss', {'rebalance__n_neighbors': 1})}, 'score': 0.9607843137254901, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'gini', 'max_depth': 3, 'max_features': 3, 'max_leaf_nodes': 2, 'min_samples_split': 2, 'n_estimators': 100}, 'config_hash': {'algorithm': '3c3fde6559b918694de4668d025d5418342db1b1', 'config': '037fd5c655b39cc7922fb394d736496befcc747b', 'pipeline': '2a5032814c6c7ed21dd5bd9686923d7fc2f8acc9'}, 'duration': 1.0435099601745605, 'iteration': 8, 'loss': 0.09955925352597172, 'max_history_score': 0.9607843137254901, 'max_history_score_std': 0.043526663832084804, 'max_history_step': 'joint', 'pipeline': {'features': ('features_NoneType', {}), 'normalizer': ('normalizer_RobustScaler', {'normalizer__quantile_range': (...), 'normalizer__with_centering': True, 'normalizer__with_scaling': True}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 7})}, 'score': 0.9004407464740283, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': 2, 'max_features': 1, 'max_leaf_nodes': None, 'min_samples_split': 3, 'n_estimators': 75}, 'config_hash': {'algorithm': '42185be98371e99ac896d2c6c2d69c451cb983ff', 'config': '6609280032189b59de1afbe36f3acb1d5c273693', 'pipeline': '8aab2941fc84d84f86fa56134e50909dbf9e19f5'}, 'duration': 0.9665219783782959, 'iteration': 9, 'loss': 0.01637426900584804, 'max_history_score': 0.983625730994152, 'max_history_score_std': 0.025023500462379746, 'max_history_step': 'joint', 'pipeline': {'features': ('features_NoneType', {}), 'normalizer': ('normalizer_PowerTransformer', {}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 5})}, 'score': 0.983625730994152, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': 1, 'max_features': 3, 'max_leaf_nodes': 2, 'min_samples_split': 3, 'n_estimators': 10}, 'config_hash': {'algorithm': '62a9fe705e4cd96e762bcc9543c4a456a5a9f188', 'config': '8e1c17ac9f6e03740f380fccb833c9c3931ffc35', 'pipeline': '3d44d7482e468d08c4f94457a205f3dac74084c1'}, 'duration': 0.46930503845214844, 'iteration': 10, 'loss': 1.0, 'max_history_score': 0.983625730994152, 'max_history_score_std': 0.025023500462379746, 'max_history_step': 'joint', 'pipeline': {'features': ('features_PCA', {'features__n_components': 1}), 'normalizer': ('normalizer_NoneType', {}), 'rebalance': ('rebalance_CondensedNearestNeighbour', {'rebalance__n_neighbors': 3})}, 'score': 0.0, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'gini', 'max_depth': 4, 'max_features': 1, 'max_leaf_nodes': 3, 'min_samples_split': 2, 'n_estimators': 100}, 'config_hash': {'algorithm': '086d6ca939a757bb32edb113a567f9d38744f061', 'config': '87c03d0cb8e8500e58cacc1a0f27ce54c41a2937', 'pipeline': '8f28ef0f35d97142278f9dacb4e9d1ff082e470f'}, 'duration': 2.1196961402893066, 'iteration': 11, 'loss': 0.15471276229790154, 'max_history_score': 0.983625730994152, 'max_history_score_std': 0.025023500462379746, 'max_history_step': 'joint', 'pipeline': {'features': ('features_PCA', {'features__n_components': 1}), 'normalizer': ('normalizer_StandardScaler', {'normalizer__with_mean': True, 'normalizer__with_std': True}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 7})}, 'score': 0.8452872377020985, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'entropy', 'max_depth': 3, 'max_features': 1, 'max_leaf_nodes': 2, 'min_samples_split': 2, 'n_estimators': 25}, 'config_hash': {'algorithm': '59f64a966796648c7bebade1127fa05541b391ad', 'config': '2ab964abffa0a277a9e2ee9b5570cd258e428b62', 'pipeline': 'eef3f702fd2fed761fa6744c1640d0bf320f1d00'}, 'duration': 0.9828321933746338, 'iteration': 12, 'loss': 0.0778465772273822, 'max_history_score': 0.983625730994152, 'max_history_score_std': 0.025023500462379746, 'max_history_step': 'joint', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 3, 'features__selectkbest__k': 1}), 'normalizer': ('normalizer_PowerTransformer', {}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 6})}, 'score': 0.9221534227726178, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'gini', 'max_depth': 4, 'max_features': 2, 'max_leaf_nodes': 3, 'min_samples_split': 3, 'n_estimators': 75}, 'config_hash': {'algorithm': '6f75c2a196eb9836df2b424e095051192eaed6ea', 'config': '5c95db3ad238063227f1b36e6a006d70c834c5da', 'pipeline': '1eae01a1128bee425c4d4ca0ee97a9afd409680e'}, 'duration': 0.8217771053314209, 'iteration': 13, 'loss': 0.03863089095287242, 'max_history_score': 0.983625730994152, 'max_history_score_std': 0.025023500462379746, 'max_history_step': 'joint', 'pipeline': {'features': ('features_NoneType', {}), 'normalizer': ('normalizer_StandardScaler', {'normalizer__with_mean': False, 'normalizer__with_std': False}), 'rebalance': ('rebalance_NearMiss', {'rebalance__n_neighbors': 1})}, 'score': 0.9613691090471276, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'entropy', 'max_depth': 4, 'max_features': 2, 'max_leaf_nodes': 3, 'min_samples_split': 2, 'n_estimators': 25}, 'config_hash': {'algorithm': '8aef3174f6b8020de06b825e0424c1e54d690afd', 'config': '50fd1169b8e42190600f25152654254b5d0e3ed1', 'pipeline': '9ceaa544911dc6c687e336cb8e9dd4d15ff1ceaf'}, 'duration': 0.40307188034057617, 'iteration': 14, 'loss': 1.0, 'max_history_score': 0.983625730994152, 'max_history_score_std': 0.025023500462379746, 'max_history_step': 'joint', 'pipeline': {'features': ('features_PCA', {'features__n_components': 1}), 'normalizer': ('normalizer_RobustScaler', {'normalizer__quantile_range': (...), 'normalizer__with_centering': False, 'normalizer__with_scaling': False}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 7})}, 'score': 0.0, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'gini', 'max_depth': 1, 'max_features': 1, 'max_leaf_nodes': 3, 'min_samples_split': 3, 'n_estimators': 50}, 'config_hash': {'algorithm': '37be8b6737f4b5d5ae35da51886f302b07ba6001', 'config': 'a05b6d2ffd65d4d937c0b178655d857bf4d61410', 'pipeline': 'cfef88e895db321122f2f7b813d9267b973c2468'}, 'duration': 1.7094659805297852, 'iteration': 15, 'loss': 0.011111111111111072, 'max_history_score': 0.9888888888888889, 'max_history_score_std': 0.022222222222222233, 'max_history_step': 'joint', 'pipeline': {'features': ('features_NoneType', {}), 'normalizer': ('normalizer_NoneType', {}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 5})}, 'score': 0.9888888888888889, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'entropy', 'max_depth': None, 'max_features': 3, 'max_leaf_nodes': None, 'min_samples_split': 2, 'n_estimators': 100}, 'config_hash': {'algorithm': 'c40543ce91793e367c1892c886bc49621c22ecfb', 'config': 'ebebb7a93116f14f470e062e37582a59f4aeb0df', 'pipeline': 'b50c63e800574e8b760f55f7c4ff1fcae8816dd8'}, 'duration': 0.6425540447235107, 'iteration': 16, 'loss': 1.0, 'max_history_score': 0.9888888888888889, 'max_history_score_std': 0.022222222222222233, 'max_history_step': 'joint', 'pipeline': {'features': ('features_PCA', {'features__n_components': 1}), 'normalizer': ('normalizer_PowerTransformer', {}), 'rebalance': ('rebalance_NearMiss', {'rebalance__n_neighbors': 1})}, 'score': 0.0, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'gini', 'max_depth': None, 'max_features': 1, 'max_leaf_nodes': 3, 'min_samples_split': 2, 'n_estimators': 50}, 'config_hash': {'algorithm': '0c69b9601237c20664085fa05764d855e28f98f7', 'config': 'a2c21314ddbba47ddbfe416e0aa14853a71179e0', 'pipeline': '914f81fa4fbb61db251201f32bd8ea11bfeea2a5'}, 'duration': 2.2209739685058594, 'iteration': 17, 'loss': 0.3206720846233231, 'max_history_score': 0.9888888888888889, 'max_history_score_std': 0.022222222222222233, 'max_history_step': 'joint', 'pipeline': {'features': ('features_SelectKBest', {'features__k': 4}), 'normalizer': ('normalizer_PowerTransformer', {}), 'rebalance': ('rebalance_CondensedNearestNeighbour', {'rebalance__n_neighbors': 1})}, 'score': 0.6793279153766769, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': 4, 'max_features': None, 'max_leaf_nodes': None, 'min_samples_split': 3, 'n_estimators': 25}, 'config_hash': {'algorithm': '1aae0f1fce5cab293ffdd4581c4838c8051ac815', 'config': '6c8a721218e7c550a98c5ba72ad9ff86afd5e3a4', 'pipeline': '77189452469cef9c840643f2babe0f825c6667c8'}, 'duration': 0.3951280117034912, 'iteration': 18, 'loss': 0.1804760061919506, 'max_history_score': 0.9888888888888889, 'max_history_score_std': 0.022222222222222233, 'max_history_step': 'joint', 'pipeline': {'features': ('features_SelectKBest', {'features__k': 2}), 'normalizer': ('normalizer_NoneType', {}), 'rebalance': ('rebalance_NearMiss', {'rebalance__n_neighbors': 1})}, 'score': 0.8195239938080494, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': None, 'max_features': 3, 'max_leaf_nodes': 5, 'min_samples_split': 3, 'n_estimators': 50}, 'config_hash': {'algorithm': '0129970b8c7fe034ac8283fb518a06cfbead63d2', 'config': '61bcd2f64860b3dfe2503be88a6bbec165db0754', 'pipeline': '359f2473075ecfd9ae3ce526da96143918517601'}, 'duration': 0.7467091083526611, 'iteration': 19, 'loss': 0.09915720674234607, 'max_history_score': 0.9888888888888889, 'max_history_score_std': 0.022222222222222233, 'max_history_step': 'joint', 'pipeline': {'features': ('features_SelectKBest', {'features__k': 3}), 'normalizer': ('normalizer_RobustScaler', {'normalizer__quantile_range': (...), 'normalizer__with_centering': True, 'normalizer__with_scaling': False}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 7})}, 'score': 0.9008427932576539, ...}, ...], 'history_hash': ['2e6648b63441361b4398cb94f81d2e04a830b2ef', '584343bc020d2d7bc89bd0856bc7770dae1c84fc', 'de121d053e65def047cc8947f505578d5c5eab67', 'b21c9d15a389baa5bfea4c8ddcec129259f37540', 'edd3456355d80775739c31515c832ca7b4e5e094', '0800d7d2c8c10d2f9e7b4e5127b343e916eb742c', 'd98b641879b4754f2169335626a90575e945fd7c', '3f83df36a6abbdf7ea4a4bdcaf6727f23529c2bb', '037fd5c655b39cc7922fb394d736496befcc747b', '6609280032189b59de1afbe36f3acb1d5c273693', '8e1c17ac9f6e03740f380fccb833c9c3931ffc35', '87c03d0cb8e8500e58cacc1a0f27ce54c41a2937', '2ab964abffa0a277a9e2ee9b5570cd258e428b62', '5c95db3ad238063227f1b36e6a006d70c834c5da', '50fd1169b8e42190600f25152654254b5d0e3ed1', 'a05b6d2ffd65d4d937c0b178655d857bf4d61410', 'ebebb7a93116f14f470e062e37582a59f4aeb0df', 'a2c21314ddbba47ddbfe416e0aa14853a71179e0', '6c8a721218e7c550a98c5ba72ad9ff86afd5e3a4', '61bcd2f64860b3dfe2503be88a6bbec165db0754', ...], 'history_index': {'037fd5c655b39cc7922fb394d736496befcc747b': 8, '07fdf9d0d0248a4b0215a633c75a2dd101dcf465': 22, '0800d7d2c8c10d2f9e7b4e5127b343e916eb742c': 5, '0babf362e2373c001d4eb84f3c4eda27e56fe02d': 33, '0e45095dfe50d5be759b179b50e63384925c7027': 32, '2323c40e4e6c5f4aa333620a6b998b510ca41854': 35, '26ed0b67cf1046a22e2baba31b70ce3b6e762a03': 40, '28944b74104bc5bb782512b0eefa3167fe189355': 30, '2a317f1667c0a37724743084ca5dcbf14ff107f0': 29, '2ab964abffa0a277a9e2ee9b5570cd258e428b62': 12, ...}, 'iteration': 42, 'max_history_score': 0.9944444444444445, 'max_history_score_std': 0.016666666666666673, 'max_history_step': 'joint'}, config={'algorithm': 'RandomForest', 'seed': 42, 'time': 300}, step='joint')
     45                 y,
     46                 cv=10,
     47                 n_jobs=-1,
     48                 return_estimator=False,
     49                 return_train_score=False,
---> 50                 verbose=0)
     51         score = np.mean(scores['test_score'])
     52         std = np.std(scores['test_score'])
     53         status = STATUS_OK
     54     except Exception as e:

...........................................................................
/home/aquemy/.local/lib/python2.7/site-packages/sklearn/model_selection/_validation.py in cross_validate(estimator=Pipeline(memory=None,
     steps=[('normalizer',... random_state=42, verbose=0, warm_start=False))]), X=array([[1.423e+01, 1.710e+00, 2.430e+00, ..., 1...., ..., 6.100e-01, 1.600e+00,
        5.600e+02]]), y=array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,
       2, 2]), groups=None, scoring=None, cv=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1, verbose=0, fit_params=None, pre_dispatch='2*n_jobs', return_train_score=False, return_estimator=False, error_score='raise-deprecating')
    235         delayed(_fit_and_score)(
    236             clone(estimator), X, y, scorers, train, test, verbose, None,
    237             fit_params, return_train_score=return_train_score,
    238             return_times=True, return_estimator=return_estimator,
    239             error_score=error_score)
--> 240         for train, test in cv.split(X, y, groups))
        cv.split = <bound method StratifiedKFold.split of Stratifie...d(n_splits=10, random_state=None, shuffle=False)>
        X = array([[1.423e+01, 1.710e+00, 2.430e+00, ..., 1...., ..., 6.100e-01, 1.600e+00,
        5.600e+02]])
        y = array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,
       2, 2])
        groups = None
    241 
    242     zipped_scores = list(zip(*scores))
    243     if return_train_score:
    244         train_scores = zipped_scores.pop(0)

...........................................................................
/home/aquemy/.local/lib/python2.7/site-packages/sklearn/externals/joblib/parallel.py in __call__(self=Parallel(n_jobs=-1), iterable=<generator object <genexpr>>)
    925                 # No need to wait for async callbacks to trigger to
    926                 # consumption.
    927                 self._iterating = False
    928 
    929             with self._backend.retrieval_context():
--> 930                 self.retrieve()
        self.retrieve = <bound method Parallel.retrieve of Parallel(n_jobs=-1)>
    931             # Make sure that we get a last message telling us we are done
    932             elapsed_time = time.time() - self._start_time
    933             self._print('Done %3i out of %3i | elapsed: %s finished',
    934                         (len(self._output), len(self._output),

---------------------------------------------------------------------------
Joblib worker traceback:
---------------------------------------------------------------------------
ValueError                                         Mon Jun 17 12:45:54 2019
PID: 15299                                  Python 2.7.15+: /usr/bin/python
...........................................................................
/home/aquemy/.local/lib/python2.7/site-packages/sklearn/externals/joblib/parallel.py in __call__(self=<sklearn.externals.joblib.parallel.BatchedCalls object>)
    220     def __call__(self):
    221         # Set the default nested backend to self._backend but do not set the
    222         # change the default number of processes to -1
    223         with parallel_backend(self._backend, n_jobs=self._n_jobs):
    224             return [func(*args, **kwargs)
--> 225                     for func, args, kwargs in self.items]
        func = <function _fit_and_score>
        args = (Pipeline(memory=None,
     steps=[('normalizer',... random_state=42, verbose=0, warm_start=False))]), array([[1.423e+01, 1.710e+00, 2.430e+00, ..., 1...., ..., 6.100e-01, 1.600e+00,
        5.600e+02]]), array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,
       2, 2]), {'score': <function _passthrough_scorer>}, array([  6,   7,   8,   9,  10,  11,  12,  13,  ..., 170, 171, 172, 173, 174,
       175, 176, 177]), array([  0,   1,   2,   3,   4,   5,  59,  60,  ...,  64,  65,
        66, 130, 131, 132, 133, 134]), 0, None, None)
        kwargs = {'error_score': 'raise-deprecating', 'return_estimator': False, 'return_times': True, 'return_train_score': False}
        self.items = [(<function _fit_and_score>, (Pipeline(memory=None,
     steps=[('normalizer',... random_state=42, verbose=0, warm_start=False))]), array([[1.423e+01, 1.710e+00, 2.430e+00, ..., 1...., ..., 6.100e-01, 1.600e+00,
        5.600e+02]]), array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,
       2, 2]), {'score': <function _passthrough_scorer>}, array([  6,   7,   8,   9,  10,  11,  12,  13,  ..., 170, 171, 172, 173, 174,
       175, 176, 177]), array([  0,   1,   2,   3,   4,   5,  59,  60,  ...,  64,  65,
        66, 130, 131, 132, 133, 134]), 0, None, None), {'error_score': 'raise-deprecating', 'return_estimator': False, 'return_times': True, 'return_train_score': False})]
    226 
    227     def __len__(self):
    228         return self._size
    229 

...........................................................................
/home/aquemy/.local/lib/python2.7/site-packages/sklearn/model_selection/_validation.py in _fit_and_score(estimator=Pipeline(memory=None,
     steps=[('normalizer',... random_state=42, verbose=0, warm_start=False))]), X=array([[1.423e+01, 1.710e+00, 2.430e+00, ..., 1...., ..., 6.100e-01, 1.600e+00,
        5.600e+02]]), y=array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,
       2, 2]), scorer={'score': <function _passthrough_scorer>}, train=array([  6,   7,   8,   9,  10,  11,  12,  13,  ..., 170, 171, 172, 173, 174,
       175, 176, 177]), test=array([  0,   1,   2,   3,   4,   5,  59,  60,  ...,  64,  65,
        66, 130, 131, 132, 133, 134]), verbose=0, parameters=None, fit_params={}, return_train_score=False, return_parameters=False, return_n_test_samples=False, return_times=True, return_estimator=False, error_score='raise-deprecating')
    523 
    524     try:
    525         if y_train is None:
    526             estimator.fit(X_train, **fit_params)
    527         else:
--> 528             estimator.fit(X_train, y_train, **fit_params)
        estimator.fit = <bound method Pipeline.fit of Pipeline(memory=No...random_state=42, verbose=0, warm_start=False))])>
        X_train = array([[1.439e+01, 1.870e+00, 2.450e+00, ..., 1...., ..., 6.100e-01, 1.600e+00,
        5.600e+02]])
        y_train = array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...2, 2, 2, 2, 2, 2, 2, 2, 2,
       2, 2, 2, 2, 2])
        fit_params = {}
    529 
    530     except Exception as e:
    531         # Note fit time as time until error
    532         fit_time = time.time() - start_time

...........................................................................
/usr/local/lib/python2.7/dist-packages/imblearn/pipeline.py in fit(self=Pipeline(memory=None,
     steps=[('normalizer',... random_state=42, verbose=0, warm_start=False))]), X=array([[1.439e+01, 1.870e+00, 2.450e+00, ..., 1...., ..., 6.100e-01, 1.600e+00,
        5.600e+02]]), y=array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...2, 2, 2, 2, 2, 2, 2, 2, 2,
       2, 2, 2, 2, 2]), **fit_params={})
    234             This estimator
    235 
    236         """
    237         Xt, yt, fit_params = self._fit(X, y, **fit_params)
    238         if self._final_estimator is not None:
--> 239             self._final_estimator.fit(Xt, yt, **fit_params)
        self._final_estimator.fit = <bound method RandomForestClassifier.fit of Rand...e, random_state=42, verbose=0, warm_start=False)>
        Xt = array([[0.45991561, 0.84615385],
       [0.45780...6, 0.12820513],
       [0.08860759, 0.12087912]])
        yt = array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...2, 2, 2, 2, 2, 2, 2, 2, 2,
       2, 2, 2, 2, 2])
        fit_params = {}
    240         return self
    241 
    242     def fit_transform(self, X, y=None, **fit_params):
    243         """Fit the model and transform with the final estimator

...........................................................................
/home/aquemy/.local/lib/python2.7/site-packages/sklearn/ensemble/forest.py in fit(self=RandomForestClassifier(bootstrap=False, class_we...se, random_state=42, verbose=0, warm_start=False), X=array([[0.4599156 , 0.84615386],
       [0.45780...
       [0.08860759, 0.12087912]], dtype=float32), y=array([[0.],
       [0.],
       [0.],
       [0...    [2.],
       [2.],
       [2.],
       [2.]]), sample_weight=None)
    328             trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,
    329                              **_joblib_parallel_args(prefer='threads'))(
    330                 delayed(_parallel_build_trees)(
    331                     t, self, X, y, sample_weight, i, len(trees),
    332                     verbose=self.verbose, class_weight=self.class_weight)
--> 333                 for i, t in enumerate(trees))
        i = 99
    334 
    335             # Collect newly grown trees
    336             self.estimators_.extend(trees)
    337 

...........................................................................
/home/aquemy/.local/lib/python2.7/site-packages/sklearn/externals/joblib/parallel.py in __call__(self=Parallel(n_jobs=1), iterable=<generator object <genexpr>>)
    912             # self._original_iterator is None, then this means either
    913             # that pre_dispatch == "all", n_jobs == 1 or that the first batch
    914             # was very quick and its callback already dispatched all the
    915             # remaining jobs.
    916             self._iterating = False
--> 917             if self.dispatch_one_batch(iterator):
        self.dispatch_one_batch = <bound method Parallel.dispatch_one_batch of Parallel(n_jobs=1)>
        iterator = <generator object <genexpr>>
    918                 self._iterating = self._original_iterator is not None
    919 
    920             while self.dispatch_one_batch(iterator):
    921                 pass

...........................................................................
/home/aquemy/.local/lib/python2.7/site-packages/sklearn/externals/joblib/parallel.py in dispatch_one_batch(self=Parallel(n_jobs=1), iterator=<generator object <genexpr>>)
    754                                  self._pickle_cache)
    755             if len(tasks) == 0:
    756                 # No more tasks available in the iterator: tell caller to stop.
    757                 return False
    758             else:
--> 759                 self._dispatch(tasks)
        self._dispatch = <bound method Parallel._dispatch of Parallel(n_jobs=1)>
        tasks = <sklearn.externals.joblib.parallel.BatchedCalls object>
    760                 return True
    761 
    762     def _print(self, msg, msg_args):
    763         """Display the message on stout or stderr depending on verbosity"""

...........................................................................
/home/aquemy/.local/lib/python2.7/site-packages/sklearn/externals/joblib/parallel.py in _dispatch(self=Parallel(n_jobs=1), batch=<sklearn.externals.joblib.parallel.BatchedCalls object>)
    711 
    712         dispatch_timestamp = time.time()
    713         cb = BatchCompletionCallBack(dispatch_timestamp, len(batch), self)
    714         with self._lock:
    715             job_idx = len(self._jobs)
--> 716             job = self._backend.apply_async(batch, callback=cb)
        job = undefined
        self._backend.apply_async = <bound method SequentialBackend.apply_async of <...lib._parallel_backends.SequentialBackend object>>
        batch = <sklearn.externals.joblib.parallel.BatchedCalls object>
        cb = <sklearn.externals.joblib.parallel.BatchCompletionCallBack object>
    717             # A job can complete so quickly than its callback is
    718             # called before we get here, causing self._jobs to
    719             # grow. To ensure correct results ordering, .insert is
    720             # used (rather than .append) in the following line

...........................................................................
/home/aquemy/.local/lib/python2.7/site-packages/sklearn/externals/joblib/_parallel_backends.py in apply_async(self=<sklearn.externals.joblib._parallel_backends.SequentialBackend object>, func=<sklearn.externals.joblib.parallel.BatchedCalls object>, callback=<sklearn.externals.joblib.parallel.BatchCompletionCallBack object>)
    177             raise ValueError('n_jobs == 0 in Parallel has no meaning')
    178         return 1
    179 
    180     def apply_async(self, func, callback=None):
    181         """Schedule a func to be run"""
--> 182         result = ImmediateResult(func)
        result = undefined
        func = <sklearn.externals.joblib.parallel.BatchedCalls object>
    183         if callback:
    184             callback(result)
    185         return result
    186 

...........................................................................
/home/aquemy/.local/lib/python2.7/site-packages/sklearn/externals/joblib/_parallel_backends.py in __init__(self=<sklearn.externals.joblib._parallel_backends.ImmediateResult object>, batch=<sklearn.externals.joblib.parallel.BatchedCalls object>)
    544 
    545 class ImmediateResult(object):
    546     def __init__(self, batch):
    547         # Don't delay the application, to avoid keeping the input
    548         # arguments in memory
--> 549         self.results = batch()
        self.results = undefined
        batch = <sklearn.externals.joblib.parallel.BatchedCalls object>
    550 
    551     def get(self):
    552         return self.results
    553 

...........................................................................
/home/aquemy/.local/lib/python2.7/site-packages/sklearn/externals/joblib/parallel.py in __call__(self=<sklearn.externals.joblib.parallel.BatchedCalls object>)
    220     def __call__(self):
    221         # Set the default nested backend to self._backend but do not set the
    222         # change the default number of processes to -1
    223         with parallel_backend(self._backend, n_jobs=self._n_jobs):
    224             return [func(*args, **kwargs)
--> 225                     for func, args, kwargs in self.items]
        func = <function _parallel_build_trees>
        args = (DecisionTreeClassifier(class_weight=None, criter...=False, random_state=1608637542, splitter='best'), RandomForestClassifier(bootstrap=False, class_we...se, random_state=42, verbose=0, warm_start=False), array([[0.4599156 , 0.84615386],
       [0.45780...
       [0.08860759, 0.12087912]], dtype=float32), array([[0.],
       [0.],
       [0.],
       [0...    [2.],
       [2.],
       [2.],
       [2.]]), None, 0, 100)
        kwargs = {'class_weight': None, 'verbose': 0}
        self.items = [(<function _parallel_build_trees>, (DecisionTreeClassifier(class_weight=None, criter...=False, random_state=1608637542, splitter='best'), RandomForestClassifier(bootstrap=False, class_we...se, random_state=42, verbose=0, warm_start=False), array([[0.4599156 , 0.84615386],
       [0.45780...
       [0.08860759, 0.12087912]], dtype=float32), array([[0.],
       [0.],
       [0.],
       [0...    [2.],
       [2.],
       [2.],
       [2.]]), None, 0, 100), {'class_weight': None, 'verbose': 0})]
    226 
    227     def __len__(self):
    228         return self._size
    229 

...........................................................................
/home/aquemy/.local/lib/python2.7/site-packages/sklearn/ensemble/forest.py in _parallel_build_trees(tree=DecisionTreeClassifier(class_weight=None, criter...=False, random_state=1608637542, splitter='best'), forest=RandomForestClassifier(bootstrap=False, class_we...se, random_state=42, verbose=0, warm_start=False), X=array([[0.4599156 , 0.84615386],
       [0.45780...
       [0.08860759, 0.12087912]], dtype=float32), y=array([[0.],
       [0.],
       [0.],
       [0...    [2.],
       [2.],
       [2.],
       [2.]]), sample_weight=None, tree_idx=0, n_trees=100, verbose=0, class_weight=None)
    116         elif class_weight == 'balanced_subsample':
    117             curr_sample_weight *= compute_sample_weight('balanced', y, indices)
    118 
    119         tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)
    120     else:
--> 121         tree.fit(X, y, sample_weight=sample_weight, check_input=False)
        tree.fit = <bound method DecisionTreeClassifier.fit of Deci...False, random_state=1608637542, splitter='best')>
        X = array([[0.4599156 , 0.84615386],
       [0.45780...
       [0.08860759, 0.12087912]], dtype=float32)
        y = array([[0.],
       [0.],
       [0.],
       [0...    [2.],
       [2.],
       [2.],
       [2.]])
        sample_weight = None
    122 
    123     return tree
    124 
    125 

...........................................................................
/home/aquemy/.local/lib/python2.7/site-packages/sklearn/tree/tree.py in fit(self=DecisionTreeClassifier(class_weight=None, criter...=False, random_state=1608637542, splitter='best'), X=array([[0.4599156 , 0.84615386],
       [0.45780...
       [0.08860759, 0.12087912]], dtype=float32), y=array([[0.],
       [0.],
       [0.],
       [0...    [2.],
       [2.],
       [2.],
       [2.]]), sample_weight=None, check_input=False, X_idx_sorted=None)
    796 
    797         super(DecisionTreeClassifier, self).fit(
    798             X, y,
    799             sample_weight=sample_weight,
    800             check_input=check_input,
--> 801             X_idx_sorted=X_idx_sorted)
        X_idx_sorted = None
    802         return self
    803 
    804     def predict_proba(self, X, check_input=True):
    805         """Predict class probabilities of the input samples X.

...........................................................................
/home/aquemy/.local/lib/python2.7/site-packages/sklearn/tree/tree.py in fit(self=DecisionTreeClassifier(class_weight=None, criter...=False, random_state=1608637542, splitter='best'), X=array([[0.4599156 , 0.84615386],
       [0.45780...
       [0.08860759, 0.12087912]], dtype=float32), y=array([[0.],
       [0.],
       [0.],
       [0...    [2.],
       [2.],
       [2.],
       [2.]]), sample_weight=None, check_input=False, X_idx_sorted=None)
    237         if not 0 <= self.min_weight_fraction_leaf <= 0.5:
    238             raise ValueError("min_weight_fraction_leaf must in [0, 0.5]")
    239         if max_depth <= 0:
    240             raise ValueError("max_depth must be greater than zero. ")
    241         if not (0 < max_features <= self.n_features_):
--> 242             raise ValueError("max_features must be in (0, n_features]")
    243         if not isinstance(max_leaf_nodes, (numbers.Integral, np.integer)):
    244             raise ValueError("max_leaf_nodes must be integral number but was "
    245                              "%r" % max_leaf_nodes)
    246         if -1 < max_leaf_nodes < 2:

ValueError: max_features must be in (0, n_features]
___________________________________________________________________________
Best score: 0.994444444444 (0.0166666666667) [J] | Score: 0.0 (0.0) [J]
Best score: 0.994444444444 (0.0166666666667) [J] | Score: 0.667223512212 (0.092153980432) [J]
Best score: 0.994444444444 (0.0166666666667) [J] | Score: 0.736199260406 (0.121237317141) [J]
Best score: 0.994444444444 (0.0166666666667) [J] | Score: 0.818094255246 (0.147217744855) [J]
Best score: 0.994444444444 (0.0166666666667) [J] | Score: 0.927306931545 (0.060109319289) [J]
Best score: 0.994444444444 (0.0166666666667) [J] | Score: 0.900842793258 (0.0716323059902) [J]
JoblibValueError
___________________________________________________________________________
...........................................................................
/home/aquemy/dev/dp_hyperparameters/extension/main.py in <module>()
     27 
     28     serializer.serialize_results(scenario, policy)
     29 
     30 if __name__ == "__main__":
     31     args = cli.parse_args()
---> 32     main(args)

...........................................................................
/home/aquemy/dev/dp_hyperparameters/extension/main.py in main(args=Namespace(customize=[(['control', 'seed'], '42')...io='./scenarios/rf_wine_joint.yaml', verbosity=0))
     21         test_size=0.4, 
     22         random_state=scenario['control']['seed']
     23     )
     24 
     25     policy = policies.initiate(scenario['setup']['policy'], config)
---> 26     policy.run(X,y)
        policy.run = <bound method Joint.run of <experiment.policies.joint.Joint object>>
        X = array([[1.423e+01, 1.710e+00, 2.430e+00, ..., 1...., ..., 6.100e-01, 1.600e+00,
        5.600e+02]])
        y = array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,
       2, 2])
     27 
     28     serializer.serialize_results(scenario, policy)
     29 
     30 if __name__ == "__main__":

...........................................................................
/home/aquemy/dev/dp_hyperparameters/extension/experiment/policies/joint.py in run(self=<experiment.policies.joint.Joint object>, X=array([[1.423e+01, 1.710e+00, 2.430e+00, ..., 1...., ..., 6.100e-01, 1.600e+00,
        5.600e+02]]), y=array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,
       2, 2]))
     32             algo=tpe.suggest, 
     33             max_evals=None,
     34             max_time=self.config['time'],     
     35             trials=trials,
     36             show_progressbar=False,
---> 37             verbose=0
     38         )
     39 
     40         best_config = self.context['best_config']
     41         super(Joint, self).display_step_results(best_config)

...........................................................................
/home/aquemy/dev/dp_hyperparameters/extension/hyperopt/fmin.py in fmin(fn=<functools.partial object>, space={'algorithm': {'bootstrap': <hyperopt.pyll.base.Apply object>, 'criterion': <hyperopt.pyll.base.Apply object>, 'max_depth': <hyperopt.pyll.base.Apply object>, 'max_features': <hyperopt.pyll.base.Apply object>, 'max_leaf_nodes': <hyperopt.pyll.base.Apply object>, 'min_samples_split': <hyperopt.pyll.base.Apply object>, 'n_estimators': <hyperopt.pyll.base.Apply object>}, 'pipeline': {'features': <hyperopt.pyll.base.Apply object>, 'normalizer': <hyperopt.pyll.base.Apply object>, 'rebalance': <hyperopt.pyll.base.Apply object>}}, algo=<function suggest>, max_evals=9223372036854775807, max_time=300, trials=<hyperopt.base.Trials object>, rstate=<mtrand.RandomState object>, allow_trials_fmin=True, pass_expr_memo_ctrl=None, catch_eval_exceptions=False, verbose=0, return_argmin=True, points_to_evaluate=None, max_queue_len=1, show_progressbar=False)
    406             pass_expr_memo_ctrl=pass_expr_memo_ctrl,
    407             verbose=verbose,
    408             catch_eval_exceptions=catch_eval_exceptions,
    409             return_argmin=return_argmin,
    410             show_progressbar=show_progressbar,
--> 411             max_time=max_time
        max_time = 300
    412         )
    413 
    414     if trials is None:
    415         if points_to_evaluate is None:

...........................................................................
/home/aquemy/dev/dp_hyperparameters/extension/hyperopt/base.py in fmin(self=<hyperopt.base.Trials object>, fn=<functools.partial object>, space={'algorithm': {'bootstrap': <hyperopt.pyll.base.Apply object>, 'criterion': <hyperopt.pyll.base.Apply object>, 'max_depth': <hyperopt.pyll.base.Apply object>, 'max_features': <hyperopt.pyll.base.Apply object>, 'max_leaf_nodes': <hyperopt.pyll.base.Apply object>, 'min_samples_split': <hyperopt.pyll.base.Apply object>, 'n_estimators': <hyperopt.pyll.base.Apply object>}, 'pipeline': {'features': <hyperopt.pyll.base.Apply object>, 'normalizer': <hyperopt.pyll.base.Apply object>, 'rebalance': <hyperopt.pyll.base.Apply object>}}, algo=<function suggest>, max_evals=9223372036854775807, max_time=300, rstate=<mtrand.RandomState object>, verbose=0, pass_expr_memo_ctrl=None, catch_eval_exceptions=False, return_argmin=True, show_progressbar=False)
    636             verbose=verbose,
    637             allow_trials_fmin=False,  # -- prevent recursion
    638             pass_expr_memo_ctrl=pass_expr_memo_ctrl,
    639             catch_eval_exceptions=catch_eval_exceptions,
    640             return_argmin=return_argmin,
--> 641             show_progressbar=show_progressbar)
        show_progressbar = False
    642 
    643 
    644 def trials_from_docs(docs, validate=True, **kwargs):
    645     """Construct a Trials base class instance from a list of trials documents

...........................................................................
/home/aquemy/dev/dp_hyperparameters/extension/hyperopt/fmin.py in fmin(fn=<functools.partial object>, space={'algorithm': {'bootstrap': <hyperopt.pyll.base.Apply object>, 'criterion': <hyperopt.pyll.base.Apply object>, 'max_depth': <hyperopt.pyll.base.Apply object>, 'max_features': <hyperopt.pyll.base.Apply object>, 'max_leaf_nodes': <hyperopt.pyll.base.Apply object>, 'min_samples_split': <hyperopt.pyll.base.Apply object>, 'n_estimators': <hyperopt.pyll.base.Apply object>}, 'pipeline': {'features': <hyperopt.pyll.base.Apply object>, 'normalizer': <hyperopt.pyll.base.Apply object>, 'rebalance': <hyperopt.pyll.base.Apply object>}}, algo=<function suggest>, max_evals=9223372036854775807, max_time=300, trials=<hyperopt.base.Trials object>, rstate=<mtrand.RandomState object>, allow_trials_fmin=False, pass_expr_memo_ctrl=None, catch_eval_exceptions=False, verbose=0, return_argmin=True, points_to_evaluate=None, max_queue_len=1, show_progressbar=False)
    426                     verbose=verbose,
    427                     max_queue_len=max_queue_len,
    428                     show_progressbar=show_progressbar,
    429                     max_time=max_time)
    430     rval.catch_eval_exceptions = catch_eval_exceptions
--> 431     rval.exhaust()
        rval.exhaust = <bound method FMinIter.exhaust of <hyperopt.fmin.FMinIter object>>
    432     if return_argmin:
    433         return trials.argmin
    434     elif len(trials) > 0:
    435         # Only if there are some succesfull trail runs, return the best point in the evaluation space

...........................................................................
/home/aquemy/dev/dp_hyperparameters/extension/hyperopt/fmin.py in exhaust(self=<hyperopt.fmin.FMinIter object>)
    273             raise StopIteration()
    274         return self.trials
    275 
    276     def exhaust(self):
    277         n_done = len(self.trials)
--> 278         self.run(self.max_evals - n_done, block_until_done=self.asynchronous)
        self.run = <bound method FMinIter.run of <hyperopt.fmin.FMinIter object>>
        self.max_evals = 9223372036854775807
        n_done = 0
        self.asynchronous = False
    279         self.trials.refresh()
    280         return self
    281 
    282 

...........................................................................
/home/aquemy/dev/dp_hyperparameters/extension/hyperopt/fmin.py in run(self=<hyperopt.fmin.FMinIter object>, N=9223372036854775807, block_until_done=False)
    232                     if self.asynchronous:
    233                         # -- wait for workers to fill in the trials
    234                         time.sleep(self.poll_interval_secs)
    235                     else:
    236                         # -- loop over trials and do the jobs directly
--> 237                         self.serial_evaluate()
        self.serial_evaluate = <bound method FMinIter.serial_evaluate of <hyperopt.fmin.FMinIter object>>
    238                     try:
    239                         res = [d['result']['loss'] for d in
    240                                          self.trials.trials if
    241                                          d['result']['status'] == 'ok']

...........................................................................
/home/aquemy/dev/dp_hyperparameters/extension/hyperopt/fmin.py in serial_evaluate(self=<hyperopt.fmin.FMinIter object>, N=-1)
    138                 trial['book_time'] = now
    139                 trial['refresh_time'] = now
    140                 spec = base.spec_from_misc(trial['misc'])
    141                 ctrl = base.Ctrl(self.trials, current_trial=trial)
    142                 try:
--> 143                     result = self.domain.evaluate(spec, ctrl)
        result = undefined
        self.domain.evaluate = <bound method Domain.evaluate of <hyperopt.base.Domain object>>
        spec = {'bootstrap': 1, 'criterion': 0, 'features': 1, 'features_PCA_features__n_components': 1, 'max_depth': 0, 'max_features': 2, 'max_leaf_nodes': 0, 'min_samples_split': 2, 'n_estimators': 4, 'normalizer': 3, ...}
        ctrl = <hyperopt.base.Ctrl object>
    144                 except Exception as e:
    145                     logger.info('job exception: %s' % str(e))
    146                     trial['state'] = base.JOB_STATE_ERROR
    147                     trial['misc']['error'] = (str(type(e)), str(e))

...........................................................................
/home/aquemy/dev/dp_hyperparameters/extension/hyperopt/base.py in evaluate(self=<hyperopt.base.Domain object>, config={'bootstrap': 1, 'criterion': 0, 'features': 1, 'features_PCA_features__n_components': 1, 'max_depth': 0, 'max_features': 2, 'max_leaf_nodes': 0, 'min_samples_split': 2, 'n_estimators': 4, 'normalizer': 3, ...}, ctrl=<hyperopt.base.Ctrl object>, attach_attachments=True)
    841             #    or the normal Python part (self.fn)
    842             pyll_rval = pyll.rec_eval(
    843                 self.expr,
    844                 memo=memo,
    845                 print_node_on_error=self.rec_eval_print_node_on_error)
--> 846             rval = self.fn(pyll_rval)
        rval = undefined
        self.fn = <functools.partial object>
        pyll_rval = {'algorithm': {'bootstrap': False, 'criterion': 'gini', 'max_depth': 1, 'max_features': 3, 'max_leaf_nodes': 2, 'min_samples_split': 5, 'n_estimators': 100}, 'pipeline': {'features': ('features_PCA', {'features__n_components': 2}), 'normalizer': ('normalizer_MinMaxScaler', {}), 'rebalance': ('rebalance_NearMiss', {'rebalance__n_neighbors': 3})}}
    847 
    848         if isinstance(rval, (float, int, np.number)):
    849             dict_rval = {'loss': float(rval), 'status': STATUS_OK}
    850         else:

...........................................................................
/home/aquemy/dev/dp_hyperparameters/extension/experiment/objective.py in objective_joint(wconfig={'algorithm': {'bootstrap': False, 'criterion': 'gini', 'max_depth': 1, 'max_features': 3, 'max_leaf_nodes': 2, 'min_samples_split': 5, 'n_estimators': 100}, 'pipeline': {'features': ('features_PCA', {'features__n_components': 2}), 'normalizer': ('normalizer_MinMaxScaler', {}), 'rebalance': ('rebalance_NearMiss', {'rebalance__n_neighbors': 3})}}, algorithm='RandomForest', X=array([[1.423e+01, 1.710e+00, 2.430e+00, ..., 1...., ..., 6.100e-01, 1.600e+00,
        5.600e+02]]), y=array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,
       2, 2]), context={'baseline_score': 0.9444100447196423, 'baseline_score_std': 0.04305547117084885, 'best_config': {'algorithm': {'bootstrap': False, 'criterion': 'gini', 'max_depth': 1, 'max_features': 1, 'max_leaf_nodes': 3, 'min_samples_split': 5, 'n_estimators': 50}, 'config_hash': {'algorithm': 'cefc05c6c759dc564d289289fe401e0f8737951d', 'config': '7a1c40755d84d62f5d2ab1ed021e7dff93dfce45', 'pipeline': '3ee6a915db2d8d71f204c103803fb8eabea0d54f'}, 'duration': 0.6908998489379883, 'iteration': 24, 'loss': 0.005555555555555536, 'max_history_score': 0.9944444444444445, 'max_history_score_std': 0.016666666666666673, 'max_history_step': 'joint', 'pipeline': {'features': ('features_NoneType', {}), 'normalizer': ('normalizer_MinMaxScaler', {}), 'rebalance': ('rebalance_NoneType', {})}, 'score': 0.9944444444444445, ...}, 'history': [{'algorithm': {'bootstrap': False, 'criterion': 'entropy', 'max_depth': None, 'max_features': 3, 'max_leaf_nodes': 5, 'min_samples_split': 2, 'n_estimators': 50}, 'config_hash': {'algorithm': 'b2c6464add7a35ce8048653a39338c9994de9a4f', 'config': '2e6648b63441361b4398cb94f81d2e04a830b2ef', 'pipeline': '3d44d7482e468d08c4f94457a205f3dac74084c1'}, 'duration': 0.737678050994873, 'iteration': 0, 'loss': 1.0, 'max_history_score': 0.0, 'max_history_score_std': 0.0, 'max_history_step': 'baseline', 'pipeline': {'features': ('features_PCA', {'features__n_components': 1}), 'normalizer': ('normalizer_NoneType', {}), 'rebalance': ('rebalance_CondensedNearestNeighbour', {'rebalance__n_neighbors': 3})}, 'score': 0.0, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'gini', 'max_depth': 1, 'max_features': None, 'max_leaf_nodes': 2, 'min_samples_split': 3, 'n_estimators': 25}, 'config_hash': {'algorithm': '7f71bbbfdb4e8da52b6fc33a43224183117de15e', 'config': '584343bc020d2d7bc89bd0856bc7770dae1c84fc', 'pipeline': '466ffa7ace0e442beb7c311eb214b17a4c6832b3'}, 'duration': 1.5976769924163818, 'iteration': 1, 'loss': 0.40386351909184726, 'max_history_score': 0.5961364809081527, 'max_history_score_std': 0.05351463210025494, 'max_history_step': 'joint', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 3, 'features__selectkbest__k': 3}), 'normalizer': ('normalizer_StandardScaler', {'normalizer__with_mean': True, 'normalizer__with_std': True}), 'rebalance': ('rebalance_NearMiss', {'rebalance__n_neighbors': 2})}, 'score': 0.5961364809081527, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'entropy', 'max_depth': 1, 'max_features': 2, 'max_leaf_nodes': 2, 'min_samples_split': 5, 'n_estimators': 25}, 'config_hash': {'algorithm': '897745a20d929d43e760cacee0a764bd8070daa5', 'config': 'de121d053e65def047cc8947f505578d5c5eab67', 'pipeline': '63040b39b48626a8232e847e8327bdca5cd88611'}, 'duration': 0.815453052520752, 'iteration': 2, 'loss': 0.07327786377708967, 'max_history_score': 0.9267221362229103, 'max_history_score_std': 0.043920207373658794, 'max_history_step': 'joint', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 3, 'features__selectkbest__k': 2}), 'normalizer': ('normalizer_StandardScaler', {'normalizer__with_mean': True, 'normalizer__with_std': True}), 'rebalance': ('rebalance_NoneType', {})}, 'score': 0.9267221362229103, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'entropy', 'max_depth': 4, 'max_features': 3, 'max_leaf_nodes': None, 'min_samples_split': 2, 'n_estimators': 100}, 'config_hash': {'algorithm': 'dbd92c75280ec06b66ca4ad9b135cf36957031a4', 'config': 'b21c9d15a389baa5bfea4c8ddcec129259f37540', 'pipeline': '38866720d2f120c863351493b9b4e23b9a4506dc'}, 'duration': 1.2293269634246826, 'iteration': 3, 'loss': 0.07199862401100798, 'max_history_score': 0.928001375988992, 'max_history_score_std': 0.06518367535896959, 'max_history_step': 'joint', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 2, 'features__selectkbest__k': 4}), 'normalizer': ('normalizer_NoneType', {}), 'rebalance': ('rebalance_NoneType', {})}, 'score': 0.928001375988992, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': 2, 'max_features': None, 'max_leaf_nodes': None, 'min_samples_split': 5, 'n_estimators': 100}, 'config_hash': {'algorithm': 'f455eefd9fdd03ece88892c3f440c580bdf27ddb', 'config': 'edd3456355d80775739c31515c832ca7b4e5e094', 'pipeline': '1d1034f9f0871e43f896c1db4ed6fd572ed0a6ef'}, 'duration': 1.6186630725860596, 'iteration': 4, 'loss': 0.16651831785345705, 'max_history_score': 0.928001375988992, 'max_history_score_std': 0.06518367535896959, 'max_history_step': 'joint', 'pipeline': {'features': ('features_SelectKBest', {'features__k': 4}), 'normalizer': ('normalizer_MinMaxScaler', {}), 'rebalance': ('rebalance_CondensedNearestNeighbour', {'rebalance__n_neighbors': 1})}, 'score': 0.833481682146543, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'entropy', 'max_depth': 1, 'max_features': 2, 'max_leaf_nodes': None, 'min_samples_split': 2, 'n_estimators': 10}, 'config_hash': {'algorithm': '29906eaa0712a68ea145b12821d54ba445726fbf', 'config': '0800d7d2c8c10d2f9e7b4e5127b343e916eb742c', 'pipeline': '2e0f188ae61600352a7159285e0f542b4587a403'}, 'duration': 0.19410085678100586, 'iteration': 5, 'loss': 0.20164258685930514, 'max_history_score': 0.928001375988992, 'max_history_score_std': 0.06518367535896959, 'max_history_step': 'joint', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 3, 'features__selectkbest__k': 4}), 'normalizer': ('normalizer_StandardScaler', {'normalizer__with_mean': True, 'normalizer__with_std': False}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 7})}, 'score': 0.7983574131406949, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': 1, 'max_features': 1, 'max_leaf_nodes': 5, 'min_samples_split': 2, 'n_estimators': 25}, 'config_hash': {'algorithm': 'fbb7d57e38cfc08240f0af985282da418cb33556', 'config': 'd98b641879b4754f2169335626a90575e945fd7c', 'pipeline': '62463de065924498cdcd2f2f1f7e68535cdb33a5'}, 'duration': 0.3625810146331787, 'iteration': 6, 'loss': 0.14327485380116955, 'max_history_score': 0.928001375988992, 'max_history_score_std': 0.06518367535896959, 'max_history_step': 'joint', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 1, 'features__selectkbest__k': 2}), 'normalizer': ('normalizer_NoneType', {}), 'rebalance': ('rebalance_NoneType', {})}, 'score': 0.8567251461988304, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'entropy', 'max_depth': 3, 'max_features': 1, 'max_leaf_nodes': None, 'min_samples_split': 2, 'n_estimators': 75}, 'config_hash': {'algorithm': 'fb2f5d4c4d636edac929e1454ce3d02a4fb134c1', 'config': '3f83df36a6abbdf7ea4a4bdcaf6727f23529c2bb', 'pipeline': '8377b93e334656d1a93d266493b58ef9a6a1786f'}, 'duration': 0.8223779201507568, 'iteration': 7, 'loss': 0.03921568627450989, 'max_history_score': 0.9607843137254901, 'max_history_score_std': 0.043526663832084804, 'max_history_step': 'joint', 'pipeline': {'features': ('features_PCA', {'features__n_components': 3}), 'normalizer': ('normalizer_MinMaxScaler', {}), 'rebalance': ('rebalance_NearMiss', {'rebalance__n_neighbors': 1})}, 'score': 0.9607843137254901, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'gini', 'max_depth': 3, 'max_features': 3, 'max_leaf_nodes': 2, 'min_samples_split': 2, 'n_estimators': 100}, 'config_hash': {'algorithm': '3c3fde6559b918694de4668d025d5418342db1b1', 'config': '037fd5c655b39cc7922fb394d736496befcc747b', 'pipeline': '2a5032814c6c7ed21dd5bd9686923d7fc2f8acc9'}, 'duration': 1.0435099601745605, 'iteration': 8, 'loss': 0.09955925352597172, 'max_history_score': 0.9607843137254901, 'max_history_score_std': 0.043526663832084804, 'max_history_step': 'joint', 'pipeline': {'features': ('features_NoneType', {}), 'normalizer': ('normalizer_RobustScaler', {'normalizer__quantile_range': (...), 'normalizer__with_centering': True, 'normalizer__with_scaling': True}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 7})}, 'score': 0.9004407464740283, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': 2, 'max_features': 1, 'max_leaf_nodes': None, 'min_samples_split': 3, 'n_estimators': 75}, 'config_hash': {'algorithm': '42185be98371e99ac896d2c6c2d69c451cb983ff', 'config': '6609280032189b59de1afbe36f3acb1d5c273693', 'pipeline': '8aab2941fc84d84f86fa56134e50909dbf9e19f5'}, 'duration': 0.9665219783782959, 'iteration': 9, 'loss': 0.01637426900584804, 'max_history_score': 0.983625730994152, 'max_history_score_std': 0.025023500462379746, 'max_history_step': 'joint', 'pipeline': {'features': ('features_NoneType', {}), 'normalizer': ('normalizer_PowerTransformer', {}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 5})}, 'score': 0.983625730994152, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': 1, 'max_features': 3, 'max_leaf_nodes': 2, 'min_samples_split': 3, 'n_estimators': 10}, 'config_hash': {'algorithm': '62a9fe705e4cd96e762bcc9543c4a456a5a9f188', 'config': '8e1c17ac9f6e03740f380fccb833c9c3931ffc35', 'pipeline': '3d44d7482e468d08c4f94457a205f3dac74084c1'}, 'duration': 0.46930503845214844, 'iteration': 10, 'loss': 1.0, 'max_history_score': 0.983625730994152, 'max_history_score_std': 0.025023500462379746, 'max_history_step': 'joint', 'pipeline': {'features': ('features_PCA', {'features__n_components': 1}), 'normalizer': ('normalizer_NoneType', {}), 'rebalance': ('rebalance_CondensedNearestNeighbour', {'rebalance__n_neighbors': 3})}, 'score': 0.0, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'gini', 'max_depth': 4, 'max_features': 1, 'max_leaf_nodes': 3, 'min_samples_split': 2, 'n_estimators': 100}, 'config_hash': {'algorithm': '086d6ca939a757bb32edb113a567f9d38744f061', 'config': '87c03d0cb8e8500e58cacc1a0f27ce54c41a2937', 'pipeline': '8f28ef0f35d97142278f9dacb4e9d1ff082e470f'}, 'duration': 2.1196961402893066, 'iteration': 11, 'loss': 0.15471276229790154, 'max_history_score': 0.983625730994152, 'max_history_score_std': 0.025023500462379746, 'max_history_step': 'joint', 'pipeline': {'features': ('features_PCA', {'features__n_components': 1}), 'normalizer': ('normalizer_StandardScaler', {'normalizer__with_mean': True, 'normalizer__with_std': True}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 7})}, 'score': 0.8452872377020985, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'entropy', 'max_depth': 3, 'max_features': 1, 'max_leaf_nodes': 2, 'min_samples_split': 2, 'n_estimators': 25}, 'config_hash': {'algorithm': '59f64a966796648c7bebade1127fa05541b391ad', 'config': '2ab964abffa0a277a9e2ee9b5570cd258e428b62', 'pipeline': 'eef3f702fd2fed761fa6744c1640d0bf320f1d00'}, 'duration': 0.9828321933746338, 'iteration': 12, 'loss': 0.0778465772273822, 'max_history_score': 0.983625730994152, 'max_history_score_std': 0.025023500462379746, 'max_history_step': 'joint', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 3, 'features__selectkbest__k': 1}), 'normalizer': ('normalizer_PowerTransformer', {}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 6})}, 'score': 0.9221534227726178, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'gini', 'max_depth': 4, 'max_features': 2, 'max_leaf_nodes': 3, 'min_samples_split': 3, 'n_estimators': 75}, 'config_hash': {'algorithm': '6f75c2a196eb9836df2b424e095051192eaed6ea', 'config': '5c95db3ad238063227f1b36e6a006d70c834c5da', 'pipeline': '1eae01a1128bee425c4d4ca0ee97a9afd409680e'}, 'duration': 0.8217771053314209, 'iteration': 13, 'loss': 0.03863089095287242, 'max_history_score': 0.983625730994152, 'max_history_score_std': 0.025023500462379746, 'max_history_step': 'joint', 'pipeline': {'features': ('features_NoneType', {}), 'normalizer': ('normalizer_StandardScaler', {'normalizer__with_mean': False, 'normalizer__with_std': False}), 'rebalance': ('rebalance_NearMiss', {'rebalance__n_neighbors': 1})}, 'score': 0.9613691090471276, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'entropy', 'max_depth': 4, 'max_features': 2, 'max_leaf_nodes': 3, 'min_samples_split': 2, 'n_estimators': 25}, 'config_hash': {'algorithm': '8aef3174f6b8020de06b825e0424c1e54d690afd', 'config': '50fd1169b8e42190600f25152654254b5d0e3ed1', 'pipeline': '9ceaa544911dc6c687e336cb8e9dd4d15ff1ceaf'}, 'duration': 0.40307188034057617, 'iteration': 14, 'loss': 1.0, 'max_history_score': 0.983625730994152, 'max_history_score_std': 0.025023500462379746, 'max_history_step': 'joint', 'pipeline': {'features': ('features_PCA', {'features__n_components': 1}), 'normalizer': ('normalizer_RobustScaler', {'normalizer__quantile_range': (...), 'normalizer__with_centering': False, 'normalizer__with_scaling': False}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 7})}, 'score': 0.0, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'gini', 'max_depth': 1, 'max_features': 1, 'max_leaf_nodes': 3, 'min_samples_split': 3, 'n_estimators': 50}, 'config_hash': {'algorithm': '37be8b6737f4b5d5ae35da51886f302b07ba6001', 'config': 'a05b6d2ffd65d4d937c0b178655d857bf4d61410', 'pipeline': 'cfef88e895db321122f2f7b813d9267b973c2468'}, 'duration': 1.7094659805297852, 'iteration': 15, 'loss': 0.011111111111111072, 'max_history_score': 0.9888888888888889, 'max_history_score_std': 0.022222222222222233, 'max_history_step': 'joint', 'pipeline': {'features': ('features_NoneType', {}), 'normalizer': ('normalizer_NoneType', {}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 5})}, 'score': 0.9888888888888889, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'entropy', 'max_depth': None, 'max_features': 3, 'max_leaf_nodes': None, 'min_samples_split': 2, 'n_estimators': 100}, 'config_hash': {'algorithm': 'c40543ce91793e367c1892c886bc49621c22ecfb', 'config': 'ebebb7a93116f14f470e062e37582a59f4aeb0df', 'pipeline': 'b50c63e800574e8b760f55f7c4ff1fcae8816dd8'}, 'duration': 0.6425540447235107, 'iteration': 16, 'loss': 1.0, 'max_history_score': 0.9888888888888889, 'max_history_score_std': 0.022222222222222233, 'max_history_step': 'joint', 'pipeline': {'features': ('features_PCA', {'features__n_components': 1}), 'normalizer': ('normalizer_PowerTransformer', {}), 'rebalance': ('rebalance_NearMiss', {'rebalance__n_neighbors': 1})}, 'score': 0.0, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'gini', 'max_depth': None, 'max_features': 1, 'max_leaf_nodes': 3, 'min_samples_split': 2, 'n_estimators': 50}, 'config_hash': {'algorithm': '0c69b9601237c20664085fa05764d855e28f98f7', 'config': 'a2c21314ddbba47ddbfe416e0aa14853a71179e0', 'pipeline': '914f81fa4fbb61db251201f32bd8ea11bfeea2a5'}, 'duration': 2.2209739685058594, 'iteration': 17, 'loss': 0.3206720846233231, 'max_history_score': 0.9888888888888889, 'max_history_score_std': 0.022222222222222233, 'max_history_step': 'joint', 'pipeline': {'features': ('features_SelectKBest', {'features__k': 4}), 'normalizer': ('normalizer_PowerTransformer', {}), 'rebalance': ('rebalance_CondensedNearestNeighbour', {'rebalance__n_neighbors': 1})}, 'score': 0.6793279153766769, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': 4, 'max_features': None, 'max_leaf_nodes': None, 'min_samples_split': 3, 'n_estimators': 25}, 'config_hash': {'algorithm': '1aae0f1fce5cab293ffdd4581c4838c8051ac815', 'config': '6c8a721218e7c550a98c5ba72ad9ff86afd5e3a4', 'pipeline': '77189452469cef9c840643f2babe0f825c6667c8'}, 'duration': 0.3951280117034912, 'iteration': 18, 'loss': 0.1804760061919506, 'max_history_score': 0.9888888888888889, 'max_history_score_std': 0.022222222222222233, 'max_history_step': 'joint', 'pipeline': {'features': ('features_SelectKBest', {'features__k': 2}), 'normalizer': ('normalizer_NoneType', {}), 'rebalance': ('rebalance_NearMiss', {'rebalance__n_neighbors': 1})}, 'score': 0.8195239938080494, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': None, 'max_features': 3, 'max_leaf_nodes': 5, 'min_samples_split': 3, 'n_estimators': 50}, 'config_hash': {'algorithm': '0129970b8c7fe034ac8283fb518a06cfbead63d2', 'config': '61bcd2f64860b3dfe2503be88a6bbec165db0754', 'pipeline': '359f2473075ecfd9ae3ce526da96143918517601'}, 'duration': 0.7467091083526611, 'iteration': 19, 'loss': 0.09915720674234607, 'max_history_score': 0.9888888888888889, 'max_history_score_std': 0.022222222222222233, 'max_history_step': 'joint', 'pipeline': {'features': ('features_SelectKBest', {'features__k': 3}), 'normalizer': ('normalizer_RobustScaler', {'normalizer__quantile_range': (...), 'normalizer__with_centering': True, 'normalizer__with_scaling': False}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 7})}, 'score': 0.9008427932576539, ...}, ...], 'history_hash': ['2e6648b63441361b4398cb94f81d2e04a830b2ef', '584343bc020d2d7bc89bd0856bc7770dae1c84fc', 'de121d053e65def047cc8947f505578d5c5eab67', 'b21c9d15a389baa5bfea4c8ddcec129259f37540', 'edd3456355d80775739c31515c832ca7b4e5e094', '0800d7d2c8c10d2f9e7b4e5127b343e916eb742c', 'd98b641879b4754f2169335626a90575e945fd7c', '3f83df36a6abbdf7ea4a4bdcaf6727f23529c2bb', '037fd5c655b39cc7922fb394d736496befcc747b', '6609280032189b59de1afbe36f3acb1d5c273693', '8e1c17ac9f6e03740f380fccb833c9c3931ffc35', '87c03d0cb8e8500e58cacc1a0f27ce54c41a2937', '2ab964abffa0a277a9e2ee9b5570cd258e428b62', '5c95db3ad238063227f1b36e6a006d70c834c5da', '50fd1169b8e42190600f25152654254b5d0e3ed1', 'a05b6d2ffd65d4d937c0b178655d857bf4d61410', 'ebebb7a93116f14f470e062e37582a59f4aeb0df', 'a2c21314ddbba47ddbfe416e0aa14853a71179e0', '6c8a721218e7c550a98c5ba72ad9ff86afd5e3a4', '61bcd2f64860b3dfe2503be88a6bbec165db0754', ...], 'history_index': {'037fd5c655b39cc7922fb394d736496befcc747b': 8, '07fdf9d0d0248a4b0215a633c75a2dd101dcf465': 22, '0800d7d2c8c10d2f9e7b4e5127b343e916eb742c': 5, '0babf362e2373c001d4eb84f3c4eda27e56fe02d': 33, '0c9d6c44176dcc6b6ed48155a6e53130cb2c32e8': 45, '0e45095dfe50d5be759b179b50e63384925c7027': 32, '10bbd802ae07af833e53a3844fb056ba4016b893': 46, '2323c40e4e6c5f4aa333620a6b998b510ca41854': 35, '26ed0b67cf1046a22e2baba31b70ce3b6e762a03': 40, '28944b74104bc5bb782512b0eefa3167fe189355': 30, ...}, 'iteration': 48, 'max_history_score': 0.9944444444444445, 'max_history_score_std': 0.016666666666666673, 'max_history_step': 'joint'}, config={'algorithm': 'RandomForest', 'seed': 42, 'time': 300})
    108 
    109 def objective_algo(algo_config, current_pipeline_config, algorithm, X, y, context, config):
    110     return objective(current_pipeline_config, algo_config, algorithm, X, y, context, config, step='algorithm')
    111 
    112 def objective_joint(wconfig, algorithm, X, y, context, config):
--> 113     return objective(wconfig['pipeline'], wconfig['algorithm'], algorithm, X, y, context, config, step='joint')
        wconfig = {'algorithm': {'bootstrap': False, 'criterion': 'gini', 'max_depth': 1, 'max_features': 3, 'max_leaf_nodes': 2, 'min_samples_split': 5, 'n_estimators': 100}, 'pipeline': {'features': ('features_PCA', {'features__n_components': 2}), 'normalizer': ('normalizer_MinMaxScaler', {}), 'rebalance': ('rebalance_NearMiss', {'rebalance__n_neighbors': 3})}}
        algorithm = 'RandomForest'
        X = array([[1.423e+01, 1.710e+00, 2.430e+00, ..., 1...., ..., 6.100e-01, 1.600e+00,
        5.600e+02]])
        y = array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,
       2, 2])
        context = {'baseline_score': 0.9444100447196423, 'baseline_score_std': 0.04305547117084885, 'best_config': {'algorithm': {'bootstrap': False, 'criterion': 'gini', 'max_depth': 1, 'max_features': 1, 'max_leaf_nodes': 3, 'min_samples_split': 5, 'n_estimators': 50}, 'config_hash': {'algorithm': 'cefc05c6c759dc564d289289fe401e0f8737951d', 'config': '7a1c40755d84d62f5d2ab1ed021e7dff93dfce45', 'pipeline': '3ee6a915db2d8d71f204c103803fb8eabea0d54f'}, 'duration': 0.6908998489379883, 'iteration': 24, 'loss': 0.005555555555555536, 'max_history_score': 0.9944444444444445, 'max_history_score_std': 0.016666666666666673, 'max_history_step': 'joint', 'pipeline': {'features': ('features_NoneType', {}), 'normalizer': ('normalizer_MinMaxScaler', {}), 'rebalance': ('rebalance_NoneType', {})}, 'score': 0.9944444444444445, ...}, 'history': [{'algorithm': {'bootstrap': False, 'criterion': 'entropy', 'max_depth': None, 'max_features': 3, 'max_leaf_nodes': 5, 'min_samples_split': 2, 'n_estimators': 50}, 'config_hash': {'algorithm': 'b2c6464add7a35ce8048653a39338c9994de9a4f', 'config': '2e6648b63441361b4398cb94f81d2e04a830b2ef', 'pipeline': '3d44d7482e468d08c4f94457a205f3dac74084c1'}, 'duration': 0.737678050994873, 'iteration': 0, 'loss': 1.0, 'max_history_score': 0.0, 'max_history_score_std': 0.0, 'max_history_step': 'baseline', 'pipeline': {'features': ('features_PCA', {'features__n_components': 1}), 'normalizer': ('normalizer_NoneType', {}), 'rebalance': ('rebalance_CondensedNearestNeighbour', {'rebalance__n_neighbors': 3})}, 'score': 0.0, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'gini', 'max_depth': 1, 'max_features': None, 'max_leaf_nodes': 2, 'min_samples_split': 3, 'n_estimators': 25}, 'config_hash': {'algorithm': '7f71bbbfdb4e8da52b6fc33a43224183117de15e', 'config': '584343bc020d2d7bc89bd0856bc7770dae1c84fc', 'pipeline': '466ffa7ace0e442beb7c311eb214b17a4c6832b3'}, 'duration': 1.5976769924163818, 'iteration': 1, 'loss': 0.40386351909184726, 'max_history_score': 0.5961364809081527, 'max_history_score_std': 0.05351463210025494, 'max_history_step': 'joint', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 3, 'features__selectkbest__k': 3}), 'normalizer': ('normalizer_StandardScaler', {'normalizer__with_mean': True, 'normalizer__with_std': True}), 'rebalance': ('rebalance_NearMiss', {'rebalance__n_neighbors': 2})}, 'score': 0.5961364809081527, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'entropy', 'max_depth': 1, 'max_features': 2, 'max_leaf_nodes': 2, 'min_samples_split': 5, 'n_estimators': 25}, 'config_hash': {'algorithm': '897745a20d929d43e760cacee0a764bd8070daa5', 'config': 'de121d053e65def047cc8947f505578d5c5eab67', 'pipeline': '63040b39b48626a8232e847e8327bdca5cd88611'}, 'duration': 0.815453052520752, 'iteration': 2, 'loss': 0.07327786377708967, 'max_history_score': 0.9267221362229103, 'max_history_score_std': 0.043920207373658794, 'max_history_step': 'joint', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 3, 'features__selectkbest__k': 2}), 'normalizer': ('normalizer_StandardScaler', {'normalizer__with_mean': True, 'normalizer__with_std': True}), 'rebalance': ('rebalance_NoneType', {})}, 'score': 0.9267221362229103, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'entropy', 'max_depth': 4, 'max_features': 3, 'max_leaf_nodes': None, 'min_samples_split': 2, 'n_estimators': 100}, 'config_hash': {'algorithm': 'dbd92c75280ec06b66ca4ad9b135cf36957031a4', 'config': 'b21c9d15a389baa5bfea4c8ddcec129259f37540', 'pipeline': '38866720d2f120c863351493b9b4e23b9a4506dc'}, 'duration': 1.2293269634246826, 'iteration': 3, 'loss': 0.07199862401100798, 'max_history_score': 0.928001375988992, 'max_history_score_std': 0.06518367535896959, 'max_history_step': 'joint', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 2, 'features__selectkbest__k': 4}), 'normalizer': ('normalizer_NoneType', {}), 'rebalance': ('rebalance_NoneType', {})}, 'score': 0.928001375988992, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': 2, 'max_features': None, 'max_leaf_nodes': None, 'min_samples_split': 5, 'n_estimators': 100}, 'config_hash': {'algorithm': 'f455eefd9fdd03ece88892c3f440c580bdf27ddb', 'config': 'edd3456355d80775739c31515c832ca7b4e5e094', 'pipeline': '1d1034f9f0871e43f896c1db4ed6fd572ed0a6ef'}, 'duration': 1.6186630725860596, 'iteration': 4, 'loss': 0.16651831785345705, 'max_history_score': 0.928001375988992, 'max_history_score_std': 0.06518367535896959, 'max_history_step': 'joint', 'pipeline': {'features': ('features_SelectKBest', {'features__k': 4}), 'normalizer': ('normalizer_MinMaxScaler', {}), 'rebalance': ('rebalance_CondensedNearestNeighbour', {'rebalance__n_neighbors': 1})}, 'score': 0.833481682146543, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'entropy', 'max_depth': 1, 'max_features': 2, 'max_leaf_nodes': None, 'min_samples_split': 2, 'n_estimators': 10}, 'config_hash': {'algorithm': '29906eaa0712a68ea145b12821d54ba445726fbf', 'config': '0800d7d2c8c10d2f9e7b4e5127b343e916eb742c', 'pipeline': '2e0f188ae61600352a7159285e0f542b4587a403'}, 'duration': 0.19410085678100586, 'iteration': 5, 'loss': 0.20164258685930514, 'max_history_score': 0.928001375988992, 'max_history_score_std': 0.06518367535896959, 'max_history_step': 'joint', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 3, 'features__selectkbest__k': 4}), 'normalizer': ('normalizer_StandardScaler', {'normalizer__with_mean': True, 'normalizer__with_std': False}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 7})}, 'score': 0.7983574131406949, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': 1, 'max_features': 1, 'max_leaf_nodes': 5, 'min_samples_split': 2, 'n_estimators': 25}, 'config_hash': {'algorithm': 'fbb7d57e38cfc08240f0af985282da418cb33556', 'config': 'd98b641879b4754f2169335626a90575e945fd7c', 'pipeline': '62463de065924498cdcd2f2f1f7e68535cdb33a5'}, 'duration': 0.3625810146331787, 'iteration': 6, 'loss': 0.14327485380116955, 'max_history_score': 0.928001375988992, 'max_history_score_std': 0.06518367535896959, 'max_history_step': 'joint', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 1, 'features__selectkbest__k': 2}), 'normalizer': ('normalizer_NoneType', {}), 'rebalance': ('rebalance_NoneType', {})}, 'score': 0.8567251461988304, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'entropy', 'max_depth': 3, 'max_features': 1, 'max_leaf_nodes': None, 'min_samples_split': 2, 'n_estimators': 75}, 'config_hash': {'algorithm': 'fb2f5d4c4d636edac929e1454ce3d02a4fb134c1', 'config': '3f83df36a6abbdf7ea4a4bdcaf6727f23529c2bb', 'pipeline': '8377b93e334656d1a93d266493b58ef9a6a1786f'}, 'duration': 0.8223779201507568, 'iteration': 7, 'loss': 0.03921568627450989, 'max_history_score': 0.9607843137254901, 'max_history_score_std': 0.043526663832084804, 'max_history_step': 'joint', 'pipeline': {'features': ('features_PCA', {'features__n_components': 3}), 'normalizer': ('normalizer_MinMaxScaler', {}), 'rebalance': ('rebalance_NearMiss', {'rebalance__n_neighbors': 1})}, 'score': 0.9607843137254901, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'gini', 'max_depth': 3, 'max_features': 3, 'max_leaf_nodes': 2, 'min_samples_split': 2, 'n_estimators': 100}, 'config_hash': {'algorithm': '3c3fde6559b918694de4668d025d5418342db1b1', 'config': '037fd5c655b39cc7922fb394d736496befcc747b', 'pipeline': '2a5032814c6c7ed21dd5bd9686923d7fc2f8acc9'}, 'duration': 1.0435099601745605, 'iteration': 8, 'loss': 0.09955925352597172, 'max_history_score': 0.9607843137254901, 'max_history_score_std': 0.043526663832084804, 'max_history_step': 'joint', 'pipeline': {'features': ('features_NoneType', {}), 'normalizer': ('normalizer_RobustScaler', {'normalizer__quantile_range': (...), 'normalizer__with_centering': True, 'normalizer__with_scaling': True}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 7})}, 'score': 0.9004407464740283, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': 2, 'max_features': 1, 'max_leaf_nodes': None, 'min_samples_split': 3, 'n_estimators': 75}, 'config_hash': {'algorithm': '42185be98371e99ac896d2c6c2d69c451cb983ff', 'config': '6609280032189b59de1afbe36f3acb1d5c273693', 'pipeline': '8aab2941fc84d84f86fa56134e50909dbf9e19f5'}, 'duration': 0.9665219783782959, 'iteration': 9, 'loss': 0.01637426900584804, 'max_history_score': 0.983625730994152, 'max_history_score_std': 0.025023500462379746, 'max_history_step': 'joint', 'pipeline': {'features': ('features_NoneType', {}), 'normalizer': ('normalizer_PowerTransformer', {}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 5})}, 'score': 0.983625730994152, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': 1, 'max_features': 3, 'max_leaf_nodes': 2, 'min_samples_split': 3, 'n_estimators': 10}, 'config_hash': {'algorithm': '62a9fe705e4cd96e762bcc9543c4a456a5a9f188', 'config': '8e1c17ac9f6e03740f380fccb833c9c3931ffc35', 'pipeline': '3d44d7482e468d08c4f94457a205f3dac74084c1'}, 'duration': 0.46930503845214844, 'iteration': 10, 'loss': 1.0, 'max_history_score': 0.983625730994152, 'max_history_score_std': 0.025023500462379746, 'max_history_step': 'joint', 'pipeline': {'features': ('features_PCA', {'features__n_components': 1}), 'normalizer': ('normalizer_NoneType', {}), 'rebalance': ('rebalance_CondensedNearestNeighbour', {'rebalance__n_neighbors': 3})}, 'score': 0.0, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'gini', 'max_depth': 4, 'max_features': 1, 'max_leaf_nodes': 3, 'min_samples_split': 2, 'n_estimators': 100}, 'config_hash': {'algorithm': '086d6ca939a757bb32edb113a567f9d38744f061', 'config': '87c03d0cb8e8500e58cacc1a0f27ce54c41a2937', 'pipeline': '8f28ef0f35d97142278f9dacb4e9d1ff082e470f'}, 'duration': 2.1196961402893066, 'iteration': 11, 'loss': 0.15471276229790154, 'max_history_score': 0.983625730994152, 'max_history_score_std': 0.025023500462379746, 'max_history_step': 'joint', 'pipeline': {'features': ('features_PCA', {'features__n_components': 1}), 'normalizer': ('normalizer_StandardScaler', {'normalizer__with_mean': True, 'normalizer__with_std': True}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 7})}, 'score': 0.8452872377020985, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'entropy', 'max_depth': 3, 'max_features': 1, 'max_leaf_nodes': 2, 'min_samples_split': 2, 'n_estimators': 25}, 'config_hash': {'algorithm': '59f64a966796648c7bebade1127fa05541b391ad', 'config': '2ab964abffa0a277a9e2ee9b5570cd258e428b62', 'pipeline': 'eef3f702fd2fed761fa6744c1640d0bf320f1d00'}, 'duration': 0.9828321933746338, 'iteration': 12, 'loss': 0.0778465772273822, 'max_history_score': 0.983625730994152, 'max_history_score_std': 0.025023500462379746, 'max_history_step': 'joint', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 3, 'features__selectkbest__k': 1}), 'normalizer': ('normalizer_PowerTransformer', {}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 6})}, 'score': 0.9221534227726178, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'gini', 'max_depth': 4, 'max_features': 2, 'max_leaf_nodes': 3, 'min_samples_split': 3, 'n_estimators': 75}, 'config_hash': {'algorithm': '6f75c2a196eb9836df2b424e095051192eaed6ea', 'config': '5c95db3ad238063227f1b36e6a006d70c834c5da', 'pipeline': '1eae01a1128bee425c4d4ca0ee97a9afd409680e'}, 'duration': 0.8217771053314209, 'iteration': 13, 'loss': 0.03863089095287242, 'max_history_score': 0.983625730994152, 'max_history_score_std': 0.025023500462379746, 'max_history_step': 'joint', 'pipeline': {'features': ('features_NoneType', {}), 'normalizer': ('normalizer_StandardScaler', {'normalizer__with_mean': False, 'normalizer__with_std': False}), 'rebalance': ('rebalance_NearMiss', {'rebalance__n_neighbors': 1})}, 'score': 0.9613691090471276, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'entropy', 'max_depth': 4, 'max_features': 2, 'max_leaf_nodes': 3, 'min_samples_split': 2, 'n_estimators': 25}, 'config_hash': {'algorithm': '8aef3174f6b8020de06b825e0424c1e54d690afd', 'config': '50fd1169b8e42190600f25152654254b5d0e3ed1', 'pipeline': '9ceaa544911dc6c687e336cb8e9dd4d15ff1ceaf'}, 'duration': 0.40307188034057617, 'iteration': 14, 'loss': 1.0, 'max_history_score': 0.983625730994152, 'max_history_score_std': 0.025023500462379746, 'max_history_step': 'joint', 'pipeline': {'features': ('features_PCA', {'features__n_components': 1}), 'normalizer': ('normalizer_RobustScaler', {'normalizer__quantile_range': (...), 'normalizer__with_centering': False, 'normalizer__with_scaling': False}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 7})}, 'score': 0.0, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'gini', 'max_depth': 1, 'max_features': 1, 'max_leaf_nodes': 3, 'min_samples_split': 3, 'n_estimators': 50}, 'config_hash': {'algorithm': '37be8b6737f4b5d5ae35da51886f302b07ba6001', 'config': 'a05b6d2ffd65d4d937c0b178655d857bf4d61410', 'pipeline': 'cfef88e895db321122f2f7b813d9267b973c2468'}, 'duration': 1.7094659805297852, 'iteration': 15, 'loss': 0.011111111111111072, 'max_history_score': 0.9888888888888889, 'max_history_score_std': 0.022222222222222233, 'max_history_step': 'joint', 'pipeline': {'features': ('features_NoneType', {}), 'normalizer': ('normalizer_NoneType', {}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 5})}, 'score': 0.9888888888888889, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'entropy', 'max_depth': None, 'max_features': 3, 'max_leaf_nodes': None, 'min_samples_split': 2, 'n_estimators': 100}, 'config_hash': {'algorithm': 'c40543ce91793e367c1892c886bc49621c22ecfb', 'config': 'ebebb7a93116f14f470e062e37582a59f4aeb0df', 'pipeline': 'b50c63e800574e8b760f55f7c4ff1fcae8816dd8'}, 'duration': 0.6425540447235107, 'iteration': 16, 'loss': 1.0, 'max_history_score': 0.9888888888888889, 'max_history_score_std': 0.022222222222222233, 'max_history_step': 'joint', 'pipeline': {'features': ('features_PCA', {'features__n_components': 1}), 'normalizer': ('normalizer_PowerTransformer', {}), 'rebalance': ('rebalance_NearMiss', {'rebalance__n_neighbors': 1})}, 'score': 0.0, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'gini', 'max_depth': None, 'max_features': 1, 'max_leaf_nodes': 3, 'min_samples_split': 2, 'n_estimators': 50}, 'config_hash': {'algorithm': '0c69b9601237c20664085fa05764d855e28f98f7', 'config': 'a2c21314ddbba47ddbfe416e0aa14853a71179e0', 'pipeline': '914f81fa4fbb61db251201f32bd8ea11bfeea2a5'}, 'duration': 2.2209739685058594, 'iteration': 17, 'loss': 0.3206720846233231, 'max_history_score': 0.9888888888888889, 'max_history_score_std': 0.022222222222222233, 'max_history_step': 'joint', 'pipeline': {'features': ('features_SelectKBest', {'features__k': 4}), 'normalizer': ('normalizer_PowerTransformer', {}), 'rebalance': ('rebalance_CondensedNearestNeighbour', {'rebalance__n_neighbors': 1})}, 'score': 0.6793279153766769, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': 4, 'max_features': None, 'max_leaf_nodes': None, 'min_samples_split': 3, 'n_estimators': 25}, 'config_hash': {'algorithm': '1aae0f1fce5cab293ffdd4581c4838c8051ac815', 'config': '6c8a721218e7c550a98c5ba72ad9ff86afd5e3a4', 'pipeline': '77189452469cef9c840643f2babe0f825c6667c8'}, 'duration': 0.3951280117034912, 'iteration': 18, 'loss': 0.1804760061919506, 'max_history_score': 0.9888888888888889, 'max_history_score_std': 0.022222222222222233, 'max_history_step': 'joint', 'pipeline': {'features': ('features_SelectKBest', {'features__k': 2}), 'normalizer': ('normalizer_NoneType', {}), 'rebalance': ('rebalance_NearMiss', {'rebalance__n_neighbors': 1})}, 'score': 0.8195239938080494, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': None, 'max_features': 3, 'max_leaf_nodes': 5, 'min_samples_split': 3, 'n_estimators': 50}, 'config_hash': {'algorithm': '0129970b8c7fe034ac8283fb518a06cfbead63d2', 'config': '61bcd2f64860b3dfe2503be88a6bbec165db0754', 'pipeline': '359f2473075ecfd9ae3ce526da96143918517601'}, 'duration': 0.7467091083526611, 'iteration': 19, 'loss': 0.09915720674234607, 'max_history_score': 0.9888888888888889, 'max_history_score_std': 0.022222222222222233, 'max_history_step': 'joint', 'pipeline': {'features': ('features_SelectKBest', {'features__k': 3}), 'normalizer': ('normalizer_RobustScaler', {'normalizer__quantile_range': (...), 'normalizer__with_centering': True, 'normalizer__with_scaling': False}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 7})}, 'score': 0.9008427932576539, ...}, ...], 'history_hash': ['2e6648b63441361b4398cb94f81d2e04a830b2ef', '584343bc020d2d7bc89bd0856bc7770dae1c84fc', 'de121d053e65def047cc8947f505578d5c5eab67', 'b21c9d15a389baa5bfea4c8ddcec129259f37540', 'edd3456355d80775739c31515c832ca7b4e5e094', '0800d7d2c8c10d2f9e7b4e5127b343e916eb742c', 'd98b641879b4754f2169335626a90575e945fd7c', '3f83df36a6abbdf7ea4a4bdcaf6727f23529c2bb', '037fd5c655b39cc7922fb394d736496befcc747b', '6609280032189b59de1afbe36f3acb1d5c273693', '8e1c17ac9f6e03740f380fccb833c9c3931ffc35', '87c03d0cb8e8500e58cacc1a0f27ce54c41a2937', '2ab964abffa0a277a9e2ee9b5570cd258e428b62', '5c95db3ad238063227f1b36e6a006d70c834c5da', '50fd1169b8e42190600f25152654254b5d0e3ed1', 'a05b6d2ffd65d4d937c0b178655d857bf4d61410', 'ebebb7a93116f14f470e062e37582a59f4aeb0df', 'a2c21314ddbba47ddbfe416e0aa14853a71179e0', '6c8a721218e7c550a98c5ba72ad9ff86afd5e3a4', '61bcd2f64860b3dfe2503be88a6bbec165db0754', ...], 'history_index': {'037fd5c655b39cc7922fb394d736496befcc747b': 8, '07fdf9d0d0248a4b0215a633c75a2dd101dcf465': 22, '0800d7d2c8c10d2f9e7b4e5127b343e916eb742c': 5, '0babf362e2373c001d4eb84f3c4eda27e56fe02d': 33, '0c9d6c44176dcc6b6ed48155a6e53130cb2c32e8': 45, '0e45095dfe50d5be759b179b50e63384925c7027': 32, '10bbd802ae07af833e53a3844fb056ba4016b893': 46, '2323c40e4e6c5f4aa333620a6b998b510ca41854': 35, '26ed0b67cf1046a22e2baba31b70ce3b6e762a03': 40, '28944b74104bc5bb782512b0eefa3167fe189355': 30, ...}, 'iteration': 48, 'max_history_score': 0.9944444444444445, 'max_history_score_std': 0.016666666666666673, 'max_history_step': 'joint'}
        config = {'algorithm': 'RandomForest', 'seed': 42, 'time': 300}
    114 
    115 
    116 def get_baseline_score(algorithm, X, y, seed):
    117     pipeline, _ = pipeline_conf_to_full_pipeline(

...........................................................................
/home/aquemy/dev/dp_hyperparameters/extension/experiment/objective.py in objective(pipeline_config={'features': ('features_PCA', {'features__n_components': 2}), 'normalizer': ('normalizer_MinMaxScaler', {}), 'rebalance': ('rebalance_NearMiss', {'rebalance__n_neighbors': 3})}, algo_config={'bootstrap': False, 'criterion': 'gini', 'max_depth': 1, 'max_features': 3, 'max_leaf_nodes': 2, 'min_samples_split': 5, 'n_estimators': 100}, algorithm='RandomForest', X=array([[1.423e+01, 1.710e+00, 2.430e+00, ..., 1...., ..., 6.100e-01, 1.600e+00,
        5.600e+02]]), y=array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,
       2, 2]), context={'baseline_score': 0.9444100447196423, 'baseline_score_std': 0.04305547117084885, 'best_config': {'algorithm': {'bootstrap': False, 'criterion': 'gini', 'max_depth': 1, 'max_features': 1, 'max_leaf_nodes': 3, 'min_samples_split': 5, 'n_estimators': 50}, 'config_hash': {'algorithm': 'cefc05c6c759dc564d289289fe401e0f8737951d', 'config': '7a1c40755d84d62f5d2ab1ed021e7dff93dfce45', 'pipeline': '3ee6a915db2d8d71f204c103803fb8eabea0d54f'}, 'duration': 0.6908998489379883, 'iteration': 24, 'loss': 0.005555555555555536, 'max_history_score': 0.9944444444444445, 'max_history_score_std': 0.016666666666666673, 'max_history_step': 'joint', 'pipeline': {'features': ('features_NoneType', {}), 'normalizer': ('normalizer_MinMaxScaler', {}), 'rebalance': ('rebalance_NoneType', {})}, 'score': 0.9944444444444445, ...}, 'history': [{'algorithm': {'bootstrap': False, 'criterion': 'entropy', 'max_depth': None, 'max_features': 3, 'max_leaf_nodes': 5, 'min_samples_split': 2, 'n_estimators': 50}, 'config_hash': {'algorithm': 'b2c6464add7a35ce8048653a39338c9994de9a4f', 'config': '2e6648b63441361b4398cb94f81d2e04a830b2ef', 'pipeline': '3d44d7482e468d08c4f94457a205f3dac74084c1'}, 'duration': 0.737678050994873, 'iteration': 0, 'loss': 1.0, 'max_history_score': 0.0, 'max_history_score_std': 0.0, 'max_history_step': 'baseline', 'pipeline': {'features': ('features_PCA', {'features__n_components': 1}), 'normalizer': ('normalizer_NoneType', {}), 'rebalance': ('rebalance_CondensedNearestNeighbour', {'rebalance__n_neighbors': 3})}, 'score': 0.0, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'gini', 'max_depth': 1, 'max_features': None, 'max_leaf_nodes': 2, 'min_samples_split': 3, 'n_estimators': 25}, 'config_hash': {'algorithm': '7f71bbbfdb4e8da52b6fc33a43224183117de15e', 'config': '584343bc020d2d7bc89bd0856bc7770dae1c84fc', 'pipeline': '466ffa7ace0e442beb7c311eb214b17a4c6832b3'}, 'duration': 1.5976769924163818, 'iteration': 1, 'loss': 0.40386351909184726, 'max_history_score': 0.5961364809081527, 'max_history_score_std': 0.05351463210025494, 'max_history_step': 'joint', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 3, 'features__selectkbest__k': 3}), 'normalizer': ('normalizer_StandardScaler', {'normalizer__with_mean': True, 'normalizer__with_std': True}), 'rebalance': ('rebalance_NearMiss', {'rebalance__n_neighbors': 2})}, 'score': 0.5961364809081527, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'entropy', 'max_depth': 1, 'max_features': 2, 'max_leaf_nodes': 2, 'min_samples_split': 5, 'n_estimators': 25}, 'config_hash': {'algorithm': '897745a20d929d43e760cacee0a764bd8070daa5', 'config': 'de121d053e65def047cc8947f505578d5c5eab67', 'pipeline': '63040b39b48626a8232e847e8327bdca5cd88611'}, 'duration': 0.815453052520752, 'iteration': 2, 'loss': 0.07327786377708967, 'max_history_score': 0.9267221362229103, 'max_history_score_std': 0.043920207373658794, 'max_history_step': 'joint', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 3, 'features__selectkbest__k': 2}), 'normalizer': ('normalizer_StandardScaler', {'normalizer__with_mean': True, 'normalizer__with_std': True}), 'rebalance': ('rebalance_NoneType', {})}, 'score': 0.9267221362229103, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'entropy', 'max_depth': 4, 'max_features': 3, 'max_leaf_nodes': None, 'min_samples_split': 2, 'n_estimators': 100}, 'config_hash': {'algorithm': 'dbd92c75280ec06b66ca4ad9b135cf36957031a4', 'config': 'b21c9d15a389baa5bfea4c8ddcec129259f37540', 'pipeline': '38866720d2f120c863351493b9b4e23b9a4506dc'}, 'duration': 1.2293269634246826, 'iteration': 3, 'loss': 0.07199862401100798, 'max_history_score': 0.928001375988992, 'max_history_score_std': 0.06518367535896959, 'max_history_step': 'joint', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 2, 'features__selectkbest__k': 4}), 'normalizer': ('normalizer_NoneType', {}), 'rebalance': ('rebalance_NoneType', {})}, 'score': 0.928001375988992, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': 2, 'max_features': None, 'max_leaf_nodes': None, 'min_samples_split': 5, 'n_estimators': 100}, 'config_hash': {'algorithm': 'f455eefd9fdd03ece88892c3f440c580bdf27ddb', 'config': 'edd3456355d80775739c31515c832ca7b4e5e094', 'pipeline': '1d1034f9f0871e43f896c1db4ed6fd572ed0a6ef'}, 'duration': 1.6186630725860596, 'iteration': 4, 'loss': 0.16651831785345705, 'max_history_score': 0.928001375988992, 'max_history_score_std': 0.06518367535896959, 'max_history_step': 'joint', 'pipeline': {'features': ('features_SelectKBest', {'features__k': 4}), 'normalizer': ('normalizer_MinMaxScaler', {}), 'rebalance': ('rebalance_CondensedNearestNeighbour', {'rebalance__n_neighbors': 1})}, 'score': 0.833481682146543, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'entropy', 'max_depth': 1, 'max_features': 2, 'max_leaf_nodes': None, 'min_samples_split': 2, 'n_estimators': 10}, 'config_hash': {'algorithm': '29906eaa0712a68ea145b12821d54ba445726fbf', 'config': '0800d7d2c8c10d2f9e7b4e5127b343e916eb742c', 'pipeline': '2e0f188ae61600352a7159285e0f542b4587a403'}, 'duration': 0.19410085678100586, 'iteration': 5, 'loss': 0.20164258685930514, 'max_history_score': 0.928001375988992, 'max_history_score_std': 0.06518367535896959, 'max_history_step': 'joint', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 3, 'features__selectkbest__k': 4}), 'normalizer': ('normalizer_StandardScaler', {'normalizer__with_mean': True, 'normalizer__with_std': False}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 7})}, 'score': 0.7983574131406949, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': 1, 'max_features': 1, 'max_leaf_nodes': 5, 'min_samples_split': 2, 'n_estimators': 25}, 'config_hash': {'algorithm': 'fbb7d57e38cfc08240f0af985282da418cb33556', 'config': 'd98b641879b4754f2169335626a90575e945fd7c', 'pipeline': '62463de065924498cdcd2f2f1f7e68535cdb33a5'}, 'duration': 0.3625810146331787, 'iteration': 6, 'loss': 0.14327485380116955, 'max_history_score': 0.928001375988992, 'max_history_score_std': 0.06518367535896959, 'max_history_step': 'joint', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 1, 'features__selectkbest__k': 2}), 'normalizer': ('normalizer_NoneType', {}), 'rebalance': ('rebalance_NoneType', {})}, 'score': 0.8567251461988304, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'entropy', 'max_depth': 3, 'max_features': 1, 'max_leaf_nodes': None, 'min_samples_split': 2, 'n_estimators': 75}, 'config_hash': {'algorithm': 'fb2f5d4c4d636edac929e1454ce3d02a4fb134c1', 'config': '3f83df36a6abbdf7ea4a4bdcaf6727f23529c2bb', 'pipeline': '8377b93e334656d1a93d266493b58ef9a6a1786f'}, 'duration': 0.8223779201507568, 'iteration': 7, 'loss': 0.03921568627450989, 'max_history_score': 0.9607843137254901, 'max_history_score_std': 0.043526663832084804, 'max_history_step': 'joint', 'pipeline': {'features': ('features_PCA', {'features__n_components': 3}), 'normalizer': ('normalizer_MinMaxScaler', {}), 'rebalance': ('rebalance_NearMiss', {'rebalance__n_neighbors': 1})}, 'score': 0.9607843137254901, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'gini', 'max_depth': 3, 'max_features': 3, 'max_leaf_nodes': 2, 'min_samples_split': 2, 'n_estimators': 100}, 'config_hash': {'algorithm': '3c3fde6559b918694de4668d025d5418342db1b1', 'config': '037fd5c655b39cc7922fb394d736496befcc747b', 'pipeline': '2a5032814c6c7ed21dd5bd9686923d7fc2f8acc9'}, 'duration': 1.0435099601745605, 'iteration': 8, 'loss': 0.09955925352597172, 'max_history_score': 0.9607843137254901, 'max_history_score_std': 0.043526663832084804, 'max_history_step': 'joint', 'pipeline': {'features': ('features_NoneType', {}), 'normalizer': ('normalizer_RobustScaler', {'normalizer__quantile_range': (...), 'normalizer__with_centering': True, 'normalizer__with_scaling': True}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 7})}, 'score': 0.9004407464740283, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': 2, 'max_features': 1, 'max_leaf_nodes': None, 'min_samples_split': 3, 'n_estimators': 75}, 'config_hash': {'algorithm': '42185be98371e99ac896d2c6c2d69c451cb983ff', 'config': '6609280032189b59de1afbe36f3acb1d5c273693', 'pipeline': '8aab2941fc84d84f86fa56134e50909dbf9e19f5'}, 'duration': 0.9665219783782959, 'iteration': 9, 'loss': 0.01637426900584804, 'max_history_score': 0.983625730994152, 'max_history_score_std': 0.025023500462379746, 'max_history_step': 'joint', 'pipeline': {'features': ('features_NoneType', {}), 'normalizer': ('normalizer_PowerTransformer', {}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 5})}, 'score': 0.983625730994152, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': 1, 'max_features': 3, 'max_leaf_nodes': 2, 'min_samples_split': 3, 'n_estimators': 10}, 'config_hash': {'algorithm': '62a9fe705e4cd96e762bcc9543c4a456a5a9f188', 'config': '8e1c17ac9f6e03740f380fccb833c9c3931ffc35', 'pipeline': '3d44d7482e468d08c4f94457a205f3dac74084c1'}, 'duration': 0.46930503845214844, 'iteration': 10, 'loss': 1.0, 'max_history_score': 0.983625730994152, 'max_history_score_std': 0.025023500462379746, 'max_history_step': 'joint', 'pipeline': {'features': ('features_PCA', {'features__n_components': 1}), 'normalizer': ('normalizer_NoneType', {}), 'rebalance': ('rebalance_CondensedNearestNeighbour', {'rebalance__n_neighbors': 3})}, 'score': 0.0, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'gini', 'max_depth': 4, 'max_features': 1, 'max_leaf_nodes': 3, 'min_samples_split': 2, 'n_estimators': 100}, 'config_hash': {'algorithm': '086d6ca939a757bb32edb113a567f9d38744f061', 'config': '87c03d0cb8e8500e58cacc1a0f27ce54c41a2937', 'pipeline': '8f28ef0f35d97142278f9dacb4e9d1ff082e470f'}, 'duration': 2.1196961402893066, 'iteration': 11, 'loss': 0.15471276229790154, 'max_history_score': 0.983625730994152, 'max_history_score_std': 0.025023500462379746, 'max_history_step': 'joint', 'pipeline': {'features': ('features_PCA', {'features__n_components': 1}), 'normalizer': ('normalizer_StandardScaler', {'normalizer__with_mean': True, 'normalizer__with_std': True}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 7})}, 'score': 0.8452872377020985, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'entropy', 'max_depth': 3, 'max_features': 1, 'max_leaf_nodes': 2, 'min_samples_split': 2, 'n_estimators': 25}, 'config_hash': {'algorithm': '59f64a966796648c7bebade1127fa05541b391ad', 'config': '2ab964abffa0a277a9e2ee9b5570cd258e428b62', 'pipeline': 'eef3f702fd2fed761fa6744c1640d0bf320f1d00'}, 'duration': 0.9828321933746338, 'iteration': 12, 'loss': 0.0778465772273822, 'max_history_score': 0.983625730994152, 'max_history_score_std': 0.025023500462379746, 'max_history_step': 'joint', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 3, 'features__selectkbest__k': 1}), 'normalizer': ('normalizer_PowerTransformer', {}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 6})}, 'score': 0.9221534227726178, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'gini', 'max_depth': 4, 'max_features': 2, 'max_leaf_nodes': 3, 'min_samples_split': 3, 'n_estimators': 75}, 'config_hash': {'algorithm': '6f75c2a196eb9836df2b424e095051192eaed6ea', 'config': '5c95db3ad238063227f1b36e6a006d70c834c5da', 'pipeline': '1eae01a1128bee425c4d4ca0ee97a9afd409680e'}, 'duration': 0.8217771053314209, 'iteration': 13, 'loss': 0.03863089095287242, 'max_history_score': 0.983625730994152, 'max_history_score_std': 0.025023500462379746, 'max_history_step': 'joint', 'pipeline': {'features': ('features_NoneType', {}), 'normalizer': ('normalizer_StandardScaler', {'normalizer__with_mean': False, 'normalizer__with_std': False}), 'rebalance': ('rebalance_NearMiss', {'rebalance__n_neighbors': 1})}, 'score': 0.9613691090471276, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'entropy', 'max_depth': 4, 'max_features': 2, 'max_leaf_nodes': 3, 'min_samples_split': 2, 'n_estimators': 25}, 'config_hash': {'algorithm': '8aef3174f6b8020de06b825e0424c1e54d690afd', 'config': '50fd1169b8e42190600f25152654254b5d0e3ed1', 'pipeline': '9ceaa544911dc6c687e336cb8e9dd4d15ff1ceaf'}, 'duration': 0.40307188034057617, 'iteration': 14, 'loss': 1.0, 'max_history_score': 0.983625730994152, 'max_history_score_std': 0.025023500462379746, 'max_history_step': 'joint', 'pipeline': {'features': ('features_PCA', {'features__n_components': 1}), 'normalizer': ('normalizer_RobustScaler', {'normalizer__quantile_range': (...), 'normalizer__with_centering': False, 'normalizer__with_scaling': False}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 7})}, 'score': 0.0, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'gini', 'max_depth': 1, 'max_features': 1, 'max_leaf_nodes': 3, 'min_samples_split': 3, 'n_estimators': 50}, 'config_hash': {'algorithm': '37be8b6737f4b5d5ae35da51886f302b07ba6001', 'config': 'a05b6d2ffd65d4d937c0b178655d857bf4d61410', 'pipeline': 'cfef88e895db321122f2f7b813d9267b973c2468'}, 'duration': 1.7094659805297852, 'iteration': 15, 'loss': 0.011111111111111072, 'max_history_score': 0.9888888888888889, 'max_history_score_std': 0.022222222222222233, 'max_history_step': 'joint', 'pipeline': {'features': ('features_NoneType', {}), 'normalizer': ('normalizer_NoneType', {}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 5})}, 'score': 0.9888888888888889, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'entropy', 'max_depth': None, 'max_features': 3, 'max_leaf_nodes': None, 'min_samples_split': 2, 'n_estimators': 100}, 'config_hash': {'algorithm': 'c40543ce91793e367c1892c886bc49621c22ecfb', 'config': 'ebebb7a93116f14f470e062e37582a59f4aeb0df', 'pipeline': 'b50c63e800574e8b760f55f7c4ff1fcae8816dd8'}, 'duration': 0.6425540447235107, 'iteration': 16, 'loss': 1.0, 'max_history_score': 0.9888888888888889, 'max_history_score_std': 0.022222222222222233, 'max_history_step': 'joint', 'pipeline': {'features': ('features_PCA', {'features__n_components': 1}), 'normalizer': ('normalizer_PowerTransformer', {}), 'rebalance': ('rebalance_NearMiss', {'rebalance__n_neighbors': 1})}, 'score': 0.0, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'gini', 'max_depth': None, 'max_features': 1, 'max_leaf_nodes': 3, 'min_samples_split': 2, 'n_estimators': 50}, 'config_hash': {'algorithm': '0c69b9601237c20664085fa05764d855e28f98f7', 'config': 'a2c21314ddbba47ddbfe416e0aa14853a71179e0', 'pipeline': '914f81fa4fbb61db251201f32bd8ea11bfeea2a5'}, 'duration': 2.2209739685058594, 'iteration': 17, 'loss': 0.3206720846233231, 'max_history_score': 0.9888888888888889, 'max_history_score_std': 0.022222222222222233, 'max_history_step': 'joint', 'pipeline': {'features': ('features_SelectKBest', {'features__k': 4}), 'normalizer': ('normalizer_PowerTransformer', {}), 'rebalance': ('rebalance_CondensedNearestNeighbour', {'rebalance__n_neighbors': 1})}, 'score': 0.6793279153766769, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': 4, 'max_features': None, 'max_leaf_nodes': None, 'min_samples_split': 3, 'n_estimators': 25}, 'config_hash': {'algorithm': '1aae0f1fce5cab293ffdd4581c4838c8051ac815', 'config': '6c8a721218e7c550a98c5ba72ad9ff86afd5e3a4', 'pipeline': '77189452469cef9c840643f2babe0f825c6667c8'}, 'duration': 0.3951280117034912, 'iteration': 18, 'loss': 0.1804760061919506, 'max_history_score': 0.9888888888888889, 'max_history_score_std': 0.022222222222222233, 'max_history_step': 'joint', 'pipeline': {'features': ('features_SelectKBest', {'features__k': 2}), 'normalizer': ('normalizer_NoneType', {}), 'rebalance': ('rebalance_NearMiss', {'rebalance__n_neighbors': 1})}, 'score': 0.8195239938080494, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': None, 'max_features': 3, 'max_leaf_nodes': 5, 'min_samples_split': 3, 'n_estimators': 50}, 'config_hash': {'algorithm': '0129970b8c7fe034ac8283fb518a06cfbead63d2', 'config': '61bcd2f64860b3dfe2503be88a6bbec165db0754', 'pipeline': '359f2473075ecfd9ae3ce526da96143918517601'}, 'duration': 0.7467091083526611, 'iteration': 19, 'loss': 0.09915720674234607, 'max_history_score': 0.9888888888888889, 'max_history_score_std': 0.022222222222222233, 'max_history_step': 'joint', 'pipeline': {'features': ('features_SelectKBest', {'features__k': 3}), 'normalizer': ('normalizer_RobustScaler', {'normalizer__quantile_range': (...), 'normalizer__with_centering': True, 'normalizer__with_scaling': False}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 7})}, 'score': 0.9008427932576539, ...}, ...], 'history_hash': ['2e6648b63441361b4398cb94f81d2e04a830b2ef', '584343bc020d2d7bc89bd0856bc7770dae1c84fc', 'de121d053e65def047cc8947f505578d5c5eab67', 'b21c9d15a389baa5bfea4c8ddcec129259f37540', 'edd3456355d80775739c31515c832ca7b4e5e094', '0800d7d2c8c10d2f9e7b4e5127b343e916eb742c', 'd98b641879b4754f2169335626a90575e945fd7c', '3f83df36a6abbdf7ea4a4bdcaf6727f23529c2bb', '037fd5c655b39cc7922fb394d736496befcc747b', '6609280032189b59de1afbe36f3acb1d5c273693', '8e1c17ac9f6e03740f380fccb833c9c3931ffc35', '87c03d0cb8e8500e58cacc1a0f27ce54c41a2937', '2ab964abffa0a277a9e2ee9b5570cd258e428b62', '5c95db3ad238063227f1b36e6a006d70c834c5da', '50fd1169b8e42190600f25152654254b5d0e3ed1', 'a05b6d2ffd65d4d937c0b178655d857bf4d61410', 'ebebb7a93116f14f470e062e37582a59f4aeb0df', 'a2c21314ddbba47ddbfe416e0aa14853a71179e0', '6c8a721218e7c550a98c5ba72ad9ff86afd5e3a4', '61bcd2f64860b3dfe2503be88a6bbec165db0754', ...], 'history_index': {'037fd5c655b39cc7922fb394d736496befcc747b': 8, '07fdf9d0d0248a4b0215a633c75a2dd101dcf465': 22, '0800d7d2c8c10d2f9e7b4e5127b343e916eb742c': 5, '0babf362e2373c001d4eb84f3c4eda27e56fe02d': 33, '0c9d6c44176dcc6b6ed48155a6e53130cb2c32e8': 45, '0e45095dfe50d5be759b179b50e63384925c7027': 32, '10bbd802ae07af833e53a3844fb056ba4016b893': 46, '2323c40e4e6c5f4aa333620a6b998b510ca41854': 35, '26ed0b67cf1046a22e2baba31b70ce3b6e762a03': 40, '28944b74104bc5bb782512b0eefa3167fe189355': 30, ...}, 'iteration': 48, 'max_history_score': 0.9944444444444445, 'max_history_score_std': 0.016666666666666673, 'max_history_step': 'joint'}, config={'algorithm': 'RandomForest', 'seed': 42, 'time': 300}, step='joint')
     45                 y,
     46                 cv=10,
     47                 n_jobs=-1,
     48                 return_estimator=False,
     49                 return_train_score=False,
---> 50                 verbose=0)
     51         score = np.mean(scores['test_score'])
     52         std = np.std(scores['test_score'])
     53         status = STATUS_OK
     54     except Exception as e:

...........................................................................
/home/aquemy/.local/lib/python2.7/site-packages/sklearn/model_selection/_validation.py in cross_validate(estimator=Pipeline(memory=None,
     steps=[('rebalance', ... random_state=42, verbose=0, warm_start=False))]), X=array([[1.423e+01, 1.710e+00, 2.430e+00, ..., 1...., ..., 6.100e-01, 1.600e+00,
        5.600e+02]]), y=array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,
       2, 2]), groups=None, scoring=None, cv=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1, verbose=0, fit_params=None, pre_dispatch='2*n_jobs', return_train_score=False, return_estimator=False, error_score='raise-deprecating')
    235         delayed(_fit_and_score)(
    236             clone(estimator), X, y, scorers, train, test, verbose, None,
    237             fit_params, return_train_score=return_train_score,
    238             return_times=True, return_estimator=return_estimator,
    239             error_score=error_score)
--> 240         for train, test in cv.split(X, y, groups))
        cv.split = <bound method StratifiedKFold.split of Stratifie...d(n_splits=10, random_state=None, shuffle=False)>
        X = array([[1.423e+01, 1.710e+00, 2.430e+00, ..., 1...., ..., 6.100e-01, 1.600e+00,
        5.600e+02]])
        y = array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,
       2, 2])
        groups = None
    241 
    242     zipped_scores = list(zip(*scores))
    243     if return_train_score:
    244         train_scores = zipped_scores.pop(0)

...........................................................................
/home/aquemy/.local/lib/python2.7/site-packages/sklearn/externals/joblib/parallel.py in __call__(self=Parallel(n_jobs=-1), iterable=<generator object <genexpr>>)
    925                 # No need to wait for async callbacks to trigger to
    926                 # consumption.
    927                 self._iterating = False
    928 
    929             with self._backend.retrieval_context():
--> 930                 self.retrieve()
        self.retrieve = <bound method Parallel.retrieve of Parallel(n_jobs=-1)>
    931             # Make sure that we get a last message telling us we are done
    932             elapsed_time = time.time() - self._start_time
    933             self._print('Done %3i out of %3i | elapsed: %s finished',
    934                         (len(self._output), len(self._output),

---------------------------------------------------------------------------
Joblib worker traceback:
---------------------------------------------------------------------------
ValueError                                         Mon Jun 17 12:46:01 2019
PID: 15341                                  Python 2.7.15+: /usr/bin/python
...........................................................................
/home/aquemy/.local/lib/python2.7/site-packages/sklearn/externals/joblib/parallel.py in __call__(self=<sklearn.externals.joblib.parallel.BatchedCalls object>)
    220     def __call__(self):
    221         # Set the default nested backend to self._backend but do not set the
    222         # change the default number of processes to -1
    223         with parallel_backend(self._backend, n_jobs=self._n_jobs):
    224             return [func(*args, **kwargs)
--> 225                     for func, args, kwargs in self.items]
        func = <function _fit_and_score>
        args = (Pipeline(memory=None,
     steps=[('rebalance', ... random_state=42, verbose=0, warm_start=False))]), array([[1.423e+01, 1.710e+00, 2.430e+00, ..., 1...., ..., 6.100e-01, 1.600e+00,
        5.600e+02]]), array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,
       2, 2]), {'score': <function _passthrough_scorer>}, array([  6,   7,   8,   9,  10,  11,  12,  13,  ..., 170, 171, 172, 173, 174,
       175, 176, 177]), array([  0,   1,   2,   3,   4,   5,  59,  60,  ...,  64,  65,
        66, 130, 131, 132, 133, 134]), 0, None, None)
        kwargs = {'error_score': 'raise-deprecating', 'return_estimator': False, 'return_times': True, 'return_train_score': False}
        self.items = [(<function _fit_and_score>, (Pipeline(memory=None,
     steps=[('rebalance', ... random_state=42, verbose=0, warm_start=False))]), array([[1.423e+01, 1.710e+00, 2.430e+00, ..., 1...., ..., 6.100e-01, 1.600e+00,
        5.600e+02]]), array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,
       2, 2]), {'score': <function _passthrough_scorer>}, array([  6,   7,   8,   9,  10,  11,  12,  13,  ..., 170, 171, 172, 173, 174,
       175, 176, 177]), array([  0,   1,   2,   3,   4,   5,  59,  60,  ...,  64,  65,
        66, 130, 131, 132, 133, 134]), 0, None, None), {'error_score': 'raise-deprecating', 'return_estimator': False, 'return_times': True, 'return_train_score': False})]
    226 
    227     def __len__(self):
    228         return self._size
    229 

...........................................................................
/home/aquemy/.local/lib/python2.7/site-packages/sklearn/model_selection/_validation.py in _fit_and_score(estimator=Pipeline(memory=None,
     steps=[('rebalance', ... random_state=42, verbose=0, warm_start=False))]), X=array([[1.423e+01, 1.710e+00, 2.430e+00, ..., 1...., ..., 6.100e-01, 1.600e+00,
        5.600e+02]]), y=array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,
       2, 2]), scorer={'score': <function _passthrough_scorer>}, train=array([  6,   7,   8,   9,  10,  11,  12,  13,  ..., 170, 171, 172, 173, 174,
       175, 176, 177]), test=array([  0,   1,   2,   3,   4,   5,  59,  60,  ...,  64,  65,
        66, 130, 131, 132, 133, 134]), verbose=0, parameters=None, fit_params={}, return_train_score=False, return_parameters=False, return_n_test_samples=False, return_times=True, return_estimator=False, error_score='raise-deprecating')
    523 
    524     try:
    525         if y_train is None:
    526             estimator.fit(X_train, **fit_params)
    527         else:
--> 528             estimator.fit(X_train, y_train, **fit_params)
        estimator.fit = <bound method Pipeline.fit of Pipeline(memory=No...random_state=42, verbose=0, warm_start=False))])>
        X_train = array([[1.439e+01, 1.870e+00, 2.450e+00, ..., 1...., ..., 6.100e-01, 1.600e+00,
        5.600e+02]])
        y_train = array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...2, 2, 2, 2, 2, 2, 2, 2, 2,
       2, 2, 2, 2, 2])
        fit_params = {}
    529 
    530     except Exception as e:
    531         # Note fit time as time until error
    532         fit_time = time.time() - start_time

...........................................................................
/usr/local/lib/python2.7/dist-packages/imblearn/pipeline.py in fit(self=Pipeline(memory=None,
     steps=[('rebalance', ... random_state=42, verbose=0, warm_start=False))]), X=array([[1.439e+01, 1.870e+00, 2.450e+00, ..., 1...., ..., 6.100e-01, 1.600e+00,
        5.600e+02]]), y=array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...2, 2, 2, 2, 2, 2, 2, 2, 2,
       2, 2, 2, 2, 2]), **fit_params={})
    234             This estimator
    235 
    236         """
    237         Xt, yt, fit_params = self._fit(X, y, **fit_params)
    238         if self._final_estimator is not None:
--> 239             self._final_estimator.fit(Xt, yt, **fit_params)
        self._final_estimator.fit = <bound method RandomForestClassifier.fit of Rand...e, random_state=42, verbose=0, warm_start=False)>
        Xt = array([[-1.49671333e-01, -3.67009150e-02],
     ...-01],
       [ 7.12877536e-01, -4.42945906e-01]])
        yt = array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,... 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2])
        fit_params = {}
    240         return self
    241 
    242     def fit_transform(self, X, y=None, **fit_params):
    243         """Fit the model and transform with the final estimator

...........................................................................
/home/aquemy/.local/lib/python2.7/site-packages/sklearn/ensemble/forest.py in fit(self=RandomForestClassifier(bootstrap=False, class_we...se, random_state=42, verbose=0, warm_start=False), X=array([[-1.49671331e-01, -3.67009155e-02],
     ...7.12877512e-01, -4.42945898e-01]], dtype=float32), y=array([[0.],
       [0.],
       [0.],
       [0...    [2.],
       [2.],
       [2.],
       [2.]]), sample_weight=None)
    328             trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,
    329                              **_joblib_parallel_args(prefer='threads'))(
    330                 delayed(_parallel_build_trees)(
    331                     t, self, X, y, sample_weight, i, len(trees),
    332                     verbose=self.verbose, class_weight=self.class_weight)
--> 333                 for i, t in enumerate(trees))
        i = 99
    334 
    335             # Collect newly grown trees
    336             self.estimators_.extend(trees)
    337 

...........................................................................
/home/aquemy/.local/lib/python2.7/site-packages/sklearn/externals/joblib/parallel.py in __call__(self=Parallel(n_jobs=1), iterable=<generator object <genexpr>>)
    912             # self._original_iterator is None, then this means either
    913             # that pre_dispatch == "all", n_jobs == 1 or that the first batch
    914             # was very quick and its callback already dispatched all the
    915             # remaining jobs.
    916             self._iterating = False
--> 917             if self.dispatch_one_batch(iterator):
        self.dispatch_one_batch = <bound method Parallel.dispatch_one_batch of Parallel(n_jobs=1)>
        iterator = <generator object <genexpr>>
    918                 self._iterating = self._original_iterator is not None
    919 
    920             while self.dispatch_one_batch(iterator):
    921                 pass

...........................................................................
/home/aquemy/.local/lib/python2.7/site-packages/sklearn/externals/joblib/parallel.py in dispatch_one_batch(self=Parallel(n_jobs=1), iterator=<generator object <genexpr>>)
    754                                  self._pickle_cache)
    755             if len(tasks) == 0:
    756                 # No more tasks available in the iterator: tell caller to stop.
    757                 return False
    758             else:
--> 759                 self._dispatch(tasks)
        self._dispatch = <bound method Parallel._dispatch of Parallel(n_jobs=1)>
        tasks = <sklearn.externals.joblib.parallel.BatchedCalls object>
    760                 return True
    761 
    762     def _print(self, msg, msg_args):
    763         """Display the message on stout or stderr depending on verbosity"""

...........................................................................
/home/aquemy/.local/lib/python2.7/site-packages/sklearn/externals/joblib/parallel.py in _dispatch(self=Parallel(n_jobs=1), batch=<sklearn.externals.joblib.parallel.BatchedCalls object>)
    711 
    712         dispatch_timestamp = time.time()
    713         cb = BatchCompletionCallBack(dispatch_timestamp, len(batch), self)
    714         with self._lock:
    715             job_idx = len(self._jobs)
--> 716             job = self._backend.apply_async(batch, callback=cb)
        job = undefined
        self._backend.apply_async = <bound method SequentialBackend.apply_async of <...lib._parallel_backends.SequentialBackend object>>
        batch = <sklearn.externals.joblib.parallel.BatchedCalls object>
        cb = <sklearn.externals.joblib.parallel.BatchCompletionCallBack object>
    717             # A job can complete so quickly than its callback is
    718             # called before we get here, causing self._jobs to
    719             # grow. To ensure correct results ordering, .insert is
    720             # used (rather than .append) in the following line

...........................................................................
/home/aquemy/.local/lib/python2.7/site-packages/sklearn/externals/joblib/_parallel_backends.py in apply_async(self=<sklearn.externals.joblib._parallel_backends.SequentialBackend object>, func=<sklearn.externals.joblib.parallel.BatchedCalls object>, callback=<sklearn.externals.joblib.parallel.BatchCompletionCallBack object>)
    177             raise ValueError('n_jobs == 0 in Parallel has no meaning')
    178         return 1
    179 
    180     def apply_async(self, func, callback=None):
    181         """Schedule a func to be run"""
--> 182         result = ImmediateResult(func)
        result = undefined
        func = <sklearn.externals.joblib.parallel.BatchedCalls object>
    183         if callback:
    184             callback(result)
    185         return result
    186 

...........................................................................
/home/aquemy/.local/lib/python2.7/site-packages/sklearn/externals/joblib/_parallel_backends.py in __init__(self=<sklearn.externals.joblib._parallel_backends.ImmediateResult object>, batch=<sklearn.externals.joblib.parallel.BatchedCalls object>)
    544 
    545 class ImmediateResult(object):
    546     def __init__(self, batch):
    547         # Don't delay the application, to avoid keeping the input
    548         # arguments in memory
--> 549         self.results = batch()
        self.results = undefined
        batch = <sklearn.externals.joblib.parallel.BatchedCalls object>
    550 
    551     def get(self):
    552         return self.results
    553 

...........................................................................
/home/aquemy/.local/lib/python2.7/site-packages/sklearn/externals/joblib/parallel.py in __call__(self=<sklearn.externals.joblib.parallel.BatchedCalls object>)
    220     def __call__(self):
    221         # Set the default nested backend to self._backend but do not set the
    222         # change the default number of processes to -1
    223         with parallel_backend(self._backend, n_jobs=self._n_jobs):
    224             return [func(*args, **kwargs)
--> 225                     for func, args, kwargs in self.items]
        func = <function _parallel_build_trees>
        args = (DecisionTreeClassifier(class_weight=None, criter...=False, random_state=1608637542, splitter='best'), RandomForestClassifier(bootstrap=False, class_we...se, random_state=42, verbose=0, warm_start=False), array([[-1.49671331e-01, -3.67009155e-02],
     ...7.12877512e-01, -4.42945898e-01]], dtype=float32), array([[0.],
       [0.],
       [0.],
       [0...    [2.],
       [2.],
       [2.],
       [2.]]), None, 0, 100)
        kwargs = {'class_weight': None, 'verbose': 0}
        self.items = [(<function _parallel_build_trees>, (DecisionTreeClassifier(class_weight=None, criter...=False, random_state=1608637542, splitter='best'), RandomForestClassifier(bootstrap=False, class_we...se, random_state=42, verbose=0, warm_start=False), array([[-1.49671331e-01, -3.67009155e-02],
     ...7.12877512e-01, -4.42945898e-01]], dtype=float32), array([[0.],
       [0.],
       [0.],
       [0...    [2.],
       [2.],
       [2.],
       [2.]]), None, 0, 100), {'class_weight': None, 'verbose': 0})]
    226 
    227     def __len__(self):
    228         return self._size
    229 

...........................................................................
/home/aquemy/.local/lib/python2.7/site-packages/sklearn/ensemble/forest.py in _parallel_build_trees(tree=DecisionTreeClassifier(class_weight=None, criter...=False, random_state=1608637542, splitter='best'), forest=RandomForestClassifier(bootstrap=False, class_we...se, random_state=42, verbose=0, warm_start=False), X=array([[-1.49671331e-01, -3.67009155e-02],
     ...7.12877512e-01, -4.42945898e-01]], dtype=float32), y=array([[0.],
       [0.],
       [0.],
       [0...    [2.],
       [2.],
       [2.],
       [2.]]), sample_weight=None, tree_idx=0, n_trees=100, verbose=0, class_weight=None)
    116         elif class_weight == 'balanced_subsample':
    117             curr_sample_weight *= compute_sample_weight('balanced', y, indices)
    118 
    119         tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)
    120     else:
--> 121         tree.fit(X, y, sample_weight=sample_weight, check_input=False)
        tree.fit = <bound method DecisionTreeClassifier.fit of Deci...False, random_state=1608637542, splitter='best')>
        X = array([[-1.49671331e-01, -3.67009155e-02],
     ...7.12877512e-01, -4.42945898e-01]], dtype=float32)
        y = array([[0.],
       [0.],
       [0.],
       [0...    [2.],
       [2.],
       [2.],
       [2.]])
        sample_weight = None
    122 
    123     return tree
    124 
    125 

...........................................................................
/home/aquemy/.local/lib/python2.7/site-packages/sklearn/tree/tree.py in fit(self=DecisionTreeClassifier(class_weight=None, criter...=False, random_state=1608637542, splitter='best'), X=array([[-1.49671331e-01, -3.67009155e-02],
     ...7.12877512e-01, -4.42945898e-01]], dtype=float32), y=array([[0.],
       [0.],
       [0.],
       [0...    [2.],
       [2.],
       [2.],
       [2.]]), sample_weight=None, check_input=False, X_idx_sorted=None)
    796 
    797         super(DecisionTreeClassifier, self).fit(
    798             X, y,
    799             sample_weight=sample_weight,
    800             check_input=check_input,
--> 801             X_idx_sorted=X_idx_sorted)
        X_idx_sorted = None
    802         return self
    803 
    804     def predict_proba(self, X, check_input=True):
    805         """Predict class probabilities of the input samples X.

...........................................................................
/home/aquemy/.local/lib/python2.7/site-packages/sklearn/tree/tree.py in fit(self=DecisionTreeClassifier(class_weight=None, criter...=False, random_state=1608637542, splitter='best'), X=array([[-1.49671331e-01, -3.67009155e-02],
     ...7.12877512e-01, -4.42945898e-01]], dtype=float32), y=array([[0.],
       [0.],
       [0.],
       [0...    [2.],
       [2.],
       [2.],
       [2.]]), sample_weight=None, check_input=False, X_idx_sorted=None)
    237         if not 0 <= self.min_weight_fraction_leaf <= 0.5:
    238             raise ValueError("min_weight_fraction_leaf must in [0, 0.5]")
    239         if max_depth <= 0:
    240             raise ValueError("max_depth must be greater than zero. ")
    241         if not (0 < max_features <= self.n_features_):
--> 242             raise ValueError("max_features must be in (0, n_features]")
    243         if not isinstance(max_leaf_nodes, (numbers.Integral, np.integer)):
    244             raise ValueError("max_leaf_nodes must be integral number but was "
    245                              "%r" % max_leaf_nodes)
    246         if -1 < max_leaf_nodes < 2:

ValueError: max_features must be in (0, n_features]
___________________________________________________________________________
Best score: 0.994444444444 (0.0166666666667) [J] | Score: 0.0 (0.0) [J]
Best score: 0.994444444444 (0.0166666666667) [J] | Score: 0.921895424837 (0.0792636936865) [J]
Best score: 0.994444444444 (0.0166666666667) [J] | Score: 0.878035775714 (0.0645861795518) [J]
Best score: 0.994444444444 (0.0166666666667) [J] | Score: 0.94470244238 (0.0490772839771) [J]
JoblibValueError
___________________________________________________________________________
...........................................................................
/home/aquemy/dev/dp_hyperparameters/extension/main.py in <module>()
     27 
     28     serializer.serialize_results(scenario, policy)
     29 
     30 if __name__ == "__main__":
     31     args = cli.parse_args()
---> 32     main(args)

...........................................................................
/home/aquemy/dev/dp_hyperparameters/extension/main.py in main(args=Namespace(customize=[(['control', 'seed'], '42')...io='./scenarios/rf_wine_joint.yaml', verbosity=0))
     21         test_size=0.4, 
     22         random_state=scenario['control']['seed']
     23     )
     24 
     25     policy = policies.initiate(scenario['setup']['policy'], config)
---> 26     policy.run(X,y)
        policy.run = <bound method Joint.run of <experiment.policies.joint.Joint object>>
        X = array([[1.423e+01, 1.710e+00, 2.430e+00, ..., 1...., ..., 6.100e-01, 1.600e+00,
        5.600e+02]])
        y = array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,
       2, 2])
     27 
     28     serializer.serialize_results(scenario, policy)
     29 
     30 if __name__ == "__main__":

...........................................................................
/home/aquemy/dev/dp_hyperparameters/extension/experiment/policies/joint.py in run(self=<experiment.policies.joint.Joint object>, X=array([[1.423e+01, 1.710e+00, 2.430e+00, ..., 1...., ..., 6.100e-01, 1.600e+00,
        5.600e+02]]), y=array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,
       2, 2]))
     32             algo=tpe.suggest, 
     33             max_evals=None,
     34             max_time=self.config['time'],     
     35             trials=trials,
     36             show_progressbar=False,
---> 37             verbose=0
     38         )
     39 
     40         best_config = self.context['best_config']
     41         super(Joint, self).display_step_results(best_config)

...........................................................................
/home/aquemy/dev/dp_hyperparameters/extension/hyperopt/fmin.py in fmin(fn=<functools.partial object>, space={'algorithm': {'bootstrap': <hyperopt.pyll.base.Apply object>, 'criterion': <hyperopt.pyll.base.Apply object>, 'max_depth': <hyperopt.pyll.base.Apply object>, 'max_features': <hyperopt.pyll.base.Apply object>, 'max_leaf_nodes': <hyperopt.pyll.base.Apply object>, 'min_samples_split': <hyperopt.pyll.base.Apply object>, 'n_estimators': <hyperopt.pyll.base.Apply object>}, 'pipeline': {'features': <hyperopt.pyll.base.Apply object>, 'normalizer': <hyperopt.pyll.base.Apply object>, 'rebalance': <hyperopt.pyll.base.Apply object>}}, algo=<function suggest>, max_evals=9223372036854775807, max_time=300, trials=<hyperopt.base.Trials object>, rstate=<mtrand.RandomState object>, allow_trials_fmin=True, pass_expr_memo_ctrl=None, catch_eval_exceptions=False, verbose=0, return_argmin=True, points_to_evaluate=None, max_queue_len=1, show_progressbar=False)
    406             pass_expr_memo_ctrl=pass_expr_memo_ctrl,
    407             verbose=verbose,
    408             catch_eval_exceptions=catch_eval_exceptions,
    409             return_argmin=return_argmin,
    410             show_progressbar=show_progressbar,
--> 411             max_time=max_time
        max_time = 300
    412         )
    413 
    414     if trials is None:
    415         if points_to_evaluate is None:

...........................................................................
/home/aquemy/dev/dp_hyperparameters/extension/hyperopt/base.py in fmin(self=<hyperopt.base.Trials object>, fn=<functools.partial object>, space={'algorithm': {'bootstrap': <hyperopt.pyll.base.Apply object>, 'criterion': <hyperopt.pyll.base.Apply object>, 'max_depth': <hyperopt.pyll.base.Apply object>, 'max_features': <hyperopt.pyll.base.Apply object>, 'max_leaf_nodes': <hyperopt.pyll.base.Apply object>, 'min_samples_split': <hyperopt.pyll.base.Apply object>, 'n_estimators': <hyperopt.pyll.base.Apply object>}, 'pipeline': {'features': <hyperopt.pyll.base.Apply object>, 'normalizer': <hyperopt.pyll.base.Apply object>, 'rebalance': <hyperopt.pyll.base.Apply object>}}, algo=<function suggest>, max_evals=9223372036854775807, max_time=300, rstate=<mtrand.RandomState object>, verbose=0, pass_expr_memo_ctrl=None, catch_eval_exceptions=False, return_argmin=True, show_progressbar=False)
    636             verbose=verbose,
    637             allow_trials_fmin=False,  # -- prevent recursion
    638             pass_expr_memo_ctrl=pass_expr_memo_ctrl,
    639             catch_eval_exceptions=catch_eval_exceptions,
    640             return_argmin=return_argmin,
--> 641             show_progressbar=show_progressbar)
        show_progressbar = False
    642 
    643 
    644 def trials_from_docs(docs, validate=True, **kwargs):
    645     """Construct a Trials base class instance from a list of trials documents

...........................................................................
/home/aquemy/dev/dp_hyperparameters/extension/hyperopt/fmin.py in fmin(fn=<functools.partial object>, space={'algorithm': {'bootstrap': <hyperopt.pyll.base.Apply object>, 'criterion': <hyperopt.pyll.base.Apply object>, 'max_depth': <hyperopt.pyll.base.Apply object>, 'max_features': <hyperopt.pyll.base.Apply object>, 'max_leaf_nodes': <hyperopt.pyll.base.Apply object>, 'min_samples_split': <hyperopt.pyll.base.Apply object>, 'n_estimators': <hyperopt.pyll.base.Apply object>}, 'pipeline': {'features': <hyperopt.pyll.base.Apply object>, 'normalizer': <hyperopt.pyll.base.Apply object>, 'rebalance': <hyperopt.pyll.base.Apply object>}}, algo=<function suggest>, max_evals=9223372036854775807, max_time=300, trials=<hyperopt.base.Trials object>, rstate=<mtrand.RandomState object>, allow_trials_fmin=False, pass_expr_memo_ctrl=None, catch_eval_exceptions=False, verbose=0, return_argmin=True, points_to_evaluate=None, max_queue_len=1, show_progressbar=False)
    426                     verbose=verbose,
    427                     max_queue_len=max_queue_len,
    428                     show_progressbar=show_progressbar,
    429                     max_time=max_time)
    430     rval.catch_eval_exceptions = catch_eval_exceptions
--> 431     rval.exhaust()
        rval.exhaust = <bound method FMinIter.exhaust of <hyperopt.fmin.FMinIter object>>
    432     if return_argmin:
    433         return trials.argmin
    434     elif len(trials) > 0:
    435         # Only if there are some succesfull trail runs, return the best point in the evaluation space

...........................................................................
/home/aquemy/dev/dp_hyperparameters/extension/hyperopt/fmin.py in exhaust(self=<hyperopt.fmin.FMinIter object>)
    273             raise StopIteration()
    274         return self.trials
    275 
    276     def exhaust(self):
    277         n_done = len(self.trials)
--> 278         self.run(self.max_evals - n_done, block_until_done=self.asynchronous)
        self.run = <bound method FMinIter.run of <hyperopt.fmin.FMinIter object>>
        self.max_evals = 9223372036854775807
        n_done = 0
        self.asynchronous = False
    279         self.trials.refresh()
    280         return self
    281 
    282 

...........................................................................
/home/aquemy/dev/dp_hyperparameters/extension/hyperopt/fmin.py in run(self=<hyperopt.fmin.FMinIter object>, N=9223372036854775807, block_until_done=False)
    232                     if self.asynchronous:
    233                         # -- wait for workers to fill in the trials
    234                         time.sleep(self.poll_interval_secs)
    235                     else:
    236                         # -- loop over trials and do the jobs directly
--> 237                         self.serial_evaluate()
        self.serial_evaluate = <bound method FMinIter.serial_evaluate of <hyperopt.fmin.FMinIter object>>
    238                     try:
    239                         res = [d['result']['loss'] for d in
    240                                          self.trials.trials if
    241                                          d['result']['status'] == 'ok']

...........................................................................
/home/aquemy/dev/dp_hyperparameters/extension/hyperopt/fmin.py in serial_evaluate(self=<hyperopt.fmin.FMinIter object>, N=-1)
    138                 trial['book_time'] = now
    139                 trial['refresh_time'] = now
    140                 spec = base.spec_from_misc(trial['misc'])
    141                 ctrl = base.Ctrl(self.trials, current_trial=trial)
    142                 try:
--> 143                     result = self.domain.evaluate(spec, ctrl)
        result = undefined
        self.domain.evaluate = <bound method Domain.evaluate of <hyperopt.base.Domain object>>
        spec = {'bootstrap': 0, 'criterion': 0, 'features': 2, 'features_SelectKBest_features__k': 0, 'max_depth': 0, 'max_features': 2, 'max_leaf_nodes': 1, 'min_samples_split': 1, 'n_estimators': 2, 'normalizer': 1, ...}
        ctrl = <hyperopt.base.Ctrl object>
    144                 except Exception as e:
    145                     logger.info('job exception: %s' % str(e))
    146                     trial['state'] = base.JOB_STATE_ERROR
    147                     trial['misc']['error'] = (str(type(e)), str(e))

...........................................................................
/home/aquemy/dev/dp_hyperparameters/extension/hyperopt/base.py in evaluate(self=<hyperopt.base.Domain object>, config={'bootstrap': 0, 'criterion': 0, 'features': 2, 'features_SelectKBest_features__k': 0, 'max_depth': 0, 'max_features': 2, 'max_leaf_nodes': 1, 'min_samples_split': 1, 'n_estimators': 2, 'normalizer': 1, ...}, ctrl=<hyperopt.base.Ctrl object>, attach_attachments=True)
    841             #    or the normal Python part (self.fn)
    842             pyll_rval = pyll.rec_eval(
    843                 self.expr,
    844                 memo=memo,
    845                 print_node_on_error=self.rec_eval_print_node_on_error)
--> 846             rval = self.fn(pyll_rval)
        rval = undefined
        self.fn = <functools.partial object>
        pyll_rval = {'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': 1, 'max_features': 3, 'max_leaf_nodes': 3, 'min_samples_split': 3, 'n_estimators': 50}, 'pipeline': {'features': ('features_SelectKBest', {'features__k': 1}), 'normalizer': ('normalizer_StandardScaler', {'normalizer__with_mean': True, 'normalizer__with_std': True}), 'rebalance': ('rebalance_NearMiss', {'rebalance__n_neighbors': 2})}}
    847 
    848         if isinstance(rval, (float, int, np.number)):
    849             dict_rval = {'loss': float(rval), 'status': STATUS_OK}
    850         else:

...........................................................................
/home/aquemy/dev/dp_hyperparameters/extension/experiment/objective.py in objective_joint(wconfig={'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': 1, 'max_features': 3, 'max_leaf_nodes': 3, 'min_samples_split': 3, 'n_estimators': 50}, 'pipeline': {'features': ('features_SelectKBest', {'features__k': 1}), 'normalizer': ('normalizer_StandardScaler', {'normalizer__with_mean': True, 'normalizer__with_std': True}), 'rebalance': ('rebalance_NearMiss', {'rebalance__n_neighbors': 2})}}, algorithm='RandomForest', X=array([[1.423e+01, 1.710e+00, 2.430e+00, ..., 1...., ..., 6.100e-01, 1.600e+00,
        5.600e+02]]), y=array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,
       2, 2]), context={'baseline_score': 0.9444100447196423, 'baseline_score_std': 0.04305547117084885, 'best_config': {'algorithm': {'bootstrap': False, 'criterion': 'gini', 'max_depth': 1, 'max_features': 1, 'max_leaf_nodes': 3, 'min_samples_split': 5, 'n_estimators': 50}, 'config_hash': {'algorithm': 'cefc05c6c759dc564d289289fe401e0f8737951d', 'config': '7a1c40755d84d62f5d2ab1ed021e7dff93dfce45', 'pipeline': '3ee6a915db2d8d71f204c103803fb8eabea0d54f'}, 'duration': 0.6908998489379883, 'iteration': 24, 'loss': 0.005555555555555536, 'max_history_score': 0.9944444444444445, 'max_history_score_std': 0.016666666666666673, 'max_history_step': 'joint', 'pipeline': {'features': ('features_NoneType', {}), 'normalizer': ('normalizer_MinMaxScaler', {}), 'rebalance': ('rebalance_NoneType', {})}, 'score': 0.9944444444444445, ...}, 'history': [{'algorithm': {'bootstrap': False, 'criterion': 'entropy', 'max_depth': None, 'max_features': 3, 'max_leaf_nodes': 5, 'min_samples_split': 2, 'n_estimators': 50}, 'config_hash': {'algorithm': 'b2c6464add7a35ce8048653a39338c9994de9a4f', 'config': '2e6648b63441361b4398cb94f81d2e04a830b2ef', 'pipeline': '3d44d7482e468d08c4f94457a205f3dac74084c1'}, 'duration': 0.737678050994873, 'iteration': 0, 'loss': 1.0, 'max_history_score': 0.0, 'max_history_score_std': 0.0, 'max_history_step': 'baseline', 'pipeline': {'features': ('features_PCA', {'features__n_components': 1}), 'normalizer': ('normalizer_NoneType', {}), 'rebalance': ('rebalance_CondensedNearestNeighbour', {'rebalance__n_neighbors': 3})}, 'score': 0.0, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'gini', 'max_depth': 1, 'max_features': None, 'max_leaf_nodes': 2, 'min_samples_split': 3, 'n_estimators': 25}, 'config_hash': {'algorithm': '7f71bbbfdb4e8da52b6fc33a43224183117de15e', 'config': '584343bc020d2d7bc89bd0856bc7770dae1c84fc', 'pipeline': '466ffa7ace0e442beb7c311eb214b17a4c6832b3'}, 'duration': 1.5976769924163818, 'iteration': 1, 'loss': 0.40386351909184726, 'max_history_score': 0.5961364809081527, 'max_history_score_std': 0.05351463210025494, 'max_history_step': 'joint', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 3, 'features__selectkbest__k': 3}), 'normalizer': ('normalizer_StandardScaler', {'normalizer__with_mean': True, 'normalizer__with_std': True}), 'rebalance': ('rebalance_NearMiss', {'rebalance__n_neighbors': 2})}, 'score': 0.5961364809081527, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'entropy', 'max_depth': 1, 'max_features': 2, 'max_leaf_nodes': 2, 'min_samples_split': 5, 'n_estimators': 25}, 'config_hash': {'algorithm': '897745a20d929d43e760cacee0a764bd8070daa5', 'config': 'de121d053e65def047cc8947f505578d5c5eab67', 'pipeline': '63040b39b48626a8232e847e8327bdca5cd88611'}, 'duration': 0.815453052520752, 'iteration': 2, 'loss': 0.07327786377708967, 'max_history_score': 0.9267221362229103, 'max_history_score_std': 0.043920207373658794, 'max_history_step': 'joint', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 3, 'features__selectkbest__k': 2}), 'normalizer': ('normalizer_StandardScaler', {'normalizer__with_mean': True, 'normalizer__with_std': True}), 'rebalance': ('rebalance_NoneType', {})}, 'score': 0.9267221362229103, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'entropy', 'max_depth': 4, 'max_features': 3, 'max_leaf_nodes': None, 'min_samples_split': 2, 'n_estimators': 100}, 'config_hash': {'algorithm': 'dbd92c75280ec06b66ca4ad9b135cf36957031a4', 'config': 'b21c9d15a389baa5bfea4c8ddcec129259f37540', 'pipeline': '38866720d2f120c863351493b9b4e23b9a4506dc'}, 'duration': 1.2293269634246826, 'iteration': 3, 'loss': 0.07199862401100798, 'max_history_score': 0.928001375988992, 'max_history_score_std': 0.06518367535896959, 'max_history_step': 'joint', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 2, 'features__selectkbest__k': 4}), 'normalizer': ('normalizer_NoneType', {}), 'rebalance': ('rebalance_NoneType', {})}, 'score': 0.928001375988992, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': 2, 'max_features': None, 'max_leaf_nodes': None, 'min_samples_split': 5, 'n_estimators': 100}, 'config_hash': {'algorithm': 'f455eefd9fdd03ece88892c3f440c580bdf27ddb', 'config': 'edd3456355d80775739c31515c832ca7b4e5e094', 'pipeline': '1d1034f9f0871e43f896c1db4ed6fd572ed0a6ef'}, 'duration': 1.6186630725860596, 'iteration': 4, 'loss': 0.16651831785345705, 'max_history_score': 0.928001375988992, 'max_history_score_std': 0.06518367535896959, 'max_history_step': 'joint', 'pipeline': {'features': ('features_SelectKBest', {'features__k': 4}), 'normalizer': ('normalizer_MinMaxScaler', {}), 'rebalance': ('rebalance_CondensedNearestNeighbour', {'rebalance__n_neighbors': 1})}, 'score': 0.833481682146543, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'entropy', 'max_depth': 1, 'max_features': 2, 'max_leaf_nodes': None, 'min_samples_split': 2, 'n_estimators': 10}, 'config_hash': {'algorithm': '29906eaa0712a68ea145b12821d54ba445726fbf', 'config': '0800d7d2c8c10d2f9e7b4e5127b343e916eb742c', 'pipeline': '2e0f188ae61600352a7159285e0f542b4587a403'}, 'duration': 0.19410085678100586, 'iteration': 5, 'loss': 0.20164258685930514, 'max_history_score': 0.928001375988992, 'max_history_score_std': 0.06518367535896959, 'max_history_step': 'joint', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 3, 'features__selectkbest__k': 4}), 'normalizer': ('normalizer_StandardScaler', {'normalizer__with_mean': True, 'normalizer__with_std': False}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 7})}, 'score': 0.7983574131406949, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': 1, 'max_features': 1, 'max_leaf_nodes': 5, 'min_samples_split': 2, 'n_estimators': 25}, 'config_hash': {'algorithm': 'fbb7d57e38cfc08240f0af985282da418cb33556', 'config': 'd98b641879b4754f2169335626a90575e945fd7c', 'pipeline': '62463de065924498cdcd2f2f1f7e68535cdb33a5'}, 'duration': 0.3625810146331787, 'iteration': 6, 'loss': 0.14327485380116955, 'max_history_score': 0.928001375988992, 'max_history_score_std': 0.06518367535896959, 'max_history_step': 'joint', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 1, 'features__selectkbest__k': 2}), 'normalizer': ('normalizer_NoneType', {}), 'rebalance': ('rebalance_NoneType', {})}, 'score': 0.8567251461988304, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'entropy', 'max_depth': 3, 'max_features': 1, 'max_leaf_nodes': None, 'min_samples_split': 2, 'n_estimators': 75}, 'config_hash': {'algorithm': 'fb2f5d4c4d636edac929e1454ce3d02a4fb134c1', 'config': '3f83df36a6abbdf7ea4a4bdcaf6727f23529c2bb', 'pipeline': '8377b93e334656d1a93d266493b58ef9a6a1786f'}, 'duration': 0.8223779201507568, 'iteration': 7, 'loss': 0.03921568627450989, 'max_history_score': 0.9607843137254901, 'max_history_score_std': 0.043526663832084804, 'max_history_step': 'joint', 'pipeline': {'features': ('features_PCA', {'features__n_components': 3}), 'normalizer': ('normalizer_MinMaxScaler', {}), 'rebalance': ('rebalance_NearMiss', {'rebalance__n_neighbors': 1})}, 'score': 0.9607843137254901, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'gini', 'max_depth': 3, 'max_features': 3, 'max_leaf_nodes': 2, 'min_samples_split': 2, 'n_estimators': 100}, 'config_hash': {'algorithm': '3c3fde6559b918694de4668d025d5418342db1b1', 'config': '037fd5c655b39cc7922fb394d736496befcc747b', 'pipeline': '2a5032814c6c7ed21dd5bd9686923d7fc2f8acc9'}, 'duration': 1.0435099601745605, 'iteration': 8, 'loss': 0.09955925352597172, 'max_history_score': 0.9607843137254901, 'max_history_score_std': 0.043526663832084804, 'max_history_step': 'joint', 'pipeline': {'features': ('features_NoneType', {}), 'normalizer': ('normalizer_RobustScaler', {'normalizer__quantile_range': (...), 'normalizer__with_centering': True, 'normalizer__with_scaling': True}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 7})}, 'score': 0.9004407464740283, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': 2, 'max_features': 1, 'max_leaf_nodes': None, 'min_samples_split': 3, 'n_estimators': 75}, 'config_hash': {'algorithm': '42185be98371e99ac896d2c6c2d69c451cb983ff', 'config': '6609280032189b59de1afbe36f3acb1d5c273693', 'pipeline': '8aab2941fc84d84f86fa56134e50909dbf9e19f5'}, 'duration': 0.9665219783782959, 'iteration': 9, 'loss': 0.01637426900584804, 'max_history_score': 0.983625730994152, 'max_history_score_std': 0.025023500462379746, 'max_history_step': 'joint', 'pipeline': {'features': ('features_NoneType', {}), 'normalizer': ('normalizer_PowerTransformer', {}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 5})}, 'score': 0.983625730994152, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': 1, 'max_features': 3, 'max_leaf_nodes': 2, 'min_samples_split': 3, 'n_estimators': 10}, 'config_hash': {'algorithm': '62a9fe705e4cd96e762bcc9543c4a456a5a9f188', 'config': '8e1c17ac9f6e03740f380fccb833c9c3931ffc35', 'pipeline': '3d44d7482e468d08c4f94457a205f3dac74084c1'}, 'duration': 0.46930503845214844, 'iteration': 10, 'loss': 1.0, 'max_history_score': 0.983625730994152, 'max_history_score_std': 0.025023500462379746, 'max_history_step': 'joint', 'pipeline': {'features': ('features_PCA', {'features__n_components': 1}), 'normalizer': ('normalizer_NoneType', {}), 'rebalance': ('rebalance_CondensedNearestNeighbour', {'rebalance__n_neighbors': 3})}, 'score': 0.0, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'gini', 'max_depth': 4, 'max_features': 1, 'max_leaf_nodes': 3, 'min_samples_split': 2, 'n_estimators': 100}, 'config_hash': {'algorithm': '086d6ca939a757bb32edb113a567f9d38744f061', 'config': '87c03d0cb8e8500e58cacc1a0f27ce54c41a2937', 'pipeline': '8f28ef0f35d97142278f9dacb4e9d1ff082e470f'}, 'duration': 2.1196961402893066, 'iteration': 11, 'loss': 0.15471276229790154, 'max_history_score': 0.983625730994152, 'max_history_score_std': 0.025023500462379746, 'max_history_step': 'joint', 'pipeline': {'features': ('features_PCA', {'features__n_components': 1}), 'normalizer': ('normalizer_StandardScaler', {'normalizer__with_mean': True, 'normalizer__with_std': True}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 7})}, 'score': 0.8452872377020985, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'entropy', 'max_depth': 3, 'max_features': 1, 'max_leaf_nodes': 2, 'min_samples_split': 2, 'n_estimators': 25}, 'config_hash': {'algorithm': '59f64a966796648c7bebade1127fa05541b391ad', 'config': '2ab964abffa0a277a9e2ee9b5570cd258e428b62', 'pipeline': 'eef3f702fd2fed761fa6744c1640d0bf320f1d00'}, 'duration': 0.9828321933746338, 'iteration': 12, 'loss': 0.0778465772273822, 'max_history_score': 0.983625730994152, 'max_history_score_std': 0.025023500462379746, 'max_history_step': 'joint', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 3, 'features__selectkbest__k': 1}), 'normalizer': ('normalizer_PowerTransformer', {}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 6})}, 'score': 0.9221534227726178, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'gini', 'max_depth': 4, 'max_features': 2, 'max_leaf_nodes': 3, 'min_samples_split': 3, 'n_estimators': 75}, 'config_hash': {'algorithm': '6f75c2a196eb9836df2b424e095051192eaed6ea', 'config': '5c95db3ad238063227f1b36e6a006d70c834c5da', 'pipeline': '1eae01a1128bee425c4d4ca0ee97a9afd409680e'}, 'duration': 0.8217771053314209, 'iteration': 13, 'loss': 0.03863089095287242, 'max_history_score': 0.983625730994152, 'max_history_score_std': 0.025023500462379746, 'max_history_step': 'joint', 'pipeline': {'features': ('features_NoneType', {}), 'normalizer': ('normalizer_StandardScaler', {'normalizer__with_mean': False, 'normalizer__with_std': False}), 'rebalance': ('rebalance_NearMiss', {'rebalance__n_neighbors': 1})}, 'score': 0.9613691090471276, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'entropy', 'max_depth': 4, 'max_features': 2, 'max_leaf_nodes': 3, 'min_samples_split': 2, 'n_estimators': 25}, 'config_hash': {'algorithm': '8aef3174f6b8020de06b825e0424c1e54d690afd', 'config': '50fd1169b8e42190600f25152654254b5d0e3ed1', 'pipeline': '9ceaa544911dc6c687e336cb8e9dd4d15ff1ceaf'}, 'duration': 0.40307188034057617, 'iteration': 14, 'loss': 1.0, 'max_history_score': 0.983625730994152, 'max_history_score_std': 0.025023500462379746, 'max_history_step': 'joint', 'pipeline': {'features': ('features_PCA', {'features__n_components': 1}), 'normalizer': ('normalizer_RobustScaler', {'normalizer__quantile_range': (...), 'normalizer__with_centering': False, 'normalizer__with_scaling': False}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 7})}, 'score': 0.0, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'gini', 'max_depth': 1, 'max_features': 1, 'max_leaf_nodes': 3, 'min_samples_split': 3, 'n_estimators': 50}, 'config_hash': {'algorithm': '37be8b6737f4b5d5ae35da51886f302b07ba6001', 'config': 'a05b6d2ffd65d4d937c0b178655d857bf4d61410', 'pipeline': 'cfef88e895db321122f2f7b813d9267b973c2468'}, 'duration': 1.7094659805297852, 'iteration': 15, 'loss': 0.011111111111111072, 'max_history_score': 0.9888888888888889, 'max_history_score_std': 0.022222222222222233, 'max_history_step': 'joint', 'pipeline': {'features': ('features_NoneType', {}), 'normalizer': ('normalizer_NoneType', {}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 5})}, 'score': 0.9888888888888889, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'entropy', 'max_depth': None, 'max_features': 3, 'max_leaf_nodes': None, 'min_samples_split': 2, 'n_estimators': 100}, 'config_hash': {'algorithm': 'c40543ce91793e367c1892c886bc49621c22ecfb', 'config': 'ebebb7a93116f14f470e062e37582a59f4aeb0df', 'pipeline': 'b50c63e800574e8b760f55f7c4ff1fcae8816dd8'}, 'duration': 0.6425540447235107, 'iteration': 16, 'loss': 1.0, 'max_history_score': 0.9888888888888889, 'max_history_score_std': 0.022222222222222233, 'max_history_step': 'joint', 'pipeline': {'features': ('features_PCA', {'features__n_components': 1}), 'normalizer': ('normalizer_PowerTransformer', {}), 'rebalance': ('rebalance_NearMiss', {'rebalance__n_neighbors': 1})}, 'score': 0.0, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'gini', 'max_depth': None, 'max_features': 1, 'max_leaf_nodes': 3, 'min_samples_split': 2, 'n_estimators': 50}, 'config_hash': {'algorithm': '0c69b9601237c20664085fa05764d855e28f98f7', 'config': 'a2c21314ddbba47ddbfe416e0aa14853a71179e0', 'pipeline': '914f81fa4fbb61db251201f32bd8ea11bfeea2a5'}, 'duration': 2.2209739685058594, 'iteration': 17, 'loss': 0.3206720846233231, 'max_history_score': 0.9888888888888889, 'max_history_score_std': 0.022222222222222233, 'max_history_step': 'joint', 'pipeline': {'features': ('features_SelectKBest', {'features__k': 4}), 'normalizer': ('normalizer_PowerTransformer', {}), 'rebalance': ('rebalance_CondensedNearestNeighbour', {'rebalance__n_neighbors': 1})}, 'score': 0.6793279153766769, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': 4, 'max_features': None, 'max_leaf_nodes': None, 'min_samples_split': 3, 'n_estimators': 25}, 'config_hash': {'algorithm': '1aae0f1fce5cab293ffdd4581c4838c8051ac815', 'config': '6c8a721218e7c550a98c5ba72ad9ff86afd5e3a4', 'pipeline': '77189452469cef9c840643f2babe0f825c6667c8'}, 'duration': 0.3951280117034912, 'iteration': 18, 'loss': 0.1804760061919506, 'max_history_score': 0.9888888888888889, 'max_history_score_std': 0.022222222222222233, 'max_history_step': 'joint', 'pipeline': {'features': ('features_SelectKBest', {'features__k': 2}), 'normalizer': ('normalizer_NoneType', {}), 'rebalance': ('rebalance_NearMiss', {'rebalance__n_neighbors': 1})}, 'score': 0.8195239938080494, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': None, 'max_features': 3, 'max_leaf_nodes': 5, 'min_samples_split': 3, 'n_estimators': 50}, 'config_hash': {'algorithm': '0129970b8c7fe034ac8283fb518a06cfbead63d2', 'config': '61bcd2f64860b3dfe2503be88a6bbec165db0754', 'pipeline': '359f2473075ecfd9ae3ce526da96143918517601'}, 'duration': 0.7467091083526611, 'iteration': 19, 'loss': 0.09915720674234607, 'max_history_score': 0.9888888888888889, 'max_history_score_std': 0.022222222222222233, 'max_history_step': 'joint', 'pipeline': {'features': ('features_SelectKBest', {'features__k': 3}), 'normalizer': ('normalizer_RobustScaler', {'normalizer__quantile_range': (...), 'normalizer__with_centering': True, 'normalizer__with_scaling': False}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 7})}, 'score': 0.9008427932576539, ...}, ...], 'history_hash': ['2e6648b63441361b4398cb94f81d2e04a830b2ef', '584343bc020d2d7bc89bd0856bc7770dae1c84fc', 'de121d053e65def047cc8947f505578d5c5eab67', 'b21c9d15a389baa5bfea4c8ddcec129259f37540', 'edd3456355d80775739c31515c832ca7b4e5e094', '0800d7d2c8c10d2f9e7b4e5127b343e916eb742c', 'd98b641879b4754f2169335626a90575e945fd7c', '3f83df36a6abbdf7ea4a4bdcaf6727f23529c2bb', '037fd5c655b39cc7922fb394d736496befcc747b', '6609280032189b59de1afbe36f3acb1d5c273693', '8e1c17ac9f6e03740f380fccb833c9c3931ffc35', '87c03d0cb8e8500e58cacc1a0f27ce54c41a2937', '2ab964abffa0a277a9e2ee9b5570cd258e428b62', '5c95db3ad238063227f1b36e6a006d70c834c5da', '50fd1169b8e42190600f25152654254b5d0e3ed1', 'a05b6d2ffd65d4d937c0b178655d857bf4d61410', 'ebebb7a93116f14f470e062e37582a59f4aeb0df', 'a2c21314ddbba47ddbfe416e0aa14853a71179e0', '6c8a721218e7c550a98c5ba72ad9ff86afd5e3a4', '61bcd2f64860b3dfe2503be88a6bbec165db0754', ...], 'history_index': {'037fd5c655b39cc7922fb394d736496befcc747b': 8, '07fdf9d0d0248a4b0215a633c75a2dd101dcf465': 22, '0800d7d2c8c10d2f9e7b4e5127b343e916eb742c': 5, '0babf362e2373c001d4eb84f3c4eda27e56fe02d': 33, '0c9d6c44176dcc6b6ed48155a6e53130cb2c32e8': 45, '0e45095dfe50d5be759b179b50e63384925c7027': 32, '10bbd802ae07af833e53a3844fb056ba4016b893': 46, '2323c40e4e6c5f4aa333620a6b998b510ca41854': 35, '26ed0b67cf1046a22e2baba31b70ce3b6e762a03': 40, '28944b74104bc5bb782512b0eefa3167fe189355': 30, ...}, 'iteration': 52, 'max_history_score': 0.9944444444444445, 'max_history_score_std': 0.016666666666666673, 'max_history_step': 'joint'}, config={'algorithm': 'RandomForest', 'seed': 42, 'time': 300})
    108 
    109 def objective_algo(algo_config, current_pipeline_config, algorithm, X, y, context, config):
    110     return objective(current_pipeline_config, algo_config, algorithm, X, y, context, config, step='algorithm')
    111 
    112 def objective_joint(wconfig, algorithm, X, y, context, config):
--> 113     return objective(wconfig['pipeline'], wconfig['algorithm'], algorithm, X, y, context, config, step='joint')
        wconfig = {'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': 1, 'max_features': 3, 'max_leaf_nodes': 3, 'min_samples_split': 3, 'n_estimators': 50}, 'pipeline': {'features': ('features_SelectKBest', {'features__k': 1}), 'normalizer': ('normalizer_StandardScaler', {'normalizer__with_mean': True, 'normalizer__with_std': True}), 'rebalance': ('rebalance_NearMiss', {'rebalance__n_neighbors': 2})}}
        algorithm = 'RandomForest'
        X = array([[1.423e+01, 1.710e+00, 2.430e+00, ..., 1...., ..., 6.100e-01, 1.600e+00,
        5.600e+02]])
        y = array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,
       2, 2])
        context = {'baseline_score': 0.9444100447196423, 'baseline_score_std': 0.04305547117084885, 'best_config': {'algorithm': {'bootstrap': False, 'criterion': 'gini', 'max_depth': 1, 'max_features': 1, 'max_leaf_nodes': 3, 'min_samples_split': 5, 'n_estimators': 50}, 'config_hash': {'algorithm': 'cefc05c6c759dc564d289289fe401e0f8737951d', 'config': '7a1c40755d84d62f5d2ab1ed021e7dff93dfce45', 'pipeline': '3ee6a915db2d8d71f204c103803fb8eabea0d54f'}, 'duration': 0.6908998489379883, 'iteration': 24, 'loss': 0.005555555555555536, 'max_history_score': 0.9944444444444445, 'max_history_score_std': 0.016666666666666673, 'max_history_step': 'joint', 'pipeline': {'features': ('features_NoneType', {}), 'normalizer': ('normalizer_MinMaxScaler', {}), 'rebalance': ('rebalance_NoneType', {})}, 'score': 0.9944444444444445, ...}, 'history': [{'algorithm': {'bootstrap': False, 'criterion': 'entropy', 'max_depth': None, 'max_features': 3, 'max_leaf_nodes': 5, 'min_samples_split': 2, 'n_estimators': 50}, 'config_hash': {'algorithm': 'b2c6464add7a35ce8048653a39338c9994de9a4f', 'config': '2e6648b63441361b4398cb94f81d2e04a830b2ef', 'pipeline': '3d44d7482e468d08c4f94457a205f3dac74084c1'}, 'duration': 0.737678050994873, 'iteration': 0, 'loss': 1.0, 'max_history_score': 0.0, 'max_history_score_std': 0.0, 'max_history_step': 'baseline', 'pipeline': {'features': ('features_PCA', {'features__n_components': 1}), 'normalizer': ('normalizer_NoneType', {}), 'rebalance': ('rebalance_CondensedNearestNeighbour', {'rebalance__n_neighbors': 3})}, 'score': 0.0, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'gini', 'max_depth': 1, 'max_features': None, 'max_leaf_nodes': 2, 'min_samples_split': 3, 'n_estimators': 25}, 'config_hash': {'algorithm': '7f71bbbfdb4e8da52b6fc33a43224183117de15e', 'config': '584343bc020d2d7bc89bd0856bc7770dae1c84fc', 'pipeline': '466ffa7ace0e442beb7c311eb214b17a4c6832b3'}, 'duration': 1.5976769924163818, 'iteration': 1, 'loss': 0.40386351909184726, 'max_history_score': 0.5961364809081527, 'max_history_score_std': 0.05351463210025494, 'max_history_step': 'joint', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 3, 'features__selectkbest__k': 3}), 'normalizer': ('normalizer_StandardScaler', {'normalizer__with_mean': True, 'normalizer__with_std': True}), 'rebalance': ('rebalance_NearMiss', {'rebalance__n_neighbors': 2})}, 'score': 0.5961364809081527, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'entropy', 'max_depth': 1, 'max_features': 2, 'max_leaf_nodes': 2, 'min_samples_split': 5, 'n_estimators': 25}, 'config_hash': {'algorithm': '897745a20d929d43e760cacee0a764bd8070daa5', 'config': 'de121d053e65def047cc8947f505578d5c5eab67', 'pipeline': '63040b39b48626a8232e847e8327bdca5cd88611'}, 'duration': 0.815453052520752, 'iteration': 2, 'loss': 0.07327786377708967, 'max_history_score': 0.9267221362229103, 'max_history_score_std': 0.043920207373658794, 'max_history_step': 'joint', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 3, 'features__selectkbest__k': 2}), 'normalizer': ('normalizer_StandardScaler', {'normalizer__with_mean': True, 'normalizer__with_std': True}), 'rebalance': ('rebalance_NoneType', {})}, 'score': 0.9267221362229103, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'entropy', 'max_depth': 4, 'max_features': 3, 'max_leaf_nodes': None, 'min_samples_split': 2, 'n_estimators': 100}, 'config_hash': {'algorithm': 'dbd92c75280ec06b66ca4ad9b135cf36957031a4', 'config': 'b21c9d15a389baa5bfea4c8ddcec129259f37540', 'pipeline': '38866720d2f120c863351493b9b4e23b9a4506dc'}, 'duration': 1.2293269634246826, 'iteration': 3, 'loss': 0.07199862401100798, 'max_history_score': 0.928001375988992, 'max_history_score_std': 0.06518367535896959, 'max_history_step': 'joint', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 2, 'features__selectkbest__k': 4}), 'normalizer': ('normalizer_NoneType', {}), 'rebalance': ('rebalance_NoneType', {})}, 'score': 0.928001375988992, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': 2, 'max_features': None, 'max_leaf_nodes': None, 'min_samples_split': 5, 'n_estimators': 100}, 'config_hash': {'algorithm': 'f455eefd9fdd03ece88892c3f440c580bdf27ddb', 'config': 'edd3456355d80775739c31515c832ca7b4e5e094', 'pipeline': '1d1034f9f0871e43f896c1db4ed6fd572ed0a6ef'}, 'duration': 1.6186630725860596, 'iteration': 4, 'loss': 0.16651831785345705, 'max_history_score': 0.928001375988992, 'max_history_score_std': 0.06518367535896959, 'max_history_step': 'joint', 'pipeline': {'features': ('features_SelectKBest', {'features__k': 4}), 'normalizer': ('normalizer_MinMaxScaler', {}), 'rebalance': ('rebalance_CondensedNearestNeighbour', {'rebalance__n_neighbors': 1})}, 'score': 0.833481682146543, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'entropy', 'max_depth': 1, 'max_features': 2, 'max_leaf_nodes': None, 'min_samples_split': 2, 'n_estimators': 10}, 'config_hash': {'algorithm': '29906eaa0712a68ea145b12821d54ba445726fbf', 'config': '0800d7d2c8c10d2f9e7b4e5127b343e916eb742c', 'pipeline': '2e0f188ae61600352a7159285e0f542b4587a403'}, 'duration': 0.19410085678100586, 'iteration': 5, 'loss': 0.20164258685930514, 'max_history_score': 0.928001375988992, 'max_history_score_std': 0.06518367535896959, 'max_history_step': 'joint', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 3, 'features__selectkbest__k': 4}), 'normalizer': ('normalizer_StandardScaler', {'normalizer__with_mean': True, 'normalizer__with_std': False}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 7})}, 'score': 0.7983574131406949, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': 1, 'max_features': 1, 'max_leaf_nodes': 5, 'min_samples_split': 2, 'n_estimators': 25}, 'config_hash': {'algorithm': 'fbb7d57e38cfc08240f0af985282da418cb33556', 'config': 'd98b641879b4754f2169335626a90575e945fd7c', 'pipeline': '62463de065924498cdcd2f2f1f7e68535cdb33a5'}, 'duration': 0.3625810146331787, 'iteration': 6, 'loss': 0.14327485380116955, 'max_history_score': 0.928001375988992, 'max_history_score_std': 0.06518367535896959, 'max_history_step': 'joint', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 1, 'features__selectkbest__k': 2}), 'normalizer': ('normalizer_NoneType', {}), 'rebalance': ('rebalance_NoneType', {})}, 'score': 0.8567251461988304, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'entropy', 'max_depth': 3, 'max_features': 1, 'max_leaf_nodes': None, 'min_samples_split': 2, 'n_estimators': 75}, 'config_hash': {'algorithm': 'fb2f5d4c4d636edac929e1454ce3d02a4fb134c1', 'config': '3f83df36a6abbdf7ea4a4bdcaf6727f23529c2bb', 'pipeline': '8377b93e334656d1a93d266493b58ef9a6a1786f'}, 'duration': 0.8223779201507568, 'iteration': 7, 'loss': 0.03921568627450989, 'max_history_score': 0.9607843137254901, 'max_history_score_std': 0.043526663832084804, 'max_history_step': 'joint', 'pipeline': {'features': ('features_PCA', {'features__n_components': 3}), 'normalizer': ('normalizer_MinMaxScaler', {}), 'rebalance': ('rebalance_NearMiss', {'rebalance__n_neighbors': 1})}, 'score': 0.9607843137254901, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'gini', 'max_depth': 3, 'max_features': 3, 'max_leaf_nodes': 2, 'min_samples_split': 2, 'n_estimators': 100}, 'config_hash': {'algorithm': '3c3fde6559b918694de4668d025d5418342db1b1', 'config': '037fd5c655b39cc7922fb394d736496befcc747b', 'pipeline': '2a5032814c6c7ed21dd5bd9686923d7fc2f8acc9'}, 'duration': 1.0435099601745605, 'iteration': 8, 'loss': 0.09955925352597172, 'max_history_score': 0.9607843137254901, 'max_history_score_std': 0.043526663832084804, 'max_history_step': 'joint', 'pipeline': {'features': ('features_NoneType', {}), 'normalizer': ('normalizer_RobustScaler', {'normalizer__quantile_range': (...), 'normalizer__with_centering': True, 'normalizer__with_scaling': True}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 7})}, 'score': 0.9004407464740283, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': 2, 'max_features': 1, 'max_leaf_nodes': None, 'min_samples_split': 3, 'n_estimators': 75}, 'config_hash': {'algorithm': '42185be98371e99ac896d2c6c2d69c451cb983ff', 'config': '6609280032189b59de1afbe36f3acb1d5c273693', 'pipeline': '8aab2941fc84d84f86fa56134e50909dbf9e19f5'}, 'duration': 0.9665219783782959, 'iteration': 9, 'loss': 0.01637426900584804, 'max_history_score': 0.983625730994152, 'max_history_score_std': 0.025023500462379746, 'max_history_step': 'joint', 'pipeline': {'features': ('features_NoneType', {}), 'normalizer': ('normalizer_PowerTransformer', {}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 5})}, 'score': 0.983625730994152, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': 1, 'max_features': 3, 'max_leaf_nodes': 2, 'min_samples_split': 3, 'n_estimators': 10}, 'config_hash': {'algorithm': '62a9fe705e4cd96e762bcc9543c4a456a5a9f188', 'config': '8e1c17ac9f6e03740f380fccb833c9c3931ffc35', 'pipeline': '3d44d7482e468d08c4f94457a205f3dac74084c1'}, 'duration': 0.46930503845214844, 'iteration': 10, 'loss': 1.0, 'max_history_score': 0.983625730994152, 'max_history_score_std': 0.025023500462379746, 'max_history_step': 'joint', 'pipeline': {'features': ('features_PCA', {'features__n_components': 1}), 'normalizer': ('normalizer_NoneType', {}), 'rebalance': ('rebalance_CondensedNearestNeighbour', {'rebalance__n_neighbors': 3})}, 'score': 0.0, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'gini', 'max_depth': 4, 'max_features': 1, 'max_leaf_nodes': 3, 'min_samples_split': 2, 'n_estimators': 100}, 'config_hash': {'algorithm': '086d6ca939a757bb32edb113a567f9d38744f061', 'config': '87c03d0cb8e8500e58cacc1a0f27ce54c41a2937', 'pipeline': '8f28ef0f35d97142278f9dacb4e9d1ff082e470f'}, 'duration': 2.1196961402893066, 'iteration': 11, 'loss': 0.15471276229790154, 'max_history_score': 0.983625730994152, 'max_history_score_std': 0.025023500462379746, 'max_history_step': 'joint', 'pipeline': {'features': ('features_PCA', {'features__n_components': 1}), 'normalizer': ('normalizer_StandardScaler', {'normalizer__with_mean': True, 'normalizer__with_std': True}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 7})}, 'score': 0.8452872377020985, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'entropy', 'max_depth': 3, 'max_features': 1, 'max_leaf_nodes': 2, 'min_samples_split': 2, 'n_estimators': 25}, 'config_hash': {'algorithm': '59f64a966796648c7bebade1127fa05541b391ad', 'config': '2ab964abffa0a277a9e2ee9b5570cd258e428b62', 'pipeline': 'eef3f702fd2fed761fa6744c1640d0bf320f1d00'}, 'duration': 0.9828321933746338, 'iteration': 12, 'loss': 0.0778465772273822, 'max_history_score': 0.983625730994152, 'max_history_score_std': 0.025023500462379746, 'max_history_step': 'joint', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 3, 'features__selectkbest__k': 1}), 'normalizer': ('normalizer_PowerTransformer', {}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 6})}, 'score': 0.9221534227726178, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'gini', 'max_depth': 4, 'max_features': 2, 'max_leaf_nodes': 3, 'min_samples_split': 3, 'n_estimators': 75}, 'config_hash': {'algorithm': '6f75c2a196eb9836df2b424e095051192eaed6ea', 'config': '5c95db3ad238063227f1b36e6a006d70c834c5da', 'pipeline': '1eae01a1128bee425c4d4ca0ee97a9afd409680e'}, 'duration': 0.8217771053314209, 'iteration': 13, 'loss': 0.03863089095287242, 'max_history_score': 0.983625730994152, 'max_history_score_std': 0.025023500462379746, 'max_history_step': 'joint', 'pipeline': {'features': ('features_NoneType', {}), 'normalizer': ('normalizer_StandardScaler', {'normalizer__with_mean': False, 'normalizer__with_std': False}), 'rebalance': ('rebalance_NearMiss', {'rebalance__n_neighbors': 1})}, 'score': 0.9613691090471276, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'entropy', 'max_depth': 4, 'max_features': 2, 'max_leaf_nodes': 3, 'min_samples_split': 2, 'n_estimators': 25}, 'config_hash': {'algorithm': '8aef3174f6b8020de06b825e0424c1e54d690afd', 'config': '50fd1169b8e42190600f25152654254b5d0e3ed1', 'pipeline': '9ceaa544911dc6c687e336cb8e9dd4d15ff1ceaf'}, 'duration': 0.40307188034057617, 'iteration': 14, 'loss': 1.0, 'max_history_score': 0.983625730994152, 'max_history_score_std': 0.025023500462379746, 'max_history_step': 'joint', 'pipeline': {'features': ('features_PCA', {'features__n_components': 1}), 'normalizer': ('normalizer_RobustScaler', {'normalizer__quantile_range': (...), 'normalizer__with_centering': False, 'normalizer__with_scaling': False}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 7})}, 'score': 0.0, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'gini', 'max_depth': 1, 'max_features': 1, 'max_leaf_nodes': 3, 'min_samples_split': 3, 'n_estimators': 50}, 'config_hash': {'algorithm': '37be8b6737f4b5d5ae35da51886f302b07ba6001', 'config': 'a05b6d2ffd65d4d937c0b178655d857bf4d61410', 'pipeline': 'cfef88e895db321122f2f7b813d9267b973c2468'}, 'duration': 1.7094659805297852, 'iteration': 15, 'loss': 0.011111111111111072, 'max_history_score': 0.9888888888888889, 'max_history_score_std': 0.022222222222222233, 'max_history_step': 'joint', 'pipeline': {'features': ('features_NoneType', {}), 'normalizer': ('normalizer_NoneType', {}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 5})}, 'score': 0.9888888888888889, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'entropy', 'max_depth': None, 'max_features': 3, 'max_leaf_nodes': None, 'min_samples_split': 2, 'n_estimators': 100}, 'config_hash': {'algorithm': 'c40543ce91793e367c1892c886bc49621c22ecfb', 'config': 'ebebb7a93116f14f470e062e37582a59f4aeb0df', 'pipeline': 'b50c63e800574e8b760f55f7c4ff1fcae8816dd8'}, 'duration': 0.6425540447235107, 'iteration': 16, 'loss': 1.0, 'max_history_score': 0.9888888888888889, 'max_history_score_std': 0.022222222222222233, 'max_history_step': 'joint', 'pipeline': {'features': ('features_PCA', {'features__n_components': 1}), 'normalizer': ('normalizer_PowerTransformer', {}), 'rebalance': ('rebalance_NearMiss', {'rebalance__n_neighbors': 1})}, 'score': 0.0, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'gini', 'max_depth': None, 'max_features': 1, 'max_leaf_nodes': 3, 'min_samples_split': 2, 'n_estimators': 50}, 'config_hash': {'algorithm': '0c69b9601237c20664085fa05764d855e28f98f7', 'config': 'a2c21314ddbba47ddbfe416e0aa14853a71179e0', 'pipeline': '914f81fa4fbb61db251201f32bd8ea11bfeea2a5'}, 'duration': 2.2209739685058594, 'iteration': 17, 'loss': 0.3206720846233231, 'max_history_score': 0.9888888888888889, 'max_history_score_std': 0.022222222222222233, 'max_history_step': 'joint', 'pipeline': {'features': ('features_SelectKBest', {'features__k': 4}), 'normalizer': ('normalizer_PowerTransformer', {}), 'rebalance': ('rebalance_CondensedNearestNeighbour', {'rebalance__n_neighbors': 1})}, 'score': 0.6793279153766769, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': 4, 'max_features': None, 'max_leaf_nodes': None, 'min_samples_split': 3, 'n_estimators': 25}, 'config_hash': {'algorithm': '1aae0f1fce5cab293ffdd4581c4838c8051ac815', 'config': '6c8a721218e7c550a98c5ba72ad9ff86afd5e3a4', 'pipeline': '77189452469cef9c840643f2babe0f825c6667c8'}, 'duration': 0.3951280117034912, 'iteration': 18, 'loss': 0.1804760061919506, 'max_history_score': 0.9888888888888889, 'max_history_score_std': 0.022222222222222233, 'max_history_step': 'joint', 'pipeline': {'features': ('features_SelectKBest', {'features__k': 2}), 'normalizer': ('normalizer_NoneType', {}), 'rebalance': ('rebalance_NearMiss', {'rebalance__n_neighbors': 1})}, 'score': 0.8195239938080494, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': None, 'max_features': 3, 'max_leaf_nodes': 5, 'min_samples_split': 3, 'n_estimators': 50}, 'config_hash': {'algorithm': '0129970b8c7fe034ac8283fb518a06cfbead63d2', 'config': '61bcd2f64860b3dfe2503be88a6bbec165db0754', 'pipeline': '359f2473075ecfd9ae3ce526da96143918517601'}, 'duration': 0.7467091083526611, 'iteration': 19, 'loss': 0.09915720674234607, 'max_history_score': 0.9888888888888889, 'max_history_score_std': 0.022222222222222233, 'max_history_step': 'joint', 'pipeline': {'features': ('features_SelectKBest', {'features__k': 3}), 'normalizer': ('normalizer_RobustScaler', {'normalizer__quantile_range': (...), 'normalizer__with_centering': True, 'normalizer__with_scaling': False}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 7})}, 'score': 0.9008427932576539, ...}, ...], 'history_hash': ['2e6648b63441361b4398cb94f81d2e04a830b2ef', '584343bc020d2d7bc89bd0856bc7770dae1c84fc', 'de121d053e65def047cc8947f505578d5c5eab67', 'b21c9d15a389baa5bfea4c8ddcec129259f37540', 'edd3456355d80775739c31515c832ca7b4e5e094', '0800d7d2c8c10d2f9e7b4e5127b343e916eb742c', 'd98b641879b4754f2169335626a90575e945fd7c', '3f83df36a6abbdf7ea4a4bdcaf6727f23529c2bb', '037fd5c655b39cc7922fb394d736496befcc747b', '6609280032189b59de1afbe36f3acb1d5c273693', '8e1c17ac9f6e03740f380fccb833c9c3931ffc35', '87c03d0cb8e8500e58cacc1a0f27ce54c41a2937', '2ab964abffa0a277a9e2ee9b5570cd258e428b62', '5c95db3ad238063227f1b36e6a006d70c834c5da', '50fd1169b8e42190600f25152654254b5d0e3ed1', 'a05b6d2ffd65d4d937c0b178655d857bf4d61410', 'ebebb7a93116f14f470e062e37582a59f4aeb0df', 'a2c21314ddbba47ddbfe416e0aa14853a71179e0', '6c8a721218e7c550a98c5ba72ad9ff86afd5e3a4', '61bcd2f64860b3dfe2503be88a6bbec165db0754', ...], 'history_index': {'037fd5c655b39cc7922fb394d736496befcc747b': 8, '07fdf9d0d0248a4b0215a633c75a2dd101dcf465': 22, '0800d7d2c8c10d2f9e7b4e5127b343e916eb742c': 5, '0babf362e2373c001d4eb84f3c4eda27e56fe02d': 33, '0c9d6c44176dcc6b6ed48155a6e53130cb2c32e8': 45, '0e45095dfe50d5be759b179b50e63384925c7027': 32, '10bbd802ae07af833e53a3844fb056ba4016b893': 46, '2323c40e4e6c5f4aa333620a6b998b510ca41854': 35, '26ed0b67cf1046a22e2baba31b70ce3b6e762a03': 40, '28944b74104bc5bb782512b0eefa3167fe189355': 30, ...}, 'iteration': 52, 'max_history_score': 0.9944444444444445, 'max_history_score_std': 0.016666666666666673, 'max_history_step': 'joint'}
        config = {'algorithm': 'RandomForest', 'seed': 42, 'time': 300}
    114 
    115 
    116 def get_baseline_score(algorithm, X, y, seed):
    117     pipeline, _ = pipeline_conf_to_full_pipeline(

...........................................................................
/home/aquemy/dev/dp_hyperparameters/extension/experiment/objective.py in objective(pipeline_config={'features': ('features_SelectKBest', {'features__k': 1}), 'normalizer': ('normalizer_StandardScaler', {'normalizer__with_mean': True, 'normalizer__with_std': True}), 'rebalance': ('rebalance_NearMiss', {'rebalance__n_neighbors': 2})}, algo_config={'bootstrap': True, 'criterion': 'gini', 'max_depth': 1, 'max_features': 3, 'max_leaf_nodes': 3, 'min_samples_split': 3, 'n_estimators': 50}, algorithm='RandomForest', X=array([[1.423e+01, 1.710e+00, 2.430e+00, ..., 1...., ..., 6.100e-01, 1.600e+00,
        5.600e+02]]), y=array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,
       2, 2]), context={'baseline_score': 0.9444100447196423, 'baseline_score_std': 0.04305547117084885, 'best_config': {'algorithm': {'bootstrap': False, 'criterion': 'gini', 'max_depth': 1, 'max_features': 1, 'max_leaf_nodes': 3, 'min_samples_split': 5, 'n_estimators': 50}, 'config_hash': {'algorithm': 'cefc05c6c759dc564d289289fe401e0f8737951d', 'config': '7a1c40755d84d62f5d2ab1ed021e7dff93dfce45', 'pipeline': '3ee6a915db2d8d71f204c103803fb8eabea0d54f'}, 'duration': 0.6908998489379883, 'iteration': 24, 'loss': 0.005555555555555536, 'max_history_score': 0.9944444444444445, 'max_history_score_std': 0.016666666666666673, 'max_history_step': 'joint', 'pipeline': {'features': ('features_NoneType', {}), 'normalizer': ('normalizer_MinMaxScaler', {}), 'rebalance': ('rebalance_NoneType', {})}, 'score': 0.9944444444444445, ...}, 'history': [{'algorithm': {'bootstrap': False, 'criterion': 'entropy', 'max_depth': None, 'max_features': 3, 'max_leaf_nodes': 5, 'min_samples_split': 2, 'n_estimators': 50}, 'config_hash': {'algorithm': 'b2c6464add7a35ce8048653a39338c9994de9a4f', 'config': '2e6648b63441361b4398cb94f81d2e04a830b2ef', 'pipeline': '3d44d7482e468d08c4f94457a205f3dac74084c1'}, 'duration': 0.737678050994873, 'iteration': 0, 'loss': 1.0, 'max_history_score': 0.0, 'max_history_score_std': 0.0, 'max_history_step': 'baseline', 'pipeline': {'features': ('features_PCA', {'features__n_components': 1}), 'normalizer': ('normalizer_NoneType', {}), 'rebalance': ('rebalance_CondensedNearestNeighbour', {'rebalance__n_neighbors': 3})}, 'score': 0.0, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'gini', 'max_depth': 1, 'max_features': None, 'max_leaf_nodes': 2, 'min_samples_split': 3, 'n_estimators': 25}, 'config_hash': {'algorithm': '7f71bbbfdb4e8da52b6fc33a43224183117de15e', 'config': '584343bc020d2d7bc89bd0856bc7770dae1c84fc', 'pipeline': '466ffa7ace0e442beb7c311eb214b17a4c6832b3'}, 'duration': 1.5976769924163818, 'iteration': 1, 'loss': 0.40386351909184726, 'max_history_score': 0.5961364809081527, 'max_history_score_std': 0.05351463210025494, 'max_history_step': 'joint', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 3, 'features__selectkbest__k': 3}), 'normalizer': ('normalizer_StandardScaler', {'normalizer__with_mean': True, 'normalizer__with_std': True}), 'rebalance': ('rebalance_NearMiss', {'rebalance__n_neighbors': 2})}, 'score': 0.5961364809081527, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'entropy', 'max_depth': 1, 'max_features': 2, 'max_leaf_nodes': 2, 'min_samples_split': 5, 'n_estimators': 25}, 'config_hash': {'algorithm': '897745a20d929d43e760cacee0a764bd8070daa5', 'config': 'de121d053e65def047cc8947f505578d5c5eab67', 'pipeline': '63040b39b48626a8232e847e8327bdca5cd88611'}, 'duration': 0.815453052520752, 'iteration': 2, 'loss': 0.07327786377708967, 'max_history_score': 0.9267221362229103, 'max_history_score_std': 0.043920207373658794, 'max_history_step': 'joint', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 3, 'features__selectkbest__k': 2}), 'normalizer': ('normalizer_StandardScaler', {'normalizer__with_mean': True, 'normalizer__with_std': True}), 'rebalance': ('rebalance_NoneType', {})}, 'score': 0.9267221362229103, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'entropy', 'max_depth': 4, 'max_features': 3, 'max_leaf_nodes': None, 'min_samples_split': 2, 'n_estimators': 100}, 'config_hash': {'algorithm': 'dbd92c75280ec06b66ca4ad9b135cf36957031a4', 'config': 'b21c9d15a389baa5bfea4c8ddcec129259f37540', 'pipeline': '38866720d2f120c863351493b9b4e23b9a4506dc'}, 'duration': 1.2293269634246826, 'iteration': 3, 'loss': 0.07199862401100798, 'max_history_score': 0.928001375988992, 'max_history_score_std': 0.06518367535896959, 'max_history_step': 'joint', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 2, 'features__selectkbest__k': 4}), 'normalizer': ('normalizer_NoneType', {}), 'rebalance': ('rebalance_NoneType', {})}, 'score': 0.928001375988992, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': 2, 'max_features': None, 'max_leaf_nodes': None, 'min_samples_split': 5, 'n_estimators': 100}, 'config_hash': {'algorithm': 'f455eefd9fdd03ece88892c3f440c580bdf27ddb', 'config': 'edd3456355d80775739c31515c832ca7b4e5e094', 'pipeline': '1d1034f9f0871e43f896c1db4ed6fd572ed0a6ef'}, 'duration': 1.6186630725860596, 'iteration': 4, 'loss': 0.16651831785345705, 'max_history_score': 0.928001375988992, 'max_history_score_std': 0.06518367535896959, 'max_history_step': 'joint', 'pipeline': {'features': ('features_SelectKBest', {'features__k': 4}), 'normalizer': ('normalizer_MinMaxScaler', {}), 'rebalance': ('rebalance_CondensedNearestNeighbour', {'rebalance__n_neighbors': 1})}, 'score': 0.833481682146543, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'entropy', 'max_depth': 1, 'max_features': 2, 'max_leaf_nodes': None, 'min_samples_split': 2, 'n_estimators': 10}, 'config_hash': {'algorithm': '29906eaa0712a68ea145b12821d54ba445726fbf', 'config': '0800d7d2c8c10d2f9e7b4e5127b343e916eb742c', 'pipeline': '2e0f188ae61600352a7159285e0f542b4587a403'}, 'duration': 0.19410085678100586, 'iteration': 5, 'loss': 0.20164258685930514, 'max_history_score': 0.928001375988992, 'max_history_score_std': 0.06518367535896959, 'max_history_step': 'joint', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 3, 'features__selectkbest__k': 4}), 'normalizer': ('normalizer_StandardScaler', {'normalizer__with_mean': True, 'normalizer__with_std': False}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 7})}, 'score': 0.7983574131406949, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': 1, 'max_features': 1, 'max_leaf_nodes': 5, 'min_samples_split': 2, 'n_estimators': 25}, 'config_hash': {'algorithm': 'fbb7d57e38cfc08240f0af985282da418cb33556', 'config': 'd98b641879b4754f2169335626a90575e945fd7c', 'pipeline': '62463de065924498cdcd2f2f1f7e68535cdb33a5'}, 'duration': 0.3625810146331787, 'iteration': 6, 'loss': 0.14327485380116955, 'max_history_score': 0.928001375988992, 'max_history_score_std': 0.06518367535896959, 'max_history_step': 'joint', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 1, 'features__selectkbest__k': 2}), 'normalizer': ('normalizer_NoneType', {}), 'rebalance': ('rebalance_NoneType', {})}, 'score': 0.8567251461988304, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'entropy', 'max_depth': 3, 'max_features': 1, 'max_leaf_nodes': None, 'min_samples_split': 2, 'n_estimators': 75}, 'config_hash': {'algorithm': 'fb2f5d4c4d636edac929e1454ce3d02a4fb134c1', 'config': '3f83df36a6abbdf7ea4a4bdcaf6727f23529c2bb', 'pipeline': '8377b93e334656d1a93d266493b58ef9a6a1786f'}, 'duration': 0.8223779201507568, 'iteration': 7, 'loss': 0.03921568627450989, 'max_history_score': 0.9607843137254901, 'max_history_score_std': 0.043526663832084804, 'max_history_step': 'joint', 'pipeline': {'features': ('features_PCA', {'features__n_components': 3}), 'normalizer': ('normalizer_MinMaxScaler', {}), 'rebalance': ('rebalance_NearMiss', {'rebalance__n_neighbors': 1})}, 'score': 0.9607843137254901, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'gini', 'max_depth': 3, 'max_features': 3, 'max_leaf_nodes': 2, 'min_samples_split': 2, 'n_estimators': 100}, 'config_hash': {'algorithm': '3c3fde6559b918694de4668d025d5418342db1b1', 'config': '037fd5c655b39cc7922fb394d736496befcc747b', 'pipeline': '2a5032814c6c7ed21dd5bd9686923d7fc2f8acc9'}, 'duration': 1.0435099601745605, 'iteration': 8, 'loss': 0.09955925352597172, 'max_history_score': 0.9607843137254901, 'max_history_score_std': 0.043526663832084804, 'max_history_step': 'joint', 'pipeline': {'features': ('features_NoneType', {}), 'normalizer': ('normalizer_RobustScaler', {'normalizer__quantile_range': (...), 'normalizer__with_centering': True, 'normalizer__with_scaling': True}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 7})}, 'score': 0.9004407464740283, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': 2, 'max_features': 1, 'max_leaf_nodes': None, 'min_samples_split': 3, 'n_estimators': 75}, 'config_hash': {'algorithm': '42185be98371e99ac896d2c6c2d69c451cb983ff', 'config': '6609280032189b59de1afbe36f3acb1d5c273693', 'pipeline': '8aab2941fc84d84f86fa56134e50909dbf9e19f5'}, 'duration': 0.9665219783782959, 'iteration': 9, 'loss': 0.01637426900584804, 'max_history_score': 0.983625730994152, 'max_history_score_std': 0.025023500462379746, 'max_history_step': 'joint', 'pipeline': {'features': ('features_NoneType', {}), 'normalizer': ('normalizer_PowerTransformer', {}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 5})}, 'score': 0.983625730994152, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': 1, 'max_features': 3, 'max_leaf_nodes': 2, 'min_samples_split': 3, 'n_estimators': 10}, 'config_hash': {'algorithm': '62a9fe705e4cd96e762bcc9543c4a456a5a9f188', 'config': '8e1c17ac9f6e03740f380fccb833c9c3931ffc35', 'pipeline': '3d44d7482e468d08c4f94457a205f3dac74084c1'}, 'duration': 0.46930503845214844, 'iteration': 10, 'loss': 1.0, 'max_history_score': 0.983625730994152, 'max_history_score_std': 0.025023500462379746, 'max_history_step': 'joint', 'pipeline': {'features': ('features_PCA', {'features__n_components': 1}), 'normalizer': ('normalizer_NoneType', {}), 'rebalance': ('rebalance_CondensedNearestNeighbour', {'rebalance__n_neighbors': 3})}, 'score': 0.0, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'gini', 'max_depth': 4, 'max_features': 1, 'max_leaf_nodes': 3, 'min_samples_split': 2, 'n_estimators': 100}, 'config_hash': {'algorithm': '086d6ca939a757bb32edb113a567f9d38744f061', 'config': '87c03d0cb8e8500e58cacc1a0f27ce54c41a2937', 'pipeline': '8f28ef0f35d97142278f9dacb4e9d1ff082e470f'}, 'duration': 2.1196961402893066, 'iteration': 11, 'loss': 0.15471276229790154, 'max_history_score': 0.983625730994152, 'max_history_score_std': 0.025023500462379746, 'max_history_step': 'joint', 'pipeline': {'features': ('features_PCA', {'features__n_components': 1}), 'normalizer': ('normalizer_StandardScaler', {'normalizer__with_mean': True, 'normalizer__with_std': True}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 7})}, 'score': 0.8452872377020985, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'entropy', 'max_depth': 3, 'max_features': 1, 'max_leaf_nodes': 2, 'min_samples_split': 2, 'n_estimators': 25}, 'config_hash': {'algorithm': '59f64a966796648c7bebade1127fa05541b391ad', 'config': '2ab964abffa0a277a9e2ee9b5570cd258e428b62', 'pipeline': 'eef3f702fd2fed761fa6744c1640d0bf320f1d00'}, 'duration': 0.9828321933746338, 'iteration': 12, 'loss': 0.0778465772273822, 'max_history_score': 0.983625730994152, 'max_history_score_std': 0.025023500462379746, 'max_history_step': 'joint', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 3, 'features__selectkbest__k': 1}), 'normalizer': ('normalizer_PowerTransformer', {}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 6})}, 'score': 0.9221534227726178, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'gini', 'max_depth': 4, 'max_features': 2, 'max_leaf_nodes': 3, 'min_samples_split': 3, 'n_estimators': 75}, 'config_hash': {'algorithm': '6f75c2a196eb9836df2b424e095051192eaed6ea', 'config': '5c95db3ad238063227f1b36e6a006d70c834c5da', 'pipeline': '1eae01a1128bee425c4d4ca0ee97a9afd409680e'}, 'duration': 0.8217771053314209, 'iteration': 13, 'loss': 0.03863089095287242, 'max_history_score': 0.983625730994152, 'max_history_score_std': 0.025023500462379746, 'max_history_step': 'joint', 'pipeline': {'features': ('features_NoneType', {}), 'normalizer': ('normalizer_StandardScaler', {'normalizer__with_mean': False, 'normalizer__with_std': False}), 'rebalance': ('rebalance_NearMiss', {'rebalance__n_neighbors': 1})}, 'score': 0.9613691090471276, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'entropy', 'max_depth': 4, 'max_features': 2, 'max_leaf_nodes': 3, 'min_samples_split': 2, 'n_estimators': 25}, 'config_hash': {'algorithm': '8aef3174f6b8020de06b825e0424c1e54d690afd', 'config': '50fd1169b8e42190600f25152654254b5d0e3ed1', 'pipeline': '9ceaa544911dc6c687e336cb8e9dd4d15ff1ceaf'}, 'duration': 0.40307188034057617, 'iteration': 14, 'loss': 1.0, 'max_history_score': 0.983625730994152, 'max_history_score_std': 0.025023500462379746, 'max_history_step': 'joint', 'pipeline': {'features': ('features_PCA', {'features__n_components': 1}), 'normalizer': ('normalizer_RobustScaler', {'normalizer__quantile_range': (...), 'normalizer__with_centering': False, 'normalizer__with_scaling': False}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 7})}, 'score': 0.0, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'gini', 'max_depth': 1, 'max_features': 1, 'max_leaf_nodes': 3, 'min_samples_split': 3, 'n_estimators': 50}, 'config_hash': {'algorithm': '37be8b6737f4b5d5ae35da51886f302b07ba6001', 'config': 'a05b6d2ffd65d4d937c0b178655d857bf4d61410', 'pipeline': 'cfef88e895db321122f2f7b813d9267b973c2468'}, 'duration': 1.7094659805297852, 'iteration': 15, 'loss': 0.011111111111111072, 'max_history_score': 0.9888888888888889, 'max_history_score_std': 0.022222222222222233, 'max_history_step': 'joint', 'pipeline': {'features': ('features_NoneType', {}), 'normalizer': ('normalizer_NoneType', {}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 5})}, 'score': 0.9888888888888889, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'entropy', 'max_depth': None, 'max_features': 3, 'max_leaf_nodes': None, 'min_samples_split': 2, 'n_estimators': 100}, 'config_hash': {'algorithm': 'c40543ce91793e367c1892c886bc49621c22ecfb', 'config': 'ebebb7a93116f14f470e062e37582a59f4aeb0df', 'pipeline': 'b50c63e800574e8b760f55f7c4ff1fcae8816dd8'}, 'duration': 0.6425540447235107, 'iteration': 16, 'loss': 1.0, 'max_history_score': 0.9888888888888889, 'max_history_score_std': 0.022222222222222233, 'max_history_step': 'joint', 'pipeline': {'features': ('features_PCA', {'features__n_components': 1}), 'normalizer': ('normalizer_PowerTransformer', {}), 'rebalance': ('rebalance_NearMiss', {'rebalance__n_neighbors': 1})}, 'score': 0.0, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'gini', 'max_depth': None, 'max_features': 1, 'max_leaf_nodes': 3, 'min_samples_split': 2, 'n_estimators': 50}, 'config_hash': {'algorithm': '0c69b9601237c20664085fa05764d855e28f98f7', 'config': 'a2c21314ddbba47ddbfe416e0aa14853a71179e0', 'pipeline': '914f81fa4fbb61db251201f32bd8ea11bfeea2a5'}, 'duration': 2.2209739685058594, 'iteration': 17, 'loss': 0.3206720846233231, 'max_history_score': 0.9888888888888889, 'max_history_score_std': 0.022222222222222233, 'max_history_step': 'joint', 'pipeline': {'features': ('features_SelectKBest', {'features__k': 4}), 'normalizer': ('normalizer_PowerTransformer', {}), 'rebalance': ('rebalance_CondensedNearestNeighbour', {'rebalance__n_neighbors': 1})}, 'score': 0.6793279153766769, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': 4, 'max_features': None, 'max_leaf_nodes': None, 'min_samples_split': 3, 'n_estimators': 25}, 'config_hash': {'algorithm': '1aae0f1fce5cab293ffdd4581c4838c8051ac815', 'config': '6c8a721218e7c550a98c5ba72ad9ff86afd5e3a4', 'pipeline': '77189452469cef9c840643f2babe0f825c6667c8'}, 'duration': 0.3951280117034912, 'iteration': 18, 'loss': 0.1804760061919506, 'max_history_score': 0.9888888888888889, 'max_history_score_std': 0.022222222222222233, 'max_history_step': 'joint', 'pipeline': {'features': ('features_SelectKBest', {'features__k': 2}), 'normalizer': ('normalizer_NoneType', {}), 'rebalance': ('rebalance_NearMiss', {'rebalance__n_neighbors': 1})}, 'score': 0.8195239938080494, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': None, 'max_features': 3, 'max_leaf_nodes': 5, 'min_samples_split': 3, 'n_estimators': 50}, 'config_hash': {'algorithm': '0129970b8c7fe034ac8283fb518a06cfbead63d2', 'config': '61bcd2f64860b3dfe2503be88a6bbec165db0754', 'pipeline': '359f2473075ecfd9ae3ce526da96143918517601'}, 'duration': 0.7467091083526611, 'iteration': 19, 'loss': 0.09915720674234607, 'max_history_score': 0.9888888888888889, 'max_history_score_std': 0.022222222222222233, 'max_history_step': 'joint', 'pipeline': {'features': ('features_SelectKBest', {'features__k': 3}), 'normalizer': ('normalizer_RobustScaler', {'normalizer__quantile_range': (...), 'normalizer__with_centering': True, 'normalizer__with_scaling': False}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 7})}, 'score': 0.9008427932576539, ...}, ...], 'history_hash': ['2e6648b63441361b4398cb94f81d2e04a830b2ef', '584343bc020d2d7bc89bd0856bc7770dae1c84fc', 'de121d053e65def047cc8947f505578d5c5eab67', 'b21c9d15a389baa5bfea4c8ddcec129259f37540', 'edd3456355d80775739c31515c832ca7b4e5e094', '0800d7d2c8c10d2f9e7b4e5127b343e916eb742c', 'd98b641879b4754f2169335626a90575e945fd7c', '3f83df36a6abbdf7ea4a4bdcaf6727f23529c2bb', '037fd5c655b39cc7922fb394d736496befcc747b', '6609280032189b59de1afbe36f3acb1d5c273693', '8e1c17ac9f6e03740f380fccb833c9c3931ffc35', '87c03d0cb8e8500e58cacc1a0f27ce54c41a2937', '2ab964abffa0a277a9e2ee9b5570cd258e428b62', '5c95db3ad238063227f1b36e6a006d70c834c5da', '50fd1169b8e42190600f25152654254b5d0e3ed1', 'a05b6d2ffd65d4d937c0b178655d857bf4d61410', 'ebebb7a93116f14f470e062e37582a59f4aeb0df', 'a2c21314ddbba47ddbfe416e0aa14853a71179e0', '6c8a721218e7c550a98c5ba72ad9ff86afd5e3a4', '61bcd2f64860b3dfe2503be88a6bbec165db0754', ...], 'history_index': {'037fd5c655b39cc7922fb394d736496befcc747b': 8, '07fdf9d0d0248a4b0215a633c75a2dd101dcf465': 22, '0800d7d2c8c10d2f9e7b4e5127b343e916eb742c': 5, '0babf362e2373c001d4eb84f3c4eda27e56fe02d': 33, '0c9d6c44176dcc6b6ed48155a6e53130cb2c32e8': 45, '0e45095dfe50d5be759b179b50e63384925c7027': 32, '10bbd802ae07af833e53a3844fb056ba4016b893': 46, '2323c40e4e6c5f4aa333620a6b998b510ca41854': 35, '26ed0b67cf1046a22e2baba31b70ce3b6e762a03': 40, '28944b74104bc5bb782512b0eefa3167fe189355': 30, ...}, 'iteration': 52, 'max_history_score': 0.9944444444444445, 'max_history_score_std': 0.016666666666666673, 'max_history_step': 'joint'}, config={'algorithm': 'RandomForest', 'seed': 42, 'time': 300}, step='joint')
     45                 y,
     46                 cv=10,
     47                 n_jobs=-1,
     48                 return_estimator=False,
     49                 return_train_score=False,
---> 50                 verbose=0)
     51         score = np.mean(scores['test_score'])
     52         std = np.std(scores['test_score'])
     53         status = STATUS_OK
     54     except Exception as e:

...........................................................................
/home/aquemy/.local/lib/python2.7/site-packages/sklearn/model_selection/_validation.py in cross_validate(estimator=Pipeline(memory=None,
     steps=[('rebalance', ... random_state=42, verbose=0, warm_start=False))]), X=array([[1.423e+01, 1.710e+00, 2.430e+00, ..., 1...., ..., 6.100e-01, 1.600e+00,
        5.600e+02]]), y=array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,
       2, 2]), groups=None, scoring=None, cv=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1, verbose=0, fit_params=None, pre_dispatch='2*n_jobs', return_train_score=False, return_estimator=False, error_score='raise-deprecating')
    235         delayed(_fit_and_score)(
    236             clone(estimator), X, y, scorers, train, test, verbose, None,
    237             fit_params, return_train_score=return_train_score,
    238             return_times=True, return_estimator=return_estimator,
    239             error_score=error_score)
--> 240         for train, test in cv.split(X, y, groups))
        cv.split = <bound method StratifiedKFold.split of Stratifie...d(n_splits=10, random_state=None, shuffle=False)>
        X = array([[1.423e+01, 1.710e+00, 2.430e+00, ..., 1...., ..., 6.100e-01, 1.600e+00,
        5.600e+02]])
        y = array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,
       2, 2])
        groups = None
    241 
    242     zipped_scores = list(zip(*scores))
    243     if return_train_score:
    244         train_scores = zipped_scores.pop(0)

...........................................................................
/home/aquemy/.local/lib/python2.7/site-packages/sklearn/externals/joblib/parallel.py in __call__(self=Parallel(n_jobs=-1), iterable=<generator object <genexpr>>)
    925                 # No need to wait for async callbacks to trigger to
    926                 # consumption.
    927                 self._iterating = False
    928 
    929             with self._backend.retrieval_context():
--> 930                 self.retrieve()
        self.retrieve = <bound method Parallel.retrieve of Parallel(n_jobs=-1)>
    931             # Make sure that we get a last message telling us we are done
    932             elapsed_time = time.time() - self._start_time
    933             self._print('Done %3i out of %3i | elapsed: %s finished',
    934                         (len(self._output), len(self._output),

---------------------------------------------------------------------------
Joblib worker traceback:
---------------------------------------------------------------------------
ValueError                                         Mon Jun 17 12:46:06 2019
PID: 15390                                  Python 2.7.15+: /usr/bin/python
...........................................................................
/home/aquemy/.local/lib/python2.7/site-packages/sklearn/externals/joblib/parallel.py in __call__(self=<sklearn.externals.joblib.parallel.BatchedCalls object>)
    220     def __call__(self):
    221         # Set the default nested backend to self._backend but do not set the
    222         # change the default number of processes to -1
    223         with parallel_backend(self._backend, n_jobs=self._n_jobs):
    224             return [func(*args, **kwargs)
--> 225                     for func, args, kwargs in self.items]
        func = <function _fit_and_score>
        args = (Pipeline(memory=None,
     steps=[('rebalance', ... random_state=42, verbose=0, warm_start=False))]), array([[1.423e+01, 1.710e+00, 2.430e+00, ..., 1...., ..., 6.100e-01, 1.600e+00,
        5.600e+02]]), array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,
       2, 2]), {'score': <function _passthrough_scorer>}, array([  6,   7,   8,   9,  10,  11,  12,  13,  ..., 170, 171, 172, 173, 174,
       175, 176, 177]), array([  0,   1,   2,   3,   4,   5,  59,  60,  ...,  64,  65,
        66, 130, 131, 132, 133, 134]), 0, None, None)
        kwargs = {'error_score': 'raise-deprecating', 'return_estimator': False, 'return_times': True, 'return_train_score': False}
        self.items = [(<function _fit_and_score>, (Pipeline(memory=None,
     steps=[('rebalance', ... random_state=42, verbose=0, warm_start=False))]), array([[1.423e+01, 1.710e+00, 2.430e+00, ..., 1...., ..., 6.100e-01, 1.600e+00,
        5.600e+02]]), array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,
       2, 2]), {'score': <function _passthrough_scorer>}, array([  6,   7,   8,   9,  10,  11,  12,  13,  ..., 170, 171, 172, 173, 174,
       175, 176, 177]), array([  0,   1,   2,   3,   4,   5,  59,  60,  ...,  64,  65,
        66, 130, 131, 132, 133, 134]), 0, None, None), {'error_score': 'raise-deprecating', 'return_estimator': False, 'return_times': True, 'return_train_score': False})]
    226 
    227     def __len__(self):
    228         return self._size
    229 

...........................................................................
/home/aquemy/.local/lib/python2.7/site-packages/sklearn/model_selection/_validation.py in _fit_and_score(estimator=Pipeline(memory=None,
     steps=[('rebalance', ... random_state=42, verbose=0, warm_start=False))]), X=array([[1.423e+01, 1.710e+00, 2.430e+00, ..., 1...., ..., 6.100e-01, 1.600e+00,
        5.600e+02]]), y=array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,
       2, 2]), scorer={'score': <function _passthrough_scorer>}, train=array([  6,   7,   8,   9,  10,  11,  12,  13,  ..., 170, 171, 172, 173, 174,
       175, 176, 177]), test=array([  0,   1,   2,   3,   4,   5,  59,  60,  ...,  64,  65,
        66, 130, 131, 132, 133, 134]), verbose=0, parameters=None, fit_params={}, return_train_score=False, return_parameters=False, return_n_test_samples=False, return_times=True, return_estimator=False, error_score='raise-deprecating')
    523 
    524     try:
    525         if y_train is None:
    526             estimator.fit(X_train, **fit_params)
    527         else:
--> 528             estimator.fit(X_train, y_train, **fit_params)
        estimator.fit = <bound method Pipeline.fit of Pipeline(memory=No...random_state=42, verbose=0, warm_start=False))])>
        X_train = array([[1.439e+01, 1.870e+00, 2.450e+00, ..., 1...., ..., 6.100e-01, 1.600e+00,
        5.600e+02]])
        y_train = array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...2, 2, 2, 2, 2, 2, 2, 2, 2,
       2, 2, 2, 2, 2])
        fit_params = {}
    529 
    530     except Exception as e:
    531         # Note fit time as time until error
    532         fit_time = time.time() - start_time

...........................................................................
/usr/local/lib/python2.7/dist-packages/imblearn/pipeline.py in fit(self=Pipeline(memory=None,
     steps=[('rebalance', ... random_state=42, verbose=0, warm_start=False))]), X=array([[1.439e+01, 1.870e+00, 2.450e+00, ..., 1...., ..., 6.100e-01, 1.600e+00,
        5.600e+02]]), y=array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...2, 2, 2, 2, 2, 2, 2, 2, 2,
       2, 2, 2, 2, 2]), **fit_params={})
    234             This estimator
    235 
    236         """
    237         Xt, yt, fit_params = self._fit(X, y, **fit_params)
    238         if self._final_estimator is not None:
--> 239             self._final_estimator.fit(Xt, yt, **fit_params)
        self._final_estimator.fit = <bound method RandomForestClassifier.fit of Rand...e, random_state=42, verbose=0, warm_start=False)>
        Xt = array([[ 0.68908439],
       [ 1.07448168],
    ...49],
       [-1.18972742],
       [-1.11264797]])
        yt = array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,... 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2])
        fit_params = {}
    240         return self
    241 
    242     def fit_transform(self, X, y=None, **fit_params):
    243         """Fit the model and transform with the final estimator

...........................................................................
/home/aquemy/.local/lib/python2.7/site-packages/sklearn/ensemble/forest.py in fit(self=RandomForestClassifier(bootstrap=True, class_wei...se, random_state=42, verbose=0, warm_start=False), X=array([[ 0.6890844 ],
       [ 1.0744817 ],
    ....1897274 ],
       [-1.112648  ]], dtype=float32), y=array([[0.],
       [0.],
       [0.],
       [0...    [2.],
       [2.],
       [2.],
       [2.]]), sample_weight=None)
    328             trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,
    329                              **_joblib_parallel_args(prefer='threads'))(
    330                 delayed(_parallel_build_trees)(
    331                     t, self, X, y, sample_weight, i, len(trees),
    332                     verbose=self.verbose, class_weight=self.class_weight)
--> 333                 for i, t in enumerate(trees))
        i = 49
    334 
    335             # Collect newly grown trees
    336             self.estimators_.extend(trees)
    337 

...........................................................................
/home/aquemy/.local/lib/python2.7/site-packages/sklearn/externals/joblib/parallel.py in __call__(self=Parallel(n_jobs=1), iterable=<generator object <genexpr>>)
    912             # self._original_iterator is None, then this means either
    913             # that pre_dispatch == "all", n_jobs == 1 or that the first batch
    914             # was very quick and its callback already dispatched all the
    915             # remaining jobs.
    916             self._iterating = False
--> 917             if self.dispatch_one_batch(iterator):
        self.dispatch_one_batch = <bound method Parallel.dispatch_one_batch of Parallel(n_jobs=1)>
        iterator = <generator object <genexpr>>
    918                 self._iterating = self._original_iterator is not None
    919 
    920             while self.dispatch_one_batch(iterator):
    921                 pass

...........................................................................
/home/aquemy/.local/lib/python2.7/site-packages/sklearn/externals/joblib/parallel.py in dispatch_one_batch(self=Parallel(n_jobs=1), iterator=<generator object <genexpr>>)
    754                                  self._pickle_cache)
    755             if len(tasks) == 0:
    756                 # No more tasks available in the iterator: tell caller to stop.
    757                 return False
    758             else:
--> 759                 self._dispatch(tasks)
        self._dispatch = <bound method Parallel._dispatch of Parallel(n_jobs=1)>
        tasks = <sklearn.externals.joblib.parallel.BatchedCalls object>
    760                 return True
    761 
    762     def _print(self, msg, msg_args):
    763         """Display the message on stout or stderr depending on verbosity"""

...........................................................................
/home/aquemy/.local/lib/python2.7/site-packages/sklearn/externals/joblib/parallel.py in _dispatch(self=Parallel(n_jobs=1), batch=<sklearn.externals.joblib.parallel.BatchedCalls object>)
    711 
    712         dispatch_timestamp = time.time()
    713         cb = BatchCompletionCallBack(dispatch_timestamp, len(batch), self)
    714         with self._lock:
    715             job_idx = len(self._jobs)
--> 716             job = self._backend.apply_async(batch, callback=cb)
        job = undefined
        self._backend.apply_async = <bound method SequentialBackend.apply_async of <...lib._parallel_backends.SequentialBackend object>>
        batch = <sklearn.externals.joblib.parallel.BatchedCalls object>
        cb = <sklearn.externals.joblib.parallel.BatchCompletionCallBack object>
    717             # A job can complete so quickly than its callback is
    718             # called before we get here, causing self._jobs to
    719             # grow. To ensure correct results ordering, .insert is
    720             # used (rather than .append) in the following line

...........................................................................
/home/aquemy/.local/lib/python2.7/site-packages/sklearn/externals/joblib/_parallel_backends.py in apply_async(self=<sklearn.externals.joblib._parallel_backends.SequentialBackend object>, func=<sklearn.externals.joblib.parallel.BatchedCalls object>, callback=<sklearn.externals.joblib.parallel.BatchCompletionCallBack object>)
    177             raise ValueError('n_jobs == 0 in Parallel has no meaning')
    178         return 1
    179 
    180     def apply_async(self, func, callback=None):
    181         """Schedule a func to be run"""
--> 182         result = ImmediateResult(func)
        result = undefined
        func = <sklearn.externals.joblib.parallel.BatchedCalls object>
    183         if callback:
    184             callback(result)
    185         return result
    186 

...........................................................................
/home/aquemy/.local/lib/python2.7/site-packages/sklearn/externals/joblib/_parallel_backends.py in __init__(self=<sklearn.externals.joblib._parallel_backends.ImmediateResult object>, batch=<sklearn.externals.joblib.parallel.BatchedCalls object>)
    544 
    545 class ImmediateResult(object):
    546     def __init__(self, batch):
    547         # Don't delay the application, to avoid keeping the input
    548         # arguments in memory
--> 549         self.results = batch()
        self.results = undefined
        batch = <sklearn.externals.joblib.parallel.BatchedCalls object>
    550 
    551     def get(self):
    552         return self.results
    553 

...........................................................................
/home/aquemy/.local/lib/python2.7/site-packages/sklearn/externals/joblib/parallel.py in __call__(self=<sklearn.externals.joblib.parallel.BatchedCalls object>)
    220     def __call__(self):
    221         # Set the default nested backend to self._backend but do not set the
    222         # change the default number of processes to -1
    223         with parallel_backend(self._backend, n_jobs=self._n_jobs):
    224             return [func(*args, **kwargs)
--> 225                     for func, args, kwargs in self.items]
        func = <function _parallel_build_trees>
        args = (DecisionTreeClassifier(class_weight=None, criter...=False, random_state=1608637542, splitter='best'), RandomForestClassifier(bootstrap=True, class_wei...se, random_state=42, verbose=0, warm_start=False), array([[ 0.6890844 ],
       [ 1.0744817 ],
    ....1897274 ],
       [-1.112648  ]], dtype=float32), array([[0.],
       [0.],
       [0.],
       [0...    [2.],
       [2.],
       [2.],
       [2.]]), None, 0, 50)
        kwargs = {'class_weight': None, 'verbose': 0}
        self.items = [(<function _parallel_build_trees>, (DecisionTreeClassifier(class_weight=None, criter...=False, random_state=1608637542, splitter='best'), RandomForestClassifier(bootstrap=True, class_wei...se, random_state=42, verbose=0, warm_start=False), array([[ 0.6890844 ],
       [ 1.0744817 ],
    ....1897274 ],
       [-1.112648  ]], dtype=float32), array([[0.],
       [0.],
       [0.],
       [0...    [2.],
       [2.],
       [2.],
       [2.]]), None, 0, 50), {'class_weight': None, 'verbose': 0})]
    226 
    227     def __len__(self):
    228         return self._size
    229 

...........................................................................
/home/aquemy/.local/lib/python2.7/site-packages/sklearn/ensemble/forest.py in _parallel_build_trees(tree=DecisionTreeClassifier(class_weight=None, criter...=False, random_state=1608637542, splitter='best'), forest=RandomForestClassifier(bootstrap=True, class_wei...se, random_state=42, verbose=0, warm_start=False), X=array([[ 0.6890844 ],
       [ 1.0744817 ],
    ....1897274 ],
       [-1.112648  ]], dtype=float32), y=array([[0.],
       [0.],
       [0.],
       [0...    [2.],
       [2.],
       [2.],
       [2.]]), sample_weight=None, tree_idx=0, n_trees=50, verbose=0, class_weight=None)
    114                 simplefilter('ignore', DeprecationWarning)
    115                 curr_sample_weight *= compute_sample_weight('auto', y, indices)
    116         elif class_weight == 'balanced_subsample':
    117             curr_sample_weight *= compute_sample_weight('balanced', y, indices)
    118 
--> 119         tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)
        tree.fit = <bound method DecisionTreeClassifier.fit of Deci...False, random_state=1608637542, splitter='best')>
        X = array([[ 0.6890844 ],
       [ 1.0744817 ],
    ....1897274 ],
       [-1.112648  ]], dtype=float32)
        y = array([[0.],
       [0.],
       [0.],
       [0...    [2.],
       [2.],
       [2.],
       [2.]])
        sample_weight = None
        curr_sample_weight = array([3., 3., 0., 1., 1., 2., 2., 0., 1., 2., 0...,
       1., 2., 1., 3., 1., 0., 1., 0., 1., 1.])
    120     else:
    121         tree.fit(X, y, sample_weight=sample_weight, check_input=False)
    122 
    123     return tree

...........................................................................
/home/aquemy/.local/lib/python2.7/site-packages/sklearn/tree/tree.py in fit(self=DecisionTreeClassifier(class_weight=None, criter...=False, random_state=1608637542, splitter='best'), X=array([[ 0.6890844 ],
       [ 1.0744817 ],
    ....1897274 ],
       [-1.112648  ]], dtype=float32), y=array([[0.],
       [0.],
       [0.],
       [0...    [2.],
       [2.],
       [2.],
       [2.]]), sample_weight=array([3., 3., 0., 1., 1., 2., 2., 0., 1., 2., 0...,
       1., 2., 1., 3., 1., 0., 1., 0., 1., 1.]), check_input=False, X_idx_sorted=None)
    796 
    797         super(DecisionTreeClassifier, self).fit(
    798             X, y,
    799             sample_weight=sample_weight,
    800             check_input=check_input,
--> 801             X_idx_sorted=X_idx_sorted)
        X_idx_sorted = None
    802         return self
    803 
    804     def predict_proba(self, X, check_input=True):
    805         """Predict class probabilities of the input samples X.

...........................................................................
/home/aquemy/.local/lib/python2.7/site-packages/sklearn/tree/tree.py in fit(self=DecisionTreeClassifier(class_weight=None, criter...=False, random_state=1608637542, splitter='best'), X=array([[ 0.6890844 ],
       [ 1.0744817 ],
    ....1897274 ],
       [-1.112648  ]], dtype=float32), y=array([[0.],
       [0.],
       [0.],
       [0...    [2.],
       [2.],
       [2.],
       [2.]]), sample_weight=array([3., 3., 0., 1., 1., 2., 2., 0., 1., 2., 0...,
       1., 2., 1., 3., 1., 0., 1., 0., 1., 1.]), check_input=False, X_idx_sorted=None)
    237         if not 0 <= self.min_weight_fraction_leaf <= 0.5:
    238             raise ValueError("min_weight_fraction_leaf must in [0, 0.5]")
    239         if max_depth <= 0:
    240             raise ValueError("max_depth must be greater than zero. ")
    241         if not (0 < max_features <= self.n_features_):
--> 242             raise ValueError("max_features must be in (0, n_features]")
    243         if not isinstance(max_leaf_nodes, (numbers.Integral, np.integer)):
    244             raise ValueError("max_leaf_nodes must be integral number but was "
    245                              "%r" % max_leaf_nodes)
    246         if -1 < max_leaf_nodes < 2:

ValueError: max_features must be in (0, n_features]
___________________________________________________________________________
Best score: 0.994444444444 (0.0166666666667) [J] | Score: 0.0 (0.0) [J]
Best score: 0.994444444444 (0.0166666666667) [J] | Score: 0.994444444444 (0.0166666666667) [J]
Best score: 0.994444444444 (0.0166666666667) [J] | Score: 0.939146886825 (0.0518577306106) [J]
Best score: 0.994444444444 (0.0166666666667) [J] | Score: 0.927048933609 (0.0353178643097) [J]
Best score: 0.994444444444 (0.0166666666667) [J] | Score: 0.988888888889 (0.0222222222222) [J]
Best score: 0.994444444444 (0.0166666666667) [J] | Score: 0.855301857585 (0.103613137545) [J]
Best score: 0.994444444444 (0.0166666666667) [J] | Score: 0.928620571035 (0.0679808976909) [J]
Best score: 0.994444444444 (0.0166666666667) [J] | Score: 0.673105865153 (0.0899931906099) [J]
Best score: 0.994444444444 (0.0166666666667) [J] | Score: 0.988888888889 (0.0222222222222) [J]
Best score: 1.0 (0.0) [J] | Score: 1.0 (0.0) [J]
Best score: 1.0 (0.0) [J] | Score: 0.954826711386 (0.0546385737948) [J]
Best score: 1.0 (0.0) [J] | Score: 0.983006535948 (0.0259716555377) [J]
Best score: 1.0 (0.0) [J] | Score: 0.972187822497 (0.0373191871643) [J]
Best score: 1.0 (0.0) [J] | Score: 0.966339869281 (0.0510693458899) [J]
Best score: 1.0 (0.0) [J] | Score: 0.498191864465 (0.10639969439) [J]
Best score: 1.0 (0.0) [J] | Score: 0.988888888889 (0.0222222222222) [J]
Best score: 1.0 (0.0) [J] | Score: 0.895252837977 (0.0688820024158) [J]
Best score: 1.0 (0.0) [J] | Score: 0.961369109047 (0.0425859145526) [J]
Best score: 1.0 (0.0) [J] | Score: 0.768094255246 (0.147178470812) [J]
Best score: 1.0 (0.0) [J] | Score: 0.635468266254 (0.0446977405969) [J]
Best score: 1.0 (0.0) [J] | Score: 0.994444444444 (0.0166666666667) [J]
Best score: 1.0 (0.0) [J] | Score: 0.972187822497 (0.0373191871643) [J]
Best score: 1.0 (0.0) [J] | Score: 0.878551771586 (0.0987753355938) [J]
Best score: 1.0 (0.0) [J] | Score: 0.900842793258 (0.106320396762) [J]
Best score: 1.0 (0.0) [J] | Score: 0.983006535948 (0.0259716555377) [J]
Best score: 1.0 (0.0) [J] | Score: 0.768167354661 (0.163529444601) [J]
Best score: 1.0 (0.0) [J] | Score: 0.817911506708 (0.117573386292) [J]
Best score: 1.0 (0.0) [J] | Score: 0.977450980392 (0.0371587453033) [J]
Best score: 1.0 (0.0) [J] | Score: 0.847628568971 (0.0949529637841) [J]
Best score: 1.0 (0.0) [J] | Score: 0.977743378053 (0.0272938784642) [J]
Best score: 1.0 (0.0) [J] | Score: 0.878328173375 (0.0729315622787) [J]
Best score: 1.0 (0.0) [J] | Score: 0.904499914001 (0.0499935112182) [J]
Best score: 1.0 (0.0) [J] | Score: 0.988888888889 (0.0222222222222) [J]
Best score: 1.0 (0.0) [J] | Score: 0.942945906433 (0.0733541704829) [J]
Best score: 1.0 (0.0) [J] | Score: 0.884176126591 (0.0785989751115) [J]
Best score: 1.0 (0.0) [J] | Score: 0.972807017544 (0.0437239616535) [J]
Best score: 1.0 (0.0) [J] | Score: 0.965972222222 (0.0512620431499) [J]
Best score: 1.0 (0.0) [J] | Score: 0.927416580667 (0.0664637491512) [J]
Best score: 1.0 (0.0) [J] | Score: 0.944117647059 (0.0555642054012) [J]
Best score: 1.0 (0.0) [J] | Score: 0.844225146199 (0.12272799689) [J]
Best score: 1.0 (0.0) [J] | Score: 0.872411420709 (0.0739256729006) [J]
Best score: 1.0 (0.0) [J] | Score: 0.876578087375 (0.0531645425374) [J]
Best score: 1.0 (0.0) [J] | Score: 0.988888888889 (0.0222222222222) [J]
Best score: 1.0 (0.0) [J] | Score: 0.927341331269 (0.0425712395965) [J]
Best score: 1.0 (0.0) [J] | Score: 0.851025541796 (0.11447409352) [J]
Best score: 1.0 (0.0) [J] | Score: 0.988888888889 (0.0222222222222) [J]
Best score: 1.0 (0.0) [J] | Score: 0.752857327141 (0.157275469274) [J]
Best score: 1.0 (0.0) [J] | Score: 0.954424664603 (0.049826224844) [J]
Best score: 1.0 (0.0) [J] | Score: 0.915937822497 (0.0368050511809) [J]
Best score: 1.0 (0.0) [J] | Score: 0.823649810802 (0.113405934627) [J]
Best score: 1.0 (0.0) [J] | Score: 0.85701754386 (0.0981293694082) [J]
Best score: 1.0 (0.0) [J] | Score: 0.84649122807 (0.122509036984) [J]
Best score: 1.0 (0.0) [J] | Score: 0.994444444444 (0.0166666666667) [J]
Best score: 1.0 (0.0) [J] | Score: 0.994444444444 (0.0166666666667) [J]
Best score: 1.0 (0.0) [J] | Score: 0.808412882697 (0.104104973601) [J]
Best score: 1.0 (0.0) [J] | Score: 0.950257997936 (0.0574523705971) [J]
Best score: 1.0 (0.0) [J] | Score: 0.949965600275 (0.0524329814649) [J]
Best score: 1.0 (0.0) [J] | Score: 0.938779239766 (0.0518550707484) [J]
Best score: 1.0 (0.0) [J] | Score: 0.895029239766 (0.103769865966) [J]
Best score: 1.0 (0.0) [J] | Score: 0.927743378053 (0.0611174524145) [J]
Best score: 1.0 (0.0) [J] | Score: 0.584079377365 (0.0347070625992) [J]
Best score: 1.0 (0.0) [J] | Score: 0.960749914001 (0.0368115471763) [J]
Best score: 1.0 (0.0) [J] | Score: 0.900842793258 (0.100346693351) [J]
Best score: 1.0 (0.0) [J] | Score: 0.793756449948 (0.105657158768) [J]
Best score: 1.0 (0.0) [J] | Score: 0.856071551428 (0.0989554229196) [J]
Best score: 1.0 (0.0) [J] | Score: 0.744777691778 (0.13534256806) [J]
JoblibValueError
___________________________________________________________________________
...........................................................................
/home/aquemy/dev/dp_hyperparameters/extension/main.py in <module>()
     27 
     28     serializer.serialize_results(scenario, policy)
     29 
     30 if __name__ == "__main__":
     31     args = cli.parse_args()
---> 32     main(args)

...........................................................................
/home/aquemy/dev/dp_hyperparameters/extension/main.py in main(args=Namespace(customize=[(['control', 'seed'], '42')...io='./scenarios/rf_wine_joint.yaml', verbosity=0))
     21         test_size=0.4, 
     22         random_state=scenario['control']['seed']
     23     )
     24 
     25     policy = policies.initiate(scenario['setup']['policy'], config)
---> 26     policy.run(X,y)
        policy.run = <bound method Joint.run of <experiment.policies.joint.Joint object>>
        X = array([[1.423e+01, 1.710e+00, 2.430e+00, ..., 1...., ..., 6.100e-01, 1.600e+00,
        5.600e+02]])
        y = array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,
       2, 2])
     27 
     28     serializer.serialize_results(scenario, policy)
     29 
     30 if __name__ == "__main__":

...........................................................................
/home/aquemy/dev/dp_hyperparameters/extension/experiment/policies/joint.py in run(self=<experiment.policies.joint.Joint object>, X=array([[1.423e+01, 1.710e+00, 2.430e+00, ..., 1...., ..., 6.100e-01, 1.600e+00,
        5.600e+02]]), y=array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,
       2, 2]))
     32             algo=tpe.suggest, 
     33             max_evals=None,
     34             max_time=self.config['time'],     
     35             trials=trials,
     36             show_progressbar=False,
---> 37             verbose=0
     38         )
     39 
     40         best_config = self.context['best_config']
     41         super(Joint, self).display_step_results(best_config)

...........................................................................
/home/aquemy/dev/dp_hyperparameters/extension/hyperopt/fmin.py in fmin(fn=<functools.partial object>, space={'algorithm': {'bootstrap': <hyperopt.pyll.base.Apply object>, 'criterion': <hyperopt.pyll.base.Apply object>, 'max_depth': <hyperopt.pyll.base.Apply object>, 'max_features': <hyperopt.pyll.base.Apply object>, 'max_leaf_nodes': <hyperopt.pyll.base.Apply object>, 'min_samples_split': <hyperopt.pyll.base.Apply object>, 'n_estimators': <hyperopt.pyll.base.Apply object>}, 'pipeline': {'features': <hyperopt.pyll.base.Apply object>, 'normalizer': <hyperopt.pyll.base.Apply object>, 'rebalance': <hyperopt.pyll.base.Apply object>}}, algo=<function suggest>, max_evals=9223372036854775807, max_time=300, trials=<hyperopt.base.Trials object>, rstate=<mtrand.RandomState object>, allow_trials_fmin=True, pass_expr_memo_ctrl=None, catch_eval_exceptions=False, verbose=0, return_argmin=True, points_to_evaluate=None, max_queue_len=1, show_progressbar=False)
    406             pass_expr_memo_ctrl=pass_expr_memo_ctrl,
    407             verbose=verbose,
    408             catch_eval_exceptions=catch_eval_exceptions,
    409             return_argmin=return_argmin,
    410             show_progressbar=show_progressbar,
--> 411             max_time=max_time
        max_time = 300
    412         )
    413 
    414     if trials is None:
    415         if points_to_evaluate is None:

...........................................................................
/home/aquemy/dev/dp_hyperparameters/extension/hyperopt/base.py in fmin(self=<hyperopt.base.Trials object>, fn=<functools.partial object>, space={'algorithm': {'bootstrap': <hyperopt.pyll.base.Apply object>, 'criterion': <hyperopt.pyll.base.Apply object>, 'max_depth': <hyperopt.pyll.base.Apply object>, 'max_features': <hyperopt.pyll.base.Apply object>, 'max_leaf_nodes': <hyperopt.pyll.base.Apply object>, 'min_samples_split': <hyperopt.pyll.base.Apply object>, 'n_estimators': <hyperopt.pyll.base.Apply object>}, 'pipeline': {'features': <hyperopt.pyll.base.Apply object>, 'normalizer': <hyperopt.pyll.base.Apply object>, 'rebalance': <hyperopt.pyll.base.Apply object>}}, algo=<function suggest>, max_evals=9223372036854775807, max_time=300, rstate=<mtrand.RandomState object>, verbose=0, pass_expr_memo_ctrl=None, catch_eval_exceptions=False, return_argmin=True, show_progressbar=False)
    636             verbose=verbose,
    637             allow_trials_fmin=False,  # -- prevent recursion
    638             pass_expr_memo_ctrl=pass_expr_memo_ctrl,
    639             catch_eval_exceptions=catch_eval_exceptions,
    640             return_argmin=return_argmin,
--> 641             show_progressbar=show_progressbar)
        show_progressbar = False
    642 
    643 
    644 def trials_from_docs(docs, validate=True, **kwargs):
    645     """Construct a Trials base class instance from a list of trials documents

...........................................................................
/home/aquemy/dev/dp_hyperparameters/extension/hyperopt/fmin.py in fmin(fn=<functools.partial object>, space={'algorithm': {'bootstrap': <hyperopt.pyll.base.Apply object>, 'criterion': <hyperopt.pyll.base.Apply object>, 'max_depth': <hyperopt.pyll.base.Apply object>, 'max_features': <hyperopt.pyll.base.Apply object>, 'max_leaf_nodes': <hyperopt.pyll.base.Apply object>, 'min_samples_split': <hyperopt.pyll.base.Apply object>, 'n_estimators': <hyperopt.pyll.base.Apply object>}, 'pipeline': {'features': <hyperopt.pyll.base.Apply object>, 'normalizer': <hyperopt.pyll.base.Apply object>, 'rebalance': <hyperopt.pyll.base.Apply object>}}, algo=<function suggest>, max_evals=9223372036854775807, max_time=300, trials=<hyperopt.base.Trials object>, rstate=<mtrand.RandomState object>, allow_trials_fmin=False, pass_expr_memo_ctrl=None, catch_eval_exceptions=False, verbose=0, return_argmin=True, points_to_evaluate=None, max_queue_len=1, show_progressbar=False)
    426                     verbose=verbose,
    427                     max_queue_len=max_queue_len,
    428                     show_progressbar=show_progressbar,
    429                     max_time=max_time)
    430     rval.catch_eval_exceptions = catch_eval_exceptions
--> 431     rval.exhaust()
        rval.exhaust = <bound method FMinIter.exhaust of <hyperopt.fmin.FMinIter object>>
    432     if return_argmin:
    433         return trials.argmin
    434     elif len(trials) > 0:
    435         # Only if there are some succesfull trail runs, return the best point in the evaluation space

...........................................................................
/home/aquemy/dev/dp_hyperparameters/extension/hyperopt/fmin.py in exhaust(self=<hyperopt.fmin.FMinIter object>)
    273             raise StopIteration()
    274         return self.trials
    275 
    276     def exhaust(self):
    277         n_done = len(self.trials)
--> 278         self.run(self.max_evals - n_done, block_until_done=self.asynchronous)
        self.run = <bound method FMinIter.run of <hyperopt.fmin.FMinIter object>>
        self.max_evals = 9223372036854775807
        n_done = 0
        self.asynchronous = False
    279         self.trials.refresh()
    280         return self
    281 
    282 

...........................................................................
/home/aquemy/dev/dp_hyperparameters/extension/hyperopt/fmin.py in run(self=<hyperopt.fmin.FMinIter object>, N=9223372036854775807, block_until_done=False)
    232                     if self.asynchronous:
    233                         # -- wait for workers to fill in the trials
    234                         time.sleep(self.poll_interval_secs)
    235                     else:
    236                         # -- loop over trials and do the jobs directly
--> 237                         self.serial_evaluate()
        self.serial_evaluate = <bound method FMinIter.serial_evaluate of <hyperopt.fmin.FMinIter object>>
    238                     try:
    239                         res = [d['result']['loss'] for d in
    240                                          self.trials.trials if
    241                                          d['result']['status'] == 'ok']

...........................................................................
/home/aquemy/dev/dp_hyperparameters/extension/hyperopt/fmin.py in serial_evaluate(self=<hyperopt.fmin.FMinIter object>, N=-1)
    138                 trial['book_time'] = now
    139                 trial['refresh_time'] = now
    140                 spec = base.spec_from_misc(trial['misc'])
    141                 ctrl = base.Ctrl(self.trials, current_trial=trial)
    142                 try:
--> 143                     result = self.domain.evaluate(spec, ctrl)
        result = undefined
        self.domain.evaluate = <bound method Domain.evaluate of <hyperopt.base.Domain object>>
        spec = {'bootstrap': 1, 'criterion': 0, 'features': 1, 'features_PCA_features__n_components': 0, 'max_depth': 4, 'max_features': 1, 'max_leaf_nodes': 2, 'min_samples_split': 2, 'n_estimators': 4, 'normalizer': 3, ...}
        ctrl = <hyperopt.base.Ctrl object>
    144                 except Exception as e:
    145                     logger.info('job exception: %s' % str(e))
    146                     trial['state'] = base.JOB_STATE_ERROR
    147                     trial['misc']['error'] = (str(type(e)), str(e))

...........................................................................
/home/aquemy/dev/dp_hyperparameters/extension/hyperopt/base.py in evaluate(self=<hyperopt.base.Domain object>, config={'bootstrap': 1, 'criterion': 0, 'features': 1, 'features_PCA_features__n_components': 0, 'max_depth': 4, 'max_features': 1, 'max_leaf_nodes': 2, 'min_samples_split': 2, 'n_estimators': 4, 'normalizer': 3, ...}, ctrl=<hyperopt.base.Ctrl object>, attach_attachments=True)
    841             #    or the normal Python part (self.fn)
    842             pyll_rval = pyll.rec_eval(
    843                 self.expr,
    844                 memo=memo,
    845                 print_node_on_error=self.rec_eval_print_node_on_error)
--> 846             rval = self.fn(pyll_rval)
        rval = undefined
        self.fn = <functools.partial object>
        pyll_rval = {'algorithm': {'bootstrap': False, 'criterion': 'gini', 'max_depth': None, 'max_features': 2, 'max_leaf_nodes': 5, 'min_samples_split': 5, 'n_estimators': 100}, 'pipeline': {'features': ('features_PCA', {'features__n_components': 1}), 'normalizer': ('normalizer_MinMaxScaler', {}), 'rebalance': ('rebalance_NoneType', {})}}
    847 
    848         if isinstance(rval, (float, int, np.number)):
    849             dict_rval = {'loss': float(rval), 'status': STATUS_OK}
    850         else:

...........................................................................
/home/aquemy/dev/dp_hyperparameters/extension/experiment/objective.py in objective_joint(wconfig={'algorithm': {'bootstrap': False, 'criterion': 'gini', 'max_depth': None, 'max_features': 2, 'max_leaf_nodes': 5, 'min_samples_split': 5, 'n_estimators': 100}, 'pipeline': {'features': ('features_PCA', {'features__n_components': 1}), 'normalizer': ('normalizer_MinMaxScaler', {}), 'rebalance': ('rebalance_NoneType', {})}}, algorithm='RandomForest', X=array([[1.423e+01, 1.710e+00, 2.430e+00, ..., 1...., ..., 6.100e-01, 1.600e+00,
        5.600e+02]]), y=array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,
       2, 2]), context={'baseline_score': 0.9444100447196423, 'baseline_score_std': 0.04305547117084885, 'best_config': {'algorithm': {'bootstrap': False, 'criterion': 'gini', 'max_depth': 1, 'max_features': 1, 'max_leaf_nodes': 3, 'min_samples_split': 2, 'n_estimators': 50}, 'config_hash': {'algorithm': '41bdc0fd26679e3e9de3f47a81dcebdeb54f6274', 'config': '0ada0978fbb60b78d813177773f684a809a8f7c8', 'pipeline': 'aaf976c7c663a31fa039582d42f9e07101556a7c'}, 'duration': 0.6971359252929688, 'iteration': 62, 'loss': 0.0, 'max_history_score': 1.0, 'max_history_score_std': 0.0, 'max_history_step': 'joint', 'pipeline': {'features': ('features_NoneType', {}), 'normalizer': ('normalizer_PowerTransformer', {}), 'rebalance': ('rebalance_NoneType', {})}, 'score': 1.0, ...}, 'history': [{'algorithm': {'bootstrap': False, 'criterion': 'entropy', 'max_depth': None, 'max_features': 3, 'max_leaf_nodes': 5, 'min_samples_split': 2, 'n_estimators': 50}, 'config_hash': {'algorithm': 'b2c6464add7a35ce8048653a39338c9994de9a4f', 'config': '2e6648b63441361b4398cb94f81d2e04a830b2ef', 'pipeline': '3d44d7482e468d08c4f94457a205f3dac74084c1'}, 'duration': 0.737678050994873, 'iteration': 0, 'loss': 1.0, 'max_history_score': 0.0, 'max_history_score_std': 0.0, 'max_history_step': 'baseline', 'pipeline': {'features': ('features_PCA', {'features__n_components': 1}), 'normalizer': ('normalizer_NoneType', {}), 'rebalance': ('rebalance_CondensedNearestNeighbour', {'rebalance__n_neighbors': 3})}, 'score': 0.0, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'gini', 'max_depth': 1, 'max_features': None, 'max_leaf_nodes': 2, 'min_samples_split': 3, 'n_estimators': 25}, 'config_hash': {'algorithm': '7f71bbbfdb4e8da52b6fc33a43224183117de15e', 'config': '584343bc020d2d7bc89bd0856bc7770dae1c84fc', 'pipeline': '466ffa7ace0e442beb7c311eb214b17a4c6832b3'}, 'duration': 1.5976769924163818, 'iteration': 1, 'loss': 0.40386351909184726, 'max_history_score': 0.5961364809081527, 'max_history_score_std': 0.05351463210025494, 'max_history_step': 'joint', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 3, 'features__selectkbest__k': 3}), 'normalizer': ('normalizer_StandardScaler', {'normalizer__with_mean': True, 'normalizer__with_std': True}), 'rebalance': ('rebalance_NearMiss', {'rebalance__n_neighbors': 2})}, 'score': 0.5961364809081527, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'entropy', 'max_depth': 1, 'max_features': 2, 'max_leaf_nodes': 2, 'min_samples_split': 5, 'n_estimators': 25}, 'config_hash': {'algorithm': '897745a20d929d43e760cacee0a764bd8070daa5', 'config': 'de121d053e65def047cc8947f505578d5c5eab67', 'pipeline': '63040b39b48626a8232e847e8327bdca5cd88611'}, 'duration': 0.815453052520752, 'iteration': 2, 'loss': 0.07327786377708967, 'max_history_score': 0.9267221362229103, 'max_history_score_std': 0.043920207373658794, 'max_history_step': 'joint', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 3, 'features__selectkbest__k': 2}), 'normalizer': ('normalizer_StandardScaler', {'normalizer__with_mean': True, 'normalizer__with_std': True}), 'rebalance': ('rebalance_NoneType', {})}, 'score': 0.9267221362229103, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'entropy', 'max_depth': 4, 'max_features': 3, 'max_leaf_nodes': None, 'min_samples_split': 2, 'n_estimators': 100}, 'config_hash': {'algorithm': 'dbd92c75280ec06b66ca4ad9b135cf36957031a4', 'config': 'b21c9d15a389baa5bfea4c8ddcec129259f37540', 'pipeline': '38866720d2f120c863351493b9b4e23b9a4506dc'}, 'duration': 1.2293269634246826, 'iteration': 3, 'loss': 0.07199862401100798, 'max_history_score': 0.928001375988992, 'max_history_score_std': 0.06518367535896959, 'max_history_step': 'joint', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 2, 'features__selectkbest__k': 4}), 'normalizer': ('normalizer_NoneType', {}), 'rebalance': ('rebalance_NoneType', {})}, 'score': 0.928001375988992, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': 2, 'max_features': None, 'max_leaf_nodes': None, 'min_samples_split': 5, 'n_estimators': 100}, 'config_hash': {'algorithm': 'f455eefd9fdd03ece88892c3f440c580bdf27ddb', 'config': 'edd3456355d80775739c31515c832ca7b4e5e094', 'pipeline': '1d1034f9f0871e43f896c1db4ed6fd572ed0a6ef'}, 'duration': 1.6186630725860596, 'iteration': 4, 'loss': 0.16651831785345705, 'max_history_score': 0.928001375988992, 'max_history_score_std': 0.06518367535896959, 'max_history_step': 'joint', 'pipeline': {'features': ('features_SelectKBest', {'features__k': 4}), 'normalizer': ('normalizer_MinMaxScaler', {}), 'rebalance': ('rebalance_CondensedNearestNeighbour', {'rebalance__n_neighbors': 1})}, 'score': 0.833481682146543, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'entropy', 'max_depth': 1, 'max_features': 2, 'max_leaf_nodes': None, 'min_samples_split': 2, 'n_estimators': 10}, 'config_hash': {'algorithm': '29906eaa0712a68ea145b12821d54ba445726fbf', 'config': '0800d7d2c8c10d2f9e7b4e5127b343e916eb742c', 'pipeline': '2e0f188ae61600352a7159285e0f542b4587a403'}, 'duration': 0.19410085678100586, 'iteration': 5, 'loss': 0.20164258685930514, 'max_history_score': 0.928001375988992, 'max_history_score_std': 0.06518367535896959, 'max_history_step': 'joint', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 3, 'features__selectkbest__k': 4}), 'normalizer': ('normalizer_StandardScaler', {'normalizer__with_mean': True, 'normalizer__with_std': False}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 7})}, 'score': 0.7983574131406949, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': 1, 'max_features': 1, 'max_leaf_nodes': 5, 'min_samples_split': 2, 'n_estimators': 25}, 'config_hash': {'algorithm': 'fbb7d57e38cfc08240f0af985282da418cb33556', 'config': 'd98b641879b4754f2169335626a90575e945fd7c', 'pipeline': '62463de065924498cdcd2f2f1f7e68535cdb33a5'}, 'duration': 0.3625810146331787, 'iteration': 6, 'loss': 0.14327485380116955, 'max_history_score': 0.928001375988992, 'max_history_score_std': 0.06518367535896959, 'max_history_step': 'joint', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 1, 'features__selectkbest__k': 2}), 'normalizer': ('normalizer_NoneType', {}), 'rebalance': ('rebalance_NoneType', {})}, 'score': 0.8567251461988304, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'entropy', 'max_depth': 3, 'max_features': 1, 'max_leaf_nodes': None, 'min_samples_split': 2, 'n_estimators': 75}, 'config_hash': {'algorithm': 'fb2f5d4c4d636edac929e1454ce3d02a4fb134c1', 'config': '3f83df36a6abbdf7ea4a4bdcaf6727f23529c2bb', 'pipeline': '8377b93e334656d1a93d266493b58ef9a6a1786f'}, 'duration': 0.8223779201507568, 'iteration': 7, 'loss': 0.03921568627450989, 'max_history_score': 0.9607843137254901, 'max_history_score_std': 0.043526663832084804, 'max_history_step': 'joint', 'pipeline': {'features': ('features_PCA', {'features__n_components': 3}), 'normalizer': ('normalizer_MinMaxScaler', {}), 'rebalance': ('rebalance_NearMiss', {'rebalance__n_neighbors': 1})}, 'score': 0.9607843137254901, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'gini', 'max_depth': 3, 'max_features': 3, 'max_leaf_nodes': 2, 'min_samples_split': 2, 'n_estimators': 100}, 'config_hash': {'algorithm': '3c3fde6559b918694de4668d025d5418342db1b1', 'config': '037fd5c655b39cc7922fb394d736496befcc747b', 'pipeline': '2a5032814c6c7ed21dd5bd9686923d7fc2f8acc9'}, 'duration': 1.0435099601745605, 'iteration': 8, 'loss': 0.09955925352597172, 'max_history_score': 0.9607843137254901, 'max_history_score_std': 0.043526663832084804, 'max_history_step': 'joint', 'pipeline': {'features': ('features_NoneType', {}), 'normalizer': ('normalizer_RobustScaler', {'normalizer__quantile_range': (...), 'normalizer__with_centering': True, 'normalizer__with_scaling': True}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 7})}, 'score': 0.9004407464740283, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': 2, 'max_features': 1, 'max_leaf_nodes': None, 'min_samples_split': 3, 'n_estimators': 75}, 'config_hash': {'algorithm': '42185be98371e99ac896d2c6c2d69c451cb983ff', 'config': '6609280032189b59de1afbe36f3acb1d5c273693', 'pipeline': '8aab2941fc84d84f86fa56134e50909dbf9e19f5'}, 'duration': 0.9665219783782959, 'iteration': 9, 'loss': 0.01637426900584804, 'max_history_score': 0.983625730994152, 'max_history_score_std': 0.025023500462379746, 'max_history_step': 'joint', 'pipeline': {'features': ('features_NoneType', {}), 'normalizer': ('normalizer_PowerTransformer', {}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 5})}, 'score': 0.983625730994152, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': 1, 'max_features': 3, 'max_leaf_nodes': 2, 'min_samples_split': 3, 'n_estimators': 10}, 'config_hash': {'algorithm': '62a9fe705e4cd96e762bcc9543c4a456a5a9f188', 'config': '8e1c17ac9f6e03740f380fccb833c9c3931ffc35', 'pipeline': '3d44d7482e468d08c4f94457a205f3dac74084c1'}, 'duration': 0.46930503845214844, 'iteration': 10, 'loss': 1.0, 'max_history_score': 0.983625730994152, 'max_history_score_std': 0.025023500462379746, 'max_history_step': 'joint', 'pipeline': {'features': ('features_PCA', {'features__n_components': 1}), 'normalizer': ('normalizer_NoneType', {}), 'rebalance': ('rebalance_CondensedNearestNeighbour', {'rebalance__n_neighbors': 3})}, 'score': 0.0, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'gini', 'max_depth': 4, 'max_features': 1, 'max_leaf_nodes': 3, 'min_samples_split': 2, 'n_estimators': 100}, 'config_hash': {'algorithm': '086d6ca939a757bb32edb113a567f9d38744f061', 'config': '87c03d0cb8e8500e58cacc1a0f27ce54c41a2937', 'pipeline': '8f28ef0f35d97142278f9dacb4e9d1ff082e470f'}, 'duration': 2.1196961402893066, 'iteration': 11, 'loss': 0.15471276229790154, 'max_history_score': 0.983625730994152, 'max_history_score_std': 0.025023500462379746, 'max_history_step': 'joint', 'pipeline': {'features': ('features_PCA', {'features__n_components': 1}), 'normalizer': ('normalizer_StandardScaler', {'normalizer__with_mean': True, 'normalizer__with_std': True}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 7})}, 'score': 0.8452872377020985, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'entropy', 'max_depth': 3, 'max_features': 1, 'max_leaf_nodes': 2, 'min_samples_split': 2, 'n_estimators': 25}, 'config_hash': {'algorithm': '59f64a966796648c7bebade1127fa05541b391ad', 'config': '2ab964abffa0a277a9e2ee9b5570cd258e428b62', 'pipeline': 'eef3f702fd2fed761fa6744c1640d0bf320f1d00'}, 'duration': 0.9828321933746338, 'iteration': 12, 'loss': 0.0778465772273822, 'max_history_score': 0.983625730994152, 'max_history_score_std': 0.025023500462379746, 'max_history_step': 'joint', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 3, 'features__selectkbest__k': 1}), 'normalizer': ('normalizer_PowerTransformer', {}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 6})}, 'score': 0.9221534227726178, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'gini', 'max_depth': 4, 'max_features': 2, 'max_leaf_nodes': 3, 'min_samples_split': 3, 'n_estimators': 75}, 'config_hash': {'algorithm': '6f75c2a196eb9836df2b424e095051192eaed6ea', 'config': '5c95db3ad238063227f1b36e6a006d70c834c5da', 'pipeline': '1eae01a1128bee425c4d4ca0ee97a9afd409680e'}, 'duration': 0.8217771053314209, 'iteration': 13, 'loss': 0.03863089095287242, 'max_history_score': 0.983625730994152, 'max_history_score_std': 0.025023500462379746, 'max_history_step': 'joint', 'pipeline': {'features': ('features_NoneType', {}), 'normalizer': ('normalizer_StandardScaler', {'normalizer__with_mean': False, 'normalizer__with_std': False}), 'rebalance': ('rebalance_NearMiss', {'rebalance__n_neighbors': 1})}, 'score': 0.9613691090471276, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'entropy', 'max_depth': 4, 'max_features': 2, 'max_leaf_nodes': 3, 'min_samples_split': 2, 'n_estimators': 25}, 'config_hash': {'algorithm': '8aef3174f6b8020de06b825e0424c1e54d690afd', 'config': '50fd1169b8e42190600f25152654254b5d0e3ed1', 'pipeline': '9ceaa544911dc6c687e336cb8e9dd4d15ff1ceaf'}, 'duration': 0.40307188034057617, 'iteration': 14, 'loss': 1.0, 'max_history_score': 0.983625730994152, 'max_history_score_std': 0.025023500462379746, 'max_history_step': 'joint', 'pipeline': {'features': ('features_PCA', {'features__n_components': 1}), 'normalizer': ('normalizer_RobustScaler', {'normalizer__quantile_range': (...), 'normalizer__with_centering': False, 'normalizer__with_scaling': False}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 7})}, 'score': 0.0, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'gini', 'max_depth': 1, 'max_features': 1, 'max_leaf_nodes': 3, 'min_samples_split': 3, 'n_estimators': 50}, 'config_hash': {'algorithm': '37be8b6737f4b5d5ae35da51886f302b07ba6001', 'config': 'a05b6d2ffd65d4d937c0b178655d857bf4d61410', 'pipeline': 'cfef88e895db321122f2f7b813d9267b973c2468'}, 'duration': 1.7094659805297852, 'iteration': 15, 'loss': 0.011111111111111072, 'max_history_score': 0.9888888888888889, 'max_history_score_std': 0.022222222222222233, 'max_history_step': 'joint', 'pipeline': {'features': ('features_NoneType', {}), 'normalizer': ('normalizer_NoneType', {}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 5})}, 'score': 0.9888888888888889, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'entropy', 'max_depth': None, 'max_features': 3, 'max_leaf_nodes': None, 'min_samples_split': 2, 'n_estimators': 100}, 'config_hash': {'algorithm': 'c40543ce91793e367c1892c886bc49621c22ecfb', 'config': 'ebebb7a93116f14f470e062e37582a59f4aeb0df', 'pipeline': 'b50c63e800574e8b760f55f7c4ff1fcae8816dd8'}, 'duration': 0.6425540447235107, 'iteration': 16, 'loss': 1.0, 'max_history_score': 0.9888888888888889, 'max_history_score_std': 0.022222222222222233, 'max_history_step': 'joint', 'pipeline': {'features': ('features_PCA', {'features__n_components': 1}), 'normalizer': ('normalizer_PowerTransformer', {}), 'rebalance': ('rebalance_NearMiss', {'rebalance__n_neighbors': 1})}, 'score': 0.0, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'gini', 'max_depth': None, 'max_features': 1, 'max_leaf_nodes': 3, 'min_samples_split': 2, 'n_estimators': 50}, 'config_hash': {'algorithm': '0c69b9601237c20664085fa05764d855e28f98f7', 'config': 'a2c21314ddbba47ddbfe416e0aa14853a71179e0', 'pipeline': '914f81fa4fbb61db251201f32bd8ea11bfeea2a5'}, 'duration': 2.2209739685058594, 'iteration': 17, 'loss': 0.3206720846233231, 'max_history_score': 0.9888888888888889, 'max_history_score_std': 0.022222222222222233, 'max_history_step': 'joint', 'pipeline': {'features': ('features_SelectKBest', {'features__k': 4}), 'normalizer': ('normalizer_PowerTransformer', {}), 'rebalance': ('rebalance_CondensedNearestNeighbour', {'rebalance__n_neighbors': 1})}, 'score': 0.6793279153766769, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': 4, 'max_features': None, 'max_leaf_nodes': None, 'min_samples_split': 3, 'n_estimators': 25}, 'config_hash': {'algorithm': '1aae0f1fce5cab293ffdd4581c4838c8051ac815', 'config': '6c8a721218e7c550a98c5ba72ad9ff86afd5e3a4', 'pipeline': '77189452469cef9c840643f2babe0f825c6667c8'}, 'duration': 0.3951280117034912, 'iteration': 18, 'loss': 0.1804760061919506, 'max_history_score': 0.9888888888888889, 'max_history_score_std': 0.022222222222222233, 'max_history_step': 'joint', 'pipeline': {'features': ('features_SelectKBest', {'features__k': 2}), 'normalizer': ('normalizer_NoneType', {}), 'rebalance': ('rebalance_NearMiss', {'rebalance__n_neighbors': 1})}, 'score': 0.8195239938080494, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': None, 'max_features': 3, 'max_leaf_nodes': 5, 'min_samples_split': 3, 'n_estimators': 50}, 'config_hash': {'algorithm': '0129970b8c7fe034ac8283fb518a06cfbead63d2', 'config': '61bcd2f64860b3dfe2503be88a6bbec165db0754', 'pipeline': '359f2473075ecfd9ae3ce526da96143918517601'}, 'duration': 0.7467091083526611, 'iteration': 19, 'loss': 0.09915720674234607, 'max_history_score': 0.9888888888888889, 'max_history_score_std': 0.022222222222222233, 'max_history_step': 'joint', 'pipeline': {'features': ('features_SelectKBest', {'features__k': 3}), 'normalizer': ('normalizer_RobustScaler', {'normalizer__quantile_range': (...), 'normalizer__with_centering': True, 'normalizer__with_scaling': False}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 7})}, 'score': 0.9008427932576539, ...}, ...], 'history_hash': ['2e6648b63441361b4398cb94f81d2e04a830b2ef', '584343bc020d2d7bc89bd0856bc7770dae1c84fc', 'de121d053e65def047cc8947f505578d5c5eab67', 'b21c9d15a389baa5bfea4c8ddcec129259f37540', 'edd3456355d80775739c31515c832ca7b4e5e094', '0800d7d2c8c10d2f9e7b4e5127b343e916eb742c', 'd98b641879b4754f2169335626a90575e945fd7c', '3f83df36a6abbdf7ea4a4bdcaf6727f23529c2bb', '037fd5c655b39cc7922fb394d736496befcc747b', '6609280032189b59de1afbe36f3acb1d5c273693', '8e1c17ac9f6e03740f380fccb833c9c3931ffc35', '87c03d0cb8e8500e58cacc1a0f27ce54c41a2937', '2ab964abffa0a277a9e2ee9b5570cd258e428b62', '5c95db3ad238063227f1b36e6a006d70c834c5da', '50fd1169b8e42190600f25152654254b5d0e3ed1', 'a05b6d2ffd65d4d937c0b178655d857bf4d61410', 'ebebb7a93116f14f470e062e37582a59f4aeb0df', 'a2c21314ddbba47ddbfe416e0aa14853a71179e0', '6c8a721218e7c550a98c5ba72ad9ff86afd5e3a4', '61bcd2f64860b3dfe2503be88a6bbec165db0754', ...], 'history_index': {'0018716ad6e0edc096329f31492734a67d79d3b3': 64, '01c777816cea234a1e6b73501020cf6f05ea69b9': 111, '020ec4a49249e6e129cbf2800d975e6e1c8842aa': 92, '037fd5c655b39cc7922fb394d736496befcc747b': 8, '0414a55701bd4c21bd4e55ad37a0576c56d56b3f': 94, '0650ac92dace31c01ac743925565b952112a5c82': 78, '07fdf9d0d0248a4b0215a633c75a2dd101dcf465': 22, '0800d7d2c8c10d2f9e7b4e5127b343e916eb742c': 5, '09cf55372e045d42fd53684507ba9d24737bdcec': 87, '0a142ac69e30e7fae1cad9a5b362875659cd1fb4': 118, ...}, 'iteration': 118, 'max_history_score': 1.0, 'max_history_score_std': 0.0, 'max_history_step': 'joint'}, config={'algorithm': 'RandomForest', 'seed': 42, 'time': 300})
    108 
    109 def objective_algo(algo_config, current_pipeline_config, algorithm, X, y, context, config):
    110     return objective(current_pipeline_config, algo_config, algorithm, X, y, context, config, step='algorithm')
    111 
    112 def objective_joint(wconfig, algorithm, X, y, context, config):
--> 113     return objective(wconfig['pipeline'], wconfig['algorithm'], algorithm, X, y, context, config, step='joint')
        wconfig = {'algorithm': {'bootstrap': False, 'criterion': 'gini', 'max_depth': None, 'max_features': 2, 'max_leaf_nodes': 5, 'min_samples_split': 5, 'n_estimators': 100}, 'pipeline': {'features': ('features_PCA', {'features__n_components': 1}), 'normalizer': ('normalizer_MinMaxScaler', {}), 'rebalance': ('rebalance_NoneType', {})}}
        algorithm = 'RandomForest'
        X = array([[1.423e+01, 1.710e+00, 2.430e+00, ..., 1...., ..., 6.100e-01, 1.600e+00,
        5.600e+02]])
        y = array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,
       2, 2])
        context = {'baseline_score': 0.9444100447196423, 'baseline_score_std': 0.04305547117084885, 'best_config': {'algorithm': {'bootstrap': False, 'criterion': 'gini', 'max_depth': 1, 'max_features': 1, 'max_leaf_nodes': 3, 'min_samples_split': 2, 'n_estimators': 50}, 'config_hash': {'algorithm': '41bdc0fd26679e3e9de3f47a81dcebdeb54f6274', 'config': '0ada0978fbb60b78d813177773f684a809a8f7c8', 'pipeline': 'aaf976c7c663a31fa039582d42f9e07101556a7c'}, 'duration': 0.6971359252929688, 'iteration': 62, 'loss': 0.0, 'max_history_score': 1.0, 'max_history_score_std': 0.0, 'max_history_step': 'joint', 'pipeline': {'features': ('features_NoneType', {}), 'normalizer': ('normalizer_PowerTransformer', {}), 'rebalance': ('rebalance_NoneType', {})}, 'score': 1.0, ...}, 'history': [{'algorithm': {'bootstrap': False, 'criterion': 'entropy', 'max_depth': None, 'max_features': 3, 'max_leaf_nodes': 5, 'min_samples_split': 2, 'n_estimators': 50}, 'config_hash': {'algorithm': 'b2c6464add7a35ce8048653a39338c9994de9a4f', 'config': '2e6648b63441361b4398cb94f81d2e04a830b2ef', 'pipeline': '3d44d7482e468d08c4f94457a205f3dac74084c1'}, 'duration': 0.737678050994873, 'iteration': 0, 'loss': 1.0, 'max_history_score': 0.0, 'max_history_score_std': 0.0, 'max_history_step': 'baseline', 'pipeline': {'features': ('features_PCA', {'features__n_components': 1}), 'normalizer': ('normalizer_NoneType', {}), 'rebalance': ('rebalance_CondensedNearestNeighbour', {'rebalance__n_neighbors': 3})}, 'score': 0.0, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'gini', 'max_depth': 1, 'max_features': None, 'max_leaf_nodes': 2, 'min_samples_split': 3, 'n_estimators': 25}, 'config_hash': {'algorithm': '7f71bbbfdb4e8da52b6fc33a43224183117de15e', 'config': '584343bc020d2d7bc89bd0856bc7770dae1c84fc', 'pipeline': '466ffa7ace0e442beb7c311eb214b17a4c6832b3'}, 'duration': 1.5976769924163818, 'iteration': 1, 'loss': 0.40386351909184726, 'max_history_score': 0.5961364809081527, 'max_history_score_std': 0.05351463210025494, 'max_history_step': 'joint', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 3, 'features__selectkbest__k': 3}), 'normalizer': ('normalizer_StandardScaler', {'normalizer__with_mean': True, 'normalizer__with_std': True}), 'rebalance': ('rebalance_NearMiss', {'rebalance__n_neighbors': 2})}, 'score': 0.5961364809081527, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'entropy', 'max_depth': 1, 'max_features': 2, 'max_leaf_nodes': 2, 'min_samples_split': 5, 'n_estimators': 25}, 'config_hash': {'algorithm': '897745a20d929d43e760cacee0a764bd8070daa5', 'config': 'de121d053e65def047cc8947f505578d5c5eab67', 'pipeline': '63040b39b48626a8232e847e8327bdca5cd88611'}, 'duration': 0.815453052520752, 'iteration': 2, 'loss': 0.07327786377708967, 'max_history_score': 0.9267221362229103, 'max_history_score_std': 0.043920207373658794, 'max_history_step': 'joint', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 3, 'features__selectkbest__k': 2}), 'normalizer': ('normalizer_StandardScaler', {'normalizer__with_mean': True, 'normalizer__with_std': True}), 'rebalance': ('rebalance_NoneType', {})}, 'score': 0.9267221362229103, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'entropy', 'max_depth': 4, 'max_features': 3, 'max_leaf_nodes': None, 'min_samples_split': 2, 'n_estimators': 100}, 'config_hash': {'algorithm': 'dbd92c75280ec06b66ca4ad9b135cf36957031a4', 'config': 'b21c9d15a389baa5bfea4c8ddcec129259f37540', 'pipeline': '38866720d2f120c863351493b9b4e23b9a4506dc'}, 'duration': 1.2293269634246826, 'iteration': 3, 'loss': 0.07199862401100798, 'max_history_score': 0.928001375988992, 'max_history_score_std': 0.06518367535896959, 'max_history_step': 'joint', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 2, 'features__selectkbest__k': 4}), 'normalizer': ('normalizer_NoneType', {}), 'rebalance': ('rebalance_NoneType', {})}, 'score': 0.928001375988992, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': 2, 'max_features': None, 'max_leaf_nodes': None, 'min_samples_split': 5, 'n_estimators': 100}, 'config_hash': {'algorithm': 'f455eefd9fdd03ece88892c3f440c580bdf27ddb', 'config': 'edd3456355d80775739c31515c832ca7b4e5e094', 'pipeline': '1d1034f9f0871e43f896c1db4ed6fd572ed0a6ef'}, 'duration': 1.6186630725860596, 'iteration': 4, 'loss': 0.16651831785345705, 'max_history_score': 0.928001375988992, 'max_history_score_std': 0.06518367535896959, 'max_history_step': 'joint', 'pipeline': {'features': ('features_SelectKBest', {'features__k': 4}), 'normalizer': ('normalizer_MinMaxScaler', {}), 'rebalance': ('rebalance_CondensedNearestNeighbour', {'rebalance__n_neighbors': 1})}, 'score': 0.833481682146543, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'entropy', 'max_depth': 1, 'max_features': 2, 'max_leaf_nodes': None, 'min_samples_split': 2, 'n_estimators': 10}, 'config_hash': {'algorithm': '29906eaa0712a68ea145b12821d54ba445726fbf', 'config': '0800d7d2c8c10d2f9e7b4e5127b343e916eb742c', 'pipeline': '2e0f188ae61600352a7159285e0f542b4587a403'}, 'duration': 0.19410085678100586, 'iteration': 5, 'loss': 0.20164258685930514, 'max_history_score': 0.928001375988992, 'max_history_score_std': 0.06518367535896959, 'max_history_step': 'joint', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 3, 'features__selectkbest__k': 4}), 'normalizer': ('normalizer_StandardScaler', {'normalizer__with_mean': True, 'normalizer__with_std': False}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 7})}, 'score': 0.7983574131406949, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': 1, 'max_features': 1, 'max_leaf_nodes': 5, 'min_samples_split': 2, 'n_estimators': 25}, 'config_hash': {'algorithm': 'fbb7d57e38cfc08240f0af985282da418cb33556', 'config': 'd98b641879b4754f2169335626a90575e945fd7c', 'pipeline': '62463de065924498cdcd2f2f1f7e68535cdb33a5'}, 'duration': 0.3625810146331787, 'iteration': 6, 'loss': 0.14327485380116955, 'max_history_score': 0.928001375988992, 'max_history_score_std': 0.06518367535896959, 'max_history_step': 'joint', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 1, 'features__selectkbest__k': 2}), 'normalizer': ('normalizer_NoneType', {}), 'rebalance': ('rebalance_NoneType', {})}, 'score': 0.8567251461988304, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'entropy', 'max_depth': 3, 'max_features': 1, 'max_leaf_nodes': None, 'min_samples_split': 2, 'n_estimators': 75}, 'config_hash': {'algorithm': 'fb2f5d4c4d636edac929e1454ce3d02a4fb134c1', 'config': '3f83df36a6abbdf7ea4a4bdcaf6727f23529c2bb', 'pipeline': '8377b93e334656d1a93d266493b58ef9a6a1786f'}, 'duration': 0.8223779201507568, 'iteration': 7, 'loss': 0.03921568627450989, 'max_history_score': 0.9607843137254901, 'max_history_score_std': 0.043526663832084804, 'max_history_step': 'joint', 'pipeline': {'features': ('features_PCA', {'features__n_components': 3}), 'normalizer': ('normalizer_MinMaxScaler', {}), 'rebalance': ('rebalance_NearMiss', {'rebalance__n_neighbors': 1})}, 'score': 0.9607843137254901, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'gini', 'max_depth': 3, 'max_features': 3, 'max_leaf_nodes': 2, 'min_samples_split': 2, 'n_estimators': 100}, 'config_hash': {'algorithm': '3c3fde6559b918694de4668d025d5418342db1b1', 'config': '037fd5c655b39cc7922fb394d736496befcc747b', 'pipeline': '2a5032814c6c7ed21dd5bd9686923d7fc2f8acc9'}, 'duration': 1.0435099601745605, 'iteration': 8, 'loss': 0.09955925352597172, 'max_history_score': 0.9607843137254901, 'max_history_score_std': 0.043526663832084804, 'max_history_step': 'joint', 'pipeline': {'features': ('features_NoneType', {}), 'normalizer': ('normalizer_RobustScaler', {'normalizer__quantile_range': (...), 'normalizer__with_centering': True, 'normalizer__with_scaling': True}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 7})}, 'score': 0.9004407464740283, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': 2, 'max_features': 1, 'max_leaf_nodes': None, 'min_samples_split': 3, 'n_estimators': 75}, 'config_hash': {'algorithm': '42185be98371e99ac896d2c6c2d69c451cb983ff', 'config': '6609280032189b59de1afbe36f3acb1d5c273693', 'pipeline': '8aab2941fc84d84f86fa56134e50909dbf9e19f5'}, 'duration': 0.9665219783782959, 'iteration': 9, 'loss': 0.01637426900584804, 'max_history_score': 0.983625730994152, 'max_history_score_std': 0.025023500462379746, 'max_history_step': 'joint', 'pipeline': {'features': ('features_NoneType', {}), 'normalizer': ('normalizer_PowerTransformer', {}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 5})}, 'score': 0.983625730994152, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': 1, 'max_features': 3, 'max_leaf_nodes': 2, 'min_samples_split': 3, 'n_estimators': 10}, 'config_hash': {'algorithm': '62a9fe705e4cd96e762bcc9543c4a456a5a9f188', 'config': '8e1c17ac9f6e03740f380fccb833c9c3931ffc35', 'pipeline': '3d44d7482e468d08c4f94457a205f3dac74084c1'}, 'duration': 0.46930503845214844, 'iteration': 10, 'loss': 1.0, 'max_history_score': 0.983625730994152, 'max_history_score_std': 0.025023500462379746, 'max_history_step': 'joint', 'pipeline': {'features': ('features_PCA', {'features__n_components': 1}), 'normalizer': ('normalizer_NoneType', {}), 'rebalance': ('rebalance_CondensedNearestNeighbour', {'rebalance__n_neighbors': 3})}, 'score': 0.0, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'gini', 'max_depth': 4, 'max_features': 1, 'max_leaf_nodes': 3, 'min_samples_split': 2, 'n_estimators': 100}, 'config_hash': {'algorithm': '086d6ca939a757bb32edb113a567f9d38744f061', 'config': '87c03d0cb8e8500e58cacc1a0f27ce54c41a2937', 'pipeline': '8f28ef0f35d97142278f9dacb4e9d1ff082e470f'}, 'duration': 2.1196961402893066, 'iteration': 11, 'loss': 0.15471276229790154, 'max_history_score': 0.983625730994152, 'max_history_score_std': 0.025023500462379746, 'max_history_step': 'joint', 'pipeline': {'features': ('features_PCA', {'features__n_components': 1}), 'normalizer': ('normalizer_StandardScaler', {'normalizer__with_mean': True, 'normalizer__with_std': True}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 7})}, 'score': 0.8452872377020985, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'entropy', 'max_depth': 3, 'max_features': 1, 'max_leaf_nodes': 2, 'min_samples_split': 2, 'n_estimators': 25}, 'config_hash': {'algorithm': '59f64a966796648c7bebade1127fa05541b391ad', 'config': '2ab964abffa0a277a9e2ee9b5570cd258e428b62', 'pipeline': 'eef3f702fd2fed761fa6744c1640d0bf320f1d00'}, 'duration': 0.9828321933746338, 'iteration': 12, 'loss': 0.0778465772273822, 'max_history_score': 0.983625730994152, 'max_history_score_std': 0.025023500462379746, 'max_history_step': 'joint', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 3, 'features__selectkbest__k': 1}), 'normalizer': ('normalizer_PowerTransformer', {}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 6})}, 'score': 0.9221534227726178, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'gini', 'max_depth': 4, 'max_features': 2, 'max_leaf_nodes': 3, 'min_samples_split': 3, 'n_estimators': 75}, 'config_hash': {'algorithm': '6f75c2a196eb9836df2b424e095051192eaed6ea', 'config': '5c95db3ad238063227f1b36e6a006d70c834c5da', 'pipeline': '1eae01a1128bee425c4d4ca0ee97a9afd409680e'}, 'duration': 0.8217771053314209, 'iteration': 13, 'loss': 0.03863089095287242, 'max_history_score': 0.983625730994152, 'max_history_score_std': 0.025023500462379746, 'max_history_step': 'joint', 'pipeline': {'features': ('features_NoneType', {}), 'normalizer': ('normalizer_StandardScaler', {'normalizer__with_mean': False, 'normalizer__with_std': False}), 'rebalance': ('rebalance_NearMiss', {'rebalance__n_neighbors': 1})}, 'score': 0.9613691090471276, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'entropy', 'max_depth': 4, 'max_features': 2, 'max_leaf_nodes': 3, 'min_samples_split': 2, 'n_estimators': 25}, 'config_hash': {'algorithm': '8aef3174f6b8020de06b825e0424c1e54d690afd', 'config': '50fd1169b8e42190600f25152654254b5d0e3ed1', 'pipeline': '9ceaa544911dc6c687e336cb8e9dd4d15ff1ceaf'}, 'duration': 0.40307188034057617, 'iteration': 14, 'loss': 1.0, 'max_history_score': 0.983625730994152, 'max_history_score_std': 0.025023500462379746, 'max_history_step': 'joint', 'pipeline': {'features': ('features_PCA', {'features__n_components': 1}), 'normalizer': ('normalizer_RobustScaler', {'normalizer__quantile_range': (...), 'normalizer__with_centering': False, 'normalizer__with_scaling': False}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 7})}, 'score': 0.0, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'gini', 'max_depth': 1, 'max_features': 1, 'max_leaf_nodes': 3, 'min_samples_split': 3, 'n_estimators': 50}, 'config_hash': {'algorithm': '37be8b6737f4b5d5ae35da51886f302b07ba6001', 'config': 'a05b6d2ffd65d4d937c0b178655d857bf4d61410', 'pipeline': 'cfef88e895db321122f2f7b813d9267b973c2468'}, 'duration': 1.7094659805297852, 'iteration': 15, 'loss': 0.011111111111111072, 'max_history_score': 0.9888888888888889, 'max_history_score_std': 0.022222222222222233, 'max_history_step': 'joint', 'pipeline': {'features': ('features_NoneType', {}), 'normalizer': ('normalizer_NoneType', {}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 5})}, 'score': 0.9888888888888889, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'entropy', 'max_depth': None, 'max_features': 3, 'max_leaf_nodes': None, 'min_samples_split': 2, 'n_estimators': 100}, 'config_hash': {'algorithm': 'c40543ce91793e367c1892c886bc49621c22ecfb', 'config': 'ebebb7a93116f14f470e062e37582a59f4aeb0df', 'pipeline': 'b50c63e800574e8b760f55f7c4ff1fcae8816dd8'}, 'duration': 0.6425540447235107, 'iteration': 16, 'loss': 1.0, 'max_history_score': 0.9888888888888889, 'max_history_score_std': 0.022222222222222233, 'max_history_step': 'joint', 'pipeline': {'features': ('features_PCA', {'features__n_components': 1}), 'normalizer': ('normalizer_PowerTransformer', {}), 'rebalance': ('rebalance_NearMiss', {'rebalance__n_neighbors': 1})}, 'score': 0.0, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'gini', 'max_depth': None, 'max_features': 1, 'max_leaf_nodes': 3, 'min_samples_split': 2, 'n_estimators': 50}, 'config_hash': {'algorithm': '0c69b9601237c20664085fa05764d855e28f98f7', 'config': 'a2c21314ddbba47ddbfe416e0aa14853a71179e0', 'pipeline': '914f81fa4fbb61db251201f32bd8ea11bfeea2a5'}, 'duration': 2.2209739685058594, 'iteration': 17, 'loss': 0.3206720846233231, 'max_history_score': 0.9888888888888889, 'max_history_score_std': 0.022222222222222233, 'max_history_step': 'joint', 'pipeline': {'features': ('features_SelectKBest', {'features__k': 4}), 'normalizer': ('normalizer_PowerTransformer', {}), 'rebalance': ('rebalance_CondensedNearestNeighbour', {'rebalance__n_neighbors': 1})}, 'score': 0.6793279153766769, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': 4, 'max_features': None, 'max_leaf_nodes': None, 'min_samples_split': 3, 'n_estimators': 25}, 'config_hash': {'algorithm': '1aae0f1fce5cab293ffdd4581c4838c8051ac815', 'config': '6c8a721218e7c550a98c5ba72ad9ff86afd5e3a4', 'pipeline': '77189452469cef9c840643f2babe0f825c6667c8'}, 'duration': 0.3951280117034912, 'iteration': 18, 'loss': 0.1804760061919506, 'max_history_score': 0.9888888888888889, 'max_history_score_std': 0.022222222222222233, 'max_history_step': 'joint', 'pipeline': {'features': ('features_SelectKBest', {'features__k': 2}), 'normalizer': ('normalizer_NoneType', {}), 'rebalance': ('rebalance_NearMiss', {'rebalance__n_neighbors': 1})}, 'score': 0.8195239938080494, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': None, 'max_features': 3, 'max_leaf_nodes': 5, 'min_samples_split': 3, 'n_estimators': 50}, 'config_hash': {'algorithm': '0129970b8c7fe034ac8283fb518a06cfbead63d2', 'config': '61bcd2f64860b3dfe2503be88a6bbec165db0754', 'pipeline': '359f2473075ecfd9ae3ce526da96143918517601'}, 'duration': 0.7467091083526611, 'iteration': 19, 'loss': 0.09915720674234607, 'max_history_score': 0.9888888888888889, 'max_history_score_std': 0.022222222222222233, 'max_history_step': 'joint', 'pipeline': {'features': ('features_SelectKBest', {'features__k': 3}), 'normalizer': ('normalizer_RobustScaler', {'normalizer__quantile_range': (...), 'normalizer__with_centering': True, 'normalizer__with_scaling': False}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 7})}, 'score': 0.9008427932576539, ...}, ...], 'history_hash': ['2e6648b63441361b4398cb94f81d2e04a830b2ef', '584343bc020d2d7bc89bd0856bc7770dae1c84fc', 'de121d053e65def047cc8947f505578d5c5eab67', 'b21c9d15a389baa5bfea4c8ddcec129259f37540', 'edd3456355d80775739c31515c832ca7b4e5e094', '0800d7d2c8c10d2f9e7b4e5127b343e916eb742c', 'd98b641879b4754f2169335626a90575e945fd7c', '3f83df36a6abbdf7ea4a4bdcaf6727f23529c2bb', '037fd5c655b39cc7922fb394d736496befcc747b', '6609280032189b59de1afbe36f3acb1d5c273693', '8e1c17ac9f6e03740f380fccb833c9c3931ffc35', '87c03d0cb8e8500e58cacc1a0f27ce54c41a2937', '2ab964abffa0a277a9e2ee9b5570cd258e428b62', '5c95db3ad238063227f1b36e6a006d70c834c5da', '50fd1169b8e42190600f25152654254b5d0e3ed1', 'a05b6d2ffd65d4d937c0b178655d857bf4d61410', 'ebebb7a93116f14f470e062e37582a59f4aeb0df', 'a2c21314ddbba47ddbfe416e0aa14853a71179e0', '6c8a721218e7c550a98c5ba72ad9ff86afd5e3a4', '61bcd2f64860b3dfe2503be88a6bbec165db0754', ...], 'history_index': {'0018716ad6e0edc096329f31492734a67d79d3b3': 64, '01c777816cea234a1e6b73501020cf6f05ea69b9': 111, '020ec4a49249e6e129cbf2800d975e6e1c8842aa': 92, '037fd5c655b39cc7922fb394d736496befcc747b': 8, '0414a55701bd4c21bd4e55ad37a0576c56d56b3f': 94, '0650ac92dace31c01ac743925565b952112a5c82': 78, '07fdf9d0d0248a4b0215a633c75a2dd101dcf465': 22, '0800d7d2c8c10d2f9e7b4e5127b343e916eb742c': 5, '09cf55372e045d42fd53684507ba9d24737bdcec': 87, '0a142ac69e30e7fae1cad9a5b362875659cd1fb4': 118, ...}, 'iteration': 118, 'max_history_score': 1.0, 'max_history_score_std': 0.0, 'max_history_step': 'joint'}
        config = {'algorithm': 'RandomForest', 'seed': 42, 'time': 300}
    114 
    115 
    116 def get_baseline_score(algorithm, X, y, seed):
    117     pipeline, _ = pipeline_conf_to_full_pipeline(

...........................................................................
/home/aquemy/dev/dp_hyperparameters/extension/experiment/objective.py in objective(pipeline_config={'features': ('features_PCA', {'features__n_components': 1}), 'normalizer': ('normalizer_MinMaxScaler', {}), 'rebalance': ('rebalance_NoneType', {})}, algo_config={'bootstrap': False, 'criterion': 'gini', 'max_depth': None, 'max_features': 2, 'max_leaf_nodes': 5, 'min_samples_split': 5, 'n_estimators': 100}, algorithm='RandomForest', X=array([[1.423e+01, 1.710e+00, 2.430e+00, ..., 1...., ..., 6.100e-01, 1.600e+00,
        5.600e+02]]), y=array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,
       2, 2]), context={'baseline_score': 0.9444100447196423, 'baseline_score_std': 0.04305547117084885, 'best_config': {'algorithm': {'bootstrap': False, 'criterion': 'gini', 'max_depth': 1, 'max_features': 1, 'max_leaf_nodes': 3, 'min_samples_split': 2, 'n_estimators': 50}, 'config_hash': {'algorithm': '41bdc0fd26679e3e9de3f47a81dcebdeb54f6274', 'config': '0ada0978fbb60b78d813177773f684a809a8f7c8', 'pipeline': 'aaf976c7c663a31fa039582d42f9e07101556a7c'}, 'duration': 0.6971359252929688, 'iteration': 62, 'loss': 0.0, 'max_history_score': 1.0, 'max_history_score_std': 0.0, 'max_history_step': 'joint', 'pipeline': {'features': ('features_NoneType', {}), 'normalizer': ('normalizer_PowerTransformer', {}), 'rebalance': ('rebalance_NoneType', {})}, 'score': 1.0, ...}, 'history': [{'algorithm': {'bootstrap': False, 'criterion': 'entropy', 'max_depth': None, 'max_features': 3, 'max_leaf_nodes': 5, 'min_samples_split': 2, 'n_estimators': 50}, 'config_hash': {'algorithm': 'b2c6464add7a35ce8048653a39338c9994de9a4f', 'config': '2e6648b63441361b4398cb94f81d2e04a830b2ef', 'pipeline': '3d44d7482e468d08c4f94457a205f3dac74084c1'}, 'duration': 0.737678050994873, 'iteration': 0, 'loss': 1.0, 'max_history_score': 0.0, 'max_history_score_std': 0.0, 'max_history_step': 'baseline', 'pipeline': {'features': ('features_PCA', {'features__n_components': 1}), 'normalizer': ('normalizer_NoneType', {}), 'rebalance': ('rebalance_CondensedNearestNeighbour', {'rebalance__n_neighbors': 3})}, 'score': 0.0, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'gini', 'max_depth': 1, 'max_features': None, 'max_leaf_nodes': 2, 'min_samples_split': 3, 'n_estimators': 25}, 'config_hash': {'algorithm': '7f71bbbfdb4e8da52b6fc33a43224183117de15e', 'config': '584343bc020d2d7bc89bd0856bc7770dae1c84fc', 'pipeline': '466ffa7ace0e442beb7c311eb214b17a4c6832b3'}, 'duration': 1.5976769924163818, 'iteration': 1, 'loss': 0.40386351909184726, 'max_history_score': 0.5961364809081527, 'max_history_score_std': 0.05351463210025494, 'max_history_step': 'joint', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 3, 'features__selectkbest__k': 3}), 'normalizer': ('normalizer_StandardScaler', {'normalizer__with_mean': True, 'normalizer__with_std': True}), 'rebalance': ('rebalance_NearMiss', {'rebalance__n_neighbors': 2})}, 'score': 0.5961364809081527, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'entropy', 'max_depth': 1, 'max_features': 2, 'max_leaf_nodes': 2, 'min_samples_split': 5, 'n_estimators': 25}, 'config_hash': {'algorithm': '897745a20d929d43e760cacee0a764bd8070daa5', 'config': 'de121d053e65def047cc8947f505578d5c5eab67', 'pipeline': '63040b39b48626a8232e847e8327bdca5cd88611'}, 'duration': 0.815453052520752, 'iteration': 2, 'loss': 0.07327786377708967, 'max_history_score': 0.9267221362229103, 'max_history_score_std': 0.043920207373658794, 'max_history_step': 'joint', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 3, 'features__selectkbest__k': 2}), 'normalizer': ('normalizer_StandardScaler', {'normalizer__with_mean': True, 'normalizer__with_std': True}), 'rebalance': ('rebalance_NoneType', {})}, 'score': 0.9267221362229103, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'entropy', 'max_depth': 4, 'max_features': 3, 'max_leaf_nodes': None, 'min_samples_split': 2, 'n_estimators': 100}, 'config_hash': {'algorithm': 'dbd92c75280ec06b66ca4ad9b135cf36957031a4', 'config': 'b21c9d15a389baa5bfea4c8ddcec129259f37540', 'pipeline': '38866720d2f120c863351493b9b4e23b9a4506dc'}, 'duration': 1.2293269634246826, 'iteration': 3, 'loss': 0.07199862401100798, 'max_history_score': 0.928001375988992, 'max_history_score_std': 0.06518367535896959, 'max_history_step': 'joint', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 2, 'features__selectkbest__k': 4}), 'normalizer': ('normalizer_NoneType', {}), 'rebalance': ('rebalance_NoneType', {})}, 'score': 0.928001375988992, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': 2, 'max_features': None, 'max_leaf_nodes': None, 'min_samples_split': 5, 'n_estimators': 100}, 'config_hash': {'algorithm': 'f455eefd9fdd03ece88892c3f440c580bdf27ddb', 'config': 'edd3456355d80775739c31515c832ca7b4e5e094', 'pipeline': '1d1034f9f0871e43f896c1db4ed6fd572ed0a6ef'}, 'duration': 1.6186630725860596, 'iteration': 4, 'loss': 0.16651831785345705, 'max_history_score': 0.928001375988992, 'max_history_score_std': 0.06518367535896959, 'max_history_step': 'joint', 'pipeline': {'features': ('features_SelectKBest', {'features__k': 4}), 'normalizer': ('normalizer_MinMaxScaler', {}), 'rebalance': ('rebalance_CondensedNearestNeighbour', {'rebalance__n_neighbors': 1})}, 'score': 0.833481682146543, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'entropy', 'max_depth': 1, 'max_features': 2, 'max_leaf_nodes': None, 'min_samples_split': 2, 'n_estimators': 10}, 'config_hash': {'algorithm': '29906eaa0712a68ea145b12821d54ba445726fbf', 'config': '0800d7d2c8c10d2f9e7b4e5127b343e916eb742c', 'pipeline': '2e0f188ae61600352a7159285e0f542b4587a403'}, 'duration': 0.19410085678100586, 'iteration': 5, 'loss': 0.20164258685930514, 'max_history_score': 0.928001375988992, 'max_history_score_std': 0.06518367535896959, 'max_history_step': 'joint', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 3, 'features__selectkbest__k': 4}), 'normalizer': ('normalizer_StandardScaler', {'normalizer__with_mean': True, 'normalizer__with_std': False}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 7})}, 'score': 0.7983574131406949, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': 1, 'max_features': 1, 'max_leaf_nodes': 5, 'min_samples_split': 2, 'n_estimators': 25}, 'config_hash': {'algorithm': 'fbb7d57e38cfc08240f0af985282da418cb33556', 'config': 'd98b641879b4754f2169335626a90575e945fd7c', 'pipeline': '62463de065924498cdcd2f2f1f7e68535cdb33a5'}, 'duration': 0.3625810146331787, 'iteration': 6, 'loss': 0.14327485380116955, 'max_history_score': 0.928001375988992, 'max_history_score_std': 0.06518367535896959, 'max_history_step': 'joint', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 1, 'features__selectkbest__k': 2}), 'normalizer': ('normalizer_NoneType', {}), 'rebalance': ('rebalance_NoneType', {})}, 'score': 0.8567251461988304, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'entropy', 'max_depth': 3, 'max_features': 1, 'max_leaf_nodes': None, 'min_samples_split': 2, 'n_estimators': 75}, 'config_hash': {'algorithm': 'fb2f5d4c4d636edac929e1454ce3d02a4fb134c1', 'config': '3f83df36a6abbdf7ea4a4bdcaf6727f23529c2bb', 'pipeline': '8377b93e334656d1a93d266493b58ef9a6a1786f'}, 'duration': 0.8223779201507568, 'iteration': 7, 'loss': 0.03921568627450989, 'max_history_score': 0.9607843137254901, 'max_history_score_std': 0.043526663832084804, 'max_history_step': 'joint', 'pipeline': {'features': ('features_PCA', {'features__n_components': 3}), 'normalizer': ('normalizer_MinMaxScaler', {}), 'rebalance': ('rebalance_NearMiss', {'rebalance__n_neighbors': 1})}, 'score': 0.9607843137254901, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'gini', 'max_depth': 3, 'max_features': 3, 'max_leaf_nodes': 2, 'min_samples_split': 2, 'n_estimators': 100}, 'config_hash': {'algorithm': '3c3fde6559b918694de4668d025d5418342db1b1', 'config': '037fd5c655b39cc7922fb394d736496befcc747b', 'pipeline': '2a5032814c6c7ed21dd5bd9686923d7fc2f8acc9'}, 'duration': 1.0435099601745605, 'iteration': 8, 'loss': 0.09955925352597172, 'max_history_score': 0.9607843137254901, 'max_history_score_std': 0.043526663832084804, 'max_history_step': 'joint', 'pipeline': {'features': ('features_NoneType', {}), 'normalizer': ('normalizer_RobustScaler', {'normalizer__quantile_range': (...), 'normalizer__with_centering': True, 'normalizer__with_scaling': True}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 7})}, 'score': 0.9004407464740283, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': 2, 'max_features': 1, 'max_leaf_nodes': None, 'min_samples_split': 3, 'n_estimators': 75}, 'config_hash': {'algorithm': '42185be98371e99ac896d2c6c2d69c451cb983ff', 'config': '6609280032189b59de1afbe36f3acb1d5c273693', 'pipeline': '8aab2941fc84d84f86fa56134e50909dbf9e19f5'}, 'duration': 0.9665219783782959, 'iteration': 9, 'loss': 0.01637426900584804, 'max_history_score': 0.983625730994152, 'max_history_score_std': 0.025023500462379746, 'max_history_step': 'joint', 'pipeline': {'features': ('features_NoneType', {}), 'normalizer': ('normalizer_PowerTransformer', {}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 5})}, 'score': 0.983625730994152, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': 1, 'max_features': 3, 'max_leaf_nodes': 2, 'min_samples_split': 3, 'n_estimators': 10}, 'config_hash': {'algorithm': '62a9fe705e4cd96e762bcc9543c4a456a5a9f188', 'config': '8e1c17ac9f6e03740f380fccb833c9c3931ffc35', 'pipeline': '3d44d7482e468d08c4f94457a205f3dac74084c1'}, 'duration': 0.46930503845214844, 'iteration': 10, 'loss': 1.0, 'max_history_score': 0.983625730994152, 'max_history_score_std': 0.025023500462379746, 'max_history_step': 'joint', 'pipeline': {'features': ('features_PCA', {'features__n_components': 1}), 'normalizer': ('normalizer_NoneType', {}), 'rebalance': ('rebalance_CondensedNearestNeighbour', {'rebalance__n_neighbors': 3})}, 'score': 0.0, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'gini', 'max_depth': 4, 'max_features': 1, 'max_leaf_nodes': 3, 'min_samples_split': 2, 'n_estimators': 100}, 'config_hash': {'algorithm': '086d6ca939a757bb32edb113a567f9d38744f061', 'config': '87c03d0cb8e8500e58cacc1a0f27ce54c41a2937', 'pipeline': '8f28ef0f35d97142278f9dacb4e9d1ff082e470f'}, 'duration': 2.1196961402893066, 'iteration': 11, 'loss': 0.15471276229790154, 'max_history_score': 0.983625730994152, 'max_history_score_std': 0.025023500462379746, 'max_history_step': 'joint', 'pipeline': {'features': ('features_PCA', {'features__n_components': 1}), 'normalizer': ('normalizer_StandardScaler', {'normalizer__with_mean': True, 'normalizer__with_std': True}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 7})}, 'score': 0.8452872377020985, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'entropy', 'max_depth': 3, 'max_features': 1, 'max_leaf_nodes': 2, 'min_samples_split': 2, 'n_estimators': 25}, 'config_hash': {'algorithm': '59f64a966796648c7bebade1127fa05541b391ad', 'config': '2ab964abffa0a277a9e2ee9b5570cd258e428b62', 'pipeline': 'eef3f702fd2fed761fa6744c1640d0bf320f1d00'}, 'duration': 0.9828321933746338, 'iteration': 12, 'loss': 0.0778465772273822, 'max_history_score': 0.983625730994152, 'max_history_score_std': 0.025023500462379746, 'max_history_step': 'joint', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 3, 'features__selectkbest__k': 1}), 'normalizer': ('normalizer_PowerTransformer', {}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 6})}, 'score': 0.9221534227726178, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'gini', 'max_depth': 4, 'max_features': 2, 'max_leaf_nodes': 3, 'min_samples_split': 3, 'n_estimators': 75}, 'config_hash': {'algorithm': '6f75c2a196eb9836df2b424e095051192eaed6ea', 'config': '5c95db3ad238063227f1b36e6a006d70c834c5da', 'pipeline': '1eae01a1128bee425c4d4ca0ee97a9afd409680e'}, 'duration': 0.8217771053314209, 'iteration': 13, 'loss': 0.03863089095287242, 'max_history_score': 0.983625730994152, 'max_history_score_std': 0.025023500462379746, 'max_history_step': 'joint', 'pipeline': {'features': ('features_NoneType', {}), 'normalizer': ('normalizer_StandardScaler', {'normalizer__with_mean': False, 'normalizer__with_std': False}), 'rebalance': ('rebalance_NearMiss', {'rebalance__n_neighbors': 1})}, 'score': 0.9613691090471276, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'entropy', 'max_depth': 4, 'max_features': 2, 'max_leaf_nodes': 3, 'min_samples_split': 2, 'n_estimators': 25}, 'config_hash': {'algorithm': '8aef3174f6b8020de06b825e0424c1e54d690afd', 'config': '50fd1169b8e42190600f25152654254b5d0e3ed1', 'pipeline': '9ceaa544911dc6c687e336cb8e9dd4d15ff1ceaf'}, 'duration': 0.40307188034057617, 'iteration': 14, 'loss': 1.0, 'max_history_score': 0.983625730994152, 'max_history_score_std': 0.025023500462379746, 'max_history_step': 'joint', 'pipeline': {'features': ('features_PCA', {'features__n_components': 1}), 'normalizer': ('normalizer_RobustScaler', {'normalizer__quantile_range': (...), 'normalizer__with_centering': False, 'normalizer__with_scaling': False}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 7})}, 'score': 0.0, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'gini', 'max_depth': 1, 'max_features': 1, 'max_leaf_nodes': 3, 'min_samples_split': 3, 'n_estimators': 50}, 'config_hash': {'algorithm': '37be8b6737f4b5d5ae35da51886f302b07ba6001', 'config': 'a05b6d2ffd65d4d937c0b178655d857bf4d61410', 'pipeline': 'cfef88e895db321122f2f7b813d9267b973c2468'}, 'duration': 1.7094659805297852, 'iteration': 15, 'loss': 0.011111111111111072, 'max_history_score': 0.9888888888888889, 'max_history_score_std': 0.022222222222222233, 'max_history_step': 'joint', 'pipeline': {'features': ('features_NoneType', {}), 'normalizer': ('normalizer_NoneType', {}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 5})}, 'score': 0.9888888888888889, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'entropy', 'max_depth': None, 'max_features': 3, 'max_leaf_nodes': None, 'min_samples_split': 2, 'n_estimators': 100}, 'config_hash': {'algorithm': 'c40543ce91793e367c1892c886bc49621c22ecfb', 'config': 'ebebb7a93116f14f470e062e37582a59f4aeb0df', 'pipeline': 'b50c63e800574e8b760f55f7c4ff1fcae8816dd8'}, 'duration': 0.6425540447235107, 'iteration': 16, 'loss': 1.0, 'max_history_score': 0.9888888888888889, 'max_history_score_std': 0.022222222222222233, 'max_history_step': 'joint', 'pipeline': {'features': ('features_PCA', {'features__n_components': 1}), 'normalizer': ('normalizer_PowerTransformer', {}), 'rebalance': ('rebalance_NearMiss', {'rebalance__n_neighbors': 1})}, 'score': 0.0, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'gini', 'max_depth': None, 'max_features': 1, 'max_leaf_nodes': 3, 'min_samples_split': 2, 'n_estimators': 50}, 'config_hash': {'algorithm': '0c69b9601237c20664085fa05764d855e28f98f7', 'config': 'a2c21314ddbba47ddbfe416e0aa14853a71179e0', 'pipeline': '914f81fa4fbb61db251201f32bd8ea11bfeea2a5'}, 'duration': 2.2209739685058594, 'iteration': 17, 'loss': 0.3206720846233231, 'max_history_score': 0.9888888888888889, 'max_history_score_std': 0.022222222222222233, 'max_history_step': 'joint', 'pipeline': {'features': ('features_SelectKBest', {'features__k': 4}), 'normalizer': ('normalizer_PowerTransformer', {}), 'rebalance': ('rebalance_CondensedNearestNeighbour', {'rebalance__n_neighbors': 1})}, 'score': 0.6793279153766769, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': 4, 'max_features': None, 'max_leaf_nodes': None, 'min_samples_split': 3, 'n_estimators': 25}, 'config_hash': {'algorithm': '1aae0f1fce5cab293ffdd4581c4838c8051ac815', 'config': '6c8a721218e7c550a98c5ba72ad9ff86afd5e3a4', 'pipeline': '77189452469cef9c840643f2babe0f825c6667c8'}, 'duration': 0.3951280117034912, 'iteration': 18, 'loss': 0.1804760061919506, 'max_history_score': 0.9888888888888889, 'max_history_score_std': 0.022222222222222233, 'max_history_step': 'joint', 'pipeline': {'features': ('features_SelectKBest', {'features__k': 2}), 'normalizer': ('normalizer_NoneType', {}), 'rebalance': ('rebalance_NearMiss', {'rebalance__n_neighbors': 1})}, 'score': 0.8195239938080494, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': None, 'max_features': 3, 'max_leaf_nodes': 5, 'min_samples_split': 3, 'n_estimators': 50}, 'config_hash': {'algorithm': '0129970b8c7fe034ac8283fb518a06cfbead63d2', 'config': '61bcd2f64860b3dfe2503be88a6bbec165db0754', 'pipeline': '359f2473075ecfd9ae3ce526da96143918517601'}, 'duration': 0.7467091083526611, 'iteration': 19, 'loss': 0.09915720674234607, 'max_history_score': 0.9888888888888889, 'max_history_score_std': 0.022222222222222233, 'max_history_step': 'joint', 'pipeline': {'features': ('features_SelectKBest', {'features__k': 3}), 'normalizer': ('normalizer_RobustScaler', {'normalizer__quantile_range': (...), 'normalizer__with_centering': True, 'normalizer__with_scaling': False}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 7})}, 'score': 0.9008427932576539, ...}, ...], 'history_hash': ['2e6648b63441361b4398cb94f81d2e04a830b2ef', '584343bc020d2d7bc89bd0856bc7770dae1c84fc', 'de121d053e65def047cc8947f505578d5c5eab67', 'b21c9d15a389baa5bfea4c8ddcec129259f37540', 'edd3456355d80775739c31515c832ca7b4e5e094', '0800d7d2c8c10d2f9e7b4e5127b343e916eb742c', 'd98b641879b4754f2169335626a90575e945fd7c', '3f83df36a6abbdf7ea4a4bdcaf6727f23529c2bb', '037fd5c655b39cc7922fb394d736496befcc747b', '6609280032189b59de1afbe36f3acb1d5c273693', '8e1c17ac9f6e03740f380fccb833c9c3931ffc35', '87c03d0cb8e8500e58cacc1a0f27ce54c41a2937', '2ab964abffa0a277a9e2ee9b5570cd258e428b62', '5c95db3ad238063227f1b36e6a006d70c834c5da', '50fd1169b8e42190600f25152654254b5d0e3ed1', 'a05b6d2ffd65d4d937c0b178655d857bf4d61410', 'ebebb7a93116f14f470e062e37582a59f4aeb0df', 'a2c21314ddbba47ddbfe416e0aa14853a71179e0', '6c8a721218e7c550a98c5ba72ad9ff86afd5e3a4', '61bcd2f64860b3dfe2503be88a6bbec165db0754', ...], 'history_index': {'0018716ad6e0edc096329f31492734a67d79d3b3': 64, '01c777816cea234a1e6b73501020cf6f05ea69b9': 111, '020ec4a49249e6e129cbf2800d975e6e1c8842aa': 92, '037fd5c655b39cc7922fb394d736496befcc747b': 8, '0414a55701bd4c21bd4e55ad37a0576c56d56b3f': 94, '0650ac92dace31c01ac743925565b952112a5c82': 78, '07fdf9d0d0248a4b0215a633c75a2dd101dcf465': 22, '0800d7d2c8c10d2f9e7b4e5127b343e916eb742c': 5, '09cf55372e045d42fd53684507ba9d24737bdcec': 87, '0a142ac69e30e7fae1cad9a5b362875659cd1fb4': 118, ...}, 'iteration': 118, 'max_history_score': 1.0, 'max_history_score_std': 0.0, 'max_history_step': 'joint'}, config={'algorithm': 'RandomForest', 'seed': 42, 'time': 300}, step='joint')
     45                 y,
     46                 cv=10,
     47                 n_jobs=-1,
     48                 return_estimator=False,
     49                 return_train_score=False,
---> 50                 verbose=0)
     51         score = np.mean(scores['test_score'])
     52         std = np.std(scores['test_score'])
     53         status = STATUS_OK
     54     except Exception as e:

...........................................................................
/home/aquemy/.local/lib/python2.7/site-packages/sklearn/model_selection/_validation.py in cross_validate(estimator=Pipeline(memory=None,
     steps=[('normalizer',... random_state=42, verbose=0, warm_start=False))]), X=array([[1.423e+01, 1.710e+00, 2.430e+00, ..., 1...., ..., 6.100e-01, 1.600e+00,
        5.600e+02]]), y=array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,
       2, 2]), groups=None, scoring=None, cv=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1, verbose=0, fit_params=None, pre_dispatch='2*n_jobs', return_train_score=False, return_estimator=False, error_score='raise-deprecating')
    235         delayed(_fit_and_score)(
    236             clone(estimator), X, y, scorers, train, test, verbose, None,
    237             fit_params, return_train_score=return_train_score,
    238             return_times=True, return_estimator=return_estimator,
    239             error_score=error_score)
--> 240         for train, test in cv.split(X, y, groups))
        cv.split = <bound method StratifiedKFold.split of Stratifie...d(n_splits=10, random_state=None, shuffle=False)>
        X = array([[1.423e+01, 1.710e+00, 2.430e+00, ..., 1...., ..., 6.100e-01, 1.600e+00,
        5.600e+02]])
        y = array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,
       2, 2])
        groups = None
    241 
    242     zipped_scores = list(zip(*scores))
    243     if return_train_score:
    244         train_scores = zipped_scores.pop(0)

...........................................................................
/home/aquemy/.local/lib/python2.7/site-packages/sklearn/externals/joblib/parallel.py in __call__(self=Parallel(n_jobs=-1), iterable=<generator object <genexpr>>)
    925                 # No need to wait for async callbacks to trigger to
    926                 # consumption.
    927                 self._iterating = False
    928 
    929             with self._backend.retrieval_context():
--> 930                 self.retrieve()
        self.retrieve = <bound method Parallel.retrieve of Parallel(n_jobs=-1)>
    931             # Make sure that we get a last message telling us we are done
    932             elapsed_time = time.time() - self._start_time
    933             self._print('Done %3i out of %3i | elapsed: %s finished',
    934                         (len(self._output), len(self._output),

---------------------------------------------------------------------------
Joblib worker traceback:
---------------------------------------------------------------------------
ValueError                                         Mon Jun 17 12:47:06 2019
PID: 15432                                  Python 2.7.15+: /usr/bin/python
...........................................................................
/home/aquemy/.local/lib/python2.7/site-packages/sklearn/externals/joblib/parallel.py in __call__(self=<sklearn.externals.joblib.parallel.BatchedCalls object>)
    220     def __call__(self):
    221         # Set the default nested backend to self._backend but do not set the
    222         # change the default number of processes to -1
    223         with parallel_backend(self._backend, n_jobs=self._n_jobs):
    224             return [func(*args, **kwargs)
--> 225                     for func, args, kwargs in self.items]
        func = <function _fit_and_score>
        args = (Pipeline(memory=None,
     steps=[('normalizer',... random_state=42, verbose=0, warm_start=False))]), array([[1.423e+01, 1.710e+00, 2.430e+00, ..., 1...., ..., 6.100e-01, 1.600e+00,
        5.600e+02]]), array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,
       2, 2]), {'score': <function _passthrough_scorer>}, array([  6,   7,   8,   9,  10,  11,  12,  13,  ..., 170, 171, 172, 173, 174,
       175, 176, 177]), array([  0,   1,   2,   3,   4,   5,  59,  60,  ...,  64,  65,
        66, 130, 131, 132, 133, 134]), 0, None, None)
        kwargs = {'error_score': 'raise-deprecating', 'return_estimator': False, 'return_times': True, 'return_train_score': False}
        self.items = [(<function _fit_and_score>, (Pipeline(memory=None,
     steps=[('normalizer',... random_state=42, verbose=0, warm_start=False))]), array([[1.423e+01, 1.710e+00, 2.430e+00, ..., 1...., ..., 6.100e-01, 1.600e+00,
        5.600e+02]]), array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,
       2, 2]), {'score': <function _passthrough_scorer>}, array([  6,   7,   8,   9,  10,  11,  12,  13,  ..., 170, 171, 172, 173, 174,
       175, 176, 177]), array([  0,   1,   2,   3,   4,   5,  59,  60,  ...,  64,  65,
        66, 130, 131, 132, 133, 134]), 0, None, None), {'error_score': 'raise-deprecating', 'return_estimator': False, 'return_times': True, 'return_train_score': False})]
    226 
    227     def __len__(self):
    228         return self._size
    229 

...........................................................................
/home/aquemy/.local/lib/python2.7/site-packages/sklearn/model_selection/_validation.py in _fit_and_score(estimator=Pipeline(memory=None,
     steps=[('normalizer',... random_state=42, verbose=0, warm_start=False))]), X=array([[1.423e+01, 1.710e+00, 2.430e+00, ..., 1...., ..., 6.100e-01, 1.600e+00,
        5.600e+02]]), y=array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,
       2, 2]), scorer={'score': <function _passthrough_scorer>}, train=array([  6,   7,   8,   9,  10,  11,  12,  13,  ..., 170, 171, 172, 173, 174,
       175, 176, 177]), test=array([  0,   1,   2,   3,   4,   5,  59,  60,  ...,  64,  65,
        66, 130, 131, 132, 133, 134]), verbose=0, parameters=None, fit_params={}, return_train_score=False, return_parameters=False, return_n_test_samples=False, return_times=True, return_estimator=False, error_score='raise-deprecating')
    523 
    524     try:
    525         if y_train is None:
    526             estimator.fit(X_train, **fit_params)
    527         else:
--> 528             estimator.fit(X_train, y_train, **fit_params)
        estimator.fit = <bound method Pipeline.fit of Pipeline(memory=No...random_state=42, verbose=0, warm_start=False))])>
        X_train = array([[1.439e+01, 1.870e+00, 2.450e+00, ..., 1...., ..., 6.100e-01, 1.600e+00,
        5.600e+02]])
        y_train = array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...2, 2, 2, 2, 2, 2, 2, 2, 2,
       2, 2, 2, 2, 2])
        fit_params = {}
    529 
    530     except Exception as e:
    531         # Note fit time as time until error
    532         fit_time = time.time() - start_time

...........................................................................
/usr/local/lib/python2.7/dist-packages/imblearn/pipeline.py in fit(self=Pipeline(memory=None,
     steps=[('normalizer',... random_state=42, verbose=0, warm_start=False))]), X=array([[1.439e+01, 1.870e+00, 2.450e+00, ..., 1...., ..., 6.100e-01, 1.600e+00,
        5.600e+02]]), y=array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...2, 2, 2, 2, 2, 2, 2, 2, 2,
       2, 2, 2, 2, 2]), **fit_params={})
    234             This estimator
    235 
    236         """
    237         Xt, yt, fit_params = self._fit(X, y, **fit_params)
    238         if self._final_estimator is not None:
--> 239             self._final_estimator.fit(Xt, yt, **fit_params)
        self._final_estimator.fit = <bound method RandomForestClassifier.fit of Rand...e, random_state=42, verbose=0, warm_start=False)>
        Xt = array([[-5.34359176e-01],
       [-4.64738753e-0...    [ 5.86525179e-01],
       [ 7.39234465e-01]])
        yt = array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...2, 2, 2, 2, 2, 2, 2, 2, 2,
       2, 2, 2, 2, 2])
        fit_params = {}
    240         return self
    241 
    242     def fit_transform(self, X, y=None, **fit_params):
    243         """Fit the model and transform with the final estimator

...........................................................................
/home/aquemy/.local/lib/python2.7/site-packages/sklearn/ensemble/forest.py in fit(self=RandomForestClassifier(bootstrap=False, class_we...se, random_state=42, verbose=0, warm_start=False), X=array([[-5.34359157e-01],
       [-4.64738756e-0...2e-01],
       [ 7.39234447e-01]], dtype=float32), y=array([[0.],
       [0.],
       [0.],
       [0...    [2.],
       [2.],
       [2.],
       [2.]]), sample_weight=None)
    328             trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,
    329                              **_joblib_parallel_args(prefer='threads'))(
    330                 delayed(_parallel_build_trees)(
    331                     t, self, X, y, sample_weight, i, len(trees),
    332                     verbose=self.verbose, class_weight=self.class_weight)
--> 333                 for i, t in enumerate(trees))
        i = 99
    334 
    335             # Collect newly grown trees
    336             self.estimators_.extend(trees)
    337 

...........................................................................
/home/aquemy/.local/lib/python2.7/site-packages/sklearn/externals/joblib/parallel.py in __call__(self=Parallel(n_jobs=1), iterable=<generator object <genexpr>>)
    912             # self._original_iterator is None, then this means either
    913             # that pre_dispatch == "all", n_jobs == 1 or that the first batch
    914             # was very quick and its callback already dispatched all the
    915             # remaining jobs.
    916             self._iterating = False
--> 917             if self.dispatch_one_batch(iterator):
        self.dispatch_one_batch = <bound method Parallel.dispatch_one_batch of Parallel(n_jobs=1)>
        iterator = <generator object <genexpr>>
    918                 self._iterating = self._original_iterator is not None
    919 
    920             while self.dispatch_one_batch(iterator):
    921                 pass

...........................................................................
/home/aquemy/.local/lib/python2.7/site-packages/sklearn/externals/joblib/parallel.py in dispatch_one_batch(self=Parallel(n_jobs=1), iterator=<generator object <genexpr>>)
    754                                  self._pickle_cache)
    755             if len(tasks) == 0:
    756                 # No more tasks available in the iterator: tell caller to stop.
    757                 return False
    758             else:
--> 759                 self._dispatch(tasks)
        self._dispatch = <bound method Parallel._dispatch of Parallel(n_jobs=1)>
        tasks = <sklearn.externals.joblib.parallel.BatchedCalls object>
    760                 return True
    761 
    762     def _print(self, msg, msg_args):
    763         """Display the message on stout or stderr depending on verbosity"""

...........................................................................
/home/aquemy/.local/lib/python2.7/site-packages/sklearn/externals/joblib/parallel.py in _dispatch(self=Parallel(n_jobs=1), batch=<sklearn.externals.joblib.parallel.BatchedCalls object>)
    711 
    712         dispatch_timestamp = time.time()
    713         cb = BatchCompletionCallBack(dispatch_timestamp, len(batch), self)
    714         with self._lock:
    715             job_idx = len(self._jobs)
--> 716             job = self._backend.apply_async(batch, callback=cb)
        job = undefined
        self._backend.apply_async = <bound method SequentialBackend.apply_async of <...lib._parallel_backends.SequentialBackend object>>
        batch = <sklearn.externals.joblib.parallel.BatchedCalls object>
        cb = <sklearn.externals.joblib.parallel.BatchCompletionCallBack object>
    717             # A job can complete so quickly than its callback is
    718             # called before we get here, causing self._jobs to
    719             # grow. To ensure correct results ordering, .insert is
    720             # used (rather than .append) in the following line

...........................................................................
/home/aquemy/.local/lib/python2.7/site-packages/sklearn/externals/joblib/_parallel_backends.py in apply_async(self=<sklearn.externals.joblib._parallel_backends.SequentialBackend object>, func=<sklearn.externals.joblib.parallel.BatchedCalls object>, callback=<sklearn.externals.joblib.parallel.BatchCompletionCallBack object>)
    177             raise ValueError('n_jobs == 0 in Parallel has no meaning')
    178         return 1
    179 
    180     def apply_async(self, func, callback=None):
    181         """Schedule a func to be run"""
--> 182         result = ImmediateResult(func)
        result = undefined
        func = <sklearn.externals.joblib.parallel.BatchedCalls object>
    183         if callback:
    184             callback(result)
    185         return result
    186 

...........................................................................
/home/aquemy/.local/lib/python2.7/site-packages/sklearn/externals/joblib/_parallel_backends.py in __init__(self=<sklearn.externals.joblib._parallel_backends.ImmediateResult object>, batch=<sklearn.externals.joblib.parallel.BatchedCalls object>)
    544 
    545 class ImmediateResult(object):
    546     def __init__(self, batch):
    547         # Don't delay the application, to avoid keeping the input
    548         # arguments in memory
--> 549         self.results = batch()
        self.results = undefined
        batch = <sklearn.externals.joblib.parallel.BatchedCalls object>
    550 
    551     def get(self):
    552         return self.results
    553 

...........................................................................
/home/aquemy/.local/lib/python2.7/site-packages/sklearn/externals/joblib/parallel.py in __call__(self=<sklearn.externals.joblib.parallel.BatchedCalls object>)
    220     def __call__(self):
    221         # Set the default nested backend to self._backend but do not set the
    222         # change the default number of processes to -1
    223         with parallel_backend(self._backend, n_jobs=self._n_jobs):
    224             return [func(*args, **kwargs)
--> 225                     for func, args, kwargs in self.items]
        func = <function _parallel_build_trees>
        args = (DecisionTreeClassifier(class_weight=None, criter...=False, random_state=1608637542, splitter='best'), RandomForestClassifier(bootstrap=False, class_we...se, random_state=42, verbose=0, warm_start=False), array([[-5.34359157e-01],
       [-4.64738756e-0...2e-01],
       [ 7.39234447e-01]], dtype=float32), array([[0.],
       [0.],
       [0.],
       [0...    [2.],
       [2.],
       [2.],
       [2.]]), None, 0, 100)
        kwargs = {'class_weight': None, 'verbose': 0}
        self.items = [(<function _parallel_build_trees>, (DecisionTreeClassifier(class_weight=None, criter...=False, random_state=1608637542, splitter='best'), RandomForestClassifier(bootstrap=False, class_we...se, random_state=42, verbose=0, warm_start=False), array([[-5.34359157e-01],
       [-4.64738756e-0...2e-01],
       [ 7.39234447e-01]], dtype=float32), array([[0.],
       [0.],
       [0.],
       [0...    [2.],
       [2.],
       [2.],
       [2.]]), None, 0, 100), {'class_weight': None, 'verbose': 0})]
    226 
    227     def __len__(self):
    228         return self._size
    229 

...........................................................................
/home/aquemy/.local/lib/python2.7/site-packages/sklearn/ensemble/forest.py in _parallel_build_trees(tree=DecisionTreeClassifier(class_weight=None, criter...=False, random_state=1608637542, splitter='best'), forest=RandomForestClassifier(bootstrap=False, class_we...se, random_state=42, verbose=0, warm_start=False), X=array([[-5.34359157e-01],
       [-4.64738756e-0...2e-01],
       [ 7.39234447e-01]], dtype=float32), y=array([[0.],
       [0.],
       [0.],
       [0...    [2.],
       [2.],
       [2.],
       [2.]]), sample_weight=None, tree_idx=0, n_trees=100, verbose=0, class_weight=None)
    116         elif class_weight == 'balanced_subsample':
    117             curr_sample_weight *= compute_sample_weight('balanced', y, indices)
    118 
    119         tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)
    120     else:
--> 121         tree.fit(X, y, sample_weight=sample_weight, check_input=False)
        tree.fit = <bound method DecisionTreeClassifier.fit of Deci...False, random_state=1608637542, splitter='best')>
        X = array([[-5.34359157e-01],
       [-4.64738756e-0...2e-01],
       [ 7.39234447e-01]], dtype=float32)
        y = array([[0.],
       [0.],
       [0.],
       [0...    [2.],
       [2.],
       [2.],
       [2.]])
        sample_weight = None
    122 
    123     return tree
    124 
    125 

...........................................................................
/home/aquemy/.local/lib/python2.7/site-packages/sklearn/tree/tree.py in fit(self=DecisionTreeClassifier(class_weight=None, criter...=False, random_state=1608637542, splitter='best'), X=array([[-5.34359157e-01],
       [-4.64738756e-0...2e-01],
       [ 7.39234447e-01]], dtype=float32), y=array([[0.],
       [0.],
       [0.],
       [0...    [2.],
       [2.],
       [2.],
       [2.]]), sample_weight=None, check_input=False, X_idx_sorted=None)
    796 
    797         super(DecisionTreeClassifier, self).fit(
    798             X, y,
    799             sample_weight=sample_weight,
    800             check_input=check_input,
--> 801             X_idx_sorted=X_idx_sorted)
        X_idx_sorted = None
    802         return self
    803 
    804     def predict_proba(self, X, check_input=True):
    805         """Predict class probabilities of the input samples X.

...........................................................................
/home/aquemy/.local/lib/python2.7/site-packages/sklearn/tree/tree.py in fit(self=DecisionTreeClassifier(class_weight=None, criter...=False, random_state=1608637542, splitter='best'), X=array([[-5.34359157e-01],
       [-4.64738756e-0...2e-01],
       [ 7.39234447e-01]], dtype=float32), y=array([[0.],
       [0.],
       [0.],
       [0...    [2.],
       [2.],
       [2.],
       [2.]]), sample_weight=None, check_input=False, X_idx_sorted=None)
    237         if not 0 <= self.min_weight_fraction_leaf <= 0.5:
    238             raise ValueError("min_weight_fraction_leaf must in [0, 0.5]")
    239         if max_depth <= 0:
    240             raise ValueError("max_depth must be greater than zero. ")
    241         if not (0 < max_features <= self.n_features_):
--> 242             raise ValueError("max_features must be in (0, n_features]")
    243         if not isinstance(max_leaf_nodes, (numbers.Integral, np.integer)):
    244             raise ValueError("max_leaf_nodes must be integral number but was "
    245                              "%r" % max_leaf_nodes)
    246         if -1 < max_leaf_nodes < 2:

ValueError: max_features must be in (0, n_features]
___________________________________________________________________________
Best score: 1.0 (0.0) [J] | Score: 0.0 (0.0) [J]
Best score: 1.0 (0.0) [J] | Score: 0.531593997248 (0.108159957755) [J]
Best score: 1.0 (0.0) [J] | Score: 0.977743378053 (0.0272938784642) [J]
Best score: 1.0 (0.0) [J] | Score: 0.806581097351 (0.0948575062591) [J]
Best score: 1.0 (0.0) [J] | Score: 0.809795321637 (0.0903893112674) [J]
Best score: 1.0 (0.0) [J] | Score: 0.983918128655 (0.0340301135812) [J]
Best score: 1.0 (0.0) [J] | Score: 0.856398348813 (0.0988635597795) [J]
Best score: 1.0 (0.0) [J] | Score: 0.994444444444 (0.0166666666667) [J]
Best score: 1.0 (0.0) [J] | Score: 0.994444444444 (0.0166666666667) [J]
Best score: 1.0 (0.0) [J] | Score: 0.994444444444 (0.0166666666667) [J]
Best score: 1.0 (0.0) [J] | Score: 0.977777777778 (0.0509175077217) [J]
Best score: 1.0 (0.0) [J] | Score: 0.509302975576 (0.111678945496) [J]
Best score: 1.0 (0.0) [J] | Score: 0.786775455796 (0.12405865966) [J]
Best score: 1.0 (0.0) [J] | Score: 0.994444444444 (0.0166666666667) [J]
Best score: 1.0 (0.0) [J] | Score: 0.966230220158 (0.0363533344041) [J]
Best score: 1.0 (0.0) [J] | Score: 0.922772617819 (0.0605404860549) [J]
Best score: 1.0 (0.0) [J] | Score: 0.955153508772 (0.041747398576) [J]
Best score: 1.0 (0.0) [J] | Score: 0.553197024424 (0.110444305497) [J]
Best score: 1.0 (0.0) [J] | Score: 0.994444444444 (0.0166666666667) [J]
Best score: 1.0 (0.0) [J] | Score: 0.617412710698 (0.0559477664207) [J]
Best score: 1.0 (0.0) [J] | Score: 0.988888888889 (0.0222222222222) [J]
Best score: 1.0 (0.0) [J] | Score: 0.954534313725 (0.0487157144722) [J]
Best score: 1.0 (0.0) [J] | Score: 0.94441004472 (0.0430554711708) [J]
Best score: 1.0 (0.0) [J] | Score: 0.722125472996 (0.143330553871) [J]
Best score: 1.0 (0.0) [J] | Score: 0.971895424837 (0.0450032156473) [J]
Best score: 1.0 (0.0) [J] | Score: 0.983333333333 (0.0355729124302) [J]
Best score: 1.0 (0.0) [J] | Score: 0.994444444444 (0.0166666666667) [J]
Best score: 1.0 (0.0) [J] | Score: 0.889731682147 (0.101052681289) [J]
Best score: 1.0 (0.0) [J] | Score: 0.961661506708 (0.0479080516355) [J]
Best score: 1.0 (0.0) [J] | Score: 0.954901960784 (0.0426542577752) [J]
Best score: 1.0 (0.0) [J] | Score: 0.922153422773 (0.0445823087728) [J]
Best score: 1.0 (0.0) [J] | Score: 0.943530701754 (0.0793863098788) [J]
Best score: 1.0 (0.0) [J] | Score: 0.680273907809 (0.100058436854) [J]
Best score: 1.0 (0.0) [J] | Score: 0.983333333333 (0.0355729124302) [J]
Best score: 1.0 (0.0) [J] | Score: 0.92763372893 (0.0691589966796) [J]
Best score: 1.0 (0.0) [J] | Score: 0.911953904369 (0.0642246385854) [J]
Best score: 1.0 (0.0) [J] | Score: 0.954901960784 (0.0426542577752) [J]
Best score: 1.0 (0.0) [J] | Score: 0.861042311662 (0.0713894767071) [J]
Best score: 1.0 (0.0) [J] | Score: 0.911369109047 (0.0708404704781) [J]
Best score: 1.0 (0.0) [J] | Score: 0.994444444444 (0.0166666666667) [J]
Best score: 1.0 (0.0) [J] | Score: 0.994444444444 (0.0166666666667) [J]
Best score: 1.0 (0.0) [J] | Score: 0.878912968696 (0.0994641140553) [J]
Best score: 1.0 (0.0) [J] | Score: 0.888383642931 (0.0731797571716) [J]
JoblibValueError
___________________________________________________________________________
...........................................................................
/home/aquemy/dev/dp_hyperparameters/extension/main.py in <module>()
     27 
     28     serializer.serialize_results(scenario, policy)
     29 
     30 if __name__ == "__main__":
     31     args = cli.parse_args()
---> 32     main(args)

...........................................................................
/home/aquemy/dev/dp_hyperparameters/extension/main.py in main(args=Namespace(customize=[(['control', 'seed'], '42')...io='./scenarios/rf_wine_joint.yaml', verbosity=0))
     21         test_size=0.4, 
     22         random_state=scenario['control']['seed']
     23     )
     24 
     25     policy = policies.initiate(scenario['setup']['policy'], config)
---> 26     policy.run(X,y)
        policy.run = <bound method Joint.run of <experiment.policies.joint.Joint object>>
        X = array([[1.423e+01, 1.710e+00, 2.430e+00, ..., 1...., ..., 6.100e-01, 1.600e+00,
        5.600e+02]])
        y = array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,
       2, 2])
     27 
     28     serializer.serialize_results(scenario, policy)
     29 
     30 if __name__ == "__main__":

...........................................................................
/home/aquemy/dev/dp_hyperparameters/extension/experiment/policies/joint.py in run(self=<experiment.policies.joint.Joint object>, X=array([[1.423e+01, 1.710e+00, 2.430e+00, ..., 1...., ..., 6.100e-01, 1.600e+00,
        5.600e+02]]), y=array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,
       2, 2]))
     32             algo=tpe.suggest, 
     33             max_evals=None,
     34             max_time=self.config['time'],     
     35             trials=trials,
     36             show_progressbar=False,
---> 37             verbose=0
     38         )
     39 
     40         best_config = self.context['best_config']
     41         super(Joint, self).display_step_results(best_config)

...........................................................................
/home/aquemy/dev/dp_hyperparameters/extension/hyperopt/fmin.py in fmin(fn=<functools.partial object>, space={'algorithm': {'bootstrap': <hyperopt.pyll.base.Apply object>, 'criterion': <hyperopt.pyll.base.Apply object>, 'max_depth': <hyperopt.pyll.base.Apply object>, 'max_features': <hyperopt.pyll.base.Apply object>, 'max_leaf_nodes': <hyperopt.pyll.base.Apply object>, 'min_samples_split': <hyperopt.pyll.base.Apply object>, 'n_estimators': <hyperopt.pyll.base.Apply object>}, 'pipeline': {'features': <hyperopt.pyll.base.Apply object>, 'normalizer': <hyperopt.pyll.base.Apply object>, 'rebalance': <hyperopt.pyll.base.Apply object>}}, algo=<function suggest>, max_evals=9223372036854775807, max_time=300, trials=<hyperopt.base.Trials object>, rstate=<mtrand.RandomState object>, allow_trials_fmin=True, pass_expr_memo_ctrl=None, catch_eval_exceptions=False, verbose=0, return_argmin=True, points_to_evaluate=None, max_queue_len=1, show_progressbar=False)
    406             pass_expr_memo_ctrl=pass_expr_memo_ctrl,
    407             verbose=verbose,
    408             catch_eval_exceptions=catch_eval_exceptions,
    409             return_argmin=return_argmin,
    410             show_progressbar=show_progressbar,
--> 411             max_time=max_time
        max_time = 300
    412         )
    413 
    414     if trials is None:
    415         if points_to_evaluate is None:

...........................................................................
/home/aquemy/dev/dp_hyperparameters/extension/hyperopt/base.py in fmin(self=<hyperopt.base.Trials object>, fn=<functools.partial object>, space={'algorithm': {'bootstrap': <hyperopt.pyll.base.Apply object>, 'criterion': <hyperopt.pyll.base.Apply object>, 'max_depth': <hyperopt.pyll.base.Apply object>, 'max_features': <hyperopt.pyll.base.Apply object>, 'max_leaf_nodes': <hyperopt.pyll.base.Apply object>, 'min_samples_split': <hyperopt.pyll.base.Apply object>, 'n_estimators': <hyperopt.pyll.base.Apply object>}, 'pipeline': {'features': <hyperopt.pyll.base.Apply object>, 'normalizer': <hyperopt.pyll.base.Apply object>, 'rebalance': <hyperopt.pyll.base.Apply object>}}, algo=<function suggest>, max_evals=9223372036854775807, max_time=300, rstate=<mtrand.RandomState object>, verbose=0, pass_expr_memo_ctrl=None, catch_eval_exceptions=False, return_argmin=True, show_progressbar=False)
    636             verbose=verbose,
    637             allow_trials_fmin=False,  # -- prevent recursion
    638             pass_expr_memo_ctrl=pass_expr_memo_ctrl,
    639             catch_eval_exceptions=catch_eval_exceptions,
    640             return_argmin=return_argmin,
--> 641             show_progressbar=show_progressbar)
        show_progressbar = False
    642 
    643 
    644 def trials_from_docs(docs, validate=True, **kwargs):
    645     """Construct a Trials base class instance from a list of trials documents

...........................................................................
/home/aquemy/dev/dp_hyperparameters/extension/hyperopt/fmin.py in fmin(fn=<functools.partial object>, space={'algorithm': {'bootstrap': <hyperopt.pyll.base.Apply object>, 'criterion': <hyperopt.pyll.base.Apply object>, 'max_depth': <hyperopt.pyll.base.Apply object>, 'max_features': <hyperopt.pyll.base.Apply object>, 'max_leaf_nodes': <hyperopt.pyll.base.Apply object>, 'min_samples_split': <hyperopt.pyll.base.Apply object>, 'n_estimators': <hyperopt.pyll.base.Apply object>}, 'pipeline': {'features': <hyperopt.pyll.base.Apply object>, 'normalizer': <hyperopt.pyll.base.Apply object>, 'rebalance': <hyperopt.pyll.base.Apply object>}}, algo=<function suggest>, max_evals=9223372036854775807, max_time=300, trials=<hyperopt.base.Trials object>, rstate=<mtrand.RandomState object>, allow_trials_fmin=False, pass_expr_memo_ctrl=None, catch_eval_exceptions=False, verbose=0, return_argmin=True, points_to_evaluate=None, max_queue_len=1, show_progressbar=False)
    426                     verbose=verbose,
    427                     max_queue_len=max_queue_len,
    428                     show_progressbar=show_progressbar,
    429                     max_time=max_time)
    430     rval.catch_eval_exceptions = catch_eval_exceptions
--> 431     rval.exhaust()
        rval.exhaust = <bound method FMinIter.exhaust of <hyperopt.fmin.FMinIter object>>
    432     if return_argmin:
    433         return trials.argmin
    434     elif len(trials) > 0:
    435         # Only if there are some succesfull trail runs, return the best point in the evaluation space

...........................................................................
/home/aquemy/dev/dp_hyperparameters/extension/hyperopt/fmin.py in exhaust(self=<hyperopt.fmin.FMinIter object>)
    273             raise StopIteration()
    274         return self.trials
    275 
    276     def exhaust(self):
    277         n_done = len(self.trials)
--> 278         self.run(self.max_evals - n_done, block_until_done=self.asynchronous)
        self.run = <bound method FMinIter.run of <hyperopt.fmin.FMinIter object>>
        self.max_evals = 9223372036854775807
        n_done = 0
        self.asynchronous = False
    279         self.trials.refresh()
    280         return self
    281 
    282 

...........................................................................
/home/aquemy/dev/dp_hyperparameters/extension/hyperopt/fmin.py in run(self=<hyperopt.fmin.FMinIter object>, N=9223372036854775807, block_until_done=False)
    232                     if self.asynchronous:
    233                         # -- wait for workers to fill in the trials
    234                         time.sleep(self.poll_interval_secs)
    235                     else:
    236                         # -- loop over trials and do the jobs directly
--> 237                         self.serial_evaluate()
        self.serial_evaluate = <bound method FMinIter.serial_evaluate of <hyperopt.fmin.FMinIter object>>
    238                     try:
    239                         res = [d['result']['loss'] for d in
    240                                          self.trials.trials if
    241                                          d['result']['status'] == 'ok']

...........................................................................
/home/aquemy/dev/dp_hyperparameters/extension/hyperopt/fmin.py in serial_evaluate(self=<hyperopt.fmin.FMinIter object>, N=-1)
    138                 trial['book_time'] = now
    139                 trial['refresh_time'] = now
    140                 spec = base.spec_from_misc(trial['misc'])
    141                 ctrl = base.Ctrl(self.trials, current_trial=trial)
    142                 try:
--> 143                     result = self.domain.evaluate(spec, ctrl)
        result = undefined
        self.domain.evaluate = <bound method Domain.evaluate of <hyperopt.base.Domain object>>
        spec = {'bootstrap': 0, 'criterion': 0, 'features': 1, 'features_PCA_features__n_components': 0, 'max_depth': 3, 'max_features': 1, 'max_leaf_nodes': 0, 'min_samples_split': 1, 'n_estimators': 3, 'normalizer': 2, ...}
        ctrl = <hyperopt.base.Ctrl object>
    144                 except Exception as e:
    145                     logger.info('job exception: %s' % str(e))
    146                     trial['state'] = base.JOB_STATE_ERROR
    147                     trial['misc']['error'] = (str(type(e)), str(e))

...........................................................................
/home/aquemy/dev/dp_hyperparameters/extension/hyperopt/base.py in evaluate(self=<hyperopt.base.Domain object>, config={'bootstrap': 0, 'criterion': 0, 'features': 1, 'features_PCA_features__n_components': 0, 'max_depth': 3, 'max_features': 1, 'max_leaf_nodes': 0, 'min_samples_split': 1, 'n_estimators': 3, 'normalizer': 2, ...}, ctrl=<hyperopt.base.Ctrl object>, attach_attachments=True)
    841             #    or the normal Python part (self.fn)
    842             pyll_rval = pyll.rec_eval(
    843                 self.expr,
    844                 memo=memo,
    845                 print_node_on_error=self.rec_eval_print_node_on_error)
--> 846             rval = self.fn(pyll_rval)
        rval = undefined
        self.fn = <functools.partial object>
        pyll_rval = {'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': 4, 'max_features': 2, 'max_leaf_nodes': 2, 'min_samples_split': 3, 'n_estimators': 75}, 'pipeline': {'features': ('features_PCA', {'features__n_components': 1}), 'normalizer': ('normalizer_PowerTransformer', {}), 'rebalance': ('rebalance_NoneType', {})}}
    847 
    848         if isinstance(rval, (float, int, np.number)):
    849             dict_rval = {'loss': float(rval), 'status': STATUS_OK}
    850         else:

...........................................................................
/home/aquemy/dev/dp_hyperparameters/extension/experiment/objective.py in objective_joint(wconfig={'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': 4, 'max_features': 2, 'max_leaf_nodes': 2, 'min_samples_split': 3, 'n_estimators': 75}, 'pipeline': {'features': ('features_PCA', {'features__n_components': 1}), 'normalizer': ('normalizer_PowerTransformer', {}), 'rebalance': ('rebalance_NoneType', {})}}, algorithm='RandomForest', X=array([[1.423e+01, 1.710e+00, 2.430e+00, ..., 1...., ..., 6.100e-01, 1.600e+00,
        5.600e+02]]), y=array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,
       2, 2]), context={'baseline_score': 0.9444100447196423, 'baseline_score_std': 0.04305547117084885, 'best_config': {'algorithm': {'bootstrap': False, 'criterion': 'gini', 'max_depth': 1, 'max_features': 1, 'max_leaf_nodes': 3, 'min_samples_split': 2, 'n_estimators': 50}, 'config_hash': {'algorithm': '41bdc0fd26679e3e9de3f47a81dcebdeb54f6274', 'config': '0ada0978fbb60b78d813177773f684a809a8f7c8', 'pipeline': 'aaf976c7c663a31fa039582d42f9e07101556a7c'}, 'duration': 0.6971359252929688, 'iteration': 62, 'loss': 0.0, 'max_history_score': 1.0, 'max_history_score_std': 0.0, 'max_history_step': 'joint', 'pipeline': {'features': ('features_NoneType', {}), 'normalizer': ('normalizer_PowerTransformer', {}), 'rebalance': ('rebalance_NoneType', {})}, 'score': 1.0, ...}, 'history': [{'algorithm': {'bootstrap': False, 'criterion': 'entropy', 'max_depth': None, 'max_features': 3, 'max_leaf_nodes': 5, 'min_samples_split': 2, 'n_estimators': 50}, 'config_hash': {'algorithm': 'b2c6464add7a35ce8048653a39338c9994de9a4f', 'config': '2e6648b63441361b4398cb94f81d2e04a830b2ef', 'pipeline': '3d44d7482e468d08c4f94457a205f3dac74084c1'}, 'duration': 0.737678050994873, 'iteration': 0, 'loss': 1.0, 'max_history_score': 0.0, 'max_history_score_std': 0.0, 'max_history_step': 'baseline', 'pipeline': {'features': ('features_PCA', {'features__n_components': 1}), 'normalizer': ('normalizer_NoneType', {}), 'rebalance': ('rebalance_CondensedNearestNeighbour', {'rebalance__n_neighbors': 3})}, 'score': 0.0, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'gini', 'max_depth': 1, 'max_features': None, 'max_leaf_nodes': 2, 'min_samples_split': 3, 'n_estimators': 25}, 'config_hash': {'algorithm': '7f71bbbfdb4e8da52b6fc33a43224183117de15e', 'config': '584343bc020d2d7bc89bd0856bc7770dae1c84fc', 'pipeline': '466ffa7ace0e442beb7c311eb214b17a4c6832b3'}, 'duration': 1.5976769924163818, 'iteration': 1, 'loss': 0.40386351909184726, 'max_history_score': 0.5961364809081527, 'max_history_score_std': 0.05351463210025494, 'max_history_step': 'joint', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 3, 'features__selectkbest__k': 3}), 'normalizer': ('normalizer_StandardScaler', {'normalizer__with_mean': True, 'normalizer__with_std': True}), 'rebalance': ('rebalance_NearMiss', {'rebalance__n_neighbors': 2})}, 'score': 0.5961364809081527, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'entropy', 'max_depth': 1, 'max_features': 2, 'max_leaf_nodes': 2, 'min_samples_split': 5, 'n_estimators': 25}, 'config_hash': {'algorithm': '897745a20d929d43e760cacee0a764bd8070daa5', 'config': 'de121d053e65def047cc8947f505578d5c5eab67', 'pipeline': '63040b39b48626a8232e847e8327bdca5cd88611'}, 'duration': 0.815453052520752, 'iteration': 2, 'loss': 0.07327786377708967, 'max_history_score': 0.9267221362229103, 'max_history_score_std': 0.043920207373658794, 'max_history_step': 'joint', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 3, 'features__selectkbest__k': 2}), 'normalizer': ('normalizer_StandardScaler', {'normalizer__with_mean': True, 'normalizer__with_std': True}), 'rebalance': ('rebalance_NoneType', {})}, 'score': 0.9267221362229103, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'entropy', 'max_depth': 4, 'max_features': 3, 'max_leaf_nodes': None, 'min_samples_split': 2, 'n_estimators': 100}, 'config_hash': {'algorithm': 'dbd92c75280ec06b66ca4ad9b135cf36957031a4', 'config': 'b21c9d15a389baa5bfea4c8ddcec129259f37540', 'pipeline': '38866720d2f120c863351493b9b4e23b9a4506dc'}, 'duration': 1.2293269634246826, 'iteration': 3, 'loss': 0.07199862401100798, 'max_history_score': 0.928001375988992, 'max_history_score_std': 0.06518367535896959, 'max_history_step': 'joint', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 2, 'features__selectkbest__k': 4}), 'normalizer': ('normalizer_NoneType', {}), 'rebalance': ('rebalance_NoneType', {})}, 'score': 0.928001375988992, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': 2, 'max_features': None, 'max_leaf_nodes': None, 'min_samples_split': 5, 'n_estimators': 100}, 'config_hash': {'algorithm': 'f455eefd9fdd03ece88892c3f440c580bdf27ddb', 'config': 'edd3456355d80775739c31515c832ca7b4e5e094', 'pipeline': '1d1034f9f0871e43f896c1db4ed6fd572ed0a6ef'}, 'duration': 1.6186630725860596, 'iteration': 4, 'loss': 0.16651831785345705, 'max_history_score': 0.928001375988992, 'max_history_score_std': 0.06518367535896959, 'max_history_step': 'joint', 'pipeline': {'features': ('features_SelectKBest', {'features__k': 4}), 'normalizer': ('normalizer_MinMaxScaler', {}), 'rebalance': ('rebalance_CondensedNearestNeighbour', {'rebalance__n_neighbors': 1})}, 'score': 0.833481682146543, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'entropy', 'max_depth': 1, 'max_features': 2, 'max_leaf_nodes': None, 'min_samples_split': 2, 'n_estimators': 10}, 'config_hash': {'algorithm': '29906eaa0712a68ea145b12821d54ba445726fbf', 'config': '0800d7d2c8c10d2f9e7b4e5127b343e916eb742c', 'pipeline': '2e0f188ae61600352a7159285e0f542b4587a403'}, 'duration': 0.19410085678100586, 'iteration': 5, 'loss': 0.20164258685930514, 'max_history_score': 0.928001375988992, 'max_history_score_std': 0.06518367535896959, 'max_history_step': 'joint', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 3, 'features__selectkbest__k': 4}), 'normalizer': ('normalizer_StandardScaler', {'normalizer__with_mean': True, 'normalizer__with_std': False}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 7})}, 'score': 0.7983574131406949, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': 1, 'max_features': 1, 'max_leaf_nodes': 5, 'min_samples_split': 2, 'n_estimators': 25}, 'config_hash': {'algorithm': 'fbb7d57e38cfc08240f0af985282da418cb33556', 'config': 'd98b641879b4754f2169335626a90575e945fd7c', 'pipeline': '62463de065924498cdcd2f2f1f7e68535cdb33a5'}, 'duration': 0.3625810146331787, 'iteration': 6, 'loss': 0.14327485380116955, 'max_history_score': 0.928001375988992, 'max_history_score_std': 0.06518367535896959, 'max_history_step': 'joint', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 1, 'features__selectkbest__k': 2}), 'normalizer': ('normalizer_NoneType', {}), 'rebalance': ('rebalance_NoneType', {})}, 'score': 0.8567251461988304, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'entropy', 'max_depth': 3, 'max_features': 1, 'max_leaf_nodes': None, 'min_samples_split': 2, 'n_estimators': 75}, 'config_hash': {'algorithm': 'fb2f5d4c4d636edac929e1454ce3d02a4fb134c1', 'config': '3f83df36a6abbdf7ea4a4bdcaf6727f23529c2bb', 'pipeline': '8377b93e334656d1a93d266493b58ef9a6a1786f'}, 'duration': 0.8223779201507568, 'iteration': 7, 'loss': 0.03921568627450989, 'max_history_score': 0.9607843137254901, 'max_history_score_std': 0.043526663832084804, 'max_history_step': 'joint', 'pipeline': {'features': ('features_PCA', {'features__n_components': 3}), 'normalizer': ('normalizer_MinMaxScaler', {}), 'rebalance': ('rebalance_NearMiss', {'rebalance__n_neighbors': 1})}, 'score': 0.9607843137254901, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'gini', 'max_depth': 3, 'max_features': 3, 'max_leaf_nodes': 2, 'min_samples_split': 2, 'n_estimators': 100}, 'config_hash': {'algorithm': '3c3fde6559b918694de4668d025d5418342db1b1', 'config': '037fd5c655b39cc7922fb394d736496befcc747b', 'pipeline': '2a5032814c6c7ed21dd5bd9686923d7fc2f8acc9'}, 'duration': 1.0435099601745605, 'iteration': 8, 'loss': 0.09955925352597172, 'max_history_score': 0.9607843137254901, 'max_history_score_std': 0.043526663832084804, 'max_history_step': 'joint', 'pipeline': {'features': ('features_NoneType', {}), 'normalizer': ('normalizer_RobustScaler', {'normalizer__quantile_range': (...), 'normalizer__with_centering': True, 'normalizer__with_scaling': True}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 7})}, 'score': 0.9004407464740283, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': 2, 'max_features': 1, 'max_leaf_nodes': None, 'min_samples_split': 3, 'n_estimators': 75}, 'config_hash': {'algorithm': '42185be98371e99ac896d2c6c2d69c451cb983ff', 'config': '6609280032189b59de1afbe36f3acb1d5c273693', 'pipeline': '8aab2941fc84d84f86fa56134e50909dbf9e19f5'}, 'duration': 0.9665219783782959, 'iteration': 9, 'loss': 0.01637426900584804, 'max_history_score': 0.983625730994152, 'max_history_score_std': 0.025023500462379746, 'max_history_step': 'joint', 'pipeline': {'features': ('features_NoneType', {}), 'normalizer': ('normalizer_PowerTransformer', {}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 5})}, 'score': 0.983625730994152, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': 1, 'max_features': 3, 'max_leaf_nodes': 2, 'min_samples_split': 3, 'n_estimators': 10}, 'config_hash': {'algorithm': '62a9fe705e4cd96e762bcc9543c4a456a5a9f188', 'config': '8e1c17ac9f6e03740f380fccb833c9c3931ffc35', 'pipeline': '3d44d7482e468d08c4f94457a205f3dac74084c1'}, 'duration': 0.46930503845214844, 'iteration': 10, 'loss': 1.0, 'max_history_score': 0.983625730994152, 'max_history_score_std': 0.025023500462379746, 'max_history_step': 'joint', 'pipeline': {'features': ('features_PCA', {'features__n_components': 1}), 'normalizer': ('normalizer_NoneType', {}), 'rebalance': ('rebalance_CondensedNearestNeighbour', {'rebalance__n_neighbors': 3})}, 'score': 0.0, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'gini', 'max_depth': 4, 'max_features': 1, 'max_leaf_nodes': 3, 'min_samples_split': 2, 'n_estimators': 100}, 'config_hash': {'algorithm': '086d6ca939a757bb32edb113a567f9d38744f061', 'config': '87c03d0cb8e8500e58cacc1a0f27ce54c41a2937', 'pipeline': '8f28ef0f35d97142278f9dacb4e9d1ff082e470f'}, 'duration': 2.1196961402893066, 'iteration': 11, 'loss': 0.15471276229790154, 'max_history_score': 0.983625730994152, 'max_history_score_std': 0.025023500462379746, 'max_history_step': 'joint', 'pipeline': {'features': ('features_PCA', {'features__n_components': 1}), 'normalizer': ('normalizer_StandardScaler', {'normalizer__with_mean': True, 'normalizer__with_std': True}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 7})}, 'score': 0.8452872377020985, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'entropy', 'max_depth': 3, 'max_features': 1, 'max_leaf_nodes': 2, 'min_samples_split': 2, 'n_estimators': 25}, 'config_hash': {'algorithm': '59f64a966796648c7bebade1127fa05541b391ad', 'config': '2ab964abffa0a277a9e2ee9b5570cd258e428b62', 'pipeline': 'eef3f702fd2fed761fa6744c1640d0bf320f1d00'}, 'duration': 0.9828321933746338, 'iteration': 12, 'loss': 0.0778465772273822, 'max_history_score': 0.983625730994152, 'max_history_score_std': 0.025023500462379746, 'max_history_step': 'joint', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 3, 'features__selectkbest__k': 1}), 'normalizer': ('normalizer_PowerTransformer', {}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 6})}, 'score': 0.9221534227726178, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'gini', 'max_depth': 4, 'max_features': 2, 'max_leaf_nodes': 3, 'min_samples_split': 3, 'n_estimators': 75}, 'config_hash': {'algorithm': '6f75c2a196eb9836df2b424e095051192eaed6ea', 'config': '5c95db3ad238063227f1b36e6a006d70c834c5da', 'pipeline': '1eae01a1128bee425c4d4ca0ee97a9afd409680e'}, 'duration': 0.8217771053314209, 'iteration': 13, 'loss': 0.03863089095287242, 'max_history_score': 0.983625730994152, 'max_history_score_std': 0.025023500462379746, 'max_history_step': 'joint', 'pipeline': {'features': ('features_NoneType', {}), 'normalizer': ('normalizer_StandardScaler', {'normalizer__with_mean': False, 'normalizer__with_std': False}), 'rebalance': ('rebalance_NearMiss', {'rebalance__n_neighbors': 1})}, 'score': 0.9613691090471276, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'entropy', 'max_depth': 4, 'max_features': 2, 'max_leaf_nodes': 3, 'min_samples_split': 2, 'n_estimators': 25}, 'config_hash': {'algorithm': '8aef3174f6b8020de06b825e0424c1e54d690afd', 'config': '50fd1169b8e42190600f25152654254b5d0e3ed1', 'pipeline': '9ceaa544911dc6c687e336cb8e9dd4d15ff1ceaf'}, 'duration': 0.40307188034057617, 'iteration': 14, 'loss': 1.0, 'max_history_score': 0.983625730994152, 'max_history_score_std': 0.025023500462379746, 'max_history_step': 'joint', 'pipeline': {'features': ('features_PCA', {'features__n_components': 1}), 'normalizer': ('normalizer_RobustScaler', {'normalizer__quantile_range': (...), 'normalizer__with_centering': False, 'normalizer__with_scaling': False}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 7})}, 'score': 0.0, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'gini', 'max_depth': 1, 'max_features': 1, 'max_leaf_nodes': 3, 'min_samples_split': 3, 'n_estimators': 50}, 'config_hash': {'algorithm': '37be8b6737f4b5d5ae35da51886f302b07ba6001', 'config': 'a05b6d2ffd65d4d937c0b178655d857bf4d61410', 'pipeline': 'cfef88e895db321122f2f7b813d9267b973c2468'}, 'duration': 1.7094659805297852, 'iteration': 15, 'loss': 0.011111111111111072, 'max_history_score': 0.9888888888888889, 'max_history_score_std': 0.022222222222222233, 'max_history_step': 'joint', 'pipeline': {'features': ('features_NoneType', {}), 'normalizer': ('normalizer_NoneType', {}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 5})}, 'score': 0.9888888888888889, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'entropy', 'max_depth': None, 'max_features': 3, 'max_leaf_nodes': None, 'min_samples_split': 2, 'n_estimators': 100}, 'config_hash': {'algorithm': 'c40543ce91793e367c1892c886bc49621c22ecfb', 'config': 'ebebb7a93116f14f470e062e37582a59f4aeb0df', 'pipeline': 'b50c63e800574e8b760f55f7c4ff1fcae8816dd8'}, 'duration': 0.6425540447235107, 'iteration': 16, 'loss': 1.0, 'max_history_score': 0.9888888888888889, 'max_history_score_std': 0.022222222222222233, 'max_history_step': 'joint', 'pipeline': {'features': ('features_PCA', {'features__n_components': 1}), 'normalizer': ('normalizer_PowerTransformer', {}), 'rebalance': ('rebalance_NearMiss', {'rebalance__n_neighbors': 1})}, 'score': 0.0, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'gini', 'max_depth': None, 'max_features': 1, 'max_leaf_nodes': 3, 'min_samples_split': 2, 'n_estimators': 50}, 'config_hash': {'algorithm': '0c69b9601237c20664085fa05764d855e28f98f7', 'config': 'a2c21314ddbba47ddbfe416e0aa14853a71179e0', 'pipeline': '914f81fa4fbb61db251201f32bd8ea11bfeea2a5'}, 'duration': 2.2209739685058594, 'iteration': 17, 'loss': 0.3206720846233231, 'max_history_score': 0.9888888888888889, 'max_history_score_std': 0.022222222222222233, 'max_history_step': 'joint', 'pipeline': {'features': ('features_SelectKBest', {'features__k': 4}), 'normalizer': ('normalizer_PowerTransformer', {}), 'rebalance': ('rebalance_CondensedNearestNeighbour', {'rebalance__n_neighbors': 1})}, 'score': 0.6793279153766769, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': 4, 'max_features': None, 'max_leaf_nodes': None, 'min_samples_split': 3, 'n_estimators': 25}, 'config_hash': {'algorithm': '1aae0f1fce5cab293ffdd4581c4838c8051ac815', 'config': '6c8a721218e7c550a98c5ba72ad9ff86afd5e3a4', 'pipeline': '77189452469cef9c840643f2babe0f825c6667c8'}, 'duration': 0.3951280117034912, 'iteration': 18, 'loss': 0.1804760061919506, 'max_history_score': 0.9888888888888889, 'max_history_score_std': 0.022222222222222233, 'max_history_step': 'joint', 'pipeline': {'features': ('features_SelectKBest', {'features__k': 2}), 'normalizer': ('normalizer_NoneType', {}), 'rebalance': ('rebalance_NearMiss', {'rebalance__n_neighbors': 1})}, 'score': 0.8195239938080494, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': None, 'max_features': 3, 'max_leaf_nodes': 5, 'min_samples_split': 3, 'n_estimators': 50}, 'config_hash': {'algorithm': '0129970b8c7fe034ac8283fb518a06cfbead63d2', 'config': '61bcd2f64860b3dfe2503be88a6bbec165db0754', 'pipeline': '359f2473075ecfd9ae3ce526da96143918517601'}, 'duration': 0.7467091083526611, 'iteration': 19, 'loss': 0.09915720674234607, 'max_history_score': 0.9888888888888889, 'max_history_score_std': 0.022222222222222233, 'max_history_step': 'joint', 'pipeline': {'features': ('features_SelectKBest', {'features__k': 3}), 'normalizer': ('normalizer_RobustScaler', {'normalizer__quantile_range': (...), 'normalizer__with_centering': True, 'normalizer__with_scaling': False}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 7})}, 'score': 0.9008427932576539, ...}, ...], 'history_hash': ['2e6648b63441361b4398cb94f81d2e04a830b2ef', '584343bc020d2d7bc89bd0856bc7770dae1c84fc', 'de121d053e65def047cc8947f505578d5c5eab67', 'b21c9d15a389baa5bfea4c8ddcec129259f37540', 'edd3456355d80775739c31515c832ca7b4e5e094', '0800d7d2c8c10d2f9e7b4e5127b343e916eb742c', 'd98b641879b4754f2169335626a90575e945fd7c', '3f83df36a6abbdf7ea4a4bdcaf6727f23529c2bb', '037fd5c655b39cc7922fb394d736496befcc747b', '6609280032189b59de1afbe36f3acb1d5c273693', '8e1c17ac9f6e03740f380fccb833c9c3931ffc35', '87c03d0cb8e8500e58cacc1a0f27ce54c41a2937', '2ab964abffa0a277a9e2ee9b5570cd258e428b62', '5c95db3ad238063227f1b36e6a006d70c834c5da', '50fd1169b8e42190600f25152654254b5d0e3ed1', 'a05b6d2ffd65d4d937c0b178655d857bf4d61410', 'ebebb7a93116f14f470e062e37582a59f4aeb0df', 'a2c21314ddbba47ddbfe416e0aa14853a71179e0', '6c8a721218e7c550a98c5ba72ad9ff86afd5e3a4', '61bcd2f64860b3dfe2503be88a6bbec165db0754', ...], 'history_index': {'0018716ad6e0edc096329f31492734a67d79d3b3': 64, '01c777816cea234a1e6b73501020cf6f05ea69b9': 111, '020ec4a49249e6e129cbf2800d975e6e1c8842aa': 92, '037fd5c655b39cc7922fb394d736496befcc747b': 8, '0393a0da80adcc0e64c60f266b4277ec0e84ea81': 141, '0414a55701bd4c21bd4e55ad37a0576c56d56b3f': 94, '0650ac92dace31c01ac743925565b952112a5c82': 78, '07fdf9d0d0248a4b0215a633c75a2dd101dcf465': 22, '0800d7d2c8c10d2f9e7b4e5127b343e916eb742c': 5, '09cf55372e045d42fd53684507ba9d24737bdcec': 87, ...}, 'iteration': 161, 'max_history_score': 1.0, 'max_history_score_std': 0.0, 'max_history_step': 'joint'}, config={'algorithm': 'RandomForest', 'seed': 42, 'time': 300})
    108 
    109 def objective_algo(algo_config, current_pipeline_config, algorithm, X, y, context, config):
    110     return objective(current_pipeline_config, algo_config, algorithm, X, y, context, config, step='algorithm')
    111 
    112 def objective_joint(wconfig, algorithm, X, y, context, config):
--> 113     return objective(wconfig['pipeline'], wconfig['algorithm'], algorithm, X, y, context, config, step='joint')
        wconfig = {'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': 4, 'max_features': 2, 'max_leaf_nodes': 2, 'min_samples_split': 3, 'n_estimators': 75}, 'pipeline': {'features': ('features_PCA', {'features__n_components': 1}), 'normalizer': ('normalizer_PowerTransformer', {}), 'rebalance': ('rebalance_NoneType', {})}}
        algorithm = 'RandomForest'
        X = array([[1.423e+01, 1.710e+00, 2.430e+00, ..., 1...., ..., 6.100e-01, 1.600e+00,
        5.600e+02]])
        y = array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,
       2, 2])
        context = {'baseline_score': 0.9444100447196423, 'baseline_score_std': 0.04305547117084885, 'best_config': {'algorithm': {'bootstrap': False, 'criterion': 'gini', 'max_depth': 1, 'max_features': 1, 'max_leaf_nodes': 3, 'min_samples_split': 2, 'n_estimators': 50}, 'config_hash': {'algorithm': '41bdc0fd26679e3e9de3f47a81dcebdeb54f6274', 'config': '0ada0978fbb60b78d813177773f684a809a8f7c8', 'pipeline': 'aaf976c7c663a31fa039582d42f9e07101556a7c'}, 'duration': 0.6971359252929688, 'iteration': 62, 'loss': 0.0, 'max_history_score': 1.0, 'max_history_score_std': 0.0, 'max_history_step': 'joint', 'pipeline': {'features': ('features_NoneType', {}), 'normalizer': ('normalizer_PowerTransformer', {}), 'rebalance': ('rebalance_NoneType', {})}, 'score': 1.0, ...}, 'history': [{'algorithm': {'bootstrap': False, 'criterion': 'entropy', 'max_depth': None, 'max_features': 3, 'max_leaf_nodes': 5, 'min_samples_split': 2, 'n_estimators': 50}, 'config_hash': {'algorithm': 'b2c6464add7a35ce8048653a39338c9994de9a4f', 'config': '2e6648b63441361b4398cb94f81d2e04a830b2ef', 'pipeline': '3d44d7482e468d08c4f94457a205f3dac74084c1'}, 'duration': 0.737678050994873, 'iteration': 0, 'loss': 1.0, 'max_history_score': 0.0, 'max_history_score_std': 0.0, 'max_history_step': 'baseline', 'pipeline': {'features': ('features_PCA', {'features__n_components': 1}), 'normalizer': ('normalizer_NoneType', {}), 'rebalance': ('rebalance_CondensedNearestNeighbour', {'rebalance__n_neighbors': 3})}, 'score': 0.0, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'gini', 'max_depth': 1, 'max_features': None, 'max_leaf_nodes': 2, 'min_samples_split': 3, 'n_estimators': 25}, 'config_hash': {'algorithm': '7f71bbbfdb4e8da52b6fc33a43224183117de15e', 'config': '584343bc020d2d7bc89bd0856bc7770dae1c84fc', 'pipeline': '466ffa7ace0e442beb7c311eb214b17a4c6832b3'}, 'duration': 1.5976769924163818, 'iteration': 1, 'loss': 0.40386351909184726, 'max_history_score': 0.5961364809081527, 'max_history_score_std': 0.05351463210025494, 'max_history_step': 'joint', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 3, 'features__selectkbest__k': 3}), 'normalizer': ('normalizer_StandardScaler', {'normalizer__with_mean': True, 'normalizer__with_std': True}), 'rebalance': ('rebalance_NearMiss', {'rebalance__n_neighbors': 2})}, 'score': 0.5961364809081527, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'entropy', 'max_depth': 1, 'max_features': 2, 'max_leaf_nodes': 2, 'min_samples_split': 5, 'n_estimators': 25}, 'config_hash': {'algorithm': '897745a20d929d43e760cacee0a764bd8070daa5', 'config': 'de121d053e65def047cc8947f505578d5c5eab67', 'pipeline': '63040b39b48626a8232e847e8327bdca5cd88611'}, 'duration': 0.815453052520752, 'iteration': 2, 'loss': 0.07327786377708967, 'max_history_score': 0.9267221362229103, 'max_history_score_std': 0.043920207373658794, 'max_history_step': 'joint', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 3, 'features__selectkbest__k': 2}), 'normalizer': ('normalizer_StandardScaler', {'normalizer__with_mean': True, 'normalizer__with_std': True}), 'rebalance': ('rebalance_NoneType', {})}, 'score': 0.9267221362229103, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'entropy', 'max_depth': 4, 'max_features': 3, 'max_leaf_nodes': None, 'min_samples_split': 2, 'n_estimators': 100}, 'config_hash': {'algorithm': 'dbd92c75280ec06b66ca4ad9b135cf36957031a4', 'config': 'b21c9d15a389baa5bfea4c8ddcec129259f37540', 'pipeline': '38866720d2f120c863351493b9b4e23b9a4506dc'}, 'duration': 1.2293269634246826, 'iteration': 3, 'loss': 0.07199862401100798, 'max_history_score': 0.928001375988992, 'max_history_score_std': 0.06518367535896959, 'max_history_step': 'joint', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 2, 'features__selectkbest__k': 4}), 'normalizer': ('normalizer_NoneType', {}), 'rebalance': ('rebalance_NoneType', {})}, 'score': 0.928001375988992, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': 2, 'max_features': None, 'max_leaf_nodes': None, 'min_samples_split': 5, 'n_estimators': 100}, 'config_hash': {'algorithm': 'f455eefd9fdd03ece88892c3f440c580bdf27ddb', 'config': 'edd3456355d80775739c31515c832ca7b4e5e094', 'pipeline': '1d1034f9f0871e43f896c1db4ed6fd572ed0a6ef'}, 'duration': 1.6186630725860596, 'iteration': 4, 'loss': 0.16651831785345705, 'max_history_score': 0.928001375988992, 'max_history_score_std': 0.06518367535896959, 'max_history_step': 'joint', 'pipeline': {'features': ('features_SelectKBest', {'features__k': 4}), 'normalizer': ('normalizer_MinMaxScaler', {}), 'rebalance': ('rebalance_CondensedNearestNeighbour', {'rebalance__n_neighbors': 1})}, 'score': 0.833481682146543, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'entropy', 'max_depth': 1, 'max_features': 2, 'max_leaf_nodes': None, 'min_samples_split': 2, 'n_estimators': 10}, 'config_hash': {'algorithm': '29906eaa0712a68ea145b12821d54ba445726fbf', 'config': '0800d7d2c8c10d2f9e7b4e5127b343e916eb742c', 'pipeline': '2e0f188ae61600352a7159285e0f542b4587a403'}, 'duration': 0.19410085678100586, 'iteration': 5, 'loss': 0.20164258685930514, 'max_history_score': 0.928001375988992, 'max_history_score_std': 0.06518367535896959, 'max_history_step': 'joint', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 3, 'features__selectkbest__k': 4}), 'normalizer': ('normalizer_StandardScaler', {'normalizer__with_mean': True, 'normalizer__with_std': False}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 7})}, 'score': 0.7983574131406949, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': 1, 'max_features': 1, 'max_leaf_nodes': 5, 'min_samples_split': 2, 'n_estimators': 25}, 'config_hash': {'algorithm': 'fbb7d57e38cfc08240f0af985282da418cb33556', 'config': 'd98b641879b4754f2169335626a90575e945fd7c', 'pipeline': '62463de065924498cdcd2f2f1f7e68535cdb33a5'}, 'duration': 0.3625810146331787, 'iteration': 6, 'loss': 0.14327485380116955, 'max_history_score': 0.928001375988992, 'max_history_score_std': 0.06518367535896959, 'max_history_step': 'joint', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 1, 'features__selectkbest__k': 2}), 'normalizer': ('normalizer_NoneType', {}), 'rebalance': ('rebalance_NoneType', {})}, 'score': 0.8567251461988304, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'entropy', 'max_depth': 3, 'max_features': 1, 'max_leaf_nodes': None, 'min_samples_split': 2, 'n_estimators': 75}, 'config_hash': {'algorithm': 'fb2f5d4c4d636edac929e1454ce3d02a4fb134c1', 'config': '3f83df36a6abbdf7ea4a4bdcaf6727f23529c2bb', 'pipeline': '8377b93e334656d1a93d266493b58ef9a6a1786f'}, 'duration': 0.8223779201507568, 'iteration': 7, 'loss': 0.03921568627450989, 'max_history_score': 0.9607843137254901, 'max_history_score_std': 0.043526663832084804, 'max_history_step': 'joint', 'pipeline': {'features': ('features_PCA', {'features__n_components': 3}), 'normalizer': ('normalizer_MinMaxScaler', {}), 'rebalance': ('rebalance_NearMiss', {'rebalance__n_neighbors': 1})}, 'score': 0.9607843137254901, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'gini', 'max_depth': 3, 'max_features': 3, 'max_leaf_nodes': 2, 'min_samples_split': 2, 'n_estimators': 100}, 'config_hash': {'algorithm': '3c3fde6559b918694de4668d025d5418342db1b1', 'config': '037fd5c655b39cc7922fb394d736496befcc747b', 'pipeline': '2a5032814c6c7ed21dd5bd9686923d7fc2f8acc9'}, 'duration': 1.0435099601745605, 'iteration': 8, 'loss': 0.09955925352597172, 'max_history_score': 0.9607843137254901, 'max_history_score_std': 0.043526663832084804, 'max_history_step': 'joint', 'pipeline': {'features': ('features_NoneType', {}), 'normalizer': ('normalizer_RobustScaler', {'normalizer__quantile_range': (...), 'normalizer__with_centering': True, 'normalizer__with_scaling': True}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 7})}, 'score': 0.9004407464740283, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': 2, 'max_features': 1, 'max_leaf_nodes': None, 'min_samples_split': 3, 'n_estimators': 75}, 'config_hash': {'algorithm': '42185be98371e99ac896d2c6c2d69c451cb983ff', 'config': '6609280032189b59de1afbe36f3acb1d5c273693', 'pipeline': '8aab2941fc84d84f86fa56134e50909dbf9e19f5'}, 'duration': 0.9665219783782959, 'iteration': 9, 'loss': 0.01637426900584804, 'max_history_score': 0.983625730994152, 'max_history_score_std': 0.025023500462379746, 'max_history_step': 'joint', 'pipeline': {'features': ('features_NoneType', {}), 'normalizer': ('normalizer_PowerTransformer', {}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 5})}, 'score': 0.983625730994152, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': 1, 'max_features': 3, 'max_leaf_nodes': 2, 'min_samples_split': 3, 'n_estimators': 10}, 'config_hash': {'algorithm': '62a9fe705e4cd96e762bcc9543c4a456a5a9f188', 'config': '8e1c17ac9f6e03740f380fccb833c9c3931ffc35', 'pipeline': '3d44d7482e468d08c4f94457a205f3dac74084c1'}, 'duration': 0.46930503845214844, 'iteration': 10, 'loss': 1.0, 'max_history_score': 0.983625730994152, 'max_history_score_std': 0.025023500462379746, 'max_history_step': 'joint', 'pipeline': {'features': ('features_PCA', {'features__n_components': 1}), 'normalizer': ('normalizer_NoneType', {}), 'rebalance': ('rebalance_CondensedNearestNeighbour', {'rebalance__n_neighbors': 3})}, 'score': 0.0, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'gini', 'max_depth': 4, 'max_features': 1, 'max_leaf_nodes': 3, 'min_samples_split': 2, 'n_estimators': 100}, 'config_hash': {'algorithm': '086d6ca939a757bb32edb113a567f9d38744f061', 'config': '87c03d0cb8e8500e58cacc1a0f27ce54c41a2937', 'pipeline': '8f28ef0f35d97142278f9dacb4e9d1ff082e470f'}, 'duration': 2.1196961402893066, 'iteration': 11, 'loss': 0.15471276229790154, 'max_history_score': 0.983625730994152, 'max_history_score_std': 0.025023500462379746, 'max_history_step': 'joint', 'pipeline': {'features': ('features_PCA', {'features__n_components': 1}), 'normalizer': ('normalizer_StandardScaler', {'normalizer__with_mean': True, 'normalizer__with_std': True}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 7})}, 'score': 0.8452872377020985, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'entropy', 'max_depth': 3, 'max_features': 1, 'max_leaf_nodes': 2, 'min_samples_split': 2, 'n_estimators': 25}, 'config_hash': {'algorithm': '59f64a966796648c7bebade1127fa05541b391ad', 'config': '2ab964abffa0a277a9e2ee9b5570cd258e428b62', 'pipeline': 'eef3f702fd2fed761fa6744c1640d0bf320f1d00'}, 'duration': 0.9828321933746338, 'iteration': 12, 'loss': 0.0778465772273822, 'max_history_score': 0.983625730994152, 'max_history_score_std': 0.025023500462379746, 'max_history_step': 'joint', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 3, 'features__selectkbest__k': 1}), 'normalizer': ('normalizer_PowerTransformer', {}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 6})}, 'score': 0.9221534227726178, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'gini', 'max_depth': 4, 'max_features': 2, 'max_leaf_nodes': 3, 'min_samples_split': 3, 'n_estimators': 75}, 'config_hash': {'algorithm': '6f75c2a196eb9836df2b424e095051192eaed6ea', 'config': '5c95db3ad238063227f1b36e6a006d70c834c5da', 'pipeline': '1eae01a1128bee425c4d4ca0ee97a9afd409680e'}, 'duration': 0.8217771053314209, 'iteration': 13, 'loss': 0.03863089095287242, 'max_history_score': 0.983625730994152, 'max_history_score_std': 0.025023500462379746, 'max_history_step': 'joint', 'pipeline': {'features': ('features_NoneType', {}), 'normalizer': ('normalizer_StandardScaler', {'normalizer__with_mean': False, 'normalizer__with_std': False}), 'rebalance': ('rebalance_NearMiss', {'rebalance__n_neighbors': 1})}, 'score': 0.9613691090471276, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'entropy', 'max_depth': 4, 'max_features': 2, 'max_leaf_nodes': 3, 'min_samples_split': 2, 'n_estimators': 25}, 'config_hash': {'algorithm': '8aef3174f6b8020de06b825e0424c1e54d690afd', 'config': '50fd1169b8e42190600f25152654254b5d0e3ed1', 'pipeline': '9ceaa544911dc6c687e336cb8e9dd4d15ff1ceaf'}, 'duration': 0.40307188034057617, 'iteration': 14, 'loss': 1.0, 'max_history_score': 0.983625730994152, 'max_history_score_std': 0.025023500462379746, 'max_history_step': 'joint', 'pipeline': {'features': ('features_PCA', {'features__n_components': 1}), 'normalizer': ('normalizer_RobustScaler', {'normalizer__quantile_range': (...), 'normalizer__with_centering': False, 'normalizer__with_scaling': False}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 7})}, 'score': 0.0, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'gini', 'max_depth': 1, 'max_features': 1, 'max_leaf_nodes': 3, 'min_samples_split': 3, 'n_estimators': 50}, 'config_hash': {'algorithm': '37be8b6737f4b5d5ae35da51886f302b07ba6001', 'config': 'a05b6d2ffd65d4d937c0b178655d857bf4d61410', 'pipeline': 'cfef88e895db321122f2f7b813d9267b973c2468'}, 'duration': 1.7094659805297852, 'iteration': 15, 'loss': 0.011111111111111072, 'max_history_score': 0.9888888888888889, 'max_history_score_std': 0.022222222222222233, 'max_history_step': 'joint', 'pipeline': {'features': ('features_NoneType', {}), 'normalizer': ('normalizer_NoneType', {}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 5})}, 'score': 0.9888888888888889, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'entropy', 'max_depth': None, 'max_features': 3, 'max_leaf_nodes': None, 'min_samples_split': 2, 'n_estimators': 100}, 'config_hash': {'algorithm': 'c40543ce91793e367c1892c886bc49621c22ecfb', 'config': 'ebebb7a93116f14f470e062e37582a59f4aeb0df', 'pipeline': 'b50c63e800574e8b760f55f7c4ff1fcae8816dd8'}, 'duration': 0.6425540447235107, 'iteration': 16, 'loss': 1.0, 'max_history_score': 0.9888888888888889, 'max_history_score_std': 0.022222222222222233, 'max_history_step': 'joint', 'pipeline': {'features': ('features_PCA', {'features__n_components': 1}), 'normalizer': ('normalizer_PowerTransformer', {}), 'rebalance': ('rebalance_NearMiss', {'rebalance__n_neighbors': 1})}, 'score': 0.0, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'gini', 'max_depth': None, 'max_features': 1, 'max_leaf_nodes': 3, 'min_samples_split': 2, 'n_estimators': 50}, 'config_hash': {'algorithm': '0c69b9601237c20664085fa05764d855e28f98f7', 'config': 'a2c21314ddbba47ddbfe416e0aa14853a71179e0', 'pipeline': '914f81fa4fbb61db251201f32bd8ea11bfeea2a5'}, 'duration': 2.2209739685058594, 'iteration': 17, 'loss': 0.3206720846233231, 'max_history_score': 0.9888888888888889, 'max_history_score_std': 0.022222222222222233, 'max_history_step': 'joint', 'pipeline': {'features': ('features_SelectKBest', {'features__k': 4}), 'normalizer': ('normalizer_PowerTransformer', {}), 'rebalance': ('rebalance_CondensedNearestNeighbour', {'rebalance__n_neighbors': 1})}, 'score': 0.6793279153766769, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': 4, 'max_features': None, 'max_leaf_nodes': None, 'min_samples_split': 3, 'n_estimators': 25}, 'config_hash': {'algorithm': '1aae0f1fce5cab293ffdd4581c4838c8051ac815', 'config': '6c8a721218e7c550a98c5ba72ad9ff86afd5e3a4', 'pipeline': '77189452469cef9c840643f2babe0f825c6667c8'}, 'duration': 0.3951280117034912, 'iteration': 18, 'loss': 0.1804760061919506, 'max_history_score': 0.9888888888888889, 'max_history_score_std': 0.022222222222222233, 'max_history_step': 'joint', 'pipeline': {'features': ('features_SelectKBest', {'features__k': 2}), 'normalizer': ('normalizer_NoneType', {}), 'rebalance': ('rebalance_NearMiss', {'rebalance__n_neighbors': 1})}, 'score': 0.8195239938080494, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': None, 'max_features': 3, 'max_leaf_nodes': 5, 'min_samples_split': 3, 'n_estimators': 50}, 'config_hash': {'algorithm': '0129970b8c7fe034ac8283fb518a06cfbead63d2', 'config': '61bcd2f64860b3dfe2503be88a6bbec165db0754', 'pipeline': '359f2473075ecfd9ae3ce526da96143918517601'}, 'duration': 0.7467091083526611, 'iteration': 19, 'loss': 0.09915720674234607, 'max_history_score': 0.9888888888888889, 'max_history_score_std': 0.022222222222222233, 'max_history_step': 'joint', 'pipeline': {'features': ('features_SelectKBest', {'features__k': 3}), 'normalizer': ('normalizer_RobustScaler', {'normalizer__quantile_range': (...), 'normalizer__with_centering': True, 'normalizer__with_scaling': False}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 7})}, 'score': 0.9008427932576539, ...}, ...], 'history_hash': ['2e6648b63441361b4398cb94f81d2e04a830b2ef', '584343bc020d2d7bc89bd0856bc7770dae1c84fc', 'de121d053e65def047cc8947f505578d5c5eab67', 'b21c9d15a389baa5bfea4c8ddcec129259f37540', 'edd3456355d80775739c31515c832ca7b4e5e094', '0800d7d2c8c10d2f9e7b4e5127b343e916eb742c', 'd98b641879b4754f2169335626a90575e945fd7c', '3f83df36a6abbdf7ea4a4bdcaf6727f23529c2bb', '037fd5c655b39cc7922fb394d736496befcc747b', '6609280032189b59de1afbe36f3acb1d5c273693', '8e1c17ac9f6e03740f380fccb833c9c3931ffc35', '87c03d0cb8e8500e58cacc1a0f27ce54c41a2937', '2ab964abffa0a277a9e2ee9b5570cd258e428b62', '5c95db3ad238063227f1b36e6a006d70c834c5da', '50fd1169b8e42190600f25152654254b5d0e3ed1', 'a05b6d2ffd65d4d937c0b178655d857bf4d61410', 'ebebb7a93116f14f470e062e37582a59f4aeb0df', 'a2c21314ddbba47ddbfe416e0aa14853a71179e0', '6c8a721218e7c550a98c5ba72ad9ff86afd5e3a4', '61bcd2f64860b3dfe2503be88a6bbec165db0754', ...], 'history_index': {'0018716ad6e0edc096329f31492734a67d79d3b3': 64, '01c777816cea234a1e6b73501020cf6f05ea69b9': 111, '020ec4a49249e6e129cbf2800d975e6e1c8842aa': 92, '037fd5c655b39cc7922fb394d736496befcc747b': 8, '0393a0da80adcc0e64c60f266b4277ec0e84ea81': 141, '0414a55701bd4c21bd4e55ad37a0576c56d56b3f': 94, '0650ac92dace31c01ac743925565b952112a5c82': 78, '07fdf9d0d0248a4b0215a633c75a2dd101dcf465': 22, '0800d7d2c8c10d2f9e7b4e5127b343e916eb742c': 5, '09cf55372e045d42fd53684507ba9d24737bdcec': 87, ...}, 'iteration': 161, 'max_history_score': 1.0, 'max_history_score_std': 0.0, 'max_history_step': 'joint'}
        config = {'algorithm': 'RandomForest', 'seed': 42, 'time': 300}
    114 
    115 
    116 def get_baseline_score(algorithm, X, y, seed):
    117     pipeline, _ = pipeline_conf_to_full_pipeline(

...........................................................................
/home/aquemy/dev/dp_hyperparameters/extension/experiment/objective.py in objective(pipeline_config={'features': ('features_PCA', {'features__n_components': 1}), 'normalizer': ('normalizer_PowerTransformer', {}), 'rebalance': ('rebalance_NoneType', {})}, algo_config={'bootstrap': True, 'criterion': 'gini', 'max_depth': 4, 'max_features': 2, 'max_leaf_nodes': 2, 'min_samples_split': 3, 'n_estimators': 75}, algorithm='RandomForest', X=array([[1.423e+01, 1.710e+00, 2.430e+00, ..., 1...., ..., 6.100e-01, 1.600e+00,
        5.600e+02]]), y=array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,
       2, 2]), context={'baseline_score': 0.9444100447196423, 'baseline_score_std': 0.04305547117084885, 'best_config': {'algorithm': {'bootstrap': False, 'criterion': 'gini', 'max_depth': 1, 'max_features': 1, 'max_leaf_nodes': 3, 'min_samples_split': 2, 'n_estimators': 50}, 'config_hash': {'algorithm': '41bdc0fd26679e3e9de3f47a81dcebdeb54f6274', 'config': '0ada0978fbb60b78d813177773f684a809a8f7c8', 'pipeline': 'aaf976c7c663a31fa039582d42f9e07101556a7c'}, 'duration': 0.6971359252929688, 'iteration': 62, 'loss': 0.0, 'max_history_score': 1.0, 'max_history_score_std': 0.0, 'max_history_step': 'joint', 'pipeline': {'features': ('features_NoneType', {}), 'normalizer': ('normalizer_PowerTransformer', {}), 'rebalance': ('rebalance_NoneType', {})}, 'score': 1.0, ...}, 'history': [{'algorithm': {'bootstrap': False, 'criterion': 'entropy', 'max_depth': None, 'max_features': 3, 'max_leaf_nodes': 5, 'min_samples_split': 2, 'n_estimators': 50}, 'config_hash': {'algorithm': 'b2c6464add7a35ce8048653a39338c9994de9a4f', 'config': '2e6648b63441361b4398cb94f81d2e04a830b2ef', 'pipeline': '3d44d7482e468d08c4f94457a205f3dac74084c1'}, 'duration': 0.737678050994873, 'iteration': 0, 'loss': 1.0, 'max_history_score': 0.0, 'max_history_score_std': 0.0, 'max_history_step': 'baseline', 'pipeline': {'features': ('features_PCA', {'features__n_components': 1}), 'normalizer': ('normalizer_NoneType', {}), 'rebalance': ('rebalance_CondensedNearestNeighbour', {'rebalance__n_neighbors': 3})}, 'score': 0.0, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'gini', 'max_depth': 1, 'max_features': None, 'max_leaf_nodes': 2, 'min_samples_split': 3, 'n_estimators': 25}, 'config_hash': {'algorithm': '7f71bbbfdb4e8da52b6fc33a43224183117de15e', 'config': '584343bc020d2d7bc89bd0856bc7770dae1c84fc', 'pipeline': '466ffa7ace0e442beb7c311eb214b17a4c6832b3'}, 'duration': 1.5976769924163818, 'iteration': 1, 'loss': 0.40386351909184726, 'max_history_score': 0.5961364809081527, 'max_history_score_std': 0.05351463210025494, 'max_history_step': 'joint', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 3, 'features__selectkbest__k': 3}), 'normalizer': ('normalizer_StandardScaler', {'normalizer__with_mean': True, 'normalizer__with_std': True}), 'rebalance': ('rebalance_NearMiss', {'rebalance__n_neighbors': 2})}, 'score': 0.5961364809081527, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'entropy', 'max_depth': 1, 'max_features': 2, 'max_leaf_nodes': 2, 'min_samples_split': 5, 'n_estimators': 25}, 'config_hash': {'algorithm': '897745a20d929d43e760cacee0a764bd8070daa5', 'config': 'de121d053e65def047cc8947f505578d5c5eab67', 'pipeline': '63040b39b48626a8232e847e8327bdca5cd88611'}, 'duration': 0.815453052520752, 'iteration': 2, 'loss': 0.07327786377708967, 'max_history_score': 0.9267221362229103, 'max_history_score_std': 0.043920207373658794, 'max_history_step': 'joint', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 3, 'features__selectkbest__k': 2}), 'normalizer': ('normalizer_StandardScaler', {'normalizer__with_mean': True, 'normalizer__with_std': True}), 'rebalance': ('rebalance_NoneType', {})}, 'score': 0.9267221362229103, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'entropy', 'max_depth': 4, 'max_features': 3, 'max_leaf_nodes': None, 'min_samples_split': 2, 'n_estimators': 100}, 'config_hash': {'algorithm': 'dbd92c75280ec06b66ca4ad9b135cf36957031a4', 'config': 'b21c9d15a389baa5bfea4c8ddcec129259f37540', 'pipeline': '38866720d2f120c863351493b9b4e23b9a4506dc'}, 'duration': 1.2293269634246826, 'iteration': 3, 'loss': 0.07199862401100798, 'max_history_score': 0.928001375988992, 'max_history_score_std': 0.06518367535896959, 'max_history_step': 'joint', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 2, 'features__selectkbest__k': 4}), 'normalizer': ('normalizer_NoneType', {}), 'rebalance': ('rebalance_NoneType', {})}, 'score': 0.928001375988992, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': 2, 'max_features': None, 'max_leaf_nodes': None, 'min_samples_split': 5, 'n_estimators': 100}, 'config_hash': {'algorithm': 'f455eefd9fdd03ece88892c3f440c580bdf27ddb', 'config': 'edd3456355d80775739c31515c832ca7b4e5e094', 'pipeline': '1d1034f9f0871e43f896c1db4ed6fd572ed0a6ef'}, 'duration': 1.6186630725860596, 'iteration': 4, 'loss': 0.16651831785345705, 'max_history_score': 0.928001375988992, 'max_history_score_std': 0.06518367535896959, 'max_history_step': 'joint', 'pipeline': {'features': ('features_SelectKBest', {'features__k': 4}), 'normalizer': ('normalizer_MinMaxScaler', {}), 'rebalance': ('rebalance_CondensedNearestNeighbour', {'rebalance__n_neighbors': 1})}, 'score': 0.833481682146543, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'entropy', 'max_depth': 1, 'max_features': 2, 'max_leaf_nodes': None, 'min_samples_split': 2, 'n_estimators': 10}, 'config_hash': {'algorithm': '29906eaa0712a68ea145b12821d54ba445726fbf', 'config': '0800d7d2c8c10d2f9e7b4e5127b343e916eb742c', 'pipeline': '2e0f188ae61600352a7159285e0f542b4587a403'}, 'duration': 0.19410085678100586, 'iteration': 5, 'loss': 0.20164258685930514, 'max_history_score': 0.928001375988992, 'max_history_score_std': 0.06518367535896959, 'max_history_step': 'joint', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 3, 'features__selectkbest__k': 4}), 'normalizer': ('normalizer_StandardScaler', {'normalizer__with_mean': True, 'normalizer__with_std': False}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 7})}, 'score': 0.7983574131406949, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': 1, 'max_features': 1, 'max_leaf_nodes': 5, 'min_samples_split': 2, 'n_estimators': 25}, 'config_hash': {'algorithm': 'fbb7d57e38cfc08240f0af985282da418cb33556', 'config': 'd98b641879b4754f2169335626a90575e945fd7c', 'pipeline': '62463de065924498cdcd2f2f1f7e68535cdb33a5'}, 'duration': 0.3625810146331787, 'iteration': 6, 'loss': 0.14327485380116955, 'max_history_score': 0.928001375988992, 'max_history_score_std': 0.06518367535896959, 'max_history_step': 'joint', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 1, 'features__selectkbest__k': 2}), 'normalizer': ('normalizer_NoneType', {}), 'rebalance': ('rebalance_NoneType', {})}, 'score': 0.8567251461988304, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'entropy', 'max_depth': 3, 'max_features': 1, 'max_leaf_nodes': None, 'min_samples_split': 2, 'n_estimators': 75}, 'config_hash': {'algorithm': 'fb2f5d4c4d636edac929e1454ce3d02a4fb134c1', 'config': '3f83df36a6abbdf7ea4a4bdcaf6727f23529c2bb', 'pipeline': '8377b93e334656d1a93d266493b58ef9a6a1786f'}, 'duration': 0.8223779201507568, 'iteration': 7, 'loss': 0.03921568627450989, 'max_history_score': 0.9607843137254901, 'max_history_score_std': 0.043526663832084804, 'max_history_step': 'joint', 'pipeline': {'features': ('features_PCA', {'features__n_components': 3}), 'normalizer': ('normalizer_MinMaxScaler', {}), 'rebalance': ('rebalance_NearMiss', {'rebalance__n_neighbors': 1})}, 'score': 0.9607843137254901, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'gini', 'max_depth': 3, 'max_features': 3, 'max_leaf_nodes': 2, 'min_samples_split': 2, 'n_estimators': 100}, 'config_hash': {'algorithm': '3c3fde6559b918694de4668d025d5418342db1b1', 'config': '037fd5c655b39cc7922fb394d736496befcc747b', 'pipeline': '2a5032814c6c7ed21dd5bd9686923d7fc2f8acc9'}, 'duration': 1.0435099601745605, 'iteration': 8, 'loss': 0.09955925352597172, 'max_history_score': 0.9607843137254901, 'max_history_score_std': 0.043526663832084804, 'max_history_step': 'joint', 'pipeline': {'features': ('features_NoneType', {}), 'normalizer': ('normalizer_RobustScaler', {'normalizer__quantile_range': (...), 'normalizer__with_centering': True, 'normalizer__with_scaling': True}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 7})}, 'score': 0.9004407464740283, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': 2, 'max_features': 1, 'max_leaf_nodes': None, 'min_samples_split': 3, 'n_estimators': 75}, 'config_hash': {'algorithm': '42185be98371e99ac896d2c6c2d69c451cb983ff', 'config': '6609280032189b59de1afbe36f3acb1d5c273693', 'pipeline': '8aab2941fc84d84f86fa56134e50909dbf9e19f5'}, 'duration': 0.9665219783782959, 'iteration': 9, 'loss': 0.01637426900584804, 'max_history_score': 0.983625730994152, 'max_history_score_std': 0.025023500462379746, 'max_history_step': 'joint', 'pipeline': {'features': ('features_NoneType', {}), 'normalizer': ('normalizer_PowerTransformer', {}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 5})}, 'score': 0.983625730994152, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': 1, 'max_features': 3, 'max_leaf_nodes': 2, 'min_samples_split': 3, 'n_estimators': 10}, 'config_hash': {'algorithm': '62a9fe705e4cd96e762bcc9543c4a456a5a9f188', 'config': '8e1c17ac9f6e03740f380fccb833c9c3931ffc35', 'pipeline': '3d44d7482e468d08c4f94457a205f3dac74084c1'}, 'duration': 0.46930503845214844, 'iteration': 10, 'loss': 1.0, 'max_history_score': 0.983625730994152, 'max_history_score_std': 0.025023500462379746, 'max_history_step': 'joint', 'pipeline': {'features': ('features_PCA', {'features__n_components': 1}), 'normalizer': ('normalizer_NoneType', {}), 'rebalance': ('rebalance_CondensedNearestNeighbour', {'rebalance__n_neighbors': 3})}, 'score': 0.0, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'gini', 'max_depth': 4, 'max_features': 1, 'max_leaf_nodes': 3, 'min_samples_split': 2, 'n_estimators': 100}, 'config_hash': {'algorithm': '086d6ca939a757bb32edb113a567f9d38744f061', 'config': '87c03d0cb8e8500e58cacc1a0f27ce54c41a2937', 'pipeline': '8f28ef0f35d97142278f9dacb4e9d1ff082e470f'}, 'duration': 2.1196961402893066, 'iteration': 11, 'loss': 0.15471276229790154, 'max_history_score': 0.983625730994152, 'max_history_score_std': 0.025023500462379746, 'max_history_step': 'joint', 'pipeline': {'features': ('features_PCA', {'features__n_components': 1}), 'normalizer': ('normalizer_StandardScaler', {'normalizer__with_mean': True, 'normalizer__with_std': True}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 7})}, 'score': 0.8452872377020985, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'entropy', 'max_depth': 3, 'max_features': 1, 'max_leaf_nodes': 2, 'min_samples_split': 2, 'n_estimators': 25}, 'config_hash': {'algorithm': '59f64a966796648c7bebade1127fa05541b391ad', 'config': '2ab964abffa0a277a9e2ee9b5570cd258e428b62', 'pipeline': 'eef3f702fd2fed761fa6744c1640d0bf320f1d00'}, 'duration': 0.9828321933746338, 'iteration': 12, 'loss': 0.0778465772273822, 'max_history_score': 0.983625730994152, 'max_history_score_std': 0.025023500462379746, 'max_history_step': 'joint', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 3, 'features__selectkbest__k': 1}), 'normalizer': ('normalizer_PowerTransformer', {}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 6})}, 'score': 0.9221534227726178, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'gini', 'max_depth': 4, 'max_features': 2, 'max_leaf_nodes': 3, 'min_samples_split': 3, 'n_estimators': 75}, 'config_hash': {'algorithm': '6f75c2a196eb9836df2b424e095051192eaed6ea', 'config': '5c95db3ad238063227f1b36e6a006d70c834c5da', 'pipeline': '1eae01a1128bee425c4d4ca0ee97a9afd409680e'}, 'duration': 0.8217771053314209, 'iteration': 13, 'loss': 0.03863089095287242, 'max_history_score': 0.983625730994152, 'max_history_score_std': 0.025023500462379746, 'max_history_step': 'joint', 'pipeline': {'features': ('features_NoneType', {}), 'normalizer': ('normalizer_StandardScaler', {'normalizer__with_mean': False, 'normalizer__with_std': False}), 'rebalance': ('rebalance_NearMiss', {'rebalance__n_neighbors': 1})}, 'score': 0.9613691090471276, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'entropy', 'max_depth': 4, 'max_features': 2, 'max_leaf_nodes': 3, 'min_samples_split': 2, 'n_estimators': 25}, 'config_hash': {'algorithm': '8aef3174f6b8020de06b825e0424c1e54d690afd', 'config': '50fd1169b8e42190600f25152654254b5d0e3ed1', 'pipeline': '9ceaa544911dc6c687e336cb8e9dd4d15ff1ceaf'}, 'duration': 0.40307188034057617, 'iteration': 14, 'loss': 1.0, 'max_history_score': 0.983625730994152, 'max_history_score_std': 0.025023500462379746, 'max_history_step': 'joint', 'pipeline': {'features': ('features_PCA', {'features__n_components': 1}), 'normalizer': ('normalizer_RobustScaler', {'normalizer__quantile_range': (...), 'normalizer__with_centering': False, 'normalizer__with_scaling': False}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 7})}, 'score': 0.0, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'gini', 'max_depth': 1, 'max_features': 1, 'max_leaf_nodes': 3, 'min_samples_split': 3, 'n_estimators': 50}, 'config_hash': {'algorithm': '37be8b6737f4b5d5ae35da51886f302b07ba6001', 'config': 'a05b6d2ffd65d4d937c0b178655d857bf4d61410', 'pipeline': 'cfef88e895db321122f2f7b813d9267b973c2468'}, 'duration': 1.7094659805297852, 'iteration': 15, 'loss': 0.011111111111111072, 'max_history_score': 0.9888888888888889, 'max_history_score_std': 0.022222222222222233, 'max_history_step': 'joint', 'pipeline': {'features': ('features_NoneType', {}), 'normalizer': ('normalizer_NoneType', {}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 5})}, 'score': 0.9888888888888889, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'entropy', 'max_depth': None, 'max_features': 3, 'max_leaf_nodes': None, 'min_samples_split': 2, 'n_estimators': 100}, 'config_hash': {'algorithm': 'c40543ce91793e367c1892c886bc49621c22ecfb', 'config': 'ebebb7a93116f14f470e062e37582a59f4aeb0df', 'pipeline': 'b50c63e800574e8b760f55f7c4ff1fcae8816dd8'}, 'duration': 0.6425540447235107, 'iteration': 16, 'loss': 1.0, 'max_history_score': 0.9888888888888889, 'max_history_score_std': 0.022222222222222233, 'max_history_step': 'joint', 'pipeline': {'features': ('features_PCA', {'features__n_components': 1}), 'normalizer': ('normalizer_PowerTransformer', {}), 'rebalance': ('rebalance_NearMiss', {'rebalance__n_neighbors': 1})}, 'score': 0.0, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'gini', 'max_depth': None, 'max_features': 1, 'max_leaf_nodes': 3, 'min_samples_split': 2, 'n_estimators': 50}, 'config_hash': {'algorithm': '0c69b9601237c20664085fa05764d855e28f98f7', 'config': 'a2c21314ddbba47ddbfe416e0aa14853a71179e0', 'pipeline': '914f81fa4fbb61db251201f32bd8ea11bfeea2a5'}, 'duration': 2.2209739685058594, 'iteration': 17, 'loss': 0.3206720846233231, 'max_history_score': 0.9888888888888889, 'max_history_score_std': 0.022222222222222233, 'max_history_step': 'joint', 'pipeline': {'features': ('features_SelectKBest', {'features__k': 4}), 'normalizer': ('normalizer_PowerTransformer', {}), 'rebalance': ('rebalance_CondensedNearestNeighbour', {'rebalance__n_neighbors': 1})}, 'score': 0.6793279153766769, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': 4, 'max_features': None, 'max_leaf_nodes': None, 'min_samples_split': 3, 'n_estimators': 25}, 'config_hash': {'algorithm': '1aae0f1fce5cab293ffdd4581c4838c8051ac815', 'config': '6c8a721218e7c550a98c5ba72ad9ff86afd5e3a4', 'pipeline': '77189452469cef9c840643f2babe0f825c6667c8'}, 'duration': 0.3951280117034912, 'iteration': 18, 'loss': 0.1804760061919506, 'max_history_score': 0.9888888888888889, 'max_history_score_std': 0.022222222222222233, 'max_history_step': 'joint', 'pipeline': {'features': ('features_SelectKBest', {'features__k': 2}), 'normalizer': ('normalizer_NoneType', {}), 'rebalance': ('rebalance_NearMiss', {'rebalance__n_neighbors': 1})}, 'score': 0.8195239938080494, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': None, 'max_features': 3, 'max_leaf_nodes': 5, 'min_samples_split': 3, 'n_estimators': 50}, 'config_hash': {'algorithm': '0129970b8c7fe034ac8283fb518a06cfbead63d2', 'config': '61bcd2f64860b3dfe2503be88a6bbec165db0754', 'pipeline': '359f2473075ecfd9ae3ce526da96143918517601'}, 'duration': 0.7467091083526611, 'iteration': 19, 'loss': 0.09915720674234607, 'max_history_score': 0.9888888888888889, 'max_history_score_std': 0.022222222222222233, 'max_history_step': 'joint', 'pipeline': {'features': ('features_SelectKBest', {'features__k': 3}), 'normalizer': ('normalizer_RobustScaler', {'normalizer__quantile_range': (...), 'normalizer__with_centering': True, 'normalizer__with_scaling': False}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 7})}, 'score': 0.9008427932576539, ...}, ...], 'history_hash': ['2e6648b63441361b4398cb94f81d2e04a830b2ef', '584343bc020d2d7bc89bd0856bc7770dae1c84fc', 'de121d053e65def047cc8947f505578d5c5eab67', 'b21c9d15a389baa5bfea4c8ddcec129259f37540', 'edd3456355d80775739c31515c832ca7b4e5e094', '0800d7d2c8c10d2f9e7b4e5127b343e916eb742c', 'd98b641879b4754f2169335626a90575e945fd7c', '3f83df36a6abbdf7ea4a4bdcaf6727f23529c2bb', '037fd5c655b39cc7922fb394d736496befcc747b', '6609280032189b59de1afbe36f3acb1d5c273693', '8e1c17ac9f6e03740f380fccb833c9c3931ffc35', '87c03d0cb8e8500e58cacc1a0f27ce54c41a2937', '2ab964abffa0a277a9e2ee9b5570cd258e428b62', '5c95db3ad238063227f1b36e6a006d70c834c5da', '50fd1169b8e42190600f25152654254b5d0e3ed1', 'a05b6d2ffd65d4d937c0b178655d857bf4d61410', 'ebebb7a93116f14f470e062e37582a59f4aeb0df', 'a2c21314ddbba47ddbfe416e0aa14853a71179e0', '6c8a721218e7c550a98c5ba72ad9ff86afd5e3a4', '61bcd2f64860b3dfe2503be88a6bbec165db0754', ...], 'history_index': {'0018716ad6e0edc096329f31492734a67d79d3b3': 64, '01c777816cea234a1e6b73501020cf6f05ea69b9': 111, '020ec4a49249e6e129cbf2800d975e6e1c8842aa': 92, '037fd5c655b39cc7922fb394d736496befcc747b': 8, '0393a0da80adcc0e64c60f266b4277ec0e84ea81': 141, '0414a55701bd4c21bd4e55ad37a0576c56d56b3f': 94, '0650ac92dace31c01ac743925565b952112a5c82': 78, '07fdf9d0d0248a4b0215a633c75a2dd101dcf465': 22, '0800d7d2c8c10d2f9e7b4e5127b343e916eb742c': 5, '09cf55372e045d42fd53684507ba9d24737bdcec': 87, ...}, 'iteration': 161, 'max_history_score': 1.0, 'max_history_score_std': 0.0, 'max_history_step': 'joint'}, config={'algorithm': 'RandomForest', 'seed': 42, 'time': 300}, step='joint')
     45                 y,
     46                 cv=10,
     47                 n_jobs=-1,
     48                 return_estimator=False,
     49                 return_train_score=False,
---> 50                 verbose=0)
     51         score = np.mean(scores['test_score'])
     52         std = np.std(scores['test_score'])
     53         status = STATUS_OK
     54     except Exception as e:

...........................................................................
/home/aquemy/.local/lib/python2.7/site-packages/sklearn/model_selection/_validation.py in cross_validate(estimator=Pipeline(memory=None,
     steps=[('normalizer',... random_state=42, verbose=0, warm_start=False))]), X=array([[1.423e+01, 1.710e+00, 2.430e+00, ..., 1...., ..., 6.100e-01, 1.600e+00,
        5.600e+02]]), y=array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,
       2, 2]), groups=None, scoring=None, cv=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1, verbose=0, fit_params=None, pre_dispatch='2*n_jobs', return_train_score=False, return_estimator=False, error_score='raise-deprecating')
    235         delayed(_fit_and_score)(
    236             clone(estimator), X, y, scorers, train, test, verbose, None,
    237             fit_params, return_train_score=return_train_score,
    238             return_times=True, return_estimator=return_estimator,
    239             error_score=error_score)
--> 240         for train, test in cv.split(X, y, groups))
        cv.split = <bound method StratifiedKFold.split of Stratifie...d(n_splits=10, random_state=None, shuffle=False)>
        X = array([[1.423e+01, 1.710e+00, 2.430e+00, ..., 1...., ..., 6.100e-01, 1.600e+00,
        5.600e+02]])
        y = array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,
       2, 2])
        groups = None
    241 
    242     zipped_scores = list(zip(*scores))
    243     if return_train_score:
    244         train_scores = zipped_scores.pop(0)

...........................................................................
/home/aquemy/.local/lib/python2.7/site-packages/sklearn/externals/joblib/parallel.py in __call__(self=Parallel(n_jobs=-1), iterable=<generator object <genexpr>>)
    925                 # No need to wait for async callbacks to trigger to
    926                 # consumption.
    927                 self._iterating = False
    928 
    929             with self._backend.retrieval_context():
--> 930                 self.retrieve()
        self.retrieve = <bound method Parallel.retrieve of Parallel(n_jobs=-1)>
    931             # Make sure that we get a last message telling us we are done
    932             elapsed_time = time.time() - self._start_time
    933             self._print('Done %3i out of %3i | elapsed: %s finished',
    934                         (len(self._output), len(self._output),

---------------------------------------------------------------------------
Joblib worker traceback:
---------------------------------------------------------------------------
ValueError                                         Mon Jun 17 12:47:41 2019
PID: 15508                                  Python 2.7.15+: /usr/bin/python
...........................................................................
/home/aquemy/.local/lib/python2.7/site-packages/sklearn/externals/joblib/parallel.py in __call__(self=<sklearn.externals.joblib.parallel.BatchedCalls object>)
    220     def __call__(self):
    221         # Set the default nested backend to self._backend but do not set the
    222         # change the default number of processes to -1
    223         with parallel_backend(self._backend, n_jobs=self._n_jobs):
    224             return [func(*args, **kwargs)
--> 225                     for func, args, kwargs in self.items]
        func = <function _fit_and_score>
        args = (Pipeline(memory=None,
     steps=[('normalizer',... random_state=42, verbose=0, warm_start=False))]), array([[1.423e+01, 1.710e+00, 2.430e+00, ..., 1...., ..., 6.100e-01, 1.600e+00,
        5.600e+02]]), array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,
       2, 2]), {'score': <function _passthrough_scorer>}, array([  6,   7,   8,   9,  10,  11,  12,  13,  ..., 170, 171, 172, 173, 174,
       175, 176, 177]), array([  0,   1,   2,   3,   4,   5,  59,  60,  ...,  64,  65,
        66, 130, 131, 132, 133, 134]), 0, None, None)
        kwargs = {'error_score': 'raise-deprecating', 'return_estimator': False, 'return_times': True, 'return_train_score': False}
        self.items = [(<function _fit_and_score>, (Pipeline(memory=None,
     steps=[('normalizer',... random_state=42, verbose=0, warm_start=False))]), array([[1.423e+01, 1.710e+00, 2.430e+00, ..., 1...., ..., 6.100e-01, 1.600e+00,
        5.600e+02]]), array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,
       2, 2]), {'score': <function _passthrough_scorer>}, array([  6,   7,   8,   9,  10,  11,  12,  13,  ..., 170, 171, 172, 173, 174,
       175, 176, 177]), array([  0,   1,   2,   3,   4,   5,  59,  60,  ...,  64,  65,
        66, 130, 131, 132, 133, 134]), 0, None, None), {'error_score': 'raise-deprecating', 'return_estimator': False, 'return_times': True, 'return_train_score': False})]
    226 
    227     def __len__(self):
    228         return self._size
    229 

...........................................................................
/home/aquemy/.local/lib/python2.7/site-packages/sklearn/model_selection/_validation.py in _fit_and_score(estimator=Pipeline(memory=None,
     steps=[('normalizer',... random_state=42, verbose=0, warm_start=False))]), X=array([[1.423e+01, 1.710e+00, 2.430e+00, ..., 1...., ..., 6.100e-01, 1.600e+00,
        5.600e+02]]), y=array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,
       2, 2]), scorer={'score': <function _passthrough_scorer>}, train=array([  6,   7,   8,   9,  10,  11,  12,  13,  ..., 170, 171, 172, 173, 174,
       175, 176, 177]), test=array([  0,   1,   2,   3,   4,   5,  59,  60,  ...,  64,  65,
        66, 130, 131, 132, 133, 134]), verbose=0, parameters=None, fit_params={}, return_train_score=False, return_parameters=False, return_n_test_samples=False, return_times=True, return_estimator=False, error_score='raise-deprecating')
    523 
    524     try:
    525         if y_train is None:
    526             estimator.fit(X_train, **fit_params)
    527         else:
--> 528             estimator.fit(X_train, y_train, **fit_params)
        estimator.fit = <bound method Pipeline.fit of Pipeline(memory=No...random_state=42, verbose=0, warm_start=False))])>
        X_train = array([[1.439e+01, 1.870e+00, 2.450e+00, ..., 1...., ..., 6.100e-01, 1.600e+00,
        5.600e+02]])
        y_train = array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...2, 2, 2, 2, 2, 2, 2, 2, 2,
       2, 2, 2, 2, 2])
        fit_params = {}
    529 
    530     except Exception as e:
    531         # Note fit time as time until error
    532         fit_time = time.time() - start_time

...........................................................................
/usr/local/lib/python2.7/dist-packages/imblearn/pipeline.py in fit(self=Pipeline(memory=None,
     steps=[('normalizer',... random_state=42, verbose=0, warm_start=False))]), X=array([[1.439e+01, 1.870e+00, 2.450e+00, ..., 1...., ..., 6.100e-01, 1.600e+00,
        5.600e+02]]), y=array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...2, 2, 2, 2, 2, 2, 2, 2, 2,
       2, 2, 2, 2, 2]), **fit_params={})
    234             This estimator
    235 
    236         """
    237         Xt, yt, fit_params = self._fit(X, y, **fit_params)
    238         if self._final_estimator is not None:
--> 239             self._final_estimator.fit(Xt, yt, **fit_params)
        self._final_estimator.fit = <bound method RandomForestClassifier.fit of Rand...e, random_state=42, verbose=0, warm_start=False)>
        Xt = array([[-2.42519641],
       [-1.88635231],
    ...23],
       [ 2.40236773],
       [ 3.11189348]])
        yt = array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...2, 2, 2, 2, 2, 2, 2, 2, 2,
       2, 2, 2, 2, 2])
        fit_params = {}
    240         return self
    241 
    242     def fit_transform(self, X, y=None, **fit_params):
    243         """Fit the model and transform with the final estimator

...........................................................................
/home/aquemy/.local/lib/python2.7/site-packages/sklearn/ensemble/forest.py in fit(self=RandomForestClassifier(bootstrap=True, class_wei...se, random_state=42, verbose=0, warm_start=False), X=array([[-2.4251964 ],
       [-1.8863523 ],
    ....4023678 ],
       [ 3.1118934 ]], dtype=float32), y=array([[0.],
       [0.],
       [0.],
       [0...    [2.],
       [2.],
       [2.],
       [2.]]), sample_weight=None)
    328             trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,
    329                              **_joblib_parallel_args(prefer='threads'))(
    330                 delayed(_parallel_build_trees)(
    331                     t, self, X, y, sample_weight, i, len(trees),
    332                     verbose=self.verbose, class_weight=self.class_weight)
--> 333                 for i, t in enumerate(trees))
        i = 74
    334 
    335             # Collect newly grown trees
    336             self.estimators_.extend(trees)
    337 

...........................................................................
/home/aquemy/.local/lib/python2.7/site-packages/sklearn/externals/joblib/parallel.py in __call__(self=Parallel(n_jobs=1), iterable=<generator object <genexpr>>)
    912             # self._original_iterator is None, then this means either
    913             # that pre_dispatch == "all", n_jobs == 1 or that the first batch
    914             # was very quick and its callback already dispatched all the
    915             # remaining jobs.
    916             self._iterating = False
--> 917             if self.dispatch_one_batch(iterator):
        self.dispatch_one_batch = <bound method Parallel.dispatch_one_batch of Parallel(n_jobs=1)>
        iterator = <generator object <genexpr>>
    918                 self._iterating = self._original_iterator is not None
    919 
    920             while self.dispatch_one_batch(iterator):
    921                 pass

...........................................................................
/home/aquemy/.local/lib/python2.7/site-packages/sklearn/externals/joblib/parallel.py in dispatch_one_batch(self=Parallel(n_jobs=1), iterator=<generator object <genexpr>>)
    754                                  self._pickle_cache)
    755             if len(tasks) == 0:
    756                 # No more tasks available in the iterator: tell caller to stop.
    757                 return False
    758             else:
--> 759                 self._dispatch(tasks)
        self._dispatch = <bound method Parallel._dispatch of Parallel(n_jobs=1)>
        tasks = <sklearn.externals.joblib.parallel.BatchedCalls object>
    760                 return True
    761 
    762     def _print(self, msg, msg_args):
    763         """Display the message on stout or stderr depending on verbosity"""

...........................................................................
/home/aquemy/.local/lib/python2.7/site-packages/sklearn/externals/joblib/parallel.py in _dispatch(self=Parallel(n_jobs=1), batch=<sklearn.externals.joblib.parallel.BatchedCalls object>)
    711 
    712         dispatch_timestamp = time.time()
    713         cb = BatchCompletionCallBack(dispatch_timestamp, len(batch), self)
    714         with self._lock:
    715             job_idx = len(self._jobs)
--> 716             job = self._backend.apply_async(batch, callback=cb)
        job = undefined
        self._backend.apply_async = <bound method SequentialBackend.apply_async of <...lib._parallel_backends.SequentialBackend object>>
        batch = <sklearn.externals.joblib.parallel.BatchedCalls object>
        cb = <sklearn.externals.joblib.parallel.BatchCompletionCallBack object>
    717             # A job can complete so quickly than its callback is
    718             # called before we get here, causing self._jobs to
    719             # grow. To ensure correct results ordering, .insert is
    720             # used (rather than .append) in the following line

...........................................................................
/home/aquemy/.local/lib/python2.7/site-packages/sklearn/externals/joblib/_parallel_backends.py in apply_async(self=<sklearn.externals.joblib._parallel_backends.SequentialBackend object>, func=<sklearn.externals.joblib.parallel.BatchedCalls object>, callback=<sklearn.externals.joblib.parallel.BatchCompletionCallBack object>)
    177             raise ValueError('n_jobs == 0 in Parallel has no meaning')
    178         return 1
    179 
    180     def apply_async(self, func, callback=None):
    181         """Schedule a func to be run"""
--> 182         result = ImmediateResult(func)
        result = undefined
        func = <sklearn.externals.joblib.parallel.BatchedCalls object>
    183         if callback:
    184             callback(result)
    185         return result
    186 

...........................................................................
/home/aquemy/.local/lib/python2.7/site-packages/sklearn/externals/joblib/_parallel_backends.py in __init__(self=<sklearn.externals.joblib._parallel_backends.ImmediateResult object>, batch=<sklearn.externals.joblib.parallel.BatchedCalls object>)
    544 
    545 class ImmediateResult(object):
    546     def __init__(self, batch):
    547         # Don't delay the application, to avoid keeping the input
    548         # arguments in memory
--> 549         self.results = batch()
        self.results = undefined
        batch = <sklearn.externals.joblib.parallel.BatchedCalls object>
    550 
    551     def get(self):
    552         return self.results
    553 

...........................................................................
/home/aquemy/.local/lib/python2.7/site-packages/sklearn/externals/joblib/parallel.py in __call__(self=<sklearn.externals.joblib.parallel.BatchedCalls object>)
    220     def __call__(self):
    221         # Set the default nested backend to self._backend but do not set the
    222         # change the default number of processes to -1
    223         with parallel_backend(self._backend, n_jobs=self._n_jobs):
    224             return [func(*args, **kwargs)
--> 225                     for func, args, kwargs in self.items]
        func = <function _parallel_build_trees>
        args = (DecisionTreeClassifier(class_weight=None, criter...=False, random_state=1608637542, splitter='best'), RandomForestClassifier(bootstrap=True, class_wei...se, random_state=42, verbose=0, warm_start=False), array([[-2.4251964 ],
       [-1.8863523 ],
    ....4023678 ],
       [ 3.1118934 ]], dtype=float32), array([[0.],
       [0.],
       [0.],
       [0...    [2.],
       [2.],
       [2.],
       [2.]]), None, 0, 75)
        kwargs = {'class_weight': None, 'verbose': 0}
        self.items = [(<function _parallel_build_trees>, (DecisionTreeClassifier(class_weight=None, criter...=False, random_state=1608637542, splitter='best'), RandomForestClassifier(bootstrap=True, class_wei...se, random_state=42, verbose=0, warm_start=False), array([[-2.4251964 ],
       [-1.8863523 ],
    ....4023678 ],
       [ 3.1118934 ]], dtype=float32), array([[0.],
       [0.],
       [0.],
       [0...    [2.],
       [2.],
       [2.],
       [2.]]), None, 0, 75), {'class_weight': None, 'verbose': 0})]
    226 
    227     def __len__(self):
    228         return self._size
    229 

...........................................................................
/home/aquemy/.local/lib/python2.7/site-packages/sklearn/ensemble/forest.py in _parallel_build_trees(tree=DecisionTreeClassifier(class_weight=None, criter...=False, random_state=1608637542, splitter='best'), forest=RandomForestClassifier(bootstrap=True, class_wei...se, random_state=42, verbose=0, warm_start=False), X=array([[-2.4251964 ],
       [-1.8863523 ],
    ....4023678 ],
       [ 3.1118934 ]], dtype=float32), y=array([[0.],
       [0.],
       [0.],
       [0...    [2.],
       [2.],
       [2.],
       [2.]]), sample_weight=None, tree_idx=0, n_trees=75, verbose=0, class_weight=None)
    114                 simplefilter('ignore', DeprecationWarning)
    115                 curr_sample_weight *= compute_sample_weight('auto', y, indices)
    116         elif class_weight == 'balanced_subsample':
    117             curr_sample_weight *= compute_sample_weight('balanced', y, indices)
    118 
--> 119         tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)
        tree.fit = <bound method DecisionTreeClassifier.fit of Deci...False, random_state=1608637542, splitter='best')>
        X = array([[-2.4251964 ],
       [-1.8863523 ],
    ....4023678 ],
       [ 3.1118934 ]], dtype=float32)
        y = array([[0.],
       [0.],
       [0.],
       [0...    [2.],
       [2.],
       [2.],
       [2.]])
        sample_weight = None
        curr_sample_weight = array([3., 3., 0., 1., 1., 2., 2., 0., 1., 2., 0..., 0., 3., 0., 1.,
       0., 0., 0., 2., 1., 1.])
    120     else:
    121         tree.fit(X, y, sample_weight=sample_weight, check_input=False)
    122 
    123     return tree

...........................................................................
/home/aquemy/.local/lib/python2.7/site-packages/sklearn/tree/tree.py in fit(self=DecisionTreeClassifier(class_weight=None, criter...=False, random_state=1608637542, splitter='best'), X=array([[-2.4251964 ],
       [-1.8863523 ],
    ....4023678 ],
       [ 3.1118934 ]], dtype=float32), y=array([[0.],
       [0.],
       [0.],
       [0...    [2.],
       [2.],
       [2.],
       [2.]]), sample_weight=array([3., 3., 0., 1., 1., 2., 2., 0., 1., 2., 0..., 0., 3., 0., 1.,
       0., 0., 0., 2., 1., 1.]), check_input=False, X_idx_sorted=None)
    796 
    797         super(DecisionTreeClassifier, self).fit(
    798             X, y,
    799             sample_weight=sample_weight,
    800             check_input=check_input,
--> 801             X_idx_sorted=X_idx_sorted)
        X_idx_sorted = None
    802         return self
    803 
    804     def predict_proba(self, X, check_input=True):
    805         """Predict class probabilities of the input samples X.

...........................................................................
/home/aquemy/.local/lib/python2.7/site-packages/sklearn/tree/tree.py in fit(self=DecisionTreeClassifier(class_weight=None, criter...=False, random_state=1608637542, splitter='best'), X=array([[-2.4251964 ],
       [-1.8863523 ],
    ....4023678 ],
       [ 3.1118934 ]], dtype=float32), y=array([[0.],
       [0.],
       [0.],
       [0...    [2.],
       [2.],
       [2.],
       [2.]]), sample_weight=array([3., 3., 0., 1., 1., 2., 2., 0., 1., 2., 0..., 0., 3., 0., 1.,
       0., 0., 0., 2., 1., 1.]), check_input=False, X_idx_sorted=None)
    237         if not 0 <= self.min_weight_fraction_leaf <= 0.5:
    238             raise ValueError("min_weight_fraction_leaf must in [0, 0.5]")
    239         if max_depth <= 0:
    240             raise ValueError("max_depth must be greater than zero. ")
    241         if not (0 < max_features <= self.n_features_):
--> 242             raise ValueError("max_features must be in (0, n_features]")
    243         if not isinstance(max_leaf_nodes, (numbers.Integral, np.integer)):
    244             raise ValueError("max_leaf_nodes must be integral number but was "
    245                              "%r" % max_leaf_nodes)
    246         if -1 < max_leaf_nodes < 2:

ValueError: max_features must be in (0, n_features]
___________________________________________________________________________
Best score: 1.0 (0.0) [J] | Score: 0.0 (0.0) [J]
Best score: 1.0 (0.0) [J] | Score: 0.724309855521 (0.107182653507) [J]
Best score: 1.0 (0.0) [J] | Score: 0.966959064327 (0.0366851292392) [J]
Best score: 1.0 (0.0) [J] | Score: 0.802564929481 (0.105220369305) [J]
Best score: 1.0 (0.0) [J] | Score: 0.983333333333 (0.0355729124302) [J]
Best score: 1.0 (0.0) [J] | Score: 0.983333333333 (0.0254587538609) [J]
Best score: 1.0 (0.0) [J] | Score: 0.949673202614 (0.0461976393388) [J]
Best score: 1.0 (0.0) [J] | Score: 0.977743378053 (0.0272938784642) [J]
Best score: 1.0 (0.0) [J] | Score: 0.988888888889 (0.0222222222222) [J]
Best score: 1.0 (0.0) [J] | Score: 0.938527691778 (0.0469386230249) [J]
Best score: 1.0 (0.0) [J] | Score: 0.95 (0.06309898162) [J]
Best score: 1.0 (0.0) [J] | Score: 0.805301857585 (0.103639648169) [J]
Best score: 1.0 (0.0) [J] | Score: 0.967251461988 (0.0434444283073) [J]
Best score: 1.0 (0.0) [J] | Score: 0.747886566907 (0.12937742688) [J]
Best score: 1.0 (0.0) [J] | Score: 0.971895424837 (0.0514059662804) [J]
Best score: 1.0 (0.0) [J] | Score: 0.87306501548 (0.110102014303) [J]
JoblibValueError
___________________________________________________________________________
...........................................................................
/home/aquemy/dev/dp_hyperparameters/extension/main.py in <module>()
     27 
     28     serializer.serialize_results(scenario, policy)
     29 
     30 if __name__ == "__main__":
     31     args = cli.parse_args()
---> 32     main(args)

...........................................................................
/home/aquemy/dev/dp_hyperparameters/extension/main.py in main(args=Namespace(customize=[(['control', 'seed'], '42')...io='./scenarios/rf_wine_joint.yaml', verbosity=0))
     21         test_size=0.4, 
     22         random_state=scenario['control']['seed']
     23     )
     24 
     25     policy = policies.initiate(scenario['setup']['policy'], config)
---> 26     policy.run(X,y)
        policy.run = <bound method Joint.run of <experiment.policies.joint.Joint object>>
        X = array([[1.423e+01, 1.710e+00, 2.430e+00, ..., 1...., ..., 6.100e-01, 1.600e+00,
        5.600e+02]])
        y = array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,
       2, 2])
     27 
     28     serializer.serialize_results(scenario, policy)
     29 
     30 if __name__ == "__main__":

...........................................................................
/home/aquemy/dev/dp_hyperparameters/extension/experiment/policies/joint.py in run(self=<experiment.policies.joint.Joint object>, X=array([[1.423e+01, 1.710e+00, 2.430e+00, ..., 1...., ..., 6.100e-01, 1.600e+00,
        5.600e+02]]), y=array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,
       2, 2]))
     32             algo=tpe.suggest, 
     33             max_evals=None,
     34             max_time=self.config['time'],     
     35             trials=trials,
     36             show_progressbar=False,
---> 37             verbose=0
     38         )
     39 
     40         best_config = self.context['best_config']
     41         super(Joint, self).display_step_results(best_config)

...........................................................................
/home/aquemy/dev/dp_hyperparameters/extension/hyperopt/fmin.py in fmin(fn=<functools.partial object>, space={'algorithm': {'bootstrap': <hyperopt.pyll.base.Apply object>, 'criterion': <hyperopt.pyll.base.Apply object>, 'max_depth': <hyperopt.pyll.base.Apply object>, 'max_features': <hyperopt.pyll.base.Apply object>, 'max_leaf_nodes': <hyperopt.pyll.base.Apply object>, 'min_samples_split': <hyperopt.pyll.base.Apply object>, 'n_estimators': <hyperopt.pyll.base.Apply object>}, 'pipeline': {'features': <hyperopt.pyll.base.Apply object>, 'normalizer': <hyperopt.pyll.base.Apply object>, 'rebalance': <hyperopt.pyll.base.Apply object>}}, algo=<function suggest>, max_evals=9223372036854775807, max_time=300, trials=<hyperopt.base.Trials object>, rstate=<mtrand.RandomState object>, allow_trials_fmin=True, pass_expr_memo_ctrl=None, catch_eval_exceptions=False, verbose=0, return_argmin=True, points_to_evaluate=None, max_queue_len=1, show_progressbar=False)
    406             pass_expr_memo_ctrl=pass_expr_memo_ctrl,
    407             verbose=verbose,
    408             catch_eval_exceptions=catch_eval_exceptions,
    409             return_argmin=return_argmin,
    410             show_progressbar=show_progressbar,
--> 411             max_time=max_time
        max_time = 300
    412         )
    413 
    414     if trials is None:
    415         if points_to_evaluate is None:

...........................................................................
/home/aquemy/dev/dp_hyperparameters/extension/hyperopt/base.py in fmin(self=<hyperopt.base.Trials object>, fn=<functools.partial object>, space={'algorithm': {'bootstrap': <hyperopt.pyll.base.Apply object>, 'criterion': <hyperopt.pyll.base.Apply object>, 'max_depth': <hyperopt.pyll.base.Apply object>, 'max_features': <hyperopt.pyll.base.Apply object>, 'max_leaf_nodes': <hyperopt.pyll.base.Apply object>, 'min_samples_split': <hyperopt.pyll.base.Apply object>, 'n_estimators': <hyperopt.pyll.base.Apply object>}, 'pipeline': {'features': <hyperopt.pyll.base.Apply object>, 'normalizer': <hyperopt.pyll.base.Apply object>, 'rebalance': <hyperopt.pyll.base.Apply object>}}, algo=<function suggest>, max_evals=9223372036854775807, max_time=300, rstate=<mtrand.RandomState object>, verbose=0, pass_expr_memo_ctrl=None, catch_eval_exceptions=False, return_argmin=True, show_progressbar=False)
    636             verbose=verbose,
    637             allow_trials_fmin=False,  # -- prevent recursion
    638             pass_expr_memo_ctrl=pass_expr_memo_ctrl,
    639             catch_eval_exceptions=catch_eval_exceptions,
    640             return_argmin=return_argmin,
--> 641             show_progressbar=show_progressbar)
        show_progressbar = False
    642 
    643 
    644 def trials_from_docs(docs, validate=True, **kwargs):
    645     """Construct a Trials base class instance from a list of trials documents

...........................................................................
/home/aquemy/dev/dp_hyperparameters/extension/hyperopt/fmin.py in fmin(fn=<functools.partial object>, space={'algorithm': {'bootstrap': <hyperopt.pyll.base.Apply object>, 'criterion': <hyperopt.pyll.base.Apply object>, 'max_depth': <hyperopt.pyll.base.Apply object>, 'max_features': <hyperopt.pyll.base.Apply object>, 'max_leaf_nodes': <hyperopt.pyll.base.Apply object>, 'min_samples_split': <hyperopt.pyll.base.Apply object>, 'n_estimators': <hyperopt.pyll.base.Apply object>}, 'pipeline': {'features': <hyperopt.pyll.base.Apply object>, 'normalizer': <hyperopt.pyll.base.Apply object>, 'rebalance': <hyperopt.pyll.base.Apply object>}}, algo=<function suggest>, max_evals=9223372036854775807, max_time=300, trials=<hyperopt.base.Trials object>, rstate=<mtrand.RandomState object>, allow_trials_fmin=False, pass_expr_memo_ctrl=None, catch_eval_exceptions=False, verbose=0, return_argmin=True, points_to_evaluate=None, max_queue_len=1, show_progressbar=False)
    426                     verbose=verbose,
    427                     max_queue_len=max_queue_len,
    428                     show_progressbar=show_progressbar,
    429                     max_time=max_time)
    430     rval.catch_eval_exceptions = catch_eval_exceptions
--> 431     rval.exhaust()
        rval.exhaust = <bound method FMinIter.exhaust of <hyperopt.fmin.FMinIter object>>
    432     if return_argmin:
    433         return trials.argmin
    434     elif len(trials) > 0:
    435         # Only if there are some succesfull trail runs, return the best point in the evaluation space

...........................................................................
/home/aquemy/dev/dp_hyperparameters/extension/hyperopt/fmin.py in exhaust(self=<hyperopt.fmin.FMinIter object>)
    273             raise StopIteration()
    274         return self.trials
    275 
    276     def exhaust(self):
    277         n_done = len(self.trials)
--> 278         self.run(self.max_evals - n_done, block_until_done=self.asynchronous)
        self.run = <bound method FMinIter.run of <hyperopt.fmin.FMinIter object>>
        self.max_evals = 9223372036854775807
        n_done = 0
        self.asynchronous = False
    279         self.trials.refresh()
    280         return self
    281 
    282 

...........................................................................
/home/aquemy/dev/dp_hyperparameters/extension/hyperopt/fmin.py in run(self=<hyperopt.fmin.FMinIter object>, N=9223372036854775807, block_until_done=False)
    232                     if self.asynchronous:
    233                         # -- wait for workers to fill in the trials
    234                         time.sleep(self.poll_interval_secs)
    235                     else:
    236                         # -- loop over trials and do the jobs directly
--> 237                         self.serial_evaluate()
        self.serial_evaluate = <bound method FMinIter.serial_evaluate of <hyperopt.fmin.FMinIter object>>
    238                     try:
    239                         res = [d['result']['loss'] for d in
    240                                          self.trials.trials if
    241                                          d['result']['status'] == 'ok']

...........................................................................
/home/aquemy/dev/dp_hyperparameters/extension/hyperopt/fmin.py in serial_evaluate(self=<hyperopt.fmin.FMinIter object>, N=-1)
    138                 trial['book_time'] = now
    139                 trial['refresh_time'] = now
    140                 spec = base.spec_from_misc(trial['misc'])
    141                 ctrl = base.Ctrl(self.trials, current_trial=trial)
    142                 try:
--> 143                     result = self.domain.evaluate(spec, ctrl)
        result = undefined
        self.domain.evaluate = <bound method Domain.evaluate of <hyperopt.base.Domain object>>
        spec = {'bootstrap': 1, 'criterion': 0, 'features': 1, 'features_PCA_features__n_components': 0, 'max_depth': 0, 'max_features': 1, 'max_leaf_nodes': 3, 'min_samples_split': 2, 'n_estimators': 2, 'normalizer': 3, ...}
        ctrl = <hyperopt.base.Ctrl object>
    144                 except Exception as e:
    145                     logger.info('job exception: %s' % str(e))
    146                     trial['state'] = base.JOB_STATE_ERROR
    147                     trial['misc']['error'] = (str(type(e)), str(e))

...........................................................................
/home/aquemy/dev/dp_hyperparameters/extension/hyperopt/base.py in evaluate(self=<hyperopt.base.Domain object>, config={'bootstrap': 1, 'criterion': 0, 'features': 1, 'features_PCA_features__n_components': 0, 'max_depth': 0, 'max_features': 1, 'max_leaf_nodes': 3, 'min_samples_split': 2, 'n_estimators': 2, 'normalizer': 3, ...}, ctrl=<hyperopt.base.Ctrl object>, attach_attachments=True)
    841             #    or the normal Python part (self.fn)
    842             pyll_rval = pyll.rec_eval(
    843                 self.expr,
    844                 memo=memo,
    845                 print_node_on_error=self.rec_eval_print_node_on_error)
--> 846             rval = self.fn(pyll_rval)
        rval = undefined
        self.fn = <functools.partial object>
        pyll_rval = {'algorithm': {'bootstrap': False, 'criterion': 'gini', 'max_depth': 1, 'max_features': 2, 'max_leaf_nodes': None, 'min_samples_split': 5, 'n_estimators': 50}, 'pipeline': {'features': ('features_PCA', {'features__n_components': 1}), 'normalizer': ('normalizer_MinMaxScaler', {}), 'rebalance': ('rebalance_NoneType', {})}}
    847 
    848         if isinstance(rval, (float, int, np.number)):
    849             dict_rval = {'loss': float(rval), 'status': STATUS_OK}
    850         else:

...........................................................................
/home/aquemy/dev/dp_hyperparameters/extension/experiment/objective.py in objective_joint(wconfig={'algorithm': {'bootstrap': False, 'criterion': 'gini', 'max_depth': 1, 'max_features': 2, 'max_leaf_nodes': None, 'min_samples_split': 5, 'n_estimators': 50}, 'pipeline': {'features': ('features_PCA', {'features__n_components': 1}), 'normalizer': ('normalizer_MinMaxScaler', {}), 'rebalance': ('rebalance_NoneType', {})}}, algorithm='RandomForest', X=array([[1.423e+01, 1.710e+00, 2.430e+00, ..., 1...., ..., 6.100e-01, 1.600e+00,
        5.600e+02]]), y=array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,
       2, 2]), context={'baseline_score': 0.9444100447196423, 'baseline_score_std': 0.04305547117084885, 'best_config': {'algorithm': {'bootstrap': False, 'criterion': 'gini', 'max_depth': 1, 'max_features': 1, 'max_leaf_nodes': 3, 'min_samples_split': 2, 'n_estimators': 50}, 'config_hash': {'algorithm': '41bdc0fd26679e3e9de3f47a81dcebdeb54f6274', 'config': '0ada0978fbb60b78d813177773f684a809a8f7c8', 'pipeline': 'aaf976c7c663a31fa039582d42f9e07101556a7c'}, 'duration': 0.6971359252929688, 'iteration': 62, 'loss': 0.0, 'max_history_score': 1.0, 'max_history_score_std': 0.0, 'max_history_step': 'joint', 'pipeline': {'features': ('features_NoneType', {}), 'normalizer': ('normalizer_PowerTransformer', {}), 'rebalance': ('rebalance_NoneType', {})}, 'score': 1.0, ...}, 'history': [{'algorithm': {'bootstrap': False, 'criterion': 'entropy', 'max_depth': None, 'max_features': 3, 'max_leaf_nodes': 5, 'min_samples_split': 2, 'n_estimators': 50}, 'config_hash': {'algorithm': 'b2c6464add7a35ce8048653a39338c9994de9a4f', 'config': '2e6648b63441361b4398cb94f81d2e04a830b2ef', 'pipeline': '3d44d7482e468d08c4f94457a205f3dac74084c1'}, 'duration': 0.737678050994873, 'iteration': 0, 'loss': 1.0, 'max_history_score': 0.0, 'max_history_score_std': 0.0, 'max_history_step': 'baseline', 'pipeline': {'features': ('features_PCA', {'features__n_components': 1}), 'normalizer': ('normalizer_NoneType', {}), 'rebalance': ('rebalance_CondensedNearestNeighbour', {'rebalance__n_neighbors': 3})}, 'score': 0.0, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'gini', 'max_depth': 1, 'max_features': None, 'max_leaf_nodes': 2, 'min_samples_split': 3, 'n_estimators': 25}, 'config_hash': {'algorithm': '7f71bbbfdb4e8da52b6fc33a43224183117de15e', 'config': '584343bc020d2d7bc89bd0856bc7770dae1c84fc', 'pipeline': '466ffa7ace0e442beb7c311eb214b17a4c6832b3'}, 'duration': 1.5976769924163818, 'iteration': 1, 'loss': 0.40386351909184726, 'max_history_score': 0.5961364809081527, 'max_history_score_std': 0.05351463210025494, 'max_history_step': 'joint', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 3, 'features__selectkbest__k': 3}), 'normalizer': ('normalizer_StandardScaler', {'normalizer__with_mean': True, 'normalizer__with_std': True}), 'rebalance': ('rebalance_NearMiss', {'rebalance__n_neighbors': 2})}, 'score': 0.5961364809081527, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'entropy', 'max_depth': 1, 'max_features': 2, 'max_leaf_nodes': 2, 'min_samples_split': 5, 'n_estimators': 25}, 'config_hash': {'algorithm': '897745a20d929d43e760cacee0a764bd8070daa5', 'config': 'de121d053e65def047cc8947f505578d5c5eab67', 'pipeline': '63040b39b48626a8232e847e8327bdca5cd88611'}, 'duration': 0.815453052520752, 'iteration': 2, 'loss': 0.07327786377708967, 'max_history_score': 0.9267221362229103, 'max_history_score_std': 0.043920207373658794, 'max_history_step': 'joint', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 3, 'features__selectkbest__k': 2}), 'normalizer': ('normalizer_StandardScaler', {'normalizer__with_mean': True, 'normalizer__with_std': True}), 'rebalance': ('rebalance_NoneType', {})}, 'score': 0.9267221362229103, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'entropy', 'max_depth': 4, 'max_features': 3, 'max_leaf_nodes': None, 'min_samples_split': 2, 'n_estimators': 100}, 'config_hash': {'algorithm': 'dbd92c75280ec06b66ca4ad9b135cf36957031a4', 'config': 'b21c9d15a389baa5bfea4c8ddcec129259f37540', 'pipeline': '38866720d2f120c863351493b9b4e23b9a4506dc'}, 'duration': 1.2293269634246826, 'iteration': 3, 'loss': 0.07199862401100798, 'max_history_score': 0.928001375988992, 'max_history_score_std': 0.06518367535896959, 'max_history_step': 'joint', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 2, 'features__selectkbest__k': 4}), 'normalizer': ('normalizer_NoneType', {}), 'rebalance': ('rebalance_NoneType', {})}, 'score': 0.928001375988992, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': 2, 'max_features': None, 'max_leaf_nodes': None, 'min_samples_split': 5, 'n_estimators': 100}, 'config_hash': {'algorithm': 'f455eefd9fdd03ece88892c3f440c580bdf27ddb', 'config': 'edd3456355d80775739c31515c832ca7b4e5e094', 'pipeline': '1d1034f9f0871e43f896c1db4ed6fd572ed0a6ef'}, 'duration': 1.6186630725860596, 'iteration': 4, 'loss': 0.16651831785345705, 'max_history_score': 0.928001375988992, 'max_history_score_std': 0.06518367535896959, 'max_history_step': 'joint', 'pipeline': {'features': ('features_SelectKBest', {'features__k': 4}), 'normalizer': ('normalizer_MinMaxScaler', {}), 'rebalance': ('rebalance_CondensedNearestNeighbour', {'rebalance__n_neighbors': 1})}, 'score': 0.833481682146543, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'entropy', 'max_depth': 1, 'max_features': 2, 'max_leaf_nodes': None, 'min_samples_split': 2, 'n_estimators': 10}, 'config_hash': {'algorithm': '29906eaa0712a68ea145b12821d54ba445726fbf', 'config': '0800d7d2c8c10d2f9e7b4e5127b343e916eb742c', 'pipeline': '2e0f188ae61600352a7159285e0f542b4587a403'}, 'duration': 0.19410085678100586, 'iteration': 5, 'loss': 0.20164258685930514, 'max_history_score': 0.928001375988992, 'max_history_score_std': 0.06518367535896959, 'max_history_step': 'joint', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 3, 'features__selectkbest__k': 4}), 'normalizer': ('normalizer_StandardScaler', {'normalizer__with_mean': True, 'normalizer__with_std': False}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 7})}, 'score': 0.7983574131406949, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': 1, 'max_features': 1, 'max_leaf_nodes': 5, 'min_samples_split': 2, 'n_estimators': 25}, 'config_hash': {'algorithm': 'fbb7d57e38cfc08240f0af985282da418cb33556', 'config': 'd98b641879b4754f2169335626a90575e945fd7c', 'pipeline': '62463de065924498cdcd2f2f1f7e68535cdb33a5'}, 'duration': 0.3625810146331787, 'iteration': 6, 'loss': 0.14327485380116955, 'max_history_score': 0.928001375988992, 'max_history_score_std': 0.06518367535896959, 'max_history_step': 'joint', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 1, 'features__selectkbest__k': 2}), 'normalizer': ('normalizer_NoneType', {}), 'rebalance': ('rebalance_NoneType', {})}, 'score': 0.8567251461988304, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'entropy', 'max_depth': 3, 'max_features': 1, 'max_leaf_nodes': None, 'min_samples_split': 2, 'n_estimators': 75}, 'config_hash': {'algorithm': 'fb2f5d4c4d636edac929e1454ce3d02a4fb134c1', 'config': '3f83df36a6abbdf7ea4a4bdcaf6727f23529c2bb', 'pipeline': '8377b93e334656d1a93d266493b58ef9a6a1786f'}, 'duration': 0.8223779201507568, 'iteration': 7, 'loss': 0.03921568627450989, 'max_history_score': 0.9607843137254901, 'max_history_score_std': 0.043526663832084804, 'max_history_step': 'joint', 'pipeline': {'features': ('features_PCA', {'features__n_components': 3}), 'normalizer': ('normalizer_MinMaxScaler', {}), 'rebalance': ('rebalance_NearMiss', {'rebalance__n_neighbors': 1})}, 'score': 0.9607843137254901, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'gini', 'max_depth': 3, 'max_features': 3, 'max_leaf_nodes': 2, 'min_samples_split': 2, 'n_estimators': 100}, 'config_hash': {'algorithm': '3c3fde6559b918694de4668d025d5418342db1b1', 'config': '037fd5c655b39cc7922fb394d736496befcc747b', 'pipeline': '2a5032814c6c7ed21dd5bd9686923d7fc2f8acc9'}, 'duration': 1.0435099601745605, 'iteration': 8, 'loss': 0.09955925352597172, 'max_history_score': 0.9607843137254901, 'max_history_score_std': 0.043526663832084804, 'max_history_step': 'joint', 'pipeline': {'features': ('features_NoneType', {}), 'normalizer': ('normalizer_RobustScaler', {'normalizer__quantile_range': (...), 'normalizer__with_centering': True, 'normalizer__with_scaling': True}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 7})}, 'score': 0.9004407464740283, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': 2, 'max_features': 1, 'max_leaf_nodes': None, 'min_samples_split': 3, 'n_estimators': 75}, 'config_hash': {'algorithm': '42185be98371e99ac896d2c6c2d69c451cb983ff', 'config': '6609280032189b59de1afbe36f3acb1d5c273693', 'pipeline': '8aab2941fc84d84f86fa56134e50909dbf9e19f5'}, 'duration': 0.9665219783782959, 'iteration': 9, 'loss': 0.01637426900584804, 'max_history_score': 0.983625730994152, 'max_history_score_std': 0.025023500462379746, 'max_history_step': 'joint', 'pipeline': {'features': ('features_NoneType', {}), 'normalizer': ('normalizer_PowerTransformer', {}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 5})}, 'score': 0.983625730994152, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': 1, 'max_features': 3, 'max_leaf_nodes': 2, 'min_samples_split': 3, 'n_estimators': 10}, 'config_hash': {'algorithm': '62a9fe705e4cd96e762bcc9543c4a456a5a9f188', 'config': '8e1c17ac9f6e03740f380fccb833c9c3931ffc35', 'pipeline': '3d44d7482e468d08c4f94457a205f3dac74084c1'}, 'duration': 0.46930503845214844, 'iteration': 10, 'loss': 1.0, 'max_history_score': 0.983625730994152, 'max_history_score_std': 0.025023500462379746, 'max_history_step': 'joint', 'pipeline': {'features': ('features_PCA', {'features__n_components': 1}), 'normalizer': ('normalizer_NoneType', {}), 'rebalance': ('rebalance_CondensedNearestNeighbour', {'rebalance__n_neighbors': 3})}, 'score': 0.0, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'gini', 'max_depth': 4, 'max_features': 1, 'max_leaf_nodes': 3, 'min_samples_split': 2, 'n_estimators': 100}, 'config_hash': {'algorithm': '086d6ca939a757bb32edb113a567f9d38744f061', 'config': '87c03d0cb8e8500e58cacc1a0f27ce54c41a2937', 'pipeline': '8f28ef0f35d97142278f9dacb4e9d1ff082e470f'}, 'duration': 2.1196961402893066, 'iteration': 11, 'loss': 0.15471276229790154, 'max_history_score': 0.983625730994152, 'max_history_score_std': 0.025023500462379746, 'max_history_step': 'joint', 'pipeline': {'features': ('features_PCA', {'features__n_components': 1}), 'normalizer': ('normalizer_StandardScaler', {'normalizer__with_mean': True, 'normalizer__with_std': True}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 7})}, 'score': 0.8452872377020985, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'entropy', 'max_depth': 3, 'max_features': 1, 'max_leaf_nodes': 2, 'min_samples_split': 2, 'n_estimators': 25}, 'config_hash': {'algorithm': '59f64a966796648c7bebade1127fa05541b391ad', 'config': '2ab964abffa0a277a9e2ee9b5570cd258e428b62', 'pipeline': 'eef3f702fd2fed761fa6744c1640d0bf320f1d00'}, 'duration': 0.9828321933746338, 'iteration': 12, 'loss': 0.0778465772273822, 'max_history_score': 0.983625730994152, 'max_history_score_std': 0.025023500462379746, 'max_history_step': 'joint', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 3, 'features__selectkbest__k': 1}), 'normalizer': ('normalizer_PowerTransformer', {}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 6})}, 'score': 0.9221534227726178, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'gini', 'max_depth': 4, 'max_features': 2, 'max_leaf_nodes': 3, 'min_samples_split': 3, 'n_estimators': 75}, 'config_hash': {'algorithm': '6f75c2a196eb9836df2b424e095051192eaed6ea', 'config': '5c95db3ad238063227f1b36e6a006d70c834c5da', 'pipeline': '1eae01a1128bee425c4d4ca0ee97a9afd409680e'}, 'duration': 0.8217771053314209, 'iteration': 13, 'loss': 0.03863089095287242, 'max_history_score': 0.983625730994152, 'max_history_score_std': 0.025023500462379746, 'max_history_step': 'joint', 'pipeline': {'features': ('features_NoneType', {}), 'normalizer': ('normalizer_StandardScaler', {'normalizer__with_mean': False, 'normalizer__with_std': False}), 'rebalance': ('rebalance_NearMiss', {'rebalance__n_neighbors': 1})}, 'score': 0.9613691090471276, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'entropy', 'max_depth': 4, 'max_features': 2, 'max_leaf_nodes': 3, 'min_samples_split': 2, 'n_estimators': 25}, 'config_hash': {'algorithm': '8aef3174f6b8020de06b825e0424c1e54d690afd', 'config': '50fd1169b8e42190600f25152654254b5d0e3ed1', 'pipeline': '9ceaa544911dc6c687e336cb8e9dd4d15ff1ceaf'}, 'duration': 0.40307188034057617, 'iteration': 14, 'loss': 1.0, 'max_history_score': 0.983625730994152, 'max_history_score_std': 0.025023500462379746, 'max_history_step': 'joint', 'pipeline': {'features': ('features_PCA', {'features__n_components': 1}), 'normalizer': ('normalizer_RobustScaler', {'normalizer__quantile_range': (...), 'normalizer__with_centering': False, 'normalizer__with_scaling': False}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 7})}, 'score': 0.0, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'gini', 'max_depth': 1, 'max_features': 1, 'max_leaf_nodes': 3, 'min_samples_split': 3, 'n_estimators': 50}, 'config_hash': {'algorithm': '37be8b6737f4b5d5ae35da51886f302b07ba6001', 'config': 'a05b6d2ffd65d4d937c0b178655d857bf4d61410', 'pipeline': 'cfef88e895db321122f2f7b813d9267b973c2468'}, 'duration': 1.7094659805297852, 'iteration': 15, 'loss': 0.011111111111111072, 'max_history_score': 0.9888888888888889, 'max_history_score_std': 0.022222222222222233, 'max_history_step': 'joint', 'pipeline': {'features': ('features_NoneType', {}), 'normalizer': ('normalizer_NoneType', {}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 5})}, 'score': 0.9888888888888889, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'entropy', 'max_depth': None, 'max_features': 3, 'max_leaf_nodes': None, 'min_samples_split': 2, 'n_estimators': 100}, 'config_hash': {'algorithm': 'c40543ce91793e367c1892c886bc49621c22ecfb', 'config': 'ebebb7a93116f14f470e062e37582a59f4aeb0df', 'pipeline': 'b50c63e800574e8b760f55f7c4ff1fcae8816dd8'}, 'duration': 0.6425540447235107, 'iteration': 16, 'loss': 1.0, 'max_history_score': 0.9888888888888889, 'max_history_score_std': 0.022222222222222233, 'max_history_step': 'joint', 'pipeline': {'features': ('features_PCA', {'features__n_components': 1}), 'normalizer': ('normalizer_PowerTransformer', {}), 'rebalance': ('rebalance_NearMiss', {'rebalance__n_neighbors': 1})}, 'score': 0.0, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'gini', 'max_depth': None, 'max_features': 1, 'max_leaf_nodes': 3, 'min_samples_split': 2, 'n_estimators': 50}, 'config_hash': {'algorithm': '0c69b9601237c20664085fa05764d855e28f98f7', 'config': 'a2c21314ddbba47ddbfe416e0aa14853a71179e0', 'pipeline': '914f81fa4fbb61db251201f32bd8ea11bfeea2a5'}, 'duration': 2.2209739685058594, 'iteration': 17, 'loss': 0.3206720846233231, 'max_history_score': 0.9888888888888889, 'max_history_score_std': 0.022222222222222233, 'max_history_step': 'joint', 'pipeline': {'features': ('features_SelectKBest', {'features__k': 4}), 'normalizer': ('normalizer_PowerTransformer', {}), 'rebalance': ('rebalance_CondensedNearestNeighbour', {'rebalance__n_neighbors': 1})}, 'score': 0.6793279153766769, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': 4, 'max_features': None, 'max_leaf_nodes': None, 'min_samples_split': 3, 'n_estimators': 25}, 'config_hash': {'algorithm': '1aae0f1fce5cab293ffdd4581c4838c8051ac815', 'config': '6c8a721218e7c550a98c5ba72ad9ff86afd5e3a4', 'pipeline': '77189452469cef9c840643f2babe0f825c6667c8'}, 'duration': 0.3951280117034912, 'iteration': 18, 'loss': 0.1804760061919506, 'max_history_score': 0.9888888888888889, 'max_history_score_std': 0.022222222222222233, 'max_history_step': 'joint', 'pipeline': {'features': ('features_SelectKBest', {'features__k': 2}), 'normalizer': ('normalizer_NoneType', {}), 'rebalance': ('rebalance_NearMiss', {'rebalance__n_neighbors': 1})}, 'score': 0.8195239938080494, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': None, 'max_features': 3, 'max_leaf_nodes': 5, 'min_samples_split': 3, 'n_estimators': 50}, 'config_hash': {'algorithm': '0129970b8c7fe034ac8283fb518a06cfbead63d2', 'config': '61bcd2f64860b3dfe2503be88a6bbec165db0754', 'pipeline': '359f2473075ecfd9ae3ce526da96143918517601'}, 'duration': 0.7467091083526611, 'iteration': 19, 'loss': 0.09915720674234607, 'max_history_score': 0.9888888888888889, 'max_history_score_std': 0.022222222222222233, 'max_history_step': 'joint', 'pipeline': {'features': ('features_SelectKBest', {'features__k': 3}), 'normalizer': ('normalizer_RobustScaler', {'normalizer__quantile_range': (...), 'normalizer__with_centering': True, 'normalizer__with_scaling': False}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 7})}, 'score': 0.9008427932576539, ...}, ...], 'history_hash': ['2e6648b63441361b4398cb94f81d2e04a830b2ef', '584343bc020d2d7bc89bd0856bc7770dae1c84fc', 'de121d053e65def047cc8947f505578d5c5eab67', 'b21c9d15a389baa5bfea4c8ddcec129259f37540', 'edd3456355d80775739c31515c832ca7b4e5e094', '0800d7d2c8c10d2f9e7b4e5127b343e916eb742c', 'd98b641879b4754f2169335626a90575e945fd7c', '3f83df36a6abbdf7ea4a4bdcaf6727f23529c2bb', '037fd5c655b39cc7922fb394d736496befcc747b', '6609280032189b59de1afbe36f3acb1d5c273693', '8e1c17ac9f6e03740f380fccb833c9c3931ffc35', '87c03d0cb8e8500e58cacc1a0f27ce54c41a2937', '2ab964abffa0a277a9e2ee9b5570cd258e428b62', '5c95db3ad238063227f1b36e6a006d70c834c5da', '50fd1169b8e42190600f25152654254b5d0e3ed1', 'a05b6d2ffd65d4d937c0b178655d857bf4d61410', 'ebebb7a93116f14f470e062e37582a59f4aeb0df', 'a2c21314ddbba47ddbfe416e0aa14853a71179e0', '6c8a721218e7c550a98c5ba72ad9ff86afd5e3a4', '61bcd2f64860b3dfe2503be88a6bbec165db0754', ...], 'history_index': {'0018716ad6e0edc096329f31492734a67d79d3b3': 64, '01c777816cea234a1e6b73501020cf6f05ea69b9': 111, '020ec4a49249e6e129cbf2800d975e6e1c8842aa': 92, '037fd5c655b39cc7922fb394d736496befcc747b': 8, '0393a0da80adcc0e64c60f266b4277ec0e84ea81': 141, '0414a55701bd4c21bd4e55ad37a0576c56d56b3f': 94, '0650ac92dace31c01ac743925565b952112a5c82': 78, '07fdf9d0d0248a4b0215a633c75a2dd101dcf465': 22, '0800d7d2c8c10d2f9e7b4e5127b343e916eb742c': 5, '09cf55372e045d42fd53684507ba9d24737bdcec': 87, ...}, 'iteration': 177, 'max_history_score': 1.0, 'max_history_score_std': 0.0, 'max_history_step': 'joint'}, config={'algorithm': 'RandomForest', 'seed': 42, 'time': 300})
    108 
    109 def objective_algo(algo_config, current_pipeline_config, algorithm, X, y, context, config):
    110     return objective(current_pipeline_config, algo_config, algorithm, X, y, context, config, step='algorithm')
    111 
    112 def objective_joint(wconfig, algorithm, X, y, context, config):
--> 113     return objective(wconfig['pipeline'], wconfig['algorithm'], algorithm, X, y, context, config, step='joint')
        wconfig = {'algorithm': {'bootstrap': False, 'criterion': 'gini', 'max_depth': 1, 'max_features': 2, 'max_leaf_nodes': None, 'min_samples_split': 5, 'n_estimators': 50}, 'pipeline': {'features': ('features_PCA', {'features__n_components': 1}), 'normalizer': ('normalizer_MinMaxScaler', {}), 'rebalance': ('rebalance_NoneType', {})}}
        algorithm = 'RandomForest'
        X = array([[1.423e+01, 1.710e+00, 2.430e+00, ..., 1...., ..., 6.100e-01, 1.600e+00,
        5.600e+02]])
        y = array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,
       2, 2])
        context = {'baseline_score': 0.9444100447196423, 'baseline_score_std': 0.04305547117084885, 'best_config': {'algorithm': {'bootstrap': False, 'criterion': 'gini', 'max_depth': 1, 'max_features': 1, 'max_leaf_nodes': 3, 'min_samples_split': 2, 'n_estimators': 50}, 'config_hash': {'algorithm': '41bdc0fd26679e3e9de3f47a81dcebdeb54f6274', 'config': '0ada0978fbb60b78d813177773f684a809a8f7c8', 'pipeline': 'aaf976c7c663a31fa039582d42f9e07101556a7c'}, 'duration': 0.6971359252929688, 'iteration': 62, 'loss': 0.0, 'max_history_score': 1.0, 'max_history_score_std': 0.0, 'max_history_step': 'joint', 'pipeline': {'features': ('features_NoneType', {}), 'normalizer': ('normalizer_PowerTransformer', {}), 'rebalance': ('rebalance_NoneType', {})}, 'score': 1.0, ...}, 'history': [{'algorithm': {'bootstrap': False, 'criterion': 'entropy', 'max_depth': None, 'max_features': 3, 'max_leaf_nodes': 5, 'min_samples_split': 2, 'n_estimators': 50}, 'config_hash': {'algorithm': 'b2c6464add7a35ce8048653a39338c9994de9a4f', 'config': '2e6648b63441361b4398cb94f81d2e04a830b2ef', 'pipeline': '3d44d7482e468d08c4f94457a205f3dac74084c1'}, 'duration': 0.737678050994873, 'iteration': 0, 'loss': 1.0, 'max_history_score': 0.0, 'max_history_score_std': 0.0, 'max_history_step': 'baseline', 'pipeline': {'features': ('features_PCA', {'features__n_components': 1}), 'normalizer': ('normalizer_NoneType', {}), 'rebalance': ('rebalance_CondensedNearestNeighbour', {'rebalance__n_neighbors': 3})}, 'score': 0.0, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'gini', 'max_depth': 1, 'max_features': None, 'max_leaf_nodes': 2, 'min_samples_split': 3, 'n_estimators': 25}, 'config_hash': {'algorithm': '7f71bbbfdb4e8da52b6fc33a43224183117de15e', 'config': '584343bc020d2d7bc89bd0856bc7770dae1c84fc', 'pipeline': '466ffa7ace0e442beb7c311eb214b17a4c6832b3'}, 'duration': 1.5976769924163818, 'iteration': 1, 'loss': 0.40386351909184726, 'max_history_score': 0.5961364809081527, 'max_history_score_std': 0.05351463210025494, 'max_history_step': 'joint', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 3, 'features__selectkbest__k': 3}), 'normalizer': ('normalizer_StandardScaler', {'normalizer__with_mean': True, 'normalizer__with_std': True}), 'rebalance': ('rebalance_NearMiss', {'rebalance__n_neighbors': 2})}, 'score': 0.5961364809081527, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'entropy', 'max_depth': 1, 'max_features': 2, 'max_leaf_nodes': 2, 'min_samples_split': 5, 'n_estimators': 25}, 'config_hash': {'algorithm': '897745a20d929d43e760cacee0a764bd8070daa5', 'config': 'de121d053e65def047cc8947f505578d5c5eab67', 'pipeline': '63040b39b48626a8232e847e8327bdca5cd88611'}, 'duration': 0.815453052520752, 'iteration': 2, 'loss': 0.07327786377708967, 'max_history_score': 0.9267221362229103, 'max_history_score_std': 0.043920207373658794, 'max_history_step': 'joint', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 3, 'features__selectkbest__k': 2}), 'normalizer': ('normalizer_StandardScaler', {'normalizer__with_mean': True, 'normalizer__with_std': True}), 'rebalance': ('rebalance_NoneType', {})}, 'score': 0.9267221362229103, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'entropy', 'max_depth': 4, 'max_features': 3, 'max_leaf_nodes': None, 'min_samples_split': 2, 'n_estimators': 100}, 'config_hash': {'algorithm': 'dbd92c75280ec06b66ca4ad9b135cf36957031a4', 'config': 'b21c9d15a389baa5bfea4c8ddcec129259f37540', 'pipeline': '38866720d2f120c863351493b9b4e23b9a4506dc'}, 'duration': 1.2293269634246826, 'iteration': 3, 'loss': 0.07199862401100798, 'max_history_score': 0.928001375988992, 'max_history_score_std': 0.06518367535896959, 'max_history_step': 'joint', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 2, 'features__selectkbest__k': 4}), 'normalizer': ('normalizer_NoneType', {}), 'rebalance': ('rebalance_NoneType', {})}, 'score': 0.928001375988992, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': 2, 'max_features': None, 'max_leaf_nodes': None, 'min_samples_split': 5, 'n_estimators': 100}, 'config_hash': {'algorithm': 'f455eefd9fdd03ece88892c3f440c580bdf27ddb', 'config': 'edd3456355d80775739c31515c832ca7b4e5e094', 'pipeline': '1d1034f9f0871e43f896c1db4ed6fd572ed0a6ef'}, 'duration': 1.6186630725860596, 'iteration': 4, 'loss': 0.16651831785345705, 'max_history_score': 0.928001375988992, 'max_history_score_std': 0.06518367535896959, 'max_history_step': 'joint', 'pipeline': {'features': ('features_SelectKBest', {'features__k': 4}), 'normalizer': ('normalizer_MinMaxScaler', {}), 'rebalance': ('rebalance_CondensedNearestNeighbour', {'rebalance__n_neighbors': 1})}, 'score': 0.833481682146543, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'entropy', 'max_depth': 1, 'max_features': 2, 'max_leaf_nodes': None, 'min_samples_split': 2, 'n_estimators': 10}, 'config_hash': {'algorithm': '29906eaa0712a68ea145b12821d54ba445726fbf', 'config': '0800d7d2c8c10d2f9e7b4e5127b343e916eb742c', 'pipeline': '2e0f188ae61600352a7159285e0f542b4587a403'}, 'duration': 0.19410085678100586, 'iteration': 5, 'loss': 0.20164258685930514, 'max_history_score': 0.928001375988992, 'max_history_score_std': 0.06518367535896959, 'max_history_step': 'joint', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 3, 'features__selectkbest__k': 4}), 'normalizer': ('normalizer_StandardScaler', {'normalizer__with_mean': True, 'normalizer__with_std': False}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 7})}, 'score': 0.7983574131406949, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': 1, 'max_features': 1, 'max_leaf_nodes': 5, 'min_samples_split': 2, 'n_estimators': 25}, 'config_hash': {'algorithm': 'fbb7d57e38cfc08240f0af985282da418cb33556', 'config': 'd98b641879b4754f2169335626a90575e945fd7c', 'pipeline': '62463de065924498cdcd2f2f1f7e68535cdb33a5'}, 'duration': 0.3625810146331787, 'iteration': 6, 'loss': 0.14327485380116955, 'max_history_score': 0.928001375988992, 'max_history_score_std': 0.06518367535896959, 'max_history_step': 'joint', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 1, 'features__selectkbest__k': 2}), 'normalizer': ('normalizer_NoneType', {}), 'rebalance': ('rebalance_NoneType', {})}, 'score': 0.8567251461988304, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'entropy', 'max_depth': 3, 'max_features': 1, 'max_leaf_nodes': None, 'min_samples_split': 2, 'n_estimators': 75}, 'config_hash': {'algorithm': 'fb2f5d4c4d636edac929e1454ce3d02a4fb134c1', 'config': '3f83df36a6abbdf7ea4a4bdcaf6727f23529c2bb', 'pipeline': '8377b93e334656d1a93d266493b58ef9a6a1786f'}, 'duration': 0.8223779201507568, 'iteration': 7, 'loss': 0.03921568627450989, 'max_history_score': 0.9607843137254901, 'max_history_score_std': 0.043526663832084804, 'max_history_step': 'joint', 'pipeline': {'features': ('features_PCA', {'features__n_components': 3}), 'normalizer': ('normalizer_MinMaxScaler', {}), 'rebalance': ('rebalance_NearMiss', {'rebalance__n_neighbors': 1})}, 'score': 0.9607843137254901, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'gini', 'max_depth': 3, 'max_features': 3, 'max_leaf_nodes': 2, 'min_samples_split': 2, 'n_estimators': 100}, 'config_hash': {'algorithm': '3c3fde6559b918694de4668d025d5418342db1b1', 'config': '037fd5c655b39cc7922fb394d736496befcc747b', 'pipeline': '2a5032814c6c7ed21dd5bd9686923d7fc2f8acc9'}, 'duration': 1.0435099601745605, 'iteration': 8, 'loss': 0.09955925352597172, 'max_history_score': 0.9607843137254901, 'max_history_score_std': 0.043526663832084804, 'max_history_step': 'joint', 'pipeline': {'features': ('features_NoneType', {}), 'normalizer': ('normalizer_RobustScaler', {'normalizer__quantile_range': (...), 'normalizer__with_centering': True, 'normalizer__with_scaling': True}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 7})}, 'score': 0.9004407464740283, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': 2, 'max_features': 1, 'max_leaf_nodes': None, 'min_samples_split': 3, 'n_estimators': 75}, 'config_hash': {'algorithm': '42185be98371e99ac896d2c6c2d69c451cb983ff', 'config': '6609280032189b59de1afbe36f3acb1d5c273693', 'pipeline': '8aab2941fc84d84f86fa56134e50909dbf9e19f5'}, 'duration': 0.9665219783782959, 'iteration': 9, 'loss': 0.01637426900584804, 'max_history_score': 0.983625730994152, 'max_history_score_std': 0.025023500462379746, 'max_history_step': 'joint', 'pipeline': {'features': ('features_NoneType', {}), 'normalizer': ('normalizer_PowerTransformer', {}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 5})}, 'score': 0.983625730994152, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': 1, 'max_features': 3, 'max_leaf_nodes': 2, 'min_samples_split': 3, 'n_estimators': 10}, 'config_hash': {'algorithm': '62a9fe705e4cd96e762bcc9543c4a456a5a9f188', 'config': '8e1c17ac9f6e03740f380fccb833c9c3931ffc35', 'pipeline': '3d44d7482e468d08c4f94457a205f3dac74084c1'}, 'duration': 0.46930503845214844, 'iteration': 10, 'loss': 1.0, 'max_history_score': 0.983625730994152, 'max_history_score_std': 0.025023500462379746, 'max_history_step': 'joint', 'pipeline': {'features': ('features_PCA', {'features__n_components': 1}), 'normalizer': ('normalizer_NoneType', {}), 'rebalance': ('rebalance_CondensedNearestNeighbour', {'rebalance__n_neighbors': 3})}, 'score': 0.0, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'gini', 'max_depth': 4, 'max_features': 1, 'max_leaf_nodes': 3, 'min_samples_split': 2, 'n_estimators': 100}, 'config_hash': {'algorithm': '086d6ca939a757bb32edb113a567f9d38744f061', 'config': '87c03d0cb8e8500e58cacc1a0f27ce54c41a2937', 'pipeline': '8f28ef0f35d97142278f9dacb4e9d1ff082e470f'}, 'duration': 2.1196961402893066, 'iteration': 11, 'loss': 0.15471276229790154, 'max_history_score': 0.983625730994152, 'max_history_score_std': 0.025023500462379746, 'max_history_step': 'joint', 'pipeline': {'features': ('features_PCA', {'features__n_components': 1}), 'normalizer': ('normalizer_StandardScaler', {'normalizer__with_mean': True, 'normalizer__with_std': True}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 7})}, 'score': 0.8452872377020985, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'entropy', 'max_depth': 3, 'max_features': 1, 'max_leaf_nodes': 2, 'min_samples_split': 2, 'n_estimators': 25}, 'config_hash': {'algorithm': '59f64a966796648c7bebade1127fa05541b391ad', 'config': '2ab964abffa0a277a9e2ee9b5570cd258e428b62', 'pipeline': 'eef3f702fd2fed761fa6744c1640d0bf320f1d00'}, 'duration': 0.9828321933746338, 'iteration': 12, 'loss': 0.0778465772273822, 'max_history_score': 0.983625730994152, 'max_history_score_std': 0.025023500462379746, 'max_history_step': 'joint', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 3, 'features__selectkbest__k': 1}), 'normalizer': ('normalizer_PowerTransformer', {}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 6})}, 'score': 0.9221534227726178, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'gini', 'max_depth': 4, 'max_features': 2, 'max_leaf_nodes': 3, 'min_samples_split': 3, 'n_estimators': 75}, 'config_hash': {'algorithm': '6f75c2a196eb9836df2b424e095051192eaed6ea', 'config': '5c95db3ad238063227f1b36e6a006d70c834c5da', 'pipeline': '1eae01a1128bee425c4d4ca0ee97a9afd409680e'}, 'duration': 0.8217771053314209, 'iteration': 13, 'loss': 0.03863089095287242, 'max_history_score': 0.983625730994152, 'max_history_score_std': 0.025023500462379746, 'max_history_step': 'joint', 'pipeline': {'features': ('features_NoneType', {}), 'normalizer': ('normalizer_StandardScaler', {'normalizer__with_mean': False, 'normalizer__with_std': False}), 'rebalance': ('rebalance_NearMiss', {'rebalance__n_neighbors': 1})}, 'score': 0.9613691090471276, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'entropy', 'max_depth': 4, 'max_features': 2, 'max_leaf_nodes': 3, 'min_samples_split': 2, 'n_estimators': 25}, 'config_hash': {'algorithm': '8aef3174f6b8020de06b825e0424c1e54d690afd', 'config': '50fd1169b8e42190600f25152654254b5d0e3ed1', 'pipeline': '9ceaa544911dc6c687e336cb8e9dd4d15ff1ceaf'}, 'duration': 0.40307188034057617, 'iteration': 14, 'loss': 1.0, 'max_history_score': 0.983625730994152, 'max_history_score_std': 0.025023500462379746, 'max_history_step': 'joint', 'pipeline': {'features': ('features_PCA', {'features__n_components': 1}), 'normalizer': ('normalizer_RobustScaler', {'normalizer__quantile_range': (...), 'normalizer__with_centering': False, 'normalizer__with_scaling': False}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 7})}, 'score': 0.0, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'gini', 'max_depth': 1, 'max_features': 1, 'max_leaf_nodes': 3, 'min_samples_split': 3, 'n_estimators': 50}, 'config_hash': {'algorithm': '37be8b6737f4b5d5ae35da51886f302b07ba6001', 'config': 'a05b6d2ffd65d4d937c0b178655d857bf4d61410', 'pipeline': 'cfef88e895db321122f2f7b813d9267b973c2468'}, 'duration': 1.7094659805297852, 'iteration': 15, 'loss': 0.011111111111111072, 'max_history_score': 0.9888888888888889, 'max_history_score_std': 0.022222222222222233, 'max_history_step': 'joint', 'pipeline': {'features': ('features_NoneType', {}), 'normalizer': ('normalizer_NoneType', {}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 5})}, 'score': 0.9888888888888889, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'entropy', 'max_depth': None, 'max_features': 3, 'max_leaf_nodes': None, 'min_samples_split': 2, 'n_estimators': 100}, 'config_hash': {'algorithm': 'c40543ce91793e367c1892c886bc49621c22ecfb', 'config': 'ebebb7a93116f14f470e062e37582a59f4aeb0df', 'pipeline': 'b50c63e800574e8b760f55f7c4ff1fcae8816dd8'}, 'duration': 0.6425540447235107, 'iteration': 16, 'loss': 1.0, 'max_history_score': 0.9888888888888889, 'max_history_score_std': 0.022222222222222233, 'max_history_step': 'joint', 'pipeline': {'features': ('features_PCA', {'features__n_components': 1}), 'normalizer': ('normalizer_PowerTransformer', {}), 'rebalance': ('rebalance_NearMiss', {'rebalance__n_neighbors': 1})}, 'score': 0.0, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'gini', 'max_depth': None, 'max_features': 1, 'max_leaf_nodes': 3, 'min_samples_split': 2, 'n_estimators': 50}, 'config_hash': {'algorithm': '0c69b9601237c20664085fa05764d855e28f98f7', 'config': 'a2c21314ddbba47ddbfe416e0aa14853a71179e0', 'pipeline': '914f81fa4fbb61db251201f32bd8ea11bfeea2a5'}, 'duration': 2.2209739685058594, 'iteration': 17, 'loss': 0.3206720846233231, 'max_history_score': 0.9888888888888889, 'max_history_score_std': 0.022222222222222233, 'max_history_step': 'joint', 'pipeline': {'features': ('features_SelectKBest', {'features__k': 4}), 'normalizer': ('normalizer_PowerTransformer', {}), 'rebalance': ('rebalance_CondensedNearestNeighbour', {'rebalance__n_neighbors': 1})}, 'score': 0.6793279153766769, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': 4, 'max_features': None, 'max_leaf_nodes': None, 'min_samples_split': 3, 'n_estimators': 25}, 'config_hash': {'algorithm': '1aae0f1fce5cab293ffdd4581c4838c8051ac815', 'config': '6c8a721218e7c550a98c5ba72ad9ff86afd5e3a4', 'pipeline': '77189452469cef9c840643f2babe0f825c6667c8'}, 'duration': 0.3951280117034912, 'iteration': 18, 'loss': 0.1804760061919506, 'max_history_score': 0.9888888888888889, 'max_history_score_std': 0.022222222222222233, 'max_history_step': 'joint', 'pipeline': {'features': ('features_SelectKBest', {'features__k': 2}), 'normalizer': ('normalizer_NoneType', {}), 'rebalance': ('rebalance_NearMiss', {'rebalance__n_neighbors': 1})}, 'score': 0.8195239938080494, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': None, 'max_features': 3, 'max_leaf_nodes': 5, 'min_samples_split': 3, 'n_estimators': 50}, 'config_hash': {'algorithm': '0129970b8c7fe034ac8283fb518a06cfbead63d2', 'config': '61bcd2f64860b3dfe2503be88a6bbec165db0754', 'pipeline': '359f2473075ecfd9ae3ce526da96143918517601'}, 'duration': 0.7467091083526611, 'iteration': 19, 'loss': 0.09915720674234607, 'max_history_score': 0.9888888888888889, 'max_history_score_std': 0.022222222222222233, 'max_history_step': 'joint', 'pipeline': {'features': ('features_SelectKBest', {'features__k': 3}), 'normalizer': ('normalizer_RobustScaler', {'normalizer__quantile_range': (...), 'normalizer__with_centering': True, 'normalizer__with_scaling': False}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 7})}, 'score': 0.9008427932576539, ...}, ...], 'history_hash': ['2e6648b63441361b4398cb94f81d2e04a830b2ef', '584343bc020d2d7bc89bd0856bc7770dae1c84fc', 'de121d053e65def047cc8947f505578d5c5eab67', 'b21c9d15a389baa5bfea4c8ddcec129259f37540', 'edd3456355d80775739c31515c832ca7b4e5e094', '0800d7d2c8c10d2f9e7b4e5127b343e916eb742c', 'd98b641879b4754f2169335626a90575e945fd7c', '3f83df36a6abbdf7ea4a4bdcaf6727f23529c2bb', '037fd5c655b39cc7922fb394d736496befcc747b', '6609280032189b59de1afbe36f3acb1d5c273693', '8e1c17ac9f6e03740f380fccb833c9c3931ffc35', '87c03d0cb8e8500e58cacc1a0f27ce54c41a2937', '2ab964abffa0a277a9e2ee9b5570cd258e428b62', '5c95db3ad238063227f1b36e6a006d70c834c5da', '50fd1169b8e42190600f25152654254b5d0e3ed1', 'a05b6d2ffd65d4d937c0b178655d857bf4d61410', 'ebebb7a93116f14f470e062e37582a59f4aeb0df', 'a2c21314ddbba47ddbfe416e0aa14853a71179e0', '6c8a721218e7c550a98c5ba72ad9ff86afd5e3a4', '61bcd2f64860b3dfe2503be88a6bbec165db0754', ...], 'history_index': {'0018716ad6e0edc096329f31492734a67d79d3b3': 64, '01c777816cea234a1e6b73501020cf6f05ea69b9': 111, '020ec4a49249e6e129cbf2800d975e6e1c8842aa': 92, '037fd5c655b39cc7922fb394d736496befcc747b': 8, '0393a0da80adcc0e64c60f266b4277ec0e84ea81': 141, '0414a55701bd4c21bd4e55ad37a0576c56d56b3f': 94, '0650ac92dace31c01ac743925565b952112a5c82': 78, '07fdf9d0d0248a4b0215a633c75a2dd101dcf465': 22, '0800d7d2c8c10d2f9e7b4e5127b343e916eb742c': 5, '09cf55372e045d42fd53684507ba9d24737bdcec': 87, ...}, 'iteration': 177, 'max_history_score': 1.0, 'max_history_score_std': 0.0, 'max_history_step': 'joint'}
        config = {'algorithm': 'RandomForest', 'seed': 42, 'time': 300}
    114 
    115 
    116 def get_baseline_score(algorithm, X, y, seed):
    117     pipeline, _ = pipeline_conf_to_full_pipeline(

...........................................................................
/home/aquemy/dev/dp_hyperparameters/extension/experiment/objective.py in objective(pipeline_config={'features': ('features_PCA', {'features__n_components': 1}), 'normalizer': ('normalizer_MinMaxScaler', {}), 'rebalance': ('rebalance_NoneType', {})}, algo_config={'bootstrap': False, 'criterion': 'gini', 'max_depth': 1, 'max_features': 2, 'max_leaf_nodes': None, 'min_samples_split': 5, 'n_estimators': 50}, algorithm='RandomForest', X=array([[1.423e+01, 1.710e+00, 2.430e+00, ..., 1...., ..., 6.100e-01, 1.600e+00,
        5.600e+02]]), y=array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,
       2, 2]), context={'baseline_score': 0.9444100447196423, 'baseline_score_std': 0.04305547117084885, 'best_config': {'algorithm': {'bootstrap': False, 'criterion': 'gini', 'max_depth': 1, 'max_features': 1, 'max_leaf_nodes': 3, 'min_samples_split': 2, 'n_estimators': 50}, 'config_hash': {'algorithm': '41bdc0fd26679e3e9de3f47a81dcebdeb54f6274', 'config': '0ada0978fbb60b78d813177773f684a809a8f7c8', 'pipeline': 'aaf976c7c663a31fa039582d42f9e07101556a7c'}, 'duration': 0.6971359252929688, 'iteration': 62, 'loss': 0.0, 'max_history_score': 1.0, 'max_history_score_std': 0.0, 'max_history_step': 'joint', 'pipeline': {'features': ('features_NoneType', {}), 'normalizer': ('normalizer_PowerTransformer', {}), 'rebalance': ('rebalance_NoneType', {})}, 'score': 1.0, ...}, 'history': [{'algorithm': {'bootstrap': False, 'criterion': 'entropy', 'max_depth': None, 'max_features': 3, 'max_leaf_nodes': 5, 'min_samples_split': 2, 'n_estimators': 50}, 'config_hash': {'algorithm': 'b2c6464add7a35ce8048653a39338c9994de9a4f', 'config': '2e6648b63441361b4398cb94f81d2e04a830b2ef', 'pipeline': '3d44d7482e468d08c4f94457a205f3dac74084c1'}, 'duration': 0.737678050994873, 'iteration': 0, 'loss': 1.0, 'max_history_score': 0.0, 'max_history_score_std': 0.0, 'max_history_step': 'baseline', 'pipeline': {'features': ('features_PCA', {'features__n_components': 1}), 'normalizer': ('normalizer_NoneType', {}), 'rebalance': ('rebalance_CondensedNearestNeighbour', {'rebalance__n_neighbors': 3})}, 'score': 0.0, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'gini', 'max_depth': 1, 'max_features': None, 'max_leaf_nodes': 2, 'min_samples_split': 3, 'n_estimators': 25}, 'config_hash': {'algorithm': '7f71bbbfdb4e8da52b6fc33a43224183117de15e', 'config': '584343bc020d2d7bc89bd0856bc7770dae1c84fc', 'pipeline': '466ffa7ace0e442beb7c311eb214b17a4c6832b3'}, 'duration': 1.5976769924163818, 'iteration': 1, 'loss': 0.40386351909184726, 'max_history_score': 0.5961364809081527, 'max_history_score_std': 0.05351463210025494, 'max_history_step': 'joint', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 3, 'features__selectkbest__k': 3}), 'normalizer': ('normalizer_StandardScaler', {'normalizer__with_mean': True, 'normalizer__with_std': True}), 'rebalance': ('rebalance_NearMiss', {'rebalance__n_neighbors': 2})}, 'score': 0.5961364809081527, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'entropy', 'max_depth': 1, 'max_features': 2, 'max_leaf_nodes': 2, 'min_samples_split': 5, 'n_estimators': 25}, 'config_hash': {'algorithm': '897745a20d929d43e760cacee0a764bd8070daa5', 'config': 'de121d053e65def047cc8947f505578d5c5eab67', 'pipeline': '63040b39b48626a8232e847e8327bdca5cd88611'}, 'duration': 0.815453052520752, 'iteration': 2, 'loss': 0.07327786377708967, 'max_history_score': 0.9267221362229103, 'max_history_score_std': 0.043920207373658794, 'max_history_step': 'joint', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 3, 'features__selectkbest__k': 2}), 'normalizer': ('normalizer_StandardScaler', {'normalizer__with_mean': True, 'normalizer__with_std': True}), 'rebalance': ('rebalance_NoneType', {})}, 'score': 0.9267221362229103, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'entropy', 'max_depth': 4, 'max_features': 3, 'max_leaf_nodes': None, 'min_samples_split': 2, 'n_estimators': 100}, 'config_hash': {'algorithm': 'dbd92c75280ec06b66ca4ad9b135cf36957031a4', 'config': 'b21c9d15a389baa5bfea4c8ddcec129259f37540', 'pipeline': '38866720d2f120c863351493b9b4e23b9a4506dc'}, 'duration': 1.2293269634246826, 'iteration': 3, 'loss': 0.07199862401100798, 'max_history_score': 0.928001375988992, 'max_history_score_std': 0.06518367535896959, 'max_history_step': 'joint', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 2, 'features__selectkbest__k': 4}), 'normalizer': ('normalizer_NoneType', {}), 'rebalance': ('rebalance_NoneType', {})}, 'score': 0.928001375988992, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': 2, 'max_features': None, 'max_leaf_nodes': None, 'min_samples_split': 5, 'n_estimators': 100}, 'config_hash': {'algorithm': 'f455eefd9fdd03ece88892c3f440c580bdf27ddb', 'config': 'edd3456355d80775739c31515c832ca7b4e5e094', 'pipeline': '1d1034f9f0871e43f896c1db4ed6fd572ed0a6ef'}, 'duration': 1.6186630725860596, 'iteration': 4, 'loss': 0.16651831785345705, 'max_history_score': 0.928001375988992, 'max_history_score_std': 0.06518367535896959, 'max_history_step': 'joint', 'pipeline': {'features': ('features_SelectKBest', {'features__k': 4}), 'normalizer': ('normalizer_MinMaxScaler', {}), 'rebalance': ('rebalance_CondensedNearestNeighbour', {'rebalance__n_neighbors': 1})}, 'score': 0.833481682146543, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'entropy', 'max_depth': 1, 'max_features': 2, 'max_leaf_nodes': None, 'min_samples_split': 2, 'n_estimators': 10}, 'config_hash': {'algorithm': '29906eaa0712a68ea145b12821d54ba445726fbf', 'config': '0800d7d2c8c10d2f9e7b4e5127b343e916eb742c', 'pipeline': '2e0f188ae61600352a7159285e0f542b4587a403'}, 'duration': 0.19410085678100586, 'iteration': 5, 'loss': 0.20164258685930514, 'max_history_score': 0.928001375988992, 'max_history_score_std': 0.06518367535896959, 'max_history_step': 'joint', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 3, 'features__selectkbest__k': 4}), 'normalizer': ('normalizer_StandardScaler', {'normalizer__with_mean': True, 'normalizer__with_std': False}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 7})}, 'score': 0.7983574131406949, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': 1, 'max_features': 1, 'max_leaf_nodes': 5, 'min_samples_split': 2, 'n_estimators': 25}, 'config_hash': {'algorithm': 'fbb7d57e38cfc08240f0af985282da418cb33556', 'config': 'd98b641879b4754f2169335626a90575e945fd7c', 'pipeline': '62463de065924498cdcd2f2f1f7e68535cdb33a5'}, 'duration': 0.3625810146331787, 'iteration': 6, 'loss': 0.14327485380116955, 'max_history_score': 0.928001375988992, 'max_history_score_std': 0.06518367535896959, 'max_history_step': 'joint', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 1, 'features__selectkbest__k': 2}), 'normalizer': ('normalizer_NoneType', {}), 'rebalance': ('rebalance_NoneType', {})}, 'score': 0.8567251461988304, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'entropy', 'max_depth': 3, 'max_features': 1, 'max_leaf_nodes': None, 'min_samples_split': 2, 'n_estimators': 75}, 'config_hash': {'algorithm': 'fb2f5d4c4d636edac929e1454ce3d02a4fb134c1', 'config': '3f83df36a6abbdf7ea4a4bdcaf6727f23529c2bb', 'pipeline': '8377b93e334656d1a93d266493b58ef9a6a1786f'}, 'duration': 0.8223779201507568, 'iteration': 7, 'loss': 0.03921568627450989, 'max_history_score': 0.9607843137254901, 'max_history_score_std': 0.043526663832084804, 'max_history_step': 'joint', 'pipeline': {'features': ('features_PCA', {'features__n_components': 3}), 'normalizer': ('normalizer_MinMaxScaler', {}), 'rebalance': ('rebalance_NearMiss', {'rebalance__n_neighbors': 1})}, 'score': 0.9607843137254901, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'gini', 'max_depth': 3, 'max_features': 3, 'max_leaf_nodes': 2, 'min_samples_split': 2, 'n_estimators': 100}, 'config_hash': {'algorithm': '3c3fde6559b918694de4668d025d5418342db1b1', 'config': '037fd5c655b39cc7922fb394d736496befcc747b', 'pipeline': '2a5032814c6c7ed21dd5bd9686923d7fc2f8acc9'}, 'duration': 1.0435099601745605, 'iteration': 8, 'loss': 0.09955925352597172, 'max_history_score': 0.9607843137254901, 'max_history_score_std': 0.043526663832084804, 'max_history_step': 'joint', 'pipeline': {'features': ('features_NoneType', {}), 'normalizer': ('normalizer_RobustScaler', {'normalizer__quantile_range': (...), 'normalizer__with_centering': True, 'normalizer__with_scaling': True}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 7})}, 'score': 0.9004407464740283, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': 2, 'max_features': 1, 'max_leaf_nodes': None, 'min_samples_split': 3, 'n_estimators': 75}, 'config_hash': {'algorithm': '42185be98371e99ac896d2c6c2d69c451cb983ff', 'config': '6609280032189b59de1afbe36f3acb1d5c273693', 'pipeline': '8aab2941fc84d84f86fa56134e50909dbf9e19f5'}, 'duration': 0.9665219783782959, 'iteration': 9, 'loss': 0.01637426900584804, 'max_history_score': 0.983625730994152, 'max_history_score_std': 0.025023500462379746, 'max_history_step': 'joint', 'pipeline': {'features': ('features_NoneType', {}), 'normalizer': ('normalizer_PowerTransformer', {}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 5})}, 'score': 0.983625730994152, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': 1, 'max_features': 3, 'max_leaf_nodes': 2, 'min_samples_split': 3, 'n_estimators': 10}, 'config_hash': {'algorithm': '62a9fe705e4cd96e762bcc9543c4a456a5a9f188', 'config': '8e1c17ac9f6e03740f380fccb833c9c3931ffc35', 'pipeline': '3d44d7482e468d08c4f94457a205f3dac74084c1'}, 'duration': 0.46930503845214844, 'iteration': 10, 'loss': 1.0, 'max_history_score': 0.983625730994152, 'max_history_score_std': 0.025023500462379746, 'max_history_step': 'joint', 'pipeline': {'features': ('features_PCA', {'features__n_components': 1}), 'normalizer': ('normalizer_NoneType', {}), 'rebalance': ('rebalance_CondensedNearestNeighbour', {'rebalance__n_neighbors': 3})}, 'score': 0.0, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'gini', 'max_depth': 4, 'max_features': 1, 'max_leaf_nodes': 3, 'min_samples_split': 2, 'n_estimators': 100}, 'config_hash': {'algorithm': '086d6ca939a757bb32edb113a567f9d38744f061', 'config': '87c03d0cb8e8500e58cacc1a0f27ce54c41a2937', 'pipeline': '8f28ef0f35d97142278f9dacb4e9d1ff082e470f'}, 'duration': 2.1196961402893066, 'iteration': 11, 'loss': 0.15471276229790154, 'max_history_score': 0.983625730994152, 'max_history_score_std': 0.025023500462379746, 'max_history_step': 'joint', 'pipeline': {'features': ('features_PCA', {'features__n_components': 1}), 'normalizer': ('normalizer_StandardScaler', {'normalizer__with_mean': True, 'normalizer__with_std': True}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 7})}, 'score': 0.8452872377020985, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'entropy', 'max_depth': 3, 'max_features': 1, 'max_leaf_nodes': 2, 'min_samples_split': 2, 'n_estimators': 25}, 'config_hash': {'algorithm': '59f64a966796648c7bebade1127fa05541b391ad', 'config': '2ab964abffa0a277a9e2ee9b5570cd258e428b62', 'pipeline': 'eef3f702fd2fed761fa6744c1640d0bf320f1d00'}, 'duration': 0.9828321933746338, 'iteration': 12, 'loss': 0.0778465772273822, 'max_history_score': 0.983625730994152, 'max_history_score_std': 0.025023500462379746, 'max_history_step': 'joint', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 3, 'features__selectkbest__k': 1}), 'normalizer': ('normalizer_PowerTransformer', {}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 6})}, 'score': 0.9221534227726178, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'gini', 'max_depth': 4, 'max_features': 2, 'max_leaf_nodes': 3, 'min_samples_split': 3, 'n_estimators': 75}, 'config_hash': {'algorithm': '6f75c2a196eb9836df2b424e095051192eaed6ea', 'config': '5c95db3ad238063227f1b36e6a006d70c834c5da', 'pipeline': '1eae01a1128bee425c4d4ca0ee97a9afd409680e'}, 'duration': 0.8217771053314209, 'iteration': 13, 'loss': 0.03863089095287242, 'max_history_score': 0.983625730994152, 'max_history_score_std': 0.025023500462379746, 'max_history_step': 'joint', 'pipeline': {'features': ('features_NoneType', {}), 'normalizer': ('normalizer_StandardScaler', {'normalizer__with_mean': False, 'normalizer__with_std': False}), 'rebalance': ('rebalance_NearMiss', {'rebalance__n_neighbors': 1})}, 'score': 0.9613691090471276, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'entropy', 'max_depth': 4, 'max_features': 2, 'max_leaf_nodes': 3, 'min_samples_split': 2, 'n_estimators': 25}, 'config_hash': {'algorithm': '8aef3174f6b8020de06b825e0424c1e54d690afd', 'config': '50fd1169b8e42190600f25152654254b5d0e3ed1', 'pipeline': '9ceaa544911dc6c687e336cb8e9dd4d15ff1ceaf'}, 'duration': 0.40307188034057617, 'iteration': 14, 'loss': 1.0, 'max_history_score': 0.983625730994152, 'max_history_score_std': 0.025023500462379746, 'max_history_step': 'joint', 'pipeline': {'features': ('features_PCA', {'features__n_components': 1}), 'normalizer': ('normalizer_RobustScaler', {'normalizer__quantile_range': (...), 'normalizer__with_centering': False, 'normalizer__with_scaling': False}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 7})}, 'score': 0.0, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'gini', 'max_depth': 1, 'max_features': 1, 'max_leaf_nodes': 3, 'min_samples_split': 3, 'n_estimators': 50}, 'config_hash': {'algorithm': '37be8b6737f4b5d5ae35da51886f302b07ba6001', 'config': 'a05b6d2ffd65d4d937c0b178655d857bf4d61410', 'pipeline': 'cfef88e895db321122f2f7b813d9267b973c2468'}, 'duration': 1.7094659805297852, 'iteration': 15, 'loss': 0.011111111111111072, 'max_history_score': 0.9888888888888889, 'max_history_score_std': 0.022222222222222233, 'max_history_step': 'joint', 'pipeline': {'features': ('features_NoneType', {}), 'normalizer': ('normalizer_NoneType', {}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 5})}, 'score': 0.9888888888888889, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'entropy', 'max_depth': None, 'max_features': 3, 'max_leaf_nodes': None, 'min_samples_split': 2, 'n_estimators': 100}, 'config_hash': {'algorithm': 'c40543ce91793e367c1892c886bc49621c22ecfb', 'config': 'ebebb7a93116f14f470e062e37582a59f4aeb0df', 'pipeline': 'b50c63e800574e8b760f55f7c4ff1fcae8816dd8'}, 'duration': 0.6425540447235107, 'iteration': 16, 'loss': 1.0, 'max_history_score': 0.9888888888888889, 'max_history_score_std': 0.022222222222222233, 'max_history_step': 'joint', 'pipeline': {'features': ('features_PCA', {'features__n_components': 1}), 'normalizer': ('normalizer_PowerTransformer', {}), 'rebalance': ('rebalance_NearMiss', {'rebalance__n_neighbors': 1})}, 'score': 0.0, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'gini', 'max_depth': None, 'max_features': 1, 'max_leaf_nodes': 3, 'min_samples_split': 2, 'n_estimators': 50}, 'config_hash': {'algorithm': '0c69b9601237c20664085fa05764d855e28f98f7', 'config': 'a2c21314ddbba47ddbfe416e0aa14853a71179e0', 'pipeline': '914f81fa4fbb61db251201f32bd8ea11bfeea2a5'}, 'duration': 2.2209739685058594, 'iteration': 17, 'loss': 0.3206720846233231, 'max_history_score': 0.9888888888888889, 'max_history_score_std': 0.022222222222222233, 'max_history_step': 'joint', 'pipeline': {'features': ('features_SelectKBest', {'features__k': 4}), 'normalizer': ('normalizer_PowerTransformer', {}), 'rebalance': ('rebalance_CondensedNearestNeighbour', {'rebalance__n_neighbors': 1})}, 'score': 0.6793279153766769, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': 4, 'max_features': None, 'max_leaf_nodes': None, 'min_samples_split': 3, 'n_estimators': 25}, 'config_hash': {'algorithm': '1aae0f1fce5cab293ffdd4581c4838c8051ac815', 'config': '6c8a721218e7c550a98c5ba72ad9ff86afd5e3a4', 'pipeline': '77189452469cef9c840643f2babe0f825c6667c8'}, 'duration': 0.3951280117034912, 'iteration': 18, 'loss': 0.1804760061919506, 'max_history_score': 0.9888888888888889, 'max_history_score_std': 0.022222222222222233, 'max_history_step': 'joint', 'pipeline': {'features': ('features_SelectKBest', {'features__k': 2}), 'normalizer': ('normalizer_NoneType', {}), 'rebalance': ('rebalance_NearMiss', {'rebalance__n_neighbors': 1})}, 'score': 0.8195239938080494, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': None, 'max_features': 3, 'max_leaf_nodes': 5, 'min_samples_split': 3, 'n_estimators': 50}, 'config_hash': {'algorithm': '0129970b8c7fe034ac8283fb518a06cfbead63d2', 'config': '61bcd2f64860b3dfe2503be88a6bbec165db0754', 'pipeline': '359f2473075ecfd9ae3ce526da96143918517601'}, 'duration': 0.7467091083526611, 'iteration': 19, 'loss': 0.09915720674234607, 'max_history_score': 0.9888888888888889, 'max_history_score_std': 0.022222222222222233, 'max_history_step': 'joint', 'pipeline': {'features': ('features_SelectKBest', {'features__k': 3}), 'normalizer': ('normalizer_RobustScaler', {'normalizer__quantile_range': (...), 'normalizer__with_centering': True, 'normalizer__with_scaling': False}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 7})}, 'score': 0.9008427932576539, ...}, ...], 'history_hash': ['2e6648b63441361b4398cb94f81d2e04a830b2ef', '584343bc020d2d7bc89bd0856bc7770dae1c84fc', 'de121d053e65def047cc8947f505578d5c5eab67', 'b21c9d15a389baa5bfea4c8ddcec129259f37540', 'edd3456355d80775739c31515c832ca7b4e5e094', '0800d7d2c8c10d2f9e7b4e5127b343e916eb742c', 'd98b641879b4754f2169335626a90575e945fd7c', '3f83df36a6abbdf7ea4a4bdcaf6727f23529c2bb', '037fd5c655b39cc7922fb394d736496befcc747b', '6609280032189b59de1afbe36f3acb1d5c273693', '8e1c17ac9f6e03740f380fccb833c9c3931ffc35', '87c03d0cb8e8500e58cacc1a0f27ce54c41a2937', '2ab964abffa0a277a9e2ee9b5570cd258e428b62', '5c95db3ad238063227f1b36e6a006d70c834c5da', '50fd1169b8e42190600f25152654254b5d0e3ed1', 'a05b6d2ffd65d4d937c0b178655d857bf4d61410', 'ebebb7a93116f14f470e062e37582a59f4aeb0df', 'a2c21314ddbba47ddbfe416e0aa14853a71179e0', '6c8a721218e7c550a98c5ba72ad9ff86afd5e3a4', '61bcd2f64860b3dfe2503be88a6bbec165db0754', ...], 'history_index': {'0018716ad6e0edc096329f31492734a67d79d3b3': 64, '01c777816cea234a1e6b73501020cf6f05ea69b9': 111, '020ec4a49249e6e129cbf2800d975e6e1c8842aa': 92, '037fd5c655b39cc7922fb394d736496befcc747b': 8, '0393a0da80adcc0e64c60f266b4277ec0e84ea81': 141, '0414a55701bd4c21bd4e55ad37a0576c56d56b3f': 94, '0650ac92dace31c01ac743925565b952112a5c82': 78, '07fdf9d0d0248a4b0215a633c75a2dd101dcf465': 22, '0800d7d2c8c10d2f9e7b4e5127b343e916eb742c': 5, '09cf55372e045d42fd53684507ba9d24737bdcec': 87, ...}, 'iteration': 177, 'max_history_score': 1.0, 'max_history_score_std': 0.0, 'max_history_step': 'joint'}, config={'algorithm': 'RandomForest', 'seed': 42, 'time': 300}, step='joint')
     45                 y,
     46                 cv=10,
     47                 n_jobs=-1,
     48                 return_estimator=False,
     49                 return_train_score=False,
---> 50                 verbose=0)
     51         score = np.mean(scores['test_score'])
     52         std = np.std(scores['test_score'])
     53         status = STATUS_OK
     54     except Exception as e:

...........................................................................
/home/aquemy/.local/lib/python2.7/site-packages/sklearn/model_selection/_validation.py in cross_validate(estimator=Pipeline(memory=None,
     steps=[('normalizer',... random_state=42, verbose=0, warm_start=False))]), X=array([[1.423e+01, 1.710e+00, 2.430e+00, ..., 1...., ..., 6.100e-01, 1.600e+00,
        5.600e+02]]), y=array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,
       2, 2]), groups=None, scoring=None, cv=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1, verbose=0, fit_params=None, pre_dispatch='2*n_jobs', return_train_score=False, return_estimator=False, error_score='raise-deprecating')
    235         delayed(_fit_and_score)(
    236             clone(estimator), X, y, scorers, train, test, verbose, None,
    237             fit_params, return_train_score=return_train_score,
    238             return_times=True, return_estimator=return_estimator,
    239             error_score=error_score)
--> 240         for train, test in cv.split(X, y, groups))
        cv.split = <bound method StratifiedKFold.split of Stratifie...d(n_splits=10, random_state=None, shuffle=False)>
        X = array([[1.423e+01, 1.710e+00, 2.430e+00, ..., 1...., ..., 6.100e-01, 1.600e+00,
        5.600e+02]])
        y = array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,
       2, 2])
        groups = None
    241 
    242     zipped_scores = list(zip(*scores))
    243     if return_train_score:
    244         train_scores = zipped_scores.pop(0)

...........................................................................
/home/aquemy/.local/lib/python2.7/site-packages/sklearn/externals/joblib/parallel.py in __call__(self=Parallel(n_jobs=-1), iterable=<generator object <genexpr>>)
    925                 # No need to wait for async callbacks to trigger to
    926                 # consumption.
    927                 self._iterating = False
    928 
    929             with self._backend.retrieval_context():
--> 930                 self.retrieve()
        self.retrieve = <bound method Parallel.retrieve of Parallel(n_jobs=-1)>
    931             # Make sure that we get a last message telling us we are done
    932             elapsed_time = time.time() - self._start_time
    933             self._print('Done %3i out of %3i | elapsed: %s finished',
    934                         (len(self._output), len(self._output),

---------------------------------------------------------------------------
Joblib worker traceback:
---------------------------------------------------------------------------
ValueError                                         Mon Jun 17 12:47:59 2019
PID: 15569                                  Python 2.7.15+: /usr/bin/python
...........................................................................
/home/aquemy/.local/lib/python2.7/site-packages/sklearn/externals/joblib/parallel.py in __call__(self=<sklearn.externals.joblib.parallel.BatchedCalls object>)
    220     def __call__(self):
    221         # Set the default nested backend to self._backend but do not set the
    222         # change the default number of processes to -1
    223         with parallel_backend(self._backend, n_jobs=self._n_jobs):
    224             return [func(*args, **kwargs)
--> 225                     for func, args, kwargs in self.items]
        func = <function _fit_and_score>
        args = (Pipeline(memory=None,
     steps=[('normalizer',... random_state=42, verbose=0, warm_start=False))]), array([[1.423e+01, 1.710e+00, 2.430e+00, ..., 1...., ..., 6.100e-01, 1.600e+00,
        5.600e+02]]), array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,
       2, 2]), {'score': <function _passthrough_scorer>}, array([  6,   7,   8,   9,  10,  11,  12,  13,  ..., 170, 171, 172, 173, 174,
       175, 176, 177]), array([  0,   1,   2,   3,   4,   5,  59,  60,  ...,  64,  65,
        66, 130, 131, 132, 133, 134]), 0, None, None)
        kwargs = {'error_score': 'raise-deprecating', 'return_estimator': False, 'return_times': True, 'return_train_score': False}
        self.items = [(<function _fit_and_score>, (Pipeline(memory=None,
     steps=[('normalizer',... random_state=42, verbose=0, warm_start=False))]), array([[1.423e+01, 1.710e+00, 2.430e+00, ..., 1...., ..., 6.100e-01, 1.600e+00,
        5.600e+02]]), array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,
       2, 2]), {'score': <function _passthrough_scorer>}, array([  6,   7,   8,   9,  10,  11,  12,  13,  ..., 170, 171, 172, 173, 174,
       175, 176, 177]), array([  0,   1,   2,   3,   4,   5,  59,  60,  ...,  64,  65,
        66, 130, 131, 132, 133, 134]), 0, None, None), {'error_score': 'raise-deprecating', 'return_estimator': False, 'return_times': True, 'return_train_score': False})]
    226 
    227     def __len__(self):
    228         return self._size
    229 

...........................................................................
/home/aquemy/.local/lib/python2.7/site-packages/sklearn/model_selection/_validation.py in _fit_and_score(estimator=Pipeline(memory=None,
     steps=[('normalizer',... random_state=42, verbose=0, warm_start=False))]), X=array([[1.423e+01, 1.710e+00, 2.430e+00, ..., 1...., ..., 6.100e-01, 1.600e+00,
        5.600e+02]]), y=array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,
       2, 2]), scorer={'score': <function _passthrough_scorer>}, train=array([  6,   7,   8,   9,  10,  11,  12,  13,  ..., 170, 171, 172, 173, 174,
       175, 176, 177]), test=array([  0,   1,   2,   3,   4,   5,  59,  60,  ...,  64,  65,
        66, 130, 131, 132, 133, 134]), verbose=0, parameters=None, fit_params={}, return_train_score=False, return_parameters=False, return_n_test_samples=False, return_times=True, return_estimator=False, error_score='raise-deprecating')
    523 
    524     try:
    525         if y_train is None:
    526             estimator.fit(X_train, **fit_params)
    527         else:
--> 528             estimator.fit(X_train, y_train, **fit_params)
        estimator.fit = <bound method Pipeline.fit of Pipeline(memory=No...random_state=42, verbose=0, warm_start=False))])>
        X_train = array([[1.439e+01, 1.870e+00, 2.450e+00, ..., 1...., ..., 6.100e-01, 1.600e+00,
        5.600e+02]])
        y_train = array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...2, 2, 2, 2, 2, 2, 2, 2, 2,
       2, 2, 2, 2, 2])
        fit_params = {}
    529 
    530     except Exception as e:
    531         # Note fit time as time until error
    532         fit_time = time.time() - start_time

...........................................................................
/usr/local/lib/python2.7/dist-packages/imblearn/pipeline.py in fit(self=Pipeline(memory=None,
     steps=[('normalizer',... random_state=42, verbose=0, warm_start=False))]), X=array([[1.439e+01, 1.870e+00, 2.450e+00, ..., 1...., ..., 6.100e-01, 1.600e+00,
        5.600e+02]]), y=array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...2, 2, 2, 2, 2, 2, 2, 2, 2,
       2, 2, 2, 2, 2]), **fit_params={})
    234             This estimator
    235 
    236         """
    237         Xt, yt, fit_params = self._fit(X, y, **fit_params)
    238         if self._final_estimator is not None:
--> 239             self._final_estimator.fit(Xt, yt, **fit_params)
        self._final_estimator.fit = <bound method RandomForestClassifier.fit of Rand...e, random_state=42, verbose=0, warm_start=False)>
        Xt = array([[-5.34359176e-01],
       [-4.64738753e-0...    [ 5.86525179e-01],
       [ 7.39234465e-01]])
        yt = array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...2, 2, 2, 2, 2, 2, 2, 2, 2,
       2, 2, 2, 2, 2])
        fit_params = {}
    240         return self
    241 
    242     def fit_transform(self, X, y=None, **fit_params):
    243         """Fit the model and transform with the final estimator

...........................................................................
/home/aquemy/.local/lib/python2.7/site-packages/sklearn/ensemble/forest.py in fit(self=RandomForestClassifier(bootstrap=False, class_we...se, random_state=42, verbose=0, warm_start=False), X=array([[-5.34359157e-01],
       [-4.64738756e-0...2e-01],
       [ 7.39234447e-01]], dtype=float32), y=array([[0.],
       [0.],
       [0.],
       [0...    [2.],
       [2.],
       [2.],
       [2.]]), sample_weight=None)
    328             trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,
    329                              **_joblib_parallel_args(prefer='threads'))(
    330                 delayed(_parallel_build_trees)(
    331                     t, self, X, y, sample_weight, i, len(trees),
    332                     verbose=self.verbose, class_weight=self.class_weight)
--> 333                 for i, t in enumerate(trees))
        i = 49
    334 
    335             # Collect newly grown trees
    336             self.estimators_.extend(trees)
    337 

...........................................................................
/home/aquemy/.local/lib/python2.7/site-packages/sklearn/externals/joblib/parallel.py in __call__(self=Parallel(n_jobs=1), iterable=<generator object <genexpr>>)
    912             # self._original_iterator is None, then this means either
    913             # that pre_dispatch == "all", n_jobs == 1 or that the first batch
    914             # was very quick and its callback already dispatched all the
    915             # remaining jobs.
    916             self._iterating = False
--> 917             if self.dispatch_one_batch(iterator):
        self.dispatch_one_batch = <bound method Parallel.dispatch_one_batch of Parallel(n_jobs=1)>
        iterator = <generator object <genexpr>>
    918                 self._iterating = self._original_iterator is not None
    919 
    920             while self.dispatch_one_batch(iterator):
    921                 pass

...........................................................................
/home/aquemy/.local/lib/python2.7/site-packages/sklearn/externals/joblib/parallel.py in dispatch_one_batch(self=Parallel(n_jobs=1), iterator=<generator object <genexpr>>)
    754                                  self._pickle_cache)
    755             if len(tasks) == 0:
    756                 # No more tasks available in the iterator: tell caller to stop.
    757                 return False
    758             else:
--> 759                 self._dispatch(tasks)
        self._dispatch = <bound method Parallel._dispatch of Parallel(n_jobs=1)>
        tasks = <sklearn.externals.joblib.parallel.BatchedCalls object>
    760                 return True
    761 
    762     def _print(self, msg, msg_args):
    763         """Display the message on stout or stderr depending on verbosity"""

...........................................................................
/home/aquemy/.local/lib/python2.7/site-packages/sklearn/externals/joblib/parallel.py in _dispatch(self=Parallel(n_jobs=1), batch=<sklearn.externals.joblib.parallel.BatchedCalls object>)
    711 
    712         dispatch_timestamp = time.time()
    713         cb = BatchCompletionCallBack(dispatch_timestamp, len(batch), self)
    714         with self._lock:
    715             job_idx = len(self._jobs)
--> 716             job = self._backend.apply_async(batch, callback=cb)
        job = undefined
        self._backend.apply_async = <bound method SequentialBackend.apply_async of <...lib._parallel_backends.SequentialBackend object>>
        batch = <sklearn.externals.joblib.parallel.BatchedCalls object>
        cb = <sklearn.externals.joblib.parallel.BatchCompletionCallBack object>
    717             # A job can complete so quickly than its callback is
    718             # called before we get here, causing self._jobs to
    719             # grow. To ensure correct results ordering, .insert is
    720             # used (rather than .append) in the following line

...........................................................................
/home/aquemy/.local/lib/python2.7/site-packages/sklearn/externals/joblib/_parallel_backends.py in apply_async(self=<sklearn.externals.joblib._parallel_backends.SequentialBackend object>, func=<sklearn.externals.joblib.parallel.BatchedCalls object>, callback=<sklearn.externals.joblib.parallel.BatchCompletionCallBack object>)
    177             raise ValueError('n_jobs == 0 in Parallel has no meaning')
    178         return 1
    179 
    180     def apply_async(self, func, callback=None):
    181         """Schedule a func to be run"""
--> 182         result = ImmediateResult(func)
        result = undefined
        func = <sklearn.externals.joblib.parallel.BatchedCalls object>
    183         if callback:
    184             callback(result)
    185         return result
    186 

...........................................................................
/home/aquemy/.local/lib/python2.7/site-packages/sklearn/externals/joblib/_parallel_backends.py in __init__(self=<sklearn.externals.joblib._parallel_backends.ImmediateResult object>, batch=<sklearn.externals.joblib.parallel.BatchedCalls object>)
    544 
    545 class ImmediateResult(object):
    546     def __init__(self, batch):
    547         # Don't delay the application, to avoid keeping the input
    548         # arguments in memory
--> 549         self.results = batch()
        self.results = undefined
        batch = <sklearn.externals.joblib.parallel.BatchedCalls object>
    550 
    551     def get(self):
    552         return self.results
    553 

...........................................................................
/home/aquemy/.local/lib/python2.7/site-packages/sklearn/externals/joblib/parallel.py in __call__(self=<sklearn.externals.joblib.parallel.BatchedCalls object>)
    220     def __call__(self):
    221         # Set the default nested backend to self._backend but do not set the
    222         # change the default number of processes to -1
    223         with parallel_backend(self._backend, n_jobs=self._n_jobs):
    224             return [func(*args, **kwargs)
--> 225                     for func, args, kwargs in self.items]
        func = <function _parallel_build_trees>
        args = (DecisionTreeClassifier(class_weight=None, criter...=False, random_state=1608637542, splitter='best'), RandomForestClassifier(bootstrap=False, class_we...se, random_state=42, verbose=0, warm_start=False), array([[-5.34359157e-01],
       [-4.64738756e-0...2e-01],
       [ 7.39234447e-01]], dtype=float32), array([[0.],
       [0.],
       [0.],
       [0...    [2.],
       [2.],
       [2.],
       [2.]]), None, 0, 50)
        kwargs = {'class_weight': None, 'verbose': 0}
        self.items = [(<function _parallel_build_trees>, (DecisionTreeClassifier(class_weight=None, criter...=False, random_state=1608637542, splitter='best'), RandomForestClassifier(bootstrap=False, class_we...se, random_state=42, verbose=0, warm_start=False), array([[-5.34359157e-01],
       [-4.64738756e-0...2e-01],
       [ 7.39234447e-01]], dtype=float32), array([[0.],
       [0.],
       [0.],
       [0...    [2.],
       [2.],
       [2.],
       [2.]]), None, 0, 50), {'class_weight': None, 'verbose': 0})]
    226 
    227     def __len__(self):
    228         return self._size
    229 

...........................................................................
/home/aquemy/.local/lib/python2.7/site-packages/sklearn/ensemble/forest.py in _parallel_build_trees(tree=DecisionTreeClassifier(class_weight=None, criter...=False, random_state=1608637542, splitter='best'), forest=RandomForestClassifier(bootstrap=False, class_we...se, random_state=42, verbose=0, warm_start=False), X=array([[-5.34359157e-01],
       [-4.64738756e-0...2e-01],
       [ 7.39234447e-01]], dtype=float32), y=array([[0.],
       [0.],
       [0.],
       [0...    [2.],
       [2.],
       [2.],
       [2.]]), sample_weight=None, tree_idx=0, n_trees=50, verbose=0, class_weight=None)
    116         elif class_weight == 'balanced_subsample':
    117             curr_sample_weight *= compute_sample_weight('balanced', y, indices)
    118 
    119         tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)
    120     else:
--> 121         tree.fit(X, y, sample_weight=sample_weight, check_input=False)
        tree.fit = <bound method DecisionTreeClassifier.fit of Deci...False, random_state=1608637542, splitter='best')>
        X = array([[-5.34359157e-01],
       [-4.64738756e-0...2e-01],
       [ 7.39234447e-01]], dtype=float32)
        y = array([[0.],
       [0.],
       [0.],
       [0...    [2.],
       [2.],
       [2.],
       [2.]])
        sample_weight = None
    122 
    123     return tree
    124 
    125 

...........................................................................
/home/aquemy/.local/lib/python2.7/site-packages/sklearn/tree/tree.py in fit(self=DecisionTreeClassifier(class_weight=None, criter...=False, random_state=1608637542, splitter='best'), X=array([[-5.34359157e-01],
       [-4.64738756e-0...2e-01],
       [ 7.39234447e-01]], dtype=float32), y=array([[0.],
       [0.],
       [0.],
       [0...    [2.],
       [2.],
       [2.],
       [2.]]), sample_weight=None, check_input=False, X_idx_sorted=None)
    796 
    797         super(DecisionTreeClassifier, self).fit(
    798             X, y,
    799             sample_weight=sample_weight,
    800             check_input=check_input,
--> 801             X_idx_sorted=X_idx_sorted)
        X_idx_sorted = None
    802         return self
    803 
    804     def predict_proba(self, X, check_input=True):
    805         """Predict class probabilities of the input samples X.

...........................................................................
/home/aquemy/.local/lib/python2.7/site-packages/sklearn/tree/tree.py in fit(self=DecisionTreeClassifier(class_weight=None, criter...=False, random_state=1608637542, splitter='best'), X=array([[-5.34359157e-01],
       [-4.64738756e-0...2e-01],
       [ 7.39234447e-01]], dtype=float32), y=array([[0.],
       [0.],
       [0.],
       [0...    [2.],
       [2.],
       [2.],
       [2.]]), sample_weight=None, check_input=False, X_idx_sorted=None)
    237         if not 0 <= self.min_weight_fraction_leaf <= 0.5:
    238             raise ValueError("min_weight_fraction_leaf must in [0, 0.5]")
    239         if max_depth <= 0:
    240             raise ValueError("max_depth must be greater than zero. ")
    241         if not (0 < max_features <= self.n_features_):
--> 242             raise ValueError("max_features must be in (0, n_features]")
    243         if not isinstance(max_leaf_nodes, (numbers.Integral, np.integer)):
    244             raise ValueError("max_leaf_nodes must be integral number but was "
    245                              "%r" % max_leaf_nodes)
    246         if -1 < max_leaf_nodes < 2:

ValueError: max_features must be in (0, n_features]
___________________________________________________________________________
Best score: 1.0 (0.0) [J] | Score: 0.0 (0.0) [J]
Best score: 1.0 (0.0) [J] | Score: 0.994444444444 (0.0166666666667) [J]
Best score: 1.0 (0.0) [J] | Score: 0.944117647059 (0.0555642054012) [J]
Best score: 1.0 (0.0) [J] | Score: 0.922480220158 (0.0662974737036) [J]
Best score: 1.0 (0.0) [J] | Score: 0.977743378053 (0.0369085322417) [J]
Best score: 1.0 (0.0) [J] | Score: 0.889731682147 (0.0844110457376) [J]
Best score: 1.0 (0.0) [J] | Score: 0.966924664603 (0.0358608716643) [J]
Best score: 1.0 (0.0) [J] | Score: 0.961076711386 (0.0356160146865) [J]
Best score: 1.0 (0.0) [J] | Score: 0.740466976264 (0.114900159659) [J]
Best score: 1.0 (0.0) [J] | Score: 0.770730134159 (0.0960974499677) [J]
Best score: 1.0 (0.0) [J] | Score: 0.584079377365 (0.0347070625992) [J]
Best score: 1.0 (0.0) [J] | Score: 0.866086171311 (0.109547276014) [J]
Best score: 1.0 (0.0) [J] | Score: 0.994444444444 (0.0166666666667) [J]
Best score: 1.0 (0.0) [J] | Score: 0.966230220158 (0.0363533344041) [J]
Best score: 1.0 (0.0) [J] | Score: 0.866086171311 (0.0523578687761) [J]
Best score: 1.0 (0.0) [J] | Score: 0.872738218094 (0.0732215515807) [J]
Best score: 1.0 (0.0) [J] | Score: 0.994444444444 (0.0166666666667) [J]
Best score: 1.0 (0.0) [J] | Score: 0.867801857585 (0.112402783917) [J]
Best score: 1.0 (0.0) [J] | Score: 0.934176126591 (0.0712390415734) [J]
Best score: 1.0 (0.0) [J] | Score: 0.942945906433 (0.0733541704829) [J]
Best score: 1.0 (0.0) [J] | Score: 0.910640264878 (0.0656301145371) [J]
Best score: 1.0 (0.0) [J] | Score: 0.94470244238 (0.0603584932201) [J]
Best score: 1.0 (0.0) [J] | Score: 0.624357155143 (0.0424077515085) [J]
Best score: 1.0 (0.0) [J] | Score: 0.782168042656 (0.0927695000923) [J]
Best score: 1.0 (0.0) [J] | Score: 0.845579635363 (0.0866005402807) [J]
Best score: 1.0 (0.0) [J] | Score: 0.983006535948 (0.0259716555377) [J]
Best score: 1.0 (0.0) [J] | Score: 0.867182662539 (0.0738899282443) [J]
Best score: 1.0 (0.0) [J] | Score: 0.921056931545 (0.0712169032669) [J]
Best score: 1.0 (0.0) [J] | Score: 0.912280701754 (0.081326507912) [J]
Best score: 1.0 (0.0) [J] | Score: 0.742917956656 (0.0588598291893) [J]
Best score: 1.0 (0.0) [J] | Score: 0.994444444444 (0.0166666666667) [J]
Best score: 1.0 (0.0) [J] | Score: 0.855411506708 (0.0780340967769) [J]
Best score: 1.0 (0.0) [J] | Score: 0.988888888889 (0.0222222222222) [J]
Best score: 1.0 (0.0) [J] | Score: 0.900842793258 (0.0671855885652) [J]
Best score: 1.0 (0.0) [J] | Score: 0.892801857585 (0.104787423216) [J]
Best score: 1.0 (0.0) [J] | Score: 0.923099415205 (0.074363916884) [J]
Best score: 1.0 (0.0) [J] | Score: 0.944083247334 (0.0439257311256) [J]
Best score: 1.0 (0.0) [J] | Score: 0.910784313725 (0.0752209214387) [J]
Best score: 1.0 (0.0) [J] | Score: 0.736775455796 (0.166370693715) [J]
Best score: 1.0 (0.0) [J] | Score: 0.994444444444 (0.0166666666667) [J]
Best score: 1.0 (0.0) [J] | Score: 0.994444444444 (0.0166666666667) [J]
Best score: 1.0 (0.0) [J] | Score: 0.983006535948 (0.0359417701565) [J]
Best score: 1.0 (0.0) [J] | Score: 0.994444444444 (0.0166666666667) [J]
Best score: 1.0 (0.0) [J] | Score: 0.994444444444 (0.0166666666667) [J]
Best score: 1.0 (0.0) [J] | Score: 0.994444444444 (0.0166666666667) [J]
Best score: 1.0 (0.0) [J] | Score: 0.994444444444 (0.0166666666667) [J]
Best score: 1.0 (0.0) [J] | Score: 0.994444444444 (0.0166666666667) [J]
Best score: 1.0 (0.0) [J] | Score: 0.966632266942 (0.0368981749401) [J]
Best score: 1.0 (0.0) [J] | Score: 0.584371775026 (0.039079851289) [J]
Best score: 1.0 (0.0) [J] | Score: 0.761265909873 (0.0989371608729) [J]
Best score: 1.0 (0.0) [J] | Score: 0.694674492604 (0.114340218657) [J]
Best score: 1.0 (0.0) [J] | Score: 0.972480220158 (0.0439463721021) [J]
Best score: 1.0 (0.0) [J] | Score: 0.808739680083 (0.120331911162) [J]
Best score: 1.0 (0.0) [J] | Score: 0.994444444444 (0.0166666666667) [J]
Best score: 1.0 (0.0) [J] | Score: 0.900550395597 (0.0637179947005) [J]
Best score: 1.0 (0.0) [J] | Score: 0.978070175439 (0.0268703745951) [J]
Best score: 1.0 (0.0) [J] | Score: 0.937540849673 (0.0530267309041) [J]
Best score: 1.0 (0.0) [J] | Score: 0.870145338837 (0.079380971769) [J]
Best score: 1.0 (0.0) [J] | Score: 0.988562091503 (0.0228874853528) [J]
Best score: 1.0 (0.0) [J] | Score: 0.753442122463 (0.153366425385) [J]
Best score: 1.0 (0.0) [J] | Score: 0.988888888889 (0.0222222222222) [J]
Best score: 1.0 (0.0) [J] | Score: 0.921056931545 (0.0712169032669) [J]
Best score: 1.0 (0.0) [J] | Score: 0.851427588579 (0.0960844046443) [J]
Best score: 1.0 (0.0) [J] | Score: 0.760898262814 (0.0870710430416) [J]
Best score: 1.0 (0.0) [J] | Score: 0.983006535948 (0.0259716555377) [J]
Best score: 1.0 (0.0) [J] | Score: 0.62106123151 (0.094103857005) [J]
Best score: 1.0 (0.0) [J] | Score: 0.983625730994 (0.0250235004624) [J]
Best score: 1.0 (0.0) [J] | Score: 0.917801857585 (0.0798679624874) [J]
Best score: 1.0 (0.0) [J] | Score: 0.988888888889 (0.0222222222222) [J]
Best score: 1.0 (0.0) [J] | Score: 0.923030615755 (0.0908251188881) [J]
Best score: 1.0 (0.0) [J] | Score: 0.889370485036 (0.0840224034741) [J]
Best score: 1.0 (0.0) [J] | Score: 0.994444444444 (0.0166666666667) [J]
Best score: 1.0 (0.0) [J] | Score: 0.954534313725 (0.0419039006051) [J]
Best score: 1.0 (0.0) [J] | Score: 0.757972136223 (0.105176040867) [J]
Best score: 1.0 (0.0) [J] | Score: 0.845579635363 (0.0866005402807) [J]
Best score: 1.0 (0.0) [J] | Score: 0.994444444444 (0.0166666666667) [J]
Best score: 1.0 (0.0) [J] | Score: 0.890024079807 (0.0999566921725) [J]
Best score: 1.0 (0.0) [J] | Score: 0.994444444444 (0.0166666666667) [J]
Best score: 1.0 (0.0) [J] | Score: 0.961661506708 (0.0479080516355) [J]
Best score: 1.0 (0.0) [J] | Score: 0.834176126591 (0.11302399698) [J]
Best score: 1.0 (0.0) [J] | Score: 0.833406432749 (0.11191253086) [J]
Best score: 1.0 (0.0) [J] | Score: 0.977450980392 (0.0371587453033) [J]
Best score: 1.0 (0.0) [J] | Score: 0.654026917785 (0.0988542267556) [J]
Best score: 1.0 (0.0) [J] | Score: 0.983333333333 (0.0355729124302) [J]
Best score: 1.0 (0.0) [J] | Score: 0.792331011352 (0.119723793428) [J]
Best score: 1.0 (0.0) [J] | Score: 0.955779153767 (0.0533629133535) [J]
Best score: 1.0 (0.0) [J] | Score: 0.93816004472 (0.0579854594583) [J]
Best score: 1.0 (0.0) [J] | Score: 0.966959064327 (0.0507973090678) [J]
Best score: 1.0 (0.0) [J] | Score: 0.669891640867 (0.0712113277269) [J]
Best score: 1.0 (0.0) [J] | Score: 0.89441004472 (0.0630869499571) [J]
Best score: 1.0 (0.0) [J] | Score: 0.845579635363 (0.0866005402807) [J]
Best score: 1.0 (0.0) [J] | Score: 0.961403508772 (0.0557521912525) [J]
Best score: 1.0 (0.0) [J] | Score: 0.889731682147 (0.0879915256893) [J]
Best score: 1.0 (0.0) [J] | Score: 0.994444444444 (0.0166666666667) [J]
Best score: 1.0 (0.0) [J] | Score: 0.966230220158 (0.0363533344041) [J]
Best score: 1.0 (0.0) [J] | Score: 0.895579635363 (0.0882460710341) [J]
Best score: 1.0 (0.0) [J] | Score: 0.691419418645 (0.0476917538105) [J]
Best score: 1.0 (0.0) [J] | Score: 0.803553921569 (0.119371167774) [J]
Best score: 1.0 (0.0) [J] | Score: 0.911369109047 (0.0708404704781) [J]
Best score: 1.0 (0.0) [J] | Score: 0.808120485036 (0.0858486307058) [J]
Best score: 1.0 (0.0) [J] | Score: 0.988888888889 (0.0222222222222) [J]
Best score: 1.0 (0.0) [J] | Score: 0.961661506708 (0.0479080516355) [J]
Best score: 1.0 (0.0) [J] | Score: 0.954901960784 (0.0493626342183) [J]
Best score: 1.0 (0.0) [J] | Score: 0.845579635363 (0.102888645292) [J]
Best score: 1.0 (0.0) [J] | Score: 0.595884932921 (0.0343191266948) [J]
Best score: 1.0 (0.0) [J] | Score: 0.805301857585 (0.103639648169) [J]
Best score: 1.0 (0.0) [J] | Score: 0.933189284486 (0.0724398393665) [J]
Best score: 1.0 (0.0) [J] | Score: 0.861190660475 (0.0828456351801) [J]
JoblibValueError
___________________________________________________________________________
...........................................................................
/home/aquemy/dev/dp_hyperparameters/extension/main.py in <module>()
     27 
     28     serializer.serialize_results(scenario, policy)
     29 
     30 if __name__ == "__main__":
     31     args = cli.parse_args()
---> 32     main(args)

...........................................................................
/home/aquemy/dev/dp_hyperparameters/extension/main.py in main(args=Namespace(customize=[(['control', 'seed'], '42')...io='./scenarios/rf_wine_joint.yaml', verbosity=0))
     21         test_size=0.4, 
     22         random_state=scenario['control']['seed']
     23     )
     24 
     25     policy = policies.initiate(scenario['setup']['policy'], config)
---> 26     policy.run(X,y)
        policy.run = <bound method Joint.run of <experiment.policies.joint.Joint object>>
        X = array([[1.423e+01, 1.710e+00, 2.430e+00, ..., 1...., ..., 6.100e-01, 1.600e+00,
        5.600e+02]])
        y = array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,
       2, 2])
     27 
     28     serializer.serialize_results(scenario, policy)
     29 
     30 if __name__ == "__main__":

...........................................................................
/home/aquemy/dev/dp_hyperparameters/extension/experiment/policies/joint.py in run(self=<experiment.policies.joint.Joint object>, X=array([[1.423e+01, 1.710e+00, 2.430e+00, ..., 1...., ..., 6.100e-01, 1.600e+00,
        5.600e+02]]), y=array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,
       2, 2]))
     32             algo=tpe.suggest, 
     33             max_evals=None,
     34             max_time=self.config['time'],     
     35             trials=trials,
     36             show_progressbar=False,
---> 37             verbose=0
     38         )
     39 
     40         best_config = self.context['best_config']
     41         super(Joint, self).display_step_results(best_config)

...........................................................................
/home/aquemy/dev/dp_hyperparameters/extension/hyperopt/fmin.py in fmin(fn=<functools.partial object>, space={'algorithm': {'bootstrap': <hyperopt.pyll.base.Apply object>, 'criterion': <hyperopt.pyll.base.Apply object>, 'max_depth': <hyperopt.pyll.base.Apply object>, 'max_features': <hyperopt.pyll.base.Apply object>, 'max_leaf_nodes': <hyperopt.pyll.base.Apply object>, 'min_samples_split': <hyperopt.pyll.base.Apply object>, 'n_estimators': <hyperopt.pyll.base.Apply object>}, 'pipeline': {'features': <hyperopt.pyll.base.Apply object>, 'normalizer': <hyperopt.pyll.base.Apply object>, 'rebalance': <hyperopt.pyll.base.Apply object>}}, algo=<function suggest>, max_evals=9223372036854775807, max_time=300, trials=<hyperopt.base.Trials object>, rstate=<mtrand.RandomState object>, allow_trials_fmin=True, pass_expr_memo_ctrl=None, catch_eval_exceptions=False, verbose=0, return_argmin=True, points_to_evaluate=None, max_queue_len=1, show_progressbar=False)
    406             pass_expr_memo_ctrl=pass_expr_memo_ctrl,
    407             verbose=verbose,
    408             catch_eval_exceptions=catch_eval_exceptions,
    409             return_argmin=return_argmin,
    410             show_progressbar=show_progressbar,
--> 411             max_time=max_time
        max_time = 300
    412         )
    413 
    414     if trials is None:
    415         if points_to_evaluate is None:

...........................................................................
/home/aquemy/dev/dp_hyperparameters/extension/hyperopt/base.py in fmin(self=<hyperopt.base.Trials object>, fn=<functools.partial object>, space={'algorithm': {'bootstrap': <hyperopt.pyll.base.Apply object>, 'criterion': <hyperopt.pyll.base.Apply object>, 'max_depth': <hyperopt.pyll.base.Apply object>, 'max_features': <hyperopt.pyll.base.Apply object>, 'max_leaf_nodes': <hyperopt.pyll.base.Apply object>, 'min_samples_split': <hyperopt.pyll.base.Apply object>, 'n_estimators': <hyperopt.pyll.base.Apply object>}, 'pipeline': {'features': <hyperopt.pyll.base.Apply object>, 'normalizer': <hyperopt.pyll.base.Apply object>, 'rebalance': <hyperopt.pyll.base.Apply object>}}, algo=<function suggest>, max_evals=9223372036854775807, max_time=300, rstate=<mtrand.RandomState object>, verbose=0, pass_expr_memo_ctrl=None, catch_eval_exceptions=False, return_argmin=True, show_progressbar=False)
    636             verbose=verbose,
    637             allow_trials_fmin=False,  # -- prevent recursion
    638             pass_expr_memo_ctrl=pass_expr_memo_ctrl,
    639             catch_eval_exceptions=catch_eval_exceptions,
    640             return_argmin=return_argmin,
--> 641             show_progressbar=show_progressbar)
        show_progressbar = False
    642 
    643 
    644 def trials_from_docs(docs, validate=True, **kwargs):
    645     """Construct a Trials base class instance from a list of trials documents

...........................................................................
/home/aquemy/dev/dp_hyperparameters/extension/hyperopt/fmin.py in fmin(fn=<functools.partial object>, space={'algorithm': {'bootstrap': <hyperopt.pyll.base.Apply object>, 'criterion': <hyperopt.pyll.base.Apply object>, 'max_depth': <hyperopt.pyll.base.Apply object>, 'max_features': <hyperopt.pyll.base.Apply object>, 'max_leaf_nodes': <hyperopt.pyll.base.Apply object>, 'min_samples_split': <hyperopt.pyll.base.Apply object>, 'n_estimators': <hyperopt.pyll.base.Apply object>}, 'pipeline': {'features': <hyperopt.pyll.base.Apply object>, 'normalizer': <hyperopt.pyll.base.Apply object>, 'rebalance': <hyperopt.pyll.base.Apply object>}}, algo=<function suggest>, max_evals=9223372036854775807, max_time=300, trials=<hyperopt.base.Trials object>, rstate=<mtrand.RandomState object>, allow_trials_fmin=False, pass_expr_memo_ctrl=None, catch_eval_exceptions=False, verbose=0, return_argmin=True, points_to_evaluate=None, max_queue_len=1, show_progressbar=False)
    426                     verbose=verbose,
    427                     max_queue_len=max_queue_len,
    428                     show_progressbar=show_progressbar,
    429                     max_time=max_time)
    430     rval.catch_eval_exceptions = catch_eval_exceptions
--> 431     rval.exhaust()
        rval.exhaust = <bound method FMinIter.exhaust of <hyperopt.fmin.FMinIter object>>
    432     if return_argmin:
    433         return trials.argmin
    434     elif len(trials) > 0:
    435         # Only if there are some succesfull trail runs, return the best point in the evaluation space

...........................................................................
/home/aquemy/dev/dp_hyperparameters/extension/hyperopt/fmin.py in exhaust(self=<hyperopt.fmin.FMinIter object>)
    273             raise StopIteration()
    274         return self.trials
    275 
    276     def exhaust(self):
    277         n_done = len(self.trials)
--> 278         self.run(self.max_evals - n_done, block_until_done=self.asynchronous)
        self.run = <bound method FMinIter.run of <hyperopt.fmin.FMinIter object>>
        self.max_evals = 9223372036854775807
        n_done = 0
        self.asynchronous = False
    279         self.trials.refresh()
    280         return self
    281 
    282 

...........................................................................
/home/aquemy/dev/dp_hyperparameters/extension/hyperopt/fmin.py in run(self=<hyperopt.fmin.FMinIter object>, N=9223372036854775807, block_until_done=False)
    232                     if self.asynchronous:
    233                         # -- wait for workers to fill in the trials
    234                         time.sleep(self.poll_interval_secs)
    235                     else:
    236                         # -- loop over trials and do the jobs directly
--> 237                         self.serial_evaluate()
        self.serial_evaluate = <bound method FMinIter.serial_evaluate of <hyperopt.fmin.FMinIter object>>
    238                     try:
    239                         res = [d['result']['loss'] for d in
    240                                          self.trials.trials if
    241                                          d['result']['status'] == 'ok']

...........................................................................
/home/aquemy/dev/dp_hyperparameters/extension/hyperopt/fmin.py in serial_evaluate(self=<hyperopt.fmin.FMinIter object>, N=-1)
    138                 trial['book_time'] = now
    139                 trial['refresh_time'] = now
    140                 spec = base.spec_from_misc(trial['misc'])
    141                 ctrl = base.Ctrl(self.trials, current_trial=trial)
    142                 try:
--> 143                     result = self.domain.evaluate(spec, ctrl)
        result = undefined
        self.domain.evaluate = <bound method Domain.evaluate of <hyperopt.base.Domain object>>
        spec = {'bootstrap': 1, 'criterion': 0, 'features': 1, 'features_PCA_features__n_components': 0, 'max_depth': 3, 'max_features': 1, 'max_leaf_nodes': 2, 'min_samples_split': 0, 'n_estimators': 3, 'normalizer': 2, ...}
        ctrl = <hyperopt.base.Ctrl object>
    144                 except Exception as e:
    145                     logger.info('job exception: %s' % str(e))
    146                     trial['state'] = base.JOB_STATE_ERROR
    147                     trial['misc']['error'] = (str(type(e)), str(e))

...........................................................................
/home/aquemy/dev/dp_hyperparameters/extension/hyperopt/base.py in evaluate(self=<hyperopt.base.Domain object>, config={'bootstrap': 1, 'criterion': 0, 'features': 1, 'features_PCA_features__n_components': 0, 'max_depth': 3, 'max_features': 1, 'max_leaf_nodes': 2, 'min_samples_split': 0, 'n_estimators': 3, 'normalizer': 2, ...}, ctrl=<hyperopt.base.Ctrl object>, attach_attachments=True)
    841             #    or the normal Python part (self.fn)
    842             pyll_rval = pyll.rec_eval(
    843                 self.expr,
    844                 memo=memo,
    845                 print_node_on_error=self.rec_eval_print_node_on_error)
--> 846             rval = self.fn(pyll_rval)
        rval = undefined
        self.fn = <functools.partial object>
        pyll_rval = {'algorithm': {'bootstrap': False, 'criterion': 'gini', 'max_depth': 4, 'max_features': 2, 'max_leaf_nodes': 5, 'min_samples_split': 2, 'n_estimators': 75}, 'pipeline': {'features': ('features_PCA', {'features__n_components': 1}), 'normalizer': ('normalizer_PowerTransformer', {}), 'rebalance': ('rebalance_NoneType', {})}}
    847 
    848         if isinstance(rval, (float, int, np.number)):
    849             dict_rval = {'loss': float(rval), 'status': STATUS_OK}
    850         else:

...........................................................................
/home/aquemy/dev/dp_hyperparameters/extension/experiment/objective.py in objective_joint(wconfig={'algorithm': {'bootstrap': False, 'criterion': 'gini', 'max_depth': 4, 'max_features': 2, 'max_leaf_nodes': 5, 'min_samples_split': 2, 'n_estimators': 75}, 'pipeline': {'features': ('features_PCA', {'features__n_components': 1}), 'normalizer': ('normalizer_PowerTransformer', {}), 'rebalance': ('rebalance_NoneType', {})}}, algorithm='RandomForest', X=array([[1.423e+01, 1.710e+00, 2.430e+00, ..., 1...., ..., 6.100e-01, 1.600e+00,
        5.600e+02]]), y=array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,
       2, 2]), context={'baseline_score': 0.9444100447196423, 'baseline_score_std': 0.04305547117084885, 'best_config': {'algorithm': {'bootstrap': False, 'criterion': 'gini', 'max_depth': 1, 'max_features': 1, 'max_leaf_nodes': 3, 'min_samples_split': 2, 'n_estimators': 50}, 'config_hash': {'algorithm': '41bdc0fd26679e3e9de3f47a81dcebdeb54f6274', 'config': '0ada0978fbb60b78d813177773f684a809a8f7c8', 'pipeline': 'aaf976c7c663a31fa039582d42f9e07101556a7c'}, 'duration': 0.6971359252929688, 'iteration': 62, 'loss': 0.0, 'max_history_score': 1.0, 'max_history_score_std': 0.0, 'max_history_step': 'joint', 'pipeline': {'features': ('features_NoneType', {}), 'normalizer': ('normalizer_PowerTransformer', {}), 'rebalance': ('rebalance_NoneType', {})}, 'score': 1.0, ...}, 'history': [{'algorithm': {'bootstrap': False, 'criterion': 'entropy', 'max_depth': None, 'max_features': 3, 'max_leaf_nodes': 5, 'min_samples_split': 2, 'n_estimators': 50}, 'config_hash': {'algorithm': 'b2c6464add7a35ce8048653a39338c9994de9a4f', 'config': '2e6648b63441361b4398cb94f81d2e04a830b2ef', 'pipeline': '3d44d7482e468d08c4f94457a205f3dac74084c1'}, 'duration': 0.737678050994873, 'iteration': 0, 'loss': 1.0, 'max_history_score': 0.0, 'max_history_score_std': 0.0, 'max_history_step': 'baseline', 'pipeline': {'features': ('features_PCA', {'features__n_components': 1}), 'normalizer': ('normalizer_NoneType', {}), 'rebalance': ('rebalance_CondensedNearestNeighbour', {'rebalance__n_neighbors': 3})}, 'score': 0.0, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'gini', 'max_depth': 1, 'max_features': None, 'max_leaf_nodes': 2, 'min_samples_split': 3, 'n_estimators': 25}, 'config_hash': {'algorithm': '7f71bbbfdb4e8da52b6fc33a43224183117de15e', 'config': '584343bc020d2d7bc89bd0856bc7770dae1c84fc', 'pipeline': '466ffa7ace0e442beb7c311eb214b17a4c6832b3'}, 'duration': 1.5976769924163818, 'iteration': 1, 'loss': 0.40386351909184726, 'max_history_score': 0.5961364809081527, 'max_history_score_std': 0.05351463210025494, 'max_history_step': 'joint', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 3, 'features__selectkbest__k': 3}), 'normalizer': ('normalizer_StandardScaler', {'normalizer__with_mean': True, 'normalizer__with_std': True}), 'rebalance': ('rebalance_NearMiss', {'rebalance__n_neighbors': 2})}, 'score': 0.5961364809081527, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'entropy', 'max_depth': 1, 'max_features': 2, 'max_leaf_nodes': 2, 'min_samples_split': 5, 'n_estimators': 25}, 'config_hash': {'algorithm': '897745a20d929d43e760cacee0a764bd8070daa5', 'config': 'de121d053e65def047cc8947f505578d5c5eab67', 'pipeline': '63040b39b48626a8232e847e8327bdca5cd88611'}, 'duration': 0.815453052520752, 'iteration': 2, 'loss': 0.07327786377708967, 'max_history_score': 0.9267221362229103, 'max_history_score_std': 0.043920207373658794, 'max_history_step': 'joint', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 3, 'features__selectkbest__k': 2}), 'normalizer': ('normalizer_StandardScaler', {'normalizer__with_mean': True, 'normalizer__with_std': True}), 'rebalance': ('rebalance_NoneType', {})}, 'score': 0.9267221362229103, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'entropy', 'max_depth': 4, 'max_features': 3, 'max_leaf_nodes': None, 'min_samples_split': 2, 'n_estimators': 100}, 'config_hash': {'algorithm': 'dbd92c75280ec06b66ca4ad9b135cf36957031a4', 'config': 'b21c9d15a389baa5bfea4c8ddcec129259f37540', 'pipeline': '38866720d2f120c863351493b9b4e23b9a4506dc'}, 'duration': 1.2293269634246826, 'iteration': 3, 'loss': 0.07199862401100798, 'max_history_score': 0.928001375988992, 'max_history_score_std': 0.06518367535896959, 'max_history_step': 'joint', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 2, 'features__selectkbest__k': 4}), 'normalizer': ('normalizer_NoneType', {}), 'rebalance': ('rebalance_NoneType', {})}, 'score': 0.928001375988992, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': 2, 'max_features': None, 'max_leaf_nodes': None, 'min_samples_split': 5, 'n_estimators': 100}, 'config_hash': {'algorithm': 'f455eefd9fdd03ece88892c3f440c580bdf27ddb', 'config': 'edd3456355d80775739c31515c832ca7b4e5e094', 'pipeline': '1d1034f9f0871e43f896c1db4ed6fd572ed0a6ef'}, 'duration': 1.6186630725860596, 'iteration': 4, 'loss': 0.16651831785345705, 'max_history_score': 0.928001375988992, 'max_history_score_std': 0.06518367535896959, 'max_history_step': 'joint', 'pipeline': {'features': ('features_SelectKBest', {'features__k': 4}), 'normalizer': ('normalizer_MinMaxScaler', {}), 'rebalance': ('rebalance_CondensedNearestNeighbour', {'rebalance__n_neighbors': 1})}, 'score': 0.833481682146543, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'entropy', 'max_depth': 1, 'max_features': 2, 'max_leaf_nodes': None, 'min_samples_split': 2, 'n_estimators': 10}, 'config_hash': {'algorithm': '29906eaa0712a68ea145b12821d54ba445726fbf', 'config': '0800d7d2c8c10d2f9e7b4e5127b343e916eb742c', 'pipeline': '2e0f188ae61600352a7159285e0f542b4587a403'}, 'duration': 0.19410085678100586, 'iteration': 5, 'loss': 0.20164258685930514, 'max_history_score': 0.928001375988992, 'max_history_score_std': 0.06518367535896959, 'max_history_step': 'joint', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 3, 'features__selectkbest__k': 4}), 'normalizer': ('normalizer_StandardScaler', {'normalizer__with_mean': True, 'normalizer__with_std': False}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 7})}, 'score': 0.7983574131406949, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': 1, 'max_features': 1, 'max_leaf_nodes': 5, 'min_samples_split': 2, 'n_estimators': 25}, 'config_hash': {'algorithm': 'fbb7d57e38cfc08240f0af985282da418cb33556', 'config': 'd98b641879b4754f2169335626a90575e945fd7c', 'pipeline': '62463de065924498cdcd2f2f1f7e68535cdb33a5'}, 'duration': 0.3625810146331787, 'iteration': 6, 'loss': 0.14327485380116955, 'max_history_score': 0.928001375988992, 'max_history_score_std': 0.06518367535896959, 'max_history_step': 'joint', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 1, 'features__selectkbest__k': 2}), 'normalizer': ('normalizer_NoneType', {}), 'rebalance': ('rebalance_NoneType', {})}, 'score': 0.8567251461988304, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'entropy', 'max_depth': 3, 'max_features': 1, 'max_leaf_nodes': None, 'min_samples_split': 2, 'n_estimators': 75}, 'config_hash': {'algorithm': 'fb2f5d4c4d636edac929e1454ce3d02a4fb134c1', 'config': '3f83df36a6abbdf7ea4a4bdcaf6727f23529c2bb', 'pipeline': '8377b93e334656d1a93d266493b58ef9a6a1786f'}, 'duration': 0.8223779201507568, 'iteration': 7, 'loss': 0.03921568627450989, 'max_history_score': 0.9607843137254901, 'max_history_score_std': 0.043526663832084804, 'max_history_step': 'joint', 'pipeline': {'features': ('features_PCA', {'features__n_components': 3}), 'normalizer': ('normalizer_MinMaxScaler', {}), 'rebalance': ('rebalance_NearMiss', {'rebalance__n_neighbors': 1})}, 'score': 0.9607843137254901, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'gini', 'max_depth': 3, 'max_features': 3, 'max_leaf_nodes': 2, 'min_samples_split': 2, 'n_estimators': 100}, 'config_hash': {'algorithm': '3c3fde6559b918694de4668d025d5418342db1b1', 'config': '037fd5c655b39cc7922fb394d736496befcc747b', 'pipeline': '2a5032814c6c7ed21dd5bd9686923d7fc2f8acc9'}, 'duration': 1.0435099601745605, 'iteration': 8, 'loss': 0.09955925352597172, 'max_history_score': 0.9607843137254901, 'max_history_score_std': 0.043526663832084804, 'max_history_step': 'joint', 'pipeline': {'features': ('features_NoneType', {}), 'normalizer': ('normalizer_RobustScaler', {'normalizer__quantile_range': (...), 'normalizer__with_centering': True, 'normalizer__with_scaling': True}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 7})}, 'score': 0.9004407464740283, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': 2, 'max_features': 1, 'max_leaf_nodes': None, 'min_samples_split': 3, 'n_estimators': 75}, 'config_hash': {'algorithm': '42185be98371e99ac896d2c6c2d69c451cb983ff', 'config': '6609280032189b59de1afbe36f3acb1d5c273693', 'pipeline': '8aab2941fc84d84f86fa56134e50909dbf9e19f5'}, 'duration': 0.9665219783782959, 'iteration': 9, 'loss': 0.01637426900584804, 'max_history_score': 0.983625730994152, 'max_history_score_std': 0.025023500462379746, 'max_history_step': 'joint', 'pipeline': {'features': ('features_NoneType', {}), 'normalizer': ('normalizer_PowerTransformer', {}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 5})}, 'score': 0.983625730994152, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': 1, 'max_features': 3, 'max_leaf_nodes': 2, 'min_samples_split': 3, 'n_estimators': 10}, 'config_hash': {'algorithm': '62a9fe705e4cd96e762bcc9543c4a456a5a9f188', 'config': '8e1c17ac9f6e03740f380fccb833c9c3931ffc35', 'pipeline': '3d44d7482e468d08c4f94457a205f3dac74084c1'}, 'duration': 0.46930503845214844, 'iteration': 10, 'loss': 1.0, 'max_history_score': 0.983625730994152, 'max_history_score_std': 0.025023500462379746, 'max_history_step': 'joint', 'pipeline': {'features': ('features_PCA', {'features__n_components': 1}), 'normalizer': ('normalizer_NoneType', {}), 'rebalance': ('rebalance_CondensedNearestNeighbour', {'rebalance__n_neighbors': 3})}, 'score': 0.0, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'gini', 'max_depth': 4, 'max_features': 1, 'max_leaf_nodes': 3, 'min_samples_split': 2, 'n_estimators': 100}, 'config_hash': {'algorithm': '086d6ca939a757bb32edb113a567f9d38744f061', 'config': '87c03d0cb8e8500e58cacc1a0f27ce54c41a2937', 'pipeline': '8f28ef0f35d97142278f9dacb4e9d1ff082e470f'}, 'duration': 2.1196961402893066, 'iteration': 11, 'loss': 0.15471276229790154, 'max_history_score': 0.983625730994152, 'max_history_score_std': 0.025023500462379746, 'max_history_step': 'joint', 'pipeline': {'features': ('features_PCA', {'features__n_components': 1}), 'normalizer': ('normalizer_StandardScaler', {'normalizer__with_mean': True, 'normalizer__with_std': True}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 7})}, 'score': 0.8452872377020985, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'entropy', 'max_depth': 3, 'max_features': 1, 'max_leaf_nodes': 2, 'min_samples_split': 2, 'n_estimators': 25}, 'config_hash': {'algorithm': '59f64a966796648c7bebade1127fa05541b391ad', 'config': '2ab964abffa0a277a9e2ee9b5570cd258e428b62', 'pipeline': 'eef3f702fd2fed761fa6744c1640d0bf320f1d00'}, 'duration': 0.9828321933746338, 'iteration': 12, 'loss': 0.0778465772273822, 'max_history_score': 0.983625730994152, 'max_history_score_std': 0.025023500462379746, 'max_history_step': 'joint', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 3, 'features__selectkbest__k': 1}), 'normalizer': ('normalizer_PowerTransformer', {}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 6})}, 'score': 0.9221534227726178, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'gini', 'max_depth': 4, 'max_features': 2, 'max_leaf_nodes': 3, 'min_samples_split': 3, 'n_estimators': 75}, 'config_hash': {'algorithm': '6f75c2a196eb9836df2b424e095051192eaed6ea', 'config': '5c95db3ad238063227f1b36e6a006d70c834c5da', 'pipeline': '1eae01a1128bee425c4d4ca0ee97a9afd409680e'}, 'duration': 0.8217771053314209, 'iteration': 13, 'loss': 0.03863089095287242, 'max_history_score': 0.983625730994152, 'max_history_score_std': 0.025023500462379746, 'max_history_step': 'joint', 'pipeline': {'features': ('features_NoneType', {}), 'normalizer': ('normalizer_StandardScaler', {'normalizer__with_mean': False, 'normalizer__with_std': False}), 'rebalance': ('rebalance_NearMiss', {'rebalance__n_neighbors': 1})}, 'score': 0.9613691090471276, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'entropy', 'max_depth': 4, 'max_features': 2, 'max_leaf_nodes': 3, 'min_samples_split': 2, 'n_estimators': 25}, 'config_hash': {'algorithm': '8aef3174f6b8020de06b825e0424c1e54d690afd', 'config': '50fd1169b8e42190600f25152654254b5d0e3ed1', 'pipeline': '9ceaa544911dc6c687e336cb8e9dd4d15ff1ceaf'}, 'duration': 0.40307188034057617, 'iteration': 14, 'loss': 1.0, 'max_history_score': 0.983625730994152, 'max_history_score_std': 0.025023500462379746, 'max_history_step': 'joint', 'pipeline': {'features': ('features_PCA', {'features__n_components': 1}), 'normalizer': ('normalizer_RobustScaler', {'normalizer__quantile_range': (...), 'normalizer__with_centering': False, 'normalizer__with_scaling': False}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 7})}, 'score': 0.0, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'gini', 'max_depth': 1, 'max_features': 1, 'max_leaf_nodes': 3, 'min_samples_split': 3, 'n_estimators': 50}, 'config_hash': {'algorithm': '37be8b6737f4b5d5ae35da51886f302b07ba6001', 'config': 'a05b6d2ffd65d4d937c0b178655d857bf4d61410', 'pipeline': 'cfef88e895db321122f2f7b813d9267b973c2468'}, 'duration': 1.7094659805297852, 'iteration': 15, 'loss': 0.011111111111111072, 'max_history_score': 0.9888888888888889, 'max_history_score_std': 0.022222222222222233, 'max_history_step': 'joint', 'pipeline': {'features': ('features_NoneType', {}), 'normalizer': ('normalizer_NoneType', {}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 5})}, 'score': 0.9888888888888889, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'entropy', 'max_depth': None, 'max_features': 3, 'max_leaf_nodes': None, 'min_samples_split': 2, 'n_estimators': 100}, 'config_hash': {'algorithm': 'c40543ce91793e367c1892c886bc49621c22ecfb', 'config': 'ebebb7a93116f14f470e062e37582a59f4aeb0df', 'pipeline': 'b50c63e800574e8b760f55f7c4ff1fcae8816dd8'}, 'duration': 0.6425540447235107, 'iteration': 16, 'loss': 1.0, 'max_history_score': 0.9888888888888889, 'max_history_score_std': 0.022222222222222233, 'max_history_step': 'joint', 'pipeline': {'features': ('features_PCA', {'features__n_components': 1}), 'normalizer': ('normalizer_PowerTransformer', {}), 'rebalance': ('rebalance_NearMiss', {'rebalance__n_neighbors': 1})}, 'score': 0.0, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'gini', 'max_depth': None, 'max_features': 1, 'max_leaf_nodes': 3, 'min_samples_split': 2, 'n_estimators': 50}, 'config_hash': {'algorithm': '0c69b9601237c20664085fa05764d855e28f98f7', 'config': 'a2c21314ddbba47ddbfe416e0aa14853a71179e0', 'pipeline': '914f81fa4fbb61db251201f32bd8ea11bfeea2a5'}, 'duration': 2.2209739685058594, 'iteration': 17, 'loss': 0.3206720846233231, 'max_history_score': 0.9888888888888889, 'max_history_score_std': 0.022222222222222233, 'max_history_step': 'joint', 'pipeline': {'features': ('features_SelectKBest', {'features__k': 4}), 'normalizer': ('normalizer_PowerTransformer', {}), 'rebalance': ('rebalance_CondensedNearestNeighbour', {'rebalance__n_neighbors': 1})}, 'score': 0.6793279153766769, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': 4, 'max_features': None, 'max_leaf_nodes': None, 'min_samples_split': 3, 'n_estimators': 25}, 'config_hash': {'algorithm': '1aae0f1fce5cab293ffdd4581c4838c8051ac815', 'config': '6c8a721218e7c550a98c5ba72ad9ff86afd5e3a4', 'pipeline': '77189452469cef9c840643f2babe0f825c6667c8'}, 'duration': 0.3951280117034912, 'iteration': 18, 'loss': 0.1804760061919506, 'max_history_score': 0.9888888888888889, 'max_history_score_std': 0.022222222222222233, 'max_history_step': 'joint', 'pipeline': {'features': ('features_SelectKBest', {'features__k': 2}), 'normalizer': ('normalizer_NoneType', {}), 'rebalance': ('rebalance_NearMiss', {'rebalance__n_neighbors': 1})}, 'score': 0.8195239938080494, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': None, 'max_features': 3, 'max_leaf_nodes': 5, 'min_samples_split': 3, 'n_estimators': 50}, 'config_hash': {'algorithm': '0129970b8c7fe034ac8283fb518a06cfbead63d2', 'config': '61bcd2f64860b3dfe2503be88a6bbec165db0754', 'pipeline': '359f2473075ecfd9ae3ce526da96143918517601'}, 'duration': 0.7467091083526611, 'iteration': 19, 'loss': 0.09915720674234607, 'max_history_score': 0.9888888888888889, 'max_history_score_std': 0.022222222222222233, 'max_history_step': 'joint', 'pipeline': {'features': ('features_SelectKBest', {'features__k': 3}), 'normalizer': ('normalizer_RobustScaler', {'normalizer__quantile_range': (...), 'normalizer__with_centering': True, 'normalizer__with_scaling': False}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 7})}, 'score': 0.9008427932576539, ...}, ...], 'history_hash': ['2e6648b63441361b4398cb94f81d2e04a830b2ef', '584343bc020d2d7bc89bd0856bc7770dae1c84fc', 'de121d053e65def047cc8947f505578d5c5eab67', 'b21c9d15a389baa5bfea4c8ddcec129259f37540', 'edd3456355d80775739c31515c832ca7b4e5e094', '0800d7d2c8c10d2f9e7b4e5127b343e916eb742c', 'd98b641879b4754f2169335626a90575e945fd7c', '3f83df36a6abbdf7ea4a4bdcaf6727f23529c2bb', '037fd5c655b39cc7922fb394d736496befcc747b', '6609280032189b59de1afbe36f3acb1d5c273693', '8e1c17ac9f6e03740f380fccb833c9c3931ffc35', '87c03d0cb8e8500e58cacc1a0f27ce54c41a2937', '2ab964abffa0a277a9e2ee9b5570cd258e428b62', '5c95db3ad238063227f1b36e6a006d70c834c5da', '50fd1169b8e42190600f25152654254b5d0e3ed1', 'a05b6d2ffd65d4d937c0b178655d857bf4d61410', 'ebebb7a93116f14f470e062e37582a59f4aeb0df', 'a2c21314ddbba47ddbfe416e0aa14853a71179e0', '6c8a721218e7c550a98c5ba72ad9ff86afd5e3a4', '61bcd2f64860b3dfe2503be88a6bbec165db0754', ...], 'history_index': {'0018716ad6e0edc096329f31492734a67d79d3b3': 64, '01c777816cea234a1e6b73501020cf6f05ea69b9': 111, '01d4ea6f317be786c402492e3b997e2fbf253d6d': 225, '020ec4a49249e6e129cbf2800d975e6e1c8842aa': 92, '037fd5c655b39cc7922fb394d736496befcc747b': 8, '0393a0da80adcc0e64c60f266b4277ec0e84ea81': 141, '0414a55701bd4c21bd4e55ad37a0576c56d56b3f': 94, '0650ac92dace31c01ac743925565b952112a5c82': 78, '0792bd79797828857df8b8cca60a36fcad1451e3': 224, '07fdf9d0d0248a4b0215a633c75a2dd101dcf465': 22, ...}, 'iteration': 285, 'max_history_score': 1.0, 'max_history_score_std': 0.0, 'max_history_step': 'joint'}, config={'algorithm': 'RandomForest', 'seed': 42, 'time': 300})
    108 
    109 def objective_algo(algo_config, current_pipeline_config, algorithm, X, y, context, config):
    110     return objective(current_pipeline_config, algo_config, algorithm, X, y, context, config, step='algorithm')
    111 
    112 def objective_joint(wconfig, algorithm, X, y, context, config):
--> 113     return objective(wconfig['pipeline'], wconfig['algorithm'], algorithm, X, y, context, config, step='joint')
        wconfig = {'algorithm': {'bootstrap': False, 'criterion': 'gini', 'max_depth': 4, 'max_features': 2, 'max_leaf_nodes': 5, 'min_samples_split': 2, 'n_estimators': 75}, 'pipeline': {'features': ('features_PCA', {'features__n_components': 1}), 'normalizer': ('normalizer_PowerTransformer', {}), 'rebalance': ('rebalance_NoneType', {})}}
        algorithm = 'RandomForest'
        X = array([[1.423e+01, 1.710e+00, 2.430e+00, ..., 1...., ..., 6.100e-01, 1.600e+00,
        5.600e+02]])
        y = array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,
       2, 2])
        context = {'baseline_score': 0.9444100447196423, 'baseline_score_std': 0.04305547117084885, 'best_config': {'algorithm': {'bootstrap': False, 'criterion': 'gini', 'max_depth': 1, 'max_features': 1, 'max_leaf_nodes': 3, 'min_samples_split': 2, 'n_estimators': 50}, 'config_hash': {'algorithm': '41bdc0fd26679e3e9de3f47a81dcebdeb54f6274', 'config': '0ada0978fbb60b78d813177773f684a809a8f7c8', 'pipeline': 'aaf976c7c663a31fa039582d42f9e07101556a7c'}, 'duration': 0.6971359252929688, 'iteration': 62, 'loss': 0.0, 'max_history_score': 1.0, 'max_history_score_std': 0.0, 'max_history_step': 'joint', 'pipeline': {'features': ('features_NoneType', {}), 'normalizer': ('normalizer_PowerTransformer', {}), 'rebalance': ('rebalance_NoneType', {})}, 'score': 1.0, ...}, 'history': [{'algorithm': {'bootstrap': False, 'criterion': 'entropy', 'max_depth': None, 'max_features': 3, 'max_leaf_nodes': 5, 'min_samples_split': 2, 'n_estimators': 50}, 'config_hash': {'algorithm': 'b2c6464add7a35ce8048653a39338c9994de9a4f', 'config': '2e6648b63441361b4398cb94f81d2e04a830b2ef', 'pipeline': '3d44d7482e468d08c4f94457a205f3dac74084c1'}, 'duration': 0.737678050994873, 'iteration': 0, 'loss': 1.0, 'max_history_score': 0.0, 'max_history_score_std': 0.0, 'max_history_step': 'baseline', 'pipeline': {'features': ('features_PCA', {'features__n_components': 1}), 'normalizer': ('normalizer_NoneType', {}), 'rebalance': ('rebalance_CondensedNearestNeighbour', {'rebalance__n_neighbors': 3})}, 'score': 0.0, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'gini', 'max_depth': 1, 'max_features': None, 'max_leaf_nodes': 2, 'min_samples_split': 3, 'n_estimators': 25}, 'config_hash': {'algorithm': '7f71bbbfdb4e8da52b6fc33a43224183117de15e', 'config': '584343bc020d2d7bc89bd0856bc7770dae1c84fc', 'pipeline': '466ffa7ace0e442beb7c311eb214b17a4c6832b3'}, 'duration': 1.5976769924163818, 'iteration': 1, 'loss': 0.40386351909184726, 'max_history_score': 0.5961364809081527, 'max_history_score_std': 0.05351463210025494, 'max_history_step': 'joint', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 3, 'features__selectkbest__k': 3}), 'normalizer': ('normalizer_StandardScaler', {'normalizer__with_mean': True, 'normalizer__with_std': True}), 'rebalance': ('rebalance_NearMiss', {'rebalance__n_neighbors': 2})}, 'score': 0.5961364809081527, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'entropy', 'max_depth': 1, 'max_features': 2, 'max_leaf_nodes': 2, 'min_samples_split': 5, 'n_estimators': 25}, 'config_hash': {'algorithm': '897745a20d929d43e760cacee0a764bd8070daa5', 'config': 'de121d053e65def047cc8947f505578d5c5eab67', 'pipeline': '63040b39b48626a8232e847e8327bdca5cd88611'}, 'duration': 0.815453052520752, 'iteration': 2, 'loss': 0.07327786377708967, 'max_history_score': 0.9267221362229103, 'max_history_score_std': 0.043920207373658794, 'max_history_step': 'joint', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 3, 'features__selectkbest__k': 2}), 'normalizer': ('normalizer_StandardScaler', {'normalizer__with_mean': True, 'normalizer__with_std': True}), 'rebalance': ('rebalance_NoneType', {})}, 'score': 0.9267221362229103, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'entropy', 'max_depth': 4, 'max_features': 3, 'max_leaf_nodes': None, 'min_samples_split': 2, 'n_estimators': 100}, 'config_hash': {'algorithm': 'dbd92c75280ec06b66ca4ad9b135cf36957031a4', 'config': 'b21c9d15a389baa5bfea4c8ddcec129259f37540', 'pipeline': '38866720d2f120c863351493b9b4e23b9a4506dc'}, 'duration': 1.2293269634246826, 'iteration': 3, 'loss': 0.07199862401100798, 'max_history_score': 0.928001375988992, 'max_history_score_std': 0.06518367535896959, 'max_history_step': 'joint', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 2, 'features__selectkbest__k': 4}), 'normalizer': ('normalizer_NoneType', {}), 'rebalance': ('rebalance_NoneType', {})}, 'score': 0.928001375988992, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': 2, 'max_features': None, 'max_leaf_nodes': None, 'min_samples_split': 5, 'n_estimators': 100}, 'config_hash': {'algorithm': 'f455eefd9fdd03ece88892c3f440c580bdf27ddb', 'config': 'edd3456355d80775739c31515c832ca7b4e5e094', 'pipeline': '1d1034f9f0871e43f896c1db4ed6fd572ed0a6ef'}, 'duration': 1.6186630725860596, 'iteration': 4, 'loss': 0.16651831785345705, 'max_history_score': 0.928001375988992, 'max_history_score_std': 0.06518367535896959, 'max_history_step': 'joint', 'pipeline': {'features': ('features_SelectKBest', {'features__k': 4}), 'normalizer': ('normalizer_MinMaxScaler', {}), 'rebalance': ('rebalance_CondensedNearestNeighbour', {'rebalance__n_neighbors': 1})}, 'score': 0.833481682146543, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'entropy', 'max_depth': 1, 'max_features': 2, 'max_leaf_nodes': None, 'min_samples_split': 2, 'n_estimators': 10}, 'config_hash': {'algorithm': '29906eaa0712a68ea145b12821d54ba445726fbf', 'config': '0800d7d2c8c10d2f9e7b4e5127b343e916eb742c', 'pipeline': '2e0f188ae61600352a7159285e0f542b4587a403'}, 'duration': 0.19410085678100586, 'iteration': 5, 'loss': 0.20164258685930514, 'max_history_score': 0.928001375988992, 'max_history_score_std': 0.06518367535896959, 'max_history_step': 'joint', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 3, 'features__selectkbest__k': 4}), 'normalizer': ('normalizer_StandardScaler', {'normalizer__with_mean': True, 'normalizer__with_std': False}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 7})}, 'score': 0.7983574131406949, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': 1, 'max_features': 1, 'max_leaf_nodes': 5, 'min_samples_split': 2, 'n_estimators': 25}, 'config_hash': {'algorithm': 'fbb7d57e38cfc08240f0af985282da418cb33556', 'config': 'd98b641879b4754f2169335626a90575e945fd7c', 'pipeline': '62463de065924498cdcd2f2f1f7e68535cdb33a5'}, 'duration': 0.3625810146331787, 'iteration': 6, 'loss': 0.14327485380116955, 'max_history_score': 0.928001375988992, 'max_history_score_std': 0.06518367535896959, 'max_history_step': 'joint', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 1, 'features__selectkbest__k': 2}), 'normalizer': ('normalizer_NoneType', {}), 'rebalance': ('rebalance_NoneType', {})}, 'score': 0.8567251461988304, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'entropy', 'max_depth': 3, 'max_features': 1, 'max_leaf_nodes': None, 'min_samples_split': 2, 'n_estimators': 75}, 'config_hash': {'algorithm': 'fb2f5d4c4d636edac929e1454ce3d02a4fb134c1', 'config': '3f83df36a6abbdf7ea4a4bdcaf6727f23529c2bb', 'pipeline': '8377b93e334656d1a93d266493b58ef9a6a1786f'}, 'duration': 0.8223779201507568, 'iteration': 7, 'loss': 0.03921568627450989, 'max_history_score': 0.9607843137254901, 'max_history_score_std': 0.043526663832084804, 'max_history_step': 'joint', 'pipeline': {'features': ('features_PCA', {'features__n_components': 3}), 'normalizer': ('normalizer_MinMaxScaler', {}), 'rebalance': ('rebalance_NearMiss', {'rebalance__n_neighbors': 1})}, 'score': 0.9607843137254901, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'gini', 'max_depth': 3, 'max_features': 3, 'max_leaf_nodes': 2, 'min_samples_split': 2, 'n_estimators': 100}, 'config_hash': {'algorithm': '3c3fde6559b918694de4668d025d5418342db1b1', 'config': '037fd5c655b39cc7922fb394d736496befcc747b', 'pipeline': '2a5032814c6c7ed21dd5bd9686923d7fc2f8acc9'}, 'duration': 1.0435099601745605, 'iteration': 8, 'loss': 0.09955925352597172, 'max_history_score': 0.9607843137254901, 'max_history_score_std': 0.043526663832084804, 'max_history_step': 'joint', 'pipeline': {'features': ('features_NoneType', {}), 'normalizer': ('normalizer_RobustScaler', {'normalizer__quantile_range': (...), 'normalizer__with_centering': True, 'normalizer__with_scaling': True}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 7})}, 'score': 0.9004407464740283, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': 2, 'max_features': 1, 'max_leaf_nodes': None, 'min_samples_split': 3, 'n_estimators': 75}, 'config_hash': {'algorithm': '42185be98371e99ac896d2c6c2d69c451cb983ff', 'config': '6609280032189b59de1afbe36f3acb1d5c273693', 'pipeline': '8aab2941fc84d84f86fa56134e50909dbf9e19f5'}, 'duration': 0.9665219783782959, 'iteration': 9, 'loss': 0.01637426900584804, 'max_history_score': 0.983625730994152, 'max_history_score_std': 0.025023500462379746, 'max_history_step': 'joint', 'pipeline': {'features': ('features_NoneType', {}), 'normalizer': ('normalizer_PowerTransformer', {}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 5})}, 'score': 0.983625730994152, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': 1, 'max_features': 3, 'max_leaf_nodes': 2, 'min_samples_split': 3, 'n_estimators': 10}, 'config_hash': {'algorithm': '62a9fe705e4cd96e762bcc9543c4a456a5a9f188', 'config': '8e1c17ac9f6e03740f380fccb833c9c3931ffc35', 'pipeline': '3d44d7482e468d08c4f94457a205f3dac74084c1'}, 'duration': 0.46930503845214844, 'iteration': 10, 'loss': 1.0, 'max_history_score': 0.983625730994152, 'max_history_score_std': 0.025023500462379746, 'max_history_step': 'joint', 'pipeline': {'features': ('features_PCA', {'features__n_components': 1}), 'normalizer': ('normalizer_NoneType', {}), 'rebalance': ('rebalance_CondensedNearestNeighbour', {'rebalance__n_neighbors': 3})}, 'score': 0.0, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'gini', 'max_depth': 4, 'max_features': 1, 'max_leaf_nodes': 3, 'min_samples_split': 2, 'n_estimators': 100}, 'config_hash': {'algorithm': '086d6ca939a757bb32edb113a567f9d38744f061', 'config': '87c03d0cb8e8500e58cacc1a0f27ce54c41a2937', 'pipeline': '8f28ef0f35d97142278f9dacb4e9d1ff082e470f'}, 'duration': 2.1196961402893066, 'iteration': 11, 'loss': 0.15471276229790154, 'max_history_score': 0.983625730994152, 'max_history_score_std': 0.025023500462379746, 'max_history_step': 'joint', 'pipeline': {'features': ('features_PCA', {'features__n_components': 1}), 'normalizer': ('normalizer_StandardScaler', {'normalizer__with_mean': True, 'normalizer__with_std': True}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 7})}, 'score': 0.8452872377020985, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'entropy', 'max_depth': 3, 'max_features': 1, 'max_leaf_nodes': 2, 'min_samples_split': 2, 'n_estimators': 25}, 'config_hash': {'algorithm': '59f64a966796648c7bebade1127fa05541b391ad', 'config': '2ab964abffa0a277a9e2ee9b5570cd258e428b62', 'pipeline': 'eef3f702fd2fed761fa6744c1640d0bf320f1d00'}, 'duration': 0.9828321933746338, 'iteration': 12, 'loss': 0.0778465772273822, 'max_history_score': 0.983625730994152, 'max_history_score_std': 0.025023500462379746, 'max_history_step': 'joint', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 3, 'features__selectkbest__k': 1}), 'normalizer': ('normalizer_PowerTransformer', {}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 6})}, 'score': 0.9221534227726178, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'gini', 'max_depth': 4, 'max_features': 2, 'max_leaf_nodes': 3, 'min_samples_split': 3, 'n_estimators': 75}, 'config_hash': {'algorithm': '6f75c2a196eb9836df2b424e095051192eaed6ea', 'config': '5c95db3ad238063227f1b36e6a006d70c834c5da', 'pipeline': '1eae01a1128bee425c4d4ca0ee97a9afd409680e'}, 'duration': 0.8217771053314209, 'iteration': 13, 'loss': 0.03863089095287242, 'max_history_score': 0.983625730994152, 'max_history_score_std': 0.025023500462379746, 'max_history_step': 'joint', 'pipeline': {'features': ('features_NoneType', {}), 'normalizer': ('normalizer_StandardScaler', {'normalizer__with_mean': False, 'normalizer__with_std': False}), 'rebalance': ('rebalance_NearMiss', {'rebalance__n_neighbors': 1})}, 'score': 0.9613691090471276, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'entropy', 'max_depth': 4, 'max_features': 2, 'max_leaf_nodes': 3, 'min_samples_split': 2, 'n_estimators': 25}, 'config_hash': {'algorithm': '8aef3174f6b8020de06b825e0424c1e54d690afd', 'config': '50fd1169b8e42190600f25152654254b5d0e3ed1', 'pipeline': '9ceaa544911dc6c687e336cb8e9dd4d15ff1ceaf'}, 'duration': 0.40307188034057617, 'iteration': 14, 'loss': 1.0, 'max_history_score': 0.983625730994152, 'max_history_score_std': 0.025023500462379746, 'max_history_step': 'joint', 'pipeline': {'features': ('features_PCA', {'features__n_components': 1}), 'normalizer': ('normalizer_RobustScaler', {'normalizer__quantile_range': (...), 'normalizer__with_centering': False, 'normalizer__with_scaling': False}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 7})}, 'score': 0.0, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'gini', 'max_depth': 1, 'max_features': 1, 'max_leaf_nodes': 3, 'min_samples_split': 3, 'n_estimators': 50}, 'config_hash': {'algorithm': '37be8b6737f4b5d5ae35da51886f302b07ba6001', 'config': 'a05b6d2ffd65d4d937c0b178655d857bf4d61410', 'pipeline': 'cfef88e895db321122f2f7b813d9267b973c2468'}, 'duration': 1.7094659805297852, 'iteration': 15, 'loss': 0.011111111111111072, 'max_history_score': 0.9888888888888889, 'max_history_score_std': 0.022222222222222233, 'max_history_step': 'joint', 'pipeline': {'features': ('features_NoneType', {}), 'normalizer': ('normalizer_NoneType', {}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 5})}, 'score': 0.9888888888888889, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'entropy', 'max_depth': None, 'max_features': 3, 'max_leaf_nodes': None, 'min_samples_split': 2, 'n_estimators': 100}, 'config_hash': {'algorithm': 'c40543ce91793e367c1892c886bc49621c22ecfb', 'config': 'ebebb7a93116f14f470e062e37582a59f4aeb0df', 'pipeline': 'b50c63e800574e8b760f55f7c4ff1fcae8816dd8'}, 'duration': 0.6425540447235107, 'iteration': 16, 'loss': 1.0, 'max_history_score': 0.9888888888888889, 'max_history_score_std': 0.022222222222222233, 'max_history_step': 'joint', 'pipeline': {'features': ('features_PCA', {'features__n_components': 1}), 'normalizer': ('normalizer_PowerTransformer', {}), 'rebalance': ('rebalance_NearMiss', {'rebalance__n_neighbors': 1})}, 'score': 0.0, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'gini', 'max_depth': None, 'max_features': 1, 'max_leaf_nodes': 3, 'min_samples_split': 2, 'n_estimators': 50}, 'config_hash': {'algorithm': '0c69b9601237c20664085fa05764d855e28f98f7', 'config': 'a2c21314ddbba47ddbfe416e0aa14853a71179e0', 'pipeline': '914f81fa4fbb61db251201f32bd8ea11bfeea2a5'}, 'duration': 2.2209739685058594, 'iteration': 17, 'loss': 0.3206720846233231, 'max_history_score': 0.9888888888888889, 'max_history_score_std': 0.022222222222222233, 'max_history_step': 'joint', 'pipeline': {'features': ('features_SelectKBest', {'features__k': 4}), 'normalizer': ('normalizer_PowerTransformer', {}), 'rebalance': ('rebalance_CondensedNearestNeighbour', {'rebalance__n_neighbors': 1})}, 'score': 0.6793279153766769, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': 4, 'max_features': None, 'max_leaf_nodes': None, 'min_samples_split': 3, 'n_estimators': 25}, 'config_hash': {'algorithm': '1aae0f1fce5cab293ffdd4581c4838c8051ac815', 'config': '6c8a721218e7c550a98c5ba72ad9ff86afd5e3a4', 'pipeline': '77189452469cef9c840643f2babe0f825c6667c8'}, 'duration': 0.3951280117034912, 'iteration': 18, 'loss': 0.1804760061919506, 'max_history_score': 0.9888888888888889, 'max_history_score_std': 0.022222222222222233, 'max_history_step': 'joint', 'pipeline': {'features': ('features_SelectKBest', {'features__k': 2}), 'normalizer': ('normalizer_NoneType', {}), 'rebalance': ('rebalance_NearMiss', {'rebalance__n_neighbors': 1})}, 'score': 0.8195239938080494, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': None, 'max_features': 3, 'max_leaf_nodes': 5, 'min_samples_split': 3, 'n_estimators': 50}, 'config_hash': {'algorithm': '0129970b8c7fe034ac8283fb518a06cfbead63d2', 'config': '61bcd2f64860b3dfe2503be88a6bbec165db0754', 'pipeline': '359f2473075ecfd9ae3ce526da96143918517601'}, 'duration': 0.7467091083526611, 'iteration': 19, 'loss': 0.09915720674234607, 'max_history_score': 0.9888888888888889, 'max_history_score_std': 0.022222222222222233, 'max_history_step': 'joint', 'pipeline': {'features': ('features_SelectKBest', {'features__k': 3}), 'normalizer': ('normalizer_RobustScaler', {'normalizer__quantile_range': (...), 'normalizer__with_centering': True, 'normalizer__with_scaling': False}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 7})}, 'score': 0.9008427932576539, ...}, ...], 'history_hash': ['2e6648b63441361b4398cb94f81d2e04a830b2ef', '584343bc020d2d7bc89bd0856bc7770dae1c84fc', 'de121d053e65def047cc8947f505578d5c5eab67', 'b21c9d15a389baa5bfea4c8ddcec129259f37540', 'edd3456355d80775739c31515c832ca7b4e5e094', '0800d7d2c8c10d2f9e7b4e5127b343e916eb742c', 'd98b641879b4754f2169335626a90575e945fd7c', '3f83df36a6abbdf7ea4a4bdcaf6727f23529c2bb', '037fd5c655b39cc7922fb394d736496befcc747b', '6609280032189b59de1afbe36f3acb1d5c273693', '8e1c17ac9f6e03740f380fccb833c9c3931ffc35', '87c03d0cb8e8500e58cacc1a0f27ce54c41a2937', '2ab964abffa0a277a9e2ee9b5570cd258e428b62', '5c95db3ad238063227f1b36e6a006d70c834c5da', '50fd1169b8e42190600f25152654254b5d0e3ed1', 'a05b6d2ffd65d4d937c0b178655d857bf4d61410', 'ebebb7a93116f14f470e062e37582a59f4aeb0df', 'a2c21314ddbba47ddbfe416e0aa14853a71179e0', '6c8a721218e7c550a98c5ba72ad9ff86afd5e3a4', '61bcd2f64860b3dfe2503be88a6bbec165db0754', ...], 'history_index': {'0018716ad6e0edc096329f31492734a67d79d3b3': 64, '01c777816cea234a1e6b73501020cf6f05ea69b9': 111, '01d4ea6f317be786c402492e3b997e2fbf253d6d': 225, '020ec4a49249e6e129cbf2800d975e6e1c8842aa': 92, '037fd5c655b39cc7922fb394d736496befcc747b': 8, '0393a0da80adcc0e64c60f266b4277ec0e84ea81': 141, '0414a55701bd4c21bd4e55ad37a0576c56d56b3f': 94, '0650ac92dace31c01ac743925565b952112a5c82': 78, '0792bd79797828857df8b8cca60a36fcad1451e3': 224, '07fdf9d0d0248a4b0215a633c75a2dd101dcf465': 22, ...}, 'iteration': 285, 'max_history_score': 1.0, 'max_history_score_std': 0.0, 'max_history_step': 'joint'}
        config = {'algorithm': 'RandomForest', 'seed': 42, 'time': 300}
    114 
    115 
    116 def get_baseline_score(algorithm, X, y, seed):
    117     pipeline, _ = pipeline_conf_to_full_pipeline(

...........................................................................
/home/aquemy/dev/dp_hyperparameters/extension/experiment/objective.py in objective(pipeline_config={'features': ('features_PCA', {'features__n_components': 1}), 'normalizer': ('normalizer_PowerTransformer', {}), 'rebalance': ('rebalance_NoneType', {})}, algo_config={'bootstrap': False, 'criterion': 'gini', 'max_depth': 4, 'max_features': 2, 'max_leaf_nodes': 5, 'min_samples_split': 2, 'n_estimators': 75}, algorithm='RandomForest', X=array([[1.423e+01, 1.710e+00, 2.430e+00, ..., 1...., ..., 6.100e-01, 1.600e+00,
        5.600e+02]]), y=array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,
       2, 2]), context={'baseline_score': 0.9444100447196423, 'baseline_score_std': 0.04305547117084885, 'best_config': {'algorithm': {'bootstrap': False, 'criterion': 'gini', 'max_depth': 1, 'max_features': 1, 'max_leaf_nodes': 3, 'min_samples_split': 2, 'n_estimators': 50}, 'config_hash': {'algorithm': '41bdc0fd26679e3e9de3f47a81dcebdeb54f6274', 'config': '0ada0978fbb60b78d813177773f684a809a8f7c8', 'pipeline': 'aaf976c7c663a31fa039582d42f9e07101556a7c'}, 'duration': 0.6971359252929688, 'iteration': 62, 'loss': 0.0, 'max_history_score': 1.0, 'max_history_score_std': 0.0, 'max_history_step': 'joint', 'pipeline': {'features': ('features_NoneType', {}), 'normalizer': ('normalizer_PowerTransformer', {}), 'rebalance': ('rebalance_NoneType', {})}, 'score': 1.0, ...}, 'history': [{'algorithm': {'bootstrap': False, 'criterion': 'entropy', 'max_depth': None, 'max_features': 3, 'max_leaf_nodes': 5, 'min_samples_split': 2, 'n_estimators': 50}, 'config_hash': {'algorithm': 'b2c6464add7a35ce8048653a39338c9994de9a4f', 'config': '2e6648b63441361b4398cb94f81d2e04a830b2ef', 'pipeline': '3d44d7482e468d08c4f94457a205f3dac74084c1'}, 'duration': 0.737678050994873, 'iteration': 0, 'loss': 1.0, 'max_history_score': 0.0, 'max_history_score_std': 0.0, 'max_history_step': 'baseline', 'pipeline': {'features': ('features_PCA', {'features__n_components': 1}), 'normalizer': ('normalizer_NoneType', {}), 'rebalance': ('rebalance_CondensedNearestNeighbour', {'rebalance__n_neighbors': 3})}, 'score': 0.0, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'gini', 'max_depth': 1, 'max_features': None, 'max_leaf_nodes': 2, 'min_samples_split': 3, 'n_estimators': 25}, 'config_hash': {'algorithm': '7f71bbbfdb4e8da52b6fc33a43224183117de15e', 'config': '584343bc020d2d7bc89bd0856bc7770dae1c84fc', 'pipeline': '466ffa7ace0e442beb7c311eb214b17a4c6832b3'}, 'duration': 1.5976769924163818, 'iteration': 1, 'loss': 0.40386351909184726, 'max_history_score': 0.5961364809081527, 'max_history_score_std': 0.05351463210025494, 'max_history_step': 'joint', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 3, 'features__selectkbest__k': 3}), 'normalizer': ('normalizer_StandardScaler', {'normalizer__with_mean': True, 'normalizer__with_std': True}), 'rebalance': ('rebalance_NearMiss', {'rebalance__n_neighbors': 2})}, 'score': 0.5961364809081527, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'entropy', 'max_depth': 1, 'max_features': 2, 'max_leaf_nodes': 2, 'min_samples_split': 5, 'n_estimators': 25}, 'config_hash': {'algorithm': '897745a20d929d43e760cacee0a764bd8070daa5', 'config': 'de121d053e65def047cc8947f505578d5c5eab67', 'pipeline': '63040b39b48626a8232e847e8327bdca5cd88611'}, 'duration': 0.815453052520752, 'iteration': 2, 'loss': 0.07327786377708967, 'max_history_score': 0.9267221362229103, 'max_history_score_std': 0.043920207373658794, 'max_history_step': 'joint', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 3, 'features__selectkbest__k': 2}), 'normalizer': ('normalizer_StandardScaler', {'normalizer__with_mean': True, 'normalizer__with_std': True}), 'rebalance': ('rebalance_NoneType', {})}, 'score': 0.9267221362229103, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'entropy', 'max_depth': 4, 'max_features': 3, 'max_leaf_nodes': None, 'min_samples_split': 2, 'n_estimators': 100}, 'config_hash': {'algorithm': 'dbd92c75280ec06b66ca4ad9b135cf36957031a4', 'config': 'b21c9d15a389baa5bfea4c8ddcec129259f37540', 'pipeline': '38866720d2f120c863351493b9b4e23b9a4506dc'}, 'duration': 1.2293269634246826, 'iteration': 3, 'loss': 0.07199862401100798, 'max_history_score': 0.928001375988992, 'max_history_score_std': 0.06518367535896959, 'max_history_step': 'joint', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 2, 'features__selectkbest__k': 4}), 'normalizer': ('normalizer_NoneType', {}), 'rebalance': ('rebalance_NoneType', {})}, 'score': 0.928001375988992, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': 2, 'max_features': None, 'max_leaf_nodes': None, 'min_samples_split': 5, 'n_estimators': 100}, 'config_hash': {'algorithm': 'f455eefd9fdd03ece88892c3f440c580bdf27ddb', 'config': 'edd3456355d80775739c31515c832ca7b4e5e094', 'pipeline': '1d1034f9f0871e43f896c1db4ed6fd572ed0a6ef'}, 'duration': 1.6186630725860596, 'iteration': 4, 'loss': 0.16651831785345705, 'max_history_score': 0.928001375988992, 'max_history_score_std': 0.06518367535896959, 'max_history_step': 'joint', 'pipeline': {'features': ('features_SelectKBest', {'features__k': 4}), 'normalizer': ('normalizer_MinMaxScaler', {}), 'rebalance': ('rebalance_CondensedNearestNeighbour', {'rebalance__n_neighbors': 1})}, 'score': 0.833481682146543, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'entropy', 'max_depth': 1, 'max_features': 2, 'max_leaf_nodes': None, 'min_samples_split': 2, 'n_estimators': 10}, 'config_hash': {'algorithm': '29906eaa0712a68ea145b12821d54ba445726fbf', 'config': '0800d7d2c8c10d2f9e7b4e5127b343e916eb742c', 'pipeline': '2e0f188ae61600352a7159285e0f542b4587a403'}, 'duration': 0.19410085678100586, 'iteration': 5, 'loss': 0.20164258685930514, 'max_history_score': 0.928001375988992, 'max_history_score_std': 0.06518367535896959, 'max_history_step': 'joint', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 3, 'features__selectkbest__k': 4}), 'normalizer': ('normalizer_StandardScaler', {'normalizer__with_mean': True, 'normalizer__with_std': False}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 7})}, 'score': 0.7983574131406949, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': 1, 'max_features': 1, 'max_leaf_nodes': 5, 'min_samples_split': 2, 'n_estimators': 25}, 'config_hash': {'algorithm': 'fbb7d57e38cfc08240f0af985282da418cb33556', 'config': 'd98b641879b4754f2169335626a90575e945fd7c', 'pipeline': '62463de065924498cdcd2f2f1f7e68535cdb33a5'}, 'duration': 0.3625810146331787, 'iteration': 6, 'loss': 0.14327485380116955, 'max_history_score': 0.928001375988992, 'max_history_score_std': 0.06518367535896959, 'max_history_step': 'joint', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 1, 'features__selectkbest__k': 2}), 'normalizer': ('normalizer_NoneType', {}), 'rebalance': ('rebalance_NoneType', {})}, 'score': 0.8567251461988304, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'entropy', 'max_depth': 3, 'max_features': 1, 'max_leaf_nodes': None, 'min_samples_split': 2, 'n_estimators': 75}, 'config_hash': {'algorithm': 'fb2f5d4c4d636edac929e1454ce3d02a4fb134c1', 'config': '3f83df36a6abbdf7ea4a4bdcaf6727f23529c2bb', 'pipeline': '8377b93e334656d1a93d266493b58ef9a6a1786f'}, 'duration': 0.8223779201507568, 'iteration': 7, 'loss': 0.03921568627450989, 'max_history_score': 0.9607843137254901, 'max_history_score_std': 0.043526663832084804, 'max_history_step': 'joint', 'pipeline': {'features': ('features_PCA', {'features__n_components': 3}), 'normalizer': ('normalizer_MinMaxScaler', {}), 'rebalance': ('rebalance_NearMiss', {'rebalance__n_neighbors': 1})}, 'score': 0.9607843137254901, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'gini', 'max_depth': 3, 'max_features': 3, 'max_leaf_nodes': 2, 'min_samples_split': 2, 'n_estimators': 100}, 'config_hash': {'algorithm': '3c3fde6559b918694de4668d025d5418342db1b1', 'config': '037fd5c655b39cc7922fb394d736496befcc747b', 'pipeline': '2a5032814c6c7ed21dd5bd9686923d7fc2f8acc9'}, 'duration': 1.0435099601745605, 'iteration': 8, 'loss': 0.09955925352597172, 'max_history_score': 0.9607843137254901, 'max_history_score_std': 0.043526663832084804, 'max_history_step': 'joint', 'pipeline': {'features': ('features_NoneType', {}), 'normalizer': ('normalizer_RobustScaler', {'normalizer__quantile_range': (...), 'normalizer__with_centering': True, 'normalizer__with_scaling': True}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 7})}, 'score': 0.9004407464740283, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': 2, 'max_features': 1, 'max_leaf_nodes': None, 'min_samples_split': 3, 'n_estimators': 75}, 'config_hash': {'algorithm': '42185be98371e99ac896d2c6c2d69c451cb983ff', 'config': '6609280032189b59de1afbe36f3acb1d5c273693', 'pipeline': '8aab2941fc84d84f86fa56134e50909dbf9e19f5'}, 'duration': 0.9665219783782959, 'iteration': 9, 'loss': 0.01637426900584804, 'max_history_score': 0.983625730994152, 'max_history_score_std': 0.025023500462379746, 'max_history_step': 'joint', 'pipeline': {'features': ('features_NoneType', {}), 'normalizer': ('normalizer_PowerTransformer', {}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 5})}, 'score': 0.983625730994152, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': 1, 'max_features': 3, 'max_leaf_nodes': 2, 'min_samples_split': 3, 'n_estimators': 10}, 'config_hash': {'algorithm': '62a9fe705e4cd96e762bcc9543c4a456a5a9f188', 'config': '8e1c17ac9f6e03740f380fccb833c9c3931ffc35', 'pipeline': '3d44d7482e468d08c4f94457a205f3dac74084c1'}, 'duration': 0.46930503845214844, 'iteration': 10, 'loss': 1.0, 'max_history_score': 0.983625730994152, 'max_history_score_std': 0.025023500462379746, 'max_history_step': 'joint', 'pipeline': {'features': ('features_PCA', {'features__n_components': 1}), 'normalizer': ('normalizer_NoneType', {}), 'rebalance': ('rebalance_CondensedNearestNeighbour', {'rebalance__n_neighbors': 3})}, 'score': 0.0, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'gini', 'max_depth': 4, 'max_features': 1, 'max_leaf_nodes': 3, 'min_samples_split': 2, 'n_estimators': 100}, 'config_hash': {'algorithm': '086d6ca939a757bb32edb113a567f9d38744f061', 'config': '87c03d0cb8e8500e58cacc1a0f27ce54c41a2937', 'pipeline': '8f28ef0f35d97142278f9dacb4e9d1ff082e470f'}, 'duration': 2.1196961402893066, 'iteration': 11, 'loss': 0.15471276229790154, 'max_history_score': 0.983625730994152, 'max_history_score_std': 0.025023500462379746, 'max_history_step': 'joint', 'pipeline': {'features': ('features_PCA', {'features__n_components': 1}), 'normalizer': ('normalizer_StandardScaler', {'normalizer__with_mean': True, 'normalizer__with_std': True}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 7})}, 'score': 0.8452872377020985, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'entropy', 'max_depth': 3, 'max_features': 1, 'max_leaf_nodes': 2, 'min_samples_split': 2, 'n_estimators': 25}, 'config_hash': {'algorithm': '59f64a966796648c7bebade1127fa05541b391ad', 'config': '2ab964abffa0a277a9e2ee9b5570cd258e428b62', 'pipeline': 'eef3f702fd2fed761fa6744c1640d0bf320f1d00'}, 'duration': 0.9828321933746338, 'iteration': 12, 'loss': 0.0778465772273822, 'max_history_score': 0.983625730994152, 'max_history_score_std': 0.025023500462379746, 'max_history_step': 'joint', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 3, 'features__selectkbest__k': 1}), 'normalizer': ('normalizer_PowerTransformer', {}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 6})}, 'score': 0.9221534227726178, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'gini', 'max_depth': 4, 'max_features': 2, 'max_leaf_nodes': 3, 'min_samples_split': 3, 'n_estimators': 75}, 'config_hash': {'algorithm': '6f75c2a196eb9836df2b424e095051192eaed6ea', 'config': '5c95db3ad238063227f1b36e6a006d70c834c5da', 'pipeline': '1eae01a1128bee425c4d4ca0ee97a9afd409680e'}, 'duration': 0.8217771053314209, 'iteration': 13, 'loss': 0.03863089095287242, 'max_history_score': 0.983625730994152, 'max_history_score_std': 0.025023500462379746, 'max_history_step': 'joint', 'pipeline': {'features': ('features_NoneType', {}), 'normalizer': ('normalizer_StandardScaler', {'normalizer__with_mean': False, 'normalizer__with_std': False}), 'rebalance': ('rebalance_NearMiss', {'rebalance__n_neighbors': 1})}, 'score': 0.9613691090471276, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'entropy', 'max_depth': 4, 'max_features': 2, 'max_leaf_nodes': 3, 'min_samples_split': 2, 'n_estimators': 25}, 'config_hash': {'algorithm': '8aef3174f6b8020de06b825e0424c1e54d690afd', 'config': '50fd1169b8e42190600f25152654254b5d0e3ed1', 'pipeline': '9ceaa544911dc6c687e336cb8e9dd4d15ff1ceaf'}, 'duration': 0.40307188034057617, 'iteration': 14, 'loss': 1.0, 'max_history_score': 0.983625730994152, 'max_history_score_std': 0.025023500462379746, 'max_history_step': 'joint', 'pipeline': {'features': ('features_PCA', {'features__n_components': 1}), 'normalizer': ('normalizer_RobustScaler', {'normalizer__quantile_range': (...), 'normalizer__with_centering': False, 'normalizer__with_scaling': False}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 7})}, 'score': 0.0, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'gini', 'max_depth': 1, 'max_features': 1, 'max_leaf_nodes': 3, 'min_samples_split': 3, 'n_estimators': 50}, 'config_hash': {'algorithm': '37be8b6737f4b5d5ae35da51886f302b07ba6001', 'config': 'a05b6d2ffd65d4d937c0b178655d857bf4d61410', 'pipeline': 'cfef88e895db321122f2f7b813d9267b973c2468'}, 'duration': 1.7094659805297852, 'iteration': 15, 'loss': 0.011111111111111072, 'max_history_score': 0.9888888888888889, 'max_history_score_std': 0.022222222222222233, 'max_history_step': 'joint', 'pipeline': {'features': ('features_NoneType', {}), 'normalizer': ('normalizer_NoneType', {}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 5})}, 'score': 0.9888888888888889, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'entropy', 'max_depth': None, 'max_features': 3, 'max_leaf_nodes': None, 'min_samples_split': 2, 'n_estimators': 100}, 'config_hash': {'algorithm': 'c40543ce91793e367c1892c886bc49621c22ecfb', 'config': 'ebebb7a93116f14f470e062e37582a59f4aeb0df', 'pipeline': 'b50c63e800574e8b760f55f7c4ff1fcae8816dd8'}, 'duration': 0.6425540447235107, 'iteration': 16, 'loss': 1.0, 'max_history_score': 0.9888888888888889, 'max_history_score_std': 0.022222222222222233, 'max_history_step': 'joint', 'pipeline': {'features': ('features_PCA', {'features__n_components': 1}), 'normalizer': ('normalizer_PowerTransformer', {}), 'rebalance': ('rebalance_NearMiss', {'rebalance__n_neighbors': 1})}, 'score': 0.0, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'gini', 'max_depth': None, 'max_features': 1, 'max_leaf_nodes': 3, 'min_samples_split': 2, 'n_estimators': 50}, 'config_hash': {'algorithm': '0c69b9601237c20664085fa05764d855e28f98f7', 'config': 'a2c21314ddbba47ddbfe416e0aa14853a71179e0', 'pipeline': '914f81fa4fbb61db251201f32bd8ea11bfeea2a5'}, 'duration': 2.2209739685058594, 'iteration': 17, 'loss': 0.3206720846233231, 'max_history_score': 0.9888888888888889, 'max_history_score_std': 0.022222222222222233, 'max_history_step': 'joint', 'pipeline': {'features': ('features_SelectKBest', {'features__k': 4}), 'normalizer': ('normalizer_PowerTransformer', {}), 'rebalance': ('rebalance_CondensedNearestNeighbour', {'rebalance__n_neighbors': 1})}, 'score': 0.6793279153766769, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': 4, 'max_features': None, 'max_leaf_nodes': None, 'min_samples_split': 3, 'n_estimators': 25}, 'config_hash': {'algorithm': '1aae0f1fce5cab293ffdd4581c4838c8051ac815', 'config': '6c8a721218e7c550a98c5ba72ad9ff86afd5e3a4', 'pipeline': '77189452469cef9c840643f2babe0f825c6667c8'}, 'duration': 0.3951280117034912, 'iteration': 18, 'loss': 0.1804760061919506, 'max_history_score': 0.9888888888888889, 'max_history_score_std': 0.022222222222222233, 'max_history_step': 'joint', 'pipeline': {'features': ('features_SelectKBest', {'features__k': 2}), 'normalizer': ('normalizer_NoneType', {}), 'rebalance': ('rebalance_NearMiss', {'rebalance__n_neighbors': 1})}, 'score': 0.8195239938080494, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': None, 'max_features': 3, 'max_leaf_nodes': 5, 'min_samples_split': 3, 'n_estimators': 50}, 'config_hash': {'algorithm': '0129970b8c7fe034ac8283fb518a06cfbead63d2', 'config': '61bcd2f64860b3dfe2503be88a6bbec165db0754', 'pipeline': '359f2473075ecfd9ae3ce526da96143918517601'}, 'duration': 0.7467091083526611, 'iteration': 19, 'loss': 0.09915720674234607, 'max_history_score': 0.9888888888888889, 'max_history_score_std': 0.022222222222222233, 'max_history_step': 'joint', 'pipeline': {'features': ('features_SelectKBest', {'features__k': 3}), 'normalizer': ('normalizer_RobustScaler', {'normalizer__quantile_range': (...), 'normalizer__with_centering': True, 'normalizer__with_scaling': False}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 7})}, 'score': 0.9008427932576539, ...}, ...], 'history_hash': ['2e6648b63441361b4398cb94f81d2e04a830b2ef', '584343bc020d2d7bc89bd0856bc7770dae1c84fc', 'de121d053e65def047cc8947f505578d5c5eab67', 'b21c9d15a389baa5bfea4c8ddcec129259f37540', 'edd3456355d80775739c31515c832ca7b4e5e094', '0800d7d2c8c10d2f9e7b4e5127b343e916eb742c', 'd98b641879b4754f2169335626a90575e945fd7c', '3f83df36a6abbdf7ea4a4bdcaf6727f23529c2bb', '037fd5c655b39cc7922fb394d736496befcc747b', '6609280032189b59de1afbe36f3acb1d5c273693', '8e1c17ac9f6e03740f380fccb833c9c3931ffc35', '87c03d0cb8e8500e58cacc1a0f27ce54c41a2937', '2ab964abffa0a277a9e2ee9b5570cd258e428b62', '5c95db3ad238063227f1b36e6a006d70c834c5da', '50fd1169b8e42190600f25152654254b5d0e3ed1', 'a05b6d2ffd65d4d937c0b178655d857bf4d61410', 'ebebb7a93116f14f470e062e37582a59f4aeb0df', 'a2c21314ddbba47ddbfe416e0aa14853a71179e0', '6c8a721218e7c550a98c5ba72ad9ff86afd5e3a4', '61bcd2f64860b3dfe2503be88a6bbec165db0754', ...], 'history_index': {'0018716ad6e0edc096329f31492734a67d79d3b3': 64, '01c777816cea234a1e6b73501020cf6f05ea69b9': 111, '01d4ea6f317be786c402492e3b997e2fbf253d6d': 225, '020ec4a49249e6e129cbf2800d975e6e1c8842aa': 92, '037fd5c655b39cc7922fb394d736496befcc747b': 8, '0393a0da80adcc0e64c60f266b4277ec0e84ea81': 141, '0414a55701bd4c21bd4e55ad37a0576c56d56b3f': 94, '0650ac92dace31c01ac743925565b952112a5c82': 78, '0792bd79797828857df8b8cca60a36fcad1451e3': 224, '07fdf9d0d0248a4b0215a633c75a2dd101dcf465': 22, ...}, 'iteration': 285, 'max_history_score': 1.0, 'max_history_score_std': 0.0, 'max_history_step': 'joint'}, config={'algorithm': 'RandomForest', 'seed': 42, 'time': 300}, step='joint')
     45                 y,
     46                 cv=10,
     47                 n_jobs=-1,
     48                 return_estimator=False,
     49                 return_train_score=False,
---> 50                 verbose=0)
     51         score = np.mean(scores['test_score'])
     52         std = np.std(scores['test_score'])
     53         status = STATUS_OK
     54     except Exception as e:

...........................................................................
/home/aquemy/.local/lib/python2.7/site-packages/sklearn/model_selection/_validation.py in cross_validate(estimator=Pipeline(memory=None,
     steps=[('normalizer',... random_state=42, verbose=0, warm_start=False))]), X=array([[1.423e+01, 1.710e+00, 2.430e+00, ..., 1...., ..., 6.100e-01, 1.600e+00,
        5.600e+02]]), y=array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,
       2, 2]), groups=None, scoring=None, cv=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1, verbose=0, fit_params=None, pre_dispatch='2*n_jobs', return_train_score=False, return_estimator=False, error_score='raise-deprecating')
    235         delayed(_fit_and_score)(
    236             clone(estimator), X, y, scorers, train, test, verbose, None,
    237             fit_params, return_train_score=return_train_score,
    238             return_times=True, return_estimator=return_estimator,
    239             error_score=error_score)
--> 240         for train, test in cv.split(X, y, groups))
        cv.split = <bound method StratifiedKFold.split of Stratifie...d(n_splits=10, random_state=None, shuffle=False)>
        X = array([[1.423e+01, 1.710e+00, 2.430e+00, ..., 1...., ..., 6.100e-01, 1.600e+00,
        5.600e+02]])
        y = array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,
       2, 2])
        groups = None
    241 
    242     zipped_scores = list(zip(*scores))
    243     if return_train_score:
    244         train_scores = zipped_scores.pop(0)

...........................................................................
/home/aquemy/.local/lib/python2.7/site-packages/sklearn/externals/joblib/parallel.py in __call__(self=Parallel(n_jobs=-1), iterable=<generator object <genexpr>>)
    925                 # No need to wait for async callbacks to trigger to
    926                 # consumption.
    927                 self._iterating = False
    928 
    929             with self._backend.retrieval_context():
--> 930                 self.retrieve()
        self.retrieve = <bound method Parallel.retrieve of Parallel(n_jobs=-1)>
    931             # Make sure that we get a last message telling us we are done
    932             elapsed_time = time.time() - self._start_time
    933             self._print('Done %3i out of %3i | elapsed: %s finished',
    934                         (len(self._output), len(self._output),

---------------------------------------------------------------------------
Joblib worker traceback:
---------------------------------------------------------------------------
ValueError                                         Mon Jun 17 12:49:32 2019
PID: 15623                                  Python 2.7.15+: /usr/bin/python
...........................................................................
/home/aquemy/.local/lib/python2.7/site-packages/sklearn/externals/joblib/parallel.py in __call__(self=<sklearn.externals.joblib.parallel.BatchedCalls object>)
    220     def __call__(self):
    221         # Set the default nested backend to self._backend but do not set the
    222         # change the default number of processes to -1
    223         with parallel_backend(self._backend, n_jobs=self._n_jobs):
    224             return [func(*args, **kwargs)
--> 225                     for func, args, kwargs in self.items]
        func = <function _fit_and_score>
        args = (Pipeline(memory=None,
     steps=[('normalizer',... random_state=42, verbose=0, warm_start=False))]), array([[1.423e+01, 1.710e+00, 2.430e+00, ..., 1...., ..., 6.100e-01, 1.600e+00,
        5.600e+02]]), array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,
       2, 2]), {'score': <function _passthrough_scorer>}, array([  6,   7,   8,   9,  10,  11,  12,  13,  ..., 170, 171, 172, 173, 174,
       175, 176, 177]), array([  0,   1,   2,   3,   4,   5,  59,  60,  ...,  64,  65,
        66, 130, 131, 132, 133, 134]), 0, None, None)
        kwargs = {'error_score': 'raise-deprecating', 'return_estimator': False, 'return_times': True, 'return_train_score': False}
        self.items = [(<function _fit_and_score>, (Pipeline(memory=None,
     steps=[('normalizer',... random_state=42, verbose=0, warm_start=False))]), array([[1.423e+01, 1.710e+00, 2.430e+00, ..., 1...., ..., 6.100e-01, 1.600e+00,
        5.600e+02]]), array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,
       2, 2]), {'score': <function _passthrough_scorer>}, array([  6,   7,   8,   9,  10,  11,  12,  13,  ..., 170, 171, 172, 173, 174,
       175, 176, 177]), array([  0,   1,   2,   3,   4,   5,  59,  60,  ...,  64,  65,
        66, 130, 131, 132, 133, 134]), 0, None, None), {'error_score': 'raise-deprecating', 'return_estimator': False, 'return_times': True, 'return_train_score': False})]
    226 
    227     def __len__(self):
    228         return self._size
    229 

...........................................................................
/home/aquemy/.local/lib/python2.7/site-packages/sklearn/model_selection/_validation.py in _fit_and_score(estimator=Pipeline(memory=None,
     steps=[('normalizer',... random_state=42, verbose=0, warm_start=False))]), X=array([[1.423e+01, 1.710e+00, 2.430e+00, ..., 1...., ..., 6.100e-01, 1.600e+00,
        5.600e+02]]), y=array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,
       2, 2]), scorer={'score': <function _passthrough_scorer>}, train=array([  6,   7,   8,   9,  10,  11,  12,  13,  ..., 170, 171, 172, 173, 174,
       175, 176, 177]), test=array([  0,   1,   2,   3,   4,   5,  59,  60,  ...,  64,  65,
        66, 130, 131, 132, 133, 134]), verbose=0, parameters=None, fit_params={}, return_train_score=False, return_parameters=False, return_n_test_samples=False, return_times=True, return_estimator=False, error_score='raise-deprecating')
    523 
    524     try:
    525         if y_train is None:
    526             estimator.fit(X_train, **fit_params)
    527         else:
--> 528             estimator.fit(X_train, y_train, **fit_params)
        estimator.fit = <bound method Pipeline.fit of Pipeline(memory=No...random_state=42, verbose=0, warm_start=False))])>
        X_train = array([[1.439e+01, 1.870e+00, 2.450e+00, ..., 1...., ..., 6.100e-01, 1.600e+00,
        5.600e+02]])
        y_train = array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...2, 2, 2, 2, 2, 2, 2, 2, 2,
       2, 2, 2, 2, 2])
        fit_params = {}
    529 
    530     except Exception as e:
    531         # Note fit time as time until error
    532         fit_time = time.time() - start_time

...........................................................................
/usr/local/lib/python2.7/dist-packages/imblearn/pipeline.py in fit(self=Pipeline(memory=None,
     steps=[('normalizer',... random_state=42, verbose=0, warm_start=False))]), X=array([[1.439e+01, 1.870e+00, 2.450e+00, ..., 1...., ..., 6.100e-01, 1.600e+00,
        5.600e+02]]), y=array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...2, 2, 2, 2, 2, 2, 2, 2, 2,
       2, 2, 2, 2, 2]), **fit_params={})
    234             This estimator
    235 
    236         """
    237         Xt, yt, fit_params = self._fit(X, y, **fit_params)
    238         if self._final_estimator is not None:
--> 239             self._final_estimator.fit(Xt, yt, **fit_params)
        self._final_estimator.fit = <bound method RandomForestClassifier.fit of Rand...e, random_state=42, verbose=0, warm_start=False)>
        Xt = array([[-2.42519641],
       [-1.88635231],
    ...23],
       [ 2.40236773],
       [ 3.11189348]])
        yt = array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...2, 2, 2, 2, 2, 2, 2, 2, 2,
       2, 2, 2, 2, 2])
        fit_params = {}
    240         return self
    241 
    242     def fit_transform(self, X, y=None, **fit_params):
    243         """Fit the model and transform with the final estimator

...........................................................................
/home/aquemy/.local/lib/python2.7/site-packages/sklearn/ensemble/forest.py in fit(self=RandomForestClassifier(bootstrap=False, class_we...se, random_state=42, verbose=0, warm_start=False), X=array([[-2.4251964 ],
       [-1.8863523 ],
    ....4023678 ],
       [ 3.1118934 ]], dtype=float32), y=array([[0.],
       [0.],
       [0.],
       [0...    [2.],
       [2.],
       [2.],
       [2.]]), sample_weight=None)
    328             trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,
    329                              **_joblib_parallel_args(prefer='threads'))(
    330                 delayed(_parallel_build_trees)(
    331                     t, self, X, y, sample_weight, i, len(trees),
    332                     verbose=self.verbose, class_weight=self.class_weight)
--> 333                 for i, t in enumerate(trees))
        i = 74
    334 
    335             # Collect newly grown trees
    336             self.estimators_.extend(trees)
    337 

...........................................................................
/home/aquemy/.local/lib/python2.7/site-packages/sklearn/externals/joblib/parallel.py in __call__(self=Parallel(n_jobs=1), iterable=<generator object <genexpr>>)
    912             # self._original_iterator is None, then this means either
    913             # that pre_dispatch == "all", n_jobs == 1 or that the first batch
    914             # was very quick and its callback already dispatched all the
    915             # remaining jobs.
    916             self._iterating = False
--> 917             if self.dispatch_one_batch(iterator):
        self.dispatch_one_batch = <bound method Parallel.dispatch_one_batch of Parallel(n_jobs=1)>
        iterator = <generator object <genexpr>>
    918                 self._iterating = self._original_iterator is not None
    919 
    920             while self.dispatch_one_batch(iterator):
    921                 pass

...........................................................................
/home/aquemy/.local/lib/python2.7/site-packages/sklearn/externals/joblib/parallel.py in dispatch_one_batch(self=Parallel(n_jobs=1), iterator=<generator object <genexpr>>)
    754                                  self._pickle_cache)
    755             if len(tasks) == 0:
    756                 # No more tasks available in the iterator: tell caller to stop.
    757                 return False
    758             else:
--> 759                 self._dispatch(tasks)
        self._dispatch = <bound method Parallel._dispatch of Parallel(n_jobs=1)>
        tasks = <sklearn.externals.joblib.parallel.BatchedCalls object>
    760                 return True
    761 
    762     def _print(self, msg, msg_args):
    763         """Display the message on stout or stderr depending on verbosity"""

...........................................................................
/home/aquemy/.local/lib/python2.7/site-packages/sklearn/externals/joblib/parallel.py in _dispatch(self=Parallel(n_jobs=1), batch=<sklearn.externals.joblib.parallel.BatchedCalls object>)
    711 
    712         dispatch_timestamp = time.time()
    713         cb = BatchCompletionCallBack(dispatch_timestamp, len(batch), self)
    714         with self._lock:
    715             job_idx = len(self._jobs)
--> 716             job = self._backend.apply_async(batch, callback=cb)
        job = undefined
        self._backend.apply_async = <bound method SequentialBackend.apply_async of <...lib._parallel_backends.SequentialBackend object>>
        batch = <sklearn.externals.joblib.parallel.BatchedCalls object>
        cb = <sklearn.externals.joblib.parallel.BatchCompletionCallBack object>
    717             # A job can complete so quickly than its callback is
    718             # called before we get here, causing self._jobs to
    719             # grow. To ensure correct results ordering, .insert is
    720             # used (rather than .append) in the following line

...........................................................................
/home/aquemy/.local/lib/python2.7/site-packages/sklearn/externals/joblib/_parallel_backends.py in apply_async(self=<sklearn.externals.joblib._parallel_backends.SequentialBackend object>, func=<sklearn.externals.joblib.parallel.BatchedCalls object>, callback=<sklearn.externals.joblib.parallel.BatchCompletionCallBack object>)
    177             raise ValueError('n_jobs == 0 in Parallel has no meaning')
    178         return 1
    179 
    180     def apply_async(self, func, callback=None):
    181         """Schedule a func to be run"""
--> 182         result = ImmediateResult(func)
        result = undefined
        func = <sklearn.externals.joblib.parallel.BatchedCalls object>
    183         if callback:
    184             callback(result)
    185         return result
    186 

...........................................................................
/home/aquemy/.local/lib/python2.7/site-packages/sklearn/externals/joblib/_parallel_backends.py in __init__(self=<sklearn.externals.joblib._parallel_backends.ImmediateResult object>, batch=<sklearn.externals.joblib.parallel.BatchedCalls object>)
    544 
    545 class ImmediateResult(object):
    546     def __init__(self, batch):
    547         # Don't delay the application, to avoid keeping the input
    548         # arguments in memory
--> 549         self.results = batch()
        self.results = undefined
        batch = <sklearn.externals.joblib.parallel.BatchedCalls object>
    550 
    551     def get(self):
    552         return self.results
    553 

...........................................................................
/home/aquemy/.local/lib/python2.7/site-packages/sklearn/externals/joblib/parallel.py in __call__(self=<sklearn.externals.joblib.parallel.BatchedCalls object>)
    220     def __call__(self):
    221         # Set the default nested backend to self._backend but do not set the
    222         # change the default number of processes to -1
    223         with parallel_backend(self._backend, n_jobs=self._n_jobs):
    224             return [func(*args, **kwargs)
--> 225                     for func, args, kwargs in self.items]
        func = <function _parallel_build_trees>
        args = (DecisionTreeClassifier(class_weight=None, criter...=False, random_state=1608637542, splitter='best'), RandomForestClassifier(bootstrap=False, class_we...se, random_state=42, verbose=0, warm_start=False), array([[-2.4251964 ],
       [-1.8863523 ],
    ....4023678 ],
       [ 3.1118934 ]], dtype=float32), array([[0.],
       [0.],
       [0.],
       [0...    [2.],
       [2.],
       [2.],
       [2.]]), None, 0, 75)
        kwargs = {'class_weight': None, 'verbose': 0}
        self.items = [(<function _parallel_build_trees>, (DecisionTreeClassifier(class_weight=None, criter...=False, random_state=1608637542, splitter='best'), RandomForestClassifier(bootstrap=False, class_we...se, random_state=42, verbose=0, warm_start=False), array([[-2.4251964 ],
       [-1.8863523 ],
    ....4023678 ],
       [ 3.1118934 ]], dtype=float32), array([[0.],
       [0.],
       [0.],
       [0...    [2.],
       [2.],
       [2.],
       [2.]]), None, 0, 75), {'class_weight': None, 'verbose': 0})]
    226 
    227     def __len__(self):
    228         return self._size
    229 

...........................................................................
/home/aquemy/.local/lib/python2.7/site-packages/sklearn/ensemble/forest.py in _parallel_build_trees(tree=DecisionTreeClassifier(class_weight=None, criter...=False, random_state=1608637542, splitter='best'), forest=RandomForestClassifier(bootstrap=False, class_we...se, random_state=42, verbose=0, warm_start=False), X=array([[-2.4251964 ],
       [-1.8863523 ],
    ....4023678 ],
       [ 3.1118934 ]], dtype=float32), y=array([[0.],
       [0.],
       [0.],
       [0...    [2.],
       [2.],
       [2.],
       [2.]]), sample_weight=None, tree_idx=0, n_trees=75, verbose=0, class_weight=None)
    116         elif class_weight == 'balanced_subsample':
    117             curr_sample_weight *= compute_sample_weight('balanced', y, indices)
    118 
    119         tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)
    120     else:
--> 121         tree.fit(X, y, sample_weight=sample_weight, check_input=False)
        tree.fit = <bound method DecisionTreeClassifier.fit of Deci...False, random_state=1608637542, splitter='best')>
        X = array([[-2.4251964 ],
       [-1.8863523 ],
    ....4023678 ],
       [ 3.1118934 ]], dtype=float32)
        y = array([[0.],
       [0.],
       [0.],
       [0...    [2.],
       [2.],
       [2.],
       [2.]])
        sample_weight = None
    122 
    123     return tree
    124 
    125 

...........................................................................
/home/aquemy/.local/lib/python2.7/site-packages/sklearn/tree/tree.py in fit(self=DecisionTreeClassifier(class_weight=None, criter...=False, random_state=1608637542, splitter='best'), X=array([[-2.4251964 ],
       [-1.8863523 ],
    ....4023678 ],
       [ 3.1118934 ]], dtype=float32), y=array([[0.],
       [0.],
       [0.],
       [0...    [2.],
       [2.],
       [2.],
       [2.]]), sample_weight=None, check_input=False, X_idx_sorted=None)
    796 
    797         super(DecisionTreeClassifier, self).fit(
    798             X, y,
    799             sample_weight=sample_weight,
    800             check_input=check_input,
--> 801             X_idx_sorted=X_idx_sorted)
        X_idx_sorted = None
    802         return self
    803 
    804     def predict_proba(self, X, check_input=True):
    805         """Predict class probabilities of the input samples X.

...........................................................................
/home/aquemy/.local/lib/python2.7/site-packages/sklearn/tree/tree.py in fit(self=DecisionTreeClassifier(class_weight=None, criter...=False, random_state=1608637542, splitter='best'), X=array([[-2.4251964 ],
       [-1.8863523 ],
    ....4023678 ],
       [ 3.1118934 ]], dtype=float32), y=array([[0.],
       [0.],
       [0.],
       [0...    [2.],
       [2.],
       [2.],
       [2.]]), sample_weight=None, check_input=False, X_idx_sorted=None)
    237         if not 0 <= self.min_weight_fraction_leaf <= 0.5:
    238             raise ValueError("min_weight_fraction_leaf must in [0, 0.5]")
    239         if max_depth <= 0:
    240             raise ValueError("max_depth must be greater than zero. ")
    241         if not (0 < max_features <= self.n_features_):
--> 242             raise ValueError("max_features must be in (0, n_features]")
    243         if not isinstance(max_leaf_nodes, (numbers.Integral, np.integer)):
    244             raise ValueError("max_leaf_nodes must be integral number but was "
    245                              "%r" % max_leaf_nodes)
    246         if -1 < max_leaf_nodes < 2:

ValueError: max_features must be in (0, n_features]
___________________________________________________________________________
Best score: 1.0 (0.0) [J] | Score: 0.0 (0.0) [J]
Best score: 1.0 (0.0) [J] | Score: 0.854833161335 (0.0809852375056) [J]
Best score: 1.0 (0.0) [J] | Score: 0.845579635363 (0.0866005402807) [J]
Best score: 1.0 (0.0) [J] | Score: 0.977777777778 (0.0509175077217) [J]
Best score: 1.0 (0.0) [J] | Score: 0.92306501548 (0.0687267008737) [J]
Best score: 1.0 (0.0) [J] | Score: 0.983006535948 (0.0359417701565) [J]
Best score: 1.0 (0.0) [J] | Score: 0.904717062264 (0.0604656155441) [J]
Best score: 1.0 (0.0) [J] | Score: 0.994444444444 (0.0166666666667) [J]
Best score: 1.0 (0.0) [J] | Score: 0.977743378053 (0.0272938784642) [J]
Best score: 1.0 (0.0) [J] | Score: 0.944334795322 (0.0491160758624) [J]
Best score: 1.0 (0.0) [J] | Score: 0.994444444444 (0.0166666666667) [J]
Best score: 1.0 (0.0) [J] | Score: 0.800625644995 (0.150410600002) [J]
Best score: 1.0 (0.0) [J] | Score: 0.988888888889 (0.0222222222222) [J]
JoblibValueError
___________________________________________________________________________
...........................................................................
/home/aquemy/dev/dp_hyperparameters/extension/main.py in <module>()
     27 
     28     serializer.serialize_results(scenario, policy)
     29 
     30 if __name__ == "__main__":
     31     args = cli.parse_args()
---> 32     main(args)

...........................................................................
/home/aquemy/dev/dp_hyperparameters/extension/main.py in main(args=Namespace(customize=[(['control', 'seed'], '42')...io='./scenarios/rf_wine_joint.yaml', verbosity=0))
     21         test_size=0.4, 
     22         random_state=scenario['control']['seed']
     23     )
     24 
     25     policy = policies.initiate(scenario['setup']['policy'], config)
---> 26     policy.run(X,y)
        policy.run = <bound method Joint.run of <experiment.policies.joint.Joint object>>
        X = array([[1.423e+01, 1.710e+00, 2.430e+00, ..., 1...., ..., 6.100e-01, 1.600e+00,
        5.600e+02]])
        y = array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,
       2, 2])
     27 
     28     serializer.serialize_results(scenario, policy)
     29 
     30 if __name__ == "__main__":

...........................................................................
/home/aquemy/dev/dp_hyperparameters/extension/experiment/policies/joint.py in run(self=<experiment.policies.joint.Joint object>, X=array([[1.423e+01, 1.710e+00, 2.430e+00, ..., 1...., ..., 6.100e-01, 1.600e+00,
        5.600e+02]]), y=array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,
       2, 2]))
     32             algo=tpe.suggest, 
     33             max_evals=None,
     34             max_time=self.config['time'],     
     35             trials=trials,
     36             show_progressbar=False,
---> 37             verbose=0
     38         )
     39 
     40         best_config = self.context['best_config']
     41         super(Joint, self).display_step_results(best_config)

...........................................................................
/home/aquemy/dev/dp_hyperparameters/extension/hyperopt/fmin.py in fmin(fn=<functools.partial object>, space={'algorithm': {'bootstrap': <hyperopt.pyll.base.Apply object>, 'criterion': <hyperopt.pyll.base.Apply object>, 'max_depth': <hyperopt.pyll.base.Apply object>, 'max_features': <hyperopt.pyll.base.Apply object>, 'max_leaf_nodes': <hyperopt.pyll.base.Apply object>, 'min_samples_split': <hyperopt.pyll.base.Apply object>, 'n_estimators': <hyperopt.pyll.base.Apply object>}, 'pipeline': {'features': <hyperopt.pyll.base.Apply object>, 'normalizer': <hyperopt.pyll.base.Apply object>, 'rebalance': <hyperopt.pyll.base.Apply object>}}, algo=<function suggest>, max_evals=9223372036854775807, max_time=300, trials=<hyperopt.base.Trials object>, rstate=<mtrand.RandomState object>, allow_trials_fmin=True, pass_expr_memo_ctrl=None, catch_eval_exceptions=False, verbose=0, return_argmin=True, points_to_evaluate=None, max_queue_len=1, show_progressbar=False)
    406             pass_expr_memo_ctrl=pass_expr_memo_ctrl,
    407             verbose=verbose,
    408             catch_eval_exceptions=catch_eval_exceptions,
    409             return_argmin=return_argmin,
    410             show_progressbar=show_progressbar,
--> 411             max_time=max_time
        max_time = 300
    412         )
    413 
    414     if trials is None:
    415         if points_to_evaluate is None:

...........................................................................
/home/aquemy/dev/dp_hyperparameters/extension/hyperopt/base.py in fmin(self=<hyperopt.base.Trials object>, fn=<functools.partial object>, space={'algorithm': {'bootstrap': <hyperopt.pyll.base.Apply object>, 'criterion': <hyperopt.pyll.base.Apply object>, 'max_depth': <hyperopt.pyll.base.Apply object>, 'max_features': <hyperopt.pyll.base.Apply object>, 'max_leaf_nodes': <hyperopt.pyll.base.Apply object>, 'min_samples_split': <hyperopt.pyll.base.Apply object>, 'n_estimators': <hyperopt.pyll.base.Apply object>}, 'pipeline': {'features': <hyperopt.pyll.base.Apply object>, 'normalizer': <hyperopt.pyll.base.Apply object>, 'rebalance': <hyperopt.pyll.base.Apply object>}}, algo=<function suggest>, max_evals=9223372036854775807, max_time=300, rstate=<mtrand.RandomState object>, verbose=0, pass_expr_memo_ctrl=None, catch_eval_exceptions=False, return_argmin=True, show_progressbar=False)
    636             verbose=verbose,
    637             allow_trials_fmin=False,  # -- prevent recursion
    638             pass_expr_memo_ctrl=pass_expr_memo_ctrl,
    639             catch_eval_exceptions=catch_eval_exceptions,
    640             return_argmin=return_argmin,
--> 641             show_progressbar=show_progressbar)
        show_progressbar = False
    642 
    643 
    644 def trials_from_docs(docs, validate=True, **kwargs):
    645     """Construct a Trials base class instance from a list of trials documents

...........................................................................
/home/aquemy/dev/dp_hyperparameters/extension/hyperopt/fmin.py in fmin(fn=<functools.partial object>, space={'algorithm': {'bootstrap': <hyperopt.pyll.base.Apply object>, 'criterion': <hyperopt.pyll.base.Apply object>, 'max_depth': <hyperopt.pyll.base.Apply object>, 'max_features': <hyperopt.pyll.base.Apply object>, 'max_leaf_nodes': <hyperopt.pyll.base.Apply object>, 'min_samples_split': <hyperopt.pyll.base.Apply object>, 'n_estimators': <hyperopt.pyll.base.Apply object>}, 'pipeline': {'features': <hyperopt.pyll.base.Apply object>, 'normalizer': <hyperopt.pyll.base.Apply object>, 'rebalance': <hyperopt.pyll.base.Apply object>}}, algo=<function suggest>, max_evals=9223372036854775807, max_time=300, trials=<hyperopt.base.Trials object>, rstate=<mtrand.RandomState object>, allow_trials_fmin=False, pass_expr_memo_ctrl=None, catch_eval_exceptions=False, verbose=0, return_argmin=True, points_to_evaluate=None, max_queue_len=1, show_progressbar=False)
    426                     verbose=verbose,
    427                     max_queue_len=max_queue_len,
    428                     show_progressbar=show_progressbar,
    429                     max_time=max_time)
    430     rval.catch_eval_exceptions = catch_eval_exceptions
--> 431     rval.exhaust()
        rval.exhaust = <bound method FMinIter.exhaust of <hyperopt.fmin.FMinIter object>>
    432     if return_argmin:
    433         return trials.argmin
    434     elif len(trials) > 0:
    435         # Only if there are some succesfull trail runs, return the best point in the evaluation space

...........................................................................
/home/aquemy/dev/dp_hyperparameters/extension/hyperopt/fmin.py in exhaust(self=<hyperopt.fmin.FMinIter object>)
    273             raise StopIteration()
    274         return self.trials
    275 
    276     def exhaust(self):
    277         n_done = len(self.trials)
--> 278         self.run(self.max_evals - n_done, block_until_done=self.asynchronous)
        self.run = <bound method FMinIter.run of <hyperopt.fmin.FMinIter object>>
        self.max_evals = 9223372036854775807
        n_done = 0
        self.asynchronous = False
    279         self.trials.refresh()
    280         return self
    281 
    282 

...........................................................................
/home/aquemy/dev/dp_hyperparameters/extension/hyperopt/fmin.py in run(self=<hyperopt.fmin.FMinIter object>, N=9223372036854775807, block_until_done=False)
    232                     if self.asynchronous:
    233                         # -- wait for workers to fill in the trials
    234                         time.sleep(self.poll_interval_secs)
    235                     else:
    236                         # -- loop over trials and do the jobs directly
--> 237                         self.serial_evaluate()
        self.serial_evaluate = <bound method FMinIter.serial_evaluate of <hyperopt.fmin.FMinIter object>>
    238                     try:
    239                         res = [d['result']['loss'] for d in
    240                                          self.trials.trials if
    241                                          d['result']['status'] == 'ok']

...........................................................................
/home/aquemy/dev/dp_hyperparameters/extension/hyperopt/fmin.py in serial_evaluate(self=<hyperopt.fmin.FMinIter object>, N=-1)
    138                 trial['book_time'] = now
    139                 trial['refresh_time'] = now
    140                 spec = base.spec_from_misc(trial['misc'])
    141                 ctrl = base.Ctrl(self.trials, current_trial=trial)
    142                 try:
--> 143                     result = self.domain.evaluate(spec, ctrl)
        result = undefined
        self.domain.evaluate = <bound method Domain.evaluate of <hyperopt.base.Domain object>>
        spec = {'bootstrap': 1, 'criterion': 1, 'features': 2, 'features_SelectKBest_features__k': 0, 'max_depth': 3, 'max_features': 2, 'max_leaf_nodes': 2, 'min_samples_split': 0, 'n_estimators': 3, 'normalizer': 2, ...}
        ctrl = <hyperopt.base.Ctrl object>
    144                 except Exception as e:
    145                     logger.info('job exception: %s' % str(e))
    146                     trial['state'] = base.JOB_STATE_ERROR
    147                     trial['misc']['error'] = (str(type(e)), str(e))

...........................................................................
/home/aquemy/dev/dp_hyperparameters/extension/hyperopt/base.py in evaluate(self=<hyperopt.base.Domain object>, config={'bootstrap': 1, 'criterion': 1, 'features': 2, 'features_SelectKBest_features__k': 0, 'max_depth': 3, 'max_features': 2, 'max_leaf_nodes': 2, 'min_samples_split': 0, 'n_estimators': 3, 'normalizer': 2, ...}, ctrl=<hyperopt.base.Ctrl object>, attach_attachments=True)
    841             #    or the normal Python part (self.fn)
    842             pyll_rval = pyll.rec_eval(
    843                 self.expr,
    844                 memo=memo,
    845                 print_node_on_error=self.rec_eval_print_node_on_error)
--> 846             rval = self.fn(pyll_rval)
        rval = undefined
        self.fn = <functools.partial object>
        pyll_rval = {'algorithm': {'bootstrap': False, 'criterion': 'entropy', 'max_depth': 4, 'max_features': 3, 'max_leaf_nodes': 5, 'min_samples_split': 2, 'n_estimators': 75}, 'pipeline': {'features': ('features_SelectKBest', {'features__k': 1}), 'normalizer': ('normalizer_PowerTransformer', {}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 6})}}
    847 
    848         if isinstance(rval, (float, int, np.number)):
    849             dict_rval = {'loss': float(rval), 'status': STATUS_OK}
    850         else:

...........................................................................
/home/aquemy/dev/dp_hyperparameters/extension/experiment/objective.py in objective_joint(wconfig={'algorithm': {'bootstrap': False, 'criterion': 'entropy', 'max_depth': 4, 'max_features': 3, 'max_leaf_nodes': 5, 'min_samples_split': 2, 'n_estimators': 75}, 'pipeline': {'features': ('features_SelectKBest', {'features__k': 1}), 'normalizer': ('normalizer_PowerTransformer', {}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 6})}}, algorithm='RandomForest', X=array([[1.423e+01, 1.710e+00, 2.430e+00, ..., 1...., ..., 6.100e-01, 1.600e+00,
        5.600e+02]]), y=array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,
       2, 2]), context={'baseline_score': 0.9444100447196423, 'baseline_score_std': 0.04305547117084885, 'best_config': {'algorithm': {'bootstrap': False, 'criterion': 'gini', 'max_depth': 1, 'max_features': 1, 'max_leaf_nodes': 3, 'min_samples_split': 2, 'n_estimators': 50}, 'config_hash': {'algorithm': '41bdc0fd26679e3e9de3f47a81dcebdeb54f6274', 'config': '0ada0978fbb60b78d813177773f684a809a8f7c8', 'pipeline': 'aaf976c7c663a31fa039582d42f9e07101556a7c'}, 'duration': 0.6971359252929688, 'iteration': 62, 'loss': 0.0, 'max_history_score': 1.0, 'max_history_score_std': 0.0, 'max_history_step': 'joint', 'pipeline': {'features': ('features_NoneType', {}), 'normalizer': ('normalizer_PowerTransformer', {}), 'rebalance': ('rebalance_NoneType', {})}, 'score': 1.0, ...}, 'history': [{'algorithm': {'bootstrap': False, 'criterion': 'entropy', 'max_depth': None, 'max_features': 3, 'max_leaf_nodes': 5, 'min_samples_split': 2, 'n_estimators': 50}, 'config_hash': {'algorithm': 'b2c6464add7a35ce8048653a39338c9994de9a4f', 'config': '2e6648b63441361b4398cb94f81d2e04a830b2ef', 'pipeline': '3d44d7482e468d08c4f94457a205f3dac74084c1'}, 'duration': 0.737678050994873, 'iteration': 0, 'loss': 1.0, 'max_history_score': 0.0, 'max_history_score_std': 0.0, 'max_history_step': 'baseline', 'pipeline': {'features': ('features_PCA', {'features__n_components': 1}), 'normalizer': ('normalizer_NoneType', {}), 'rebalance': ('rebalance_CondensedNearestNeighbour', {'rebalance__n_neighbors': 3})}, 'score': 0.0, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'gini', 'max_depth': 1, 'max_features': None, 'max_leaf_nodes': 2, 'min_samples_split': 3, 'n_estimators': 25}, 'config_hash': {'algorithm': '7f71bbbfdb4e8da52b6fc33a43224183117de15e', 'config': '584343bc020d2d7bc89bd0856bc7770dae1c84fc', 'pipeline': '466ffa7ace0e442beb7c311eb214b17a4c6832b3'}, 'duration': 1.5976769924163818, 'iteration': 1, 'loss': 0.40386351909184726, 'max_history_score': 0.5961364809081527, 'max_history_score_std': 0.05351463210025494, 'max_history_step': 'joint', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 3, 'features__selectkbest__k': 3}), 'normalizer': ('normalizer_StandardScaler', {'normalizer__with_mean': True, 'normalizer__with_std': True}), 'rebalance': ('rebalance_NearMiss', {'rebalance__n_neighbors': 2})}, 'score': 0.5961364809081527, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'entropy', 'max_depth': 1, 'max_features': 2, 'max_leaf_nodes': 2, 'min_samples_split': 5, 'n_estimators': 25}, 'config_hash': {'algorithm': '897745a20d929d43e760cacee0a764bd8070daa5', 'config': 'de121d053e65def047cc8947f505578d5c5eab67', 'pipeline': '63040b39b48626a8232e847e8327bdca5cd88611'}, 'duration': 0.815453052520752, 'iteration': 2, 'loss': 0.07327786377708967, 'max_history_score': 0.9267221362229103, 'max_history_score_std': 0.043920207373658794, 'max_history_step': 'joint', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 3, 'features__selectkbest__k': 2}), 'normalizer': ('normalizer_StandardScaler', {'normalizer__with_mean': True, 'normalizer__with_std': True}), 'rebalance': ('rebalance_NoneType', {})}, 'score': 0.9267221362229103, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'entropy', 'max_depth': 4, 'max_features': 3, 'max_leaf_nodes': None, 'min_samples_split': 2, 'n_estimators': 100}, 'config_hash': {'algorithm': 'dbd92c75280ec06b66ca4ad9b135cf36957031a4', 'config': 'b21c9d15a389baa5bfea4c8ddcec129259f37540', 'pipeline': '38866720d2f120c863351493b9b4e23b9a4506dc'}, 'duration': 1.2293269634246826, 'iteration': 3, 'loss': 0.07199862401100798, 'max_history_score': 0.928001375988992, 'max_history_score_std': 0.06518367535896959, 'max_history_step': 'joint', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 2, 'features__selectkbest__k': 4}), 'normalizer': ('normalizer_NoneType', {}), 'rebalance': ('rebalance_NoneType', {})}, 'score': 0.928001375988992, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': 2, 'max_features': None, 'max_leaf_nodes': None, 'min_samples_split': 5, 'n_estimators': 100}, 'config_hash': {'algorithm': 'f455eefd9fdd03ece88892c3f440c580bdf27ddb', 'config': 'edd3456355d80775739c31515c832ca7b4e5e094', 'pipeline': '1d1034f9f0871e43f896c1db4ed6fd572ed0a6ef'}, 'duration': 1.6186630725860596, 'iteration': 4, 'loss': 0.16651831785345705, 'max_history_score': 0.928001375988992, 'max_history_score_std': 0.06518367535896959, 'max_history_step': 'joint', 'pipeline': {'features': ('features_SelectKBest', {'features__k': 4}), 'normalizer': ('normalizer_MinMaxScaler', {}), 'rebalance': ('rebalance_CondensedNearestNeighbour', {'rebalance__n_neighbors': 1})}, 'score': 0.833481682146543, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'entropy', 'max_depth': 1, 'max_features': 2, 'max_leaf_nodes': None, 'min_samples_split': 2, 'n_estimators': 10}, 'config_hash': {'algorithm': '29906eaa0712a68ea145b12821d54ba445726fbf', 'config': '0800d7d2c8c10d2f9e7b4e5127b343e916eb742c', 'pipeline': '2e0f188ae61600352a7159285e0f542b4587a403'}, 'duration': 0.19410085678100586, 'iteration': 5, 'loss': 0.20164258685930514, 'max_history_score': 0.928001375988992, 'max_history_score_std': 0.06518367535896959, 'max_history_step': 'joint', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 3, 'features__selectkbest__k': 4}), 'normalizer': ('normalizer_StandardScaler', {'normalizer__with_mean': True, 'normalizer__with_std': False}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 7})}, 'score': 0.7983574131406949, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': 1, 'max_features': 1, 'max_leaf_nodes': 5, 'min_samples_split': 2, 'n_estimators': 25}, 'config_hash': {'algorithm': 'fbb7d57e38cfc08240f0af985282da418cb33556', 'config': 'd98b641879b4754f2169335626a90575e945fd7c', 'pipeline': '62463de065924498cdcd2f2f1f7e68535cdb33a5'}, 'duration': 0.3625810146331787, 'iteration': 6, 'loss': 0.14327485380116955, 'max_history_score': 0.928001375988992, 'max_history_score_std': 0.06518367535896959, 'max_history_step': 'joint', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 1, 'features__selectkbest__k': 2}), 'normalizer': ('normalizer_NoneType', {}), 'rebalance': ('rebalance_NoneType', {})}, 'score': 0.8567251461988304, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'entropy', 'max_depth': 3, 'max_features': 1, 'max_leaf_nodes': None, 'min_samples_split': 2, 'n_estimators': 75}, 'config_hash': {'algorithm': 'fb2f5d4c4d636edac929e1454ce3d02a4fb134c1', 'config': '3f83df36a6abbdf7ea4a4bdcaf6727f23529c2bb', 'pipeline': '8377b93e334656d1a93d266493b58ef9a6a1786f'}, 'duration': 0.8223779201507568, 'iteration': 7, 'loss': 0.03921568627450989, 'max_history_score': 0.9607843137254901, 'max_history_score_std': 0.043526663832084804, 'max_history_step': 'joint', 'pipeline': {'features': ('features_PCA', {'features__n_components': 3}), 'normalizer': ('normalizer_MinMaxScaler', {}), 'rebalance': ('rebalance_NearMiss', {'rebalance__n_neighbors': 1})}, 'score': 0.9607843137254901, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'gini', 'max_depth': 3, 'max_features': 3, 'max_leaf_nodes': 2, 'min_samples_split': 2, 'n_estimators': 100}, 'config_hash': {'algorithm': '3c3fde6559b918694de4668d025d5418342db1b1', 'config': '037fd5c655b39cc7922fb394d736496befcc747b', 'pipeline': '2a5032814c6c7ed21dd5bd9686923d7fc2f8acc9'}, 'duration': 1.0435099601745605, 'iteration': 8, 'loss': 0.09955925352597172, 'max_history_score': 0.9607843137254901, 'max_history_score_std': 0.043526663832084804, 'max_history_step': 'joint', 'pipeline': {'features': ('features_NoneType', {}), 'normalizer': ('normalizer_RobustScaler', {'normalizer__quantile_range': (...), 'normalizer__with_centering': True, 'normalizer__with_scaling': True}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 7})}, 'score': 0.9004407464740283, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': 2, 'max_features': 1, 'max_leaf_nodes': None, 'min_samples_split': 3, 'n_estimators': 75}, 'config_hash': {'algorithm': '42185be98371e99ac896d2c6c2d69c451cb983ff', 'config': '6609280032189b59de1afbe36f3acb1d5c273693', 'pipeline': '8aab2941fc84d84f86fa56134e50909dbf9e19f5'}, 'duration': 0.9665219783782959, 'iteration': 9, 'loss': 0.01637426900584804, 'max_history_score': 0.983625730994152, 'max_history_score_std': 0.025023500462379746, 'max_history_step': 'joint', 'pipeline': {'features': ('features_NoneType', {}), 'normalizer': ('normalizer_PowerTransformer', {}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 5})}, 'score': 0.983625730994152, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': 1, 'max_features': 3, 'max_leaf_nodes': 2, 'min_samples_split': 3, 'n_estimators': 10}, 'config_hash': {'algorithm': '62a9fe705e4cd96e762bcc9543c4a456a5a9f188', 'config': '8e1c17ac9f6e03740f380fccb833c9c3931ffc35', 'pipeline': '3d44d7482e468d08c4f94457a205f3dac74084c1'}, 'duration': 0.46930503845214844, 'iteration': 10, 'loss': 1.0, 'max_history_score': 0.983625730994152, 'max_history_score_std': 0.025023500462379746, 'max_history_step': 'joint', 'pipeline': {'features': ('features_PCA', {'features__n_components': 1}), 'normalizer': ('normalizer_NoneType', {}), 'rebalance': ('rebalance_CondensedNearestNeighbour', {'rebalance__n_neighbors': 3})}, 'score': 0.0, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'gini', 'max_depth': 4, 'max_features': 1, 'max_leaf_nodes': 3, 'min_samples_split': 2, 'n_estimators': 100}, 'config_hash': {'algorithm': '086d6ca939a757bb32edb113a567f9d38744f061', 'config': '87c03d0cb8e8500e58cacc1a0f27ce54c41a2937', 'pipeline': '8f28ef0f35d97142278f9dacb4e9d1ff082e470f'}, 'duration': 2.1196961402893066, 'iteration': 11, 'loss': 0.15471276229790154, 'max_history_score': 0.983625730994152, 'max_history_score_std': 0.025023500462379746, 'max_history_step': 'joint', 'pipeline': {'features': ('features_PCA', {'features__n_components': 1}), 'normalizer': ('normalizer_StandardScaler', {'normalizer__with_mean': True, 'normalizer__with_std': True}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 7})}, 'score': 0.8452872377020985, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'entropy', 'max_depth': 3, 'max_features': 1, 'max_leaf_nodes': 2, 'min_samples_split': 2, 'n_estimators': 25}, 'config_hash': {'algorithm': '59f64a966796648c7bebade1127fa05541b391ad', 'config': '2ab964abffa0a277a9e2ee9b5570cd258e428b62', 'pipeline': 'eef3f702fd2fed761fa6744c1640d0bf320f1d00'}, 'duration': 0.9828321933746338, 'iteration': 12, 'loss': 0.0778465772273822, 'max_history_score': 0.983625730994152, 'max_history_score_std': 0.025023500462379746, 'max_history_step': 'joint', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 3, 'features__selectkbest__k': 1}), 'normalizer': ('normalizer_PowerTransformer', {}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 6})}, 'score': 0.9221534227726178, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'gini', 'max_depth': 4, 'max_features': 2, 'max_leaf_nodes': 3, 'min_samples_split': 3, 'n_estimators': 75}, 'config_hash': {'algorithm': '6f75c2a196eb9836df2b424e095051192eaed6ea', 'config': '5c95db3ad238063227f1b36e6a006d70c834c5da', 'pipeline': '1eae01a1128bee425c4d4ca0ee97a9afd409680e'}, 'duration': 0.8217771053314209, 'iteration': 13, 'loss': 0.03863089095287242, 'max_history_score': 0.983625730994152, 'max_history_score_std': 0.025023500462379746, 'max_history_step': 'joint', 'pipeline': {'features': ('features_NoneType', {}), 'normalizer': ('normalizer_StandardScaler', {'normalizer__with_mean': False, 'normalizer__with_std': False}), 'rebalance': ('rebalance_NearMiss', {'rebalance__n_neighbors': 1})}, 'score': 0.9613691090471276, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'entropy', 'max_depth': 4, 'max_features': 2, 'max_leaf_nodes': 3, 'min_samples_split': 2, 'n_estimators': 25}, 'config_hash': {'algorithm': '8aef3174f6b8020de06b825e0424c1e54d690afd', 'config': '50fd1169b8e42190600f25152654254b5d0e3ed1', 'pipeline': '9ceaa544911dc6c687e336cb8e9dd4d15ff1ceaf'}, 'duration': 0.40307188034057617, 'iteration': 14, 'loss': 1.0, 'max_history_score': 0.983625730994152, 'max_history_score_std': 0.025023500462379746, 'max_history_step': 'joint', 'pipeline': {'features': ('features_PCA', {'features__n_components': 1}), 'normalizer': ('normalizer_RobustScaler', {'normalizer__quantile_range': (...), 'normalizer__with_centering': False, 'normalizer__with_scaling': False}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 7})}, 'score': 0.0, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'gini', 'max_depth': 1, 'max_features': 1, 'max_leaf_nodes': 3, 'min_samples_split': 3, 'n_estimators': 50}, 'config_hash': {'algorithm': '37be8b6737f4b5d5ae35da51886f302b07ba6001', 'config': 'a05b6d2ffd65d4d937c0b178655d857bf4d61410', 'pipeline': 'cfef88e895db321122f2f7b813d9267b973c2468'}, 'duration': 1.7094659805297852, 'iteration': 15, 'loss': 0.011111111111111072, 'max_history_score': 0.9888888888888889, 'max_history_score_std': 0.022222222222222233, 'max_history_step': 'joint', 'pipeline': {'features': ('features_NoneType', {}), 'normalizer': ('normalizer_NoneType', {}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 5})}, 'score': 0.9888888888888889, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'entropy', 'max_depth': None, 'max_features': 3, 'max_leaf_nodes': None, 'min_samples_split': 2, 'n_estimators': 100}, 'config_hash': {'algorithm': 'c40543ce91793e367c1892c886bc49621c22ecfb', 'config': 'ebebb7a93116f14f470e062e37582a59f4aeb0df', 'pipeline': 'b50c63e800574e8b760f55f7c4ff1fcae8816dd8'}, 'duration': 0.6425540447235107, 'iteration': 16, 'loss': 1.0, 'max_history_score': 0.9888888888888889, 'max_history_score_std': 0.022222222222222233, 'max_history_step': 'joint', 'pipeline': {'features': ('features_PCA', {'features__n_components': 1}), 'normalizer': ('normalizer_PowerTransformer', {}), 'rebalance': ('rebalance_NearMiss', {'rebalance__n_neighbors': 1})}, 'score': 0.0, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'gini', 'max_depth': None, 'max_features': 1, 'max_leaf_nodes': 3, 'min_samples_split': 2, 'n_estimators': 50}, 'config_hash': {'algorithm': '0c69b9601237c20664085fa05764d855e28f98f7', 'config': 'a2c21314ddbba47ddbfe416e0aa14853a71179e0', 'pipeline': '914f81fa4fbb61db251201f32bd8ea11bfeea2a5'}, 'duration': 2.2209739685058594, 'iteration': 17, 'loss': 0.3206720846233231, 'max_history_score': 0.9888888888888889, 'max_history_score_std': 0.022222222222222233, 'max_history_step': 'joint', 'pipeline': {'features': ('features_SelectKBest', {'features__k': 4}), 'normalizer': ('normalizer_PowerTransformer', {}), 'rebalance': ('rebalance_CondensedNearestNeighbour', {'rebalance__n_neighbors': 1})}, 'score': 0.6793279153766769, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': 4, 'max_features': None, 'max_leaf_nodes': None, 'min_samples_split': 3, 'n_estimators': 25}, 'config_hash': {'algorithm': '1aae0f1fce5cab293ffdd4581c4838c8051ac815', 'config': '6c8a721218e7c550a98c5ba72ad9ff86afd5e3a4', 'pipeline': '77189452469cef9c840643f2babe0f825c6667c8'}, 'duration': 0.3951280117034912, 'iteration': 18, 'loss': 0.1804760061919506, 'max_history_score': 0.9888888888888889, 'max_history_score_std': 0.022222222222222233, 'max_history_step': 'joint', 'pipeline': {'features': ('features_SelectKBest', {'features__k': 2}), 'normalizer': ('normalizer_NoneType', {}), 'rebalance': ('rebalance_NearMiss', {'rebalance__n_neighbors': 1})}, 'score': 0.8195239938080494, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': None, 'max_features': 3, 'max_leaf_nodes': 5, 'min_samples_split': 3, 'n_estimators': 50}, 'config_hash': {'algorithm': '0129970b8c7fe034ac8283fb518a06cfbead63d2', 'config': '61bcd2f64860b3dfe2503be88a6bbec165db0754', 'pipeline': '359f2473075ecfd9ae3ce526da96143918517601'}, 'duration': 0.7467091083526611, 'iteration': 19, 'loss': 0.09915720674234607, 'max_history_score': 0.9888888888888889, 'max_history_score_std': 0.022222222222222233, 'max_history_step': 'joint', 'pipeline': {'features': ('features_SelectKBest', {'features__k': 3}), 'normalizer': ('normalizer_RobustScaler', {'normalizer__quantile_range': (...), 'normalizer__with_centering': True, 'normalizer__with_scaling': False}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 7})}, 'score': 0.9008427932576539, ...}, ...], 'history_hash': ['2e6648b63441361b4398cb94f81d2e04a830b2ef', '584343bc020d2d7bc89bd0856bc7770dae1c84fc', 'de121d053e65def047cc8947f505578d5c5eab67', 'b21c9d15a389baa5bfea4c8ddcec129259f37540', 'edd3456355d80775739c31515c832ca7b4e5e094', '0800d7d2c8c10d2f9e7b4e5127b343e916eb742c', 'd98b641879b4754f2169335626a90575e945fd7c', '3f83df36a6abbdf7ea4a4bdcaf6727f23529c2bb', '037fd5c655b39cc7922fb394d736496befcc747b', '6609280032189b59de1afbe36f3acb1d5c273693', '8e1c17ac9f6e03740f380fccb833c9c3931ffc35', '87c03d0cb8e8500e58cacc1a0f27ce54c41a2937', '2ab964abffa0a277a9e2ee9b5570cd258e428b62', '5c95db3ad238063227f1b36e6a006d70c834c5da', '50fd1169b8e42190600f25152654254b5d0e3ed1', 'a05b6d2ffd65d4d937c0b178655d857bf4d61410', 'ebebb7a93116f14f470e062e37582a59f4aeb0df', 'a2c21314ddbba47ddbfe416e0aa14853a71179e0', '6c8a721218e7c550a98c5ba72ad9ff86afd5e3a4', '61bcd2f64860b3dfe2503be88a6bbec165db0754', ...], 'history_index': {'0018716ad6e0edc096329f31492734a67d79d3b3': 64, '01c777816cea234a1e6b73501020cf6f05ea69b9': 111, '01d4ea6f317be786c402492e3b997e2fbf253d6d': 225, '020ec4a49249e6e129cbf2800d975e6e1c8842aa': 92, '037fd5c655b39cc7922fb394d736496befcc747b': 8, '0393a0da80adcc0e64c60f266b4277ec0e84ea81': 141, '0414a55701bd4c21bd4e55ad37a0576c56d56b3f': 94, '04694e3dc0ec7217740bca3ee7723f4509d5fd32': 295, '059454b30e3cc3dfea856c92f07a9c43d4b7ea71': 291, '0650ac92dace31c01ac743925565b952112a5c82': 78, ...}, 'iteration': 298, 'max_history_score': 1.0, 'max_history_score_std': 0.0, 'max_history_step': 'joint'}, config={'algorithm': 'RandomForest', 'seed': 42, 'time': 300})
    108 
    109 def objective_algo(algo_config, current_pipeline_config, algorithm, X, y, context, config):
    110     return objective(current_pipeline_config, algo_config, algorithm, X, y, context, config, step='algorithm')
    111 
    112 def objective_joint(wconfig, algorithm, X, y, context, config):
--> 113     return objective(wconfig['pipeline'], wconfig['algorithm'], algorithm, X, y, context, config, step='joint')
        wconfig = {'algorithm': {'bootstrap': False, 'criterion': 'entropy', 'max_depth': 4, 'max_features': 3, 'max_leaf_nodes': 5, 'min_samples_split': 2, 'n_estimators': 75}, 'pipeline': {'features': ('features_SelectKBest', {'features__k': 1}), 'normalizer': ('normalizer_PowerTransformer', {}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 6})}}
        algorithm = 'RandomForest'
        X = array([[1.423e+01, 1.710e+00, 2.430e+00, ..., 1...., ..., 6.100e-01, 1.600e+00,
        5.600e+02]])
        y = array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,
       2, 2])
        context = {'baseline_score': 0.9444100447196423, 'baseline_score_std': 0.04305547117084885, 'best_config': {'algorithm': {'bootstrap': False, 'criterion': 'gini', 'max_depth': 1, 'max_features': 1, 'max_leaf_nodes': 3, 'min_samples_split': 2, 'n_estimators': 50}, 'config_hash': {'algorithm': '41bdc0fd26679e3e9de3f47a81dcebdeb54f6274', 'config': '0ada0978fbb60b78d813177773f684a809a8f7c8', 'pipeline': 'aaf976c7c663a31fa039582d42f9e07101556a7c'}, 'duration': 0.6971359252929688, 'iteration': 62, 'loss': 0.0, 'max_history_score': 1.0, 'max_history_score_std': 0.0, 'max_history_step': 'joint', 'pipeline': {'features': ('features_NoneType', {}), 'normalizer': ('normalizer_PowerTransformer', {}), 'rebalance': ('rebalance_NoneType', {})}, 'score': 1.0, ...}, 'history': [{'algorithm': {'bootstrap': False, 'criterion': 'entropy', 'max_depth': None, 'max_features': 3, 'max_leaf_nodes': 5, 'min_samples_split': 2, 'n_estimators': 50}, 'config_hash': {'algorithm': 'b2c6464add7a35ce8048653a39338c9994de9a4f', 'config': '2e6648b63441361b4398cb94f81d2e04a830b2ef', 'pipeline': '3d44d7482e468d08c4f94457a205f3dac74084c1'}, 'duration': 0.737678050994873, 'iteration': 0, 'loss': 1.0, 'max_history_score': 0.0, 'max_history_score_std': 0.0, 'max_history_step': 'baseline', 'pipeline': {'features': ('features_PCA', {'features__n_components': 1}), 'normalizer': ('normalizer_NoneType', {}), 'rebalance': ('rebalance_CondensedNearestNeighbour', {'rebalance__n_neighbors': 3})}, 'score': 0.0, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'gini', 'max_depth': 1, 'max_features': None, 'max_leaf_nodes': 2, 'min_samples_split': 3, 'n_estimators': 25}, 'config_hash': {'algorithm': '7f71bbbfdb4e8da52b6fc33a43224183117de15e', 'config': '584343bc020d2d7bc89bd0856bc7770dae1c84fc', 'pipeline': '466ffa7ace0e442beb7c311eb214b17a4c6832b3'}, 'duration': 1.5976769924163818, 'iteration': 1, 'loss': 0.40386351909184726, 'max_history_score': 0.5961364809081527, 'max_history_score_std': 0.05351463210025494, 'max_history_step': 'joint', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 3, 'features__selectkbest__k': 3}), 'normalizer': ('normalizer_StandardScaler', {'normalizer__with_mean': True, 'normalizer__with_std': True}), 'rebalance': ('rebalance_NearMiss', {'rebalance__n_neighbors': 2})}, 'score': 0.5961364809081527, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'entropy', 'max_depth': 1, 'max_features': 2, 'max_leaf_nodes': 2, 'min_samples_split': 5, 'n_estimators': 25}, 'config_hash': {'algorithm': '897745a20d929d43e760cacee0a764bd8070daa5', 'config': 'de121d053e65def047cc8947f505578d5c5eab67', 'pipeline': '63040b39b48626a8232e847e8327bdca5cd88611'}, 'duration': 0.815453052520752, 'iteration': 2, 'loss': 0.07327786377708967, 'max_history_score': 0.9267221362229103, 'max_history_score_std': 0.043920207373658794, 'max_history_step': 'joint', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 3, 'features__selectkbest__k': 2}), 'normalizer': ('normalizer_StandardScaler', {'normalizer__with_mean': True, 'normalizer__with_std': True}), 'rebalance': ('rebalance_NoneType', {})}, 'score': 0.9267221362229103, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'entropy', 'max_depth': 4, 'max_features': 3, 'max_leaf_nodes': None, 'min_samples_split': 2, 'n_estimators': 100}, 'config_hash': {'algorithm': 'dbd92c75280ec06b66ca4ad9b135cf36957031a4', 'config': 'b21c9d15a389baa5bfea4c8ddcec129259f37540', 'pipeline': '38866720d2f120c863351493b9b4e23b9a4506dc'}, 'duration': 1.2293269634246826, 'iteration': 3, 'loss': 0.07199862401100798, 'max_history_score': 0.928001375988992, 'max_history_score_std': 0.06518367535896959, 'max_history_step': 'joint', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 2, 'features__selectkbest__k': 4}), 'normalizer': ('normalizer_NoneType', {}), 'rebalance': ('rebalance_NoneType', {})}, 'score': 0.928001375988992, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': 2, 'max_features': None, 'max_leaf_nodes': None, 'min_samples_split': 5, 'n_estimators': 100}, 'config_hash': {'algorithm': 'f455eefd9fdd03ece88892c3f440c580bdf27ddb', 'config': 'edd3456355d80775739c31515c832ca7b4e5e094', 'pipeline': '1d1034f9f0871e43f896c1db4ed6fd572ed0a6ef'}, 'duration': 1.6186630725860596, 'iteration': 4, 'loss': 0.16651831785345705, 'max_history_score': 0.928001375988992, 'max_history_score_std': 0.06518367535896959, 'max_history_step': 'joint', 'pipeline': {'features': ('features_SelectKBest', {'features__k': 4}), 'normalizer': ('normalizer_MinMaxScaler', {}), 'rebalance': ('rebalance_CondensedNearestNeighbour', {'rebalance__n_neighbors': 1})}, 'score': 0.833481682146543, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'entropy', 'max_depth': 1, 'max_features': 2, 'max_leaf_nodes': None, 'min_samples_split': 2, 'n_estimators': 10}, 'config_hash': {'algorithm': '29906eaa0712a68ea145b12821d54ba445726fbf', 'config': '0800d7d2c8c10d2f9e7b4e5127b343e916eb742c', 'pipeline': '2e0f188ae61600352a7159285e0f542b4587a403'}, 'duration': 0.19410085678100586, 'iteration': 5, 'loss': 0.20164258685930514, 'max_history_score': 0.928001375988992, 'max_history_score_std': 0.06518367535896959, 'max_history_step': 'joint', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 3, 'features__selectkbest__k': 4}), 'normalizer': ('normalizer_StandardScaler', {'normalizer__with_mean': True, 'normalizer__with_std': False}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 7})}, 'score': 0.7983574131406949, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': 1, 'max_features': 1, 'max_leaf_nodes': 5, 'min_samples_split': 2, 'n_estimators': 25}, 'config_hash': {'algorithm': 'fbb7d57e38cfc08240f0af985282da418cb33556', 'config': 'd98b641879b4754f2169335626a90575e945fd7c', 'pipeline': '62463de065924498cdcd2f2f1f7e68535cdb33a5'}, 'duration': 0.3625810146331787, 'iteration': 6, 'loss': 0.14327485380116955, 'max_history_score': 0.928001375988992, 'max_history_score_std': 0.06518367535896959, 'max_history_step': 'joint', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 1, 'features__selectkbest__k': 2}), 'normalizer': ('normalizer_NoneType', {}), 'rebalance': ('rebalance_NoneType', {})}, 'score': 0.8567251461988304, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'entropy', 'max_depth': 3, 'max_features': 1, 'max_leaf_nodes': None, 'min_samples_split': 2, 'n_estimators': 75}, 'config_hash': {'algorithm': 'fb2f5d4c4d636edac929e1454ce3d02a4fb134c1', 'config': '3f83df36a6abbdf7ea4a4bdcaf6727f23529c2bb', 'pipeline': '8377b93e334656d1a93d266493b58ef9a6a1786f'}, 'duration': 0.8223779201507568, 'iteration': 7, 'loss': 0.03921568627450989, 'max_history_score': 0.9607843137254901, 'max_history_score_std': 0.043526663832084804, 'max_history_step': 'joint', 'pipeline': {'features': ('features_PCA', {'features__n_components': 3}), 'normalizer': ('normalizer_MinMaxScaler', {}), 'rebalance': ('rebalance_NearMiss', {'rebalance__n_neighbors': 1})}, 'score': 0.9607843137254901, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'gini', 'max_depth': 3, 'max_features': 3, 'max_leaf_nodes': 2, 'min_samples_split': 2, 'n_estimators': 100}, 'config_hash': {'algorithm': '3c3fde6559b918694de4668d025d5418342db1b1', 'config': '037fd5c655b39cc7922fb394d736496befcc747b', 'pipeline': '2a5032814c6c7ed21dd5bd9686923d7fc2f8acc9'}, 'duration': 1.0435099601745605, 'iteration': 8, 'loss': 0.09955925352597172, 'max_history_score': 0.9607843137254901, 'max_history_score_std': 0.043526663832084804, 'max_history_step': 'joint', 'pipeline': {'features': ('features_NoneType', {}), 'normalizer': ('normalizer_RobustScaler', {'normalizer__quantile_range': (...), 'normalizer__with_centering': True, 'normalizer__with_scaling': True}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 7})}, 'score': 0.9004407464740283, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': 2, 'max_features': 1, 'max_leaf_nodes': None, 'min_samples_split': 3, 'n_estimators': 75}, 'config_hash': {'algorithm': '42185be98371e99ac896d2c6c2d69c451cb983ff', 'config': '6609280032189b59de1afbe36f3acb1d5c273693', 'pipeline': '8aab2941fc84d84f86fa56134e50909dbf9e19f5'}, 'duration': 0.9665219783782959, 'iteration': 9, 'loss': 0.01637426900584804, 'max_history_score': 0.983625730994152, 'max_history_score_std': 0.025023500462379746, 'max_history_step': 'joint', 'pipeline': {'features': ('features_NoneType', {}), 'normalizer': ('normalizer_PowerTransformer', {}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 5})}, 'score': 0.983625730994152, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': 1, 'max_features': 3, 'max_leaf_nodes': 2, 'min_samples_split': 3, 'n_estimators': 10}, 'config_hash': {'algorithm': '62a9fe705e4cd96e762bcc9543c4a456a5a9f188', 'config': '8e1c17ac9f6e03740f380fccb833c9c3931ffc35', 'pipeline': '3d44d7482e468d08c4f94457a205f3dac74084c1'}, 'duration': 0.46930503845214844, 'iteration': 10, 'loss': 1.0, 'max_history_score': 0.983625730994152, 'max_history_score_std': 0.025023500462379746, 'max_history_step': 'joint', 'pipeline': {'features': ('features_PCA', {'features__n_components': 1}), 'normalizer': ('normalizer_NoneType', {}), 'rebalance': ('rebalance_CondensedNearestNeighbour', {'rebalance__n_neighbors': 3})}, 'score': 0.0, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'gini', 'max_depth': 4, 'max_features': 1, 'max_leaf_nodes': 3, 'min_samples_split': 2, 'n_estimators': 100}, 'config_hash': {'algorithm': '086d6ca939a757bb32edb113a567f9d38744f061', 'config': '87c03d0cb8e8500e58cacc1a0f27ce54c41a2937', 'pipeline': '8f28ef0f35d97142278f9dacb4e9d1ff082e470f'}, 'duration': 2.1196961402893066, 'iteration': 11, 'loss': 0.15471276229790154, 'max_history_score': 0.983625730994152, 'max_history_score_std': 0.025023500462379746, 'max_history_step': 'joint', 'pipeline': {'features': ('features_PCA', {'features__n_components': 1}), 'normalizer': ('normalizer_StandardScaler', {'normalizer__with_mean': True, 'normalizer__with_std': True}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 7})}, 'score': 0.8452872377020985, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'entropy', 'max_depth': 3, 'max_features': 1, 'max_leaf_nodes': 2, 'min_samples_split': 2, 'n_estimators': 25}, 'config_hash': {'algorithm': '59f64a966796648c7bebade1127fa05541b391ad', 'config': '2ab964abffa0a277a9e2ee9b5570cd258e428b62', 'pipeline': 'eef3f702fd2fed761fa6744c1640d0bf320f1d00'}, 'duration': 0.9828321933746338, 'iteration': 12, 'loss': 0.0778465772273822, 'max_history_score': 0.983625730994152, 'max_history_score_std': 0.025023500462379746, 'max_history_step': 'joint', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 3, 'features__selectkbest__k': 1}), 'normalizer': ('normalizer_PowerTransformer', {}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 6})}, 'score': 0.9221534227726178, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'gini', 'max_depth': 4, 'max_features': 2, 'max_leaf_nodes': 3, 'min_samples_split': 3, 'n_estimators': 75}, 'config_hash': {'algorithm': '6f75c2a196eb9836df2b424e095051192eaed6ea', 'config': '5c95db3ad238063227f1b36e6a006d70c834c5da', 'pipeline': '1eae01a1128bee425c4d4ca0ee97a9afd409680e'}, 'duration': 0.8217771053314209, 'iteration': 13, 'loss': 0.03863089095287242, 'max_history_score': 0.983625730994152, 'max_history_score_std': 0.025023500462379746, 'max_history_step': 'joint', 'pipeline': {'features': ('features_NoneType', {}), 'normalizer': ('normalizer_StandardScaler', {'normalizer__with_mean': False, 'normalizer__with_std': False}), 'rebalance': ('rebalance_NearMiss', {'rebalance__n_neighbors': 1})}, 'score': 0.9613691090471276, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'entropy', 'max_depth': 4, 'max_features': 2, 'max_leaf_nodes': 3, 'min_samples_split': 2, 'n_estimators': 25}, 'config_hash': {'algorithm': '8aef3174f6b8020de06b825e0424c1e54d690afd', 'config': '50fd1169b8e42190600f25152654254b5d0e3ed1', 'pipeline': '9ceaa544911dc6c687e336cb8e9dd4d15ff1ceaf'}, 'duration': 0.40307188034057617, 'iteration': 14, 'loss': 1.0, 'max_history_score': 0.983625730994152, 'max_history_score_std': 0.025023500462379746, 'max_history_step': 'joint', 'pipeline': {'features': ('features_PCA', {'features__n_components': 1}), 'normalizer': ('normalizer_RobustScaler', {'normalizer__quantile_range': (...), 'normalizer__with_centering': False, 'normalizer__with_scaling': False}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 7})}, 'score': 0.0, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'gini', 'max_depth': 1, 'max_features': 1, 'max_leaf_nodes': 3, 'min_samples_split': 3, 'n_estimators': 50}, 'config_hash': {'algorithm': '37be8b6737f4b5d5ae35da51886f302b07ba6001', 'config': 'a05b6d2ffd65d4d937c0b178655d857bf4d61410', 'pipeline': 'cfef88e895db321122f2f7b813d9267b973c2468'}, 'duration': 1.7094659805297852, 'iteration': 15, 'loss': 0.011111111111111072, 'max_history_score': 0.9888888888888889, 'max_history_score_std': 0.022222222222222233, 'max_history_step': 'joint', 'pipeline': {'features': ('features_NoneType', {}), 'normalizer': ('normalizer_NoneType', {}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 5})}, 'score': 0.9888888888888889, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'entropy', 'max_depth': None, 'max_features': 3, 'max_leaf_nodes': None, 'min_samples_split': 2, 'n_estimators': 100}, 'config_hash': {'algorithm': 'c40543ce91793e367c1892c886bc49621c22ecfb', 'config': 'ebebb7a93116f14f470e062e37582a59f4aeb0df', 'pipeline': 'b50c63e800574e8b760f55f7c4ff1fcae8816dd8'}, 'duration': 0.6425540447235107, 'iteration': 16, 'loss': 1.0, 'max_history_score': 0.9888888888888889, 'max_history_score_std': 0.022222222222222233, 'max_history_step': 'joint', 'pipeline': {'features': ('features_PCA', {'features__n_components': 1}), 'normalizer': ('normalizer_PowerTransformer', {}), 'rebalance': ('rebalance_NearMiss', {'rebalance__n_neighbors': 1})}, 'score': 0.0, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'gini', 'max_depth': None, 'max_features': 1, 'max_leaf_nodes': 3, 'min_samples_split': 2, 'n_estimators': 50}, 'config_hash': {'algorithm': '0c69b9601237c20664085fa05764d855e28f98f7', 'config': 'a2c21314ddbba47ddbfe416e0aa14853a71179e0', 'pipeline': '914f81fa4fbb61db251201f32bd8ea11bfeea2a5'}, 'duration': 2.2209739685058594, 'iteration': 17, 'loss': 0.3206720846233231, 'max_history_score': 0.9888888888888889, 'max_history_score_std': 0.022222222222222233, 'max_history_step': 'joint', 'pipeline': {'features': ('features_SelectKBest', {'features__k': 4}), 'normalizer': ('normalizer_PowerTransformer', {}), 'rebalance': ('rebalance_CondensedNearestNeighbour', {'rebalance__n_neighbors': 1})}, 'score': 0.6793279153766769, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': 4, 'max_features': None, 'max_leaf_nodes': None, 'min_samples_split': 3, 'n_estimators': 25}, 'config_hash': {'algorithm': '1aae0f1fce5cab293ffdd4581c4838c8051ac815', 'config': '6c8a721218e7c550a98c5ba72ad9ff86afd5e3a4', 'pipeline': '77189452469cef9c840643f2babe0f825c6667c8'}, 'duration': 0.3951280117034912, 'iteration': 18, 'loss': 0.1804760061919506, 'max_history_score': 0.9888888888888889, 'max_history_score_std': 0.022222222222222233, 'max_history_step': 'joint', 'pipeline': {'features': ('features_SelectKBest', {'features__k': 2}), 'normalizer': ('normalizer_NoneType', {}), 'rebalance': ('rebalance_NearMiss', {'rebalance__n_neighbors': 1})}, 'score': 0.8195239938080494, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': None, 'max_features': 3, 'max_leaf_nodes': 5, 'min_samples_split': 3, 'n_estimators': 50}, 'config_hash': {'algorithm': '0129970b8c7fe034ac8283fb518a06cfbead63d2', 'config': '61bcd2f64860b3dfe2503be88a6bbec165db0754', 'pipeline': '359f2473075ecfd9ae3ce526da96143918517601'}, 'duration': 0.7467091083526611, 'iteration': 19, 'loss': 0.09915720674234607, 'max_history_score': 0.9888888888888889, 'max_history_score_std': 0.022222222222222233, 'max_history_step': 'joint', 'pipeline': {'features': ('features_SelectKBest', {'features__k': 3}), 'normalizer': ('normalizer_RobustScaler', {'normalizer__quantile_range': (...), 'normalizer__with_centering': True, 'normalizer__with_scaling': False}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 7})}, 'score': 0.9008427932576539, ...}, ...], 'history_hash': ['2e6648b63441361b4398cb94f81d2e04a830b2ef', '584343bc020d2d7bc89bd0856bc7770dae1c84fc', 'de121d053e65def047cc8947f505578d5c5eab67', 'b21c9d15a389baa5bfea4c8ddcec129259f37540', 'edd3456355d80775739c31515c832ca7b4e5e094', '0800d7d2c8c10d2f9e7b4e5127b343e916eb742c', 'd98b641879b4754f2169335626a90575e945fd7c', '3f83df36a6abbdf7ea4a4bdcaf6727f23529c2bb', '037fd5c655b39cc7922fb394d736496befcc747b', '6609280032189b59de1afbe36f3acb1d5c273693', '8e1c17ac9f6e03740f380fccb833c9c3931ffc35', '87c03d0cb8e8500e58cacc1a0f27ce54c41a2937', '2ab964abffa0a277a9e2ee9b5570cd258e428b62', '5c95db3ad238063227f1b36e6a006d70c834c5da', '50fd1169b8e42190600f25152654254b5d0e3ed1', 'a05b6d2ffd65d4d937c0b178655d857bf4d61410', 'ebebb7a93116f14f470e062e37582a59f4aeb0df', 'a2c21314ddbba47ddbfe416e0aa14853a71179e0', '6c8a721218e7c550a98c5ba72ad9ff86afd5e3a4', '61bcd2f64860b3dfe2503be88a6bbec165db0754', ...], 'history_index': {'0018716ad6e0edc096329f31492734a67d79d3b3': 64, '01c777816cea234a1e6b73501020cf6f05ea69b9': 111, '01d4ea6f317be786c402492e3b997e2fbf253d6d': 225, '020ec4a49249e6e129cbf2800d975e6e1c8842aa': 92, '037fd5c655b39cc7922fb394d736496befcc747b': 8, '0393a0da80adcc0e64c60f266b4277ec0e84ea81': 141, '0414a55701bd4c21bd4e55ad37a0576c56d56b3f': 94, '04694e3dc0ec7217740bca3ee7723f4509d5fd32': 295, '059454b30e3cc3dfea856c92f07a9c43d4b7ea71': 291, '0650ac92dace31c01ac743925565b952112a5c82': 78, ...}, 'iteration': 298, 'max_history_score': 1.0, 'max_history_score_std': 0.0, 'max_history_step': 'joint'}
        config = {'algorithm': 'RandomForest', 'seed': 42, 'time': 300}
    114 
    115 
    116 def get_baseline_score(algorithm, X, y, seed):
    117     pipeline, _ = pipeline_conf_to_full_pipeline(

...........................................................................
/home/aquemy/dev/dp_hyperparameters/extension/experiment/objective.py in objective(pipeline_config={'features': ('features_SelectKBest', {'features__k': 1}), 'normalizer': ('normalizer_PowerTransformer', {}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 6})}, algo_config={'bootstrap': False, 'criterion': 'entropy', 'max_depth': 4, 'max_features': 3, 'max_leaf_nodes': 5, 'min_samples_split': 2, 'n_estimators': 75}, algorithm='RandomForest', X=array([[1.423e+01, 1.710e+00, 2.430e+00, ..., 1...., ..., 6.100e-01, 1.600e+00,
        5.600e+02]]), y=array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,
       2, 2]), context={'baseline_score': 0.9444100447196423, 'baseline_score_std': 0.04305547117084885, 'best_config': {'algorithm': {'bootstrap': False, 'criterion': 'gini', 'max_depth': 1, 'max_features': 1, 'max_leaf_nodes': 3, 'min_samples_split': 2, 'n_estimators': 50}, 'config_hash': {'algorithm': '41bdc0fd26679e3e9de3f47a81dcebdeb54f6274', 'config': '0ada0978fbb60b78d813177773f684a809a8f7c8', 'pipeline': 'aaf976c7c663a31fa039582d42f9e07101556a7c'}, 'duration': 0.6971359252929688, 'iteration': 62, 'loss': 0.0, 'max_history_score': 1.0, 'max_history_score_std': 0.0, 'max_history_step': 'joint', 'pipeline': {'features': ('features_NoneType', {}), 'normalizer': ('normalizer_PowerTransformer', {}), 'rebalance': ('rebalance_NoneType', {})}, 'score': 1.0, ...}, 'history': [{'algorithm': {'bootstrap': False, 'criterion': 'entropy', 'max_depth': None, 'max_features': 3, 'max_leaf_nodes': 5, 'min_samples_split': 2, 'n_estimators': 50}, 'config_hash': {'algorithm': 'b2c6464add7a35ce8048653a39338c9994de9a4f', 'config': '2e6648b63441361b4398cb94f81d2e04a830b2ef', 'pipeline': '3d44d7482e468d08c4f94457a205f3dac74084c1'}, 'duration': 0.737678050994873, 'iteration': 0, 'loss': 1.0, 'max_history_score': 0.0, 'max_history_score_std': 0.0, 'max_history_step': 'baseline', 'pipeline': {'features': ('features_PCA', {'features__n_components': 1}), 'normalizer': ('normalizer_NoneType', {}), 'rebalance': ('rebalance_CondensedNearestNeighbour', {'rebalance__n_neighbors': 3})}, 'score': 0.0, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'gini', 'max_depth': 1, 'max_features': None, 'max_leaf_nodes': 2, 'min_samples_split': 3, 'n_estimators': 25}, 'config_hash': {'algorithm': '7f71bbbfdb4e8da52b6fc33a43224183117de15e', 'config': '584343bc020d2d7bc89bd0856bc7770dae1c84fc', 'pipeline': '466ffa7ace0e442beb7c311eb214b17a4c6832b3'}, 'duration': 1.5976769924163818, 'iteration': 1, 'loss': 0.40386351909184726, 'max_history_score': 0.5961364809081527, 'max_history_score_std': 0.05351463210025494, 'max_history_step': 'joint', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 3, 'features__selectkbest__k': 3}), 'normalizer': ('normalizer_StandardScaler', {'normalizer__with_mean': True, 'normalizer__with_std': True}), 'rebalance': ('rebalance_NearMiss', {'rebalance__n_neighbors': 2})}, 'score': 0.5961364809081527, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'entropy', 'max_depth': 1, 'max_features': 2, 'max_leaf_nodes': 2, 'min_samples_split': 5, 'n_estimators': 25}, 'config_hash': {'algorithm': '897745a20d929d43e760cacee0a764bd8070daa5', 'config': 'de121d053e65def047cc8947f505578d5c5eab67', 'pipeline': '63040b39b48626a8232e847e8327bdca5cd88611'}, 'duration': 0.815453052520752, 'iteration': 2, 'loss': 0.07327786377708967, 'max_history_score': 0.9267221362229103, 'max_history_score_std': 0.043920207373658794, 'max_history_step': 'joint', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 3, 'features__selectkbest__k': 2}), 'normalizer': ('normalizer_StandardScaler', {'normalizer__with_mean': True, 'normalizer__with_std': True}), 'rebalance': ('rebalance_NoneType', {})}, 'score': 0.9267221362229103, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'entropy', 'max_depth': 4, 'max_features': 3, 'max_leaf_nodes': None, 'min_samples_split': 2, 'n_estimators': 100}, 'config_hash': {'algorithm': 'dbd92c75280ec06b66ca4ad9b135cf36957031a4', 'config': 'b21c9d15a389baa5bfea4c8ddcec129259f37540', 'pipeline': '38866720d2f120c863351493b9b4e23b9a4506dc'}, 'duration': 1.2293269634246826, 'iteration': 3, 'loss': 0.07199862401100798, 'max_history_score': 0.928001375988992, 'max_history_score_std': 0.06518367535896959, 'max_history_step': 'joint', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 2, 'features__selectkbest__k': 4}), 'normalizer': ('normalizer_NoneType', {}), 'rebalance': ('rebalance_NoneType', {})}, 'score': 0.928001375988992, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': 2, 'max_features': None, 'max_leaf_nodes': None, 'min_samples_split': 5, 'n_estimators': 100}, 'config_hash': {'algorithm': 'f455eefd9fdd03ece88892c3f440c580bdf27ddb', 'config': 'edd3456355d80775739c31515c832ca7b4e5e094', 'pipeline': '1d1034f9f0871e43f896c1db4ed6fd572ed0a6ef'}, 'duration': 1.6186630725860596, 'iteration': 4, 'loss': 0.16651831785345705, 'max_history_score': 0.928001375988992, 'max_history_score_std': 0.06518367535896959, 'max_history_step': 'joint', 'pipeline': {'features': ('features_SelectKBest', {'features__k': 4}), 'normalizer': ('normalizer_MinMaxScaler', {}), 'rebalance': ('rebalance_CondensedNearestNeighbour', {'rebalance__n_neighbors': 1})}, 'score': 0.833481682146543, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'entropy', 'max_depth': 1, 'max_features': 2, 'max_leaf_nodes': None, 'min_samples_split': 2, 'n_estimators': 10}, 'config_hash': {'algorithm': '29906eaa0712a68ea145b12821d54ba445726fbf', 'config': '0800d7d2c8c10d2f9e7b4e5127b343e916eb742c', 'pipeline': '2e0f188ae61600352a7159285e0f542b4587a403'}, 'duration': 0.19410085678100586, 'iteration': 5, 'loss': 0.20164258685930514, 'max_history_score': 0.928001375988992, 'max_history_score_std': 0.06518367535896959, 'max_history_step': 'joint', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 3, 'features__selectkbest__k': 4}), 'normalizer': ('normalizer_StandardScaler', {'normalizer__with_mean': True, 'normalizer__with_std': False}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 7})}, 'score': 0.7983574131406949, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': 1, 'max_features': 1, 'max_leaf_nodes': 5, 'min_samples_split': 2, 'n_estimators': 25}, 'config_hash': {'algorithm': 'fbb7d57e38cfc08240f0af985282da418cb33556', 'config': 'd98b641879b4754f2169335626a90575e945fd7c', 'pipeline': '62463de065924498cdcd2f2f1f7e68535cdb33a5'}, 'duration': 0.3625810146331787, 'iteration': 6, 'loss': 0.14327485380116955, 'max_history_score': 0.928001375988992, 'max_history_score_std': 0.06518367535896959, 'max_history_step': 'joint', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 1, 'features__selectkbest__k': 2}), 'normalizer': ('normalizer_NoneType', {}), 'rebalance': ('rebalance_NoneType', {})}, 'score': 0.8567251461988304, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'entropy', 'max_depth': 3, 'max_features': 1, 'max_leaf_nodes': None, 'min_samples_split': 2, 'n_estimators': 75}, 'config_hash': {'algorithm': 'fb2f5d4c4d636edac929e1454ce3d02a4fb134c1', 'config': '3f83df36a6abbdf7ea4a4bdcaf6727f23529c2bb', 'pipeline': '8377b93e334656d1a93d266493b58ef9a6a1786f'}, 'duration': 0.8223779201507568, 'iteration': 7, 'loss': 0.03921568627450989, 'max_history_score': 0.9607843137254901, 'max_history_score_std': 0.043526663832084804, 'max_history_step': 'joint', 'pipeline': {'features': ('features_PCA', {'features__n_components': 3}), 'normalizer': ('normalizer_MinMaxScaler', {}), 'rebalance': ('rebalance_NearMiss', {'rebalance__n_neighbors': 1})}, 'score': 0.9607843137254901, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'gini', 'max_depth': 3, 'max_features': 3, 'max_leaf_nodes': 2, 'min_samples_split': 2, 'n_estimators': 100}, 'config_hash': {'algorithm': '3c3fde6559b918694de4668d025d5418342db1b1', 'config': '037fd5c655b39cc7922fb394d736496befcc747b', 'pipeline': '2a5032814c6c7ed21dd5bd9686923d7fc2f8acc9'}, 'duration': 1.0435099601745605, 'iteration': 8, 'loss': 0.09955925352597172, 'max_history_score': 0.9607843137254901, 'max_history_score_std': 0.043526663832084804, 'max_history_step': 'joint', 'pipeline': {'features': ('features_NoneType', {}), 'normalizer': ('normalizer_RobustScaler', {'normalizer__quantile_range': (...), 'normalizer__with_centering': True, 'normalizer__with_scaling': True}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 7})}, 'score': 0.9004407464740283, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': 2, 'max_features': 1, 'max_leaf_nodes': None, 'min_samples_split': 3, 'n_estimators': 75}, 'config_hash': {'algorithm': '42185be98371e99ac896d2c6c2d69c451cb983ff', 'config': '6609280032189b59de1afbe36f3acb1d5c273693', 'pipeline': '8aab2941fc84d84f86fa56134e50909dbf9e19f5'}, 'duration': 0.9665219783782959, 'iteration': 9, 'loss': 0.01637426900584804, 'max_history_score': 0.983625730994152, 'max_history_score_std': 0.025023500462379746, 'max_history_step': 'joint', 'pipeline': {'features': ('features_NoneType', {}), 'normalizer': ('normalizer_PowerTransformer', {}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 5})}, 'score': 0.983625730994152, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': 1, 'max_features': 3, 'max_leaf_nodes': 2, 'min_samples_split': 3, 'n_estimators': 10}, 'config_hash': {'algorithm': '62a9fe705e4cd96e762bcc9543c4a456a5a9f188', 'config': '8e1c17ac9f6e03740f380fccb833c9c3931ffc35', 'pipeline': '3d44d7482e468d08c4f94457a205f3dac74084c1'}, 'duration': 0.46930503845214844, 'iteration': 10, 'loss': 1.0, 'max_history_score': 0.983625730994152, 'max_history_score_std': 0.025023500462379746, 'max_history_step': 'joint', 'pipeline': {'features': ('features_PCA', {'features__n_components': 1}), 'normalizer': ('normalizer_NoneType', {}), 'rebalance': ('rebalance_CondensedNearestNeighbour', {'rebalance__n_neighbors': 3})}, 'score': 0.0, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'gini', 'max_depth': 4, 'max_features': 1, 'max_leaf_nodes': 3, 'min_samples_split': 2, 'n_estimators': 100}, 'config_hash': {'algorithm': '086d6ca939a757bb32edb113a567f9d38744f061', 'config': '87c03d0cb8e8500e58cacc1a0f27ce54c41a2937', 'pipeline': '8f28ef0f35d97142278f9dacb4e9d1ff082e470f'}, 'duration': 2.1196961402893066, 'iteration': 11, 'loss': 0.15471276229790154, 'max_history_score': 0.983625730994152, 'max_history_score_std': 0.025023500462379746, 'max_history_step': 'joint', 'pipeline': {'features': ('features_PCA', {'features__n_components': 1}), 'normalizer': ('normalizer_StandardScaler', {'normalizer__with_mean': True, 'normalizer__with_std': True}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 7})}, 'score': 0.8452872377020985, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'entropy', 'max_depth': 3, 'max_features': 1, 'max_leaf_nodes': 2, 'min_samples_split': 2, 'n_estimators': 25}, 'config_hash': {'algorithm': '59f64a966796648c7bebade1127fa05541b391ad', 'config': '2ab964abffa0a277a9e2ee9b5570cd258e428b62', 'pipeline': 'eef3f702fd2fed761fa6744c1640d0bf320f1d00'}, 'duration': 0.9828321933746338, 'iteration': 12, 'loss': 0.0778465772273822, 'max_history_score': 0.983625730994152, 'max_history_score_std': 0.025023500462379746, 'max_history_step': 'joint', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 3, 'features__selectkbest__k': 1}), 'normalizer': ('normalizer_PowerTransformer', {}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 6})}, 'score': 0.9221534227726178, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'gini', 'max_depth': 4, 'max_features': 2, 'max_leaf_nodes': 3, 'min_samples_split': 3, 'n_estimators': 75}, 'config_hash': {'algorithm': '6f75c2a196eb9836df2b424e095051192eaed6ea', 'config': '5c95db3ad238063227f1b36e6a006d70c834c5da', 'pipeline': '1eae01a1128bee425c4d4ca0ee97a9afd409680e'}, 'duration': 0.8217771053314209, 'iteration': 13, 'loss': 0.03863089095287242, 'max_history_score': 0.983625730994152, 'max_history_score_std': 0.025023500462379746, 'max_history_step': 'joint', 'pipeline': {'features': ('features_NoneType', {}), 'normalizer': ('normalizer_StandardScaler', {'normalizer__with_mean': False, 'normalizer__with_std': False}), 'rebalance': ('rebalance_NearMiss', {'rebalance__n_neighbors': 1})}, 'score': 0.9613691090471276, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'entropy', 'max_depth': 4, 'max_features': 2, 'max_leaf_nodes': 3, 'min_samples_split': 2, 'n_estimators': 25}, 'config_hash': {'algorithm': '8aef3174f6b8020de06b825e0424c1e54d690afd', 'config': '50fd1169b8e42190600f25152654254b5d0e3ed1', 'pipeline': '9ceaa544911dc6c687e336cb8e9dd4d15ff1ceaf'}, 'duration': 0.40307188034057617, 'iteration': 14, 'loss': 1.0, 'max_history_score': 0.983625730994152, 'max_history_score_std': 0.025023500462379746, 'max_history_step': 'joint', 'pipeline': {'features': ('features_PCA', {'features__n_components': 1}), 'normalizer': ('normalizer_RobustScaler', {'normalizer__quantile_range': (...), 'normalizer__with_centering': False, 'normalizer__with_scaling': False}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 7})}, 'score': 0.0, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'gini', 'max_depth': 1, 'max_features': 1, 'max_leaf_nodes': 3, 'min_samples_split': 3, 'n_estimators': 50}, 'config_hash': {'algorithm': '37be8b6737f4b5d5ae35da51886f302b07ba6001', 'config': 'a05b6d2ffd65d4d937c0b178655d857bf4d61410', 'pipeline': 'cfef88e895db321122f2f7b813d9267b973c2468'}, 'duration': 1.7094659805297852, 'iteration': 15, 'loss': 0.011111111111111072, 'max_history_score': 0.9888888888888889, 'max_history_score_std': 0.022222222222222233, 'max_history_step': 'joint', 'pipeline': {'features': ('features_NoneType', {}), 'normalizer': ('normalizer_NoneType', {}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 5})}, 'score': 0.9888888888888889, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'entropy', 'max_depth': None, 'max_features': 3, 'max_leaf_nodes': None, 'min_samples_split': 2, 'n_estimators': 100}, 'config_hash': {'algorithm': 'c40543ce91793e367c1892c886bc49621c22ecfb', 'config': 'ebebb7a93116f14f470e062e37582a59f4aeb0df', 'pipeline': 'b50c63e800574e8b760f55f7c4ff1fcae8816dd8'}, 'duration': 0.6425540447235107, 'iteration': 16, 'loss': 1.0, 'max_history_score': 0.9888888888888889, 'max_history_score_std': 0.022222222222222233, 'max_history_step': 'joint', 'pipeline': {'features': ('features_PCA', {'features__n_components': 1}), 'normalizer': ('normalizer_PowerTransformer', {}), 'rebalance': ('rebalance_NearMiss', {'rebalance__n_neighbors': 1})}, 'score': 0.0, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'gini', 'max_depth': None, 'max_features': 1, 'max_leaf_nodes': 3, 'min_samples_split': 2, 'n_estimators': 50}, 'config_hash': {'algorithm': '0c69b9601237c20664085fa05764d855e28f98f7', 'config': 'a2c21314ddbba47ddbfe416e0aa14853a71179e0', 'pipeline': '914f81fa4fbb61db251201f32bd8ea11bfeea2a5'}, 'duration': 2.2209739685058594, 'iteration': 17, 'loss': 0.3206720846233231, 'max_history_score': 0.9888888888888889, 'max_history_score_std': 0.022222222222222233, 'max_history_step': 'joint', 'pipeline': {'features': ('features_SelectKBest', {'features__k': 4}), 'normalizer': ('normalizer_PowerTransformer', {}), 'rebalance': ('rebalance_CondensedNearestNeighbour', {'rebalance__n_neighbors': 1})}, 'score': 0.6793279153766769, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': 4, 'max_features': None, 'max_leaf_nodes': None, 'min_samples_split': 3, 'n_estimators': 25}, 'config_hash': {'algorithm': '1aae0f1fce5cab293ffdd4581c4838c8051ac815', 'config': '6c8a721218e7c550a98c5ba72ad9ff86afd5e3a4', 'pipeline': '77189452469cef9c840643f2babe0f825c6667c8'}, 'duration': 0.3951280117034912, 'iteration': 18, 'loss': 0.1804760061919506, 'max_history_score': 0.9888888888888889, 'max_history_score_std': 0.022222222222222233, 'max_history_step': 'joint', 'pipeline': {'features': ('features_SelectKBest', {'features__k': 2}), 'normalizer': ('normalizer_NoneType', {}), 'rebalance': ('rebalance_NearMiss', {'rebalance__n_neighbors': 1})}, 'score': 0.8195239938080494, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': None, 'max_features': 3, 'max_leaf_nodes': 5, 'min_samples_split': 3, 'n_estimators': 50}, 'config_hash': {'algorithm': '0129970b8c7fe034ac8283fb518a06cfbead63d2', 'config': '61bcd2f64860b3dfe2503be88a6bbec165db0754', 'pipeline': '359f2473075ecfd9ae3ce526da96143918517601'}, 'duration': 0.7467091083526611, 'iteration': 19, 'loss': 0.09915720674234607, 'max_history_score': 0.9888888888888889, 'max_history_score_std': 0.022222222222222233, 'max_history_step': 'joint', 'pipeline': {'features': ('features_SelectKBest', {'features__k': 3}), 'normalizer': ('normalizer_RobustScaler', {'normalizer__quantile_range': (...), 'normalizer__with_centering': True, 'normalizer__with_scaling': False}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 7})}, 'score': 0.9008427932576539, ...}, ...], 'history_hash': ['2e6648b63441361b4398cb94f81d2e04a830b2ef', '584343bc020d2d7bc89bd0856bc7770dae1c84fc', 'de121d053e65def047cc8947f505578d5c5eab67', 'b21c9d15a389baa5bfea4c8ddcec129259f37540', 'edd3456355d80775739c31515c832ca7b4e5e094', '0800d7d2c8c10d2f9e7b4e5127b343e916eb742c', 'd98b641879b4754f2169335626a90575e945fd7c', '3f83df36a6abbdf7ea4a4bdcaf6727f23529c2bb', '037fd5c655b39cc7922fb394d736496befcc747b', '6609280032189b59de1afbe36f3acb1d5c273693', '8e1c17ac9f6e03740f380fccb833c9c3931ffc35', '87c03d0cb8e8500e58cacc1a0f27ce54c41a2937', '2ab964abffa0a277a9e2ee9b5570cd258e428b62', '5c95db3ad238063227f1b36e6a006d70c834c5da', '50fd1169b8e42190600f25152654254b5d0e3ed1', 'a05b6d2ffd65d4d937c0b178655d857bf4d61410', 'ebebb7a93116f14f470e062e37582a59f4aeb0df', 'a2c21314ddbba47ddbfe416e0aa14853a71179e0', '6c8a721218e7c550a98c5ba72ad9ff86afd5e3a4', '61bcd2f64860b3dfe2503be88a6bbec165db0754', ...], 'history_index': {'0018716ad6e0edc096329f31492734a67d79d3b3': 64, '01c777816cea234a1e6b73501020cf6f05ea69b9': 111, '01d4ea6f317be786c402492e3b997e2fbf253d6d': 225, '020ec4a49249e6e129cbf2800d975e6e1c8842aa': 92, '037fd5c655b39cc7922fb394d736496befcc747b': 8, '0393a0da80adcc0e64c60f266b4277ec0e84ea81': 141, '0414a55701bd4c21bd4e55ad37a0576c56d56b3f': 94, '04694e3dc0ec7217740bca3ee7723f4509d5fd32': 295, '059454b30e3cc3dfea856c92f07a9c43d4b7ea71': 291, '0650ac92dace31c01ac743925565b952112a5c82': 78, ...}, 'iteration': 298, 'max_history_score': 1.0, 'max_history_score_std': 0.0, 'max_history_step': 'joint'}, config={'algorithm': 'RandomForest', 'seed': 42, 'time': 300}, step='joint')
     45                 y,
     46                 cv=10,
     47                 n_jobs=-1,
     48                 return_estimator=False,
     49                 return_train_score=False,
---> 50                 verbose=0)
     51         score = np.mean(scores['test_score'])
     52         std = np.std(scores['test_score'])
     53         status = STATUS_OK
     54     except Exception as e:

...........................................................................
/home/aquemy/.local/lib/python2.7/site-packages/sklearn/model_selection/_validation.py in cross_validate(estimator=Pipeline(memory=None,
     steps=[('rebalance', ...e=42,
            verbose=0, warm_start=False))]), X=array([[1.423e+01, 1.710e+00, 2.430e+00, ..., 1...., ..., 6.100e-01, 1.600e+00,
        5.600e+02]]), y=array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,
       2, 2]), groups=None, scoring=None, cv=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1, verbose=0, fit_params=None, pre_dispatch='2*n_jobs', return_train_score=False, return_estimator=False, error_score='raise-deprecating')
    235         delayed(_fit_and_score)(
    236             clone(estimator), X, y, scorers, train, test, verbose, None,
    237             fit_params, return_train_score=return_train_score,
    238             return_times=True, return_estimator=return_estimator,
    239             error_score=error_score)
--> 240         for train, test in cv.split(X, y, groups))
        cv.split = <bound method StratifiedKFold.split of Stratifie...d(n_splits=10, random_state=None, shuffle=False)>
        X = array([[1.423e+01, 1.710e+00, 2.430e+00, ..., 1...., ..., 6.100e-01, 1.600e+00,
        5.600e+02]])
        y = array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,
       2, 2])
        groups = None
    241 
    242     zipped_scores = list(zip(*scores))
    243     if return_train_score:
    244         train_scores = zipped_scores.pop(0)

...........................................................................
/home/aquemy/.local/lib/python2.7/site-packages/sklearn/externals/joblib/parallel.py in __call__(self=Parallel(n_jobs=-1), iterable=<generator object <genexpr>>)
    925                 # No need to wait for async callbacks to trigger to
    926                 # consumption.
    927                 self._iterating = False
    928 
    929             with self._backend.retrieval_context():
--> 930                 self.retrieve()
        self.retrieve = <bound method Parallel.retrieve of Parallel(n_jobs=-1)>
    931             # Make sure that we get a last message telling us we are done
    932             elapsed_time = time.time() - self._start_time
    933             self._print('Done %3i out of %3i | elapsed: %s finished',
    934                         (len(self._output), len(self._output),

---------------------------------------------------------------------------
Joblib worker traceback:
---------------------------------------------------------------------------
ValueError                                         Mon Jun 17 12:49:47 2019
PID: 15690                                  Python 2.7.15+: /usr/bin/python
...........................................................................
/home/aquemy/.local/lib/python2.7/site-packages/sklearn/externals/joblib/parallel.py in __call__(self=<sklearn.externals.joblib.parallel.BatchedCalls object>)
    220     def __call__(self):
    221         # Set the default nested backend to self._backend but do not set the
    222         # change the default number of processes to -1
    223         with parallel_backend(self._backend, n_jobs=self._n_jobs):
    224             return [func(*args, **kwargs)
--> 225                     for func, args, kwargs in self.items]
        func = <function _fit_and_score>
        args = (Pipeline(memory=None,
     steps=[('rebalance', ...e=42,
            verbose=0, warm_start=False))]), array([[1.423e+01, 1.710e+00, 2.430e+00, ..., 1...., ..., 6.100e-01, 1.600e+00,
        5.600e+02]]), array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,
       2, 2]), {'score': <function _passthrough_scorer>}, array([  6,   7,   8,   9,  10,  11,  12,  13,  ..., 170, 171, 172, 173, 174,
       175, 176, 177]), array([  0,   1,   2,   3,   4,   5,  59,  60,  ...,  64,  65,
        66, 130, 131, 132, 133, 134]), 0, None, None)
        kwargs = {'error_score': 'raise-deprecating', 'return_estimator': False, 'return_times': True, 'return_train_score': False}
        self.items = [(<function _fit_and_score>, (Pipeline(memory=None,
     steps=[('rebalance', ...e=42,
            verbose=0, warm_start=False))]), array([[1.423e+01, 1.710e+00, 2.430e+00, ..., 1...., ..., 6.100e-01, 1.600e+00,
        5.600e+02]]), array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,
       2, 2]), {'score': <function _passthrough_scorer>}, array([  6,   7,   8,   9,  10,  11,  12,  13,  ..., 170, 171, 172, 173, 174,
       175, 176, 177]), array([  0,   1,   2,   3,   4,   5,  59,  60,  ...,  64,  65,
        66, 130, 131, 132, 133, 134]), 0, None, None), {'error_score': 'raise-deprecating', 'return_estimator': False, 'return_times': True, 'return_train_score': False})]
    226 
    227     def __len__(self):
    228         return self._size
    229 

...........................................................................
/home/aquemy/.local/lib/python2.7/site-packages/sklearn/model_selection/_validation.py in _fit_and_score(estimator=Pipeline(memory=None,
     steps=[('rebalance', ...e=42,
            verbose=0, warm_start=False))]), X=array([[1.423e+01, 1.710e+00, 2.430e+00, ..., 1...., ..., 6.100e-01, 1.600e+00,
        5.600e+02]]), y=array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,
       2, 2]), scorer={'score': <function _passthrough_scorer>}, train=array([  6,   7,   8,   9,  10,  11,  12,  13,  ..., 170, 171, 172, 173, 174,
       175, 176, 177]), test=array([  0,   1,   2,   3,   4,   5,  59,  60,  ...,  64,  65,
        66, 130, 131, 132, 133, 134]), verbose=0, parameters=None, fit_params={}, return_train_score=False, return_parameters=False, return_n_test_samples=False, return_times=True, return_estimator=False, error_score='raise-deprecating')
    523 
    524     try:
    525         if y_train is None:
    526             estimator.fit(X_train, **fit_params)
    527         else:
--> 528             estimator.fit(X_train, y_train, **fit_params)
        estimator.fit = <bound method Pipeline.fit of Pipeline(memory=No...=42,
            verbose=0, warm_start=False))])>
        X_train = array([[1.439e+01, 1.870e+00, 2.450e+00, ..., 1...., ..., 6.100e-01, 1.600e+00,
        5.600e+02]])
        y_train = array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...2, 2, 2, 2, 2, 2, 2, 2, 2,
       2, 2, 2, 2, 2])
        fit_params = {}
    529 
    530     except Exception as e:
    531         # Note fit time as time until error
    532         fit_time = time.time() - start_time

...........................................................................
/usr/local/lib/python2.7/dist-packages/imblearn/pipeline.py in fit(self=Pipeline(memory=None,
     steps=[('rebalance', ...e=42,
            verbose=0, warm_start=False))]), X=array([[1.439e+01, 1.870e+00, 2.450e+00, ..., 1...., ..., 6.100e-01, 1.600e+00,
        5.600e+02]]), y=array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...2, 2, 2, 2, 2, 2, 2, 2, 2,
       2, 2, 2, 2, 2]), **fit_params={})
    234             This estimator
    235 
    236         """
    237         Xt, yt, fit_params = self._fit(X, y, **fit_params)
    238         if self._final_estimator is not None:
--> 239             self._final_estimator.fit(Xt, yt, **fit_params)
        self._final_estimator.fit = <bound method RandomForestClassifier.fit of Rand...ate=42,
            verbose=0, warm_start=False)>
        Xt = array([[ 0.62198548],
       [ 0.61318429],
    ...9 ],
       [-1.44697927],
       [-0.99502602]])
        yt = array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...2,
       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2])
        fit_params = {}
    240         return self
    241 
    242     def fit_transform(self, X, y=None, **fit_params):
    243         """Fit the model and transform with the final estimator

...........................................................................
/home/aquemy/.local/lib/python2.7/site-packages/sklearn/ensemble/forest.py in fit(self=RandomForestClassifier(bootstrap=False, class_we...tate=42,
            verbose=0, warm_start=False), X=array([[ 0.6219855 ],
       [ 0.6131843 ],
    ....4469793 ],
       [-0.995026  ]], dtype=float32), y=array([[0.],
       [0.],
       [0.],
       [0...    [2.],
       [2.],
       [2.],
       [2.]]), sample_weight=None)
    328             trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,
    329                              **_joblib_parallel_args(prefer='threads'))(
    330                 delayed(_parallel_build_trees)(
    331                     t, self, X, y, sample_weight, i, len(trees),
    332                     verbose=self.verbose, class_weight=self.class_weight)
--> 333                 for i, t in enumerate(trees))
        i = 74
    334 
    335             # Collect newly grown trees
    336             self.estimators_.extend(trees)
    337 

...........................................................................
/home/aquemy/.local/lib/python2.7/site-packages/sklearn/externals/joblib/parallel.py in __call__(self=Parallel(n_jobs=1), iterable=<generator object <genexpr>>)
    912             # self._original_iterator is None, then this means either
    913             # that pre_dispatch == "all", n_jobs == 1 or that the first batch
    914             # was very quick and its callback already dispatched all the
    915             # remaining jobs.
    916             self._iterating = False
--> 917             if self.dispatch_one_batch(iterator):
        self.dispatch_one_batch = <bound method Parallel.dispatch_one_batch of Parallel(n_jobs=1)>
        iterator = <generator object <genexpr>>
    918                 self._iterating = self._original_iterator is not None
    919 
    920             while self.dispatch_one_batch(iterator):
    921                 pass

...........................................................................
/home/aquemy/.local/lib/python2.7/site-packages/sklearn/externals/joblib/parallel.py in dispatch_one_batch(self=Parallel(n_jobs=1), iterator=<generator object <genexpr>>)
    754                                  self._pickle_cache)
    755             if len(tasks) == 0:
    756                 # No more tasks available in the iterator: tell caller to stop.
    757                 return False
    758             else:
--> 759                 self._dispatch(tasks)
        self._dispatch = <bound method Parallel._dispatch of Parallel(n_jobs=1)>
        tasks = <sklearn.externals.joblib.parallel.BatchedCalls object>
    760                 return True
    761 
    762     def _print(self, msg, msg_args):
    763         """Display the message on stout or stderr depending on verbosity"""

...........................................................................
/home/aquemy/.local/lib/python2.7/site-packages/sklearn/externals/joblib/parallel.py in _dispatch(self=Parallel(n_jobs=1), batch=<sklearn.externals.joblib.parallel.BatchedCalls object>)
    711 
    712         dispatch_timestamp = time.time()
    713         cb = BatchCompletionCallBack(dispatch_timestamp, len(batch), self)
    714         with self._lock:
    715             job_idx = len(self._jobs)
--> 716             job = self._backend.apply_async(batch, callback=cb)
        job = undefined
        self._backend.apply_async = <bound method SequentialBackend.apply_async of <...lib._parallel_backends.SequentialBackend object>>
        batch = <sklearn.externals.joblib.parallel.BatchedCalls object>
        cb = <sklearn.externals.joblib.parallel.BatchCompletionCallBack object>
    717             # A job can complete so quickly than its callback is
    718             # called before we get here, causing self._jobs to
    719             # grow. To ensure correct results ordering, .insert is
    720             # used (rather than .append) in the following line

...........................................................................
/home/aquemy/.local/lib/python2.7/site-packages/sklearn/externals/joblib/_parallel_backends.py in apply_async(self=<sklearn.externals.joblib._parallel_backends.SequentialBackend object>, func=<sklearn.externals.joblib.parallel.BatchedCalls object>, callback=<sklearn.externals.joblib.parallel.BatchCompletionCallBack object>)
    177             raise ValueError('n_jobs == 0 in Parallel has no meaning')
    178         return 1
    179 
    180     def apply_async(self, func, callback=None):
    181         """Schedule a func to be run"""
--> 182         result = ImmediateResult(func)
        result = undefined
        func = <sklearn.externals.joblib.parallel.BatchedCalls object>
    183         if callback:
    184             callback(result)
    185         return result
    186 

...........................................................................
/home/aquemy/.local/lib/python2.7/site-packages/sklearn/externals/joblib/_parallel_backends.py in __init__(self=<sklearn.externals.joblib._parallel_backends.ImmediateResult object>, batch=<sklearn.externals.joblib.parallel.BatchedCalls object>)
    544 
    545 class ImmediateResult(object):
    546     def __init__(self, batch):
    547         # Don't delay the application, to avoid keeping the input
    548         # arguments in memory
--> 549         self.results = batch()
        self.results = undefined
        batch = <sklearn.externals.joblib.parallel.BatchedCalls object>
    550 
    551     def get(self):
    552         return self.results
    553 

...........................................................................
/home/aquemy/.local/lib/python2.7/site-packages/sklearn/externals/joblib/parallel.py in __call__(self=<sklearn.externals.joblib.parallel.BatchedCalls object>)
    220     def __call__(self):
    221         # Set the default nested backend to self._backend but do not set the
    222         # change the default number of processes to -1
    223         with parallel_backend(self._backend, n_jobs=self._n_jobs):
    224             return [func(*args, **kwargs)
--> 225                     for func, args, kwargs in self.items]
        func = <function _parallel_build_trees>
        args = (DecisionTreeClassifier(class_weight=None, criter...=False, random_state=1608637542, splitter='best'), RandomForestClassifier(bootstrap=False, class_we...tate=42,
            verbose=0, warm_start=False), array([[ 0.6219855 ],
       [ 0.6131843 ],
    ....4469793 ],
       [-0.995026  ]], dtype=float32), array([[0.],
       [0.],
       [0.],
       [0...    [2.],
       [2.],
       [2.],
       [2.]]), None, 0, 75)
        kwargs = {'class_weight': None, 'verbose': 0}
        self.items = [(<function _parallel_build_trees>, (DecisionTreeClassifier(class_weight=None, criter...=False, random_state=1608637542, splitter='best'), RandomForestClassifier(bootstrap=False, class_we...tate=42,
            verbose=0, warm_start=False), array([[ 0.6219855 ],
       [ 0.6131843 ],
    ....4469793 ],
       [-0.995026  ]], dtype=float32), array([[0.],
       [0.],
       [0.],
       [0...    [2.],
       [2.],
       [2.],
       [2.]]), None, 0, 75), {'class_weight': None, 'verbose': 0})]
    226 
    227     def __len__(self):
    228         return self._size
    229 

...........................................................................
/home/aquemy/.local/lib/python2.7/site-packages/sklearn/ensemble/forest.py in _parallel_build_trees(tree=DecisionTreeClassifier(class_weight=None, criter...=False, random_state=1608637542, splitter='best'), forest=RandomForestClassifier(bootstrap=False, class_we...tate=42,
            verbose=0, warm_start=False), X=array([[ 0.6219855 ],
       [ 0.6131843 ],
    ....4469793 ],
       [-0.995026  ]], dtype=float32), y=array([[0.],
       [0.],
       [0.],
       [0...    [2.],
       [2.],
       [2.],
       [2.]]), sample_weight=None, tree_idx=0, n_trees=75, verbose=0, class_weight=None)
    116         elif class_weight == 'balanced_subsample':
    117             curr_sample_weight *= compute_sample_weight('balanced', y, indices)
    118 
    119         tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)
    120     else:
--> 121         tree.fit(X, y, sample_weight=sample_weight, check_input=False)
        tree.fit = <bound method DecisionTreeClassifier.fit of Deci...False, random_state=1608637542, splitter='best')>
        X = array([[ 0.6219855 ],
       [ 0.6131843 ],
    ....4469793 ],
       [-0.995026  ]], dtype=float32)
        y = array([[0.],
       [0.],
       [0.],
       [0...    [2.],
       [2.],
       [2.],
       [2.]])
        sample_weight = None
    122 
    123     return tree
    124 
    125 

...........................................................................
/home/aquemy/.local/lib/python2.7/site-packages/sklearn/tree/tree.py in fit(self=DecisionTreeClassifier(class_weight=None, criter...=False, random_state=1608637542, splitter='best'), X=array([[ 0.6219855 ],
       [ 0.6131843 ],
    ....4469793 ],
       [-0.995026  ]], dtype=float32), y=array([[0.],
       [0.],
       [0.],
       [0...    [2.],
       [2.],
       [2.],
       [2.]]), sample_weight=None, check_input=False, X_idx_sorted=None)
    796 
    797         super(DecisionTreeClassifier, self).fit(
    798             X, y,
    799             sample_weight=sample_weight,
    800             check_input=check_input,
--> 801             X_idx_sorted=X_idx_sorted)
        X_idx_sorted = None
    802         return self
    803 
    804     def predict_proba(self, X, check_input=True):
    805         """Predict class probabilities of the input samples X.

...........................................................................
/home/aquemy/.local/lib/python2.7/site-packages/sklearn/tree/tree.py in fit(self=DecisionTreeClassifier(class_weight=None, criter...=False, random_state=1608637542, splitter='best'), X=array([[ 0.6219855 ],
       [ 0.6131843 ],
    ....4469793 ],
       [-0.995026  ]], dtype=float32), y=array([[0.],
       [0.],
       [0.],
       [0...    [2.],
       [2.],
       [2.],
       [2.]]), sample_weight=None, check_input=False, X_idx_sorted=None)
    237         if not 0 <= self.min_weight_fraction_leaf <= 0.5:
    238             raise ValueError("min_weight_fraction_leaf must in [0, 0.5]")
    239         if max_depth <= 0:
    240             raise ValueError("max_depth must be greater than zero. ")
    241         if not (0 < max_features <= self.n_features_):
--> 242             raise ValueError("max_features must be in (0, n_features]")
    243         if not isinstance(max_leaf_nodes, (numbers.Integral, np.integer)):
    244             raise ValueError("max_leaf_nodes must be integral number but was "
    245                              "%r" % max_leaf_nodes)
    246         if -1 < max_leaf_nodes < 2:

ValueError: max_features must be in (0, n_features]
___________________________________________________________________________
Best score: 1.0 (0.0) [J] | Score: 0.0 (0.0) [J]
Best score: 1.0 (0.0) [J] | Score: 0.994444444444 (0.0166666666667) [J]
Best score: 1.0 (0.0) [J] | Score: 0.994444444444 (0.0166666666667) [J]
Best score: 1.0 (0.0) [J] | Score: 0.881800395597 (0.0884062941077) [J]
Best score: 1.0 (0.0) [J] | Score: 0.720695734434 (0.0671397550011) [J]
Best score: 1.0 (0.0) [J] | Score: 0.977743378053 (0.0272938784642) [J]
Best score: 1.0 (0.0) [J] | Score: 0.702087633299 (0.148990566365) [J]
Best score: 1.0 (0.0) [J] | Score: 0.954826711386 (0.0546385737948) [J]
Best score: 1.0 (0.0) [J] | Score: 0.824787151703 (0.0973439662711) [J]
Best score: 1.0 (0.0) [J] | Score: 0.927231682147 (0.084960373988) [J]
Best score: 1.0 (0.0) [J] | Score: 0.939404884761 (0.0744278828567) [J]
Best score: 1.0 (0.0) [J] | Score: 0.994444444444 (0.0166666666667) [J]
Best score: 1.0 (0.0) [J] | Score: 0.827816477468 (0.111716462883) [J]
Best score: 1.0 (0.0) [J] | Score: 0.837186102511 (0.109201903358) [J]
Best score: 1.0 (0.0) [J] | Score: 0.994444444444 (0.0166666666667) [J]
Best score: 1.0 (0.0) [J] | Score: 0.988888888889 (0.0222222222222) [J]
Best score: 1.0 (0.0) [J] | Score: 0.950257997936 (0.0574523705971) [J]
Best score: 1.0 (0.0) [J] | Score: 0.966924664603 (0.0358608716643) [J]
Best score: 1.0 (0.0) [J] | Score: 0.811885104919 (0.117517587535) [J]
Best score: 1.0 (0.0) [J] | Score: 0.983918128655 (0.0340301135812) [J]
Best score: 1.0 (0.0) [J] | Score: 0.911334709322 (0.070471564125) [J]
Best score: 1.0 (0.0) [J] | Score: 0.839622033024 (0.0999392447379) [J]
Best score: 1.0 (0.0) [J] | Score: 0.994444444444 (0.0166666666667) [J]
Best score: 1.0 (0.0) [J] | Score: 0.927048933609 (0.0353178643097) [J]
Best score: 1.0 (0.0) [J] | Score: 0.781546697626 (0.130226202121) [J]
Best score: 1.0 (0.0) [J] | Score: 0.954826711386 (0.0546385737948) [J]
Best score: 1.0 (0.0) [J] | Score: 0.966924664603 (0.0358608716643) [J]
Best score: 1.0 (0.0) [J] | Score: 0.827564929481 (0.0953479301862) [J]
Best score: 1.0 (0.0) [J] | Score: 0.95522875817 (0.0485170314967) [J]
Best score: 1.0 (0.0) [J] | Score: 0.988888888889 (0.0222222222222) [J]
Best score: 1.0 (0.0) [J] | Score: 0.830377106983 (0.116883561827) [J]
#################### STEP RESULT ####################
BEST PIPELINE:
 {
    "features": [
        "features_NoneType", 
        {}
    ], 
    "normalizer": [
        "normalizer_PowerTransformer", 
        {}
    ], 
    "rebalance": [
        "rebalance_NoneType", 
        {}
    ]
}
BEST ALGO CONFIG:
 {
    "bootstrap": false, 
    "criterion": "gini", 
    "max_depth": 1, 
    "max_features": 1, 
    "max_leaf_nodes": 3, 
    "min_samples_split": 2, 
    "n_estimators": 50
}
BEST SCORE: 1.0 (0.0)
##################################################
