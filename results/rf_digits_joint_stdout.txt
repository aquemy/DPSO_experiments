SCENARIO:
 {
    "control": {
        "seed": 42
    }, 
    "file_name": "rf_digits_joint", 
    "policy": null, 
    "setup": {
        "algorithm": "RandomForest", 
        "dataset": "digits", 
        "policy": "joint", 
        "runtime": 300
    }, 
    "title": "Random Forest on Digits with Joint policy"
}
Best score: 0.339712048089 (0.033465429491) [J] | Score: 0.339712048089 (0.033465429491) [J]
Best score: 0.487780389826 (0.0548607975922) [J] | Score: 0.487780389826 (0.0548607975922) [J]
Best score: 0.616807358247 (0.05286679173) [J] | Score: 0.616807358247 (0.05286679173) [J]
Best score: 0.616807358247 (0.05286679173) [J] | Score: 0.323115901222 (0.0637755487612) [J]
Best score: 0.745519104943 (0.0484344830817) [J] | Score: 0.745519104943 (0.0484344830817) [J]
Best score: 0.745519104943 (0.0484344830817) [J] | Score: 0.468448981242 (0.0592009972987) [J]
Best score: 0.8552867039 (0.0221373079127) [J] | Score: 0.8552867039 (0.0221373079127) [J]
Best score: 0.8552867039 (0.0221373079127) [J] | Score: 0.38413879506 (0.0523047252391) [J]
Best score: 0.8552867039 (0.0221373079127) [J] | Score: 0.593263364516 (0.0653227408258) [J]
Best score: 0.8552867039 (0.0221373079127) [J] | Score: 0.303408997961 (0.0445502015263) [J]
Best score: 0.8552867039 (0.0221373079127) [J] | Score: 0.231298370902 (0.0687095714092) [J]
Best score: 0.8552867039 (0.0221373079127) [J] | Score: 0.368618126262 (0.0324001477736) [J]
Best score: 0.8552867039 (0.0221373079127) [J] | Score: 0.387975680865 (0.0478432672794) [J]
Best score: 0.8552867039 (0.0221373079127) [J] | Score: 0.372857261701 (0.0341646858526) [J]
Best score: 0.8552867039 (0.0221373079127) [J] | Score: 0.31689544273 (0.0494296082453) [J]
Best score: 0.8552867039 (0.0221373079127) [J] | Score: 0.30785789088 (0.0291454605573) [J]
JoblibValueError
___________________________________________________________________________
...........................................................................
/home/aquemy/dev/dp_hyperparameters/extension/main.py in <module>()
     27 
     28     serializer.serialize_results(scenario, policy)
     29 
     30 if __name__ == "__main__":
     31     args = cli.parse_args()
---> 32     main(args)

...........................................................................
/home/aquemy/dev/dp_hyperparameters/extension/main.py in main(args=Namespace(customize=[(['control', 'seed'], '42')...='./scenarios/rf_digits_joint.yaml', verbosity=0))
     21         test_size=0.4, 
     22         random_state=scenario['control']['seed']
     23     )
     24 
     25     policy = policies.initiate(scenario['setup']['policy'], config)
---> 26     policy.run(X,y)
        policy.run = <bound method Joint.run of <experiment.policies.joint.Joint object>>
        X = array([[ 0.,  0.,  5., ...,  0.,  0.,  0.],
    ...0.],
       [ 0.,  0., 10., ..., 12.,  1.,  0.]])
        y = array([0, 1, 2, ..., 8, 9, 8])
     27 
     28     serializer.serialize_results(scenario, policy)
     29 
     30 if __name__ == "__main__":

...........................................................................
/home/aquemy/dev/dp_hyperparameters/extension/experiment/policies/joint.py in run(self=<experiment.policies.joint.Joint object>, X=array([[ 0.,  0.,  5., ...,  0.,  0.,  0.],
    ...0.],
       [ 0.,  0., 10., ..., 12.,  1.,  0.]]), y=array([0, 1, 2, ..., 8, 9, 8]))
     32             algo=tpe.suggest, 
     33             max_evals=None,
     34             max_time=self.config['time'],     
     35             trials=trials,
     36             show_progressbar=False,
---> 37             verbose=0
     38         )
     39 
     40         best_config = self.context['best_config']
     41         super(Joint, self).display_step_results(best_config)

...........................................................................
/home/aquemy/dev/dp_hyperparameters/extension/hyperopt/fmin.py in fmin(fn=<functools.partial object>, space={'algorithm': {'bootstrap': <hyperopt.pyll.base.Apply object>, 'criterion': <hyperopt.pyll.base.Apply object>, 'max_depth': <hyperopt.pyll.base.Apply object>, 'max_features': <hyperopt.pyll.base.Apply object>, 'max_leaf_nodes': <hyperopt.pyll.base.Apply object>, 'min_samples_split': <hyperopt.pyll.base.Apply object>, 'n_estimators': <hyperopt.pyll.base.Apply object>}, 'pipeline': {'features': <hyperopt.pyll.base.Apply object>, 'normalizer': <hyperopt.pyll.base.Apply object>, 'rebalance': <hyperopt.pyll.base.Apply object>}}, algo=<function suggest>, max_evals=9223372036854775807, max_time=300, trials=<hyperopt.base.Trials object>, rstate=<mtrand.RandomState object>, allow_trials_fmin=True, pass_expr_memo_ctrl=None, catch_eval_exceptions=False, verbose=0, return_argmin=True, points_to_evaluate=None, max_queue_len=1, show_progressbar=False)
    406             pass_expr_memo_ctrl=pass_expr_memo_ctrl,
    407             verbose=verbose,
    408             catch_eval_exceptions=catch_eval_exceptions,
    409             return_argmin=return_argmin,
    410             show_progressbar=show_progressbar,
--> 411             max_time=max_time
        max_time = 300
    412         )
    413 
    414     if trials is None:
    415         if points_to_evaluate is None:

...........................................................................
/home/aquemy/dev/dp_hyperparameters/extension/hyperopt/base.py in fmin(self=<hyperopt.base.Trials object>, fn=<functools.partial object>, space={'algorithm': {'bootstrap': <hyperopt.pyll.base.Apply object>, 'criterion': <hyperopt.pyll.base.Apply object>, 'max_depth': <hyperopt.pyll.base.Apply object>, 'max_features': <hyperopt.pyll.base.Apply object>, 'max_leaf_nodes': <hyperopt.pyll.base.Apply object>, 'min_samples_split': <hyperopt.pyll.base.Apply object>, 'n_estimators': <hyperopt.pyll.base.Apply object>}, 'pipeline': {'features': <hyperopt.pyll.base.Apply object>, 'normalizer': <hyperopt.pyll.base.Apply object>, 'rebalance': <hyperopt.pyll.base.Apply object>}}, algo=<function suggest>, max_evals=9223372036854775807, max_time=300, rstate=<mtrand.RandomState object>, verbose=0, pass_expr_memo_ctrl=None, catch_eval_exceptions=False, return_argmin=True, show_progressbar=False)
    636             verbose=verbose,
    637             allow_trials_fmin=False,  # -- prevent recursion
    638             pass_expr_memo_ctrl=pass_expr_memo_ctrl,
    639             catch_eval_exceptions=catch_eval_exceptions,
    640             return_argmin=return_argmin,
--> 641             show_progressbar=show_progressbar)
        show_progressbar = False
    642 
    643 
    644 def trials_from_docs(docs, validate=True, **kwargs):
    645     """Construct a Trials base class instance from a list of trials documents

...........................................................................
/home/aquemy/dev/dp_hyperparameters/extension/hyperopt/fmin.py in fmin(fn=<functools.partial object>, space={'algorithm': {'bootstrap': <hyperopt.pyll.base.Apply object>, 'criterion': <hyperopt.pyll.base.Apply object>, 'max_depth': <hyperopt.pyll.base.Apply object>, 'max_features': <hyperopt.pyll.base.Apply object>, 'max_leaf_nodes': <hyperopt.pyll.base.Apply object>, 'min_samples_split': <hyperopt.pyll.base.Apply object>, 'n_estimators': <hyperopt.pyll.base.Apply object>}, 'pipeline': {'features': <hyperopt.pyll.base.Apply object>, 'normalizer': <hyperopt.pyll.base.Apply object>, 'rebalance': <hyperopt.pyll.base.Apply object>}}, algo=<function suggest>, max_evals=9223372036854775807, max_time=300, trials=<hyperopt.base.Trials object>, rstate=<mtrand.RandomState object>, allow_trials_fmin=False, pass_expr_memo_ctrl=None, catch_eval_exceptions=False, verbose=0, return_argmin=True, points_to_evaluate=None, max_queue_len=1, show_progressbar=False)
    426                     verbose=verbose,
    427                     max_queue_len=max_queue_len,
    428                     show_progressbar=show_progressbar,
    429                     max_time=max_time)
    430     rval.catch_eval_exceptions = catch_eval_exceptions
--> 431     rval.exhaust()
        rval.exhaust = <bound method FMinIter.exhaust of <hyperopt.fmin.FMinIter object>>
    432     if return_argmin:
    433         return trials.argmin
    434     elif len(trials) > 0:
    435         # Only if there are some succesfull trail runs, return the best point in the evaluation space

...........................................................................
/home/aquemy/dev/dp_hyperparameters/extension/hyperopt/fmin.py in exhaust(self=<hyperopt.fmin.FMinIter object>)
    273             raise StopIteration()
    274         return self.trials
    275 
    276     def exhaust(self):
    277         n_done = len(self.trials)
--> 278         self.run(self.max_evals - n_done, block_until_done=self.asynchronous)
        self.run = <bound method FMinIter.run of <hyperopt.fmin.FMinIter object>>
        self.max_evals = 9223372036854775807
        n_done = 0
        self.asynchronous = False
    279         self.trials.refresh()
    280         return self
    281 
    282 

...........................................................................
/home/aquemy/dev/dp_hyperparameters/extension/hyperopt/fmin.py in run(self=<hyperopt.fmin.FMinIter object>, N=9223372036854775807, block_until_done=False)
    232                     if self.asynchronous:
    233                         # -- wait for workers to fill in the trials
    234                         time.sleep(self.poll_interval_secs)
    235                     else:
    236                         # -- loop over trials and do the jobs directly
--> 237                         self.serial_evaluate()
        self.serial_evaluate = <bound method FMinIter.serial_evaluate of <hyperopt.fmin.FMinIter object>>
    238                     try:
    239                         res = [d['result']['loss'] for d in
    240                                          self.trials.trials if
    241                                          d['result']['status'] == 'ok']

...........................................................................
/home/aquemy/dev/dp_hyperparameters/extension/hyperopt/fmin.py in serial_evaluate(self=<hyperopt.fmin.FMinIter object>, N=-1)
    138                 trial['book_time'] = now
    139                 trial['refresh_time'] = now
    140                 spec = base.spec_from_misc(trial['misc'])
    141                 ctrl = base.Ctrl(self.trials, current_trial=trial)
    142                 try:
--> 143                     result = self.domain.evaluate(spec, ctrl)
        result = undefined
        self.domain.evaluate = <bound method Domain.evaluate of <hyperopt.base.Domain object>>
        spec = {'bootstrap': 1, 'criterion': 1, 'features': 1, 'features_PCA_features__n_components': 1, 'max_depth': 1, 'max_features': 2, 'max_leaf_nodes': 1, 'min_samples_split': 0, 'n_estimators': 3, 'normalizer': 4, ...}
        ctrl = <hyperopt.base.Ctrl object>
    144                 except Exception as e:
    145                     logger.info('job exception: %s' % str(e))
    146                     trial['state'] = base.JOB_STATE_ERROR
    147                     trial['misc']['error'] = (str(type(e)), str(e))

...........................................................................
/home/aquemy/dev/dp_hyperparameters/extension/hyperopt/base.py in evaluate(self=<hyperopt.base.Domain object>, config={'bootstrap': 1, 'criterion': 1, 'features': 1, 'features_PCA_features__n_components': 1, 'max_depth': 1, 'max_features': 2, 'max_leaf_nodes': 1, 'min_samples_split': 0, 'n_estimators': 3, 'normalizer': 4, ...}, ctrl=<hyperopt.base.Ctrl object>, attach_attachments=True)
    841             #    or the normal Python part (self.fn)
    842             pyll_rval = pyll.rec_eval(
    843                 self.expr,
    844                 memo=memo,
    845                 print_node_on_error=self.rec_eval_print_node_on_error)
--> 846             rval = self.fn(pyll_rval)
        rval = undefined
        self.fn = <functools.partial object>
        pyll_rval = {'algorithm': {'bootstrap': False, 'criterion': 'entropy', 'max_depth': 2, 'max_features': 3, 'max_leaf_nodes': 3, 'min_samples_split': 2, 'n_estimators': 75}, 'pipeline': {'features': ('features_PCA', {'features__n_components': 2}), 'normalizer': ('normalizer_RobustScaler', {'normalizer__quantile_range': (5.0, 95.0), 'normalizer__with_centering': False, 'normalizer__with_scaling': True}), 'rebalance': ('rebalance_NearMiss', {'rebalance__n_neighbors': 2})}}
    847 
    848         if isinstance(rval, (float, int, np.number)):
    849             dict_rval = {'loss': float(rval), 'status': STATUS_OK}
    850         else:

...........................................................................
/home/aquemy/dev/dp_hyperparameters/extension/experiment/objective.py in objective_joint(wconfig={'algorithm': {'bootstrap': False, 'criterion': 'entropy', 'max_depth': 2, 'max_features': 3, 'max_leaf_nodes': 3, 'min_samples_split': 2, 'n_estimators': 75}, 'pipeline': {'features': ('features_PCA', {'features__n_components': 2}), 'normalizer': ('normalizer_RobustScaler', {'normalizer__quantile_range': (5.0, 95.0), 'normalizer__with_centering': False, 'normalizer__with_scaling': True}), 'rebalance': ('rebalance_NearMiss', {'rebalance__n_neighbors': 2})}}, algorithm='RandomForest', X=array([[ 0.,  0.,  5., ...,  0.,  0.,  0.],
    ...0.],
       [ 0.,  0., 10., ..., 12.,  1.,  0.]]), y=array([0, 1, 2, ..., 8, 9, 8]), context={'baseline_score': 0.9272021217853512, 'baseline_score_std': 0.026919033284817703, 'best_config': {'algorithm': {'bootstrap': False, 'criterion': 'entropy', 'max_depth': None, 'max_features': 2, 'max_leaf_nodes': None, 'min_samples_split': 2, 'n_estimators': 10}, 'config_hash': {'algorithm': 'a49ecb99e74217d6812f98ead7bc9d1fe4a53ba0', 'config': '6749af1a67b4dbcd2b4719e419d99908063c05e1', 'pipeline': '19bdf19a2eec5febce95ab8fa2a71040d75114aa'}, 'duration': 1.5498578548431396, 'iteration': 6, 'loss': 0.14471329609998995, 'max_history_score': 0.85528670390001, 'max_history_score_std': 0.02213730791268438, 'max_history_step': 'joint', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 4, 'features__selectkbest__k': 3}), 'normalizer': ('normalizer_NoneType', {}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 7})}, 'score': 0.85528670390001, ...}, 'history': [{'algorithm': {'bootstrap': False, 'criterion': 'entropy', 'max_depth': 1, 'max_features': 3, 'max_leaf_nodes': 3, 'min_samples_split': 5, 'n_estimators': 50}, 'config_hash': {'algorithm': '752fa095cdab58a238ae606c613606188964cc0c', 'config': 'fd24b065dda6bdeb1077793f9df480ff318c7a37', 'pipeline': '13ea3359c453b8993fcec1e88bc0e19cd0a2b112'}, 'duration': 0.689669132232666, 'iteration': 0, 'loss': 0.6602879519109309, 'max_history_score': 0.3397120480890691, 'max_history_score_std': 0.03346542949100545, 'max_history_step': 'joint', 'pipeline': {'features': ('features_SelectKBest', {'features__k': 4}), 'normalizer': ('normalizer_MinMaxScaler', {}), 'rebalance': ('rebalance_NoneType', {})}, 'score': 0.3397120480890691, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'gini', 'max_depth': 4, 'max_features': 1, 'max_leaf_nodes': 5, 'min_samples_split': 3, 'n_estimators': 25}, 'config_hash': {'algorithm': '9d9de4aee820052ddfe83bfffca420f6b50837d3', 'config': 'fb22f80fb4358ae1ee4c9bd4a83543992be8d806', 'pipeline': '6251ad4bb7a110726a67f90c319f4717ac37a312'}, 'duration': 1.4300940036773682, 'iteration': 1, 'loss': 0.5122196101741096, 'max_history_score': 0.48778038982589045, 'max_history_score_std': 0.05486079759217226, 'max_history_step': 'joint', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 2, 'features__selectkbest__k': 2}), 'normalizer': ('normalizer_StandardScaler', {'normalizer__with_mean': True, 'normalizer__with_std': True}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 5})}, 'score': 0.48778038982589045, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': 4, 'max_features': 1, 'max_leaf_nodes': None, 'min_samples_split': 2, 'n_estimators': 10}, 'config_hash': {'algorithm': '2ed7d27df9a1b2d5e63da76f7cb309616c232022', 'config': '8c97cdb885dd05cfd8c40ee3ac445b61e5c767a8', 'pipeline': 'c0abb5e23a4739d3120740a9519fb36c43eb94d5'}, 'duration': 3.0036678314208984, 'iteration': 2, 'loss': 0.38319264175312906, 'max_history_score': 0.6168073582468709, 'max_history_score_std': 0.05286679173001824, 'max_history_step': 'joint', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 1, 'features__selectkbest__k': 4}), 'normalizer': ('normalizer_PowerTransformer', {}), 'rebalance': ('rebalance_NearMiss', {'rebalance__n_neighbors': 2})}, 'score': 0.6168073582468709, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'entropy', 'max_depth': None, 'max_features': None, 'max_leaf_nodes': 2, 'min_samples_split': 2, 'n_estimators': 100}, 'config_hash': {'algorithm': '17962655e3b76dfcd0843d1e5c2cb7a9db1c6a79', 'config': '16fbb5fd5cfbbacfddf27c61c0c7397a7f6d8ade', 'pipeline': '13ea3359c453b8993fcec1e88bc0e19cd0a2b112'}, 'duration': 1.3447980880737305, 'iteration': 3, 'loss': 0.6768840987778313, 'max_history_score': 0.6168073582468709, 'max_history_score_std': 0.05286679173001824, 'max_history_step': 'joint', 'pipeline': {'features': ('features_SelectKBest', {'features__k': 4}), 'normalizer': ('normalizer_MinMaxScaler', {}), 'rebalance': ('rebalance_NoneType', {})}, 'score': 0.32311590122216866, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'gini', 'max_depth': 2, 'max_features': 2, 'max_leaf_nodes': 2, 'min_samples_split': 3, 'n_estimators': 100}, 'config_hash': {'algorithm': '1ea8965b2247f86950e54510ee6d79399816341b', 'config': 'a77c698197c31308211b854e81a998178941f87d', 'pipeline': 'aaf976c7c663a31fa039582d42f9e07101556a7c'}, 'duration': 2.589430093765259, 'iteration': 4, 'loss': 0.2544808950572157, 'max_history_score': 0.7455191049427843, 'max_history_score_std': 0.04843448308166839, 'max_history_step': 'joint', 'pipeline': {'features': ('features_NoneType', {}), 'normalizer': ('normalizer_PowerTransformer', {}), 'rebalance': ('rebalance_NoneType', {})}, 'score': 0.7455191049427843, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': None, 'max_features': 2, 'max_leaf_nodes': 5, 'min_samples_split': 5, 'n_estimators': 25}, 'config_hash': {'algorithm': 'fd8aeb6a05eaaba41e676d60596c8e0c71b35e0c', 'config': '1fc13606bca3aaf342ca6ea21139cb598b56f8db', 'pipeline': 'f00bd8de05642e026bbba4ad20d3a60088c86b6c'}, 'duration': 1.8779079914093018, 'iteration': 5, 'loss': 0.531551018758381, 'max_history_score': 0.7455191049427843, 'max_history_score_std': 0.04843448308166839, 'max_history_step': 'joint', 'pipeline': {'features': ('features_PCA', {'features__n_components': 2}), 'normalizer': ('normalizer_MinMaxScaler', {}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 5})}, 'score': 0.46844898124161904, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'entropy', 'max_depth': None, 'max_features': 2, 'max_leaf_nodes': None, 'min_samples_split': 2, 'n_estimators': 10}, 'config_hash': {'algorithm': 'a49ecb99e74217d6812f98ead7bc9d1fe4a53ba0', 'config': '6749af1a67b4dbcd2b4719e419d99908063c05e1', 'pipeline': '19bdf19a2eec5febce95ab8fa2a71040d75114aa'}, 'duration': 1.5498578548431396, 'iteration': 6, 'loss': 0.14471329609998995, 'max_history_score': 0.85528670390001, 'max_history_score_std': 0.02213730791268438, 'max_history_step': 'joint', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 4, 'features__selectkbest__k': 3}), 'normalizer': ('normalizer_NoneType', {}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 7})}, 'score': 0.85528670390001, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': 1, 'max_features': 3, 'max_leaf_nodes': 3, 'min_samples_split': 3, 'n_estimators': 75}, 'config_hash': {'algorithm': 'ebfb16234172ae811ff21185ff92bbdbb8f32f14', 'config': 'd92d4ada2394fc132733e176e926ee53acdc6a00', 'pipeline': '8071e7cbf86a5c3056493dc3aa40063aeb28cdfe'}, 'duration': 1.3618149757385254, 'iteration': 7, 'loss': 0.6158612049395463, 'max_history_score': 0.85528670390001, 'max_history_score_std': 0.02213730791268438, 'max_history_step': 'joint', 'pipeline': {'features': ('features_SelectKBest', {'features__k': 4}), 'normalizer': ('normalizer_StandardScaler', {'normalizer__with_mean': True, 'normalizer__with_std': True}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 5})}, 'score': 0.3841387950604537, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'entropy', 'max_depth': 1, 'max_features': 1, 'max_leaf_nodes': 5, 'min_samples_split': 2, 'n_estimators': 100}, 'config_hash': {'algorithm': '896b53c75a2db568fb7b6da3bfca2f7a1535a11b', 'config': 'f0d0b1d2cedc22ae15d9a208a3fc3fc133bf0d3d', 'pipeline': 'c9761c9a33bf75d6dcad0742c421548a7655ccc9'}, 'duration': 2.297278881072998, 'iteration': 8, 'loss': 0.40673663548410355, 'max_history_score': 0.85528670390001, 'max_history_score_std': 0.02213730791268438, 'max_history_step': 'joint', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 2, 'features__selectkbest__k': 4}), 'normalizer': ('normalizer_StandardScaler', {'normalizer__with_mean': False, 'normalizer__with_std': False}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 5})}, 'score': 0.5932633645158965, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'entropy', 'max_depth': 2, 'max_features': None, 'max_leaf_nodes': None, 'min_samples_split': 5, 'n_estimators': 25}, 'config_hash': {'algorithm': '0b0e954757c4f75343a6efb740ad93260ed781ae', 'config': '47584de0e60d0d12c7dbbf0dc60e5aea96e3f4b2', 'pipeline': 'b37ee32d59413053bf9a2a72c8ff7135f3701e05'}, 'duration': 0.7249000072479248, 'iteration': 9, 'loss': 0.6965910020393421, 'max_history_score': 0.85528670390001, 'max_history_score_std': 0.02213730791268438, 'max_history_step': 'joint', 'pipeline': {'features': ('features_SelectKBest', {'features__k': 3}), 'normalizer': ('normalizer_NoneType', {}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 7})}, 'score': 0.3034089979606579, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'gini', 'max_depth': 2, 'max_features': 2, 'max_leaf_nodes': 5, 'min_samples_split': 5, 'n_estimators': 75}, 'config_hash': {'algorithm': 'f1ead1d9e33ea927e1dd27d872a058fa3de4f832', 'config': 'eecb88ee2b1b95d741c1b5c7751534d31aae6a77', 'pipeline': '6746650871e8b61efc9302b092dc05f7cdb179d5'}, 'duration': 5.340634822845459, 'iteration': 10, 'loss': 0.7687016290977936, 'max_history_score': 0.85528670390001, 'max_history_score_std': 0.02213730791268438, 'max_history_step': 'joint', 'pipeline': {'features': ('features_SelectKBest', {'features__k': 3}), 'normalizer': ('normalizer_RobustScaler', {'normalizer__quantile_range': (...), 'normalizer__with_centering': False, 'normalizer__with_scaling': False}), 'rebalance': ('rebalance_CondensedNearestNeighbour', {'rebalance__n_neighbors': 1})}, 'score': 0.23129837090220637, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': 1, 'max_features': 2, 'max_leaf_nodes': 2, 'min_samples_split': 3, 'n_estimators': 75}, 'config_hash': {'algorithm': '531a3bb8ccf0baa06727af4b3de9e62d25e6eabf', 'config': '27a7ed0502b321ab7256b77c8ce79e90cb9da815', 'pipeline': '77e6d84e2217b92b3cf67cc6defef9dd3554cec0'}, 'duration': 1.775357961654663, 'iteration': 11, 'loss': 0.6313818737375694, 'max_history_score': 0.85528670390001, 'max_history_score_std': 0.02213730791268438, 'max_history_step': 'joint', 'pipeline': {'features': ('features_SelectKBest', {'features__k': 4}), 'normalizer': ('normalizer_MinMaxScaler', {}), 'rebalance': ('rebalance_NearMiss', {'rebalance__n_neighbors': 3})}, 'score': 0.3686181262624307, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'entropy', 'max_depth': 4, 'max_features': 3, 'max_leaf_nodes': 2, 'min_samples_split': 3, 'n_estimators': 10}, 'config_hash': {'algorithm': '93518f8ded6074d537900b26be72f8485782f933', 'config': '45f056102dd2d644bd8befa471f17b2311ac7954', 'pipeline': '5240329df25c9a533d025c1a401d49835a501b41'}, 'duration': 3.2622711658477783, 'iteration': 12, 'loss': 0.6120243191353301, 'max_history_score': 0.85528670390001, 'max_history_score_std': 0.02213730791268438, 'max_history_step': 'joint', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 4, 'features__selectkbest__k': 2}), 'normalizer': ('normalizer_PowerTransformer', {}), 'rebalance': ('rebalance_NearMiss', {'rebalance__n_neighbors': 1})}, 'score': 0.38797568086467, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'entropy', 'max_depth': None, 'max_features': 1, 'max_leaf_nodes': 5, 'min_samples_split': 3, 'n_estimators': 75}, 'config_hash': {'algorithm': 'e515d45b764fa43591032874a0ff9c25bf12fddd', 'config': 'ba108323623936872824ed8f1c41d615d25523b3', 'pipeline': '9d823bc0442f21b5ce8af67a5eb1237f64ffc2f8'}, 'duration': 2.5326571464538574, 'iteration': 13, 'loss': 0.6271427382991047, 'max_history_score': 0.85528670390001, 'max_history_score_std': 0.02213730791268438, 'max_history_step': 'joint', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 1, 'features__selectkbest__k': 1}), 'normalizer': ('normalizer_StandardScaler', {'normalizer__with_mean': True, 'normalizer__with_std': True}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 5})}, 'score': 0.3728572617008953, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'entropy', 'max_depth': 3, 'max_features': 2, 'max_leaf_nodes': 2, 'min_samples_split': 3, 'n_estimators': 25}, 'config_hash': {'algorithm': '2808e67f609eba5c8a97f81ac0c9413cd37cf7aa', 'config': 'dde4d3b5f37741629cb58bfc4051ed9f98c8f311', 'pipeline': 'bc52deabf1f5ee60968ba541d9d2574353c30a9c'}, 'duration': 0.7145559787750244, 'iteration': 14, 'loss': 0.6831045572696203, 'max_history_score': 0.85528670390001, 'max_history_score_std': 0.02213730791268438, 'max_history_step': 'joint', 'pipeline': {'features': ('features_SelectKBest', {'features__k': 3}), 'normalizer': ('normalizer_MinMaxScaler', {}), 'rebalance': ('rebalance_NearMiss', {'rebalance__n_neighbors': 1})}, 'score': 0.31689544273037973, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'gini', 'max_depth': 2, 'max_features': 2, 'max_leaf_nodes': None, 'min_samples_split': 5, 'n_estimators': 100}, 'config_hash': {'algorithm': 'b942acdead762d34afeb474bc2fe6f7fd0f23493', 'config': '1080c25b92da3f15a6f8eec003957f7e0a66324f', 'pipeline': 'cfa84fe703dc5bc0bbd2257a6d524fee2693b804'}, 'duration': 2.812459945678711, 'iteration': 15, 'loss': 0.6921421091202761, 'max_history_score': 0.85528670390001, 'max_history_score_std': 0.02213730791268438, 'max_history_step': 'joint', 'pipeline': {'features': ('features_SelectKBest', {'features__k': 2}), 'normalizer': ('normalizer_PowerTransformer', {}), 'rebalance': ('rebalance_NoneType', {})}, 'score': 0.3078578908797239, ...}], 'history_hash': ['fd24b065dda6bdeb1077793f9df480ff318c7a37', 'fb22f80fb4358ae1ee4c9bd4a83543992be8d806', '8c97cdb885dd05cfd8c40ee3ac445b61e5c767a8', '16fbb5fd5cfbbacfddf27c61c0c7397a7f6d8ade', 'a77c698197c31308211b854e81a998178941f87d', '1fc13606bca3aaf342ca6ea21139cb598b56f8db', '6749af1a67b4dbcd2b4719e419d99908063c05e1', 'd92d4ada2394fc132733e176e926ee53acdc6a00', 'f0d0b1d2cedc22ae15d9a208a3fc3fc133bf0d3d', '47584de0e60d0d12c7dbbf0dc60e5aea96e3f4b2', 'eecb88ee2b1b95d741c1b5c7751534d31aae6a77', '27a7ed0502b321ab7256b77c8ce79e90cb9da815', '45f056102dd2d644bd8befa471f17b2311ac7954', 'ba108323623936872824ed8f1c41d615d25523b3', 'dde4d3b5f37741629cb58bfc4051ed9f98c8f311', '1080c25b92da3f15a6f8eec003957f7e0a66324f'], 'history_index': {'1080c25b92da3f15a6f8eec003957f7e0a66324f': 15, '16fbb5fd5cfbbacfddf27c61c0c7397a7f6d8ade': 3, '1fc13606bca3aaf342ca6ea21139cb598b56f8db': 5, '27a7ed0502b321ab7256b77c8ce79e90cb9da815': 11, '45f056102dd2d644bd8befa471f17b2311ac7954': 12, '47584de0e60d0d12c7dbbf0dc60e5aea96e3f4b2': 9, '6749af1a67b4dbcd2b4719e419d99908063c05e1': 6, '8c97cdb885dd05cfd8c40ee3ac445b61e5c767a8': 2, 'a77c698197c31308211b854e81a998178941f87d': 4, 'ba108323623936872824ed8f1c41d615d25523b3': 13, ...}, 'iteration': 15, 'max_history_score': 0.85528670390001, 'max_history_score_std': 0.02213730791268438, 'max_history_step': 'joint'}, config={'algorithm': 'RandomForest', 'seed': 42, 'time': 300})
    108 
    109 def objective_algo(algo_config, current_pipeline_config, algorithm, X, y, context, config):
    110     return objective(current_pipeline_config, algo_config, algorithm, X, y, context, config, step='algorithm')
    111 
    112 def objective_joint(wconfig, algorithm, X, y, context, config):
--> 113     return objective(wconfig['pipeline'], wconfig['algorithm'], algorithm, X, y, context, config, step='joint')
        wconfig = {'algorithm': {'bootstrap': False, 'criterion': 'entropy', 'max_depth': 2, 'max_features': 3, 'max_leaf_nodes': 3, 'min_samples_split': 2, 'n_estimators': 75}, 'pipeline': {'features': ('features_PCA', {'features__n_components': 2}), 'normalizer': ('normalizer_RobustScaler', {'normalizer__quantile_range': (5.0, 95.0), 'normalizer__with_centering': False, 'normalizer__with_scaling': True}), 'rebalance': ('rebalance_NearMiss', {'rebalance__n_neighbors': 2})}}
        algorithm = 'RandomForest'
        X = array([[ 0.,  0.,  5., ...,  0.,  0.,  0.],
    ...0.],
       [ 0.,  0., 10., ..., 12.,  1.,  0.]])
        y = array([0, 1, 2, ..., 8, 9, 8])
        context = {'baseline_score': 0.9272021217853512, 'baseline_score_std': 0.026919033284817703, 'best_config': {'algorithm': {'bootstrap': False, 'criterion': 'entropy', 'max_depth': None, 'max_features': 2, 'max_leaf_nodes': None, 'min_samples_split': 2, 'n_estimators': 10}, 'config_hash': {'algorithm': 'a49ecb99e74217d6812f98ead7bc9d1fe4a53ba0', 'config': '6749af1a67b4dbcd2b4719e419d99908063c05e1', 'pipeline': '19bdf19a2eec5febce95ab8fa2a71040d75114aa'}, 'duration': 1.5498578548431396, 'iteration': 6, 'loss': 0.14471329609998995, 'max_history_score': 0.85528670390001, 'max_history_score_std': 0.02213730791268438, 'max_history_step': 'joint', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 4, 'features__selectkbest__k': 3}), 'normalizer': ('normalizer_NoneType', {}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 7})}, 'score': 0.85528670390001, ...}, 'history': [{'algorithm': {'bootstrap': False, 'criterion': 'entropy', 'max_depth': 1, 'max_features': 3, 'max_leaf_nodes': 3, 'min_samples_split': 5, 'n_estimators': 50}, 'config_hash': {'algorithm': '752fa095cdab58a238ae606c613606188964cc0c', 'config': 'fd24b065dda6bdeb1077793f9df480ff318c7a37', 'pipeline': '13ea3359c453b8993fcec1e88bc0e19cd0a2b112'}, 'duration': 0.689669132232666, 'iteration': 0, 'loss': 0.6602879519109309, 'max_history_score': 0.3397120480890691, 'max_history_score_std': 0.03346542949100545, 'max_history_step': 'joint', 'pipeline': {'features': ('features_SelectKBest', {'features__k': 4}), 'normalizer': ('normalizer_MinMaxScaler', {}), 'rebalance': ('rebalance_NoneType', {})}, 'score': 0.3397120480890691, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'gini', 'max_depth': 4, 'max_features': 1, 'max_leaf_nodes': 5, 'min_samples_split': 3, 'n_estimators': 25}, 'config_hash': {'algorithm': '9d9de4aee820052ddfe83bfffca420f6b50837d3', 'config': 'fb22f80fb4358ae1ee4c9bd4a83543992be8d806', 'pipeline': '6251ad4bb7a110726a67f90c319f4717ac37a312'}, 'duration': 1.4300940036773682, 'iteration': 1, 'loss': 0.5122196101741096, 'max_history_score': 0.48778038982589045, 'max_history_score_std': 0.05486079759217226, 'max_history_step': 'joint', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 2, 'features__selectkbest__k': 2}), 'normalizer': ('normalizer_StandardScaler', {'normalizer__with_mean': True, 'normalizer__with_std': True}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 5})}, 'score': 0.48778038982589045, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': 4, 'max_features': 1, 'max_leaf_nodes': None, 'min_samples_split': 2, 'n_estimators': 10}, 'config_hash': {'algorithm': '2ed7d27df9a1b2d5e63da76f7cb309616c232022', 'config': '8c97cdb885dd05cfd8c40ee3ac445b61e5c767a8', 'pipeline': 'c0abb5e23a4739d3120740a9519fb36c43eb94d5'}, 'duration': 3.0036678314208984, 'iteration': 2, 'loss': 0.38319264175312906, 'max_history_score': 0.6168073582468709, 'max_history_score_std': 0.05286679173001824, 'max_history_step': 'joint', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 1, 'features__selectkbest__k': 4}), 'normalizer': ('normalizer_PowerTransformer', {}), 'rebalance': ('rebalance_NearMiss', {'rebalance__n_neighbors': 2})}, 'score': 0.6168073582468709, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'entropy', 'max_depth': None, 'max_features': None, 'max_leaf_nodes': 2, 'min_samples_split': 2, 'n_estimators': 100}, 'config_hash': {'algorithm': '17962655e3b76dfcd0843d1e5c2cb7a9db1c6a79', 'config': '16fbb5fd5cfbbacfddf27c61c0c7397a7f6d8ade', 'pipeline': '13ea3359c453b8993fcec1e88bc0e19cd0a2b112'}, 'duration': 1.3447980880737305, 'iteration': 3, 'loss': 0.6768840987778313, 'max_history_score': 0.6168073582468709, 'max_history_score_std': 0.05286679173001824, 'max_history_step': 'joint', 'pipeline': {'features': ('features_SelectKBest', {'features__k': 4}), 'normalizer': ('normalizer_MinMaxScaler', {}), 'rebalance': ('rebalance_NoneType', {})}, 'score': 0.32311590122216866, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'gini', 'max_depth': 2, 'max_features': 2, 'max_leaf_nodes': 2, 'min_samples_split': 3, 'n_estimators': 100}, 'config_hash': {'algorithm': '1ea8965b2247f86950e54510ee6d79399816341b', 'config': 'a77c698197c31308211b854e81a998178941f87d', 'pipeline': 'aaf976c7c663a31fa039582d42f9e07101556a7c'}, 'duration': 2.589430093765259, 'iteration': 4, 'loss': 0.2544808950572157, 'max_history_score': 0.7455191049427843, 'max_history_score_std': 0.04843448308166839, 'max_history_step': 'joint', 'pipeline': {'features': ('features_NoneType', {}), 'normalizer': ('normalizer_PowerTransformer', {}), 'rebalance': ('rebalance_NoneType', {})}, 'score': 0.7455191049427843, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': None, 'max_features': 2, 'max_leaf_nodes': 5, 'min_samples_split': 5, 'n_estimators': 25}, 'config_hash': {'algorithm': 'fd8aeb6a05eaaba41e676d60596c8e0c71b35e0c', 'config': '1fc13606bca3aaf342ca6ea21139cb598b56f8db', 'pipeline': 'f00bd8de05642e026bbba4ad20d3a60088c86b6c'}, 'duration': 1.8779079914093018, 'iteration': 5, 'loss': 0.531551018758381, 'max_history_score': 0.7455191049427843, 'max_history_score_std': 0.04843448308166839, 'max_history_step': 'joint', 'pipeline': {'features': ('features_PCA', {'features__n_components': 2}), 'normalizer': ('normalizer_MinMaxScaler', {}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 5})}, 'score': 0.46844898124161904, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'entropy', 'max_depth': None, 'max_features': 2, 'max_leaf_nodes': None, 'min_samples_split': 2, 'n_estimators': 10}, 'config_hash': {'algorithm': 'a49ecb99e74217d6812f98ead7bc9d1fe4a53ba0', 'config': '6749af1a67b4dbcd2b4719e419d99908063c05e1', 'pipeline': '19bdf19a2eec5febce95ab8fa2a71040d75114aa'}, 'duration': 1.5498578548431396, 'iteration': 6, 'loss': 0.14471329609998995, 'max_history_score': 0.85528670390001, 'max_history_score_std': 0.02213730791268438, 'max_history_step': 'joint', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 4, 'features__selectkbest__k': 3}), 'normalizer': ('normalizer_NoneType', {}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 7})}, 'score': 0.85528670390001, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': 1, 'max_features': 3, 'max_leaf_nodes': 3, 'min_samples_split': 3, 'n_estimators': 75}, 'config_hash': {'algorithm': 'ebfb16234172ae811ff21185ff92bbdbb8f32f14', 'config': 'd92d4ada2394fc132733e176e926ee53acdc6a00', 'pipeline': '8071e7cbf86a5c3056493dc3aa40063aeb28cdfe'}, 'duration': 1.3618149757385254, 'iteration': 7, 'loss': 0.6158612049395463, 'max_history_score': 0.85528670390001, 'max_history_score_std': 0.02213730791268438, 'max_history_step': 'joint', 'pipeline': {'features': ('features_SelectKBest', {'features__k': 4}), 'normalizer': ('normalizer_StandardScaler', {'normalizer__with_mean': True, 'normalizer__with_std': True}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 5})}, 'score': 0.3841387950604537, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'entropy', 'max_depth': 1, 'max_features': 1, 'max_leaf_nodes': 5, 'min_samples_split': 2, 'n_estimators': 100}, 'config_hash': {'algorithm': '896b53c75a2db568fb7b6da3bfca2f7a1535a11b', 'config': 'f0d0b1d2cedc22ae15d9a208a3fc3fc133bf0d3d', 'pipeline': 'c9761c9a33bf75d6dcad0742c421548a7655ccc9'}, 'duration': 2.297278881072998, 'iteration': 8, 'loss': 0.40673663548410355, 'max_history_score': 0.85528670390001, 'max_history_score_std': 0.02213730791268438, 'max_history_step': 'joint', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 2, 'features__selectkbest__k': 4}), 'normalizer': ('normalizer_StandardScaler', {'normalizer__with_mean': False, 'normalizer__with_std': False}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 5})}, 'score': 0.5932633645158965, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'entropy', 'max_depth': 2, 'max_features': None, 'max_leaf_nodes': None, 'min_samples_split': 5, 'n_estimators': 25}, 'config_hash': {'algorithm': '0b0e954757c4f75343a6efb740ad93260ed781ae', 'config': '47584de0e60d0d12c7dbbf0dc60e5aea96e3f4b2', 'pipeline': 'b37ee32d59413053bf9a2a72c8ff7135f3701e05'}, 'duration': 0.7249000072479248, 'iteration': 9, 'loss': 0.6965910020393421, 'max_history_score': 0.85528670390001, 'max_history_score_std': 0.02213730791268438, 'max_history_step': 'joint', 'pipeline': {'features': ('features_SelectKBest', {'features__k': 3}), 'normalizer': ('normalizer_NoneType', {}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 7})}, 'score': 0.3034089979606579, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'gini', 'max_depth': 2, 'max_features': 2, 'max_leaf_nodes': 5, 'min_samples_split': 5, 'n_estimators': 75}, 'config_hash': {'algorithm': 'f1ead1d9e33ea927e1dd27d872a058fa3de4f832', 'config': 'eecb88ee2b1b95d741c1b5c7751534d31aae6a77', 'pipeline': '6746650871e8b61efc9302b092dc05f7cdb179d5'}, 'duration': 5.340634822845459, 'iteration': 10, 'loss': 0.7687016290977936, 'max_history_score': 0.85528670390001, 'max_history_score_std': 0.02213730791268438, 'max_history_step': 'joint', 'pipeline': {'features': ('features_SelectKBest', {'features__k': 3}), 'normalizer': ('normalizer_RobustScaler', {'normalizer__quantile_range': (...), 'normalizer__with_centering': False, 'normalizer__with_scaling': False}), 'rebalance': ('rebalance_CondensedNearestNeighbour', {'rebalance__n_neighbors': 1})}, 'score': 0.23129837090220637, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': 1, 'max_features': 2, 'max_leaf_nodes': 2, 'min_samples_split': 3, 'n_estimators': 75}, 'config_hash': {'algorithm': '531a3bb8ccf0baa06727af4b3de9e62d25e6eabf', 'config': '27a7ed0502b321ab7256b77c8ce79e90cb9da815', 'pipeline': '77e6d84e2217b92b3cf67cc6defef9dd3554cec0'}, 'duration': 1.775357961654663, 'iteration': 11, 'loss': 0.6313818737375694, 'max_history_score': 0.85528670390001, 'max_history_score_std': 0.02213730791268438, 'max_history_step': 'joint', 'pipeline': {'features': ('features_SelectKBest', {'features__k': 4}), 'normalizer': ('normalizer_MinMaxScaler', {}), 'rebalance': ('rebalance_NearMiss', {'rebalance__n_neighbors': 3})}, 'score': 0.3686181262624307, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'entropy', 'max_depth': 4, 'max_features': 3, 'max_leaf_nodes': 2, 'min_samples_split': 3, 'n_estimators': 10}, 'config_hash': {'algorithm': '93518f8ded6074d537900b26be72f8485782f933', 'config': '45f056102dd2d644bd8befa471f17b2311ac7954', 'pipeline': '5240329df25c9a533d025c1a401d49835a501b41'}, 'duration': 3.2622711658477783, 'iteration': 12, 'loss': 0.6120243191353301, 'max_history_score': 0.85528670390001, 'max_history_score_std': 0.02213730791268438, 'max_history_step': 'joint', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 4, 'features__selectkbest__k': 2}), 'normalizer': ('normalizer_PowerTransformer', {}), 'rebalance': ('rebalance_NearMiss', {'rebalance__n_neighbors': 1})}, 'score': 0.38797568086467, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'entropy', 'max_depth': None, 'max_features': 1, 'max_leaf_nodes': 5, 'min_samples_split': 3, 'n_estimators': 75}, 'config_hash': {'algorithm': 'e515d45b764fa43591032874a0ff9c25bf12fddd', 'config': 'ba108323623936872824ed8f1c41d615d25523b3', 'pipeline': '9d823bc0442f21b5ce8af67a5eb1237f64ffc2f8'}, 'duration': 2.5326571464538574, 'iteration': 13, 'loss': 0.6271427382991047, 'max_history_score': 0.85528670390001, 'max_history_score_std': 0.02213730791268438, 'max_history_step': 'joint', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 1, 'features__selectkbest__k': 1}), 'normalizer': ('normalizer_StandardScaler', {'normalizer__with_mean': True, 'normalizer__with_std': True}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 5})}, 'score': 0.3728572617008953, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'entropy', 'max_depth': 3, 'max_features': 2, 'max_leaf_nodes': 2, 'min_samples_split': 3, 'n_estimators': 25}, 'config_hash': {'algorithm': '2808e67f609eba5c8a97f81ac0c9413cd37cf7aa', 'config': 'dde4d3b5f37741629cb58bfc4051ed9f98c8f311', 'pipeline': 'bc52deabf1f5ee60968ba541d9d2574353c30a9c'}, 'duration': 0.7145559787750244, 'iteration': 14, 'loss': 0.6831045572696203, 'max_history_score': 0.85528670390001, 'max_history_score_std': 0.02213730791268438, 'max_history_step': 'joint', 'pipeline': {'features': ('features_SelectKBest', {'features__k': 3}), 'normalizer': ('normalizer_MinMaxScaler', {}), 'rebalance': ('rebalance_NearMiss', {'rebalance__n_neighbors': 1})}, 'score': 0.31689544273037973, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'gini', 'max_depth': 2, 'max_features': 2, 'max_leaf_nodes': None, 'min_samples_split': 5, 'n_estimators': 100}, 'config_hash': {'algorithm': 'b942acdead762d34afeb474bc2fe6f7fd0f23493', 'config': '1080c25b92da3f15a6f8eec003957f7e0a66324f', 'pipeline': 'cfa84fe703dc5bc0bbd2257a6d524fee2693b804'}, 'duration': 2.812459945678711, 'iteration': 15, 'loss': 0.6921421091202761, 'max_history_score': 0.85528670390001, 'max_history_score_std': 0.02213730791268438, 'max_history_step': 'joint', 'pipeline': {'features': ('features_SelectKBest', {'features__k': 2}), 'normalizer': ('normalizer_PowerTransformer', {}), 'rebalance': ('rebalance_NoneType', {})}, 'score': 0.3078578908797239, ...}], 'history_hash': ['fd24b065dda6bdeb1077793f9df480ff318c7a37', 'fb22f80fb4358ae1ee4c9bd4a83543992be8d806', '8c97cdb885dd05cfd8c40ee3ac445b61e5c767a8', '16fbb5fd5cfbbacfddf27c61c0c7397a7f6d8ade', 'a77c698197c31308211b854e81a998178941f87d', '1fc13606bca3aaf342ca6ea21139cb598b56f8db', '6749af1a67b4dbcd2b4719e419d99908063c05e1', 'd92d4ada2394fc132733e176e926ee53acdc6a00', 'f0d0b1d2cedc22ae15d9a208a3fc3fc133bf0d3d', '47584de0e60d0d12c7dbbf0dc60e5aea96e3f4b2', 'eecb88ee2b1b95d741c1b5c7751534d31aae6a77', '27a7ed0502b321ab7256b77c8ce79e90cb9da815', '45f056102dd2d644bd8befa471f17b2311ac7954', 'ba108323623936872824ed8f1c41d615d25523b3', 'dde4d3b5f37741629cb58bfc4051ed9f98c8f311', '1080c25b92da3f15a6f8eec003957f7e0a66324f'], 'history_index': {'1080c25b92da3f15a6f8eec003957f7e0a66324f': 15, '16fbb5fd5cfbbacfddf27c61c0c7397a7f6d8ade': 3, '1fc13606bca3aaf342ca6ea21139cb598b56f8db': 5, '27a7ed0502b321ab7256b77c8ce79e90cb9da815': 11, '45f056102dd2d644bd8befa471f17b2311ac7954': 12, '47584de0e60d0d12c7dbbf0dc60e5aea96e3f4b2': 9, '6749af1a67b4dbcd2b4719e419d99908063c05e1': 6, '8c97cdb885dd05cfd8c40ee3ac445b61e5c767a8': 2, 'a77c698197c31308211b854e81a998178941f87d': 4, 'ba108323623936872824ed8f1c41d615d25523b3': 13, ...}, 'iteration': 15, 'max_history_score': 0.85528670390001, 'max_history_score_std': 0.02213730791268438, 'max_history_step': 'joint'}
        config = {'algorithm': 'RandomForest', 'seed': 42, 'time': 300}
    114 
    115 
    116 def get_baseline_score(algorithm, X, y, seed):
    117     pipeline, _ = pipeline_conf_to_full_pipeline(

...........................................................................
/home/aquemy/dev/dp_hyperparameters/extension/experiment/objective.py in objective(pipeline_config={'features': ('features_PCA', {'features__n_components': 2}), 'normalizer': ('normalizer_RobustScaler', {'normalizer__quantile_range': (5.0, 95.0), 'normalizer__with_centering': False, 'normalizer__with_scaling': True}), 'rebalance': ('rebalance_NearMiss', {'rebalance__n_neighbors': 2})}, algo_config={'bootstrap': False, 'criterion': 'entropy', 'max_depth': 2, 'max_features': 3, 'max_leaf_nodes': 3, 'min_samples_split': 2, 'n_estimators': 75}, algorithm='RandomForest', X=array([[ 0.,  0.,  5., ...,  0.,  0.,  0.],
    ...0.],
       [ 0.,  0., 10., ..., 12.,  1.,  0.]]), y=array([0, 1, 2, ..., 8, 9, 8]), context={'baseline_score': 0.9272021217853512, 'baseline_score_std': 0.026919033284817703, 'best_config': {'algorithm': {'bootstrap': False, 'criterion': 'entropy', 'max_depth': None, 'max_features': 2, 'max_leaf_nodes': None, 'min_samples_split': 2, 'n_estimators': 10}, 'config_hash': {'algorithm': 'a49ecb99e74217d6812f98ead7bc9d1fe4a53ba0', 'config': '6749af1a67b4dbcd2b4719e419d99908063c05e1', 'pipeline': '19bdf19a2eec5febce95ab8fa2a71040d75114aa'}, 'duration': 1.5498578548431396, 'iteration': 6, 'loss': 0.14471329609998995, 'max_history_score': 0.85528670390001, 'max_history_score_std': 0.02213730791268438, 'max_history_step': 'joint', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 4, 'features__selectkbest__k': 3}), 'normalizer': ('normalizer_NoneType', {}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 7})}, 'score': 0.85528670390001, ...}, 'history': [{'algorithm': {'bootstrap': False, 'criterion': 'entropy', 'max_depth': 1, 'max_features': 3, 'max_leaf_nodes': 3, 'min_samples_split': 5, 'n_estimators': 50}, 'config_hash': {'algorithm': '752fa095cdab58a238ae606c613606188964cc0c', 'config': 'fd24b065dda6bdeb1077793f9df480ff318c7a37', 'pipeline': '13ea3359c453b8993fcec1e88bc0e19cd0a2b112'}, 'duration': 0.689669132232666, 'iteration': 0, 'loss': 0.6602879519109309, 'max_history_score': 0.3397120480890691, 'max_history_score_std': 0.03346542949100545, 'max_history_step': 'joint', 'pipeline': {'features': ('features_SelectKBest', {'features__k': 4}), 'normalizer': ('normalizer_MinMaxScaler', {}), 'rebalance': ('rebalance_NoneType', {})}, 'score': 0.3397120480890691, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'gini', 'max_depth': 4, 'max_features': 1, 'max_leaf_nodes': 5, 'min_samples_split': 3, 'n_estimators': 25}, 'config_hash': {'algorithm': '9d9de4aee820052ddfe83bfffca420f6b50837d3', 'config': 'fb22f80fb4358ae1ee4c9bd4a83543992be8d806', 'pipeline': '6251ad4bb7a110726a67f90c319f4717ac37a312'}, 'duration': 1.4300940036773682, 'iteration': 1, 'loss': 0.5122196101741096, 'max_history_score': 0.48778038982589045, 'max_history_score_std': 0.05486079759217226, 'max_history_step': 'joint', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 2, 'features__selectkbest__k': 2}), 'normalizer': ('normalizer_StandardScaler', {'normalizer__with_mean': True, 'normalizer__with_std': True}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 5})}, 'score': 0.48778038982589045, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': 4, 'max_features': 1, 'max_leaf_nodes': None, 'min_samples_split': 2, 'n_estimators': 10}, 'config_hash': {'algorithm': '2ed7d27df9a1b2d5e63da76f7cb309616c232022', 'config': '8c97cdb885dd05cfd8c40ee3ac445b61e5c767a8', 'pipeline': 'c0abb5e23a4739d3120740a9519fb36c43eb94d5'}, 'duration': 3.0036678314208984, 'iteration': 2, 'loss': 0.38319264175312906, 'max_history_score': 0.6168073582468709, 'max_history_score_std': 0.05286679173001824, 'max_history_step': 'joint', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 1, 'features__selectkbest__k': 4}), 'normalizer': ('normalizer_PowerTransformer', {}), 'rebalance': ('rebalance_NearMiss', {'rebalance__n_neighbors': 2})}, 'score': 0.6168073582468709, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'entropy', 'max_depth': None, 'max_features': None, 'max_leaf_nodes': 2, 'min_samples_split': 2, 'n_estimators': 100}, 'config_hash': {'algorithm': '17962655e3b76dfcd0843d1e5c2cb7a9db1c6a79', 'config': '16fbb5fd5cfbbacfddf27c61c0c7397a7f6d8ade', 'pipeline': '13ea3359c453b8993fcec1e88bc0e19cd0a2b112'}, 'duration': 1.3447980880737305, 'iteration': 3, 'loss': 0.6768840987778313, 'max_history_score': 0.6168073582468709, 'max_history_score_std': 0.05286679173001824, 'max_history_step': 'joint', 'pipeline': {'features': ('features_SelectKBest', {'features__k': 4}), 'normalizer': ('normalizer_MinMaxScaler', {}), 'rebalance': ('rebalance_NoneType', {})}, 'score': 0.32311590122216866, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'gini', 'max_depth': 2, 'max_features': 2, 'max_leaf_nodes': 2, 'min_samples_split': 3, 'n_estimators': 100}, 'config_hash': {'algorithm': '1ea8965b2247f86950e54510ee6d79399816341b', 'config': 'a77c698197c31308211b854e81a998178941f87d', 'pipeline': 'aaf976c7c663a31fa039582d42f9e07101556a7c'}, 'duration': 2.589430093765259, 'iteration': 4, 'loss': 0.2544808950572157, 'max_history_score': 0.7455191049427843, 'max_history_score_std': 0.04843448308166839, 'max_history_step': 'joint', 'pipeline': {'features': ('features_NoneType', {}), 'normalizer': ('normalizer_PowerTransformer', {}), 'rebalance': ('rebalance_NoneType', {})}, 'score': 0.7455191049427843, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': None, 'max_features': 2, 'max_leaf_nodes': 5, 'min_samples_split': 5, 'n_estimators': 25}, 'config_hash': {'algorithm': 'fd8aeb6a05eaaba41e676d60596c8e0c71b35e0c', 'config': '1fc13606bca3aaf342ca6ea21139cb598b56f8db', 'pipeline': 'f00bd8de05642e026bbba4ad20d3a60088c86b6c'}, 'duration': 1.8779079914093018, 'iteration': 5, 'loss': 0.531551018758381, 'max_history_score': 0.7455191049427843, 'max_history_score_std': 0.04843448308166839, 'max_history_step': 'joint', 'pipeline': {'features': ('features_PCA', {'features__n_components': 2}), 'normalizer': ('normalizer_MinMaxScaler', {}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 5})}, 'score': 0.46844898124161904, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'entropy', 'max_depth': None, 'max_features': 2, 'max_leaf_nodes': None, 'min_samples_split': 2, 'n_estimators': 10}, 'config_hash': {'algorithm': 'a49ecb99e74217d6812f98ead7bc9d1fe4a53ba0', 'config': '6749af1a67b4dbcd2b4719e419d99908063c05e1', 'pipeline': '19bdf19a2eec5febce95ab8fa2a71040d75114aa'}, 'duration': 1.5498578548431396, 'iteration': 6, 'loss': 0.14471329609998995, 'max_history_score': 0.85528670390001, 'max_history_score_std': 0.02213730791268438, 'max_history_step': 'joint', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 4, 'features__selectkbest__k': 3}), 'normalizer': ('normalizer_NoneType', {}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 7})}, 'score': 0.85528670390001, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': 1, 'max_features': 3, 'max_leaf_nodes': 3, 'min_samples_split': 3, 'n_estimators': 75}, 'config_hash': {'algorithm': 'ebfb16234172ae811ff21185ff92bbdbb8f32f14', 'config': 'd92d4ada2394fc132733e176e926ee53acdc6a00', 'pipeline': '8071e7cbf86a5c3056493dc3aa40063aeb28cdfe'}, 'duration': 1.3618149757385254, 'iteration': 7, 'loss': 0.6158612049395463, 'max_history_score': 0.85528670390001, 'max_history_score_std': 0.02213730791268438, 'max_history_step': 'joint', 'pipeline': {'features': ('features_SelectKBest', {'features__k': 4}), 'normalizer': ('normalizer_StandardScaler', {'normalizer__with_mean': True, 'normalizer__with_std': True}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 5})}, 'score': 0.3841387950604537, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'entropy', 'max_depth': 1, 'max_features': 1, 'max_leaf_nodes': 5, 'min_samples_split': 2, 'n_estimators': 100}, 'config_hash': {'algorithm': '896b53c75a2db568fb7b6da3bfca2f7a1535a11b', 'config': 'f0d0b1d2cedc22ae15d9a208a3fc3fc133bf0d3d', 'pipeline': 'c9761c9a33bf75d6dcad0742c421548a7655ccc9'}, 'duration': 2.297278881072998, 'iteration': 8, 'loss': 0.40673663548410355, 'max_history_score': 0.85528670390001, 'max_history_score_std': 0.02213730791268438, 'max_history_step': 'joint', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 2, 'features__selectkbest__k': 4}), 'normalizer': ('normalizer_StandardScaler', {'normalizer__with_mean': False, 'normalizer__with_std': False}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 5})}, 'score': 0.5932633645158965, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'entropy', 'max_depth': 2, 'max_features': None, 'max_leaf_nodes': None, 'min_samples_split': 5, 'n_estimators': 25}, 'config_hash': {'algorithm': '0b0e954757c4f75343a6efb740ad93260ed781ae', 'config': '47584de0e60d0d12c7dbbf0dc60e5aea96e3f4b2', 'pipeline': 'b37ee32d59413053bf9a2a72c8ff7135f3701e05'}, 'duration': 0.7249000072479248, 'iteration': 9, 'loss': 0.6965910020393421, 'max_history_score': 0.85528670390001, 'max_history_score_std': 0.02213730791268438, 'max_history_step': 'joint', 'pipeline': {'features': ('features_SelectKBest', {'features__k': 3}), 'normalizer': ('normalizer_NoneType', {}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 7})}, 'score': 0.3034089979606579, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'gini', 'max_depth': 2, 'max_features': 2, 'max_leaf_nodes': 5, 'min_samples_split': 5, 'n_estimators': 75}, 'config_hash': {'algorithm': 'f1ead1d9e33ea927e1dd27d872a058fa3de4f832', 'config': 'eecb88ee2b1b95d741c1b5c7751534d31aae6a77', 'pipeline': '6746650871e8b61efc9302b092dc05f7cdb179d5'}, 'duration': 5.340634822845459, 'iteration': 10, 'loss': 0.7687016290977936, 'max_history_score': 0.85528670390001, 'max_history_score_std': 0.02213730791268438, 'max_history_step': 'joint', 'pipeline': {'features': ('features_SelectKBest', {'features__k': 3}), 'normalizer': ('normalizer_RobustScaler', {'normalizer__quantile_range': (...), 'normalizer__with_centering': False, 'normalizer__with_scaling': False}), 'rebalance': ('rebalance_CondensedNearestNeighbour', {'rebalance__n_neighbors': 1})}, 'score': 0.23129837090220637, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': 1, 'max_features': 2, 'max_leaf_nodes': 2, 'min_samples_split': 3, 'n_estimators': 75}, 'config_hash': {'algorithm': '531a3bb8ccf0baa06727af4b3de9e62d25e6eabf', 'config': '27a7ed0502b321ab7256b77c8ce79e90cb9da815', 'pipeline': '77e6d84e2217b92b3cf67cc6defef9dd3554cec0'}, 'duration': 1.775357961654663, 'iteration': 11, 'loss': 0.6313818737375694, 'max_history_score': 0.85528670390001, 'max_history_score_std': 0.02213730791268438, 'max_history_step': 'joint', 'pipeline': {'features': ('features_SelectKBest', {'features__k': 4}), 'normalizer': ('normalizer_MinMaxScaler', {}), 'rebalance': ('rebalance_NearMiss', {'rebalance__n_neighbors': 3})}, 'score': 0.3686181262624307, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'entropy', 'max_depth': 4, 'max_features': 3, 'max_leaf_nodes': 2, 'min_samples_split': 3, 'n_estimators': 10}, 'config_hash': {'algorithm': '93518f8ded6074d537900b26be72f8485782f933', 'config': '45f056102dd2d644bd8befa471f17b2311ac7954', 'pipeline': '5240329df25c9a533d025c1a401d49835a501b41'}, 'duration': 3.2622711658477783, 'iteration': 12, 'loss': 0.6120243191353301, 'max_history_score': 0.85528670390001, 'max_history_score_std': 0.02213730791268438, 'max_history_step': 'joint', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 4, 'features__selectkbest__k': 2}), 'normalizer': ('normalizer_PowerTransformer', {}), 'rebalance': ('rebalance_NearMiss', {'rebalance__n_neighbors': 1})}, 'score': 0.38797568086467, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'entropy', 'max_depth': None, 'max_features': 1, 'max_leaf_nodes': 5, 'min_samples_split': 3, 'n_estimators': 75}, 'config_hash': {'algorithm': 'e515d45b764fa43591032874a0ff9c25bf12fddd', 'config': 'ba108323623936872824ed8f1c41d615d25523b3', 'pipeline': '9d823bc0442f21b5ce8af67a5eb1237f64ffc2f8'}, 'duration': 2.5326571464538574, 'iteration': 13, 'loss': 0.6271427382991047, 'max_history_score': 0.85528670390001, 'max_history_score_std': 0.02213730791268438, 'max_history_step': 'joint', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 1, 'features__selectkbest__k': 1}), 'normalizer': ('normalizer_StandardScaler', {'normalizer__with_mean': True, 'normalizer__with_std': True}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 5})}, 'score': 0.3728572617008953, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'entropy', 'max_depth': 3, 'max_features': 2, 'max_leaf_nodes': 2, 'min_samples_split': 3, 'n_estimators': 25}, 'config_hash': {'algorithm': '2808e67f609eba5c8a97f81ac0c9413cd37cf7aa', 'config': 'dde4d3b5f37741629cb58bfc4051ed9f98c8f311', 'pipeline': 'bc52deabf1f5ee60968ba541d9d2574353c30a9c'}, 'duration': 0.7145559787750244, 'iteration': 14, 'loss': 0.6831045572696203, 'max_history_score': 0.85528670390001, 'max_history_score_std': 0.02213730791268438, 'max_history_step': 'joint', 'pipeline': {'features': ('features_SelectKBest', {'features__k': 3}), 'normalizer': ('normalizer_MinMaxScaler', {}), 'rebalance': ('rebalance_NearMiss', {'rebalance__n_neighbors': 1})}, 'score': 0.31689544273037973, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'gini', 'max_depth': 2, 'max_features': 2, 'max_leaf_nodes': None, 'min_samples_split': 5, 'n_estimators': 100}, 'config_hash': {'algorithm': 'b942acdead762d34afeb474bc2fe6f7fd0f23493', 'config': '1080c25b92da3f15a6f8eec003957f7e0a66324f', 'pipeline': 'cfa84fe703dc5bc0bbd2257a6d524fee2693b804'}, 'duration': 2.812459945678711, 'iteration': 15, 'loss': 0.6921421091202761, 'max_history_score': 0.85528670390001, 'max_history_score_std': 0.02213730791268438, 'max_history_step': 'joint', 'pipeline': {'features': ('features_SelectKBest', {'features__k': 2}), 'normalizer': ('normalizer_PowerTransformer', {}), 'rebalance': ('rebalance_NoneType', {})}, 'score': 0.3078578908797239, ...}], 'history_hash': ['fd24b065dda6bdeb1077793f9df480ff318c7a37', 'fb22f80fb4358ae1ee4c9bd4a83543992be8d806', '8c97cdb885dd05cfd8c40ee3ac445b61e5c767a8', '16fbb5fd5cfbbacfddf27c61c0c7397a7f6d8ade', 'a77c698197c31308211b854e81a998178941f87d', '1fc13606bca3aaf342ca6ea21139cb598b56f8db', '6749af1a67b4dbcd2b4719e419d99908063c05e1', 'd92d4ada2394fc132733e176e926ee53acdc6a00', 'f0d0b1d2cedc22ae15d9a208a3fc3fc133bf0d3d', '47584de0e60d0d12c7dbbf0dc60e5aea96e3f4b2', 'eecb88ee2b1b95d741c1b5c7751534d31aae6a77', '27a7ed0502b321ab7256b77c8ce79e90cb9da815', '45f056102dd2d644bd8befa471f17b2311ac7954', 'ba108323623936872824ed8f1c41d615d25523b3', 'dde4d3b5f37741629cb58bfc4051ed9f98c8f311', '1080c25b92da3f15a6f8eec003957f7e0a66324f'], 'history_index': {'1080c25b92da3f15a6f8eec003957f7e0a66324f': 15, '16fbb5fd5cfbbacfddf27c61c0c7397a7f6d8ade': 3, '1fc13606bca3aaf342ca6ea21139cb598b56f8db': 5, '27a7ed0502b321ab7256b77c8ce79e90cb9da815': 11, '45f056102dd2d644bd8befa471f17b2311ac7954': 12, '47584de0e60d0d12c7dbbf0dc60e5aea96e3f4b2': 9, '6749af1a67b4dbcd2b4719e419d99908063c05e1': 6, '8c97cdb885dd05cfd8c40ee3ac445b61e5c767a8': 2, 'a77c698197c31308211b854e81a998178941f87d': 4, 'ba108323623936872824ed8f1c41d615d25523b3': 13, ...}, 'iteration': 15, 'max_history_score': 0.85528670390001, 'max_history_score_std': 0.02213730791268438, 'max_history_step': 'joint'}, config={'algorithm': 'RandomForest', 'seed': 42, 'time': 300}, step='joint')
     45                 y,
     46                 cv=10,
     47                 n_jobs=-1,
     48                 return_estimator=False,
     49                 return_train_score=False,
---> 50                 verbose=0)
     51         score = np.mean(scores['test_score'])
     52         std = np.std(scores['test_score'])
     53         status = STATUS_OK
     54     except Exception as e:

...........................................................................
/home/aquemy/.local/lib/python2.7/site-packages/sklearn/model_selection/_validation.py in cross_validate(estimator=Pipeline(memory=None,
     steps=[('rebalance', ...e=42,
            verbose=0, warm_start=False))]), X=array([[ 0.,  0.,  5., ...,  0.,  0.,  0.],
    ...0.],
       [ 0.,  0., 10., ..., 12.,  1.,  0.]]), y=array([0, 1, 2, ..., 8, 9, 8]), groups=None, scoring=None, cv=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1, verbose=0, fit_params=None, pre_dispatch='2*n_jobs', return_train_score=False, return_estimator=False, error_score='raise-deprecating')
    235         delayed(_fit_and_score)(
    236             clone(estimator), X, y, scorers, train, test, verbose, None,
    237             fit_params, return_train_score=return_train_score,
    238             return_times=True, return_estimator=return_estimator,
    239             error_score=error_score)
--> 240         for train, test in cv.split(X, y, groups))
        cv.split = <bound method StratifiedKFold.split of Stratifie...d(n_splits=10, random_state=None, shuffle=False)>
        X = array([[ 0.,  0.,  5., ...,  0.,  0.,  0.],
    ...0.],
       [ 0.,  0., 10., ..., 12.,  1.,  0.]])
        y = array([0, 1, 2, ..., 8, 9, 8])
        groups = None
    241 
    242     zipped_scores = list(zip(*scores))
    243     if return_train_score:
    244         train_scores = zipped_scores.pop(0)

...........................................................................
/home/aquemy/.local/lib/python2.7/site-packages/sklearn/externals/joblib/parallel.py in __call__(self=Parallel(n_jobs=-1), iterable=<generator object <genexpr>>)
    925                 # No need to wait for async callbacks to trigger to
    926                 # consumption.
    927                 self._iterating = False
    928 
    929             with self._backend.retrieval_context():
--> 930                 self.retrieve()
        self.retrieve = <bound method Parallel.retrieve of Parallel(n_jobs=-1)>
    931             # Make sure that we get a last message telling us we are done
    932             elapsed_time = time.time() - self._start_time
    933             self._print('Done %3i out of %3i | elapsed: %s finished',
    934                         (len(self._output), len(self._output),

---------------------------------------------------------------------------
Joblib worker traceback:
---------------------------------------------------------------------------
ValueError                                         Mon Jun 17 13:06:03 2019
PID: 19890                                  Python 2.7.15+: /usr/bin/python
...........................................................................
/home/aquemy/.local/lib/python2.7/site-packages/sklearn/externals/joblib/parallel.py in __call__(self=<sklearn.externals.joblib.parallel.BatchedCalls object>)
    220     def __call__(self):
    221         # Set the default nested backend to self._backend but do not set the
    222         # change the default number of processes to -1
    223         with parallel_backend(self._backend, n_jobs=self._n_jobs):
    224             return [func(*args, **kwargs)
--> 225                     for func, args, kwargs in self.items]
        func = <function _fit_and_score>
        args = (Pipeline(memory=None,
     steps=[('rebalance', ...e=42,
            verbose=0, warm_start=False))]), array([[ 0.,  0.,  5., ...,  0.,  0.,  0.],
    ...0.],
       [ 0.,  0., 10., ..., 12.,  1.,  0.]]), array([0, 1, 2, ..., 8, 9, 8]), {'score': <function _passthrough_scorer>}, array([ 169,  176,  178, ..., 1794, 1795, 1796]), array([  0,   1,   2,   3,   4,   5,   6,   7,  ..., 181, 186, 188, 189, 190,
       194, 195, 198]), 0, None, None)
        kwargs = {'error_score': 'raise-deprecating', 'return_estimator': False, 'return_times': True, 'return_train_score': False}
        self.items = [(<function _fit_and_score>, (Pipeline(memory=None,
     steps=[('rebalance', ...e=42,
            verbose=0, warm_start=False))]), array([[ 0.,  0.,  5., ...,  0.,  0.,  0.],
    ...0.],
       [ 0.,  0., 10., ..., 12.,  1.,  0.]]), array([0, 1, 2, ..., 8, 9, 8]), {'score': <function _passthrough_scorer>}, array([ 169,  176,  178, ..., 1794, 1795, 1796]), array([  0,   1,   2,   3,   4,   5,   6,   7,  ..., 181, 186, 188, 189, 190,
       194, 195, 198]), 0, None, None), {'error_score': 'raise-deprecating', 'return_estimator': False, 'return_times': True, 'return_train_score': False})]
    226 
    227     def __len__(self):
    228         return self._size
    229 

...........................................................................
/home/aquemy/.local/lib/python2.7/site-packages/sklearn/model_selection/_validation.py in _fit_and_score(estimator=Pipeline(memory=None,
     steps=[('rebalance', ...e=42,
            verbose=0, warm_start=False))]), X=array([[ 0.,  0.,  5., ...,  0.,  0.,  0.],
    ...0.],
       [ 0.,  0., 10., ..., 12.,  1.,  0.]]), y=array([0, 1, 2, ..., 8, 9, 8]), scorer={'score': <function _passthrough_scorer>}, train=array([ 169,  176,  178, ..., 1794, 1795, 1796]), test=array([  0,   1,   2,   3,   4,   5,   6,   7,  ..., 181, 186, 188, 189, 190,
       194, 195, 198]), verbose=0, parameters=None, fit_params={}, return_train_score=False, return_parameters=False, return_n_test_samples=False, return_times=True, return_estimator=False, error_score='raise-deprecating')
    523 
    524     try:
    525         if y_train is None:
    526             estimator.fit(X_train, **fit_params)
    527         else:
--> 528             estimator.fit(X_train, y_train, **fit_params)
        estimator.fit = <bound method Pipeline.fit of Pipeline(memory=No...=42,
            verbose=0, warm_start=False))])>
        X_train = array([[ 0.,  0.,  6., ...,  9.,  4.,  0.],
    ...0.],
       [ 0.,  0., 10., ..., 12.,  1.,  0.]])
        y_train = array([9, 5, 0, ..., 8, 9, 8])
        fit_params = {}
    529 
    530     except Exception as e:
    531         # Note fit time as time until error
    532         fit_time = time.time() - start_time

...........................................................................
/usr/local/lib/python2.7/dist-packages/imblearn/pipeline.py in fit(self=Pipeline(memory=None,
     steps=[('rebalance', ...e=42,
            verbose=0, warm_start=False))]), X=array([[ 0.,  0.,  6., ...,  9.,  4.,  0.],
    ...0.],
       [ 0.,  0., 10., ..., 12.,  1.,  0.]]), y=array([9, 5, 0, ..., 8, 9, 8]), **fit_params={})
    234             This estimator
    235 
    236         """
    237         Xt, yt, fit_params = self._fit(X, y, **fit_params)
    238         if self._final_estimator is not None:
--> 239             self._final_estimator.fit(Xt, yt, **fit_params)
        self._final_estimator.fit = <bound method RandomForestClassifier.fit of Rand...ate=42,
            verbose=0, warm_start=False)>
        Xt = array([[-0.45290966, -0.2464417 ],
       [-0.49... 0.19450864],
       [-0.76158783,  2.70144655]])
        yt = array([0, 0, 0, ..., 9, 9, 9])
        fit_params = {}
    240         return self
    241 
    242     def fit_transform(self, X, y=None, **fit_params):
    243         """Fit the model and transform with the final estimator

...........................................................................
/home/aquemy/.local/lib/python2.7/site-packages/sklearn/ensemble/forest.py in fit(self=RandomForestClassifier(bootstrap=False, class_we...tate=42,
            verbose=0, warm_start=False), X=array([[-0.45290968, -0.2464417 ],
       [-0.49...      [-0.76158786,  2.7014465 ]], dtype=float32), y=array([[0.],
       [0.],
       [0.],
       ...,
       [9.],
       [9.],
       [9.]]), sample_weight=None)
    328             trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,
    329                              **_joblib_parallel_args(prefer='threads'))(
    330                 delayed(_parallel_build_trees)(
    331                     t, self, X, y, sample_weight, i, len(trees),
    332                     verbose=self.verbose, class_weight=self.class_weight)
--> 333                 for i, t in enumerate(trees))
        i = 74
    334 
    335             # Collect newly grown trees
    336             self.estimators_.extend(trees)
    337 

...........................................................................
/home/aquemy/.local/lib/python2.7/site-packages/sklearn/externals/joblib/parallel.py in __call__(self=Parallel(n_jobs=1), iterable=<generator object <genexpr>>)
    912             # self._original_iterator is None, then this means either
    913             # that pre_dispatch == "all", n_jobs == 1 or that the first batch
    914             # was very quick and its callback already dispatched all the
    915             # remaining jobs.
    916             self._iterating = False
--> 917             if self.dispatch_one_batch(iterator):
        self.dispatch_one_batch = <bound method Parallel.dispatch_one_batch of Parallel(n_jobs=1)>
        iterator = <generator object <genexpr>>
    918                 self._iterating = self._original_iterator is not None
    919 
    920             while self.dispatch_one_batch(iterator):
    921                 pass

...........................................................................
/home/aquemy/.local/lib/python2.7/site-packages/sklearn/externals/joblib/parallel.py in dispatch_one_batch(self=Parallel(n_jobs=1), iterator=<generator object <genexpr>>)
    754                                  self._pickle_cache)
    755             if len(tasks) == 0:
    756                 # No more tasks available in the iterator: tell caller to stop.
    757                 return False
    758             else:
--> 759                 self._dispatch(tasks)
        self._dispatch = <bound method Parallel._dispatch of Parallel(n_jobs=1)>
        tasks = <sklearn.externals.joblib.parallel.BatchedCalls object>
    760                 return True
    761 
    762     def _print(self, msg, msg_args):
    763         """Display the message on stout or stderr depending on verbosity"""

...........................................................................
/home/aquemy/.local/lib/python2.7/site-packages/sklearn/externals/joblib/parallel.py in _dispatch(self=Parallel(n_jobs=1), batch=<sklearn.externals.joblib.parallel.BatchedCalls object>)
    711 
    712         dispatch_timestamp = time.time()
    713         cb = BatchCompletionCallBack(dispatch_timestamp, len(batch), self)
    714         with self._lock:
    715             job_idx = len(self._jobs)
--> 716             job = self._backend.apply_async(batch, callback=cb)
        job = undefined
        self._backend.apply_async = <bound method SequentialBackend.apply_async of <...lib._parallel_backends.SequentialBackend object>>
        batch = <sklearn.externals.joblib.parallel.BatchedCalls object>
        cb = <sklearn.externals.joblib.parallel.BatchCompletionCallBack object>
    717             # A job can complete so quickly than its callback is
    718             # called before we get here, causing self._jobs to
    719             # grow. To ensure correct results ordering, .insert is
    720             # used (rather than .append) in the following line

...........................................................................
/home/aquemy/.local/lib/python2.7/site-packages/sklearn/externals/joblib/_parallel_backends.py in apply_async(self=<sklearn.externals.joblib._parallel_backends.SequentialBackend object>, func=<sklearn.externals.joblib.parallel.BatchedCalls object>, callback=<sklearn.externals.joblib.parallel.BatchCompletionCallBack object>)
    177             raise ValueError('n_jobs == 0 in Parallel has no meaning')
    178         return 1
    179 
    180     def apply_async(self, func, callback=None):
    181         """Schedule a func to be run"""
--> 182         result = ImmediateResult(func)
        result = undefined
        func = <sklearn.externals.joblib.parallel.BatchedCalls object>
    183         if callback:
    184             callback(result)
    185         return result
    186 

...........................................................................
/home/aquemy/.local/lib/python2.7/site-packages/sklearn/externals/joblib/_parallel_backends.py in __init__(self=<sklearn.externals.joblib._parallel_backends.ImmediateResult object>, batch=<sklearn.externals.joblib.parallel.BatchedCalls object>)
    544 
    545 class ImmediateResult(object):
    546     def __init__(self, batch):
    547         # Don't delay the application, to avoid keeping the input
    548         # arguments in memory
--> 549         self.results = batch()
        self.results = undefined
        batch = <sklearn.externals.joblib.parallel.BatchedCalls object>
    550 
    551     def get(self):
    552         return self.results
    553 

...........................................................................
/home/aquemy/.local/lib/python2.7/site-packages/sklearn/externals/joblib/parallel.py in __call__(self=<sklearn.externals.joblib.parallel.BatchedCalls object>)
    220     def __call__(self):
    221         # Set the default nested backend to self._backend but do not set the
    222         # change the default number of processes to -1
    223         with parallel_backend(self._backend, n_jobs=self._n_jobs):
    224             return [func(*args, **kwargs)
--> 225                     for func, args, kwargs in self.items]
        func = <function _parallel_build_trees>
        args = (DecisionTreeClassifier(class_weight=None, criter...=False, random_state=1608637542, splitter='best'), RandomForestClassifier(bootstrap=False, class_we...tate=42,
            verbose=0, warm_start=False), array([[-0.45290968, -0.2464417 ],
       [-0.49...      [-0.76158786,  2.7014465 ]], dtype=float32), array([[0.],
       [0.],
       [0.],
       ...,
       [9.],
       [9.],
       [9.]]), None, 0, 75)
        kwargs = {'class_weight': None, 'verbose': 0}
        self.items = [(<function _parallel_build_trees>, (DecisionTreeClassifier(class_weight=None, criter...=False, random_state=1608637542, splitter='best'), RandomForestClassifier(bootstrap=False, class_we...tate=42,
            verbose=0, warm_start=False), array([[-0.45290968, -0.2464417 ],
       [-0.49...      [-0.76158786,  2.7014465 ]], dtype=float32), array([[0.],
       [0.],
       [0.],
       ...,
       [9.],
       [9.],
       [9.]]), None, 0, 75), {'class_weight': None, 'verbose': 0})]
    226 
    227     def __len__(self):
    228         return self._size
    229 

...........................................................................
/home/aquemy/.local/lib/python2.7/site-packages/sklearn/ensemble/forest.py in _parallel_build_trees(tree=DecisionTreeClassifier(class_weight=None, criter...=False, random_state=1608637542, splitter='best'), forest=RandomForestClassifier(bootstrap=False, class_we...tate=42,
            verbose=0, warm_start=False), X=array([[-0.45290968, -0.2464417 ],
       [-0.49...      [-0.76158786,  2.7014465 ]], dtype=float32), y=array([[0.],
       [0.],
       [0.],
       ...,
       [9.],
       [9.],
       [9.]]), sample_weight=None, tree_idx=0, n_trees=75, verbose=0, class_weight=None)
    116         elif class_weight == 'balanced_subsample':
    117             curr_sample_weight *= compute_sample_weight('balanced', y, indices)
    118 
    119         tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)
    120     else:
--> 121         tree.fit(X, y, sample_weight=sample_weight, check_input=False)
        tree.fit = <bound method DecisionTreeClassifier.fit of Deci...False, random_state=1608637542, splitter='best')>
        X = array([[-0.45290968, -0.2464417 ],
       [-0.49...      [-0.76158786,  2.7014465 ]], dtype=float32)
        y = array([[0.],
       [0.],
       [0.],
       ...,
       [9.],
       [9.],
       [9.]])
        sample_weight = None
    122 
    123     return tree
    124 
    125 

...........................................................................
/home/aquemy/.local/lib/python2.7/site-packages/sklearn/tree/tree.py in fit(self=DecisionTreeClassifier(class_weight=None, criter...=False, random_state=1608637542, splitter='best'), X=array([[-0.45290968, -0.2464417 ],
       [-0.49...      [-0.76158786,  2.7014465 ]], dtype=float32), y=array([[0.],
       [0.],
       [0.],
       ...,
       [9.],
       [9.],
       [9.]]), sample_weight=None, check_input=False, X_idx_sorted=None)
    796 
    797         super(DecisionTreeClassifier, self).fit(
    798             X, y,
    799             sample_weight=sample_weight,
    800             check_input=check_input,
--> 801             X_idx_sorted=X_idx_sorted)
        X_idx_sorted = None
    802         return self
    803 
    804     def predict_proba(self, X, check_input=True):
    805         """Predict class probabilities of the input samples X.

...........................................................................
/home/aquemy/.local/lib/python2.7/site-packages/sklearn/tree/tree.py in fit(self=DecisionTreeClassifier(class_weight=None, criter...=False, random_state=1608637542, splitter='best'), X=array([[-0.45290968, -0.2464417 ],
       [-0.49...      [-0.76158786,  2.7014465 ]], dtype=float32), y=array([[0.],
       [0.],
       [0.],
       ...,
       [9.],
       [9.],
       [9.]]), sample_weight=None, check_input=False, X_idx_sorted=None)
    237         if not 0 <= self.min_weight_fraction_leaf <= 0.5:
    238             raise ValueError("min_weight_fraction_leaf must in [0, 0.5]")
    239         if max_depth <= 0:
    240             raise ValueError("max_depth must be greater than zero. ")
    241         if not (0 < max_features <= self.n_features_):
--> 242             raise ValueError("max_features must be in (0, n_features]")
    243         if not isinstance(max_leaf_nodes, (numbers.Integral, np.integer)):
    244             raise ValueError("max_leaf_nodes must be integral number but was "
    245                              "%r" % max_leaf_nodes)
    246         if -1 < max_leaf_nodes < 2:

ValueError: max_features must be in (0, n_features]
___________________________________________________________________________
Best score: 0.8552867039 (0.0221373079127) [J] | Score: 0.0 (0.0) [J]
Best score: 0.8552867039 (0.0221373079127) [J] | Score: 0.271084884488 (0.0505944721634) [J]
Best score: 0.8552867039 (0.0221373079127) [J] | Score: 0.3454097487 (0.0266868606139) [J]
Best score: 0.8552867039 (0.0221373079127) [J] | Score: 0.346317459665 (0.0354499624637) [J]
Best score: 0.8552867039 (0.0221373079127) [J] | Score: 0.49667372345 (0.053404977182) [J]
Best score: 0.8552867039 (0.0221373079127) [J] | Score: 0.716723559139 (0.0313136406084) [J]
Best score: 0.8552867039 (0.0221373079127) [J] | Score: 0.49667372345 (0.053404977182) [J]
Best score: 0.8552867039 (0.0221373079127) [J] | Score: 0.758351324748 (0.051115263537) [J]
Best score: 0.8552867039 (0.0221373079127) [J] | Score: 0.665308582238 (0.062550778979) [J]
JoblibValueError
___________________________________________________________________________
...........................................................................
/home/aquemy/dev/dp_hyperparameters/extension/main.py in <module>()
     27 
     28     serializer.serialize_results(scenario, policy)
     29 
     30 if __name__ == "__main__":
     31     args = cli.parse_args()
---> 32     main(args)

...........................................................................
/home/aquemy/dev/dp_hyperparameters/extension/main.py in main(args=Namespace(customize=[(['control', 'seed'], '42')...='./scenarios/rf_digits_joint.yaml', verbosity=0))
     21         test_size=0.4, 
     22         random_state=scenario['control']['seed']
     23     )
     24 
     25     policy = policies.initiate(scenario['setup']['policy'], config)
---> 26     policy.run(X,y)
        policy.run = <bound method Joint.run of <experiment.policies.joint.Joint object>>
        X = array([[ 0.,  0.,  5., ...,  0.,  0.,  0.],
    ...0.],
       [ 0.,  0., 10., ..., 12.,  1.,  0.]])
        y = array([0, 1, 2, ..., 8, 9, 8])
     27 
     28     serializer.serialize_results(scenario, policy)
     29 
     30 if __name__ == "__main__":

...........................................................................
/home/aquemy/dev/dp_hyperparameters/extension/experiment/policies/joint.py in run(self=<experiment.policies.joint.Joint object>, X=array([[ 0.,  0.,  5., ...,  0.,  0.,  0.],
    ...0.],
       [ 0.,  0., 10., ..., 12.,  1.,  0.]]), y=array([0, 1, 2, ..., 8, 9, 8]))
     32             algo=tpe.suggest, 
     33             max_evals=None,
     34             max_time=self.config['time'],     
     35             trials=trials,
     36             show_progressbar=False,
---> 37             verbose=0
     38         )
     39 
     40         best_config = self.context['best_config']
     41         super(Joint, self).display_step_results(best_config)

...........................................................................
/home/aquemy/dev/dp_hyperparameters/extension/hyperopt/fmin.py in fmin(fn=<functools.partial object>, space={'algorithm': {'bootstrap': <hyperopt.pyll.base.Apply object>, 'criterion': <hyperopt.pyll.base.Apply object>, 'max_depth': <hyperopt.pyll.base.Apply object>, 'max_features': <hyperopt.pyll.base.Apply object>, 'max_leaf_nodes': <hyperopt.pyll.base.Apply object>, 'min_samples_split': <hyperopt.pyll.base.Apply object>, 'n_estimators': <hyperopt.pyll.base.Apply object>}, 'pipeline': {'features': <hyperopt.pyll.base.Apply object>, 'normalizer': <hyperopt.pyll.base.Apply object>, 'rebalance': <hyperopt.pyll.base.Apply object>}}, algo=<function suggest>, max_evals=9223372036854775807, max_time=300, trials=<hyperopt.base.Trials object>, rstate=<mtrand.RandomState object>, allow_trials_fmin=True, pass_expr_memo_ctrl=None, catch_eval_exceptions=False, verbose=0, return_argmin=True, points_to_evaluate=None, max_queue_len=1, show_progressbar=False)
    406             pass_expr_memo_ctrl=pass_expr_memo_ctrl,
    407             verbose=verbose,
    408             catch_eval_exceptions=catch_eval_exceptions,
    409             return_argmin=return_argmin,
    410             show_progressbar=show_progressbar,
--> 411             max_time=max_time
        max_time = 300
    412         )
    413 
    414     if trials is None:
    415         if points_to_evaluate is None:

...........................................................................
/home/aquemy/dev/dp_hyperparameters/extension/hyperopt/base.py in fmin(self=<hyperopt.base.Trials object>, fn=<functools.partial object>, space={'algorithm': {'bootstrap': <hyperopt.pyll.base.Apply object>, 'criterion': <hyperopt.pyll.base.Apply object>, 'max_depth': <hyperopt.pyll.base.Apply object>, 'max_features': <hyperopt.pyll.base.Apply object>, 'max_leaf_nodes': <hyperopt.pyll.base.Apply object>, 'min_samples_split': <hyperopt.pyll.base.Apply object>, 'n_estimators': <hyperopt.pyll.base.Apply object>}, 'pipeline': {'features': <hyperopt.pyll.base.Apply object>, 'normalizer': <hyperopt.pyll.base.Apply object>, 'rebalance': <hyperopt.pyll.base.Apply object>}}, algo=<function suggest>, max_evals=9223372036854775807, max_time=300, rstate=<mtrand.RandomState object>, verbose=0, pass_expr_memo_ctrl=None, catch_eval_exceptions=False, return_argmin=True, show_progressbar=False)
    636             verbose=verbose,
    637             allow_trials_fmin=False,  # -- prevent recursion
    638             pass_expr_memo_ctrl=pass_expr_memo_ctrl,
    639             catch_eval_exceptions=catch_eval_exceptions,
    640             return_argmin=return_argmin,
--> 641             show_progressbar=show_progressbar)
        show_progressbar = False
    642 
    643 
    644 def trials_from_docs(docs, validate=True, **kwargs):
    645     """Construct a Trials base class instance from a list of trials documents

...........................................................................
/home/aquemy/dev/dp_hyperparameters/extension/hyperopt/fmin.py in fmin(fn=<functools.partial object>, space={'algorithm': {'bootstrap': <hyperopt.pyll.base.Apply object>, 'criterion': <hyperopt.pyll.base.Apply object>, 'max_depth': <hyperopt.pyll.base.Apply object>, 'max_features': <hyperopt.pyll.base.Apply object>, 'max_leaf_nodes': <hyperopt.pyll.base.Apply object>, 'min_samples_split': <hyperopt.pyll.base.Apply object>, 'n_estimators': <hyperopt.pyll.base.Apply object>}, 'pipeline': {'features': <hyperopt.pyll.base.Apply object>, 'normalizer': <hyperopt.pyll.base.Apply object>, 'rebalance': <hyperopt.pyll.base.Apply object>}}, algo=<function suggest>, max_evals=9223372036854775807, max_time=300, trials=<hyperopt.base.Trials object>, rstate=<mtrand.RandomState object>, allow_trials_fmin=False, pass_expr_memo_ctrl=None, catch_eval_exceptions=False, verbose=0, return_argmin=True, points_to_evaluate=None, max_queue_len=1, show_progressbar=False)
    426                     verbose=verbose,
    427                     max_queue_len=max_queue_len,
    428                     show_progressbar=show_progressbar,
    429                     max_time=max_time)
    430     rval.catch_eval_exceptions = catch_eval_exceptions
--> 431     rval.exhaust()
        rval.exhaust = <bound method FMinIter.exhaust of <hyperopt.fmin.FMinIter object>>
    432     if return_argmin:
    433         return trials.argmin
    434     elif len(trials) > 0:
    435         # Only if there are some succesfull trail runs, return the best point in the evaluation space

...........................................................................
/home/aquemy/dev/dp_hyperparameters/extension/hyperopt/fmin.py in exhaust(self=<hyperopt.fmin.FMinIter object>)
    273             raise StopIteration()
    274         return self.trials
    275 
    276     def exhaust(self):
    277         n_done = len(self.trials)
--> 278         self.run(self.max_evals - n_done, block_until_done=self.asynchronous)
        self.run = <bound method FMinIter.run of <hyperopt.fmin.FMinIter object>>
        self.max_evals = 9223372036854775807
        n_done = 0
        self.asynchronous = False
    279         self.trials.refresh()
    280         return self
    281 
    282 

...........................................................................
/home/aquemy/dev/dp_hyperparameters/extension/hyperopt/fmin.py in run(self=<hyperopt.fmin.FMinIter object>, N=9223372036854775807, block_until_done=False)
    232                     if self.asynchronous:
    233                         # -- wait for workers to fill in the trials
    234                         time.sleep(self.poll_interval_secs)
    235                     else:
    236                         # -- loop over trials and do the jobs directly
--> 237                         self.serial_evaluate()
        self.serial_evaluate = <bound method FMinIter.serial_evaluate of <hyperopt.fmin.FMinIter object>>
    238                     try:
    239                         res = [d['result']['loss'] for d in
    240                                          self.trials.trials if
    241                                          d['result']['status'] == 'ok']

...........................................................................
/home/aquemy/dev/dp_hyperparameters/extension/hyperopt/fmin.py in serial_evaluate(self=<hyperopt.fmin.FMinIter object>, N=-1)
    138                 trial['book_time'] = now
    139                 trial['refresh_time'] = now
    140                 spec = base.spec_from_misc(trial['misc'])
    141                 ctrl = base.Ctrl(self.trials, current_trial=trial)
    142                 try:
--> 143                     result = self.domain.evaluate(spec, ctrl)
        result = undefined
        self.domain.evaluate = <bound method Domain.evaluate of <hyperopt.base.Domain object>>
        spec = {'bootstrap': 1, 'criterion': 1, 'features': 1, 'features_PCA_features__n_components': 0, 'max_depth': 2, 'max_features': 1, 'max_leaf_nodes': 3, 'min_samples_split': 0, 'n_estimators': 0, 'normalizer': 0, ...}
        ctrl = <hyperopt.base.Ctrl object>
    144                 except Exception as e:
    145                     logger.info('job exception: %s' % str(e))
    146                     trial['state'] = base.JOB_STATE_ERROR
    147                     trial['misc']['error'] = (str(type(e)), str(e))

...........................................................................
/home/aquemy/dev/dp_hyperparameters/extension/hyperopt/base.py in evaluate(self=<hyperopt.base.Domain object>, config={'bootstrap': 1, 'criterion': 1, 'features': 1, 'features_PCA_features__n_components': 0, 'max_depth': 2, 'max_features': 1, 'max_leaf_nodes': 3, 'min_samples_split': 0, 'n_estimators': 0, 'normalizer': 0, ...}, ctrl=<hyperopt.base.Ctrl object>, attach_attachments=True)
    841             #    or the normal Python part (self.fn)
    842             pyll_rval = pyll.rec_eval(
    843                 self.expr,
    844                 memo=memo,
    845                 print_node_on_error=self.rec_eval_print_node_on_error)
--> 846             rval = self.fn(pyll_rval)
        rval = undefined
        self.fn = <functools.partial object>
        pyll_rval = {'algorithm': {'bootstrap': False, 'criterion': 'entropy', 'max_depth': 3, 'max_features': 2, 'max_leaf_nodes': None, 'min_samples_split': 2, 'n_estimators': 10}, 'pipeline': {'features': ('features_PCA', {'features__n_components': 1}), 'normalizer': ('normalizer_NoneType', {}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 7})}}
    847 
    848         if isinstance(rval, (float, int, np.number)):
    849             dict_rval = {'loss': float(rval), 'status': STATUS_OK}
    850         else:

...........................................................................
/home/aquemy/dev/dp_hyperparameters/extension/experiment/objective.py in objective_joint(wconfig={'algorithm': {'bootstrap': False, 'criterion': 'entropy', 'max_depth': 3, 'max_features': 2, 'max_leaf_nodes': None, 'min_samples_split': 2, 'n_estimators': 10}, 'pipeline': {'features': ('features_PCA', {'features__n_components': 1}), 'normalizer': ('normalizer_NoneType', {}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 7})}}, algorithm='RandomForest', X=array([[ 0.,  0.,  5., ...,  0.,  0.,  0.],
    ...0.],
       [ 0.,  0., 10., ..., 12.,  1.,  0.]]), y=array([0, 1, 2, ..., 8, 9, 8]), context={'baseline_score': 0.9272021217853512, 'baseline_score_std': 0.026919033284817703, 'best_config': {'algorithm': {'bootstrap': False, 'criterion': 'entropy', 'max_depth': None, 'max_features': 2, 'max_leaf_nodes': None, 'min_samples_split': 2, 'n_estimators': 10}, 'config_hash': {'algorithm': 'a49ecb99e74217d6812f98ead7bc9d1fe4a53ba0', 'config': '6749af1a67b4dbcd2b4719e419d99908063c05e1', 'pipeline': '19bdf19a2eec5febce95ab8fa2a71040d75114aa'}, 'duration': 1.5498578548431396, 'iteration': 6, 'loss': 0.14471329609998995, 'max_history_score': 0.85528670390001, 'max_history_score_std': 0.02213730791268438, 'max_history_step': 'joint', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 4, 'features__selectkbest__k': 3}), 'normalizer': ('normalizer_NoneType', {}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 7})}, 'score': 0.85528670390001, ...}, 'history': [{'algorithm': {'bootstrap': False, 'criterion': 'entropy', 'max_depth': 1, 'max_features': 3, 'max_leaf_nodes': 3, 'min_samples_split': 5, 'n_estimators': 50}, 'config_hash': {'algorithm': '752fa095cdab58a238ae606c613606188964cc0c', 'config': 'fd24b065dda6bdeb1077793f9df480ff318c7a37', 'pipeline': '13ea3359c453b8993fcec1e88bc0e19cd0a2b112'}, 'duration': 0.689669132232666, 'iteration': 0, 'loss': 0.6602879519109309, 'max_history_score': 0.3397120480890691, 'max_history_score_std': 0.03346542949100545, 'max_history_step': 'joint', 'pipeline': {'features': ('features_SelectKBest', {'features__k': 4}), 'normalizer': ('normalizer_MinMaxScaler', {}), 'rebalance': ('rebalance_NoneType', {})}, 'score': 0.3397120480890691, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'gini', 'max_depth': 4, 'max_features': 1, 'max_leaf_nodes': 5, 'min_samples_split': 3, 'n_estimators': 25}, 'config_hash': {'algorithm': '9d9de4aee820052ddfe83bfffca420f6b50837d3', 'config': 'fb22f80fb4358ae1ee4c9bd4a83543992be8d806', 'pipeline': '6251ad4bb7a110726a67f90c319f4717ac37a312'}, 'duration': 1.4300940036773682, 'iteration': 1, 'loss': 0.5122196101741096, 'max_history_score': 0.48778038982589045, 'max_history_score_std': 0.05486079759217226, 'max_history_step': 'joint', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 2, 'features__selectkbest__k': 2}), 'normalizer': ('normalizer_StandardScaler', {'normalizer__with_mean': True, 'normalizer__with_std': True}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 5})}, 'score': 0.48778038982589045, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': 4, 'max_features': 1, 'max_leaf_nodes': None, 'min_samples_split': 2, 'n_estimators': 10}, 'config_hash': {'algorithm': '2ed7d27df9a1b2d5e63da76f7cb309616c232022', 'config': '8c97cdb885dd05cfd8c40ee3ac445b61e5c767a8', 'pipeline': 'c0abb5e23a4739d3120740a9519fb36c43eb94d5'}, 'duration': 3.0036678314208984, 'iteration': 2, 'loss': 0.38319264175312906, 'max_history_score': 0.6168073582468709, 'max_history_score_std': 0.05286679173001824, 'max_history_step': 'joint', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 1, 'features__selectkbest__k': 4}), 'normalizer': ('normalizer_PowerTransformer', {}), 'rebalance': ('rebalance_NearMiss', {'rebalance__n_neighbors': 2})}, 'score': 0.6168073582468709, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'entropy', 'max_depth': None, 'max_features': None, 'max_leaf_nodes': 2, 'min_samples_split': 2, 'n_estimators': 100}, 'config_hash': {'algorithm': '17962655e3b76dfcd0843d1e5c2cb7a9db1c6a79', 'config': '16fbb5fd5cfbbacfddf27c61c0c7397a7f6d8ade', 'pipeline': '13ea3359c453b8993fcec1e88bc0e19cd0a2b112'}, 'duration': 1.3447980880737305, 'iteration': 3, 'loss': 0.6768840987778313, 'max_history_score': 0.6168073582468709, 'max_history_score_std': 0.05286679173001824, 'max_history_step': 'joint', 'pipeline': {'features': ('features_SelectKBest', {'features__k': 4}), 'normalizer': ('normalizer_MinMaxScaler', {}), 'rebalance': ('rebalance_NoneType', {})}, 'score': 0.32311590122216866, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'gini', 'max_depth': 2, 'max_features': 2, 'max_leaf_nodes': 2, 'min_samples_split': 3, 'n_estimators': 100}, 'config_hash': {'algorithm': '1ea8965b2247f86950e54510ee6d79399816341b', 'config': 'a77c698197c31308211b854e81a998178941f87d', 'pipeline': 'aaf976c7c663a31fa039582d42f9e07101556a7c'}, 'duration': 2.589430093765259, 'iteration': 4, 'loss': 0.2544808950572157, 'max_history_score': 0.7455191049427843, 'max_history_score_std': 0.04843448308166839, 'max_history_step': 'joint', 'pipeline': {'features': ('features_NoneType', {}), 'normalizer': ('normalizer_PowerTransformer', {}), 'rebalance': ('rebalance_NoneType', {})}, 'score': 0.7455191049427843, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': None, 'max_features': 2, 'max_leaf_nodes': 5, 'min_samples_split': 5, 'n_estimators': 25}, 'config_hash': {'algorithm': 'fd8aeb6a05eaaba41e676d60596c8e0c71b35e0c', 'config': '1fc13606bca3aaf342ca6ea21139cb598b56f8db', 'pipeline': 'f00bd8de05642e026bbba4ad20d3a60088c86b6c'}, 'duration': 1.8779079914093018, 'iteration': 5, 'loss': 0.531551018758381, 'max_history_score': 0.7455191049427843, 'max_history_score_std': 0.04843448308166839, 'max_history_step': 'joint', 'pipeline': {'features': ('features_PCA', {'features__n_components': 2}), 'normalizer': ('normalizer_MinMaxScaler', {}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 5})}, 'score': 0.46844898124161904, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'entropy', 'max_depth': None, 'max_features': 2, 'max_leaf_nodes': None, 'min_samples_split': 2, 'n_estimators': 10}, 'config_hash': {'algorithm': 'a49ecb99e74217d6812f98ead7bc9d1fe4a53ba0', 'config': '6749af1a67b4dbcd2b4719e419d99908063c05e1', 'pipeline': '19bdf19a2eec5febce95ab8fa2a71040d75114aa'}, 'duration': 1.5498578548431396, 'iteration': 6, 'loss': 0.14471329609998995, 'max_history_score': 0.85528670390001, 'max_history_score_std': 0.02213730791268438, 'max_history_step': 'joint', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 4, 'features__selectkbest__k': 3}), 'normalizer': ('normalizer_NoneType', {}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 7})}, 'score': 0.85528670390001, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': 1, 'max_features': 3, 'max_leaf_nodes': 3, 'min_samples_split': 3, 'n_estimators': 75}, 'config_hash': {'algorithm': 'ebfb16234172ae811ff21185ff92bbdbb8f32f14', 'config': 'd92d4ada2394fc132733e176e926ee53acdc6a00', 'pipeline': '8071e7cbf86a5c3056493dc3aa40063aeb28cdfe'}, 'duration': 1.3618149757385254, 'iteration': 7, 'loss': 0.6158612049395463, 'max_history_score': 0.85528670390001, 'max_history_score_std': 0.02213730791268438, 'max_history_step': 'joint', 'pipeline': {'features': ('features_SelectKBest', {'features__k': 4}), 'normalizer': ('normalizer_StandardScaler', {'normalizer__with_mean': True, 'normalizer__with_std': True}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 5})}, 'score': 0.3841387950604537, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'entropy', 'max_depth': 1, 'max_features': 1, 'max_leaf_nodes': 5, 'min_samples_split': 2, 'n_estimators': 100}, 'config_hash': {'algorithm': '896b53c75a2db568fb7b6da3bfca2f7a1535a11b', 'config': 'f0d0b1d2cedc22ae15d9a208a3fc3fc133bf0d3d', 'pipeline': 'c9761c9a33bf75d6dcad0742c421548a7655ccc9'}, 'duration': 2.297278881072998, 'iteration': 8, 'loss': 0.40673663548410355, 'max_history_score': 0.85528670390001, 'max_history_score_std': 0.02213730791268438, 'max_history_step': 'joint', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 2, 'features__selectkbest__k': 4}), 'normalizer': ('normalizer_StandardScaler', {'normalizer__with_mean': False, 'normalizer__with_std': False}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 5})}, 'score': 0.5932633645158965, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'entropy', 'max_depth': 2, 'max_features': None, 'max_leaf_nodes': None, 'min_samples_split': 5, 'n_estimators': 25}, 'config_hash': {'algorithm': '0b0e954757c4f75343a6efb740ad93260ed781ae', 'config': '47584de0e60d0d12c7dbbf0dc60e5aea96e3f4b2', 'pipeline': 'b37ee32d59413053bf9a2a72c8ff7135f3701e05'}, 'duration': 0.7249000072479248, 'iteration': 9, 'loss': 0.6965910020393421, 'max_history_score': 0.85528670390001, 'max_history_score_std': 0.02213730791268438, 'max_history_step': 'joint', 'pipeline': {'features': ('features_SelectKBest', {'features__k': 3}), 'normalizer': ('normalizer_NoneType', {}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 7})}, 'score': 0.3034089979606579, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'gini', 'max_depth': 2, 'max_features': 2, 'max_leaf_nodes': 5, 'min_samples_split': 5, 'n_estimators': 75}, 'config_hash': {'algorithm': 'f1ead1d9e33ea927e1dd27d872a058fa3de4f832', 'config': 'eecb88ee2b1b95d741c1b5c7751534d31aae6a77', 'pipeline': '6746650871e8b61efc9302b092dc05f7cdb179d5'}, 'duration': 5.340634822845459, 'iteration': 10, 'loss': 0.7687016290977936, 'max_history_score': 0.85528670390001, 'max_history_score_std': 0.02213730791268438, 'max_history_step': 'joint', 'pipeline': {'features': ('features_SelectKBest', {'features__k': 3}), 'normalizer': ('normalizer_RobustScaler', {'normalizer__quantile_range': (...), 'normalizer__with_centering': False, 'normalizer__with_scaling': False}), 'rebalance': ('rebalance_CondensedNearestNeighbour', {'rebalance__n_neighbors': 1})}, 'score': 0.23129837090220637, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': 1, 'max_features': 2, 'max_leaf_nodes': 2, 'min_samples_split': 3, 'n_estimators': 75}, 'config_hash': {'algorithm': '531a3bb8ccf0baa06727af4b3de9e62d25e6eabf', 'config': '27a7ed0502b321ab7256b77c8ce79e90cb9da815', 'pipeline': '77e6d84e2217b92b3cf67cc6defef9dd3554cec0'}, 'duration': 1.775357961654663, 'iteration': 11, 'loss': 0.6313818737375694, 'max_history_score': 0.85528670390001, 'max_history_score_std': 0.02213730791268438, 'max_history_step': 'joint', 'pipeline': {'features': ('features_SelectKBest', {'features__k': 4}), 'normalizer': ('normalizer_MinMaxScaler', {}), 'rebalance': ('rebalance_NearMiss', {'rebalance__n_neighbors': 3})}, 'score': 0.3686181262624307, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'entropy', 'max_depth': 4, 'max_features': 3, 'max_leaf_nodes': 2, 'min_samples_split': 3, 'n_estimators': 10}, 'config_hash': {'algorithm': '93518f8ded6074d537900b26be72f8485782f933', 'config': '45f056102dd2d644bd8befa471f17b2311ac7954', 'pipeline': '5240329df25c9a533d025c1a401d49835a501b41'}, 'duration': 3.2622711658477783, 'iteration': 12, 'loss': 0.6120243191353301, 'max_history_score': 0.85528670390001, 'max_history_score_std': 0.02213730791268438, 'max_history_step': 'joint', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 4, 'features__selectkbest__k': 2}), 'normalizer': ('normalizer_PowerTransformer', {}), 'rebalance': ('rebalance_NearMiss', {'rebalance__n_neighbors': 1})}, 'score': 0.38797568086467, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'entropy', 'max_depth': None, 'max_features': 1, 'max_leaf_nodes': 5, 'min_samples_split': 3, 'n_estimators': 75}, 'config_hash': {'algorithm': 'e515d45b764fa43591032874a0ff9c25bf12fddd', 'config': 'ba108323623936872824ed8f1c41d615d25523b3', 'pipeline': '9d823bc0442f21b5ce8af67a5eb1237f64ffc2f8'}, 'duration': 2.5326571464538574, 'iteration': 13, 'loss': 0.6271427382991047, 'max_history_score': 0.85528670390001, 'max_history_score_std': 0.02213730791268438, 'max_history_step': 'joint', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 1, 'features__selectkbest__k': 1}), 'normalizer': ('normalizer_StandardScaler', {'normalizer__with_mean': True, 'normalizer__with_std': True}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 5})}, 'score': 0.3728572617008953, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'entropy', 'max_depth': 3, 'max_features': 2, 'max_leaf_nodes': 2, 'min_samples_split': 3, 'n_estimators': 25}, 'config_hash': {'algorithm': '2808e67f609eba5c8a97f81ac0c9413cd37cf7aa', 'config': 'dde4d3b5f37741629cb58bfc4051ed9f98c8f311', 'pipeline': 'bc52deabf1f5ee60968ba541d9d2574353c30a9c'}, 'duration': 0.7145559787750244, 'iteration': 14, 'loss': 0.6831045572696203, 'max_history_score': 0.85528670390001, 'max_history_score_std': 0.02213730791268438, 'max_history_step': 'joint', 'pipeline': {'features': ('features_SelectKBest', {'features__k': 3}), 'normalizer': ('normalizer_MinMaxScaler', {}), 'rebalance': ('rebalance_NearMiss', {'rebalance__n_neighbors': 1})}, 'score': 0.31689544273037973, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'gini', 'max_depth': 2, 'max_features': 2, 'max_leaf_nodes': None, 'min_samples_split': 5, 'n_estimators': 100}, 'config_hash': {'algorithm': 'b942acdead762d34afeb474bc2fe6f7fd0f23493', 'config': '1080c25b92da3f15a6f8eec003957f7e0a66324f', 'pipeline': 'cfa84fe703dc5bc0bbd2257a6d524fee2693b804'}, 'duration': 2.812459945678711, 'iteration': 15, 'loss': 0.6921421091202761, 'max_history_score': 0.85528670390001, 'max_history_score_std': 0.02213730791268438, 'max_history_step': 'joint', 'pipeline': {'features': ('features_SelectKBest', {'features__k': 2}), 'normalizer': ('normalizer_PowerTransformer', {}), 'rebalance': ('rebalance_NoneType', {})}, 'score': 0.3078578908797239, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'entropy', 'max_depth': 2, 'max_features': 3, 'max_leaf_nodes': 3, 'min_samples_split': 2, 'n_estimators': 75}, 'config_hash': {'algorithm': '250661ce4193a61ef44d2f77694b52b785ff032d', 'config': 'c3e8cf4eca5aafcae4ac31b0449e105ca127ffe2', 'pipeline': 'c4dd111513ea35f97dd3aec3e8e7f6268ce035da'}, 'duration': 1.0555319786071777, 'iteration': 16, 'loss': 1.0, 'max_history_score': 0.85528670390001, 'max_history_score_std': 0.02213730791268438, 'max_history_step': 'joint', 'pipeline': {'features': ('features_PCA', {'features__n_components': 2}), 'normalizer': ('normalizer_RobustScaler', {'normalizer__quantile_range': (...), 'normalizer__with_centering': False, 'normalizer__with_scaling': True}), 'rebalance': ('rebalance_NearMiss', {'rebalance__n_neighbors': 2})}, 'score': 0.0, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'entropy', 'max_depth': 3, 'max_features': 3, 'max_leaf_nodes': None, 'min_samples_split': 3, 'n_estimators': 25}, 'config_hash': {'algorithm': '05ac02bd045c65dc4089894902ad6253661a2692', 'config': '3449b4a1c2e488e26a7195ee9edca19b854ebd33', 'pipeline': '505d3f71b534917375d765e64b0611e7dfb83746'}, 'duration': 5.5412821769714355, 'iteration': 17, 'loss': 0.7289151155121668, 'max_history_score': 0.85528670390001, 'max_history_score_std': 0.02213730791268438, 'max_history_step': 'joint', 'pipeline': {'features': ('features_SelectKBest', {'features__k': 4}), 'normalizer': ('normalizer_MinMaxScaler', {}), 'rebalance': ('rebalance_CondensedNearestNeighbour', {'rebalance__n_neighbors': 2})}, 'score': 0.2710848844878332, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'entropy', 'max_depth': 2, 'max_features': None, 'max_leaf_nodes': None, 'min_samples_split': 2, 'n_estimators': 25}, 'config_hash': {'algorithm': 'de3b3a352ebb260e16c6b213a08c9144d17a744b', 'config': '224987ffdbbb9b6182cff18d8374518b917e4f2e', 'pipeline': '12c89200a558b2f3b91332566f41050143aecbe7'}, 'duration': 2.4646048545837402, 'iteration': 18, 'loss': 0.6545902512995826, 'max_history_score': 0.85528670390001, 'max_history_score_std': 0.02213730791268438, 'max_history_step': 'joint', 'pipeline': {'features': ('features_NoneType', {}), 'normalizer': ('normalizer_PowerTransformer', {}), 'rebalance': ('rebalance_NearMiss', {'rebalance__n_neighbors': 2})}, 'score': 0.3454097487004174, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'gini', 'max_depth': None, 'max_features': 1, 'max_leaf_nodes': None, 'min_samples_split': 3, 'n_estimators': 100}, 'config_hash': {'algorithm': '30ca111584767bbf0464df40b4c928cf7ddf9459', 'config': '97ca7d6a017c721084dec2a5d2e5a67e1e6ae2f0', 'pipeline': '789eca82ea4a42d61927670c538867b745fd81d3'}, 'duration': 7.164499044418335, 'iteration': 19, 'loss': 0.6536825403350528, 'max_history_score': 0.85528670390001, 'max_history_score_std': 0.02213730791268438, 'max_history_step': 'joint', 'pipeline': {'features': ('features_SelectKBest', {'features__k': 3}), 'normalizer': ('normalizer_RobustScaler', {'normalizer__quantile_range': (...), 'normalizer__with_centering': False, 'normalizer__with_scaling': True}), 'rebalance': ('rebalance_CondensedNearestNeighbour', {'rebalance__n_neighbors': 3})}, 'score': 0.3463174596649472, ...}, ...], 'history_hash': ['fd24b065dda6bdeb1077793f9df480ff318c7a37', 'fb22f80fb4358ae1ee4c9bd4a83543992be8d806', '8c97cdb885dd05cfd8c40ee3ac445b61e5c767a8', '16fbb5fd5cfbbacfddf27c61c0c7397a7f6d8ade', 'a77c698197c31308211b854e81a998178941f87d', '1fc13606bca3aaf342ca6ea21139cb598b56f8db', '6749af1a67b4dbcd2b4719e419d99908063c05e1', 'd92d4ada2394fc132733e176e926ee53acdc6a00', 'f0d0b1d2cedc22ae15d9a208a3fc3fc133bf0d3d', '47584de0e60d0d12c7dbbf0dc60e5aea96e3f4b2', 'eecb88ee2b1b95d741c1b5c7751534d31aae6a77', '27a7ed0502b321ab7256b77c8ce79e90cb9da815', '45f056102dd2d644bd8befa471f17b2311ac7954', 'ba108323623936872824ed8f1c41d615d25523b3', 'dde4d3b5f37741629cb58bfc4051ed9f98c8f311', '1080c25b92da3f15a6f8eec003957f7e0a66324f', 'c3e8cf4eca5aafcae4ac31b0449e105ca127ffe2', '3449b4a1c2e488e26a7195ee9edca19b854ebd33', '224987ffdbbb9b6182cff18d8374518b917e4f2e', '97ca7d6a017c721084dec2a5d2e5a67e1e6ae2f0', ...], 'history_index': {'1080c25b92da3f15a6f8eec003957f7e0a66324f': 15, '16fbb5fd5cfbbacfddf27c61c0c7397a7f6d8ade': 3, '1fc13606bca3aaf342ca6ea21139cb598b56f8db': 5, '224987ffdbbb9b6182cff18d8374518b917e4f2e': 18, '27a7ed0502b321ab7256b77c8ce79e90cb9da815': 11, '3449b4a1c2e488e26a7195ee9edca19b854ebd33': 17, '3567266057a9169d1e19b5468ae8b24572886e03': 23, '45f056102dd2d644bd8befa471f17b2311ac7954': 12, '47584de0e60d0d12c7dbbf0dc60e5aea96e3f4b2': 9, '6536b5f456395080138aa989f7ae7d2dc4251725': 22, ...}, 'iteration': 24, 'max_history_score': 0.85528670390001, 'max_history_score_std': 0.02213730791268438, 'max_history_step': 'joint'}, config={'algorithm': 'RandomForest', 'seed': 42, 'time': 300})
    108 
    109 def objective_algo(algo_config, current_pipeline_config, algorithm, X, y, context, config):
    110     return objective(current_pipeline_config, algo_config, algorithm, X, y, context, config, step='algorithm')
    111 
    112 def objective_joint(wconfig, algorithm, X, y, context, config):
--> 113     return objective(wconfig['pipeline'], wconfig['algorithm'], algorithm, X, y, context, config, step='joint')
        wconfig = {'algorithm': {'bootstrap': False, 'criterion': 'entropy', 'max_depth': 3, 'max_features': 2, 'max_leaf_nodes': None, 'min_samples_split': 2, 'n_estimators': 10}, 'pipeline': {'features': ('features_PCA', {'features__n_components': 1}), 'normalizer': ('normalizer_NoneType', {}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 7})}}
        algorithm = 'RandomForest'
        X = array([[ 0.,  0.,  5., ...,  0.,  0.,  0.],
    ...0.],
       [ 0.,  0., 10., ..., 12.,  1.,  0.]])
        y = array([0, 1, 2, ..., 8, 9, 8])
        context = {'baseline_score': 0.9272021217853512, 'baseline_score_std': 0.026919033284817703, 'best_config': {'algorithm': {'bootstrap': False, 'criterion': 'entropy', 'max_depth': None, 'max_features': 2, 'max_leaf_nodes': None, 'min_samples_split': 2, 'n_estimators': 10}, 'config_hash': {'algorithm': 'a49ecb99e74217d6812f98ead7bc9d1fe4a53ba0', 'config': '6749af1a67b4dbcd2b4719e419d99908063c05e1', 'pipeline': '19bdf19a2eec5febce95ab8fa2a71040d75114aa'}, 'duration': 1.5498578548431396, 'iteration': 6, 'loss': 0.14471329609998995, 'max_history_score': 0.85528670390001, 'max_history_score_std': 0.02213730791268438, 'max_history_step': 'joint', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 4, 'features__selectkbest__k': 3}), 'normalizer': ('normalizer_NoneType', {}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 7})}, 'score': 0.85528670390001, ...}, 'history': [{'algorithm': {'bootstrap': False, 'criterion': 'entropy', 'max_depth': 1, 'max_features': 3, 'max_leaf_nodes': 3, 'min_samples_split': 5, 'n_estimators': 50}, 'config_hash': {'algorithm': '752fa095cdab58a238ae606c613606188964cc0c', 'config': 'fd24b065dda6bdeb1077793f9df480ff318c7a37', 'pipeline': '13ea3359c453b8993fcec1e88bc0e19cd0a2b112'}, 'duration': 0.689669132232666, 'iteration': 0, 'loss': 0.6602879519109309, 'max_history_score': 0.3397120480890691, 'max_history_score_std': 0.03346542949100545, 'max_history_step': 'joint', 'pipeline': {'features': ('features_SelectKBest', {'features__k': 4}), 'normalizer': ('normalizer_MinMaxScaler', {}), 'rebalance': ('rebalance_NoneType', {})}, 'score': 0.3397120480890691, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'gini', 'max_depth': 4, 'max_features': 1, 'max_leaf_nodes': 5, 'min_samples_split': 3, 'n_estimators': 25}, 'config_hash': {'algorithm': '9d9de4aee820052ddfe83bfffca420f6b50837d3', 'config': 'fb22f80fb4358ae1ee4c9bd4a83543992be8d806', 'pipeline': '6251ad4bb7a110726a67f90c319f4717ac37a312'}, 'duration': 1.4300940036773682, 'iteration': 1, 'loss': 0.5122196101741096, 'max_history_score': 0.48778038982589045, 'max_history_score_std': 0.05486079759217226, 'max_history_step': 'joint', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 2, 'features__selectkbest__k': 2}), 'normalizer': ('normalizer_StandardScaler', {'normalizer__with_mean': True, 'normalizer__with_std': True}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 5})}, 'score': 0.48778038982589045, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': 4, 'max_features': 1, 'max_leaf_nodes': None, 'min_samples_split': 2, 'n_estimators': 10}, 'config_hash': {'algorithm': '2ed7d27df9a1b2d5e63da76f7cb309616c232022', 'config': '8c97cdb885dd05cfd8c40ee3ac445b61e5c767a8', 'pipeline': 'c0abb5e23a4739d3120740a9519fb36c43eb94d5'}, 'duration': 3.0036678314208984, 'iteration': 2, 'loss': 0.38319264175312906, 'max_history_score': 0.6168073582468709, 'max_history_score_std': 0.05286679173001824, 'max_history_step': 'joint', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 1, 'features__selectkbest__k': 4}), 'normalizer': ('normalizer_PowerTransformer', {}), 'rebalance': ('rebalance_NearMiss', {'rebalance__n_neighbors': 2})}, 'score': 0.6168073582468709, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'entropy', 'max_depth': None, 'max_features': None, 'max_leaf_nodes': 2, 'min_samples_split': 2, 'n_estimators': 100}, 'config_hash': {'algorithm': '17962655e3b76dfcd0843d1e5c2cb7a9db1c6a79', 'config': '16fbb5fd5cfbbacfddf27c61c0c7397a7f6d8ade', 'pipeline': '13ea3359c453b8993fcec1e88bc0e19cd0a2b112'}, 'duration': 1.3447980880737305, 'iteration': 3, 'loss': 0.6768840987778313, 'max_history_score': 0.6168073582468709, 'max_history_score_std': 0.05286679173001824, 'max_history_step': 'joint', 'pipeline': {'features': ('features_SelectKBest', {'features__k': 4}), 'normalizer': ('normalizer_MinMaxScaler', {}), 'rebalance': ('rebalance_NoneType', {})}, 'score': 0.32311590122216866, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'gini', 'max_depth': 2, 'max_features': 2, 'max_leaf_nodes': 2, 'min_samples_split': 3, 'n_estimators': 100}, 'config_hash': {'algorithm': '1ea8965b2247f86950e54510ee6d79399816341b', 'config': 'a77c698197c31308211b854e81a998178941f87d', 'pipeline': 'aaf976c7c663a31fa039582d42f9e07101556a7c'}, 'duration': 2.589430093765259, 'iteration': 4, 'loss': 0.2544808950572157, 'max_history_score': 0.7455191049427843, 'max_history_score_std': 0.04843448308166839, 'max_history_step': 'joint', 'pipeline': {'features': ('features_NoneType', {}), 'normalizer': ('normalizer_PowerTransformer', {}), 'rebalance': ('rebalance_NoneType', {})}, 'score': 0.7455191049427843, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': None, 'max_features': 2, 'max_leaf_nodes': 5, 'min_samples_split': 5, 'n_estimators': 25}, 'config_hash': {'algorithm': 'fd8aeb6a05eaaba41e676d60596c8e0c71b35e0c', 'config': '1fc13606bca3aaf342ca6ea21139cb598b56f8db', 'pipeline': 'f00bd8de05642e026bbba4ad20d3a60088c86b6c'}, 'duration': 1.8779079914093018, 'iteration': 5, 'loss': 0.531551018758381, 'max_history_score': 0.7455191049427843, 'max_history_score_std': 0.04843448308166839, 'max_history_step': 'joint', 'pipeline': {'features': ('features_PCA', {'features__n_components': 2}), 'normalizer': ('normalizer_MinMaxScaler', {}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 5})}, 'score': 0.46844898124161904, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'entropy', 'max_depth': None, 'max_features': 2, 'max_leaf_nodes': None, 'min_samples_split': 2, 'n_estimators': 10}, 'config_hash': {'algorithm': 'a49ecb99e74217d6812f98ead7bc9d1fe4a53ba0', 'config': '6749af1a67b4dbcd2b4719e419d99908063c05e1', 'pipeline': '19bdf19a2eec5febce95ab8fa2a71040d75114aa'}, 'duration': 1.5498578548431396, 'iteration': 6, 'loss': 0.14471329609998995, 'max_history_score': 0.85528670390001, 'max_history_score_std': 0.02213730791268438, 'max_history_step': 'joint', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 4, 'features__selectkbest__k': 3}), 'normalizer': ('normalizer_NoneType', {}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 7})}, 'score': 0.85528670390001, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': 1, 'max_features': 3, 'max_leaf_nodes': 3, 'min_samples_split': 3, 'n_estimators': 75}, 'config_hash': {'algorithm': 'ebfb16234172ae811ff21185ff92bbdbb8f32f14', 'config': 'd92d4ada2394fc132733e176e926ee53acdc6a00', 'pipeline': '8071e7cbf86a5c3056493dc3aa40063aeb28cdfe'}, 'duration': 1.3618149757385254, 'iteration': 7, 'loss': 0.6158612049395463, 'max_history_score': 0.85528670390001, 'max_history_score_std': 0.02213730791268438, 'max_history_step': 'joint', 'pipeline': {'features': ('features_SelectKBest', {'features__k': 4}), 'normalizer': ('normalizer_StandardScaler', {'normalizer__with_mean': True, 'normalizer__with_std': True}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 5})}, 'score': 0.3841387950604537, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'entropy', 'max_depth': 1, 'max_features': 1, 'max_leaf_nodes': 5, 'min_samples_split': 2, 'n_estimators': 100}, 'config_hash': {'algorithm': '896b53c75a2db568fb7b6da3bfca2f7a1535a11b', 'config': 'f0d0b1d2cedc22ae15d9a208a3fc3fc133bf0d3d', 'pipeline': 'c9761c9a33bf75d6dcad0742c421548a7655ccc9'}, 'duration': 2.297278881072998, 'iteration': 8, 'loss': 0.40673663548410355, 'max_history_score': 0.85528670390001, 'max_history_score_std': 0.02213730791268438, 'max_history_step': 'joint', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 2, 'features__selectkbest__k': 4}), 'normalizer': ('normalizer_StandardScaler', {'normalizer__with_mean': False, 'normalizer__with_std': False}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 5})}, 'score': 0.5932633645158965, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'entropy', 'max_depth': 2, 'max_features': None, 'max_leaf_nodes': None, 'min_samples_split': 5, 'n_estimators': 25}, 'config_hash': {'algorithm': '0b0e954757c4f75343a6efb740ad93260ed781ae', 'config': '47584de0e60d0d12c7dbbf0dc60e5aea96e3f4b2', 'pipeline': 'b37ee32d59413053bf9a2a72c8ff7135f3701e05'}, 'duration': 0.7249000072479248, 'iteration': 9, 'loss': 0.6965910020393421, 'max_history_score': 0.85528670390001, 'max_history_score_std': 0.02213730791268438, 'max_history_step': 'joint', 'pipeline': {'features': ('features_SelectKBest', {'features__k': 3}), 'normalizer': ('normalizer_NoneType', {}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 7})}, 'score': 0.3034089979606579, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'gini', 'max_depth': 2, 'max_features': 2, 'max_leaf_nodes': 5, 'min_samples_split': 5, 'n_estimators': 75}, 'config_hash': {'algorithm': 'f1ead1d9e33ea927e1dd27d872a058fa3de4f832', 'config': 'eecb88ee2b1b95d741c1b5c7751534d31aae6a77', 'pipeline': '6746650871e8b61efc9302b092dc05f7cdb179d5'}, 'duration': 5.340634822845459, 'iteration': 10, 'loss': 0.7687016290977936, 'max_history_score': 0.85528670390001, 'max_history_score_std': 0.02213730791268438, 'max_history_step': 'joint', 'pipeline': {'features': ('features_SelectKBest', {'features__k': 3}), 'normalizer': ('normalizer_RobustScaler', {'normalizer__quantile_range': (...), 'normalizer__with_centering': False, 'normalizer__with_scaling': False}), 'rebalance': ('rebalance_CondensedNearestNeighbour', {'rebalance__n_neighbors': 1})}, 'score': 0.23129837090220637, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': 1, 'max_features': 2, 'max_leaf_nodes': 2, 'min_samples_split': 3, 'n_estimators': 75}, 'config_hash': {'algorithm': '531a3bb8ccf0baa06727af4b3de9e62d25e6eabf', 'config': '27a7ed0502b321ab7256b77c8ce79e90cb9da815', 'pipeline': '77e6d84e2217b92b3cf67cc6defef9dd3554cec0'}, 'duration': 1.775357961654663, 'iteration': 11, 'loss': 0.6313818737375694, 'max_history_score': 0.85528670390001, 'max_history_score_std': 0.02213730791268438, 'max_history_step': 'joint', 'pipeline': {'features': ('features_SelectKBest', {'features__k': 4}), 'normalizer': ('normalizer_MinMaxScaler', {}), 'rebalance': ('rebalance_NearMiss', {'rebalance__n_neighbors': 3})}, 'score': 0.3686181262624307, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'entropy', 'max_depth': 4, 'max_features': 3, 'max_leaf_nodes': 2, 'min_samples_split': 3, 'n_estimators': 10}, 'config_hash': {'algorithm': '93518f8ded6074d537900b26be72f8485782f933', 'config': '45f056102dd2d644bd8befa471f17b2311ac7954', 'pipeline': '5240329df25c9a533d025c1a401d49835a501b41'}, 'duration': 3.2622711658477783, 'iteration': 12, 'loss': 0.6120243191353301, 'max_history_score': 0.85528670390001, 'max_history_score_std': 0.02213730791268438, 'max_history_step': 'joint', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 4, 'features__selectkbest__k': 2}), 'normalizer': ('normalizer_PowerTransformer', {}), 'rebalance': ('rebalance_NearMiss', {'rebalance__n_neighbors': 1})}, 'score': 0.38797568086467, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'entropy', 'max_depth': None, 'max_features': 1, 'max_leaf_nodes': 5, 'min_samples_split': 3, 'n_estimators': 75}, 'config_hash': {'algorithm': 'e515d45b764fa43591032874a0ff9c25bf12fddd', 'config': 'ba108323623936872824ed8f1c41d615d25523b3', 'pipeline': '9d823bc0442f21b5ce8af67a5eb1237f64ffc2f8'}, 'duration': 2.5326571464538574, 'iteration': 13, 'loss': 0.6271427382991047, 'max_history_score': 0.85528670390001, 'max_history_score_std': 0.02213730791268438, 'max_history_step': 'joint', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 1, 'features__selectkbest__k': 1}), 'normalizer': ('normalizer_StandardScaler', {'normalizer__with_mean': True, 'normalizer__with_std': True}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 5})}, 'score': 0.3728572617008953, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'entropy', 'max_depth': 3, 'max_features': 2, 'max_leaf_nodes': 2, 'min_samples_split': 3, 'n_estimators': 25}, 'config_hash': {'algorithm': '2808e67f609eba5c8a97f81ac0c9413cd37cf7aa', 'config': 'dde4d3b5f37741629cb58bfc4051ed9f98c8f311', 'pipeline': 'bc52deabf1f5ee60968ba541d9d2574353c30a9c'}, 'duration': 0.7145559787750244, 'iteration': 14, 'loss': 0.6831045572696203, 'max_history_score': 0.85528670390001, 'max_history_score_std': 0.02213730791268438, 'max_history_step': 'joint', 'pipeline': {'features': ('features_SelectKBest', {'features__k': 3}), 'normalizer': ('normalizer_MinMaxScaler', {}), 'rebalance': ('rebalance_NearMiss', {'rebalance__n_neighbors': 1})}, 'score': 0.31689544273037973, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'gini', 'max_depth': 2, 'max_features': 2, 'max_leaf_nodes': None, 'min_samples_split': 5, 'n_estimators': 100}, 'config_hash': {'algorithm': 'b942acdead762d34afeb474bc2fe6f7fd0f23493', 'config': '1080c25b92da3f15a6f8eec003957f7e0a66324f', 'pipeline': 'cfa84fe703dc5bc0bbd2257a6d524fee2693b804'}, 'duration': 2.812459945678711, 'iteration': 15, 'loss': 0.6921421091202761, 'max_history_score': 0.85528670390001, 'max_history_score_std': 0.02213730791268438, 'max_history_step': 'joint', 'pipeline': {'features': ('features_SelectKBest', {'features__k': 2}), 'normalizer': ('normalizer_PowerTransformer', {}), 'rebalance': ('rebalance_NoneType', {})}, 'score': 0.3078578908797239, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'entropy', 'max_depth': 2, 'max_features': 3, 'max_leaf_nodes': 3, 'min_samples_split': 2, 'n_estimators': 75}, 'config_hash': {'algorithm': '250661ce4193a61ef44d2f77694b52b785ff032d', 'config': 'c3e8cf4eca5aafcae4ac31b0449e105ca127ffe2', 'pipeline': 'c4dd111513ea35f97dd3aec3e8e7f6268ce035da'}, 'duration': 1.0555319786071777, 'iteration': 16, 'loss': 1.0, 'max_history_score': 0.85528670390001, 'max_history_score_std': 0.02213730791268438, 'max_history_step': 'joint', 'pipeline': {'features': ('features_PCA', {'features__n_components': 2}), 'normalizer': ('normalizer_RobustScaler', {'normalizer__quantile_range': (...), 'normalizer__with_centering': False, 'normalizer__with_scaling': True}), 'rebalance': ('rebalance_NearMiss', {'rebalance__n_neighbors': 2})}, 'score': 0.0, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'entropy', 'max_depth': 3, 'max_features': 3, 'max_leaf_nodes': None, 'min_samples_split': 3, 'n_estimators': 25}, 'config_hash': {'algorithm': '05ac02bd045c65dc4089894902ad6253661a2692', 'config': '3449b4a1c2e488e26a7195ee9edca19b854ebd33', 'pipeline': '505d3f71b534917375d765e64b0611e7dfb83746'}, 'duration': 5.5412821769714355, 'iteration': 17, 'loss': 0.7289151155121668, 'max_history_score': 0.85528670390001, 'max_history_score_std': 0.02213730791268438, 'max_history_step': 'joint', 'pipeline': {'features': ('features_SelectKBest', {'features__k': 4}), 'normalizer': ('normalizer_MinMaxScaler', {}), 'rebalance': ('rebalance_CondensedNearestNeighbour', {'rebalance__n_neighbors': 2})}, 'score': 0.2710848844878332, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'entropy', 'max_depth': 2, 'max_features': None, 'max_leaf_nodes': None, 'min_samples_split': 2, 'n_estimators': 25}, 'config_hash': {'algorithm': 'de3b3a352ebb260e16c6b213a08c9144d17a744b', 'config': '224987ffdbbb9b6182cff18d8374518b917e4f2e', 'pipeline': '12c89200a558b2f3b91332566f41050143aecbe7'}, 'duration': 2.4646048545837402, 'iteration': 18, 'loss': 0.6545902512995826, 'max_history_score': 0.85528670390001, 'max_history_score_std': 0.02213730791268438, 'max_history_step': 'joint', 'pipeline': {'features': ('features_NoneType', {}), 'normalizer': ('normalizer_PowerTransformer', {}), 'rebalance': ('rebalance_NearMiss', {'rebalance__n_neighbors': 2})}, 'score': 0.3454097487004174, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'gini', 'max_depth': None, 'max_features': 1, 'max_leaf_nodes': None, 'min_samples_split': 3, 'n_estimators': 100}, 'config_hash': {'algorithm': '30ca111584767bbf0464df40b4c928cf7ddf9459', 'config': '97ca7d6a017c721084dec2a5d2e5a67e1e6ae2f0', 'pipeline': '789eca82ea4a42d61927670c538867b745fd81d3'}, 'duration': 7.164499044418335, 'iteration': 19, 'loss': 0.6536825403350528, 'max_history_score': 0.85528670390001, 'max_history_score_std': 0.02213730791268438, 'max_history_step': 'joint', 'pipeline': {'features': ('features_SelectKBest', {'features__k': 3}), 'normalizer': ('normalizer_RobustScaler', {'normalizer__quantile_range': (...), 'normalizer__with_centering': False, 'normalizer__with_scaling': True}), 'rebalance': ('rebalance_CondensedNearestNeighbour', {'rebalance__n_neighbors': 3})}, 'score': 0.3463174596649472, ...}, ...], 'history_hash': ['fd24b065dda6bdeb1077793f9df480ff318c7a37', 'fb22f80fb4358ae1ee4c9bd4a83543992be8d806', '8c97cdb885dd05cfd8c40ee3ac445b61e5c767a8', '16fbb5fd5cfbbacfddf27c61c0c7397a7f6d8ade', 'a77c698197c31308211b854e81a998178941f87d', '1fc13606bca3aaf342ca6ea21139cb598b56f8db', '6749af1a67b4dbcd2b4719e419d99908063c05e1', 'd92d4ada2394fc132733e176e926ee53acdc6a00', 'f0d0b1d2cedc22ae15d9a208a3fc3fc133bf0d3d', '47584de0e60d0d12c7dbbf0dc60e5aea96e3f4b2', 'eecb88ee2b1b95d741c1b5c7751534d31aae6a77', '27a7ed0502b321ab7256b77c8ce79e90cb9da815', '45f056102dd2d644bd8befa471f17b2311ac7954', 'ba108323623936872824ed8f1c41d615d25523b3', 'dde4d3b5f37741629cb58bfc4051ed9f98c8f311', '1080c25b92da3f15a6f8eec003957f7e0a66324f', 'c3e8cf4eca5aafcae4ac31b0449e105ca127ffe2', '3449b4a1c2e488e26a7195ee9edca19b854ebd33', '224987ffdbbb9b6182cff18d8374518b917e4f2e', '97ca7d6a017c721084dec2a5d2e5a67e1e6ae2f0', ...], 'history_index': {'1080c25b92da3f15a6f8eec003957f7e0a66324f': 15, '16fbb5fd5cfbbacfddf27c61c0c7397a7f6d8ade': 3, '1fc13606bca3aaf342ca6ea21139cb598b56f8db': 5, '224987ffdbbb9b6182cff18d8374518b917e4f2e': 18, '27a7ed0502b321ab7256b77c8ce79e90cb9da815': 11, '3449b4a1c2e488e26a7195ee9edca19b854ebd33': 17, '3567266057a9169d1e19b5468ae8b24572886e03': 23, '45f056102dd2d644bd8befa471f17b2311ac7954': 12, '47584de0e60d0d12c7dbbf0dc60e5aea96e3f4b2': 9, '6536b5f456395080138aa989f7ae7d2dc4251725': 22, ...}, 'iteration': 24, 'max_history_score': 0.85528670390001, 'max_history_score_std': 0.02213730791268438, 'max_history_step': 'joint'}
        config = {'algorithm': 'RandomForest', 'seed': 42, 'time': 300}
    114 
    115 
    116 def get_baseline_score(algorithm, X, y, seed):
    117     pipeline, _ = pipeline_conf_to_full_pipeline(

...........................................................................
/home/aquemy/dev/dp_hyperparameters/extension/experiment/objective.py in objective(pipeline_config={'features': ('features_PCA', {'features__n_components': 1}), 'normalizer': ('normalizer_NoneType', {}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 7})}, algo_config={'bootstrap': False, 'criterion': 'entropy', 'max_depth': 3, 'max_features': 2, 'max_leaf_nodes': None, 'min_samples_split': 2, 'n_estimators': 10}, algorithm='RandomForest', X=array([[ 0.,  0.,  5., ...,  0.,  0.,  0.],
    ...0.],
       [ 0.,  0., 10., ..., 12.,  1.,  0.]]), y=array([0, 1, 2, ..., 8, 9, 8]), context={'baseline_score': 0.9272021217853512, 'baseline_score_std': 0.026919033284817703, 'best_config': {'algorithm': {'bootstrap': False, 'criterion': 'entropy', 'max_depth': None, 'max_features': 2, 'max_leaf_nodes': None, 'min_samples_split': 2, 'n_estimators': 10}, 'config_hash': {'algorithm': 'a49ecb99e74217d6812f98ead7bc9d1fe4a53ba0', 'config': '6749af1a67b4dbcd2b4719e419d99908063c05e1', 'pipeline': '19bdf19a2eec5febce95ab8fa2a71040d75114aa'}, 'duration': 1.5498578548431396, 'iteration': 6, 'loss': 0.14471329609998995, 'max_history_score': 0.85528670390001, 'max_history_score_std': 0.02213730791268438, 'max_history_step': 'joint', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 4, 'features__selectkbest__k': 3}), 'normalizer': ('normalizer_NoneType', {}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 7})}, 'score': 0.85528670390001, ...}, 'history': [{'algorithm': {'bootstrap': False, 'criterion': 'entropy', 'max_depth': 1, 'max_features': 3, 'max_leaf_nodes': 3, 'min_samples_split': 5, 'n_estimators': 50}, 'config_hash': {'algorithm': '752fa095cdab58a238ae606c613606188964cc0c', 'config': 'fd24b065dda6bdeb1077793f9df480ff318c7a37', 'pipeline': '13ea3359c453b8993fcec1e88bc0e19cd0a2b112'}, 'duration': 0.689669132232666, 'iteration': 0, 'loss': 0.6602879519109309, 'max_history_score': 0.3397120480890691, 'max_history_score_std': 0.03346542949100545, 'max_history_step': 'joint', 'pipeline': {'features': ('features_SelectKBest', {'features__k': 4}), 'normalizer': ('normalizer_MinMaxScaler', {}), 'rebalance': ('rebalance_NoneType', {})}, 'score': 0.3397120480890691, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'gini', 'max_depth': 4, 'max_features': 1, 'max_leaf_nodes': 5, 'min_samples_split': 3, 'n_estimators': 25}, 'config_hash': {'algorithm': '9d9de4aee820052ddfe83bfffca420f6b50837d3', 'config': 'fb22f80fb4358ae1ee4c9bd4a83543992be8d806', 'pipeline': '6251ad4bb7a110726a67f90c319f4717ac37a312'}, 'duration': 1.4300940036773682, 'iteration': 1, 'loss': 0.5122196101741096, 'max_history_score': 0.48778038982589045, 'max_history_score_std': 0.05486079759217226, 'max_history_step': 'joint', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 2, 'features__selectkbest__k': 2}), 'normalizer': ('normalizer_StandardScaler', {'normalizer__with_mean': True, 'normalizer__with_std': True}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 5})}, 'score': 0.48778038982589045, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': 4, 'max_features': 1, 'max_leaf_nodes': None, 'min_samples_split': 2, 'n_estimators': 10}, 'config_hash': {'algorithm': '2ed7d27df9a1b2d5e63da76f7cb309616c232022', 'config': '8c97cdb885dd05cfd8c40ee3ac445b61e5c767a8', 'pipeline': 'c0abb5e23a4739d3120740a9519fb36c43eb94d5'}, 'duration': 3.0036678314208984, 'iteration': 2, 'loss': 0.38319264175312906, 'max_history_score': 0.6168073582468709, 'max_history_score_std': 0.05286679173001824, 'max_history_step': 'joint', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 1, 'features__selectkbest__k': 4}), 'normalizer': ('normalizer_PowerTransformer', {}), 'rebalance': ('rebalance_NearMiss', {'rebalance__n_neighbors': 2})}, 'score': 0.6168073582468709, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'entropy', 'max_depth': None, 'max_features': None, 'max_leaf_nodes': 2, 'min_samples_split': 2, 'n_estimators': 100}, 'config_hash': {'algorithm': '17962655e3b76dfcd0843d1e5c2cb7a9db1c6a79', 'config': '16fbb5fd5cfbbacfddf27c61c0c7397a7f6d8ade', 'pipeline': '13ea3359c453b8993fcec1e88bc0e19cd0a2b112'}, 'duration': 1.3447980880737305, 'iteration': 3, 'loss': 0.6768840987778313, 'max_history_score': 0.6168073582468709, 'max_history_score_std': 0.05286679173001824, 'max_history_step': 'joint', 'pipeline': {'features': ('features_SelectKBest', {'features__k': 4}), 'normalizer': ('normalizer_MinMaxScaler', {}), 'rebalance': ('rebalance_NoneType', {})}, 'score': 0.32311590122216866, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'gini', 'max_depth': 2, 'max_features': 2, 'max_leaf_nodes': 2, 'min_samples_split': 3, 'n_estimators': 100}, 'config_hash': {'algorithm': '1ea8965b2247f86950e54510ee6d79399816341b', 'config': 'a77c698197c31308211b854e81a998178941f87d', 'pipeline': 'aaf976c7c663a31fa039582d42f9e07101556a7c'}, 'duration': 2.589430093765259, 'iteration': 4, 'loss': 0.2544808950572157, 'max_history_score': 0.7455191049427843, 'max_history_score_std': 0.04843448308166839, 'max_history_step': 'joint', 'pipeline': {'features': ('features_NoneType', {}), 'normalizer': ('normalizer_PowerTransformer', {}), 'rebalance': ('rebalance_NoneType', {})}, 'score': 0.7455191049427843, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': None, 'max_features': 2, 'max_leaf_nodes': 5, 'min_samples_split': 5, 'n_estimators': 25}, 'config_hash': {'algorithm': 'fd8aeb6a05eaaba41e676d60596c8e0c71b35e0c', 'config': '1fc13606bca3aaf342ca6ea21139cb598b56f8db', 'pipeline': 'f00bd8de05642e026bbba4ad20d3a60088c86b6c'}, 'duration': 1.8779079914093018, 'iteration': 5, 'loss': 0.531551018758381, 'max_history_score': 0.7455191049427843, 'max_history_score_std': 0.04843448308166839, 'max_history_step': 'joint', 'pipeline': {'features': ('features_PCA', {'features__n_components': 2}), 'normalizer': ('normalizer_MinMaxScaler', {}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 5})}, 'score': 0.46844898124161904, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'entropy', 'max_depth': None, 'max_features': 2, 'max_leaf_nodes': None, 'min_samples_split': 2, 'n_estimators': 10}, 'config_hash': {'algorithm': 'a49ecb99e74217d6812f98ead7bc9d1fe4a53ba0', 'config': '6749af1a67b4dbcd2b4719e419d99908063c05e1', 'pipeline': '19bdf19a2eec5febce95ab8fa2a71040d75114aa'}, 'duration': 1.5498578548431396, 'iteration': 6, 'loss': 0.14471329609998995, 'max_history_score': 0.85528670390001, 'max_history_score_std': 0.02213730791268438, 'max_history_step': 'joint', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 4, 'features__selectkbest__k': 3}), 'normalizer': ('normalizer_NoneType', {}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 7})}, 'score': 0.85528670390001, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': 1, 'max_features': 3, 'max_leaf_nodes': 3, 'min_samples_split': 3, 'n_estimators': 75}, 'config_hash': {'algorithm': 'ebfb16234172ae811ff21185ff92bbdbb8f32f14', 'config': 'd92d4ada2394fc132733e176e926ee53acdc6a00', 'pipeline': '8071e7cbf86a5c3056493dc3aa40063aeb28cdfe'}, 'duration': 1.3618149757385254, 'iteration': 7, 'loss': 0.6158612049395463, 'max_history_score': 0.85528670390001, 'max_history_score_std': 0.02213730791268438, 'max_history_step': 'joint', 'pipeline': {'features': ('features_SelectKBest', {'features__k': 4}), 'normalizer': ('normalizer_StandardScaler', {'normalizer__with_mean': True, 'normalizer__with_std': True}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 5})}, 'score': 0.3841387950604537, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'entropy', 'max_depth': 1, 'max_features': 1, 'max_leaf_nodes': 5, 'min_samples_split': 2, 'n_estimators': 100}, 'config_hash': {'algorithm': '896b53c75a2db568fb7b6da3bfca2f7a1535a11b', 'config': 'f0d0b1d2cedc22ae15d9a208a3fc3fc133bf0d3d', 'pipeline': 'c9761c9a33bf75d6dcad0742c421548a7655ccc9'}, 'duration': 2.297278881072998, 'iteration': 8, 'loss': 0.40673663548410355, 'max_history_score': 0.85528670390001, 'max_history_score_std': 0.02213730791268438, 'max_history_step': 'joint', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 2, 'features__selectkbest__k': 4}), 'normalizer': ('normalizer_StandardScaler', {'normalizer__with_mean': False, 'normalizer__with_std': False}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 5})}, 'score': 0.5932633645158965, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'entropy', 'max_depth': 2, 'max_features': None, 'max_leaf_nodes': None, 'min_samples_split': 5, 'n_estimators': 25}, 'config_hash': {'algorithm': '0b0e954757c4f75343a6efb740ad93260ed781ae', 'config': '47584de0e60d0d12c7dbbf0dc60e5aea96e3f4b2', 'pipeline': 'b37ee32d59413053bf9a2a72c8ff7135f3701e05'}, 'duration': 0.7249000072479248, 'iteration': 9, 'loss': 0.6965910020393421, 'max_history_score': 0.85528670390001, 'max_history_score_std': 0.02213730791268438, 'max_history_step': 'joint', 'pipeline': {'features': ('features_SelectKBest', {'features__k': 3}), 'normalizer': ('normalizer_NoneType', {}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 7})}, 'score': 0.3034089979606579, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'gini', 'max_depth': 2, 'max_features': 2, 'max_leaf_nodes': 5, 'min_samples_split': 5, 'n_estimators': 75}, 'config_hash': {'algorithm': 'f1ead1d9e33ea927e1dd27d872a058fa3de4f832', 'config': 'eecb88ee2b1b95d741c1b5c7751534d31aae6a77', 'pipeline': '6746650871e8b61efc9302b092dc05f7cdb179d5'}, 'duration': 5.340634822845459, 'iteration': 10, 'loss': 0.7687016290977936, 'max_history_score': 0.85528670390001, 'max_history_score_std': 0.02213730791268438, 'max_history_step': 'joint', 'pipeline': {'features': ('features_SelectKBest', {'features__k': 3}), 'normalizer': ('normalizer_RobustScaler', {'normalizer__quantile_range': (...), 'normalizer__with_centering': False, 'normalizer__with_scaling': False}), 'rebalance': ('rebalance_CondensedNearestNeighbour', {'rebalance__n_neighbors': 1})}, 'score': 0.23129837090220637, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': 1, 'max_features': 2, 'max_leaf_nodes': 2, 'min_samples_split': 3, 'n_estimators': 75}, 'config_hash': {'algorithm': '531a3bb8ccf0baa06727af4b3de9e62d25e6eabf', 'config': '27a7ed0502b321ab7256b77c8ce79e90cb9da815', 'pipeline': '77e6d84e2217b92b3cf67cc6defef9dd3554cec0'}, 'duration': 1.775357961654663, 'iteration': 11, 'loss': 0.6313818737375694, 'max_history_score': 0.85528670390001, 'max_history_score_std': 0.02213730791268438, 'max_history_step': 'joint', 'pipeline': {'features': ('features_SelectKBest', {'features__k': 4}), 'normalizer': ('normalizer_MinMaxScaler', {}), 'rebalance': ('rebalance_NearMiss', {'rebalance__n_neighbors': 3})}, 'score': 0.3686181262624307, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'entropy', 'max_depth': 4, 'max_features': 3, 'max_leaf_nodes': 2, 'min_samples_split': 3, 'n_estimators': 10}, 'config_hash': {'algorithm': '93518f8ded6074d537900b26be72f8485782f933', 'config': '45f056102dd2d644bd8befa471f17b2311ac7954', 'pipeline': '5240329df25c9a533d025c1a401d49835a501b41'}, 'duration': 3.2622711658477783, 'iteration': 12, 'loss': 0.6120243191353301, 'max_history_score': 0.85528670390001, 'max_history_score_std': 0.02213730791268438, 'max_history_step': 'joint', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 4, 'features__selectkbest__k': 2}), 'normalizer': ('normalizer_PowerTransformer', {}), 'rebalance': ('rebalance_NearMiss', {'rebalance__n_neighbors': 1})}, 'score': 0.38797568086467, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'entropy', 'max_depth': None, 'max_features': 1, 'max_leaf_nodes': 5, 'min_samples_split': 3, 'n_estimators': 75}, 'config_hash': {'algorithm': 'e515d45b764fa43591032874a0ff9c25bf12fddd', 'config': 'ba108323623936872824ed8f1c41d615d25523b3', 'pipeline': '9d823bc0442f21b5ce8af67a5eb1237f64ffc2f8'}, 'duration': 2.5326571464538574, 'iteration': 13, 'loss': 0.6271427382991047, 'max_history_score': 0.85528670390001, 'max_history_score_std': 0.02213730791268438, 'max_history_step': 'joint', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 1, 'features__selectkbest__k': 1}), 'normalizer': ('normalizer_StandardScaler', {'normalizer__with_mean': True, 'normalizer__with_std': True}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 5})}, 'score': 0.3728572617008953, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'entropy', 'max_depth': 3, 'max_features': 2, 'max_leaf_nodes': 2, 'min_samples_split': 3, 'n_estimators': 25}, 'config_hash': {'algorithm': '2808e67f609eba5c8a97f81ac0c9413cd37cf7aa', 'config': 'dde4d3b5f37741629cb58bfc4051ed9f98c8f311', 'pipeline': 'bc52deabf1f5ee60968ba541d9d2574353c30a9c'}, 'duration': 0.7145559787750244, 'iteration': 14, 'loss': 0.6831045572696203, 'max_history_score': 0.85528670390001, 'max_history_score_std': 0.02213730791268438, 'max_history_step': 'joint', 'pipeline': {'features': ('features_SelectKBest', {'features__k': 3}), 'normalizer': ('normalizer_MinMaxScaler', {}), 'rebalance': ('rebalance_NearMiss', {'rebalance__n_neighbors': 1})}, 'score': 0.31689544273037973, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'gini', 'max_depth': 2, 'max_features': 2, 'max_leaf_nodes': None, 'min_samples_split': 5, 'n_estimators': 100}, 'config_hash': {'algorithm': 'b942acdead762d34afeb474bc2fe6f7fd0f23493', 'config': '1080c25b92da3f15a6f8eec003957f7e0a66324f', 'pipeline': 'cfa84fe703dc5bc0bbd2257a6d524fee2693b804'}, 'duration': 2.812459945678711, 'iteration': 15, 'loss': 0.6921421091202761, 'max_history_score': 0.85528670390001, 'max_history_score_std': 0.02213730791268438, 'max_history_step': 'joint', 'pipeline': {'features': ('features_SelectKBest', {'features__k': 2}), 'normalizer': ('normalizer_PowerTransformer', {}), 'rebalance': ('rebalance_NoneType', {})}, 'score': 0.3078578908797239, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'entropy', 'max_depth': 2, 'max_features': 3, 'max_leaf_nodes': 3, 'min_samples_split': 2, 'n_estimators': 75}, 'config_hash': {'algorithm': '250661ce4193a61ef44d2f77694b52b785ff032d', 'config': 'c3e8cf4eca5aafcae4ac31b0449e105ca127ffe2', 'pipeline': 'c4dd111513ea35f97dd3aec3e8e7f6268ce035da'}, 'duration': 1.0555319786071777, 'iteration': 16, 'loss': 1.0, 'max_history_score': 0.85528670390001, 'max_history_score_std': 0.02213730791268438, 'max_history_step': 'joint', 'pipeline': {'features': ('features_PCA', {'features__n_components': 2}), 'normalizer': ('normalizer_RobustScaler', {'normalizer__quantile_range': (...), 'normalizer__with_centering': False, 'normalizer__with_scaling': True}), 'rebalance': ('rebalance_NearMiss', {'rebalance__n_neighbors': 2})}, 'score': 0.0, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'entropy', 'max_depth': 3, 'max_features': 3, 'max_leaf_nodes': None, 'min_samples_split': 3, 'n_estimators': 25}, 'config_hash': {'algorithm': '05ac02bd045c65dc4089894902ad6253661a2692', 'config': '3449b4a1c2e488e26a7195ee9edca19b854ebd33', 'pipeline': '505d3f71b534917375d765e64b0611e7dfb83746'}, 'duration': 5.5412821769714355, 'iteration': 17, 'loss': 0.7289151155121668, 'max_history_score': 0.85528670390001, 'max_history_score_std': 0.02213730791268438, 'max_history_step': 'joint', 'pipeline': {'features': ('features_SelectKBest', {'features__k': 4}), 'normalizer': ('normalizer_MinMaxScaler', {}), 'rebalance': ('rebalance_CondensedNearestNeighbour', {'rebalance__n_neighbors': 2})}, 'score': 0.2710848844878332, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'entropy', 'max_depth': 2, 'max_features': None, 'max_leaf_nodes': None, 'min_samples_split': 2, 'n_estimators': 25}, 'config_hash': {'algorithm': 'de3b3a352ebb260e16c6b213a08c9144d17a744b', 'config': '224987ffdbbb9b6182cff18d8374518b917e4f2e', 'pipeline': '12c89200a558b2f3b91332566f41050143aecbe7'}, 'duration': 2.4646048545837402, 'iteration': 18, 'loss': 0.6545902512995826, 'max_history_score': 0.85528670390001, 'max_history_score_std': 0.02213730791268438, 'max_history_step': 'joint', 'pipeline': {'features': ('features_NoneType', {}), 'normalizer': ('normalizer_PowerTransformer', {}), 'rebalance': ('rebalance_NearMiss', {'rebalance__n_neighbors': 2})}, 'score': 0.3454097487004174, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'gini', 'max_depth': None, 'max_features': 1, 'max_leaf_nodes': None, 'min_samples_split': 3, 'n_estimators': 100}, 'config_hash': {'algorithm': '30ca111584767bbf0464df40b4c928cf7ddf9459', 'config': '97ca7d6a017c721084dec2a5d2e5a67e1e6ae2f0', 'pipeline': '789eca82ea4a42d61927670c538867b745fd81d3'}, 'duration': 7.164499044418335, 'iteration': 19, 'loss': 0.6536825403350528, 'max_history_score': 0.85528670390001, 'max_history_score_std': 0.02213730791268438, 'max_history_step': 'joint', 'pipeline': {'features': ('features_SelectKBest', {'features__k': 3}), 'normalizer': ('normalizer_RobustScaler', {'normalizer__quantile_range': (...), 'normalizer__with_centering': False, 'normalizer__with_scaling': True}), 'rebalance': ('rebalance_CondensedNearestNeighbour', {'rebalance__n_neighbors': 3})}, 'score': 0.3463174596649472, ...}, ...], 'history_hash': ['fd24b065dda6bdeb1077793f9df480ff318c7a37', 'fb22f80fb4358ae1ee4c9bd4a83543992be8d806', '8c97cdb885dd05cfd8c40ee3ac445b61e5c767a8', '16fbb5fd5cfbbacfddf27c61c0c7397a7f6d8ade', 'a77c698197c31308211b854e81a998178941f87d', '1fc13606bca3aaf342ca6ea21139cb598b56f8db', '6749af1a67b4dbcd2b4719e419d99908063c05e1', 'd92d4ada2394fc132733e176e926ee53acdc6a00', 'f0d0b1d2cedc22ae15d9a208a3fc3fc133bf0d3d', '47584de0e60d0d12c7dbbf0dc60e5aea96e3f4b2', 'eecb88ee2b1b95d741c1b5c7751534d31aae6a77', '27a7ed0502b321ab7256b77c8ce79e90cb9da815', '45f056102dd2d644bd8befa471f17b2311ac7954', 'ba108323623936872824ed8f1c41d615d25523b3', 'dde4d3b5f37741629cb58bfc4051ed9f98c8f311', '1080c25b92da3f15a6f8eec003957f7e0a66324f', 'c3e8cf4eca5aafcae4ac31b0449e105ca127ffe2', '3449b4a1c2e488e26a7195ee9edca19b854ebd33', '224987ffdbbb9b6182cff18d8374518b917e4f2e', '97ca7d6a017c721084dec2a5d2e5a67e1e6ae2f0', ...], 'history_index': {'1080c25b92da3f15a6f8eec003957f7e0a66324f': 15, '16fbb5fd5cfbbacfddf27c61c0c7397a7f6d8ade': 3, '1fc13606bca3aaf342ca6ea21139cb598b56f8db': 5, '224987ffdbbb9b6182cff18d8374518b917e4f2e': 18, '27a7ed0502b321ab7256b77c8ce79e90cb9da815': 11, '3449b4a1c2e488e26a7195ee9edca19b854ebd33': 17, '3567266057a9169d1e19b5468ae8b24572886e03': 23, '45f056102dd2d644bd8befa471f17b2311ac7954': 12, '47584de0e60d0d12c7dbbf0dc60e5aea96e3f4b2': 9, '6536b5f456395080138aa989f7ae7d2dc4251725': 22, ...}, 'iteration': 24, 'max_history_score': 0.85528670390001, 'max_history_score_std': 0.02213730791268438, 'max_history_step': 'joint'}, config={'algorithm': 'RandomForest', 'seed': 42, 'time': 300}, step='joint')
     45                 y,
     46                 cv=10,
     47                 n_jobs=-1,
     48                 return_estimator=False,
     49                 return_train_score=False,
---> 50                 verbose=0)
     51         score = np.mean(scores['test_score'])
     52         std = np.std(scores['test_score'])
     53         status = STATUS_OK
     54     except Exception as e:

...........................................................................
/home/aquemy/.local/lib/python2.7/site-packages/sklearn/model_selection/_validation.py in cross_validate(estimator=Pipeline(memory=None,
     steps=[('rebalance', ...e=42,
            verbose=0, warm_start=False))]), X=array([[ 0.,  0.,  5., ...,  0.,  0.,  0.],
    ...0.],
       [ 0.,  0., 10., ..., 12.,  1.,  0.]]), y=array([0, 1, 2, ..., 8, 9, 8]), groups=None, scoring=None, cv=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1, verbose=0, fit_params=None, pre_dispatch='2*n_jobs', return_train_score=False, return_estimator=False, error_score='raise-deprecating')
    235         delayed(_fit_and_score)(
    236             clone(estimator), X, y, scorers, train, test, verbose, None,
    237             fit_params, return_train_score=return_train_score,
    238             return_times=True, return_estimator=return_estimator,
    239             error_score=error_score)
--> 240         for train, test in cv.split(X, y, groups))
        cv.split = <bound method StratifiedKFold.split of Stratifie...d(n_splits=10, random_state=None, shuffle=False)>
        X = array([[ 0.,  0.,  5., ...,  0.,  0.,  0.],
    ...0.],
       [ 0.,  0., 10., ..., 12.,  1.,  0.]])
        y = array([0, 1, 2, ..., 8, 9, 8])
        groups = None
    241 
    242     zipped_scores = list(zip(*scores))
    243     if return_train_score:
    244         train_scores = zipped_scores.pop(0)

...........................................................................
/home/aquemy/.local/lib/python2.7/site-packages/sklearn/externals/joblib/parallel.py in __call__(self=Parallel(n_jobs=-1), iterable=<generator object <genexpr>>)
    925                 # No need to wait for async callbacks to trigger to
    926                 # consumption.
    927                 self._iterating = False
    928 
    929             with self._backend.retrieval_context():
--> 930                 self.retrieve()
        self.retrieve = <bound method Parallel.retrieve of Parallel(n_jobs=-1)>
    931             # Make sure that we get a last message telling us we are done
    932             elapsed_time = time.time() - self._start_time
    933             self._print('Done %3i out of %3i | elapsed: %s finished',
    934                         (len(self._output), len(self._output),

---------------------------------------------------------------------------
Joblib worker traceback:
---------------------------------------------------------------------------
ValueError                                         Mon Jun 17 13:06:24 2019
PID: 19991                                  Python 2.7.15+: /usr/bin/python
...........................................................................
/home/aquemy/.local/lib/python2.7/site-packages/sklearn/externals/joblib/parallel.py in __call__(self=<sklearn.externals.joblib.parallel.BatchedCalls object>)
    220     def __call__(self):
    221         # Set the default nested backend to self._backend but do not set the
    222         # change the default number of processes to -1
    223         with parallel_backend(self._backend, n_jobs=self._n_jobs):
    224             return [func(*args, **kwargs)
--> 225                     for func, args, kwargs in self.items]
        func = <function _fit_and_score>
        args = (Pipeline(memory=None,
     steps=[('rebalance', ...e=42,
            verbose=0, warm_start=False))]), array([[ 0.,  0.,  5., ...,  0.,  0.,  0.],
    ...0.],
       [ 0.,  0., 10., ..., 12.,  1.,  0.]]), array([0, 1, 2, ..., 8, 9, 8]), {'score': <function _passthrough_scorer>}, array([ 169,  176,  178, ..., 1794, 1795, 1796]), array([  0,   1,   2,   3,   4,   5,   6,   7,  ..., 181, 186, 188, 189, 190,
       194, 195, 198]), 0, None, None)
        kwargs = {'error_score': 'raise-deprecating', 'return_estimator': False, 'return_times': True, 'return_train_score': False}
        self.items = [(<function _fit_and_score>, (Pipeline(memory=None,
     steps=[('rebalance', ...e=42,
            verbose=0, warm_start=False))]), array([[ 0.,  0.,  5., ...,  0.,  0.,  0.],
    ...0.],
       [ 0.,  0., 10., ..., 12.,  1.,  0.]]), array([0, 1, 2, ..., 8, 9, 8]), {'score': <function _passthrough_scorer>}, array([ 169,  176,  178, ..., 1794, 1795, 1796]), array([  0,   1,   2,   3,   4,   5,   6,   7,  ..., 181, 186, 188, 189, 190,
       194, 195, 198]), 0, None, None), {'error_score': 'raise-deprecating', 'return_estimator': False, 'return_times': True, 'return_train_score': False})]
    226 
    227     def __len__(self):
    228         return self._size
    229 

...........................................................................
/home/aquemy/.local/lib/python2.7/site-packages/sklearn/model_selection/_validation.py in _fit_and_score(estimator=Pipeline(memory=None,
     steps=[('rebalance', ...e=42,
            verbose=0, warm_start=False))]), X=array([[ 0.,  0.,  5., ...,  0.,  0.,  0.],
    ...0.],
       [ 0.,  0., 10., ..., 12.,  1.,  0.]]), y=array([0, 1, 2, ..., 8, 9, 8]), scorer={'score': <function _passthrough_scorer>}, train=array([ 169,  176,  178, ..., 1794, 1795, 1796]), test=array([  0,   1,   2,   3,   4,   5,   6,   7,  ..., 181, 186, 188, 189, 190,
       194, 195, 198]), verbose=0, parameters=None, fit_params={}, return_train_score=False, return_parameters=False, return_n_test_samples=False, return_times=True, return_estimator=False, error_score='raise-deprecating')
    523 
    524     try:
    525         if y_train is None:
    526             estimator.fit(X_train, **fit_params)
    527         else:
--> 528             estimator.fit(X_train, y_train, **fit_params)
        estimator.fit = <bound method Pipeline.fit of Pipeline(memory=No...=42,
            verbose=0, warm_start=False))])>
        X_train = array([[ 0.,  0.,  6., ...,  9.,  4.,  0.],
    ...0.],
       [ 0.,  0., 10., ..., 12.,  1.,  0.]])
        y_train = array([9, 5, 0, ..., 8, 9, 8])
        fit_params = {}
    529 
    530     except Exception as e:
    531         # Note fit time as time until error
    532         fit_time = time.time() - start_time

...........................................................................
/usr/local/lib/python2.7/dist-packages/imblearn/pipeline.py in fit(self=Pipeline(memory=None,
     steps=[('rebalance', ...e=42,
            verbose=0, warm_start=False))]), X=array([[ 0.,  0.,  6., ...,  9.,  4.,  0.],
    ...0.],
       [ 0.,  0., 10., ..., 12.,  1.,  0.]]), y=array([9, 5, 0, ..., 8, 9, 8]), **fit_params={})
    234             This estimator
    235 
    236         """
    237         Xt, yt, fit_params = self._fit(X, y, **fit_params)
    238         if self._final_estimator is not None:
--> 239             self._final_estimator.fit(Xt, yt, **fit_params)
        self._final_estimator.fit = <bound method RandomForestClassifier.fit of Rand...ate=42,
            verbose=0, warm_start=False)>
        Xt = array([[-15.76474569],
       [ -3.5763136 ],
  ...],
       [ -6.21623512],
       [-13.41673072]])
        yt = array([9, 5, 0, ..., 8, 9, 9])
        fit_params = {}
    240         return self
    241 
    242     def fit_transform(self, X, y=None, **fit_params):
    243         """Fit the model and transform with the final estimator

...........................................................................
/home/aquemy/.local/lib/python2.7/site-packages/sklearn/ensemble/forest.py in fit(self=RandomForestClassifier(bootstrap=False, class_we...tate=42,
            verbose=0, warm_start=False), X=array([[-15.764746 ],
       [ -3.5763135],
    ...6.216235 ],
       [-13.416731 ]], dtype=float32), y=array([[9.],
       [5.],
       [0.],
       ...,
       [8.],
       [9.],
       [9.]]), sample_weight=None)
    328             trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,
    329                              **_joblib_parallel_args(prefer='threads'))(
    330                 delayed(_parallel_build_trees)(
    331                     t, self, X, y, sample_weight, i, len(trees),
    332                     verbose=self.verbose, class_weight=self.class_weight)
--> 333                 for i, t in enumerate(trees))
        i = 9
    334 
    335             # Collect newly grown trees
    336             self.estimators_.extend(trees)
    337 

...........................................................................
/home/aquemy/.local/lib/python2.7/site-packages/sklearn/externals/joblib/parallel.py in __call__(self=Parallel(n_jobs=1), iterable=<generator object <genexpr>>)
    912             # self._original_iterator is None, then this means either
    913             # that pre_dispatch == "all", n_jobs == 1 or that the first batch
    914             # was very quick and its callback already dispatched all the
    915             # remaining jobs.
    916             self._iterating = False
--> 917             if self.dispatch_one_batch(iterator):
        self.dispatch_one_batch = <bound method Parallel.dispatch_one_batch of Parallel(n_jobs=1)>
        iterator = <generator object <genexpr>>
    918                 self._iterating = self._original_iterator is not None
    919 
    920             while self.dispatch_one_batch(iterator):
    921                 pass

...........................................................................
/home/aquemy/.local/lib/python2.7/site-packages/sklearn/externals/joblib/parallel.py in dispatch_one_batch(self=Parallel(n_jobs=1), iterator=<generator object <genexpr>>)
    754                                  self._pickle_cache)
    755             if len(tasks) == 0:
    756                 # No more tasks available in the iterator: tell caller to stop.
    757                 return False
    758             else:
--> 759                 self._dispatch(tasks)
        self._dispatch = <bound method Parallel._dispatch of Parallel(n_jobs=1)>
        tasks = <sklearn.externals.joblib.parallel.BatchedCalls object>
    760                 return True
    761 
    762     def _print(self, msg, msg_args):
    763         """Display the message on stout or stderr depending on verbosity"""

...........................................................................
/home/aquemy/.local/lib/python2.7/site-packages/sklearn/externals/joblib/parallel.py in _dispatch(self=Parallel(n_jobs=1), batch=<sklearn.externals.joblib.parallel.BatchedCalls object>)
    711 
    712         dispatch_timestamp = time.time()
    713         cb = BatchCompletionCallBack(dispatch_timestamp, len(batch), self)
    714         with self._lock:
    715             job_idx = len(self._jobs)
--> 716             job = self._backend.apply_async(batch, callback=cb)
        job = undefined
        self._backend.apply_async = <bound method SequentialBackend.apply_async of <...lib._parallel_backends.SequentialBackend object>>
        batch = <sklearn.externals.joblib.parallel.BatchedCalls object>
        cb = <sklearn.externals.joblib.parallel.BatchCompletionCallBack object>
    717             # A job can complete so quickly than its callback is
    718             # called before we get here, causing self._jobs to
    719             # grow. To ensure correct results ordering, .insert is
    720             # used (rather than .append) in the following line

...........................................................................
/home/aquemy/.local/lib/python2.7/site-packages/sklearn/externals/joblib/_parallel_backends.py in apply_async(self=<sklearn.externals.joblib._parallel_backends.SequentialBackend object>, func=<sklearn.externals.joblib.parallel.BatchedCalls object>, callback=<sklearn.externals.joblib.parallel.BatchCompletionCallBack object>)
    177             raise ValueError('n_jobs == 0 in Parallel has no meaning')
    178         return 1
    179 
    180     def apply_async(self, func, callback=None):
    181         """Schedule a func to be run"""
--> 182         result = ImmediateResult(func)
        result = undefined
        func = <sklearn.externals.joblib.parallel.BatchedCalls object>
    183         if callback:
    184             callback(result)
    185         return result
    186 

...........................................................................
/home/aquemy/.local/lib/python2.7/site-packages/sklearn/externals/joblib/_parallel_backends.py in __init__(self=<sklearn.externals.joblib._parallel_backends.ImmediateResult object>, batch=<sklearn.externals.joblib.parallel.BatchedCalls object>)
    544 
    545 class ImmediateResult(object):
    546     def __init__(self, batch):
    547         # Don't delay the application, to avoid keeping the input
    548         # arguments in memory
--> 549         self.results = batch()
        self.results = undefined
        batch = <sklearn.externals.joblib.parallel.BatchedCalls object>
    550 
    551     def get(self):
    552         return self.results
    553 

...........................................................................
/home/aquemy/.local/lib/python2.7/site-packages/sklearn/externals/joblib/parallel.py in __call__(self=<sklearn.externals.joblib.parallel.BatchedCalls object>)
    220     def __call__(self):
    221         # Set the default nested backend to self._backend but do not set the
    222         # change the default number of processes to -1
    223         with parallel_backend(self._backend, n_jobs=self._n_jobs):
    224             return [func(*args, **kwargs)
--> 225                     for func, args, kwargs in self.items]
        func = <function _parallel_build_trees>
        args = (DecisionTreeClassifier(class_weight=None, criter...=False, random_state=1608637542, splitter='best'), RandomForestClassifier(bootstrap=False, class_we...tate=42,
            verbose=0, warm_start=False), array([[-15.764746 ],
       [ -3.5763135],
    ...6.216235 ],
       [-13.416731 ]], dtype=float32), array([[9.],
       [5.],
       [0.],
       ...,
       [8.],
       [9.],
       [9.]]), None, 0, 10)
        kwargs = {'class_weight': None, 'verbose': 0}
        self.items = [(<function _parallel_build_trees>, (DecisionTreeClassifier(class_weight=None, criter...=False, random_state=1608637542, splitter='best'), RandomForestClassifier(bootstrap=False, class_we...tate=42,
            verbose=0, warm_start=False), array([[-15.764746 ],
       [ -3.5763135],
    ...6.216235 ],
       [-13.416731 ]], dtype=float32), array([[9.],
       [5.],
       [0.],
       ...,
       [8.],
       [9.],
       [9.]]), None, 0, 10), {'class_weight': None, 'verbose': 0})]
    226 
    227     def __len__(self):
    228         return self._size
    229 

...........................................................................
/home/aquemy/.local/lib/python2.7/site-packages/sklearn/ensemble/forest.py in _parallel_build_trees(tree=DecisionTreeClassifier(class_weight=None, criter...=False, random_state=1608637542, splitter='best'), forest=RandomForestClassifier(bootstrap=False, class_we...tate=42,
            verbose=0, warm_start=False), X=array([[-15.764746 ],
       [ -3.5763135],
    ...6.216235 ],
       [-13.416731 ]], dtype=float32), y=array([[9.],
       [5.],
       [0.],
       ...,
       [8.],
       [9.],
       [9.]]), sample_weight=None, tree_idx=0, n_trees=10, verbose=0, class_weight=None)
    116         elif class_weight == 'balanced_subsample':
    117             curr_sample_weight *= compute_sample_weight('balanced', y, indices)
    118 
    119         tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)
    120     else:
--> 121         tree.fit(X, y, sample_weight=sample_weight, check_input=False)
        tree.fit = <bound method DecisionTreeClassifier.fit of Deci...False, random_state=1608637542, splitter='best')>
        X = array([[-15.764746 ],
       [ -3.5763135],
    ...6.216235 ],
       [-13.416731 ]], dtype=float32)
        y = array([[9.],
       [5.],
       [0.],
       ...,
       [8.],
       [9.],
       [9.]])
        sample_weight = None
    122 
    123     return tree
    124 
    125 

...........................................................................
/home/aquemy/.local/lib/python2.7/site-packages/sklearn/tree/tree.py in fit(self=DecisionTreeClassifier(class_weight=None, criter...=False, random_state=1608637542, splitter='best'), X=array([[-15.764746 ],
       [ -3.5763135],
    ...6.216235 ],
       [-13.416731 ]], dtype=float32), y=array([[9.],
       [5.],
       [0.],
       ...,
       [8.],
       [9.],
       [9.]]), sample_weight=None, check_input=False, X_idx_sorted=None)
    796 
    797         super(DecisionTreeClassifier, self).fit(
    798             X, y,
    799             sample_weight=sample_weight,
    800             check_input=check_input,
--> 801             X_idx_sorted=X_idx_sorted)
        X_idx_sorted = None
    802         return self
    803 
    804     def predict_proba(self, X, check_input=True):
    805         """Predict class probabilities of the input samples X.

...........................................................................
/home/aquemy/.local/lib/python2.7/site-packages/sklearn/tree/tree.py in fit(self=DecisionTreeClassifier(class_weight=None, criter...=False, random_state=1608637542, splitter='best'), X=array([[-15.764746 ],
       [ -3.5763135],
    ...6.216235 ],
       [-13.416731 ]], dtype=float32), y=array([[9.],
       [5.],
       [0.],
       ...,
       [8.],
       [9.],
       [9.]]), sample_weight=None, check_input=False, X_idx_sorted=None)
    237         if not 0 <= self.min_weight_fraction_leaf <= 0.5:
    238             raise ValueError("min_weight_fraction_leaf must in [0, 0.5]")
    239         if max_depth <= 0:
    240             raise ValueError("max_depth must be greater than zero. ")
    241         if not (0 < max_features <= self.n_features_):
--> 242             raise ValueError("max_features must be in (0, n_features]")
    243         if not isinstance(max_leaf_nodes, (numbers.Integral, np.integer)):
    244             raise ValueError("max_leaf_nodes must be integral number but was "
    245                              "%r" % max_leaf_nodes)
    246         if -1 < max_leaf_nodes < 2:

ValueError: max_features must be in (0, n_features]
___________________________________________________________________________
Best score: 0.8552867039 (0.0221373079127) [J] | Score: 0.0 (0.0) [J]
Best score: 0.8552867039 (0.0221373079127) [J] | Score: 0.495508524389 (0.0494133930551) [J]
Best score: 0.8552867039 (0.0221373079127) [J] | Score: 0.677219042557 (0.0436725412082) [J]
Best score: 0.8552867039 (0.0221373079127) [J] | Score: 0.776834526459 (0.0436586215941) [J]
Best score: 0.8552867039 (0.0221373079127) [J] | Score: 0.454111244216 (0.0728005631249) [J]
Best score: 0.8552867039 (0.0221373079127) [J] | Score: 0.125152975889 (0.0315194449554) [J]
Best score: 0.8552867039 (0.0221373079127) [J] | Score: 0.272639027132 (0.0204660738251) [J]
Best score: 0.8552867039 (0.0221373079127) [J] | Score: 0.635198724573 (0.0627742882364) [J]
Best score: 0.8552867039 (0.0221373079127) [J] | Score: 0.420600017767 (0.0516834312166) [J]
Best score: 0.8552867039 (0.0221373079127) [J] | Score: 0.0968163392773 (0.00179561960358) [J]
Best score: 0.8552867039 (0.0221373079127) [J] | Score: 0.598934434114 (0.0496448679012) [J]
Best score: 0.8552867039 (0.0221373079127) [J] | Score: 0.657080798133 (0.047852926133) [J]
Best score: 0.8552867039 (0.0221373079127) [J] | Score: 0.608926879192 (0.0583178107615) [J]
Best score: 0.8552867039 (0.0221373079127) [J] | Score: 0.58043509115 (0.0434391625791) [J]
Best score: 0.8552867039 (0.0221373079127) [J] | Score: 0.796006504839 (0.0530220625653) [J]
Best score: 0.8552867039 (0.0221373079127) [J] | Score: 0.261516262958 (0.0356782008804) [J]
JoblibValueError
___________________________________________________________________________
...........................................................................
/home/aquemy/dev/dp_hyperparameters/extension/main.py in <module>()
     27 
     28     serializer.serialize_results(scenario, policy)
     29 
     30 if __name__ == "__main__":
     31     args = cli.parse_args()
---> 32     main(args)

...........................................................................
/home/aquemy/dev/dp_hyperparameters/extension/main.py in main(args=Namespace(customize=[(['control', 'seed'], '42')...='./scenarios/rf_digits_joint.yaml', verbosity=0))
     21         test_size=0.4, 
     22         random_state=scenario['control']['seed']
     23     )
     24 
     25     policy = policies.initiate(scenario['setup']['policy'], config)
---> 26     policy.run(X,y)
        policy.run = <bound method Joint.run of <experiment.policies.joint.Joint object>>
        X = array([[ 0.,  0.,  5., ...,  0.,  0.,  0.],
    ...0.],
       [ 0.,  0., 10., ..., 12.,  1.,  0.]])
        y = array([0, 1, 2, ..., 8, 9, 8])
     27 
     28     serializer.serialize_results(scenario, policy)
     29 
     30 if __name__ == "__main__":

...........................................................................
/home/aquemy/dev/dp_hyperparameters/extension/experiment/policies/joint.py in run(self=<experiment.policies.joint.Joint object>, X=array([[ 0.,  0.,  5., ...,  0.,  0.,  0.],
    ...0.],
       [ 0.,  0., 10., ..., 12.,  1.,  0.]]), y=array([0, 1, 2, ..., 8, 9, 8]))
     32             algo=tpe.suggest, 
     33             max_evals=None,
     34             max_time=self.config['time'],     
     35             trials=trials,
     36             show_progressbar=False,
---> 37             verbose=0
     38         )
     39 
     40         best_config = self.context['best_config']
     41         super(Joint, self).display_step_results(best_config)

...........................................................................
/home/aquemy/dev/dp_hyperparameters/extension/hyperopt/fmin.py in fmin(fn=<functools.partial object>, space={'algorithm': {'bootstrap': <hyperopt.pyll.base.Apply object>, 'criterion': <hyperopt.pyll.base.Apply object>, 'max_depth': <hyperopt.pyll.base.Apply object>, 'max_features': <hyperopt.pyll.base.Apply object>, 'max_leaf_nodes': <hyperopt.pyll.base.Apply object>, 'min_samples_split': <hyperopt.pyll.base.Apply object>, 'n_estimators': <hyperopt.pyll.base.Apply object>}, 'pipeline': {'features': <hyperopt.pyll.base.Apply object>, 'normalizer': <hyperopt.pyll.base.Apply object>, 'rebalance': <hyperopt.pyll.base.Apply object>}}, algo=<function suggest>, max_evals=9223372036854775807, max_time=300, trials=<hyperopt.base.Trials object>, rstate=<mtrand.RandomState object>, allow_trials_fmin=True, pass_expr_memo_ctrl=None, catch_eval_exceptions=False, verbose=0, return_argmin=True, points_to_evaluate=None, max_queue_len=1, show_progressbar=False)
    406             pass_expr_memo_ctrl=pass_expr_memo_ctrl,
    407             verbose=verbose,
    408             catch_eval_exceptions=catch_eval_exceptions,
    409             return_argmin=return_argmin,
    410             show_progressbar=show_progressbar,
--> 411             max_time=max_time
        max_time = 300
    412         )
    413 
    414     if trials is None:
    415         if points_to_evaluate is None:

...........................................................................
/home/aquemy/dev/dp_hyperparameters/extension/hyperopt/base.py in fmin(self=<hyperopt.base.Trials object>, fn=<functools.partial object>, space={'algorithm': {'bootstrap': <hyperopt.pyll.base.Apply object>, 'criterion': <hyperopt.pyll.base.Apply object>, 'max_depth': <hyperopt.pyll.base.Apply object>, 'max_features': <hyperopt.pyll.base.Apply object>, 'max_leaf_nodes': <hyperopt.pyll.base.Apply object>, 'min_samples_split': <hyperopt.pyll.base.Apply object>, 'n_estimators': <hyperopt.pyll.base.Apply object>}, 'pipeline': {'features': <hyperopt.pyll.base.Apply object>, 'normalizer': <hyperopt.pyll.base.Apply object>, 'rebalance': <hyperopt.pyll.base.Apply object>}}, algo=<function suggest>, max_evals=9223372036854775807, max_time=300, rstate=<mtrand.RandomState object>, verbose=0, pass_expr_memo_ctrl=None, catch_eval_exceptions=False, return_argmin=True, show_progressbar=False)
    636             verbose=verbose,
    637             allow_trials_fmin=False,  # -- prevent recursion
    638             pass_expr_memo_ctrl=pass_expr_memo_ctrl,
    639             catch_eval_exceptions=catch_eval_exceptions,
    640             return_argmin=return_argmin,
--> 641             show_progressbar=show_progressbar)
        show_progressbar = False
    642 
    643 
    644 def trials_from_docs(docs, validate=True, **kwargs):
    645     """Construct a Trials base class instance from a list of trials documents

...........................................................................
/home/aquemy/dev/dp_hyperparameters/extension/hyperopt/fmin.py in fmin(fn=<functools.partial object>, space={'algorithm': {'bootstrap': <hyperopt.pyll.base.Apply object>, 'criterion': <hyperopt.pyll.base.Apply object>, 'max_depth': <hyperopt.pyll.base.Apply object>, 'max_features': <hyperopt.pyll.base.Apply object>, 'max_leaf_nodes': <hyperopt.pyll.base.Apply object>, 'min_samples_split': <hyperopt.pyll.base.Apply object>, 'n_estimators': <hyperopt.pyll.base.Apply object>}, 'pipeline': {'features': <hyperopt.pyll.base.Apply object>, 'normalizer': <hyperopt.pyll.base.Apply object>, 'rebalance': <hyperopt.pyll.base.Apply object>}}, algo=<function suggest>, max_evals=9223372036854775807, max_time=300, trials=<hyperopt.base.Trials object>, rstate=<mtrand.RandomState object>, allow_trials_fmin=False, pass_expr_memo_ctrl=None, catch_eval_exceptions=False, verbose=0, return_argmin=True, points_to_evaluate=None, max_queue_len=1, show_progressbar=False)
    426                     verbose=verbose,
    427                     max_queue_len=max_queue_len,
    428                     show_progressbar=show_progressbar,
    429                     max_time=max_time)
    430     rval.catch_eval_exceptions = catch_eval_exceptions
--> 431     rval.exhaust()
        rval.exhaust = <bound method FMinIter.exhaust of <hyperopt.fmin.FMinIter object>>
    432     if return_argmin:
    433         return trials.argmin
    434     elif len(trials) > 0:
    435         # Only if there are some succesfull trail runs, return the best point in the evaluation space

...........................................................................
/home/aquemy/dev/dp_hyperparameters/extension/hyperopt/fmin.py in exhaust(self=<hyperopt.fmin.FMinIter object>)
    273             raise StopIteration()
    274         return self.trials
    275 
    276     def exhaust(self):
    277         n_done = len(self.trials)
--> 278         self.run(self.max_evals - n_done, block_until_done=self.asynchronous)
        self.run = <bound method FMinIter.run of <hyperopt.fmin.FMinIter object>>
        self.max_evals = 9223372036854775807
        n_done = 0
        self.asynchronous = False
    279         self.trials.refresh()
    280         return self
    281 
    282 

...........................................................................
/home/aquemy/dev/dp_hyperparameters/extension/hyperopt/fmin.py in run(self=<hyperopt.fmin.FMinIter object>, N=9223372036854775807, block_until_done=False)
    232                     if self.asynchronous:
    233                         # -- wait for workers to fill in the trials
    234                         time.sleep(self.poll_interval_secs)
    235                     else:
    236                         # -- loop over trials and do the jobs directly
--> 237                         self.serial_evaluate()
        self.serial_evaluate = <bound method FMinIter.serial_evaluate of <hyperopt.fmin.FMinIter object>>
    238                     try:
    239                         res = [d['result']['loss'] for d in
    240                                          self.trials.trials if
    241                                          d['result']['status'] == 'ok']

...........................................................................
/home/aquemy/dev/dp_hyperparameters/extension/hyperopt/fmin.py in serial_evaluate(self=<hyperopt.fmin.FMinIter object>, N=-1)
    138                 trial['book_time'] = now
    139                 trial['refresh_time'] = now
    140                 spec = base.spec_from_misc(trial['misc'])
    141                 ctrl = base.Ctrl(self.trials, current_trial=trial)
    142                 try:
--> 143                     result = self.domain.evaluate(spec, ctrl)
        result = undefined
        self.domain.evaluate = <bound method Domain.evaluate of <hyperopt.base.Domain object>>
        spec = {'bootstrap': 0, 'criterion': 1, 'features': 1, 'features_PCA_features__n_components': 0, 'max_depth': 0, 'max_features': 2, 'max_leaf_nodes': 2, 'min_samples_split': 2, 'n_estimators': 3, 'normalizer': 4, ...}
        ctrl = <hyperopt.base.Ctrl object>
    144                 except Exception as e:
    145                     logger.info('job exception: %s' % str(e))
    146                     trial['state'] = base.JOB_STATE_ERROR
    147                     trial['misc']['error'] = (str(type(e)), str(e))

...........................................................................
/home/aquemy/dev/dp_hyperparameters/extension/hyperopt/base.py in evaluate(self=<hyperopt.base.Domain object>, config={'bootstrap': 0, 'criterion': 1, 'features': 1, 'features_PCA_features__n_components': 0, 'max_depth': 0, 'max_features': 2, 'max_leaf_nodes': 2, 'min_samples_split': 2, 'n_estimators': 3, 'normalizer': 4, ...}, ctrl=<hyperopt.base.Ctrl object>, attach_attachments=True)
    841             #    or the normal Python part (self.fn)
    842             pyll_rval = pyll.rec_eval(
    843                 self.expr,
    844                 memo=memo,
    845                 print_node_on_error=self.rec_eval_print_node_on_error)
--> 846             rval = self.fn(pyll_rval)
        rval = undefined
        self.fn = <functools.partial object>
        pyll_rval = {'algorithm': {'bootstrap': True, 'criterion': 'entropy', 'max_depth': 1, 'max_features': 3, 'max_leaf_nodes': 5, 'min_samples_split': 5, 'n_estimators': 75}, 'pipeline': {'features': ('features_PCA', {'features__n_components': 1}), 'normalizer': ('normalizer_RobustScaler', {'normalizer__quantile_range': (10.0, 90.0), 'normalizer__with_centering': True, 'normalizer__with_scaling': True}), 'rebalance': ('rebalance_NoneType', {})}}
    847 
    848         if isinstance(rval, (float, int, np.number)):
    849             dict_rval = {'loss': float(rval), 'status': STATUS_OK}
    850         else:

...........................................................................
/home/aquemy/dev/dp_hyperparameters/extension/experiment/objective.py in objective_joint(wconfig={'algorithm': {'bootstrap': True, 'criterion': 'entropy', 'max_depth': 1, 'max_features': 3, 'max_leaf_nodes': 5, 'min_samples_split': 5, 'n_estimators': 75}, 'pipeline': {'features': ('features_PCA', {'features__n_components': 1}), 'normalizer': ('normalizer_RobustScaler', {'normalizer__quantile_range': (10.0, 90.0), 'normalizer__with_centering': True, 'normalizer__with_scaling': True}), 'rebalance': ('rebalance_NoneType', {})}}, algorithm='RandomForest', X=array([[ 0.,  0.,  5., ...,  0.,  0.,  0.],
    ...0.],
       [ 0.,  0., 10., ..., 12.,  1.,  0.]]), y=array([0, 1, 2, ..., 8, 9, 8]), context={'baseline_score': 0.9272021217853512, 'baseline_score_std': 0.026919033284817703, 'best_config': {'algorithm': {'bootstrap': False, 'criterion': 'entropy', 'max_depth': None, 'max_features': 2, 'max_leaf_nodes': None, 'min_samples_split': 2, 'n_estimators': 10}, 'config_hash': {'algorithm': 'a49ecb99e74217d6812f98ead7bc9d1fe4a53ba0', 'config': '6749af1a67b4dbcd2b4719e419d99908063c05e1', 'pipeline': '19bdf19a2eec5febce95ab8fa2a71040d75114aa'}, 'duration': 1.5498578548431396, 'iteration': 6, 'loss': 0.14471329609998995, 'max_history_score': 0.85528670390001, 'max_history_score_std': 0.02213730791268438, 'max_history_step': 'joint', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 4, 'features__selectkbest__k': 3}), 'normalizer': ('normalizer_NoneType', {}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 7})}, 'score': 0.85528670390001, ...}, 'history': [{'algorithm': {'bootstrap': False, 'criterion': 'entropy', 'max_depth': 1, 'max_features': 3, 'max_leaf_nodes': 3, 'min_samples_split': 5, 'n_estimators': 50}, 'config_hash': {'algorithm': '752fa095cdab58a238ae606c613606188964cc0c', 'config': 'fd24b065dda6bdeb1077793f9df480ff318c7a37', 'pipeline': '13ea3359c453b8993fcec1e88bc0e19cd0a2b112'}, 'duration': 0.689669132232666, 'iteration': 0, 'loss': 0.6602879519109309, 'max_history_score': 0.3397120480890691, 'max_history_score_std': 0.03346542949100545, 'max_history_step': 'joint', 'pipeline': {'features': ('features_SelectKBest', {'features__k': 4}), 'normalizer': ('normalizer_MinMaxScaler', {}), 'rebalance': ('rebalance_NoneType', {})}, 'score': 0.3397120480890691, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'gini', 'max_depth': 4, 'max_features': 1, 'max_leaf_nodes': 5, 'min_samples_split': 3, 'n_estimators': 25}, 'config_hash': {'algorithm': '9d9de4aee820052ddfe83bfffca420f6b50837d3', 'config': 'fb22f80fb4358ae1ee4c9bd4a83543992be8d806', 'pipeline': '6251ad4bb7a110726a67f90c319f4717ac37a312'}, 'duration': 1.4300940036773682, 'iteration': 1, 'loss': 0.5122196101741096, 'max_history_score': 0.48778038982589045, 'max_history_score_std': 0.05486079759217226, 'max_history_step': 'joint', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 2, 'features__selectkbest__k': 2}), 'normalizer': ('normalizer_StandardScaler', {'normalizer__with_mean': True, 'normalizer__with_std': True}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 5})}, 'score': 0.48778038982589045, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': 4, 'max_features': 1, 'max_leaf_nodes': None, 'min_samples_split': 2, 'n_estimators': 10}, 'config_hash': {'algorithm': '2ed7d27df9a1b2d5e63da76f7cb309616c232022', 'config': '8c97cdb885dd05cfd8c40ee3ac445b61e5c767a8', 'pipeline': 'c0abb5e23a4739d3120740a9519fb36c43eb94d5'}, 'duration': 3.0036678314208984, 'iteration': 2, 'loss': 0.38319264175312906, 'max_history_score': 0.6168073582468709, 'max_history_score_std': 0.05286679173001824, 'max_history_step': 'joint', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 1, 'features__selectkbest__k': 4}), 'normalizer': ('normalizer_PowerTransformer', {}), 'rebalance': ('rebalance_NearMiss', {'rebalance__n_neighbors': 2})}, 'score': 0.6168073582468709, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'entropy', 'max_depth': None, 'max_features': None, 'max_leaf_nodes': 2, 'min_samples_split': 2, 'n_estimators': 100}, 'config_hash': {'algorithm': '17962655e3b76dfcd0843d1e5c2cb7a9db1c6a79', 'config': '16fbb5fd5cfbbacfddf27c61c0c7397a7f6d8ade', 'pipeline': '13ea3359c453b8993fcec1e88bc0e19cd0a2b112'}, 'duration': 1.3447980880737305, 'iteration': 3, 'loss': 0.6768840987778313, 'max_history_score': 0.6168073582468709, 'max_history_score_std': 0.05286679173001824, 'max_history_step': 'joint', 'pipeline': {'features': ('features_SelectKBest', {'features__k': 4}), 'normalizer': ('normalizer_MinMaxScaler', {}), 'rebalance': ('rebalance_NoneType', {})}, 'score': 0.32311590122216866, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'gini', 'max_depth': 2, 'max_features': 2, 'max_leaf_nodes': 2, 'min_samples_split': 3, 'n_estimators': 100}, 'config_hash': {'algorithm': '1ea8965b2247f86950e54510ee6d79399816341b', 'config': 'a77c698197c31308211b854e81a998178941f87d', 'pipeline': 'aaf976c7c663a31fa039582d42f9e07101556a7c'}, 'duration': 2.589430093765259, 'iteration': 4, 'loss': 0.2544808950572157, 'max_history_score': 0.7455191049427843, 'max_history_score_std': 0.04843448308166839, 'max_history_step': 'joint', 'pipeline': {'features': ('features_NoneType', {}), 'normalizer': ('normalizer_PowerTransformer', {}), 'rebalance': ('rebalance_NoneType', {})}, 'score': 0.7455191049427843, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': None, 'max_features': 2, 'max_leaf_nodes': 5, 'min_samples_split': 5, 'n_estimators': 25}, 'config_hash': {'algorithm': 'fd8aeb6a05eaaba41e676d60596c8e0c71b35e0c', 'config': '1fc13606bca3aaf342ca6ea21139cb598b56f8db', 'pipeline': 'f00bd8de05642e026bbba4ad20d3a60088c86b6c'}, 'duration': 1.8779079914093018, 'iteration': 5, 'loss': 0.531551018758381, 'max_history_score': 0.7455191049427843, 'max_history_score_std': 0.04843448308166839, 'max_history_step': 'joint', 'pipeline': {'features': ('features_PCA', {'features__n_components': 2}), 'normalizer': ('normalizer_MinMaxScaler', {}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 5})}, 'score': 0.46844898124161904, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'entropy', 'max_depth': None, 'max_features': 2, 'max_leaf_nodes': None, 'min_samples_split': 2, 'n_estimators': 10}, 'config_hash': {'algorithm': 'a49ecb99e74217d6812f98ead7bc9d1fe4a53ba0', 'config': '6749af1a67b4dbcd2b4719e419d99908063c05e1', 'pipeline': '19bdf19a2eec5febce95ab8fa2a71040d75114aa'}, 'duration': 1.5498578548431396, 'iteration': 6, 'loss': 0.14471329609998995, 'max_history_score': 0.85528670390001, 'max_history_score_std': 0.02213730791268438, 'max_history_step': 'joint', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 4, 'features__selectkbest__k': 3}), 'normalizer': ('normalizer_NoneType', {}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 7})}, 'score': 0.85528670390001, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': 1, 'max_features': 3, 'max_leaf_nodes': 3, 'min_samples_split': 3, 'n_estimators': 75}, 'config_hash': {'algorithm': 'ebfb16234172ae811ff21185ff92bbdbb8f32f14', 'config': 'd92d4ada2394fc132733e176e926ee53acdc6a00', 'pipeline': '8071e7cbf86a5c3056493dc3aa40063aeb28cdfe'}, 'duration': 1.3618149757385254, 'iteration': 7, 'loss': 0.6158612049395463, 'max_history_score': 0.85528670390001, 'max_history_score_std': 0.02213730791268438, 'max_history_step': 'joint', 'pipeline': {'features': ('features_SelectKBest', {'features__k': 4}), 'normalizer': ('normalizer_StandardScaler', {'normalizer__with_mean': True, 'normalizer__with_std': True}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 5})}, 'score': 0.3841387950604537, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'entropy', 'max_depth': 1, 'max_features': 1, 'max_leaf_nodes': 5, 'min_samples_split': 2, 'n_estimators': 100}, 'config_hash': {'algorithm': '896b53c75a2db568fb7b6da3bfca2f7a1535a11b', 'config': 'f0d0b1d2cedc22ae15d9a208a3fc3fc133bf0d3d', 'pipeline': 'c9761c9a33bf75d6dcad0742c421548a7655ccc9'}, 'duration': 2.297278881072998, 'iteration': 8, 'loss': 0.40673663548410355, 'max_history_score': 0.85528670390001, 'max_history_score_std': 0.02213730791268438, 'max_history_step': 'joint', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 2, 'features__selectkbest__k': 4}), 'normalizer': ('normalizer_StandardScaler', {'normalizer__with_mean': False, 'normalizer__with_std': False}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 5})}, 'score': 0.5932633645158965, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'entropy', 'max_depth': 2, 'max_features': None, 'max_leaf_nodes': None, 'min_samples_split': 5, 'n_estimators': 25}, 'config_hash': {'algorithm': '0b0e954757c4f75343a6efb740ad93260ed781ae', 'config': '47584de0e60d0d12c7dbbf0dc60e5aea96e3f4b2', 'pipeline': 'b37ee32d59413053bf9a2a72c8ff7135f3701e05'}, 'duration': 0.7249000072479248, 'iteration': 9, 'loss': 0.6965910020393421, 'max_history_score': 0.85528670390001, 'max_history_score_std': 0.02213730791268438, 'max_history_step': 'joint', 'pipeline': {'features': ('features_SelectKBest', {'features__k': 3}), 'normalizer': ('normalizer_NoneType', {}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 7})}, 'score': 0.3034089979606579, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'gini', 'max_depth': 2, 'max_features': 2, 'max_leaf_nodes': 5, 'min_samples_split': 5, 'n_estimators': 75}, 'config_hash': {'algorithm': 'f1ead1d9e33ea927e1dd27d872a058fa3de4f832', 'config': 'eecb88ee2b1b95d741c1b5c7751534d31aae6a77', 'pipeline': '6746650871e8b61efc9302b092dc05f7cdb179d5'}, 'duration': 5.340634822845459, 'iteration': 10, 'loss': 0.7687016290977936, 'max_history_score': 0.85528670390001, 'max_history_score_std': 0.02213730791268438, 'max_history_step': 'joint', 'pipeline': {'features': ('features_SelectKBest', {'features__k': 3}), 'normalizer': ('normalizer_RobustScaler', {'normalizer__quantile_range': (...), 'normalizer__with_centering': False, 'normalizer__with_scaling': False}), 'rebalance': ('rebalance_CondensedNearestNeighbour', {'rebalance__n_neighbors': 1})}, 'score': 0.23129837090220637, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': 1, 'max_features': 2, 'max_leaf_nodes': 2, 'min_samples_split': 3, 'n_estimators': 75}, 'config_hash': {'algorithm': '531a3bb8ccf0baa06727af4b3de9e62d25e6eabf', 'config': '27a7ed0502b321ab7256b77c8ce79e90cb9da815', 'pipeline': '77e6d84e2217b92b3cf67cc6defef9dd3554cec0'}, 'duration': 1.775357961654663, 'iteration': 11, 'loss': 0.6313818737375694, 'max_history_score': 0.85528670390001, 'max_history_score_std': 0.02213730791268438, 'max_history_step': 'joint', 'pipeline': {'features': ('features_SelectKBest', {'features__k': 4}), 'normalizer': ('normalizer_MinMaxScaler', {}), 'rebalance': ('rebalance_NearMiss', {'rebalance__n_neighbors': 3})}, 'score': 0.3686181262624307, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'entropy', 'max_depth': 4, 'max_features': 3, 'max_leaf_nodes': 2, 'min_samples_split': 3, 'n_estimators': 10}, 'config_hash': {'algorithm': '93518f8ded6074d537900b26be72f8485782f933', 'config': '45f056102dd2d644bd8befa471f17b2311ac7954', 'pipeline': '5240329df25c9a533d025c1a401d49835a501b41'}, 'duration': 3.2622711658477783, 'iteration': 12, 'loss': 0.6120243191353301, 'max_history_score': 0.85528670390001, 'max_history_score_std': 0.02213730791268438, 'max_history_step': 'joint', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 4, 'features__selectkbest__k': 2}), 'normalizer': ('normalizer_PowerTransformer', {}), 'rebalance': ('rebalance_NearMiss', {'rebalance__n_neighbors': 1})}, 'score': 0.38797568086467, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'entropy', 'max_depth': None, 'max_features': 1, 'max_leaf_nodes': 5, 'min_samples_split': 3, 'n_estimators': 75}, 'config_hash': {'algorithm': 'e515d45b764fa43591032874a0ff9c25bf12fddd', 'config': 'ba108323623936872824ed8f1c41d615d25523b3', 'pipeline': '9d823bc0442f21b5ce8af67a5eb1237f64ffc2f8'}, 'duration': 2.5326571464538574, 'iteration': 13, 'loss': 0.6271427382991047, 'max_history_score': 0.85528670390001, 'max_history_score_std': 0.02213730791268438, 'max_history_step': 'joint', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 1, 'features__selectkbest__k': 1}), 'normalizer': ('normalizer_StandardScaler', {'normalizer__with_mean': True, 'normalizer__with_std': True}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 5})}, 'score': 0.3728572617008953, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'entropy', 'max_depth': 3, 'max_features': 2, 'max_leaf_nodes': 2, 'min_samples_split': 3, 'n_estimators': 25}, 'config_hash': {'algorithm': '2808e67f609eba5c8a97f81ac0c9413cd37cf7aa', 'config': 'dde4d3b5f37741629cb58bfc4051ed9f98c8f311', 'pipeline': 'bc52deabf1f5ee60968ba541d9d2574353c30a9c'}, 'duration': 0.7145559787750244, 'iteration': 14, 'loss': 0.6831045572696203, 'max_history_score': 0.85528670390001, 'max_history_score_std': 0.02213730791268438, 'max_history_step': 'joint', 'pipeline': {'features': ('features_SelectKBest', {'features__k': 3}), 'normalizer': ('normalizer_MinMaxScaler', {}), 'rebalance': ('rebalance_NearMiss', {'rebalance__n_neighbors': 1})}, 'score': 0.31689544273037973, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'gini', 'max_depth': 2, 'max_features': 2, 'max_leaf_nodes': None, 'min_samples_split': 5, 'n_estimators': 100}, 'config_hash': {'algorithm': 'b942acdead762d34afeb474bc2fe6f7fd0f23493', 'config': '1080c25b92da3f15a6f8eec003957f7e0a66324f', 'pipeline': 'cfa84fe703dc5bc0bbd2257a6d524fee2693b804'}, 'duration': 2.812459945678711, 'iteration': 15, 'loss': 0.6921421091202761, 'max_history_score': 0.85528670390001, 'max_history_score_std': 0.02213730791268438, 'max_history_step': 'joint', 'pipeline': {'features': ('features_SelectKBest', {'features__k': 2}), 'normalizer': ('normalizer_PowerTransformer', {}), 'rebalance': ('rebalance_NoneType', {})}, 'score': 0.3078578908797239, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'entropy', 'max_depth': 2, 'max_features': 3, 'max_leaf_nodes': 3, 'min_samples_split': 2, 'n_estimators': 75}, 'config_hash': {'algorithm': '250661ce4193a61ef44d2f77694b52b785ff032d', 'config': 'c3e8cf4eca5aafcae4ac31b0449e105ca127ffe2', 'pipeline': 'c4dd111513ea35f97dd3aec3e8e7f6268ce035da'}, 'duration': 1.0555319786071777, 'iteration': 16, 'loss': 1.0, 'max_history_score': 0.85528670390001, 'max_history_score_std': 0.02213730791268438, 'max_history_step': 'joint', 'pipeline': {'features': ('features_PCA', {'features__n_components': 2}), 'normalizer': ('normalizer_RobustScaler', {'normalizer__quantile_range': (...), 'normalizer__with_centering': False, 'normalizer__with_scaling': True}), 'rebalance': ('rebalance_NearMiss', {'rebalance__n_neighbors': 2})}, 'score': 0.0, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'entropy', 'max_depth': 3, 'max_features': 3, 'max_leaf_nodes': None, 'min_samples_split': 3, 'n_estimators': 25}, 'config_hash': {'algorithm': '05ac02bd045c65dc4089894902ad6253661a2692', 'config': '3449b4a1c2e488e26a7195ee9edca19b854ebd33', 'pipeline': '505d3f71b534917375d765e64b0611e7dfb83746'}, 'duration': 5.5412821769714355, 'iteration': 17, 'loss': 0.7289151155121668, 'max_history_score': 0.85528670390001, 'max_history_score_std': 0.02213730791268438, 'max_history_step': 'joint', 'pipeline': {'features': ('features_SelectKBest', {'features__k': 4}), 'normalizer': ('normalizer_MinMaxScaler', {}), 'rebalance': ('rebalance_CondensedNearestNeighbour', {'rebalance__n_neighbors': 2})}, 'score': 0.2710848844878332, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'entropy', 'max_depth': 2, 'max_features': None, 'max_leaf_nodes': None, 'min_samples_split': 2, 'n_estimators': 25}, 'config_hash': {'algorithm': 'de3b3a352ebb260e16c6b213a08c9144d17a744b', 'config': '224987ffdbbb9b6182cff18d8374518b917e4f2e', 'pipeline': '12c89200a558b2f3b91332566f41050143aecbe7'}, 'duration': 2.4646048545837402, 'iteration': 18, 'loss': 0.6545902512995826, 'max_history_score': 0.85528670390001, 'max_history_score_std': 0.02213730791268438, 'max_history_step': 'joint', 'pipeline': {'features': ('features_NoneType', {}), 'normalizer': ('normalizer_PowerTransformer', {}), 'rebalance': ('rebalance_NearMiss', {'rebalance__n_neighbors': 2})}, 'score': 0.3454097487004174, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'gini', 'max_depth': None, 'max_features': 1, 'max_leaf_nodes': None, 'min_samples_split': 3, 'n_estimators': 100}, 'config_hash': {'algorithm': '30ca111584767bbf0464df40b4c928cf7ddf9459', 'config': '97ca7d6a017c721084dec2a5d2e5a67e1e6ae2f0', 'pipeline': '789eca82ea4a42d61927670c538867b745fd81d3'}, 'duration': 7.164499044418335, 'iteration': 19, 'loss': 0.6536825403350528, 'max_history_score': 0.85528670390001, 'max_history_score_std': 0.02213730791268438, 'max_history_step': 'joint', 'pipeline': {'features': ('features_SelectKBest', {'features__k': 3}), 'normalizer': ('normalizer_RobustScaler', {'normalizer__quantile_range': (...), 'normalizer__with_centering': False, 'normalizer__with_scaling': True}), 'rebalance': ('rebalance_CondensedNearestNeighbour', {'rebalance__n_neighbors': 3})}, 'score': 0.3463174596649472, ...}, ...], 'history_hash': ['fd24b065dda6bdeb1077793f9df480ff318c7a37', 'fb22f80fb4358ae1ee4c9bd4a83543992be8d806', '8c97cdb885dd05cfd8c40ee3ac445b61e5c767a8', '16fbb5fd5cfbbacfddf27c61c0c7397a7f6d8ade', 'a77c698197c31308211b854e81a998178941f87d', '1fc13606bca3aaf342ca6ea21139cb598b56f8db', '6749af1a67b4dbcd2b4719e419d99908063c05e1', 'd92d4ada2394fc132733e176e926ee53acdc6a00', 'f0d0b1d2cedc22ae15d9a208a3fc3fc133bf0d3d', '47584de0e60d0d12c7dbbf0dc60e5aea96e3f4b2', 'eecb88ee2b1b95d741c1b5c7751534d31aae6a77', '27a7ed0502b321ab7256b77c8ce79e90cb9da815', '45f056102dd2d644bd8befa471f17b2311ac7954', 'ba108323623936872824ed8f1c41d615d25523b3', 'dde4d3b5f37741629cb58bfc4051ed9f98c8f311', '1080c25b92da3f15a6f8eec003957f7e0a66324f', 'c3e8cf4eca5aafcae4ac31b0449e105ca127ffe2', '3449b4a1c2e488e26a7195ee9edca19b854ebd33', '224987ffdbbb9b6182cff18d8374518b917e4f2e', '97ca7d6a017c721084dec2a5d2e5a67e1e6ae2f0', ...], 'history_index': {'1080c25b92da3f15a6f8eec003957f7e0a66324f': 15, '16fbb5fd5cfbbacfddf27c61c0c7397a7f6d8ade': 3, '1fc13606bca3aaf342ca6ea21139cb598b56f8db': 5, '224987ffdbbb9b6182cff18d8374518b917e4f2e': 18, '27a7ed0502b321ab7256b77c8ce79e90cb9da815': 11, '300257dd230eb5db40e499b05582132bb87f574b': 35, '3449b4a1c2e488e26a7195ee9edca19b854ebd33': 17, '3567266057a9169d1e19b5468ae8b24572886e03': 23, '4246f7b1866b3779296f39535fc5375e2a6b004e': 31, '45f056102dd2d644bd8befa471f17b2311ac7954': 12, ...}, 'iteration': 40, 'max_history_score': 0.85528670390001, 'max_history_score_std': 0.02213730791268438, 'max_history_step': 'joint'}, config={'algorithm': 'RandomForest', 'seed': 42, 'time': 300})
    108 
    109 def objective_algo(algo_config, current_pipeline_config, algorithm, X, y, context, config):
    110     return objective(current_pipeline_config, algo_config, algorithm, X, y, context, config, step='algorithm')
    111 
    112 def objective_joint(wconfig, algorithm, X, y, context, config):
--> 113     return objective(wconfig['pipeline'], wconfig['algorithm'], algorithm, X, y, context, config, step='joint')
        wconfig = {'algorithm': {'bootstrap': True, 'criterion': 'entropy', 'max_depth': 1, 'max_features': 3, 'max_leaf_nodes': 5, 'min_samples_split': 5, 'n_estimators': 75}, 'pipeline': {'features': ('features_PCA', {'features__n_components': 1}), 'normalizer': ('normalizer_RobustScaler', {'normalizer__quantile_range': (10.0, 90.0), 'normalizer__with_centering': True, 'normalizer__with_scaling': True}), 'rebalance': ('rebalance_NoneType', {})}}
        algorithm = 'RandomForest'
        X = array([[ 0.,  0.,  5., ...,  0.,  0.,  0.],
    ...0.],
       [ 0.,  0., 10., ..., 12.,  1.,  0.]])
        y = array([0, 1, 2, ..., 8, 9, 8])
        context = {'baseline_score': 0.9272021217853512, 'baseline_score_std': 0.026919033284817703, 'best_config': {'algorithm': {'bootstrap': False, 'criterion': 'entropy', 'max_depth': None, 'max_features': 2, 'max_leaf_nodes': None, 'min_samples_split': 2, 'n_estimators': 10}, 'config_hash': {'algorithm': 'a49ecb99e74217d6812f98ead7bc9d1fe4a53ba0', 'config': '6749af1a67b4dbcd2b4719e419d99908063c05e1', 'pipeline': '19bdf19a2eec5febce95ab8fa2a71040d75114aa'}, 'duration': 1.5498578548431396, 'iteration': 6, 'loss': 0.14471329609998995, 'max_history_score': 0.85528670390001, 'max_history_score_std': 0.02213730791268438, 'max_history_step': 'joint', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 4, 'features__selectkbest__k': 3}), 'normalizer': ('normalizer_NoneType', {}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 7})}, 'score': 0.85528670390001, ...}, 'history': [{'algorithm': {'bootstrap': False, 'criterion': 'entropy', 'max_depth': 1, 'max_features': 3, 'max_leaf_nodes': 3, 'min_samples_split': 5, 'n_estimators': 50}, 'config_hash': {'algorithm': '752fa095cdab58a238ae606c613606188964cc0c', 'config': 'fd24b065dda6bdeb1077793f9df480ff318c7a37', 'pipeline': '13ea3359c453b8993fcec1e88bc0e19cd0a2b112'}, 'duration': 0.689669132232666, 'iteration': 0, 'loss': 0.6602879519109309, 'max_history_score': 0.3397120480890691, 'max_history_score_std': 0.03346542949100545, 'max_history_step': 'joint', 'pipeline': {'features': ('features_SelectKBest', {'features__k': 4}), 'normalizer': ('normalizer_MinMaxScaler', {}), 'rebalance': ('rebalance_NoneType', {})}, 'score': 0.3397120480890691, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'gini', 'max_depth': 4, 'max_features': 1, 'max_leaf_nodes': 5, 'min_samples_split': 3, 'n_estimators': 25}, 'config_hash': {'algorithm': '9d9de4aee820052ddfe83bfffca420f6b50837d3', 'config': 'fb22f80fb4358ae1ee4c9bd4a83543992be8d806', 'pipeline': '6251ad4bb7a110726a67f90c319f4717ac37a312'}, 'duration': 1.4300940036773682, 'iteration': 1, 'loss': 0.5122196101741096, 'max_history_score': 0.48778038982589045, 'max_history_score_std': 0.05486079759217226, 'max_history_step': 'joint', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 2, 'features__selectkbest__k': 2}), 'normalizer': ('normalizer_StandardScaler', {'normalizer__with_mean': True, 'normalizer__with_std': True}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 5})}, 'score': 0.48778038982589045, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': 4, 'max_features': 1, 'max_leaf_nodes': None, 'min_samples_split': 2, 'n_estimators': 10}, 'config_hash': {'algorithm': '2ed7d27df9a1b2d5e63da76f7cb309616c232022', 'config': '8c97cdb885dd05cfd8c40ee3ac445b61e5c767a8', 'pipeline': 'c0abb5e23a4739d3120740a9519fb36c43eb94d5'}, 'duration': 3.0036678314208984, 'iteration': 2, 'loss': 0.38319264175312906, 'max_history_score': 0.6168073582468709, 'max_history_score_std': 0.05286679173001824, 'max_history_step': 'joint', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 1, 'features__selectkbest__k': 4}), 'normalizer': ('normalizer_PowerTransformer', {}), 'rebalance': ('rebalance_NearMiss', {'rebalance__n_neighbors': 2})}, 'score': 0.6168073582468709, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'entropy', 'max_depth': None, 'max_features': None, 'max_leaf_nodes': 2, 'min_samples_split': 2, 'n_estimators': 100}, 'config_hash': {'algorithm': '17962655e3b76dfcd0843d1e5c2cb7a9db1c6a79', 'config': '16fbb5fd5cfbbacfddf27c61c0c7397a7f6d8ade', 'pipeline': '13ea3359c453b8993fcec1e88bc0e19cd0a2b112'}, 'duration': 1.3447980880737305, 'iteration': 3, 'loss': 0.6768840987778313, 'max_history_score': 0.6168073582468709, 'max_history_score_std': 0.05286679173001824, 'max_history_step': 'joint', 'pipeline': {'features': ('features_SelectKBest', {'features__k': 4}), 'normalizer': ('normalizer_MinMaxScaler', {}), 'rebalance': ('rebalance_NoneType', {})}, 'score': 0.32311590122216866, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'gini', 'max_depth': 2, 'max_features': 2, 'max_leaf_nodes': 2, 'min_samples_split': 3, 'n_estimators': 100}, 'config_hash': {'algorithm': '1ea8965b2247f86950e54510ee6d79399816341b', 'config': 'a77c698197c31308211b854e81a998178941f87d', 'pipeline': 'aaf976c7c663a31fa039582d42f9e07101556a7c'}, 'duration': 2.589430093765259, 'iteration': 4, 'loss': 0.2544808950572157, 'max_history_score': 0.7455191049427843, 'max_history_score_std': 0.04843448308166839, 'max_history_step': 'joint', 'pipeline': {'features': ('features_NoneType', {}), 'normalizer': ('normalizer_PowerTransformer', {}), 'rebalance': ('rebalance_NoneType', {})}, 'score': 0.7455191049427843, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': None, 'max_features': 2, 'max_leaf_nodes': 5, 'min_samples_split': 5, 'n_estimators': 25}, 'config_hash': {'algorithm': 'fd8aeb6a05eaaba41e676d60596c8e0c71b35e0c', 'config': '1fc13606bca3aaf342ca6ea21139cb598b56f8db', 'pipeline': 'f00bd8de05642e026bbba4ad20d3a60088c86b6c'}, 'duration': 1.8779079914093018, 'iteration': 5, 'loss': 0.531551018758381, 'max_history_score': 0.7455191049427843, 'max_history_score_std': 0.04843448308166839, 'max_history_step': 'joint', 'pipeline': {'features': ('features_PCA', {'features__n_components': 2}), 'normalizer': ('normalizer_MinMaxScaler', {}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 5})}, 'score': 0.46844898124161904, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'entropy', 'max_depth': None, 'max_features': 2, 'max_leaf_nodes': None, 'min_samples_split': 2, 'n_estimators': 10}, 'config_hash': {'algorithm': 'a49ecb99e74217d6812f98ead7bc9d1fe4a53ba0', 'config': '6749af1a67b4dbcd2b4719e419d99908063c05e1', 'pipeline': '19bdf19a2eec5febce95ab8fa2a71040d75114aa'}, 'duration': 1.5498578548431396, 'iteration': 6, 'loss': 0.14471329609998995, 'max_history_score': 0.85528670390001, 'max_history_score_std': 0.02213730791268438, 'max_history_step': 'joint', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 4, 'features__selectkbest__k': 3}), 'normalizer': ('normalizer_NoneType', {}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 7})}, 'score': 0.85528670390001, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': 1, 'max_features': 3, 'max_leaf_nodes': 3, 'min_samples_split': 3, 'n_estimators': 75}, 'config_hash': {'algorithm': 'ebfb16234172ae811ff21185ff92bbdbb8f32f14', 'config': 'd92d4ada2394fc132733e176e926ee53acdc6a00', 'pipeline': '8071e7cbf86a5c3056493dc3aa40063aeb28cdfe'}, 'duration': 1.3618149757385254, 'iteration': 7, 'loss': 0.6158612049395463, 'max_history_score': 0.85528670390001, 'max_history_score_std': 0.02213730791268438, 'max_history_step': 'joint', 'pipeline': {'features': ('features_SelectKBest', {'features__k': 4}), 'normalizer': ('normalizer_StandardScaler', {'normalizer__with_mean': True, 'normalizer__with_std': True}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 5})}, 'score': 0.3841387950604537, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'entropy', 'max_depth': 1, 'max_features': 1, 'max_leaf_nodes': 5, 'min_samples_split': 2, 'n_estimators': 100}, 'config_hash': {'algorithm': '896b53c75a2db568fb7b6da3bfca2f7a1535a11b', 'config': 'f0d0b1d2cedc22ae15d9a208a3fc3fc133bf0d3d', 'pipeline': 'c9761c9a33bf75d6dcad0742c421548a7655ccc9'}, 'duration': 2.297278881072998, 'iteration': 8, 'loss': 0.40673663548410355, 'max_history_score': 0.85528670390001, 'max_history_score_std': 0.02213730791268438, 'max_history_step': 'joint', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 2, 'features__selectkbest__k': 4}), 'normalizer': ('normalizer_StandardScaler', {'normalizer__with_mean': False, 'normalizer__with_std': False}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 5})}, 'score': 0.5932633645158965, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'entropy', 'max_depth': 2, 'max_features': None, 'max_leaf_nodes': None, 'min_samples_split': 5, 'n_estimators': 25}, 'config_hash': {'algorithm': '0b0e954757c4f75343a6efb740ad93260ed781ae', 'config': '47584de0e60d0d12c7dbbf0dc60e5aea96e3f4b2', 'pipeline': 'b37ee32d59413053bf9a2a72c8ff7135f3701e05'}, 'duration': 0.7249000072479248, 'iteration': 9, 'loss': 0.6965910020393421, 'max_history_score': 0.85528670390001, 'max_history_score_std': 0.02213730791268438, 'max_history_step': 'joint', 'pipeline': {'features': ('features_SelectKBest', {'features__k': 3}), 'normalizer': ('normalizer_NoneType', {}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 7})}, 'score': 0.3034089979606579, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'gini', 'max_depth': 2, 'max_features': 2, 'max_leaf_nodes': 5, 'min_samples_split': 5, 'n_estimators': 75}, 'config_hash': {'algorithm': 'f1ead1d9e33ea927e1dd27d872a058fa3de4f832', 'config': 'eecb88ee2b1b95d741c1b5c7751534d31aae6a77', 'pipeline': '6746650871e8b61efc9302b092dc05f7cdb179d5'}, 'duration': 5.340634822845459, 'iteration': 10, 'loss': 0.7687016290977936, 'max_history_score': 0.85528670390001, 'max_history_score_std': 0.02213730791268438, 'max_history_step': 'joint', 'pipeline': {'features': ('features_SelectKBest', {'features__k': 3}), 'normalizer': ('normalizer_RobustScaler', {'normalizer__quantile_range': (...), 'normalizer__with_centering': False, 'normalizer__with_scaling': False}), 'rebalance': ('rebalance_CondensedNearestNeighbour', {'rebalance__n_neighbors': 1})}, 'score': 0.23129837090220637, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': 1, 'max_features': 2, 'max_leaf_nodes': 2, 'min_samples_split': 3, 'n_estimators': 75}, 'config_hash': {'algorithm': '531a3bb8ccf0baa06727af4b3de9e62d25e6eabf', 'config': '27a7ed0502b321ab7256b77c8ce79e90cb9da815', 'pipeline': '77e6d84e2217b92b3cf67cc6defef9dd3554cec0'}, 'duration': 1.775357961654663, 'iteration': 11, 'loss': 0.6313818737375694, 'max_history_score': 0.85528670390001, 'max_history_score_std': 0.02213730791268438, 'max_history_step': 'joint', 'pipeline': {'features': ('features_SelectKBest', {'features__k': 4}), 'normalizer': ('normalizer_MinMaxScaler', {}), 'rebalance': ('rebalance_NearMiss', {'rebalance__n_neighbors': 3})}, 'score': 0.3686181262624307, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'entropy', 'max_depth': 4, 'max_features': 3, 'max_leaf_nodes': 2, 'min_samples_split': 3, 'n_estimators': 10}, 'config_hash': {'algorithm': '93518f8ded6074d537900b26be72f8485782f933', 'config': '45f056102dd2d644bd8befa471f17b2311ac7954', 'pipeline': '5240329df25c9a533d025c1a401d49835a501b41'}, 'duration': 3.2622711658477783, 'iteration': 12, 'loss': 0.6120243191353301, 'max_history_score': 0.85528670390001, 'max_history_score_std': 0.02213730791268438, 'max_history_step': 'joint', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 4, 'features__selectkbest__k': 2}), 'normalizer': ('normalizer_PowerTransformer', {}), 'rebalance': ('rebalance_NearMiss', {'rebalance__n_neighbors': 1})}, 'score': 0.38797568086467, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'entropy', 'max_depth': None, 'max_features': 1, 'max_leaf_nodes': 5, 'min_samples_split': 3, 'n_estimators': 75}, 'config_hash': {'algorithm': 'e515d45b764fa43591032874a0ff9c25bf12fddd', 'config': 'ba108323623936872824ed8f1c41d615d25523b3', 'pipeline': '9d823bc0442f21b5ce8af67a5eb1237f64ffc2f8'}, 'duration': 2.5326571464538574, 'iteration': 13, 'loss': 0.6271427382991047, 'max_history_score': 0.85528670390001, 'max_history_score_std': 0.02213730791268438, 'max_history_step': 'joint', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 1, 'features__selectkbest__k': 1}), 'normalizer': ('normalizer_StandardScaler', {'normalizer__with_mean': True, 'normalizer__with_std': True}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 5})}, 'score': 0.3728572617008953, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'entropy', 'max_depth': 3, 'max_features': 2, 'max_leaf_nodes': 2, 'min_samples_split': 3, 'n_estimators': 25}, 'config_hash': {'algorithm': '2808e67f609eba5c8a97f81ac0c9413cd37cf7aa', 'config': 'dde4d3b5f37741629cb58bfc4051ed9f98c8f311', 'pipeline': 'bc52deabf1f5ee60968ba541d9d2574353c30a9c'}, 'duration': 0.7145559787750244, 'iteration': 14, 'loss': 0.6831045572696203, 'max_history_score': 0.85528670390001, 'max_history_score_std': 0.02213730791268438, 'max_history_step': 'joint', 'pipeline': {'features': ('features_SelectKBest', {'features__k': 3}), 'normalizer': ('normalizer_MinMaxScaler', {}), 'rebalance': ('rebalance_NearMiss', {'rebalance__n_neighbors': 1})}, 'score': 0.31689544273037973, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'gini', 'max_depth': 2, 'max_features': 2, 'max_leaf_nodes': None, 'min_samples_split': 5, 'n_estimators': 100}, 'config_hash': {'algorithm': 'b942acdead762d34afeb474bc2fe6f7fd0f23493', 'config': '1080c25b92da3f15a6f8eec003957f7e0a66324f', 'pipeline': 'cfa84fe703dc5bc0bbd2257a6d524fee2693b804'}, 'duration': 2.812459945678711, 'iteration': 15, 'loss': 0.6921421091202761, 'max_history_score': 0.85528670390001, 'max_history_score_std': 0.02213730791268438, 'max_history_step': 'joint', 'pipeline': {'features': ('features_SelectKBest', {'features__k': 2}), 'normalizer': ('normalizer_PowerTransformer', {}), 'rebalance': ('rebalance_NoneType', {})}, 'score': 0.3078578908797239, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'entropy', 'max_depth': 2, 'max_features': 3, 'max_leaf_nodes': 3, 'min_samples_split': 2, 'n_estimators': 75}, 'config_hash': {'algorithm': '250661ce4193a61ef44d2f77694b52b785ff032d', 'config': 'c3e8cf4eca5aafcae4ac31b0449e105ca127ffe2', 'pipeline': 'c4dd111513ea35f97dd3aec3e8e7f6268ce035da'}, 'duration': 1.0555319786071777, 'iteration': 16, 'loss': 1.0, 'max_history_score': 0.85528670390001, 'max_history_score_std': 0.02213730791268438, 'max_history_step': 'joint', 'pipeline': {'features': ('features_PCA', {'features__n_components': 2}), 'normalizer': ('normalizer_RobustScaler', {'normalizer__quantile_range': (...), 'normalizer__with_centering': False, 'normalizer__with_scaling': True}), 'rebalance': ('rebalance_NearMiss', {'rebalance__n_neighbors': 2})}, 'score': 0.0, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'entropy', 'max_depth': 3, 'max_features': 3, 'max_leaf_nodes': None, 'min_samples_split': 3, 'n_estimators': 25}, 'config_hash': {'algorithm': '05ac02bd045c65dc4089894902ad6253661a2692', 'config': '3449b4a1c2e488e26a7195ee9edca19b854ebd33', 'pipeline': '505d3f71b534917375d765e64b0611e7dfb83746'}, 'duration': 5.5412821769714355, 'iteration': 17, 'loss': 0.7289151155121668, 'max_history_score': 0.85528670390001, 'max_history_score_std': 0.02213730791268438, 'max_history_step': 'joint', 'pipeline': {'features': ('features_SelectKBest', {'features__k': 4}), 'normalizer': ('normalizer_MinMaxScaler', {}), 'rebalance': ('rebalance_CondensedNearestNeighbour', {'rebalance__n_neighbors': 2})}, 'score': 0.2710848844878332, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'entropy', 'max_depth': 2, 'max_features': None, 'max_leaf_nodes': None, 'min_samples_split': 2, 'n_estimators': 25}, 'config_hash': {'algorithm': 'de3b3a352ebb260e16c6b213a08c9144d17a744b', 'config': '224987ffdbbb9b6182cff18d8374518b917e4f2e', 'pipeline': '12c89200a558b2f3b91332566f41050143aecbe7'}, 'duration': 2.4646048545837402, 'iteration': 18, 'loss': 0.6545902512995826, 'max_history_score': 0.85528670390001, 'max_history_score_std': 0.02213730791268438, 'max_history_step': 'joint', 'pipeline': {'features': ('features_NoneType', {}), 'normalizer': ('normalizer_PowerTransformer', {}), 'rebalance': ('rebalance_NearMiss', {'rebalance__n_neighbors': 2})}, 'score': 0.3454097487004174, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'gini', 'max_depth': None, 'max_features': 1, 'max_leaf_nodes': None, 'min_samples_split': 3, 'n_estimators': 100}, 'config_hash': {'algorithm': '30ca111584767bbf0464df40b4c928cf7ddf9459', 'config': '97ca7d6a017c721084dec2a5d2e5a67e1e6ae2f0', 'pipeline': '789eca82ea4a42d61927670c538867b745fd81d3'}, 'duration': 7.164499044418335, 'iteration': 19, 'loss': 0.6536825403350528, 'max_history_score': 0.85528670390001, 'max_history_score_std': 0.02213730791268438, 'max_history_step': 'joint', 'pipeline': {'features': ('features_SelectKBest', {'features__k': 3}), 'normalizer': ('normalizer_RobustScaler', {'normalizer__quantile_range': (...), 'normalizer__with_centering': False, 'normalizer__with_scaling': True}), 'rebalance': ('rebalance_CondensedNearestNeighbour', {'rebalance__n_neighbors': 3})}, 'score': 0.3463174596649472, ...}, ...], 'history_hash': ['fd24b065dda6bdeb1077793f9df480ff318c7a37', 'fb22f80fb4358ae1ee4c9bd4a83543992be8d806', '8c97cdb885dd05cfd8c40ee3ac445b61e5c767a8', '16fbb5fd5cfbbacfddf27c61c0c7397a7f6d8ade', 'a77c698197c31308211b854e81a998178941f87d', '1fc13606bca3aaf342ca6ea21139cb598b56f8db', '6749af1a67b4dbcd2b4719e419d99908063c05e1', 'd92d4ada2394fc132733e176e926ee53acdc6a00', 'f0d0b1d2cedc22ae15d9a208a3fc3fc133bf0d3d', '47584de0e60d0d12c7dbbf0dc60e5aea96e3f4b2', 'eecb88ee2b1b95d741c1b5c7751534d31aae6a77', '27a7ed0502b321ab7256b77c8ce79e90cb9da815', '45f056102dd2d644bd8befa471f17b2311ac7954', 'ba108323623936872824ed8f1c41d615d25523b3', 'dde4d3b5f37741629cb58bfc4051ed9f98c8f311', '1080c25b92da3f15a6f8eec003957f7e0a66324f', 'c3e8cf4eca5aafcae4ac31b0449e105ca127ffe2', '3449b4a1c2e488e26a7195ee9edca19b854ebd33', '224987ffdbbb9b6182cff18d8374518b917e4f2e', '97ca7d6a017c721084dec2a5d2e5a67e1e6ae2f0', ...], 'history_index': {'1080c25b92da3f15a6f8eec003957f7e0a66324f': 15, '16fbb5fd5cfbbacfddf27c61c0c7397a7f6d8ade': 3, '1fc13606bca3aaf342ca6ea21139cb598b56f8db': 5, '224987ffdbbb9b6182cff18d8374518b917e4f2e': 18, '27a7ed0502b321ab7256b77c8ce79e90cb9da815': 11, '300257dd230eb5db40e499b05582132bb87f574b': 35, '3449b4a1c2e488e26a7195ee9edca19b854ebd33': 17, '3567266057a9169d1e19b5468ae8b24572886e03': 23, '4246f7b1866b3779296f39535fc5375e2a6b004e': 31, '45f056102dd2d644bd8befa471f17b2311ac7954': 12, ...}, 'iteration': 40, 'max_history_score': 0.85528670390001, 'max_history_score_std': 0.02213730791268438, 'max_history_step': 'joint'}
        config = {'algorithm': 'RandomForest', 'seed': 42, 'time': 300}
    114 
    115 
    116 def get_baseline_score(algorithm, X, y, seed):
    117     pipeline, _ = pipeline_conf_to_full_pipeline(

...........................................................................
/home/aquemy/dev/dp_hyperparameters/extension/experiment/objective.py in objective(pipeline_config={'features': ('features_PCA', {'features__n_components': 1}), 'normalizer': ('normalizer_RobustScaler', {'normalizer__quantile_range': (10.0, 90.0), 'normalizer__with_centering': True, 'normalizer__with_scaling': True}), 'rebalance': ('rebalance_NoneType', {})}, algo_config={'bootstrap': True, 'criterion': 'entropy', 'max_depth': 1, 'max_features': 3, 'max_leaf_nodes': 5, 'min_samples_split': 5, 'n_estimators': 75}, algorithm='RandomForest', X=array([[ 0.,  0.,  5., ...,  0.,  0.,  0.],
    ...0.],
       [ 0.,  0., 10., ..., 12.,  1.,  0.]]), y=array([0, 1, 2, ..., 8, 9, 8]), context={'baseline_score': 0.9272021217853512, 'baseline_score_std': 0.026919033284817703, 'best_config': {'algorithm': {'bootstrap': False, 'criterion': 'entropy', 'max_depth': None, 'max_features': 2, 'max_leaf_nodes': None, 'min_samples_split': 2, 'n_estimators': 10}, 'config_hash': {'algorithm': 'a49ecb99e74217d6812f98ead7bc9d1fe4a53ba0', 'config': '6749af1a67b4dbcd2b4719e419d99908063c05e1', 'pipeline': '19bdf19a2eec5febce95ab8fa2a71040d75114aa'}, 'duration': 1.5498578548431396, 'iteration': 6, 'loss': 0.14471329609998995, 'max_history_score': 0.85528670390001, 'max_history_score_std': 0.02213730791268438, 'max_history_step': 'joint', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 4, 'features__selectkbest__k': 3}), 'normalizer': ('normalizer_NoneType', {}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 7})}, 'score': 0.85528670390001, ...}, 'history': [{'algorithm': {'bootstrap': False, 'criterion': 'entropy', 'max_depth': 1, 'max_features': 3, 'max_leaf_nodes': 3, 'min_samples_split': 5, 'n_estimators': 50}, 'config_hash': {'algorithm': '752fa095cdab58a238ae606c613606188964cc0c', 'config': 'fd24b065dda6bdeb1077793f9df480ff318c7a37', 'pipeline': '13ea3359c453b8993fcec1e88bc0e19cd0a2b112'}, 'duration': 0.689669132232666, 'iteration': 0, 'loss': 0.6602879519109309, 'max_history_score': 0.3397120480890691, 'max_history_score_std': 0.03346542949100545, 'max_history_step': 'joint', 'pipeline': {'features': ('features_SelectKBest', {'features__k': 4}), 'normalizer': ('normalizer_MinMaxScaler', {}), 'rebalance': ('rebalance_NoneType', {})}, 'score': 0.3397120480890691, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'gini', 'max_depth': 4, 'max_features': 1, 'max_leaf_nodes': 5, 'min_samples_split': 3, 'n_estimators': 25}, 'config_hash': {'algorithm': '9d9de4aee820052ddfe83bfffca420f6b50837d3', 'config': 'fb22f80fb4358ae1ee4c9bd4a83543992be8d806', 'pipeline': '6251ad4bb7a110726a67f90c319f4717ac37a312'}, 'duration': 1.4300940036773682, 'iteration': 1, 'loss': 0.5122196101741096, 'max_history_score': 0.48778038982589045, 'max_history_score_std': 0.05486079759217226, 'max_history_step': 'joint', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 2, 'features__selectkbest__k': 2}), 'normalizer': ('normalizer_StandardScaler', {'normalizer__with_mean': True, 'normalizer__with_std': True}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 5})}, 'score': 0.48778038982589045, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': 4, 'max_features': 1, 'max_leaf_nodes': None, 'min_samples_split': 2, 'n_estimators': 10}, 'config_hash': {'algorithm': '2ed7d27df9a1b2d5e63da76f7cb309616c232022', 'config': '8c97cdb885dd05cfd8c40ee3ac445b61e5c767a8', 'pipeline': 'c0abb5e23a4739d3120740a9519fb36c43eb94d5'}, 'duration': 3.0036678314208984, 'iteration': 2, 'loss': 0.38319264175312906, 'max_history_score': 0.6168073582468709, 'max_history_score_std': 0.05286679173001824, 'max_history_step': 'joint', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 1, 'features__selectkbest__k': 4}), 'normalizer': ('normalizer_PowerTransformer', {}), 'rebalance': ('rebalance_NearMiss', {'rebalance__n_neighbors': 2})}, 'score': 0.6168073582468709, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'entropy', 'max_depth': None, 'max_features': None, 'max_leaf_nodes': 2, 'min_samples_split': 2, 'n_estimators': 100}, 'config_hash': {'algorithm': '17962655e3b76dfcd0843d1e5c2cb7a9db1c6a79', 'config': '16fbb5fd5cfbbacfddf27c61c0c7397a7f6d8ade', 'pipeline': '13ea3359c453b8993fcec1e88bc0e19cd0a2b112'}, 'duration': 1.3447980880737305, 'iteration': 3, 'loss': 0.6768840987778313, 'max_history_score': 0.6168073582468709, 'max_history_score_std': 0.05286679173001824, 'max_history_step': 'joint', 'pipeline': {'features': ('features_SelectKBest', {'features__k': 4}), 'normalizer': ('normalizer_MinMaxScaler', {}), 'rebalance': ('rebalance_NoneType', {})}, 'score': 0.32311590122216866, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'gini', 'max_depth': 2, 'max_features': 2, 'max_leaf_nodes': 2, 'min_samples_split': 3, 'n_estimators': 100}, 'config_hash': {'algorithm': '1ea8965b2247f86950e54510ee6d79399816341b', 'config': 'a77c698197c31308211b854e81a998178941f87d', 'pipeline': 'aaf976c7c663a31fa039582d42f9e07101556a7c'}, 'duration': 2.589430093765259, 'iteration': 4, 'loss': 0.2544808950572157, 'max_history_score': 0.7455191049427843, 'max_history_score_std': 0.04843448308166839, 'max_history_step': 'joint', 'pipeline': {'features': ('features_NoneType', {}), 'normalizer': ('normalizer_PowerTransformer', {}), 'rebalance': ('rebalance_NoneType', {})}, 'score': 0.7455191049427843, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': None, 'max_features': 2, 'max_leaf_nodes': 5, 'min_samples_split': 5, 'n_estimators': 25}, 'config_hash': {'algorithm': 'fd8aeb6a05eaaba41e676d60596c8e0c71b35e0c', 'config': '1fc13606bca3aaf342ca6ea21139cb598b56f8db', 'pipeline': 'f00bd8de05642e026bbba4ad20d3a60088c86b6c'}, 'duration': 1.8779079914093018, 'iteration': 5, 'loss': 0.531551018758381, 'max_history_score': 0.7455191049427843, 'max_history_score_std': 0.04843448308166839, 'max_history_step': 'joint', 'pipeline': {'features': ('features_PCA', {'features__n_components': 2}), 'normalizer': ('normalizer_MinMaxScaler', {}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 5})}, 'score': 0.46844898124161904, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'entropy', 'max_depth': None, 'max_features': 2, 'max_leaf_nodes': None, 'min_samples_split': 2, 'n_estimators': 10}, 'config_hash': {'algorithm': 'a49ecb99e74217d6812f98ead7bc9d1fe4a53ba0', 'config': '6749af1a67b4dbcd2b4719e419d99908063c05e1', 'pipeline': '19bdf19a2eec5febce95ab8fa2a71040d75114aa'}, 'duration': 1.5498578548431396, 'iteration': 6, 'loss': 0.14471329609998995, 'max_history_score': 0.85528670390001, 'max_history_score_std': 0.02213730791268438, 'max_history_step': 'joint', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 4, 'features__selectkbest__k': 3}), 'normalizer': ('normalizer_NoneType', {}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 7})}, 'score': 0.85528670390001, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': 1, 'max_features': 3, 'max_leaf_nodes': 3, 'min_samples_split': 3, 'n_estimators': 75}, 'config_hash': {'algorithm': 'ebfb16234172ae811ff21185ff92bbdbb8f32f14', 'config': 'd92d4ada2394fc132733e176e926ee53acdc6a00', 'pipeline': '8071e7cbf86a5c3056493dc3aa40063aeb28cdfe'}, 'duration': 1.3618149757385254, 'iteration': 7, 'loss': 0.6158612049395463, 'max_history_score': 0.85528670390001, 'max_history_score_std': 0.02213730791268438, 'max_history_step': 'joint', 'pipeline': {'features': ('features_SelectKBest', {'features__k': 4}), 'normalizer': ('normalizer_StandardScaler', {'normalizer__with_mean': True, 'normalizer__with_std': True}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 5})}, 'score': 0.3841387950604537, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'entropy', 'max_depth': 1, 'max_features': 1, 'max_leaf_nodes': 5, 'min_samples_split': 2, 'n_estimators': 100}, 'config_hash': {'algorithm': '896b53c75a2db568fb7b6da3bfca2f7a1535a11b', 'config': 'f0d0b1d2cedc22ae15d9a208a3fc3fc133bf0d3d', 'pipeline': 'c9761c9a33bf75d6dcad0742c421548a7655ccc9'}, 'duration': 2.297278881072998, 'iteration': 8, 'loss': 0.40673663548410355, 'max_history_score': 0.85528670390001, 'max_history_score_std': 0.02213730791268438, 'max_history_step': 'joint', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 2, 'features__selectkbest__k': 4}), 'normalizer': ('normalizer_StandardScaler', {'normalizer__with_mean': False, 'normalizer__with_std': False}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 5})}, 'score': 0.5932633645158965, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'entropy', 'max_depth': 2, 'max_features': None, 'max_leaf_nodes': None, 'min_samples_split': 5, 'n_estimators': 25}, 'config_hash': {'algorithm': '0b0e954757c4f75343a6efb740ad93260ed781ae', 'config': '47584de0e60d0d12c7dbbf0dc60e5aea96e3f4b2', 'pipeline': 'b37ee32d59413053bf9a2a72c8ff7135f3701e05'}, 'duration': 0.7249000072479248, 'iteration': 9, 'loss': 0.6965910020393421, 'max_history_score': 0.85528670390001, 'max_history_score_std': 0.02213730791268438, 'max_history_step': 'joint', 'pipeline': {'features': ('features_SelectKBest', {'features__k': 3}), 'normalizer': ('normalizer_NoneType', {}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 7})}, 'score': 0.3034089979606579, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'gini', 'max_depth': 2, 'max_features': 2, 'max_leaf_nodes': 5, 'min_samples_split': 5, 'n_estimators': 75}, 'config_hash': {'algorithm': 'f1ead1d9e33ea927e1dd27d872a058fa3de4f832', 'config': 'eecb88ee2b1b95d741c1b5c7751534d31aae6a77', 'pipeline': '6746650871e8b61efc9302b092dc05f7cdb179d5'}, 'duration': 5.340634822845459, 'iteration': 10, 'loss': 0.7687016290977936, 'max_history_score': 0.85528670390001, 'max_history_score_std': 0.02213730791268438, 'max_history_step': 'joint', 'pipeline': {'features': ('features_SelectKBest', {'features__k': 3}), 'normalizer': ('normalizer_RobustScaler', {'normalizer__quantile_range': (...), 'normalizer__with_centering': False, 'normalizer__with_scaling': False}), 'rebalance': ('rebalance_CondensedNearestNeighbour', {'rebalance__n_neighbors': 1})}, 'score': 0.23129837090220637, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': 1, 'max_features': 2, 'max_leaf_nodes': 2, 'min_samples_split': 3, 'n_estimators': 75}, 'config_hash': {'algorithm': '531a3bb8ccf0baa06727af4b3de9e62d25e6eabf', 'config': '27a7ed0502b321ab7256b77c8ce79e90cb9da815', 'pipeline': '77e6d84e2217b92b3cf67cc6defef9dd3554cec0'}, 'duration': 1.775357961654663, 'iteration': 11, 'loss': 0.6313818737375694, 'max_history_score': 0.85528670390001, 'max_history_score_std': 0.02213730791268438, 'max_history_step': 'joint', 'pipeline': {'features': ('features_SelectKBest', {'features__k': 4}), 'normalizer': ('normalizer_MinMaxScaler', {}), 'rebalance': ('rebalance_NearMiss', {'rebalance__n_neighbors': 3})}, 'score': 0.3686181262624307, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'entropy', 'max_depth': 4, 'max_features': 3, 'max_leaf_nodes': 2, 'min_samples_split': 3, 'n_estimators': 10}, 'config_hash': {'algorithm': '93518f8ded6074d537900b26be72f8485782f933', 'config': '45f056102dd2d644bd8befa471f17b2311ac7954', 'pipeline': '5240329df25c9a533d025c1a401d49835a501b41'}, 'duration': 3.2622711658477783, 'iteration': 12, 'loss': 0.6120243191353301, 'max_history_score': 0.85528670390001, 'max_history_score_std': 0.02213730791268438, 'max_history_step': 'joint', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 4, 'features__selectkbest__k': 2}), 'normalizer': ('normalizer_PowerTransformer', {}), 'rebalance': ('rebalance_NearMiss', {'rebalance__n_neighbors': 1})}, 'score': 0.38797568086467, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'entropy', 'max_depth': None, 'max_features': 1, 'max_leaf_nodes': 5, 'min_samples_split': 3, 'n_estimators': 75}, 'config_hash': {'algorithm': 'e515d45b764fa43591032874a0ff9c25bf12fddd', 'config': 'ba108323623936872824ed8f1c41d615d25523b3', 'pipeline': '9d823bc0442f21b5ce8af67a5eb1237f64ffc2f8'}, 'duration': 2.5326571464538574, 'iteration': 13, 'loss': 0.6271427382991047, 'max_history_score': 0.85528670390001, 'max_history_score_std': 0.02213730791268438, 'max_history_step': 'joint', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 1, 'features__selectkbest__k': 1}), 'normalizer': ('normalizer_StandardScaler', {'normalizer__with_mean': True, 'normalizer__with_std': True}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 5})}, 'score': 0.3728572617008953, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'entropy', 'max_depth': 3, 'max_features': 2, 'max_leaf_nodes': 2, 'min_samples_split': 3, 'n_estimators': 25}, 'config_hash': {'algorithm': '2808e67f609eba5c8a97f81ac0c9413cd37cf7aa', 'config': 'dde4d3b5f37741629cb58bfc4051ed9f98c8f311', 'pipeline': 'bc52deabf1f5ee60968ba541d9d2574353c30a9c'}, 'duration': 0.7145559787750244, 'iteration': 14, 'loss': 0.6831045572696203, 'max_history_score': 0.85528670390001, 'max_history_score_std': 0.02213730791268438, 'max_history_step': 'joint', 'pipeline': {'features': ('features_SelectKBest', {'features__k': 3}), 'normalizer': ('normalizer_MinMaxScaler', {}), 'rebalance': ('rebalance_NearMiss', {'rebalance__n_neighbors': 1})}, 'score': 0.31689544273037973, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'gini', 'max_depth': 2, 'max_features': 2, 'max_leaf_nodes': None, 'min_samples_split': 5, 'n_estimators': 100}, 'config_hash': {'algorithm': 'b942acdead762d34afeb474bc2fe6f7fd0f23493', 'config': '1080c25b92da3f15a6f8eec003957f7e0a66324f', 'pipeline': 'cfa84fe703dc5bc0bbd2257a6d524fee2693b804'}, 'duration': 2.812459945678711, 'iteration': 15, 'loss': 0.6921421091202761, 'max_history_score': 0.85528670390001, 'max_history_score_std': 0.02213730791268438, 'max_history_step': 'joint', 'pipeline': {'features': ('features_SelectKBest', {'features__k': 2}), 'normalizer': ('normalizer_PowerTransformer', {}), 'rebalance': ('rebalance_NoneType', {})}, 'score': 0.3078578908797239, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'entropy', 'max_depth': 2, 'max_features': 3, 'max_leaf_nodes': 3, 'min_samples_split': 2, 'n_estimators': 75}, 'config_hash': {'algorithm': '250661ce4193a61ef44d2f77694b52b785ff032d', 'config': 'c3e8cf4eca5aafcae4ac31b0449e105ca127ffe2', 'pipeline': 'c4dd111513ea35f97dd3aec3e8e7f6268ce035da'}, 'duration': 1.0555319786071777, 'iteration': 16, 'loss': 1.0, 'max_history_score': 0.85528670390001, 'max_history_score_std': 0.02213730791268438, 'max_history_step': 'joint', 'pipeline': {'features': ('features_PCA', {'features__n_components': 2}), 'normalizer': ('normalizer_RobustScaler', {'normalizer__quantile_range': (...), 'normalizer__with_centering': False, 'normalizer__with_scaling': True}), 'rebalance': ('rebalance_NearMiss', {'rebalance__n_neighbors': 2})}, 'score': 0.0, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'entropy', 'max_depth': 3, 'max_features': 3, 'max_leaf_nodes': None, 'min_samples_split': 3, 'n_estimators': 25}, 'config_hash': {'algorithm': '05ac02bd045c65dc4089894902ad6253661a2692', 'config': '3449b4a1c2e488e26a7195ee9edca19b854ebd33', 'pipeline': '505d3f71b534917375d765e64b0611e7dfb83746'}, 'duration': 5.5412821769714355, 'iteration': 17, 'loss': 0.7289151155121668, 'max_history_score': 0.85528670390001, 'max_history_score_std': 0.02213730791268438, 'max_history_step': 'joint', 'pipeline': {'features': ('features_SelectKBest', {'features__k': 4}), 'normalizer': ('normalizer_MinMaxScaler', {}), 'rebalance': ('rebalance_CondensedNearestNeighbour', {'rebalance__n_neighbors': 2})}, 'score': 0.2710848844878332, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'entropy', 'max_depth': 2, 'max_features': None, 'max_leaf_nodes': None, 'min_samples_split': 2, 'n_estimators': 25}, 'config_hash': {'algorithm': 'de3b3a352ebb260e16c6b213a08c9144d17a744b', 'config': '224987ffdbbb9b6182cff18d8374518b917e4f2e', 'pipeline': '12c89200a558b2f3b91332566f41050143aecbe7'}, 'duration': 2.4646048545837402, 'iteration': 18, 'loss': 0.6545902512995826, 'max_history_score': 0.85528670390001, 'max_history_score_std': 0.02213730791268438, 'max_history_step': 'joint', 'pipeline': {'features': ('features_NoneType', {}), 'normalizer': ('normalizer_PowerTransformer', {}), 'rebalance': ('rebalance_NearMiss', {'rebalance__n_neighbors': 2})}, 'score': 0.3454097487004174, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'gini', 'max_depth': None, 'max_features': 1, 'max_leaf_nodes': None, 'min_samples_split': 3, 'n_estimators': 100}, 'config_hash': {'algorithm': '30ca111584767bbf0464df40b4c928cf7ddf9459', 'config': '97ca7d6a017c721084dec2a5d2e5a67e1e6ae2f0', 'pipeline': '789eca82ea4a42d61927670c538867b745fd81d3'}, 'duration': 7.164499044418335, 'iteration': 19, 'loss': 0.6536825403350528, 'max_history_score': 0.85528670390001, 'max_history_score_std': 0.02213730791268438, 'max_history_step': 'joint', 'pipeline': {'features': ('features_SelectKBest', {'features__k': 3}), 'normalizer': ('normalizer_RobustScaler', {'normalizer__quantile_range': (...), 'normalizer__with_centering': False, 'normalizer__with_scaling': True}), 'rebalance': ('rebalance_CondensedNearestNeighbour', {'rebalance__n_neighbors': 3})}, 'score': 0.3463174596649472, ...}, ...], 'history_hash': ['fd24b065dda6bdeb1077793f9df480ff318c7a37', 'fb22f80fb4358ae1ee4c9bd4a83543992be8d806', '8c97cdb885dd05cfd8c40ee3ac445b61e5c767a8', '16fbb5fd5cfbbacfddf27c61c0c7397a7f6d8ade', 'a77c698197c31308211b854e81a998178941f87d', '1fc13606bca3aaf342ca6ea21139cb598b56f8db', '6749af1a67b4dbcd2b4719e419d99908063c05e1', 'd92d4ada2394fc132733e176e926ee53acdc6a00', 'f0d0b1d2cedc22ae15d9a208a3fc3fc133bf0d3d', '47584de0e60d0d12c7dbbf0dc60e5aea96e3f4b2', 'eecb88ee2b1b95d741c1b5c7751534d31aae6a77', '27a7ed0502b321ab7256b77c8ce79e90cb9da815', '45f056102dd2d644bd8befa471f17b2311ac7954', 'ba108323623936872824ed8f1c41d615d25523b3', 'dde4d3b5f37741629cb58bfc4051ed9f98c8f311', '1080c25b92da3f15a6f8eec003957f7e0a66324f', 'c3e8cf4eca5aafcae4ac31b0449e105ca127ffe2', '3449b4a1c2e488e26a7195ee9edca19b854ebd33', '224987ffdbbb9b6182cff18d8374518b917e4f2e', '97ca7d6a017c721084dec2a5d2e5a67e1e6ae2f0', ...], 'history_index': {'1080c25b92da3f15a6f8eec003957f7e0a66324f': 15, '16fbb5fd5cfbbacfddf27c61c0c7397a7f6d8ade': 3, '1fc13606bca3aaf342ca6ea21139cb598b56f8db': 5, '224987ffdbbb9b6182cff18d8374518b917e4f2e': 18, '27a7ed0502b321ab7256b77c8ce79e90cb9da815': 11, '300257dd230eb5db40e499b05582132bb87f574b': 35, '3449b4a1c2e488e26a7195ee9edca19b854ebd33': 17, '3567266057a9169d1e19b5468ae8b24572886e03': 23, '4246f7b1866b3779296f39535fc5375e2a6b004e': 31, '45f056102dd2d644bd8befa471f17b2311ac7954': 12, ...}, 'iteration': 40, 'max_history_score': 0.85528670390001, 'max_history_score_std': 0.02213730791268438, 'max_history_step': 'joint'}, config={'algorithm': 'RandomForest', 'seed': 42, 'time': 300}, step='joint')
     45                 y,
     46                 cv=10,
     47                 n_jobs=-1,
     48                 return_estimator=False,
     49                 return_train_score=False,
---> 50                 verbose=0)
     51         score = np.mean(scores['test_score'])
     52         std = np.std(scores['test_score'])
     53         status = STATUS_OK
     54     except Exception as e:

...........................................................................
/home/aquemy/.local/lib/python2.7/site-packages/sklearn/model_selection/_validation.py in cross_validate(estimator=Pipeline(memory=None,
     steps=[('normalizer',... random_state=42, verbose=0, warm_start=False))]), X=array([[ 0.,  0.,  5., ...,  0.,  0.,  0.],
    ...0.],
       [ 0.,  0., 10., ..., 12.,  1.,  0.]]), y=array([0, 1, 2, ..., 8, 9, 8]), groups=None, scoring=None, cv=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1, verbose=0, fit_params=None, pre_dispatch='2*n_jobs', return_train_score=False, return_estimator=False, error_score='raise-deprecating')
    235         delayed(_fit_and_score)(
    236             clone(estimator), X, y, scorers, train, test, verbose, None,
    237             fit_params, return_train_score=return_train_score,
    238             return_times=True, return_estimator=return_estimator,
    239             error_score=error_score)
--> 240         for train, test in cv.split(X, y, groups))
        cv.split = <bound method StratifiedKFold.split of Stratifie...d(n_splits=10, random_state=None, shuffle=False)>
        X = array([[ 0.,  0.,  5., ...,  0.,  0.,  0.],
    ...0.],
       [ 0.,  0., 10., ..., 12.,  1.,  0.]])
        y = array([0, 1, 2, ..., 8, 9, 8])
        groups = None
    241 
    242     zipped_scores = list(zip(*scores))
    243     if return_train_score:
    244         train_scores = zipped_scores.pop(0)

...........................................................................
/home/aquemy/.local/lib/python2.7/site-packages/sklearn/externals/joblib/parallel.py in __call__(self=Parallel(n_jobs=-1), iterable=<generator object <genexpr>>)
    925                 # No need to wait for async callbacks to trigger to
    926                 # consumption.
    927                 self._iterating = False
    928 
    929             with self._backend.retrieval_context():
--> 930                 self.retrieve()
        self.retrieve = <bound method Parallel.retrieve of Parallel(n_jobs=-1)>
    931             # Make sure that we get a last message telling us we are done
    932             elapsed_time = time.time() - self._start_time
    933             self._print('Done %3i out of %3i | elapsed: %s finished',
    934                         (len(self._output), len(self._output),

---------------------------------------------------------------------------
Joblib worker traceback:
---------------------------------------------------------------------------
ValueError                                         Mon Jun 17 13:07:05 2019
PID: 20075                                  Python 2.7.15+: /usr/bin/python
...........................................................................
/home/aquemy/.local/lib/python2.7/site-packages/sklearn/externals/joblib/parallel.py in __call__(self=<sklearn.externals.joblib.parallel.BatchedCalls object>)
    220     def __call__(self):
    221         # Set the default nested backend to self._backend but do not set the
    222         # change the default number of processes to -1
    223         with parallel_backend(self._backend, n_jobs=self._n_jobs):
    224             return [func(*args, **kwargs)
--> 225                     for func, args, kwargs in self.items]
        func = <function _fit_and_score>
        args = (Pipeline(memory=None,
     steps=[('normalizer',... random_state=42, verbose=0, warm_start=False))]), array([[ 0.,  0.,  5., ...,  0.,  0.,  0.],
    ...0.],
       [ 0.,  0., 10., ..., 12.,  1.,  0.]]), array([0, 1, 2, ..., 8, 9, 8]), {'score': <function _passthrough_scorer>}, array([ 169,  176,  178, ..., 1794, 1795, 1796]), array([  0,   1,   2,   3,   4,   5,   6,   7,  ..., 181, 186, 188, 189, 190,
       194, 195, 198]), 0, None, None)
        kwargs = {'error_score': 'raise-deprecating', 'return_estimator': False, 'return_times': True, 'return_train_score': False}
        self.items = [(<function _fit_and_score>, (Pipeline(memory=None,
     steps=[('normalizer',... random_state=42, verbose=0, warm_start=False))]), array([[ 0.,  0.,  5., ...,  0.,  0.,  0.],
    ...0.],
       [ 0.,  0., 10., ..., 12.,  1.,  0.]]), array([0, 1, 2, ..., 8, 9, 8]), {'score': <function _passthrough_scorer>}, array([ 169,  176,  178, ..., 1794, 1795, 1796]), array([  0,   1,   2,   3,   4,   5,   6,   7,  ..., 181, 186, 188, 189, 190,
       194, 195, 198]), 0, None, None), {'error_score': 'raise-deprecating', 'return_estimator': False, 'return_times': True, 'return_train_score': False})]
    226 
    227     def __len__(self):
    228         return self._size
    229 

...........................................................................
/home/aquemy/.local/lib/python2.7/site-packages/sklearn/model_selection/_validation.py in _fit_and_score(estimator=Pipeline(memory=None,
     steps=[('normalizer',... random_state=42, verbose=0, warm_start=False))]), X=array([[ 0.,  0.,  5., ...,  0.,  0.,  0.],
    ...0.],
       [ 0.,  0., 10., ..., 12.,  1.,  0.]]), y=array([0, 1, 2, ..., 8, 9, 8]), scorer={'score': <function _passthrough_scorer>}, train=array([ 169,  176,  178, ..., 1794, 1795, 1796]), test=array([  0,   1,   2,   3,   4,   5,   6,   7,  ..., 181, 186, 188, 189, 190,
       194, 195, 198]), verbose=0, parameters=None, fit_params={}, return_train_score=False, return_parameters=False, return_n_test_samples=False, return_times=True, return_estimator=False, error_score='raise-deprecating')
    523 
    524     try:
    525         if y_train is None:
    526             estimator.fit(X_train, **fit_params)
    527         else:
--> 528             estimator.fit(X_train, y_train, **fit_params)
        estimator.fit = <bound method Pipeline.fit of Pipeline(memory=No...random_state=42, verbose=0, warm_start=False))])>
        X_train = array([[ 0.,  0.,  6., ...,  9.,  4.,  0.],
    ...0.],
       [ 0.,  0., 10., ..., 12.,  1.,  0.]])
        y_train = array([9, 5, 0, ..., 8, 9, 8])
        fit_params = {}
    529 
    530     except Exception as e:
    531         # Note fit time as time until error
    532         fit_time = time.time() - start_time

...........................................................................
/usr/local/lib/python2.7/dist-packages/imblearn/pipeline.py in fit(self=Pipeline(memory=None,
     steps=[('normalizer',... random_state=42, verbose=0, warm_start=False))]), X=array([[ 0.,  0.,  6., ...,  9.,  4.,  0.],
    ...0.],
       [ 0.,  0., 10., ..., 12.,  1.,  0.]]), y=array([9, 5, 0, ..., 8, 9, 8]), **fit_params={})
    234             This estimator
    235 
    236         """
    237         Xt, yt, fit_params = self._fit(X, y, **fit_params)
    238         if self._final_estimator is not None:
--> 239             self._final_estimator.fit(Xt, yt, **fit_params)
        self._final_estimator.fit = <bound method RandomForestClassifier.fit of Rand...e, random_state=42, verbose=0, warm_start=False)>
        Xt = array([[-0.24599358],
       [-0.55977943],
    ...73],
       [-0.50242515],
       [-0.39868054]])
        yt = array([9, 5, 0, ..., 8, 9, 8])
        fit_params = {}
    240         return self
    241 
    242     def fit_transform(self, X, y=None, **fit_params):
    243         """Fit the model and transform with the final estimator

...........................................................................
/home/aquemy/.local/lib/python2.7/site-packages/sklearn/ensemble/forest.py in fit(self=RandomForestClassifier(bootstrap=True, class_wei...se, random_state=42, verbose=0, warm_start=False), X=array([[-0.24599358],
       [-0.5597794 ],
    ....50242513],
       [-0.39868054]], dtype=float32), y=array([[9.],
       [5.],
       [0.],
       ...,
       [8.],
       [9.],
       [8.]]), sample_weight=None)
    328             trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,
    329                              **_joblib_parallel_args(prefer='threads'))(
    330                 delayed(_parallel_build_trees)(
    331                     t, self, X, y, sample_weight, i, len(trees),
    332                     verbose=self.verbose, class_weight=self.class_weight)
--> 333                 for i, t in enumerate(trees))
        i = 74
    334 
    335             # Collect newly grown trees
    336             self.estimators_.extend(trees)
    337 

...........................................................................
/home/aquemy/.local/lib/python2.7/site-packages/sklearn/externals/joblib/parallel.py in __call__(self=Parallel(n_jobs=1), iterable=<generator object <genexpr>>)
    912             # self._original_iterator is None, then this means either
    913             # that pre_dispatch == "all", n_jobs == 1 or that the first batch
    914             # was very quick and its callback already dispatched all the
    915             # remaining jobs.
    916             self._iterating = False
--> 917             if self.dispatch_one_batch(iterator):
        self.dispatch_one_batch = <bound method Parallel.dispatch_one_batch of Parallel(n_jobs=1)>
        iterator = <generator object <genexpr>>
    918                 self._iterating = self._original_iterator is not None
    919 
    920             while self.dispatch_one_batch(iterator):
    921                 pass

...........................................................................
/home/aquemy/.local/lib/python2.7/site-packages/sklearn/externals/joblib/parallel.py in dispatch_one_batch(self=Parallel(n_jobs=1), iterator=<generator object <genexpr>>)
    754                                  self._pickle_cache)
    755             if len(tasks) == 0:
    756                 # No more tasks available in the iterator: tell caller to stop.
    757                 return False
    758             else:
--> 759                 self._dispatch(tasks)
        self._dispatch = <bound method Parallel._dispatch of Parallel(n_jobs=1)>
        tasks = <sklearn.externals.joblib.parallel.BatchedCalls object>
    760                 return True
    761 
    762     def _print(self, msg, msg_args):
    763         """Display the message on stout or stderr depending on verbosity"""

...........................................................................
/home/aquemy/.local/lib/python2.7/site-packages/sklearn/externals/joblib/parallel.py in _dispatch(self=Parallel(n_jobs=1), batch=<sklearn.externals.joblib.parallel.BatchedCalls object>)
    711 
    712         dispatch_timestamp = time.time()
    713         cb = BatchCompletionCallBack(dispatch_timestamp, len(batch), self)
    714         with self._lock:
    715             job_idx = len(self._jobs)
--> 716             job = self._backend.apply_async(batch, callback=cb)
        job = undefined
        self._backend.apply_async = <bound method SequentialBackend.apply_async of <...lib._parallel_backends.SequentialBackend object>>
        batch = <sklearn.externals.joblib.parallel.BatchedCalls object>
        cb = <sklearn.externals.joblib.parallel.BatchCompletionCallBack object>
    717             # A job can complete so quickly than its callback is
    718             # called before we get here, causing self._jobs to
    719             # grow. To ensure correct results ordering, .insert is
    720             # used (rather than .append) in the following line

...........................................................................
/home/aquemy/.local/lib/python2.7/site-packages/sklearn/externals/joblib/_parallel_backends.py in apply_async(self=<sklearn.externals.joblib._parallel_backends.SequentialBackend object>, func=<sklearn.externals.joblib.parallel.BatchedCalls object>, callback=<sklearn.externals.joblib.parallel.BatchCompletionCallBack object>)
    177             raise ValueError('n_jobs == 0 in Parallel has no meaning')
    178         return 1
    179 
    180     def apply_async(self, func, callback=None):
    181         """Schedule a func to be run"""
--> 182         result = ImmediateResult(func)
        result = undefined
        func = <sklearn.externals.joblib.parallel.BatchedCalls object>
    183         if callback:
    184             callback(result)
    185         return result
    186 

...........................................................................
/home/aquemy/.local/lib/python2.7/site-packages/sklearn/externals/joblib/_parallel_backends.py in __init__(self=<sklearn.externals.joblib._parallel_backends.ImmediateResult object>, batch=<sklearn.externals.joblib.parallel.BatchedCalls object>)
    544 
    545 class ImmediateResult(object):
    546     def __init__(self, batch):
    547         # Don't delay the application, to avoid keeping the input
    548         # arguments in memory
--> 549         self.results = batch()
        self.results = undefined
        batch = <sklearn.externals.joblib.parallel.BatchedCalls object>
    550 
    551     def get(self):
    552         return self.results
    553 

...........................................................................
/home/aquemy/.local/lib/python2.7/site-packages/sklearn/externals/joblib/parallel.py in __call__(self=<sklearn.externals.joblib.parallel.BatchedCalls object>)
    220     def __call__(self):
    221         # Set the default nested backend to self._backend but do not set the
    222         # change the default number of processes to -1
    223         with parallel_backend(self._backend, n_jobs=self._n_jobs):
    224             return [func(*args, **kwargs)
--> 225                     for func, args, kwargs in self.items]
        func = <function _parallel_build_trees>
        args = (DecisionTreeClassifier(class_weight=None, criter...=False, random_state=1608637542, splitter='best'), RandomForestClassifier(bootstrap=True, class_wei...se, random_state=42, verbose=0, warm_start=False), array([[-0.24599358],
       [-0.5597794 ],
    ....50242513],
       [-0.39868054]], dtype=float32), array([[9.],
       [5.],
       [0.],
       ...,
       [8.],
       [9.],
       [8.]]), None, 0, 75)
        kwargs = {'class_weight': None, 'verbose': 0}
        self.items = [(<function _parallel_build_trees>, (DecisionTreeClassifier(class_weight=None, criter...=False, random_state=1608637542, splitter='best'), RandomForestClassifier(bootstrap=True, class_wei...se, random_state=42, verbose=0, warm_start=False), array([[-0.24599358],
       [-0.5597794 ],
    ....50242513],
       [-0.39868054]], dtype=float32), array([[9.],
       [5.],
       [0.],
       ...,
       [8.],
       [9.],
       [8.]]), None, 0, 75), {'class_weight': None, 'verbose': 0})]
    226 
    227     def __len__(self):
    228         return self._size
    229 

...........................................................................
/home/aquemy/.local/lib/python2.7/site-packages/sklearn/ensemble/forest.py in _parallel_build_trees(tree=DecisionTreeClassifier(class_weight=None, criter...=False, random_state=1608637542, splitter='best'), forest=RandomForestClassifier(bootstrap=True, class_wei...se, random_state=42, verbose=0, warm_start=False), X=array([[-0.24599358],
       [-0.5597794 ],
    ....50242513],
       [-0.39868054]], dtype=float32), y=array([[9.],
       [5.],
       [0.],
       ...,
       [8.],
       [9.],
       [8.]]), sample_weight=None, tree_idx=0, n_trees=75, verbose=0, class_weight=None)
    114                 simplefilter('ignore', DeprecationWarning)
    115                 curr_sample_weight *= compute_sample_weight('auto', y, indices)
    116         elif class_weight == 'balanced_subsample':
    117             curr_sample_weight *= compute_sample_weight('balanced', y, indices)
    118 
--> 119         tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)
        tree.fit = <bound method DecisionTreeClassifier.fit of Deci...False, random_state=1608637542, splitter='best')>
        X = array([[-0.24599358],
       [-0.5597794 ],
    ....50242513],
       [-0.39868054]], dtype=float32)
        y = array([[9.],
       [5.],
       [0.],
       ...,
       [8.],
       [9.],
       [8.]])
        sample_weight = None
        curr_sample_weight = array([1., 2., 0., ..., 0., 1., 1.])
    120     else:
    121         tree.fit(X, y, sample_weight=sample_weight, check_input=False)
    122 
    123     return tree

...........................................................................
/home/aquemy/.local/lib/python2.7/site-packages/sklearn/tree/tree.py in fit(self=DecisionTreeClassifier(class_weight=None, criter...=False, random_state=1608637542, splitter='best'), X=array([[-0.24599358],
       [-0.5597794 ],
    ....50242513],
       [-0.39868054]], dtype=float32), y=array([[9.],
       [5.],
       [0.],
       ...,
       [8.],
       [9.],
       [8.]]), sample_weight=array([1., 2., 0., ..., 0., 1., 1.]), check_input=False, X_idx_sorted=None)
    796 
    797         super(DecisionTreeClassifier, self).fit(
    798             X, y,
    799             sample_weight=sample_weight,
    800             check_input=check_input,
--> 801             X_idx_sorted=X_idx_sorted)
        X_idx_sorted = None
    802         return self
    803 
    804     def predict_proba(self, X, check_input=True):
    805         """Predict class probabilities of the input samples X.

...........................................................................
/home/aquemy/.local/lib/python2.7/site-packages/sklearn/tree/tree.py in fit(self=DecisionTreeClassifier(class_weight=None, criter...=False, random_state=1608637542, splitter='best'), X=array([[-0.24599358],
       [-0.5597794 ],
    ....50242513],
       [-0.39868054]], dtype=float32), y=array([[9.],
       [5.],
       [0.],
       ...,
       [8.],
       [9.],
       [8.]]), sample_weight=array([1., 2., 0., ..., 0., 1., 1.]), check_input=False, X_idx_sorted=None)
    237         if not 0 <= self.min_weight_fraction_leaf <= 0.5:
    238             raise ValueError("min_weight_fraction_leaf must in [0, 0.5]")
    239         if max_depth <= 0:
    240             raise ValueError("max_depth must be greater than zero. ")
    241         if not (0 < max_features <= self.n_features_):
--> 242             raise ValueError("max_features must be in (0, n_features]")
    243         if not isinstance(max_leaf_nodes, (numbers.Integral, np.integer)):
    244             raise ValueError("max_leaf_nodes must be integral number but was "
    245                              "%r" % max_leaf_nodes)
    246         if -1 < max_leaf_nodes < 2:

ValueError: max_features must be in (0, n_features]
___________________________________________________________________________
Best score: 0.8552867039 (0.0221373079127) [J] | Score: 0.0 (0.0) [J]
Best score: 0.8552867039 (0.0221373079127) [J] | Score: 0.749725244429 (0.0609233778032) [J]
Best score: 0.8552867039 (0.0221373079127) [J] | Score: 0.33974209739 (0.0474584661581) [J]
Best score: 0.8552867039 (0.0221373079127) [J] | Score: 0.612330439297 (0.0335941110645) [J]
Best score: 0.8552867039 (0.0221373079127) [J] | Score: 0.728929274047 (0.0473540794736) [J]
Best score: 0.8552867039 (0.0221373079127) [J] | Score: 0.43588628989 (0.04995342176) [J]
JoblibValueError
___________________________________________________________________________
...........................................................................
/home/aquemy/dev/dp_hyperparameters/extension/main.py in <module>()
     27 
     28     serializer.serialize_results(scenario, policy)
     29 
     30 if __name__ == "__main__":
     31     args = cli.parse_args()
---> 32     main(args)

...........................................................................
/home/aquemy/dev/dp_hyperparameters/extension/main.py in main(args=Namespace(customize=[(['control', 'seed'], '42')...='./scenarios/rf_digits_joint.yaml', verbosity=0))
     21         test_size=0.4, 
     22         random_state=scenario['control']['seed']
     23     )
     24 
     25     policy = policies.initiate(scenario['setup']['policy'], config)
---> 26     policy.run(X,y)
        policy.run = <bound method Joint.run of <experiment.policies.joint.Joint object>>
        X = array([[ 0.,  0.,  5., ...,  0.,  0.,  0.],
    ...0.],
       [ 0.,  0., 10., ..., 12.,  1.,  0.]])
        y = array([0, 1, 2, ..., 8, 9, 8])
     27 
     28     serializer.serialize_results(scenario, policy)
     29 
     30 if __name__ == "__main__":

...........................................................................
/home/aquemy/dev/dp_hyperparameters/extension/experiment/policies/joint.py in run(self=<experiment.policies.joint.Joint object>, X=array([[ 0.,  0.,  5., ...,  0.,  0.,  0.],
    ...0.],
       [ 0.,  0., 10., ..., 12.,  1.,  0.]]), y=array([0, 1, 2, ..., 8, 9, 8]))
     32             algo=tpe.suggest, 
     33             max_evals=None,
     34             max_time=self.config['time'],     
     35             trials=trials,
     36             show_progressbar=False,
---> 37             verbose=0
     38         )
     39 
     40         best_config = self.context['best_config']
     41         super(Joint, self).display_step_results(best_config)

...........................................................................
/home/aquemy/dev/dp_hyperparameters/extension/hyperopt/fmin.py in fmin(fn=<functools.partial object>, space={'algorithm': {'bootstrap': <hyperopt.pyll.base.Apply object>, 'criterion': <hyperopt.pyll.base.Apply object>, 'max_depth': <hyperopt.pyll.base.Apply object>, 'max_features': <hyperopt.pyll.base.Apply object>, 'max_leaf_nodes': <hyperopt.pyll.base.Apply object>, 'min_samples_split': <hyperopt.pyll.base.Apply object>, 'n_estimators': <hyperopt.pyll.base.Apply object>}, 'pipeline': {'features': <hyperopt.pyll.base.Apply object>, 'normalizer': <hyperopt.pyll.base.Apply object>, 'rebalance': <hyperopt.pyll.base.Apply object>}}, algo=<function suggest>, max_evals=9223372036854775807, max_time=300, trials=<hyperopt.base.Trials object>, rstate=<mtrand.RandomState object>, allow_trials_fmin=True, pass_expr_memo_ctrl=None, catch_eval_exceptions=False, verbose=0, return_argmin=True, points_to_evaluate=None, max_queue_len=1, show_progressbar=False)
    406             pass_expr_memo_ctrl=pass_expr_memo_ctrl,
    407             verbose=verbose,
    408             catch_eval_exceptions=catch_eval_exceptions,
    409             return_argmin=return_argmin,
    410             show_progressbar=show_progressbar,
--> 411             max_time=max_time
        max_time = 300
    412         )
    413 
    414     if trials is None:
    415         if points_to_evaluate is None:

...........................................................................
/home/aquemy/dev/dp_hyperparameters/extension/hyperopt/base.py in fmin(self=<hyperopt.base.Trials object>, fn=<functools.partial object>, space={'algorithm': {'bootstrap': <hyperopt.pyll.base.Apply object>, 'criterion': <hyperopt.pyll.base.Apply object>, 'max_depth': <hyperopt.pyll.base.Apply object>, 'max_features': <hyperopt.pyll.base.Apply object>, 'max_leaf_nodes': <hyperopt.pyll.base.Apply object>, 'min_samples_split': <hyperopt.pyll.base.Apply object>, 'n_estimators': <hyperopt.pyll.base.Apply object>}, 'pipeline': {'features': <hyperopt.pyll.base.Apply object>, 'normalizer': <hyperopt.pyll.base.Apply object>, 'rebalance': <hyperopt.pyll.base.Apply object>}}, algo=<function suggest>, max_evals=9223372036854775807, max_time=300, rstate=<mtrand.RandomState object>, verbose=0, pass_expr_memo_ctrl=None, catch_eval_exceptions=False, return_argmin=True, show_progressbar=False)
    636             verbose=verbose,
    637             allow_trials_fmin=False,  # -- prevent recursion
    638             pass_expr_memo_ctrl=pass_expr_memo_ctrl,
    639             catch_eval_exceptions=catch_eval_exceptions,
    640             return_argmin=return_argmin,
--> 641             show_progressbar=show_progressbar)
        show_progressbar = False
    642 
    643 
    644 def trials_from_docs(docs, validate=True, **kwargs):
    645     """Construct a Trials base class instance from a list of trials documents

...........................................................................
/home/aquemy/dev/dp_hyperparameters/extension/hyperopt/fmin.py in fmin(fn=<functools.partial object>, space={'algorithm': {'bootstrap': <hyperopt.pyll.base.Apply object>, 'criterion': <hyperopt.pyll.base.Apply object>, 'max_depth': <hyperopt.pyll.base.Apply object>, 'max_features': <hyperopt.pyll.base.Apply object>, 'max_leaf_nodes': <hyperopt.pyll.base.Apply object>, 'min_samples_split': <hyperopt.pyll.base.Apply object>, 'n_estimators': <hyperopt.pyll.base.Apply object>}, 'pipeline': {'features': <hyperopt.pyll.base.Apply object>, 'normalizer': <hyperopt.pyll.base.Apply object>, 'rebalance': <hyperopt.pyll.base.Apply object>}}, algo=<function suggest>, max_evals=9223372036854775807, max_time=300, trials=<hyperopt.base.Trials object>, rstate=<mtrand.RandomState object>, allow_trials_fmin=False, pass_expr_memo_ctrl=None, catch_eval_exceptions=False, verbose=0, return_argmin=True, points_to_evaluate=None, max_queue_len=1, show_progressbar=False)
    426                     verbose=verbose,
    427                     max_queue_len=max_queue_len,
    428                     show_progressbar=show_progressbar,
    429                     max_time=max_time)
    430     rval.catch_eval_exceptions = catch_eval_exceptions
--> 431     rval.exhaust()
        rval.exhaust = <bound method FMinIter.exhaust of <hyperopt.fmin.FMinIter object>>
    432     if return_argmin:
    433         return trials.argmin
    434     elif len(trials) > 0:
    435         # Only if there are some succesfull trail runs, return the best point in the evaluation space

...........................................................................
/home/aquemy/dev/dp_hyperparameters/extension/hyperopt/fmin.py in exhaust(self=<hyperopt.fmin.FMinIter object>)
    273             raise StopIteration()
    274         return self.trials
    275 
    276     def exhaust(self):
    277         n_done = len(self.trials)
--> 278         self.run(self.max_evals - n_done, block_until_done=self.asynchronous)
        self.run = <bound method FMinIter.run of <hyperopt.fmin.FMinIter object>>
        self.max_evals = 9223372036854775807
        n_done = 0
        self.asynchronous = False
    279         self.trials.refresh()
    280         return self
    281 
    282 

...........................................................................
/home/aquemy/dev/dp_hyperparameters/extension/hyperopt/fmin.py in run(self=<hyperopt.fmin.FMinIter object>, N=9223372036854775807, block_until_done=False)
    232                     if self.asynchronous:
    233                         # -- wait for workers to fill in the trials
    234                         time.sleep(self.poll_interval_secs)
    235                     else:
    236                         # -- loop over trials and do the jobs directly
--> 237                         self.serial_evaluate()
        self.serial_evaluate = <bound method FMinIter.serial_evaluate of <hyperopt.fmin.FMinIter object>>
    238                     try:
    239                         res = [d['result']['loss'] for d in
    240                                          self.trials.trials if
    241                                          d['result']['status'] == 'ok']

...........................................................................
/home/aquemy/dev/dp_hyperparameters/extension/hyperopt/fmin.py in serial_evaluate(self=<hyperopt.fmin.FMinIter object>, N=-1)
    138                 trial['book_time'] = now
    139                 trial['refresh_time'] = now
    140                 spec = base.spec_from_misc(trial['misc'])
    141                 ctrl = base.Ctrl(self.trials, current_trial=trial)
    142                 try:
--> 143                     result = self.domain.evaluate(spec, ctrl)
        result = undefined
        self.domain.evaluate = <bound method Domain.evaluate of <hyperopt.base.Domain object>>
        spec = {'bootstrap': 0, 'criterion': 1, 'features': 2, 'features_SelectKBest_features__k': 0, 'max_depth': 0, 'max_features': 2, 'max_leaf_nodes': 0, 'min_samples_split': 0, 'n_estimators': 4, 'normalizer': 3, ...}
        ctrl = <hyperopt.base.Ctrl object>
    144                 except Exception as e:
    145                     logger.info('job exception: %s' % str(e))
    146                     trial['state'] = base.JOB_STATE_ERROR
    147                     trial['misc']['error'] = (str(type(e)), str(e))

...........................................................................
/home/aquemy/dev/dp_hyperparameters/extension/hyperopt/base.py in evaluate(self=<hyperopt.base.Domain object>, config={'bootstrap': 0, 'criterion': 1, 'features': 2, 'features_SelectKBest_features__k': 0, 'max_depth': 0, 'max_features': 2, 'max_leaf_nodes': 0, 'min_samples_split': 0, 'n_estimators': 4, 'normalizer': 3, ...}, ctrl=<hyperopt.base.Ctrl object>, attach_attachments=True)
    841             #    or the normal Python part (self.fn)
    842             pyll_rval = pyll.rec_eval(
    843                 self.expr,
    844                 memo=memo,
    845                 print_node_on_error=self.rec_eval_print_node_on_error)
--> 846             rval = self.fn(pyll_rval)
        rval = undefined
        self.fn = <functools.partial object>
        pyll_rval = {'algorithm': {'bootstrap': True, 'criterion': 'entropy', 'max_depth': 1, 'max_features': 3, 'max_leaf_nodes': 2, 'min_samples_split': 2, 'n_estimators': 100}, 'pipeline': {'features': ('features_SelectKBest', {'features__k': 1}), 'normalizer': ('normalizer_MinMaxScaler', {}), 'rebalance': ('rebalance_CondensedNearestNeighbour', {'rebalance__n_neighbors': 1})}}
    847 
    848         if isinstance(rval, (float, int, np.number)):
    849             dict_rval = {'loss': float(rval), 'status': STATUS_OK}
    850         else:

...........................................................................
/home/aquemy/dev/dp_hyperparameters/extension/experiment/objective.py in objective_joint(wconfig={'algorithm': {'bootstrap': True, 'criterion': 'entropy', 'max_depth': 1, 'max_features': 3, 'max_leaf_nodes': 2, 'min_samples_split': 2, 'n_estimators': 100}, 'pipeline': {'features': ('features_SelectKBest', {'features__k': 1}), 'normalizer': ('normalizer_MinMaxScaler', {}), 'rebalance': ('rebalance_CondensedNearestNeighbour', {'rebalance__n_neighbors': 1})}}, algorithm='RandomForest', X=array([[ 0.,  0.,  5., ...,  0.,  0.,  0.],
    ...0.],
       [ 0.,  0., 10., ..., 12.,  1.,  0.]]), y=array([0, 1, 2, ..., 8, 9, 8]), context={'baseline_score': 0.9272021217853512, 'baseline_score_std': 0.026919033284817703, 'best_config': {'algorithm': {'bootstrap': False, 'criterion': 'entropy', 'max_depth': None, 'max_features': 2, 'max_leaf_nodes': None, 'min_samples_split': 2, 'n_estimators': 10}, 'config_hash': {'algorithm': 'a49ecb99e74217d6812f98ead7bc9d1fe4a53ba0', 'config': '6749af1a67b4dbcd2b4719e419d99908063c05e1', 'pipeline': '19bdf19a2eec5febce95ab8fa2a71040d75114aa'}, 'duration': 1.5498578548431396, 'iteration': 6, 'loss': 0.14471329609998995, 'max_history_score': 0.85528670390001, 'max_history_score_std': 0.02213730791268438, 'max_history_step': 'joint', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 4, 'features__selectkbest__k': 3}), 'normalizer': ('normalizer_NoneType', {}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 7})}, 'score': 0.85528670390001, ...}, 'history': [{'algorithm': {'bootstrap': False, 'criterion': 'entropy', 'max_depth': 1, 'max_features': 3, 'max_leaf_nodes': 3, 'min_samples_split': 5, 'n_estimators': 50}, 'config_hash': {'algorithm': '752fa095cdab58a238ae606c613606188964cc0c', 'config': 'fd24b065dda6bdeb1077793f9df480ff318c7a37', 'pipeline': '13ea3359c453b8993fcec1e88bc0e19cd0a2b112'}, 'duration': 0.689669132232666, 'iteration': 0, 'loss': 0.6602879519109309, 'max_history_score': 0.3397120480890691, 'max_history_score_std': 0.03346542949100545, 'max_history_step': 'joint', 'pipeline': {'features': ('features_SelectKBest', {'features__k': 4}), 'normalizer': ('normalizer_MinMaxScaler', {}), 'rebalance': ('rebalance_NoneType', {})}, 'score': 0.3397120480890691, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'gini', 'max_depth': 4, 'max_features': 1, 'max_leaf_nodes': 5, 'min_samples_split': 3, 'n_estimators': 25}, 'config_hash': {'algorithm': '9d9de4aee820052ddfe83bfffca420f6b50837d3', 'config': 'fb22f80fb4358ae1ee4c9bd4a83543992be8d806', 'pipeline': '6251ad4bb7a110726a67f90c319f4717ac37a312'}, 'duration': 1.4300940036773682, 'iteration': 1, 'loss': 0.5122196101741096, 'max_history_score': 0.48778038982589045, 'max_history_score_std': 0.05486079759217226, 'max_history_step': 'joint', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 2, 'features__selectkbest__k': 2}), 'normalizer': ('normalizer_StandardScaler', {'normalizer__with_mean': True, 'normalizer__with_std': True}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 5})}, 'score': 0.48778038982589045, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': 4, 'max_features': 1, 'max_leaf_nodes': None, 'min_samples_split': 2, 'n_estimators': 10}, 'config_hash': {'algorithm': '2ed7d27df9a1b2d5e63da76f7cb309616c232022', 'config': '8c97cdb885dd05cfd8c40ee3ac445b61e5c767a8', 'pipeline': 'c0abb5e23a4739d3120740a9519fb36c43eb94d5'}, 'duration': 3.0036678314208984, 'iteration': 2, 'loss': 0.38319264175312906, 'max_history_score': 0.6168073582468709, 'max_history_score_std': 0.05286679173001824, 'max_history_step': 'joint', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 1, 'features__selectkbest__k': 4}), 'normalizer': ('normalizer_PowerTransformer', {}), 'rebalance': ('rebalance_NearMiss', {'rebalance__n_neighbors': 2})}, 'score': 0.6168073582468709, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'entropy', 'max_depth': None, 'max_features': None, 'max_leaf_nodes': 2, 'min_samples_split': 2, 'n_estimators': 100}, 'config_hash': {'algorithm': '17962655e3b76dfcd0843d1e5c2cb7a9db1c6a79', 'config': '16fbb5fd5cfbbacfddf27c61c0c7397a7f6d8ade', 'pipeline': '13ea3359c453b8993fcec1e88bc0e19cd0a2b112'}, 'duration': 1.3447980880737305, 'iteration': 3, 'loss': 0.6768840987778313, 'max_history_score': 0.6168073582468709, 'max_history_score_std': 0.05286679173001824, 'max_history_step': 'joint', 'pipeline': {'features': ('features_SelectKBest', {'features__k': 4}), 'normalizer': ('normalizer_MinMaxScaler', {}), 'rebalance': ('rebalance_NoneType', {})}, 'score': 0.32311590122216866, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'gini', 'max_depth': 2, 'max_features': 2, 'max_leaf_nodes': 2, 'min_samples_split': 3, 'n_estimators': 100}, 'config_hash': {'algorithm': '1ea8965b2247f86950e54510ee6d79399816341b', 'config': 'a77c698197c31308211b854e81a998178941f87d', 'pipeline': 'aaf976c7c663a31fa039582d42f9e07101556a7c'}, 'duration': 2.589430093765259, 'iteration': 4, 'loss': 0.2544808950572157, 'max_history_score': 0.7455191049427843, 'max_history_score_std': 0.04843448308166839, 'max_history_step': 'joint', 'pipeline': {'features': ('features_NoneType', {}), 'normalizer': ('normalizer_PowerTransformer', {}), 'rebalance': ('rebalance_NoneType', {})}, 'score': 0.7455191049427843, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': None, 'max_features': 2, 'max_leaf_nodes': 5, 'min_samples_split': 5, 'n_estimators': 25}, 'config_hash': {'algorithm': 'fd8aeb6a05eaaba41e676d60596c8e0c71b35e0c', 'config': '1fc13606bca3aaf342ca6ea21139cb598b56f8db', 'pipeline': 'f00bd8de05642e026bbba4ad20d3a60088c86b6c'}, 'duration': 1.8779079914093018, 'iteration': 5, 'loss': 0.531551018758381, 'max_history_score': 0.7455191049427843, 'max_history_score_std': 0.04843448308166839, 'max_history_step': 'joint', 'pipeline': {'features': ('features_PCA', {'features__n_components': 2}), 'normalizer': ('normalizer_MinMaxScaler', {}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 5})}, 'score': 0.46844898124161904, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'entropy', 'max_depth': None, 'max_features': 2, 'max_leaf_nodes': None, 'min_samples_split': 2, 'n_estimators': 10}, 'config_hash': {'algorithm': 'a49ecb99e74217d6812f98ead7bc9d1fe4a53ba0', 'config': '6749af1a67b4dbcd2b4719e419d99908063c05e1', 'pipeline': '19bdf19a2eec5febce95ab8fa2a71040d75114aa'}, 'duration': 1.5498578548431396, 'iteration': 6, 'loss': 0.14471329609998995, 'max_history_score': 0.85528670390001, 'max_history_score_std': 0.02213730791268438, 'max_history_step': 'joint', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 4, 'features__selectkbest__k': 3}), 'normalizer': ('normalizer_NoneType', {}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 7})}, 'score': 0.85528670390001, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': 1, 'max_features': 3, 'max_leaf_nodes': 3, 'min_samples_split': 3, 'n_estimators': 75}, 'config_hash': {'algorithm': 'ebfb16234172ae811ff21185ff92bbdbb8f32f14', 'config': 'd92d4ada2394fc132733e176e926ee53acdc6a00', 'pipeline': '8071e7cbf86a5c3056493dc3aa40063aeb28cdfe'}, 'duration': 1.3618149757385254, 'iteration': 7, 'loss': 0.6158612049395463, 'max_history_score': 0.85528670390001, 'max_history_score_std': 0.02213730791268438, 'max_history_step': 'joint', 'pipeline': {'features': ('features_SelectKBest', {'features__k': 4}), 'normalizer': ('normalizer_StandardScaler', {'normalizer__with_mean': True, 'normalizer__with_std': True}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 5})}, 'score': 0.3841387950604537, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'entropy', 'max_depth': 1, 'max_features': 1, 'max_leaf_nodes': 5, 'min_samples_split': 2, 'n_estimators': 100}, 'config_hash': {'algorithm': '896b53c75a2db568fb7b6da3bfca2f7a1535a11b', 'config': 'f0d0b1d2cedc22ae15d9a208a3fc3fc133bf0d3d', 'pipeline': 'c9761c9a33bf75d6dcad0742c421548a7655ccc9'}, 'duration': 2.297278881072998, 'iteration': 8, 'loss': 0.40673663548410355, 'max_history_score': 0.85528670390001, 'max_history_score_std': 0.02213730791268438, 'max_history_step': 'joint', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 2, 'features__selectkbest__k': 4}), 'normalizer': ('normalizer_StandardScaler', {'normalizer__with_mean': False, 'normalizer__with_std': False}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 5})}, 'score': 0.5932633645158965, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'entropy', 'max_depth': 2, 'max_features': None, 'max_leaf_nodes': None, 'min_samples_split': 5, 'n_estimators': 25}, 'config_hash': {'algorithm': '0b0e954757c4f75343a6efb740ad93260ed781ae', 'config': '47584de0e60d0d12c7dbbf0dc60e5aea96e3f4b2', 'pipeline': 'b37ee32d59413053bf9a2a72c8ff7135f3701e05'}, 'duration': 0.7249000072479248, 'iteration': 9, 'loss': 0.6965910020393421, 'max_history_score': 0.85528670390001, 'max_history_score_std': 0.02213730791268438, 'max_history_step': 'joint', 'pipeline': {'features': ('features_SelectKBest', {'features__k': 3}), 'normalizer': ('normalizer_NoneType', {}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 7})}, 'score': 0.3034089979606579, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'gini', 'max_depth': 2, 'max_features': 2, 'max_leaf_nodes': 5, 'min_samples_split': 5, 'n_estimators': 75}, 'config_hash': {'algorithm': 'f1ead1d9e33ea927e1dd27d872a058fa3de4f832', 'config': 'eecb88ee2b1b95d741c1b5c7751534d31aae6a77', 'pipeline': '6746650871e8b61efc9302b092dc05f7cdb179d5'}, 'duration': 5.340634822845459, 'iteration': 10, 'loss': 0.7687016290977936, 'max_history_score': 0.85528670390001, 'max_history_score_std': 0.02213730791268438, 'max_history_step': 'joint', 'pipeline': {'features': ('features_SelectKBest', {'features__k': 3}), 'normalizer': ('normalizer_RobustScaler', {'normalizer__quantile_range': (...), 'normalizer__with_centering': False, 'normalizer__with_scaling': False}), 'rebalance': ('rebalance_CondensedNearestNeighbour', {'rebalance__n_neighbors': 1})}, 'score': 0.23129837090220637, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': 1, 'max_features': 2, 'max_leaf_nodes': 2, 'min_samples_split': 3, 'n_estimators': 75}, 'config_hash': {'algorithm': '531a3bb8ccf0baa06727af4b3de9e62d25e6eabf', 'config': '27a7ed0502b321ab7256b77c8ce79e90cb9da815', 'pipeline': '77e6d84e2217b92b3cf67cc6defef9dd3554cec0'}, 'duration': 1.775357961654663, 'iteration': 11, 'loss': 0.6313818737375694, 'max_history_score': 0.85528670390001, 'max_history_score_std': 0.02213730791268438, 'max_history_step': 'joint', 'pipeline': {'features': ('features_SelectKBest', {'features__k': 4}), 'normalizer': ('normalizer_MinMaxScaler', {}), 'rebalance': ('rebalance_NearMiss', {'rebalance__n_neighbors': 3})}, 'score': 0.3686181262624307, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'entropy', 'max_depth': 4, 'max_features': 3, 'max_leaf_nodes': 2, 'min_samples_split': 3, 'n_estimators': 10}, 'config_hash': {'algorithm': '93518f8ded6074d537900b26be72f8485782f933', 'config': '45f056102dd2d644bd8befa471f17b2311ac7954', 'pipeline': '5240329df25c9a533d025c1a401d49835a501b41'}, 'duration': 3.2622711658477783, 'iteration': 12, 'loss': 0.6120243191353301, 'max_history_score': 0.85528670390001, 'max_history_score_std': 0.02213730791268438, 'max_history_step': 'joint', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 4, 'features__selectkbest__k': 2}), 'normalizer': ('normalizer_PowerTransformer', {}), 'rebalance': ('rebalance_NearMiss', {'rebalance__n_neighbors': 1})}, 'score': 0.38797568086467, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'entropy', 'max_depth': None, 'max_features': 1, 'max_leaf_nodes': 5, 'min_samples_split': 3, 'n_estimators': 75}, 'config_hash': {'algorithm': 'e515d45b764fa43591032874a0ff9c25bf12fddd', 'config': 'ba108323623936872824ed8f1c41d615d25523b3', 'pipeline': '9d823bc0442f21b5ce8af67a5eb1237f64ffc2f8'}, 'duration': 2.5326571464538574, 'iteration': 13, 'loss': 0.6271427382991047, 'max_history_score': 0.85528670390001, 'max_history_score_std': 0.02213730791268438, 'max_history_step': 'joint', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 1, 'features__selectkbest__k': 1}), 'normalizer': ('normalizer_StandardScaler', {'normalizer__with_mean': True, 'normalizer__with_std': True}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 5})}, 'score': 0.3728572617008953, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'entropy', 'max_depth': 3, 'max_features': 2, 'max_leaf_nodes': 2, 'min_samples_split': 3, 'n_estimators': 25}, 'config_hash': {'algorithm': '2808e67f609eba5c8a97f81ac0c9413cd37cf7aa', 'config': 'dde4d3b5f37741629cb58bfc4051ed9f98c8f311', 'pipeline': 'bc52deabf1f5ee60968ba541d9d2574353c30a9c'}, 'duration': 0.7145559787750244, 'iteration': 14, 'loss': 0.6831045572696203, 'max_history_score': 0.85528670390001, 'max_history_score_std': 0.02213730791268438, 'max_history_step': 'joint', 'pipeline': {'features': ('features_SelectKBest', {'features__k': 3}), 'normalizer': ('normalizer_MinMaxScaler', {}), 'rebalance': ('rebalance_NearMiss', {'rebalance__n_neighbors': 1})}, 'score': 0.31689544273037973, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'gini', 'max_depth': 2, 'max_features': 2, 'max_leaf_nodes': None, 'min_samples_split': 5, 'n_estimators': 100}, 'config_hash': {'algorithm': 'b942acdead762d34afeb474bc2fe6f7fd0f23493', 'config': '1080c25b92da3f15a6f8eec003957f7e0a66324f', 'pipeline': 'cfa84fe703dc5bc0bbd2257a6d524fee2693b804'}, 'duration': 2.812459945678711, 'iteration': 15, 'loss': 0.6921421091202761, 'max_history_score': 0.85528670390001, 'max_history_score_std': 0.02213730791268438, 'max_history_step': 'joint', 'pipeline': {'features': ('features_SelectKBest', {'features__k': 2}), 'normalizer': ('normalizer_PowerTransformer', {}), 'rebalance': ('rebalance_NoneType', {})}, 'score': 0.3078578908797239, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'entropy', 'max_depth': 2, 'max_features': 3, 'max_leaf_nodes': 3, 'min_samples_split': 2, 'n_estimators': 75}, 'config_hash': {'algorithm': '250661ce4193a61ef44d2f77694b52b785ff032d', 'config': 'c3e8cf4eca5aafcae4ac31b0449e105ca127ffe2', 'pipeline': 'c4dd111513ea35f97dd3aec3e8e7f6268ce035da'}, 'duration': 1.0555319786071777, 'iteration': 16, 'loss': 1.0, 'max_history_score': 0.85528670390001, 'max_history_score_std': 0.02213730791268438, 'max_history_step': 'joint', 'pipeline': {'features': ('features_PCA', {'features__n_components': 2}), 'normalizer': ('normalizer_RobustScaler', {'normalizer__quantile_range': (...), 'normalizer__with_centering': False, 'normalizer__with_scaling': True}), 'rebalance': ('rebalance_NearMiss', {'rebalance__n_neighbors': 2})}, 'score': 0.0, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'entropy', 'max_depth': 3, 'max_features': 3, 'max_leaf_nodes': None, 'min_samples_split': 3, 'n_estimators': 25}, 'config_hash': {'algorithm': '05ac02bd045c65dc4089894902ad6253661a2692', 'config': '3449b4a1c2e488e26a7195ee9edca19b854ebd33', 'pipeline': '505d3f71b534917375d765e64b0611e7dfb83746'}, 'duration': 5.5412821769714355, 'iteration': 17, 'loss': 0.7289151155121668, 'max_history_score': 0.85528670390001, 'max_history_score_std': 0.02213730791268438, 'max_history_step': 'joint', 'pipeline': {'features': ('features_SelectKBest', {'features__k': 4}), 'normalizer': ('normalizer_MinMaxScaler', {}), 'rebalance': ('rebalance_CondensedNearestNeighbour', {'rebalance__n_neighbors': 2})}, 'score': 0.2710848844878332, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'entropy', 'max_depth': 2, 'max_features': None, 'max_leaf_nodes': None, 'min_samples_split': 2, 'n_estimators': 25}, 'config_hash': {'algorithm': 'de3b3a352ebb260e16c6b213a08c9144d17a744b', 'config': '224987ffdbbb9b6182cff18d8374518b917e4f2e', 'pipeline': '12c89200a558b2f3b91332566f41050143aecbe7'}, 'duration': 2.4646048545837402, 'iteration': 18, 'loss': 0.6545902512995826, 'max_history_score': 0.85528670390001, 'max_history_score_std': 0.02213730791268438, 'max_history_step': 'joint', 'pipeline': {'features': ('features_NoneType', {}), 'normalizer': ('normalizer_PowerTransformer', {}), 'rebalance': ('rebalance_NearMiss', {'rebalance__n_neighbors': 2})}, 'score': 0.3454097487004174, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'gini', 'max_depth': None, 'max_features': 1, 'max_leaf_nodes': None, 'min_samples_split': 3, 'n_estimators': 100}, 'config_hash': {'algorithm': '30ca111584767bbf0464df40b4c928cf7ddf9459', 'config': '97ca7d6a017c721084dec2a5d2e5a67e1e6ae2f0', 'pipeline': '789eca82ea4a42d61927670c538867b745fd81d3'}, 'duration': 7.164499044418335, 'iteration': 19, 'loss': 0.6536825403350528, 'max_history_score': 0.85528670390001, 'max_history_score_std': 0.02213730791268438, 'max_history_step': 'joint', 'pipeline': {'features': ('features_SelectKBest', {'features__k': 3}), 'normalizer': ('normalizer_RobustScaler', {'normalizer__quantile_range': (...), 'normalizer__with_centering': False, 'normalizer__with_scaling': True}), 'rebalance': ('rebalance_CondensedNearestNeighbour', {'rebalance__n_neighbors': 3})}, 'score': 0.3463174596649472, ...}, ...], 'history_hash': ['fd24b065dda6bdeb1077793f9df480ff318c7a37', 'fb22f80fb4358ae1ee4c9bd4a83543992be8d806', '8c97cdb885dd05cfd8c40ee3ac445b61e5c767a8', '16fbb5fd5cfbbacfddf27c61c0c7397a7f6d8ade', 'a77c698197c31308211b854e81a998178941f87d', '1fc13606bca3aaf342ca6ea21139cb598b56f8db', '6749af1a67b4dbcd2b4719e419d99908063c05e1', 'd92d4ada2394fc132733e176e926ee53acdc6a00', 'f0d0b1d2cedc22ae15d9a208a3fc3fc133bf0d3d', '47584de0e60d0d12c7dbbf0dc60e5aea96e3f4b2', 'eecb88ee2b1b95d741c1b5c7751534d31aae6a77', '27a7ed0502b321ab7256b77c8ce79e90cb9da815', '45f056102dd2d644bd8befa471f17b2311ac7954', 'ba108323623936872824ed8f1c41d615d25523b3', 'dde4d3b5f37741629cb58bfc4051ed9f98c8f311', '1080c25b92da3f15a6f8eec003957f7e0a66324f', 'c3e8cf4eca5aafcae4ac31b0449e105ca127ffe2', '3449b4a1c2e488e26a7195ee9edca19b854ebd33', '224987ffdbbb9b6182cff18d8374518b917e4f2e', '97ca7d6a017c721084dec2a5d2e5a67e1e6ae2f0', ...], 'history_index': {'1080c25b92da3f15a6f8eec003957f7e0a66324f': 15, '16fbb5fd5cfbbacfddf27c61c0c7397a7f6d8ade': 3, '1fc13606bca3aaf342ca6ea21139cb598b56f8db': 5, '2187b0ebdd42d61eb93839b9a1592ae8707ce4c5': 42, '224987ffdbbb9b6182cff18d8374518b917e4f2e': 18, '235f12fbdc7e6cff792ad0da8c8430ce2e5b9cc6': 46, '27a7ed0502b321ab7256b77c8ce79e90cb9da815': 11, '300257dd230eb5db40e499b05582132bb87f574b': 35, '3449b4a1c2e488e26a7195ee9edca19b854ebd33': 17, '3567266057a9169d1e19b5468ae8b24572886e03': 23, ...}, 'iteration': 46, 'max_history_score': 0.85528670390001, 'max_history_score_std': 0.02213730791268438, 'max_history_step': 'joint'}, config={'algorithm': 'RandomForest', 'seed': 42, 'time': 300})
    108 
    109 def objective_algo(algo_config, current_pipeline_config, algorithm, X, y, context, config):
    110     return objective(current_pipeline_config, algo_config, algorithm, X, y, context, config, step='algorithm')
    111 
    112 def objective_joint(wconfig, algorithm, X, y, context, config):
--> 113     return objective(wconfig['pipeline'], wconfig['algorithm'], algorithm, X, y, context, config, step='joint')
        wconfig = {'algorithm': {'bootstrap': True, 'criterion': 'entropy', 'max_depth': 1, 'max_features': 3, 'max_leaf_nodes': 2, 'min_samples_split': 2, 'n_estimators': 100}, 'pipeline': {'features': ('features_SelectKBest', {'features__k': 1}), 'normalizer': ('normalizer_MinMaxScaler', {}), 'rebalance': ('rebalance_CondensedNearestNeighbour', {'rebalance__n_neighbors': 1})}}
        algorithm = 'RandomForest'
        X = array([[ 0.,  0.,  5., ...,  0.,  0.,  0.],
    ...0.],
       [ 0.,  0., 10., ..., 12.,  1.,  0.]])
        y = array([0, 1, 2, ..., 8, 9, 8])
        context = {'baseline_score': 0.9272021217853512, 'baseline_score_std': 0.026919033284817703, 'best_config': {'algorithm': {'bootstrap': False, 'criterion': 'entropy', 'max_depth': None, 'max_features': 2, 'max_leaf_nodes': None, 'min_samples_split': 2, 'n_estimators': 10}, 'config_hash': {'algorithm': 'a49ecb99e74217d6812f98ead7bc9d1fe4a53ba0', 'config': '6749af1a67b4dbcd2b4719e419d99908063c05e1', 'pipeline': '19bdf19a2eec5febce95ab8fa2a71040d75114aa'}, 'duration': 1.5498578548431396, 'iteration': 6, 'loss': 0.14471329609998995, 'max_history_score': 0.85528670390001, 'max_history_score_std': 0.02213730791268438, 'max_history_step': 'joint', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 4, 'features__selectkbest__k': 3}), 'normalizer': ('normalizer_NoneType', {}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 7})}, 'score': 0.85528670390001, ...}, 'history': [{'algorithm': {'bootstrap': False, 'criterion': 'entropy', 'max_depth': 1, 'max_features': 3, 'max_leaf_nodes': 3, 'min_samples_split': 5, 'n_estimators': 50}, 'config_hash': {'algorithm': '752fa095cdab58a238ae606c613606188964cc0c', 'config': 'fd24b065dda6bdeb1077793f9df480ff318c7a37', 'pipeline': '13ea3359c453b8993fcec1e88bc0e19cd0a2b112'}, 'duration': 0.689669132232666, 'iteration': 0, 'loss': 0.6602879519109309, 'max_history_score': 0.3397120480890691, 'max_history_score_std': 0.03346542949100545, 'max_history_step': 'joint', 'pipeline': {'features': ('features_SelectKBest', {'features__k': 4}), 'normalizer': ('normalizer_MinMaxScaler', {}), 'rebalance': ('rebalance_NoneType', {})}, 'score': 0.3397120480890691, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'gini', 'max_depth': 4, 'max_features': 1, 'max_leaf_nodes': 5, 'min_samples_split': 3, 'n_estimators': 25}, 'config_hash': {'algorithm': '9d9de4aee820052ddfe83bfffca420f6b50837d3', 'config': 'fb22f80fb4358ae1ee4c9bd4a83543992be8d806', 'pipeline': '6251ad4bb7a110726a67f90c319f4717ac37a312'}, 'duration': 1.4300940036773682, 'iteration': 1, 'loss': 0.5122196101741096, 'max_history_score': 0.48778038982589045, 'max_history_score_std': 0.05486079759217226, 'max_history_step': 'joint', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 2, 'features__selectkbest__k': 2}), 'normalizer': ('normalizer_StandardScaler', {'normalizer__with_mean': True, 'normalizer__with_std': True}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 5})}, 'score': 0.48778038982589045, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': 4, 'max_features': 1, 'max_leaf_nodes': None, 'min_samples_split': 2, 'n_estimators': 10}, 'config_hash': {'algorithm': '2ed7d27df9a1b2d5e63da76f7cb309616c232022', 'config': '8c97cdb885dd05cfd8c40ee3ac445b61e5c767a8', 'pipeline': 'c0abb5e23a4739d3120740a9519fb36c43eb94d5'}, 'duration': 3.0036678314208984, 'iteration': 2, 'loss': 0.38319264175312906, 'max_history_score': 0.6168073582468709, 'max_history_score_std': 0.05286679173001824, 'max_history_step': 'joint', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 1, 'features__selectkbest__k': 4}), 'normalizer': ('normalizer_PowerTransformer', {}), 'rebalance': ('rebalance_NearMiss', {'rebalance__n_neighbors': 2})}, 'score': 0.6168073582468709, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'entropy', 'max_depth': None, 'max_features': None, 'max_leaf_nodes': 2, 'min_samples_split': 2, 'n_estimators': 100}, 'config_hash': {'algorithm': '17962655e3b76dfcd0843d1e5c2cb7a9db1c6a79', 'config': '16fbb5fd5cfbbacfddf27c61c0c7397a7f6d8ade', 'pipeline': '13ea3359c453b8993fcec1e88bc0e19cd0a2b112'}, 'duration': 1.3447980880737305, 'iteration': 3, 'loss': 0.6768840987778313, 'max_history_score': 0.6168073582468709, 'max_history_score_std': 0.05286679173001824, 'max_history_step': 'joint', 'pipeline': {'features': ('features_SelectKBest', {'features__k': 4}), 'normalizer': ('normalizer_MinMaxScaler', {}), 'rebalance': ('rebalance_NoneType', {})}, 'score': 0.32311590122216866, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'gini', 'max_depth': 2, 'max_features': 2, 'max_leaf_nodes': 2, 'min_samples_split': 3, 'n_estimators': 100}, 'config_hash': {'algorithm': '1ea8965b2247f86950e54510ee6d79399816341b', 'config': 'a77c698197c31308211b854e81a998178941f87d', 'pipeline': 'aaf976c7c663a31fa039582d42f9e07101556a7c'}, 'duration': 2.589430093765259, 'iteration': 4, 'loss': 0.2544808950572157, 'max_history_score': 0.7455191049427843, 'max_history_score_std': 0.04843448308166839, 'max_history_step': 'joint', 'pipeline': {'features': ('features_NoneType', {}), 'normalizer': ('normalizer_PowerTransformer', {}), 'rebalance': ('rebalance_NoneType', {})}, 'score': 0.7455191049427843, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': None, 'max_features': 2, 'max_leaf_nodes': 5, 'min_samples_split': 5, 'n_estimators': 25}, 'config_hash': {'algorithm': 'fd8aeb6a05eaaba41e676d60596c8e0c71b35e0c', 'config': '1fc13606bca3aaf342ca6ea21139cb598b56f8db', 'pipeline': 'f00bd8de05642e026bbba4ad20d3a60088c86b6c'}, 'duration': 1.8779079914093018, 'iteration': 5, 'loss': 0.531551018758381, 'max_history_score': 0.7455191049427843, 'max_history_score_std': 0.04843448308166839, 'max_history_step': 'joint', 'pipeline': {'features': ('features_PCA', {'features__n_components': 2}), 'normalizer': ('normalizer_MinMaxScaler', {}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 5})}, 'score': 0.46844898124161904, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'entropy', 'max_depth': None, 'max_features': 2, 'max_leaf_nodes': None, 'min_samples_split': 2, 'n_estimators': 10}, 'config_hash': {'algorithm': 'a49ecb99e74217d6812f98ead7bc9d1fe4a53ba0', 'config': '6749af1a67b4dbcd2b4719e419d99908063c05e1', 'pipeline': '19bdf19a2eec5febce95ab8fa2a71040d75114aa'}, 'duration': 1.5498578548431396, 'iteration': 6, 'loss': 0.14471329609998995, 'max_history_score': 0.85528670390001, 'max_history_score_std': 0.02213730791268438, 'max_history_step': 'joint', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 4, 'features__selectkbest__k': 3}), 'normalizer': ('normalizer_NoneType', {}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 7})}, 'score': 0.85528670390001, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': 1, 'max_features': 3, 'max_leaf_nodes': 3, 'min_samples_split': 3, 'n_estimators': 75}, 'config_hash': {'algorithm': 'ebfb16234172ae811ff21185ff92bbdbb8f32f14', 'config': 'd92d4ada2394fc132733e176e926ee53acdc6a00', 'pipeline': '8071e7cbf86a5c3056493dc3aa40063aeb28cdfe'}, 'duration': 1.3618149757385254, 'iteration': 7, 'loss': 0.6158612049395463, 'max_history_score': 0.85528670390001, 'max_history_score_std': 0.02213730791268438, 'max_history_step': 'joint', 'pipeline': {'features': ('features_SelectKBest', {'features__k': 4}), 'normalizer': ('normalizer_StandardScaler', {'normalizer__with_mean': True, 'normalizer__with_std': True}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 5})}, 'score': 0.3841387950604537, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'entropy', 'max_depth': 1, 'max_features': 1, 'max_leaf_nodes': 5, 'min_samples_split': 2, 'n_estimators': 100}, 'config_hash': {'algorithm': '896b53c75a2db568fb7b6da3bfca2f7a1535a11b', 'config': 'f0d0b1d2cedc22ae15d9a208a3fc3fc133bf0d3d', 'pipeline': 'c9761c9a33bf75d6dcad0742c421548a7655ccc9'}, 'duration': 2.297278881072998, 'iteration': 8, 'loss': 0.40673663548410355, 'max_history_score': 0.85528670390001, 'max_history_score_std': 0.02213730791268438, 'max_history_step': 'joint', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 2, 'features__selectkbest__k': 4}), 'normalizer': ('normalizer_StandardScaler', {'normalizer__with_mean': False, 'normalizer__with_std': False}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 5})}, 'score': 0.5932633645158965, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'entropy', 'max_depth': 2, 'max_features': None, 'max_leaf_nodes': None, 'min_samples_split': 5, 'n_estimators': 25}, 'config_hash': {'algorithm': '0b0e954757c4f75343a6efb740ad93260ed781ae', 'config': '47584de0e60d0d12c7dbbf0dc60e5aea96e3f4b2', 'pipeline': 'b37ee32d59413053bf9a2a72c8ff7135f3701e05'}, 'duration': 0.7249000072479248, 'iteration': 9, 'loss': 0.6965910020393421, 'max_history_score': 0.85528670390001, 'max_history_score_std': 0.02213730791268438, 'max_history_step': 'joint', 'pipeline': {'features': ('features_SelectKBest', {'features__k': 3}), 'normalizer': ('normalizer_NoneType', {}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 7})}, 'score': 0.3034089979606579, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'gini', 'max_depth': 2, 'max_features': 2, 'max_leaf_nodes': 5, 'min_samples_split': 5, 'n_estimators': 75}, 'config_hash': {'algorithm': 'f1ead1d9e33ea927e1dd27d872a058fa3de4f832', 'config': 'eecb88ee2b1b95d741c1b5c7751534d31aae6a77', 'pipeline': '6746650871e8b61efc9302b092dc05f7cdb179d5'}, 'duration': 5.340634822845459, 'iteration': 10, 'loss': 0.7687016290977936, 'max_history_score': 0.85528670390001, 'max_history_score_std': 0.02213730791268438, 'max_history_step': 'joint', 'pipeline': {'features': ('features_SelectKBest', {'features__k': 3}), 'normalizer': ('normalizer_RobustScaler', {'normalizer__quantile_range': (...), 'normalizer__with_centering': False, 'normalizer__with_scaling': False}), 'rebalance': ('rebalance_CondensedNearestNeighbour', {'rebalance__n_neighbors': 1})}, 'score': 0.23129837090220637, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': 1, 'max_features': 2, 'max_leaf_nodes': 2, 'min_samples_split': 3, 'n_estimators': 75}, 'config_hash': {'algorithm': '531a3bb8ccf0baa06727af4b3de9e62d25e6eabf', 'config': '27a7ed0502b321ab7256b77c8ce79e90cb9da815', 'pipeline': '77e6d84e2217b92b3cf67cc6defef9dd3554cec0'}, 'duration': 1.775357961654663, 'iteration': 11, 'loss': 0.6313818737375694, 'max_history_score': 0.85528670390001, 'max_history_score_std': 0.02213730791268438, 'max_history_step': 'joint', 'pipeline': {'features': ('features_SelectKBest', {'features__k': 4}), 'normalizer': ('normalizer_MinMaxScaler', {}), 'rebalance': ('rebalance_NearMiss', {'rebalance__n_neighbors': 3})}, 'score': 0.3686181262624307, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'entropy', 'max_depth': 4, 'max_features': 3, 'max_leaf_nodes': 2, 'min_samples_split': 3, 'n_estimators': 10}, 'config_hash': {'algorithm': '93518f8ded6074d537900b26be72f8485782f933', 'config': '45f056102dd2d644bd8befa471f17b2311ac7954', 'pipeline': '5240329df25c9a533d025c1a401d49835a501b41'}, 'duration': 3.2622711658477783, 'iteration': 12, 'loss': 0.6120243191353301, 'max_history_score': 0.85528670390001, 'max_history_score_std': 0.02213730791268438, 'max_history_step': 'joint', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 4, 'features__selectkbest__k': 2}), 'normalizer': ('normalizer_PowerTransformer', {}), 'rebalance': ('rebalance_NearMiss', {'rebalance__n_neighbors': 1})}, 'score': 0.38797568086467, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'entropy', 'max_depth': None, 'max_features': 1, 'max_leaf_nodes': 5, 'min_samples_split': 3, 'n_estimators': 75}, 'config_hash': {'algorithm': 'e515d45b764fa43591032874a0ff9c25bf12fddd', 'config': 'ba108323623936872824ed8f1c41d615d25523b3', 'pipeline': '9d823bc0442f21b5ce8af67a5eb1237f64ffc2f8'}, 'duration': 2.5326571464538574, 'iteration': 13, 'loss': 0.6271427382991047, 'max_history_score': 0.85528670390001, 'max_history_score_std': 0.02213730791268438, 'max_history_step': 'joint', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 1, 'features__selectkbest__k': 1}), 'normalizer': ('normalizer_StandardScaler', {'normalizer__with_mean': True, 'normalizer__with_std': True}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 5})}, 'score': 0.3728572617008953, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'entropy', 'max_depth': 3, 'max_features': 2, 'max_leaf_nodes': 2, 'min_samples_split': 3, 'n_estimators': 25}, 'config_hash': {'algorithm': '2808e67f609eba5c8a97f81ac0c9413cd37cf7aa', 'config': 'dde4d3b5f37741629cb58bfc4051ed9f98c8f311', 'pipeline': 'bc52deabf1f5ee60968ba541d9d2574353c30a9c'}, 'duration': 0.7145559787750244, 'iteration': 14, 'loss': 0.6831045572696203, 'max_history_score': 0.85528670390001, 'max_history_score_std': 0.02213730791268438, 'max_history_step': 'joint', 'pipeline': {'features': ('features_SelectKBest', {'features__k': 3}), 'normalizer': ('normalizer_MinMaxScaler', {}), 'rebalance': ('rebalance_NearMiss', {'rebalance__n_neighbors': 1})}, 'score': 0.31689544273037973, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'gini', 'max_depth': 2, 'max_features': 2, 'max_leaf_nodes': None, 'min_samples_split': 5, 'n_estimators': 100}, 'config_hash': {'algorithm': 'b942acdead762d34afeb474bc2fe6f7fd0f23493', 'config': '1080c25b92da3f15a6f8eec003957f7e0a66324f', 'pipeline': 'cfa84fe703dc5bc0bbd2257a6d524fee2693b804'}, 'duration': 2.812459945678711, 'iteration': 15, 'loss': 0.6921421091202761, 'max_history_score': 0.85528670390001, 'max_history_score_std': 0.02213730791268438, 'max_history_step': 'joint', 'pipeline': {'features': ('features_SelectKBest', {'features__k': 2}), 'normalizer': ('normalizer_PowerTransformer', {}), 'rebalance': ('rebalance_NoneType', {})}, 'score': 0.3078578908797239, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'entropy', 'max_depth': 2, 'max_features': 3, 'max_leaf_nodes': 3, 'min_samples_split': 2, 'n_estimators': 75}, 'config_hash': {'algorithm': '250661ce4193a61ef44d2f77694b52b785ff032d', 'config': 'c3e8cf4eca5aafcae4ac31b0449e105ca127ffe2', 'pipeline': 'c4dd111513ea35f97dd3aec3e8e7f6268ce035da'}, 'duration': 1.0555319786071777, 'iteration': 16, 'loss': 1.0, 'max_history_score': 0.85528670390001, 'max_history_score_std': 0.02213730791268438, 'max_history_step': 'joint', 'pipeline': {'features': ('features_PCA', {'features__n_components': 2}), 'normalizer': ('normalizer_RobustScaler', {'normalizer__quantile_range': (...), 'normalizer__with_centering': False, 'normalizer__with_scaling': True}), 'rebalance': ('rebalance_NearMiss', {'rebalance__n_neighbors': 2})}, 'score': 0.0, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'entropy', 'max_depth': 3, 'max_features': 3, 'max_leaf_nodes': None, 'min_samples_split': 3, 'n_estimators': 25}, 'config_hash': {'algorithm': '05ac02bd045c65dc4089894902ad6253661a2692', 'config': '3449b4a1c2e488e26a7195ee9edca19b854ebd33', 'pipeline': '505d3f71b534917375d765e64b0611e7dfb83746'}, 'duration': 5.5412821769714355, 'iteration': 17, 'loss': 0.7289151155121668, 'max_history_score': 0.85528670390001, 'max_history_score_std': 0.02213730791268438, 'max_history_step': 'joint', 'pipeline': {'features': ('features_SelectKBest', {'features__k': 4}), 'normalizer': ('normalizer_MinMaxScaler', {}), 'rebalance': ('rebalance_CondensedNearestNeighbour', {'rebalance__n_neighbors': 2})}, 'score': 0.2710848844878332, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'entropy', 'max_depth': 2, 'max_features': None, 'max_leaf_nodes': None, 'min_samples_split': 2, 'n_estimators': 25}, 'config_hash': {'algorithm': 'de3b3a352ebb260e16c6b213a08c9144d17a744b', 'config': '224987ffdbbb9b6182cff18d8374518b917e4f2e', 'pipeline': '12c89200a558b2f3b91332566f41050143aecbe7'}, 'duration': 2.4646048545837402, 'iteration': 18, 'loss': 0.6545902512995826, 'max_history_score': 0.85528670390001, 'max_history_score_std': 0.02213730791268438, 'max_history_step': 'joint', 'pipeline': {'features': ('features_NoneType', {}), 'normalizer': ('normalizer_PowerTransformer', {}), 'rebalance': ('rebalance_NearMiss', {'rebalance__n_neighbors': 2})}, 'score': 0.3454097487004174, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'gini', 'max_depth': None, 'max_features': 1, 'max_leaf_nodes': None, 'min_samples_split': 3, 'n_estimators': 100}, 'config_hash': {'algorithm': '30ca111584767bbf0464df40b4c928cf7ddf9459', 'config': '97ca7d6a017c721084dec2a5d2e5a67e1e6ae2f0', 'pipeline': '789eca82ea4a42d61927670c538867b745fd81d3'}, 'duration': 7.164499044418335, 'iteration': 19, 'loss': 0.6536825403350528, 'max_history_score': 0.85528670390001, 'max_history_score_std': 0.02213730791268438, 'max_history_step': 'joint', 'pipeline': {'features': ('features_SelectKBest', {'features__k': 3}), 'normalizer': ('normalizer_RobustScaler', {'normalizer__quantile_range': (...), 'normalizer__with_centering': False, 'normalizer__with_scaling': True}), 'rebalance': ('rebalance_CondensedNearestNeighbour', {'rebalance__n_neighbors': 3})}, 'score': 0.3463174596649472, ...}, ...], 'history_hash': ['fd24b065dda6bdeb1077793f9df480ff318c7a37', 'fb22f80fb4358ae1ee4c9bd4a83543992be8d806', '8c97cdb885dd05cfd8c40ee3ac445b61e5c767a8', '16fbb5fd5cfbbacfddf27c61c0c7397a7f6d8ade', 'a77c698197c31308211b854e81a998178941f87d', '1fc13606bca3aaf342ca6ea21139cb598b56f8db', '6749af1a67b4dbcd2b4719e419d99908063c05e1', 'd92d4ada2394fc132733e176e926ee53acdc6a00', 'f0d0b1d2cedc22ae15d9a208a3fc3fc133bf0d3d', '47584de0e60d0d12c7dbbf0dc60e5aea96e3f4b2', 'eecb88ee2b1b95d741c1b5c7751534d31aae6a77', '27a7ed0502b321ab7256b77c8ce79e90cb9da815', '45f056102dd2d644bd8befa471f17b2311ac7954', 'ba108323623936872824ed8f1c41d615d25523b3', 'dde4d3b5f37741629cb58bfc4051ed9f98c8f311', '1080c25b92da3f15a6f8eec003957f7e0a66324f', 'c3e8cf4eca5aafcae4ac31b0449e105ca127ffe2', '3449b4a1c2e488e26a7195ee9edca19b854ebd33', '224987ffdbbb9b6182cff18d8374518b917e4f2e', '97ca7d6a017c721084dec2a5d2e5a67e1e6ae2f0', ...], 'history_index': {'1080c25b92da3f15a6f8eec003957f7e0a66324f': 15, '16fbb5fd5cfbbacfddf27c61c0c7397a7f6d8ade': 3, '1fc13606bca3aaf342ca6ea21139cb598b56f8db': 5, '2187b0ebdd42d61eb93839b9a1592ae8707ce4c5': 42, '224987ffdbbb9b6182cff18d8374518b917e4f2e': 18, '235f12fbdc7e6cff792ad0da8c8430ce2e5b9cc6': 46, '27a7ed0502b321ab7256b77c8ce79e90cb9da815': 11, '300257dd230eb5db40e499b05582132bb87f574b': 35, '3449b4a1c2e488e26a7195ee9edca19b854ebd33': 17, '3567266057a9169d1e19b5468ae8b24572886e03': 23, ...}, 'iteration': 46, 'max_history_score': 0.85528670390001, 'max_history_score_std': 0.02213730791268438, 'max_history_step': 'joint'}
        config = {'algorithm': 'RandomForest', 'seed': 42, 'time': 300}
    114 
    115 
    116 def get_baseline_score(algorithm, X, y, seed):
    117     pipeline, _ = pipeline_conf_to_full_pipeline(

...........................................................................
/home/aquemy/dev/dp_hyperparameters/extension/experiment/objective.py in objective(pipeline_config={'features': ('features_SelectKBest', {'features__k': 1}), 'normalizer': ('normalizer_MinMaxScaler', {}), 'rebalance': ('rebalance_CondensedNearestNeighbour', {'rebalance__n_neighbors': 1})}, algo_config={'bootstrap': True, 'criterion': 'entropy', 'max_depth': 1, 'max_features': 3, 'max_leaf_nodes': 2, 'min_samples_split': 2, 'n_estimators': 100}, algorithm='RandomForest', X=array([[ 0.,  0.,  5., ...,  0.,  0.,  0.],
    ...0.],
       [ 0.,  0., 10., ..., 12.,  1.,  0.]]), y=array([0, 1, 2, ..., 8, 9, 8]), context={'baseline_score': 0.9272021217853512, 'baseline_score_std': 0.026919033284817703, 'best_config': {'algorithm': {'bootstrap': False, 'criterion': 'entropy', 'max_depth': None, 'max_features': 2, 'max_leaf_nodes': None, 'min_samples_split': 2, 'n_estimators': 10}, 'config_hash': {'algorithm': 'a49ecb99e74217d6812f98ead7bc9d1fe4a53ba0', 'config': '6749af1a67b4dbcd2b4719e419d99908063c05e1', 'pipeline': '19bdf19a2eec5febce95ab8fa2a71040d75114aa'}, 'duration': 1.5498578548431396, 'iteration': 6, 'loss': 0.14471329609998995, 'max_history_score': 0.85528670390001, 'max_history_score_std': 0.02213730791268438, 'max_history_step': 'joint', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 4, 'features__selectkbest__k': 3}), 'normalizer': ('normalizer_NoneType', {}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 7})}, 'score': 0.85528670390001, ...}, 'history': [{'algorithm': {'bootstrap': False, 'criterion': 'entropy', 'max_depth': 1, 'max_features': 3, 'max_leaf_nodes': 3, 'min_samples_split': 5, 'n_estimators': 50}, 'config_hash': {'algorithm': '752fa095cdab58a238ae606c613606188964cc0c', 'config': 'fd24b065dda6bdeb1077793f9df480ff318c7a37', 'pipeline': '13ea3359c453b8993fcec1e88bc0e19cd0a2b112'}, 'duration': 0.689669132232666, 'iteration': 0, 'loss': 0.6602879519109309, 'max_history_score': 0.3397120480890691, 'max_history_score_std': 0.03346542949100545, 'max_history_step': 'joint', 'pipeline': {'features': ('features_SelectKBest', {'features__k': 4}), 'normalizer': ('normalizer_MinMaxScaler', {}), 'rebalance': ('rebalance_NoneType', {})}, 'score': 0.3397120480890691, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'gini', 'max_depth': 4, 'max_features': 1, 'max_leaf_nodes': 5, 'min_samples_split': 3, 'n_estimators': 25}, 'config_hash': {'algorithm': '9d9de4aee820052ddfe83bfffca420f6b50837d3', 'config': 'fb22f80fb4358ae1ee4c9bd4a83543992be8d806', 'pipeline': '6251ad4bb7a110726a67f90c319f4717ac37a312'}, 'duration': 1.4300940036773682, 'iteration': 1, 'loss': 0.5122196101741096, 'max_history_score': 0.48778038982589045, 'max_history_score_std': 0.05486079759217226, 'max_history_step': 'joint', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 2, 'features__selectkbest__k': 2}), 'normalizer': ('normalizer_StandardScaler', {'normalizer__with_mean': True, 'normalizer__with_std': True}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 5})}, 'score': 0.48778038982589045, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': 4, 'max_features': 1, 'max_leaf_nodes': None, 'min_samples_split': 2, 'n_estimators': 10}, 'config_hash': {'algorithm': '2ed7d27df9a1b2d5e63da76f7cb309616c232022', 'config': '8c97cdb885dd05cfd8c40ee3ac445b61e5c767a8', 'pipeline': 'c0abb5e23a4739d3120740a9519fb36c43eb94d5'}, 'duration': 3.0036678314208984, 'iteration': 2, 'loss': 0.38319264175312906, 'max_history_score': 0.6168073582468709, 'max_history_score_std': 0.05286679173001824, 'max_history_step': 'joint', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 1, 'features__selectkbest__k': 4}), 'normalizer': ('normalizer_PowerTransformer', {}), 'rebalance': ('rebalance_NearMiss', {'rebalance__n_neighbors': 2})}, 'score': 0.6168073582468709, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'entropy', 'max_depth': None, 'max_features': None, 'max_leaf_nodes': 2, 'min_samples_split': 2, 'n_estimators': 100}, 'config_hash': {'algorithm': '17962655e3b76dfcd0843d1e5c2cb7a9db1c6a79', 'config': '16fbb5fd5cfbbacfddf27c61c0c7397a7f6d8ade', 'pipeline': '13ea3359c453b8993fcec1e88bc0e19cd0a2b112'}, 'duration': 1.3447980880737305, 'iteration': 3, 'loss': 0.6768840987778313, 'max_history_score': 0.6168073582468709, 'max_history_score_std': 0.05286679173001824, 'max_history_step': 'joint', 'pipeline': {'features': ('features_SelectKBest', {'features__k': 4}), 'normalizer': ('normalizer_MinMaxScaler', {}), 'rebalance': ('rebalance_NoneType', {})}, 'score': 0.32311590122216866, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'gini', 'max_depth': 2, 'max_features': 2, 'max_leaf_nodes': 2, 'min_samples_split': 3, 'n_estimators': 100}, 'config_hash': {'algorithm': '1ea8965b2247f86950e54510ee6d79399816341b', 'config': 'a77c698197c31308211b854e81a998178941f87d', 'pipeline': 'aaf976c7c663a31fa039582d42f9e07101556a7c'}, 'duration': 2.589430093765259, 'iteration': 4, 'loss': 0.2544808950572157, 'max_history_score': 0.7455191049427843, 'max_history_score_std': 0.04843448308166839, 'max_history_step': 'joint', 'pipeline': {'features': ('features_NoneType', {}), 'normalizer': ('normalizer_PowerTransformer', {}), 'rebalance': ('rebalance_NoneType', {})}, 'score': 0.7455191049427843, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': None, 'max_features': 2, 'max_leaf_nodes': 5, 'min_samples_split': 5, 'n_estimators': 25}, 'config_hash': {'algorithm': 'fd8aeb6a05eaaba41e676d60596c8e0c71b35e0c', 'config': '1fc13606bca3aaf342ca6ea21139cb598b56f8db', 'pipeline': 'f00bd8de05642e026bbba4ad20d3a60088c86b6c'}, 'duration': 1.8779079914093018, 'iteration': 5, 'loss': 0.531551018758381, 'max_history_score': 0.7455191049427843, 'max_history_score_std': 0.04843448308166839, 'max_history_step': 'joint', 'pipeline': {'features': ('features_PCA', {'features__n_components': 2}), 'normalizer': ('normalizer_MinMaxScaler', {}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 5})}, 'score': 0.46844898124161904, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'entropy', 'max_depth': None, 'max_features': 2, 'max_leaf_nodes': None, 'min_samples_split': 2, 'n_estimators': 10}, 'config_hash': {'algorithm': 'a49ecb99e74217d6812f98ead7bc9d1fe4a53ba0', 'config': '6749af1a67b4dbcd2b4719e419d99908063c05e1', 'pipeline': '19bdf19a2eec5febce95ab8fa2a71040d75114aa'}, 'duration': 1.5498578548431396, 'iteration': 6, 'loss': 0.14471329609998995, 'max_history_score': 0.85528670390001, 'max_history_score_std': 0.02213730791268438, 'max_history_step': 'joint', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 4, 'features__selectkbest__k': 3}), 'normalizer': ('normalizer_NoneType', {}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 7})}, 'score': 0.85528670390001, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': 1, 'max_features': 3, 'max_leaf_nodes': 3, 'min_samples_split': 3, 'n_estimators': 75}, 'config_hash': {'algorithm': 'ebfb16234172ae811ff21185ff92bbdbb8f32f14', 'config': 'd92d4ada2394fc132733e176e926ee53acdc6a00', 'pipeline': '8071e7cbf86a5c3056493dc3aa40063aeb28cdfe'}, 'duration': 1.3618149757385254, 'iteration': 7, 'loss': 0.6158612049395463, 'max_history_score': 0.85528670390001, 'max_history_score_std': 0.02213730791268438, 'max_history_step': 'joint', 'pipeline': {'features': ('features_SelectKBest', {'features__k': 4}), 'normalizer': ('normalizer_StandardScaler', {'normalizer__with_mean': True, 'normalizer__with_std': True}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 5})}, 'score': 0.3841387950604537, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'entropy', 'max_depth': 1, 'max_features': 1, 'max_leaf_nodes': 5, 'min_samples_split': 2, 'n_estimators': 100}, 'config_hash': {'algorithm': '896b53c75a2db568fb7b6da3bfca2f7a1535a11b', 'config': 'f0d0b1d2cedc22ae15d9a208a3fc3fc133bf0d3d', 'pipeline': 'c9761c9a33bf75d6dcad0742c421548a7655ccc9'}, 'duration': 2.297278881072998, 'iteration': 8, 'loss': 0.40673663548410355, 'max_history_score': 0.85528670390001, 'max_history_score_std': 0.02213730791268438, 'max_history_step': 'joint', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 2, 'features__selectkbest__k': 4}), 'normalizer': ('normalizer_StandardScaler', {'normalizer__with_mean': False, 'normalizer__with_std': False}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 5})}, 'score': 0.5932633645158965, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'entropy', 'max_depth': 2, 'max_features': None, 'max_leaf_nodes': None, 'min_samples_split': 5, 'n_estimators': 25}, 'config_hash': {'algorithm': '0b0e954757c4f75343a6efb740ad93260ed781ae', 'config': '47584de0e60d0d12c7dbbf0dc60e5aea96e3f4b2', 'pipeline': 'b37ee32d59413053bf9a2a72c8ff7135f3701e05'}, 'duration': 0.7249000072479248, 'iteration': 9, 'loss': 0.6965910020393421, 'max_history_score': 0.85528670390001, 'max_history_score_std': 0.02213730791268438, 'max_history_step': 'joint', 'pipeline': {'features': ('features_SelectKBest', {'features__k': 3}), 'normalizer': ('normalizer_NoneType', {}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 7})}, 'score': 0.3034089979606579, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'gini', 'max_depth': 2, 'max_features': 2, 'max_leaf_nodes': 5, 'min_samples_split': 5, 'n_estimators': 75}, 'config_hash': {'algorithm': 'f1ead1d9e33ea927e1dd27d872a058fa3de4f832', 'config': 'eecb88ee2b1b95d741c1b5c7751534d31aae6a77', 'pipeline': '6746650871e8b61efc9302b092dc05f7cdb179d5'}, 'duration': 5.340634822845459, 'iteration': 10, 'loss': 0.7687016290977936, 'max_history_score': 0.85528670390001, 'max_history_score_std': 0.02213730791268438, 'max_history_step': 'joint', 'pipeline': {'features': ('features_SelectKBest', {'features__k': 3}), 'normalizer': ('normalizer_RobustScaler', {'normalizer__quantile_range': (...), 'normalizer__with_centering': False, 'normalizer__with_scaling': False}), 'rebalance': ('rebalance_CondensedNearestNeighbour', {'rebalance__n_neighbors': 1})}, 'score': 0.23129837090220637, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': 1, 'max_features': 2, 'max_leaf_nodes': 2, 'min_samples_split': 3, 'n_estimators': 75}, 'config_hash': {'algorithm': '531a3bb8ccf0baa06727af4b3de9e62d25e6eabf', 'config': '27a7ed0502b321ab7256b77c8ce79e90cb9da815', 'pipeline': '77e6d84e2217b92b3cf67cc6defef9dd3554cec0'}, 'duration': 1.775357961654663, 'iteration': 11, 'loss': 0.6313818737375694, 'max_history_score': 0.85528670390001, 'max_history_score_std': 0.02213730791268438, 'max_history_step': 'joint', 'pipeline': {'features': ('features_SelectKBest', {'features__k': 4}), 'normalizer': ('normalizer_MinMaxScaler', {}), 'rebalance': ('rebalance_NearMiss', {'rebalance__n_neighbors': 3})}, 'score': 0.3686181262624307, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'entropy', 'max_depth': 4, 'max_features': 3, 'max_leaf_nodes': 2, 'min_samples_split': 3, 'n_estimators': 10}, 'config_hash': {'algorithm': '93518f8ded6074d537900b26be72f8485782f933', 'config': '45f056102dd2d644bd8befa471f17b2311ac7954', 'pipeline': '5240329df25c9a533d025c1a401d49835a501b41'}, 'duration': 3.2622711658477783, 'iteration': 12, 'loss': 0.6120243191353301, 'max_history_score': 0.85528670390001, 'max_history_score_std': 0.02213730791268438, 'max_history_step': 'joint', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 4, 'features__selectkbest__k': 2}), 'normalizer': ('normalizer_PowerTransformer', {}), 'rebalance': ('rebalance_NearMiss', {'rebalance__n_neighbors': 1})}, 'score': 0.38797568086467, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'entropy', 'max_depth': None, 'max_features': 1, 'max_leaf_nodes': 5, 'min_samples_split': 3, 'n_estimators': 75}, 'config_hash': {'algorithm': 'e515d45b764fa43591032874a0ff9c25bf12fddd', 'config': 'ba108323623936872824ed8f1c41d615d25523b3', 'pipeline': '9d823bc0442f21b5ce8af67a5eb1237f64ffc2f8'}, 'duration': 2.5326571464538574, 'iteration': 13, 'loss': 0.6271427382991047, 'max_history_score': 0.85528670390001, 'max_history_score_std': 0.02213730791268438, 'max_history_step': 'joint', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 1, 'features__selectkbest__k': 1}), 'normalizer': ('normalizer_StandardScaler', {'normalizer__with_mean': True, 'normalizer__with_std': True}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 5})}, 'score': 0.3728572617008953, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'entropy', 'max_depth': 3, 'max_features': 2, 'max_leaf_nodes': 2, 'min_samples_split': 3, 'n_estimators': 25}, 'config_hash': {'algorithm': '2808e67f609eba5c8a97f81ac0c9413cd37cf7aa', 'config': 'dde4d3b5f37741629cb58bfc4051ed9f98c8f311', 'pipeline': 'bc52deabf1f5ee60968ba541d9d2574353c30a9c'}, 'duration': 0.7145559787750244, 'iteration': 14, 'loss': 0.6831045572696203, 'max_history_score': 0.85528670390001, 'max_history_score_std': 0.02213730791268438, 'max_history_step': 'joint', 'pipeline': {'features': ('features_SelectKBest', {'features__k': 3}), 'normalizer': ('normalizer_MinMaxScaler', {}), 'rebalance': ('rebalance_NearMiss', {'rebalance__n_neighbors': 1})}, 'score': 0.31689544273037973, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'gini', 'max_depth': 2, 'max_features': 2, 'max_leaf_nodes': None, 'min_samples_split': 5, 'n_estimators': 100}, 'config_hash': {'algorithm': 'b942acdead762d34afeb474bc2fe6f7fd0f23493', 'config': '1080c25b92da3f15a6f8eec003957f7e0a66324f', 'pipeline': 'cfa84fe703dc5bc0bbd2257a6d524fee2693b804'}, 'duration': 2.812459945678711, 'iteration': 15, 'loss': 0.6921421091202761, 'max_history_score': 0.85528670390001, 'max_history_score_std': 0.02213730791268438, 'max_history_step': 'joint', 'pipeline': {'features': ('features_SelectKBest', {'features__k': 2}), 'normalizer': ('normalizer_PowerTransformer', {}), 'rebalance': ('rebalance_NoneType', {})}, 'score': 0.3078578908797239, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'entropy', 'max_depth': 2, 'max_features': 3, 'max_leaf_nodes': 3, 'min_samples_split': 2, 'n_estimators': 75}, 'config_hash': {'algorithm': '250661ce4193a61ef44d2f77694b52b785ff032d', 'config': 'c3e8cf4eca5aafcae4ac31b0449e105ca127ffe2', 'pipeline': 'c4dd111513ea35f97dd3aec3e8e7f6268ce035da'}, 'duration': 1.0555319786071777, 'iteration': 16, 'loss': 1.0, 'max_history_score': 0.85528670390001, 'max_history_score_std': 0.02213730791268438, 'max_history_step': 'joint', 'pipeline': {'features': ('features_PCA', {'features__n_components': 2}), 'normalizer': ('normalizer_RobustScaler', {'normalizer__quantile_range': (...), 'normalizer__with_centering': False, 'normalizer__with_scaling': True}), 'rebalance': ('rebalance_NearMiss', {'rebalance__n_neighbors': 2})}, 'score': 0.0, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'entropy', 'max_depth': 3, 'max_features': 3, 'max_leaf_nodes': None, 'min_samples_split': 3, 'n_estimators': 25}, 'config_hash': {'algorithm': '05ac02bd045c65dc4089894902ad6253661a2692', 'config': '3449b4a1c2e488e26a7195ee9edca19b854ebd33', 'pipeline': '505d3f71b534917375d765e64b0611e7dfb83746'}, 'duration': 5.5412821769714355, 'iteration': 17, 'loss': 0.7289151155121668, 'max_history_score': 0.85528670390001, 'max_history_score_std': 0.02213730791268438, 'max_history_step': 'joint', 'pipeline': {'features': ('features_SelectKBest', {'features__k': 4}), 'normalizer': ('normalizer_MinMaxScaler', {}), 'rebalance': ('rebalance_CondensedNearestNeighbour', {'rebalance__n_neighbors': 2})}, 'score': 0.2710848844878332, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'entropy', 'max_depth': 2, 'max_features': None, 'max_leaf_nodes': None, 'min_samples_split': 2, 'n_estimators': 25}, 'config_hash': {'algorithm': 'de3b3a352ebb260e16c6b213a08c9144d17a744b', 'config': '224987ffdbbb9b6182cff18d8374518b917e4f2e', 'pipeline': '12c89200a558b2f3b91332566f41050143aecbe7'}, 'duration': 2.4646048545837402, 'iteration': 18, 'loss': 0.6545902512995826, 'max_history_score': 0.85528670390001, 'max_history_score_std': 0.02213730791268438, 'max_history_step': 'joint', 'pipeline': {'features': ('features_NoneType', {}), 'normalizer': ('normalizer_PowerTransformer', {}), 'rebalance': ('rebalance_NearMiss', {'rebalance__n_neighbors': 2})}, 'score': 0.3454097487004174, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'gini', 'max_depth': None, 'max_features': 1, 'max_leaf_nodes': None, 'min_samples_split': 3, 'n_estimators': 100}, 'config_hash': {'algorithm': '30ca111584767bbf0464df40b4c928cf7ddf9459', 'config': '97ca7d6a017c721084dec2a5d2e5a67e1e6ae2f0', 'pipeline': '789eca82ea4a42d61927670c538867b745fd81d3'}, 'duration': 7.164499044418335, 'iteration': 19, 'loss': 0.6536825403350528, 'max_history_score': 0.85528670390001, 'max_history_score_std': 0.02213730791268438, 'max_history_step': 'joint', 'pipeline': {'features': ('features_SelectKBest', {'features__k': 3}), 'normalizer': ('normalizer_RobustScaler', {'normalizer__quantile_range': (...), 'normalizer__with_centering': False, 'normalizer__with_scaling': True}), 'rebalance': ('rebalance_CondensedNearestNeighbour', {'rebalance__n_neighbors': 3})}, 'score': 0.3463174596649472, ...}, ...], 'history_hash': ['fd24b065dda6bdeb1077793f9df480ff318c7a37', 'fb22f80fb4358ae1ee4c9bd4a83543992be8d806', '8c97cdb885dd05cfd8c40ee3ac445b61e5c767a8', '16fbb5fd5cfbbacfddf27c61c0c7397a7f6d8ade', 'a77c698197c31308211b854e81a998178941f87d', '1fc13606bca3aaf342ca6ea21139cb598b56f8db', '6749af1a67b4dbcd2b4719e419d99908063c05e1', 'd92d4ada2394fc132733e176e926ee53acdc6a00', 'f0d0b1d2cedc22ae15d9a208a3fc3fc133bf0d3d', '47584de0e60d0d12c7dbbf0dc60e5aea96e3f4b2', 'eecb88ee2b1b95d741c1b5c7751534d31aae6a77', '27a7ed0502b321ab7256b77c8ce79e90cb9da815', '45f056102dd2d644bd8befa471f17b2311ac7954', 'ba108323623936872824ed8f1c41d615d25523b3', 'dde4d3b5f37741629cb58bfc4051ed9f98c8f311', '1080c25b92da3f15a6f8eec003957f7e0a66324f', 'c3e8cf4eca5aafcae4ac31b0449e105ca127ffe2', '3449b4a1c2e488e26a7195ee9edca19b854ebd33', '224987ffdbbb9b6182cff18d8374518b917e4f2e', '97ca7d6a017c721084dec2a5d2e5a67e1e6ae2f0', ...], 'history_index': {'1080c25b92da3f15a6f8eec003957f7e0a66324f': 15, '16fbb5fd5cfbbacfddf27c61c0c7397a7f6d8ade': 3, '1fc13606bca3aaf342ca6ea21139cb598b56f8db': 5, '2187b0ebdd42d61eb93839b9a1592ae8707ce4c5': 42, '224987ffdbbb9b6182cff18d8374518b917e4f2e': 18, '235f12fbdc7e6cff792ad0da8c8430ce2e5b9cc6': 46, '27a7ed0502b321ab7256b77c8ce79e90cb9da815': 11, '300257dd230eb5db40e499b05582132bb87f574b': 35, '3449b4a1c2e488e26a7195ee9edca19b854ebd33': 17, '3567266057a9169d1e19b5468ae8b24572886e03': 23, ...}, 'iteration': 46, 'max_history_score': 0.85528670390001, 'max_history_score_std': 0.02213730791268438, 'max_history_step': 'joint'}, config={'algorithm': 'RandomForest', 'seed': 42, 'time': 300}, step='joint')
     45                 y,
     46                 cv=10,
     47                 n_jobs=-1,
     48                 return_estimator=False,
     49                 return_train_score=False,
---> 50                 verbose=0)
     51         score = np.mean(scores['test_score'])
     52         std = np.std(scores['test_score'])
     53         status = STATUS_OK
     54     except Exception as e:

...........................................................................
/home/aquemy/.local/lib/python2.7/site-packages/sklearn/model_selection/_validation.py in cross_validate(estimator=Pipeline(memory=None,
     steps=[('rebalance', ... random_state=42, verbose=0, warm_start=False))]), X=array([[ 0.,  0.,  5., ...,  0.,  0.,  0.],
    ...0.],
       [ 0.,  0., 10., ..., 12.,  1.,  0.]]), y=array([0, 1, 2, ..., 8, 9, 8]), groups=None, scoring=None, cv=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1, verbose=0, fit_params=None, pre_dispatch='2*n_jobs', return_train_score=False, return_estimator=False, error_score='raise-deprecating')
    235         delayed(_fit_and_score)(
    236             clone(estimator), X, y, scorers, train, test, verbose, None,
    237             fit_params, return_train_score=return_train_score,
    238             return_times=True, return_estimator=return_estimator,
    239             error_score=error_score)
--> 240         for train, test in cv.split(X, y, groups))
        cv.split = <bound method StratifiedKFold.split of Stratifie...d(n_splits=10, random_state=None, shuffle=False)>
        X = array([[ 0.,  0.,  5., ...,  0.,  0.,  0.],
    ...0.],
       [ 0.,  0., 10., ..., 12.,  1.,  0.]])
        y = array([0, 1, 2, ..., 8, 9, 8])
        groups = None
    241 
    242     zipped_scores = list(zip(*scores))
    243     if return_train_score:
    244         train_scores = zipped_scores.pop(0)

...........................................................................
/home/aquemy/.local/lib/python2.7/site-packages/sklearn/externals/joblib/parallel.py in __call__(self=Parallel(n_jobs=-1), iterable=<generator object <genexpr>>)
    925                 # No need to wait for async callbacks to trigger to
    926                 # consumption.
    927                 self._iterating = False
    928 
    929             with self._backend.retrieval_context():
--> 930                 self.retrieve()
        self.retrieve = <bound method Parallel.retrieve of Parallel(n_jobs=-1)>
    931             # Make sure that we get a last message telling us we are done
    932             elapsed_time = time.time() - self._start_time
    933             self._print('Done %3i out of %3i | elapsed: %s finished',
    934                         (len(self._output), len(self._output),

---------------------------------------------------------------------------
Joblib worker traceback:
---------------------------------------------------------------------------
ValueError                                         Mon Jun 17 13:07:16 2019
PID: 20177                                  Python 2.7.15+: /usr/bin/python
...........................................................................
/home/aquemy/.local/lib/python2.7/site-packages/sklearn/externals/joblib/parallel.py in __call__(self=<sklearn.externals.joblib.parallel.BatchedCalls object>)
    220     def __call__(self):
    221         # Set the default nested backend to self._backend but do not set the
    222         # change the default number of processes to -1
    223         with parallel_backend(self._backend, n_jobs=self._n_jobs):
    224             return [func(*args, **kwargs)
--> 225                     for func, args, kwargs in self.items]
        func = <function _fit_and_score>
        args = (Pipeline(memory=None,
     steps=[('rebalance', ... random_state=42, verbose=0, warm_start=False))]), array([[ 0.,  0.,  5., ...,  0.,  0.,  0.],
    ...0.],
       [ 0.,  0., 10., ..., 12.,  1.,  0.]]), array([0, 1, 2, ..., 8, 9, 8]), {'score': <function _passthrough_scorer>}, array([ 169,  176,  178, ..., 1794, 1795, 1796]), array([  0,   1,   2,   3,   4,   5,   6,   7,  ..., 181, 186, 188, 189, 190,
       194, 195, 198]), 0, None, None)
        kwargs = {'error_score': 'raise-deprecating', 'return_estimator': False, 'return_times': True, 'return_train_score': False}
        self.items = [(<function _fit_and_score>, (Pipeline(memory=None,
     steps=[('rebalance', ... random_state=42, verbose=0, warm_start=False))]), array([[ 0.,  0.,  5., ...,  0.,  0.,  0.],
    ...0.],
       [ 0.,  0., 10., ..., 12.,  1.,  0.]]), array([0, 1, 2, ..., 8, 9, 8]), {'score': <function _passthrough_scorer>}, array([ 169,  176,  178, ..., 1794, 1795, 1796]), array([  0,   1,   2,   3,   4,   5,   6,   7,  ..., 181, 186, 188, 189, 190,
       194, 195, 198]), 0, None, None), {'error_score': 'raise-deprecating', 'return_estimator': False, 'return_times': True, 'return_train_score': False})]
    226 
    227     def __len__(self):
    228         return self._size
    229 

...........................................................................
/home/aquemy/.local/lib/python2.7/site-packages/sklearn/model_selection/_validation.py in _fit_and_score(estimator=Pipeline(memory=None,
     steps=[('rebalance', ... random_state=42, verbose=0, warm_start=False))]), X=array([[ 0.,  0.,  5., ...,  0.,  0.,  0.],
    ...0.],
       [ 0.,  0., 10., ..., 12.,  1.,  0.]]), y=array([0, 1, 2, ..., 8, 9, 8]), scorer={'score': <function _passthrough_scorer>}, train=array([ 169,  176,  178, ..., 1794, 1795, 1796]), test=array([  0,   1,   2,   3,   4,   5,   6,   7,  ..., 181, 186, 188, 189, 190,
       194, 195, 198]), verbose=0, parameters=None, fit_params={}, return_train_score=False, return_parameters=False, return_n_test_samples=False, return_times=True, return_estimator=False, error_score='raise-deprecating')
    523 
    524     try:
    525         if y_train is None:
    526             estimator.fit(X_train, **fit_params)
    527         else:
--> 528             estimator.fit(X_train, y_train, **fit_params)
        estimator.fit = <bound method Pipeline.fit of Pipeline(memory=No...random_state=42, verbose=0, warm_start=False))])>
        X_train = array([[ 0.,  0.,  6., ...,  9.,  4.,  0.],
    ...0.],
       [ 0.,  0., 10., ..., 12.,  1.,  0.]])
        y_train = array([9, 5, 0, ..., 8, 9, 8])
        fit_params = {}
    529 
    530     except Exception as e:
    531         # Note fit time as time until error
    532         fit_time = time.time() - start_time

...........................................................................
/usr/local/lib/python2.7/dist-packages/imblearn/pipeline.py in fit(self=Pipeline(memory=None,
     steps=[('rebalance', ... random_state=42, verbose=0, warm_start=False))]), X=array([[ 0.,  0.,  6., ...,  9.,  4.,  0.],
    ...0.],
       [ 0.,  0., 10., ..., 12.,  1.,  0.]]), y=array([9, 5, 0, ..., 8, 9, 8]), **fit_params={})
    234             This estimator
    235 
    236         """
    237         Xt, yt, fit_params = self._fit(X, y, **fit_params)
    238         if self._final_estimator is not None:
--> 239             self._final_estimator.fit(Xt, yt, **fit_params)
        self._final_estimator.fit = <bound method RandomForestClassifier.fit of Rand...e, random_state=42, verbose=0, warm_start=False)>
        Xt = array([[0.88888889],
       [0.66666667],
      ...    ],
       [0.        ],
       [0.88888889]])
        yt = array([0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,... 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9])
        fit_params = {}
    240         return self
    241 
    242     def fit_transform(self, X, y=None, **fit_params):
    243         """Fit the model and transform with the final estimator

...........................................................................
/home/aquemy/.local/lib/python2.7/site-packages/sklearn/ensemble/forest.py in fit(self=RandomForestClassifier(bootstrap=True, class_wei...se, random_state=42, verbose=0, warm_start=False), X=array([[0.8888889 ],
       [0.6666667 ],
      ...0.        ],
       [0.8888889 ]], dtype=float32), y=array([[0.],
       [0.],
       [1.],
       [1...    [9.],
       [9.],
       [9.],
       [9.]]), sample_weight=None)
    328             trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,
    329                              **_joblib_parallel_args(prefer='threads'))(
    330                 delayed(_parallel_build_trees)(
    331                     t, self, X, y, sample_weight, i, len(trees),
    332                     verbose=self.verbose, class_weight=self.class_weight)
--> 333                 for i, t in enumerate(trees))
        i = 99
    334 
    335             # Collect newly grown trees
    336             self.estimators_.extend(trees)
    337 

...........................................................................
/home/aquemy/.local/lib/python2.7/site-packages/sklearn/externals/joblib/parallel.py in __call__(self=Parallel(n_jobs=1), iterable=<generator object <genexpr>>)
    912             # self._original_iterator is None, then this means either
    913             # that pre_dispatch == "all", n_jobs == 1 or that the first batch
    914             # was very quick and its callback already dispatched all the
    915             # remaining jobs.
    916             self._iterating = False
--> 917             if self.dispatch_one_batch(iterator):
        self.dispatch_one_batch = <bound method Parallel.dispatch_one_batch of Parallel(n_jobs=1)>
        iterator = <generator object <genexpr>>
    918                 self._iterating = self._original_iterator is not None
    919 
    920             while self.dispatch_one_batch(iterator):
    921                 pass

...........................................................................
/home/aquemy/.local/lib/python2.7/site-packages/sklearn/externals/joblib/parallel.py in dispatch_one_batch(self=Parallel(n_jobs=1), iterator=<generator object <genexpr>>)
    754                                  self._pickle_cache)
    755             if len(tasks) == 0:
    756                 # No more tasks available in the iterator: tell caller to stop.
    757                 return False
    758             else:
--> 759                 self._dispatch(tasks)
        self._dispatch = <bound method Parallel._dispatch of Parallel(n_jobs=1)>
        tasks = <sklearn.externals.joblib.parallel.BatchedCalls object>
    760                 return True
    761 
    762     def _print(self, msg, msg_args):
    763         """Display the message on stout or stderr depending on verbosity"""

...........................................................................
/home/aquemy/.local/lib/python2.7/site-packages/sklearn/externals/joblib/parallel.py in _dispatch(self=Parallel(n_jobs=1), batch=<sklearn.externals.joblib.parallel.BatchedCalls object>)
    711 
    712         dispatch_timestamp = time.time()
    713         cb = BatchCompletionCallBack(dispatch_timestamp, len(batch), self)
    714         with self._lock:
    715             job_idx = len(self._jobs)
--> 716             job = self._backend.apply_async(batch, callback=cb)
        job = undefined
        self._backend.apply_async = <bound method SequentialBackend.apply_async of <...lib._parallel_backends.SequentialBackend object>>
        batch = <sklearn.externals.joblib.parallel.BatchedCalls object>
        cb = <sklearn.externals.joblib.parallel.BatchCompletionCallBack object>
    717             # A job can complete so quickly than its callback is
    718             # called before we get here, causing self._jobs to
    719             # grow. To ensure correct results ordering, .insert is
    720             # used (rather than .append) in the following line

...........................................................................
/home/aquemy/.local/lib/python2.7/site-packages/sklearn/externals/joblib/_parallel_backends.py in apply_async(self=<sklearn.externals.joblib._parallel_backends.SequentialBackend object>, func=<sklearn.externals.joblib.parallel.BatchedCalls object>, callback=<sklearn.externals.joblib.parallel.BatchCompletionCallBack object>)
    177             raise ValueError('n_jobs == 0 in Parallel has no meaning')
    178         return 1
    179 
    180     def apply_async(self, func, callback=None):
    181         """Schedule a func to be run"""
--> 182         result = ImmediateResult(func)
        result = undefined
        func = <sklearn.externals.joblib.parallel.BatchedCalls object>
    183         if callback:
    184             callback(result)
    185         return result
    186 

...........................................................................
/home/aquemy/.local/lib/python2.7/site-packages/sklearn/externals/joblib/_parallel_backends.py in __init__(self=<sklearn.externals.joblib._parallel_backends.ImmediateResult object>, batch=<sklearn.externals.joblib.parallel.BatchedCalls object>)
    544 
    545 class ImmediateResult(object):
    546     def __init__(self, batch):
    547         # Don't delay the application, to avoid keeping the input
    548         # arguments in memory
--> 549         self.results = batch()
        self.results = undefined
        batch = <sklearn.externals.joblib.parallel.BatchedCalls object>
    550 
    551     def get(self):
    552         return self.results
    553 

...........................................................................
/home/aquemy/.local/lib/python2.7/site-packages/sklearn/externals/joblib/parallel.py in __call__(self=<sklearn.externals.joblib.parallel.BatchedCalls object>)
    220     def __call__(self):
    221         # Set the default nested backend to self._backend but do not set the
    222         # change the default number of processes to -1
    223         with parallel_backend(self._backend, n_jobs=self._n_jobs):
    224             return [func(*args, **kwargs)
--> 225                     for func, args, kwargs in self.items]
        func = <function _parallel_build_trees>
        args = (DecisionTreeClassifier(class_weight=None, criter...=False, random_state=1608637542, splitter='best'), RandomForestClassifier(bootstrap=True, class_wei...se, random_state=42, verbose=0, warm_start=False), array([[0.8888889 ],
       [0.6666667 ],
      ...0.        ],
       [0.8888889 ]], dtype=float32), array([[0.],
       [0.],
       [1.],
       [1...    [9.],
       [9.],
       [9.],
       [9.]]), None, 0, 100)
        kwargs = {'class_weight': None, 'verbose': 0}
        self.items = [(<function _parallel_build_trees>, (DecisionTreeClassifier(class_weight=None, criter...=False, random_state=1608637542, splitter='best'), RandomForestClassifier(bootstrap=True, class_wei...se, random_state=42, verbose=0, warm_start=False), array([[0.8888889 ],
       [0.6666667 ],
      ...0.        ],
       [0.8888889 ]], dtype=float32), array([[0.],
       [0.],
       [1.],
       [1...    [9.],
       [9.],
       [9.],
       [9.]]), None, 0, 100), {'class_weight': None, 'verbose': 0})]
    226 
    227     def __len__(self):
    228         return self._size
    229 

...........................................................................
/home/aquemy/.local/lib/python2.7/site-packages/sklearn/ensemble/forest.py in _parallel_build_trees(tree=DecisionTreeClassifier(class_weight=None, criter...=False, random_state=1608637542, splitter='best'), forest=RandomForestClassifier(bootstrap=True, class_wei...se, random_state=42, verbose=0, warm_start=False), X=array([[0.8888889 ],
       [0.6666667 ],
      ...0.        ],
       [0.8888889 ]], dtype=float32), y=array([[0.],
       [0.],
       [1.],
       [1...    [9.],
       [9.],
       [9.],
       [9.]]), sample_weight=None, tree_idx=0, n_trees=100, verbose=0, class_weight=None)
    114                 simplefilter('ignore', DeprecationWarning)
    115                 curr_sample_weight *= compute_sample_weight('auto', y, indices)
    116         elif class_weight == 'balanced_subsample':
    117             curr_sample_weight *= compute_sample_weight('balanced', y, indices)
    118 
--> 119         tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)
        tree.fit = <bound method DecisionTreeClassifier.fit of Deci...False, random_state=1608637542, splitter='best')>
        X = array([[0.8888889 ],
       [0.6666667 ],
      ...0.        ],
       [0.8888889 ]], dtype=float32)
        y = array([[0.],
       [0.],
       [1.],
       [1...    [9.],
       [9.],
       [9.],
       [9.]])
        sample_weight = None
        curr_sample_weight = array([4., 5., 1., 1., 2., 1., 1., 1., 2., 1., 0..., 1., 3., 0., 2., 0., 0., 1.,
       1., 4., 1.])
    120     else:
    121         tree.fit(X, y, sample_weight=sample_weight, check_input=False)
    122 
    123     return tree

...........................................................................
/home/aquemy/.local/lib/python2.7/site-packages/sklearn/tree/tree.py in fit(self=DecisionTreeClassifier(class_weight=None, criter...=False, random_state=1608637542, splitter='best'), X=array([[0.8888889 ],
       [0.6666667 ],
      ...0.        ],
       [0.8888889 ]], dtype=float32), y=array([[0.],
       [0.],
       [1.],
       [1...    [9.],
       [9.],
       [9.],
       [9.]]), sample_weight=array([4., 5., 1., 1., 2., 1., 1., 1., 2., 1., 0..., 1., 3., 0., 2., 0., 0., 1.,
       1., 4., 1.]), check_input=False, X_idx_sorted=None)
    796 
    797         super(DecisionTreeClassifier, self).fit(
    798             X, y,
    799             sample_weight=sample_weight,
    800             check_input=check_input,
--> 801             X_idx_sorted=X_idx_sorted)
        X_idx_sorted = None
    802         return self
    803 
    804     def predict_proba(self, X, check_input=True):
    805         """Predict class probabilities of the input samples X.

...........................................................................
/home/aquemy/.local/lib/python2.7/site-packages/sklearn/tree/tree.py in fit(self=DecisionTreeClassifier(class_weight=None, criter...=False, random_state=1608637542, splitter='best'), X=array([[0.8888889 ],
       [0.6666667 ],
      ...0.        ],
       [0.8888889 ]], dtype=float32), y=array([[0.],
       [0.],
       [1.],
       [1...    [9.],
       [9.],
       [9.],
       [9.]]), sample_weight=array([4., 5., 1., 1., 2., 1., 1., 1., 2., 1., 0..., 1., 3., 0., 2., 0., 0., 1.,
       1., 4., 1.]), check_input=False, X_idx_sorted=None)
    237         if not 0 <= self.min_weight_fraction_leaf <= 0.5:
    238             raise ValueError("min_weight_fraction_leaf must in [0, 0.5]")
    239         if max_depth <= 0:
    240             raise ValueError("max_depth must be greater than zero. ")
    241         if not (0 < max_features <= self.n_features_):
--> 242             raise ValueError("max_features must be in (0, n_features]")
    243         if not isinstance(max_leaf_nodes, (numbers.Integral, np.integer)):
    244             raise ValueError("max_leaf_nodes must be integral number but was "
    245                              "%r" % max_leaf_nodes)
    246         if -1 < max_leaf_nodes < 2:

ValueError: max_features must be in (0, n_features]
___________________________________________________________________________
Best score: 0.8552867039 (0.0221373079127) [J] | Score: 0.0 (0.0) [J]
Best score: 0.8552867039 (0.0221373079127) [J] | Score: 0.74236692358 (0.0756612859154) [J]
Best score: 0.8552867039 (0.0221373079127) [J] | Score: 0.78961797289 (0.0581102815501) [J]
Best score: 0.8552867039 (0.0221373079127) [J] | Score: 0.329017608013 (0.031667142508) [J]
Best score: 0.8552867039 (0.0221373079127) [J] | Score: 0.104426060696 (0.0166420679305) [J]
Best score: 0.8552867039 (0.0221373079127) [J] | Score: 0.81680454001 (0.0607857535005) [J]
Best score: 0.8552867039 (0.0221373079127) [J] | Score: 0.656426806921 (0.0389557040457) [J]
Best score: 0.8552867039 (0.0221373079127) [J] | Score: 0.261146299453 (0.0213070495911) [J]
Best score: 0.8552867039 (0.0221373079127) [J] | Score: 0.806847301373 (0.0674576970358) [J]
Best score: 0.8552867039 (0.0221373079127) [J] | Score: 0.447375476834 (0.0587622946181) [J]
Best score: 0.8552867039 (0.0221373079127) [J] | Score: 0.628709695054 (0.056545622167) [J]
Best score: 0.8552867039 (0.0221373079127) [J] | Score: 0.318417141387 (0.0411908170484) [J]
Best score: 0.8552867039 (0.0221373079127) [J] | Score: 0.579295980172 (0.0494258286706) [J]
Best score: 0.8552867039 (0.0221373079127) [J] | Score: 0.724593532808 (0.0426175048819) [J]
Best score: 0.8552867039 (0.0221373079127) [J] | Score: 0.155817616495 (0.0191924643299) [J]
Best score: 0.8552867039 (0.0221373079127) [J] | Score: 0.572875813001 (0.0575839928113) [J]
Best score: 0.8552867039 (0.0221373079127) [J] | Score: 0.648026523469 (0.0534759509274) [J]
JoblibValueError
___________________________________________________________________________
...........................................................................
/home/aquemy/dev/dp_hyperparameters/extension/main.py in <module>()
     27 
     28     serializer.serialize_results(scenario, policy)
     29 
     30 if __name__ == "__main__":
     31     args = cli.parse_args()
---> 32     main(args)

...........................................................................
/home/aquemy/dev/dp_hyperparameters/extension/main.py in main(args=Namespace(customize=[(['control', 'seed'], '42')...='./scenarios/rf_digits_joint.yaml', verbosity=0))
     21         test_size=0.4, 
     22         random_state=scenario['control']['seed']
     23     )
     24 
     25     policy = policies.initiate(scenario['setup']['policy'], config)
---> 26     policy.run(X,y)
        policy.run = <bound method Joint.run of <experiment.policies.joint.Joint object>>
        X = array([[ 0.,  0.,  5., ...,  0.,  0.,  0.],
    ...0.],
       [ 0.,  0., 10., ..., 12.,  1.,  0.]])
        y = array([0, 1, 2, ..., 8, 9, 8])
     27 
     28     serializer.serialize_results(scenario, policy)
     29 
     30 if __name__ == "__main__":

...........................................................................
/home/aquemy/dev/dp_hyperparameters/extension/experiment/policies/joint.py in run(self=<experiment.policies.joint.Joint object>, X=array([[ 0.,  0.,  5., ...,  0.,  0.,  0.],
    ...0.],
       [ 0.,  0., 10., ..., 12.,  1.,  0.]]), y=array([0, 1, 2, ..., 8, 9, 8]))
     32             algo=tpe.suggest, 
     33             max_evals=None,
     34             max_time=self.config['time'],     
     35             trials=trials,
     36             show_progressbar=False,
---> 37             verbose=0
     38         )
     39 
     40         best_config = self.context['best_config']
     41         super(Joint, self).display_step_results(best_config)

...........................................................................
/home/aquemy/dev/dp_hyperparameters/extension/hyperopt/fmin.py in fmin(fn=<functools.partial object>, space={'algorithm': {'bootstrap': <hyperopt.pyll.base.Apply object>, 'criterion': <hyperopt.pyll.base.Apply object>, 'max_depth': <hyperopt.pyll.base.Apply object>, 'max_features': <hyperopt.pyll.base.Apply object>, 'max_leaf_nodes': <hyperopt.pyll.base.Apply object>, 'min_samples_split': <hyperopt.pyll.base.Apply object>, 'n_estimators': <hyperopt.pyll.base.Apply object>}, 'pipeline': {'features': <hyperopt.pyll.base.Apply object>, 'normalizer': <hyperopt.pyll.base.Apply object>, 'rebalance': <hyperopt.pyll.base.Apply object>}}, algo=<function suggest>, max_evals=9223372036854775807, max_time=300, trials=<hyperopt.base.Trials object>, rstate=<mtrand.RandomState object>, allow_trials_fmin=True, pass_expr_memo_ctrl=None, catch_eval_exceptions=False, verbose=0, return_argmin=True, points_to_evaluate=None, max_queue_len=1, show_progressbar=False)
    406             pass_expr_memo_ctrl=pass_expr_memo_ctrl,
    407             verbose=verbose,
    408             catch_eval_exceptions=catch_eval_exceptions,
    409             return_argmin=return_argmin,
    410             show_progressbar=show_progressbar,
--> 411             max_time=max_time
        max_time = 300
    412         )
    413 
    414     if trials is None:
    415         if points_to_evaluate is None:

...........................................................................
/home/aquemy/dev/dp_hyperparameters/extension/hyperopt/base.py in fmin(self=<hyperopt.base.Trials object>, fn=<functools.partial object>, space={'algorithm': {'bootstrap': <hyperopt.pyll.base.Apply object>, 'criterion': <hyperopt.pyll.base.Apply object>, 'max_depth': <hyperopt.pyll.base.Apply object>, 'max_features': <hyperopt.pyll.base.Apply object>, 'max_leaf_nodes': <hyperopt.pyll.base.Apply object>, 'min_samples_split': <hyperopt.pyll.base.Apply object>, 'n_estimators': <hyperopt.pyll.base.Apply object>}, 'pipeline': {'features': <hyperopt.pyll.base.Apply object>, 'normalizer': <hyperopt.pyll.base.Apply object>, 'rebalance': <hyperopt.pyll.base.Apply object>}}, algo=<function suggest>, max_evals=9223372036854775807, max_time=300, rstate=<mtrand.RandomState object>, verbose=0, pass_expr_memo_ctrl=None, catch_eval_exceptions=False, return_argmin=True, show_progressbar=False)
    636             verbose=verbose,
    637             allow_trials_fmin=False,  # -- prevent recursion
    638             pass_expr_memo_ctrl=pass_expr_memo_ctrl,
    639             catch_eval_exceptions=catch_eval_exceptions,
    640             return_argmin=return_argmin,
--> 641             show_progressbar=show_progressbar)
        show_progressbar = False
    642 
    643 
    644 def trials_from_docs(docs, validate=True, **kwargs):
    645     """Construct a Trials base class instance from a list of trials documents

...........................................................................
/home/aquemy/dev/dp_hyperparameters/extension/hyperopt/fmin.py in fmin(fn=<functools.partial object>, space={'algorithm': {'bootstrap': <hyperopt.pyll.base.Apply object>, 'criterion': <hyperopt.pyll.base.Apply object>, 'max_depth': <hyperopt.pyll.base.Apply object>, 'max_features': <hyperopt.pyll.base.Apply object>, 'max_leaf_nodes': <hyperopt.pyll.base.Apply object>, 'min_samples_split': <hyperopt.pyll.base.Apply object>, 'n_estimators': <hyperopt.pyll.base.Apply object>}, 'pipeline': {'features': <hyperopt.pyll.base.Apply object>, 'normalizer': <hyperopt.pyll.base.Apply object>, 'rebalance': <hyperopt.pyll.base.Apply object>}}, algo=<function suggest>, max_evals=9223372036854775807, max_time=300, trials=<hyperopt.base.Trials object>, rstate=<mtrand.RandomState object>, allow_trials_fmin=False, pass_expr_memo_ctrl=None, catch_eval_exceptions=False, verbose=0, return_argmin=True, points_to_evaluate=None, max_queue_len=1, show_progressbar=False)
    426                     verbose=verbose,
    427                     max_queue_len=max_queue_len,
    428                     show_progressbar=show_progressbar,
    429                     max_time=max_time)
    430     rval.catch_eval_exceptions = catch_eval_exceptions
--> 431     rval.exhaust()
        rval.exhaust = <bound method FMinIter.exhaust of <hyperopt.fmin.FMinIter object>>
    432     if return_argmin:
    433         return trials.argmin
    434     elif len(trials) > 0:
    435         # Only if there are some succesfull trail runs, return the best point in the evaluation space

...........................................................................
/home/aquemy/dev/dp_hyperparameters/extension/hyperopt/fmin.py in exhaust(self=<hyperopt.fmin.FMinIter object>)
    273             raise StopIteration()
    274         return self.trials
    275 
    276     def exhaust(self):
    277         n_done = len(self.trials)
--> 278         self.run(self.max_evals - n_done, block_until_done=self.asynchronous)
        self.run = <bound method FMinIter.run of <hyperopt.fmin.FMinIter object>>
        self.max_evals = 9223372036854775807
        n_done = 0
        self.asynchronous = False
    279         self.trials.refresh()
    280         return self
    281 
    282 

...........................................................................
/home/aquemy/dev/dp_hyperparameters/extension/hyperopt/fmin.py in run(self=<hyperopt.fmin.FMinIter object>, N=9223372036854775807, block_until_done=False)
    232                     if self.asynchronous:
    233                         # -- wait for workers to fill in the trials
    234                         time.sleep(self.poll_interval_secs)
    235                     else:
    236                         # -- loop over trials and do the jobs directly
--> 237                         self.serial_evaluate()
        self.serial_evaluate = <bound method FMinIter.serial_evaluate of <hyperopt.fmin.FMinIter object>>
    238                     try:
    239                         res = [d['result']['loss'] for d in
    240                                          self.trials.trials if
    241                                          d['result']['status'] == 'ok']

...........................................................................
/home/aquemy/dev/dp_hyperparameters/extension/hyperopt/fmin.py in serial_evaluate(self=<hyperopt.fmin.FMinIter object>, N=-1)
    138                 trial['book_time'] = now
    139                 trial['refresh_time'] = now
    140                 spec = base.spec_from_misc(trial['misc'])
    141                 ctrl = base.Ctrl(self.trials, current_trial=trial)
    142                 try:
--> 143                     result = self.domain.evaluate(spec, ctrl)
        result = undefined
        self.domain.evaluate = <bound method Domain.evaluate of <hyperopt.base.Domain object>>
        spec = {'bootstrap': 0, 'criterion': 1, 'features': 2, 'features_SelectKBest_features__k': 0, 'max_depth': 4, 'max_features': 1, 'max_leaf_nodes': 3, 'min_samples_split': 1, 'n_estimators': 2, 'normalizer': 0, ...}
        ctrl = <hyperopt.base.Ctrl object>
    144                 except Exception as e:
    145                     logger.info('job exception: %s' % str(e))
    146                     trial['state'] = base.JOB_STATE_ERROR
    147                     trial['misc']['error'] = (str(type(e)), str(e))

...........................................................................
/home/aquemy/dev/dp_hyperparameters/extension/hyperopt/base.py in evaluate(self=<hyperopt.base.Domain object>, config={'bootstrap': 0, 'criterion': 1, 'features': 2, 'features_SelectKBest_features__k': 0, 'max_depth': 4, 'max_features': 1, 'max_leaf_nodes': 3, 'min_samples_split': 1, 'n_estimators': 2, 'normalizer': 0, ...}, ctrl=<hyperopt.base.Ctrl object>, attach_attachments=True)
    841             #    or the normal Python part (self.fn)
    842             pyll_rval = pyll.rec_eval(
    843                 self.expr,
    844                 memo=memo,
    845                 print_node_on_error=self.rec_eval_print_node_on_error)
--> 846             rval = self.fn(pyll_rval)
        rval = undefined
        self.fn = <functools.partial object>
        pyll_rval = {'algorithm': {'bootstrap': True, 'criterion': 'entropy', 'max_depth': None, 'max_features': 2, 'max_leaf_nodes': None, 'min_samples_split': 3, 'n_estimators': 50}, 'pipeline': {'features': ('features_SelectKBest', {'features__k': 1}), 'normalizer': ('normalizer_NoneType', {}), 'rebalance': ('rebalance_CondensedNearestNeighbour', {'rebalance__n_neighbors': 1})}}
    847 
    848         if isinstance(rval, (float, int, np.number)):
    849             dict_rval = {'loss': float(rval), 'status': STATUS_OK}
    850         else:

...........................................................................
/home/aquemy/dev/dp_hyperparameters/extension/experiment/objective.py in objective_joint(wconfig={'algorithm': {'bootstrap': True, 'criterion': 'entropy', 'max_depth': None, 'max_features': 2, 'max_leaf_nodes': None, 'min_samples_split': 3, 'n_estimators': 50}, 'pipeline': {'features': ('features_SelectKBest', {'features__k': 1}), 'normalizer': ('normalizer_NoneType', {}), 'rebalance': ('rebalance_CondensedNearestNeighbour', {'rebalance__n_neighbors': 1})}}, algorithm='RandomForest', X=array([[ 0.,  0.,  5., ...,  0.,  0.,  0.],
    ...0.],
       [ 0.,  0., 10., ..., 12.,  1.,  0.]]), y=array([0, 1, 2, ..., 8, 9, 8]), context={'baseline_score': 0.9272021217853512, 'baseline_score_std': 0.026919033284817703, 'best_config': {'algorithm': {'bootstrap': False, 'criterion': 'entropy', 'max_depth': None, 'max_features': 2, 'max_leaf_nodes': None, 'min_samples_split': 2, 'n_estimators': 10}, 'config_hash': {'algorithm': 'a49ecb99e74217d6812f98ead7bc9d1fe4a53ba0', 'config': '6749af1a67b4dbcd2b4719e419d99908063c05e1', 'pipeline': '19bdf19a2eec5febce95ab8fa2a71040d75114aa'}, 'duration': 1.5498578548431396, 'iteration': 6, 'loss': 0.14471329609998995, 'max_history_score': 0.85528670390001, 'max_history_score_std': 0.02213730791268438, 'max_history_step': 'joint', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 4, 'features__selectkbest__k': 3}), 'normalizer': ('normalizer_NoneType', {}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 7})}, 'score': 0.85528670390001, ...}, 'history': [{'algorithm': {'bootstrap': False, 'criterion': 'entropy', 'max_depth': 1, 'max_features': 3, 'max_leaf_nodes': 3, 'min_samples_split': 5, 'n_estimators': 50}, 'config_hash': {'algorithm': '752fa095cdab58a238ae606c613606188964cc0c', 'config': 'fd24b065dda6bdeb1077793f9df480ff318c7a37', 'pipeline': '13ea3359c453b8993fcec1e88bc0e19cd0a2b112'}, 'duration': 0.689669132232666, 'iteration': 0, 'loss': 0.6602879519109309, 'max_history_score': 0.3397120480890691, 'max_history_score_std': 0.03346542949100545, 'max_history_step': 'joint', 'pipeline': {'features': ('features_SelectKBest', {'features__k': 4}), 'normalizer': ('normalizer_MinMaxScaler', {}), 'rebalance': ('rebalance_NoneType', {})}, 'score': 0.3397120480890691, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'gini', 'max_depth': 4, 'max_features': 1, 'max_leaf_nodes': 5, 'min_samples_split': 3, 'n_estimators': 25}, 'config_hash': {'algorithm': '9d9de4aee820052ddfe83bfffca420f6b50837d3', 'config': 'fb22f80fb4358ae1ee4c9bd4a83543992be8d806', 'pipeline': '6251ad4bb7a110726a67f90c319f4717ac37a312'}, 'duration': 1.4300940036773682, 'iteration': 1, 'loss': 0.5122196101741096, 'max_history_score': 0.48778038982589045, 'max_history_score_std': 0.05486079759217226, 'max_history_step': 'joint', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 2, 'features__selectkbest__k': 2}), 'normalizer': ('normalizer_StandardScaler', {'normalizer__with_mean': True, 'normalizer__with_std': True}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 5})}, 'score': 0.48778038982589045, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': 4, 'max_features': 1, 'max_leaf_nodes': None, 'min_samples_split': 2, 'n_estimators': 10}, 'config_hash': {'algorithm': '2ed7d27df9a1b2d5e63da76f7cb309616c232022', 'config': '8c97cdb885dd05cfd8c40ee3ac445b61e5c767a8', 'pipeline': 'c0abb5e23a4739d3120740a9519fb36c43eb94d5'}, 'duration': 3.0036678314208984, 'iteration': 2, 'loss': 0.38319264175312906, 'max_history_score': 0.6168073582468709, 'max_history_score_std': 0.05286679173001824, 'max_history_step': 'joint', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 1, 'features__selectkbest__k': 4}), 'normalizer': ('normalizer_PowerTransformer', {}), 'rebalance': ('rebalance_NearMiss', {'rebalance__n_neighbors': 2})}, 'score': 0.6168073582468709, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'entropy', 'max_depth': None, 'max_features': None, 'max_leaf_nodes': 2, 'min_samples_split': 2, 'n_estimators': 100}, 'config_hash': {'algorithm': '17962655e3b76dfcd0843d1e5c2cb7a9db1c6a79', 'config': '16fbb5fd5cfbbacfddf27c61c0c7397a7f6d8ade', 'pipeline': '13ea3359c453b8993fcec1e88bc0e19cd0a2b112'}, 'duration': 1.3447980880737305, 'iteration': 3, 'loss': 0.6768840987778313, 'max_history_score': 0.6168073582468709, 'max_history_score_std': 0.05286679173001824, 'max_history_step': 'joint', 'pipeline': {'features': ('features_SelectKBest', {'features__k': 4}), 'normalizer': ('normalizer_MinMaxScaler', {}), 'rebalance': ('rebalance_NoneType', {})}, 'score': 0.32311590122216866, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'gini', 'max_depth': 2, 'max_features': 2, 'max_leaf_nodes': 2, 'min_samples_split': 3, 'n_estimators': 100}, 'config_hash': {'algorithm': '1ea8965b2247f86950e54510ee6d79399816341b', 'config': 'a77c698197c31308211b854e81a998178941f87d', 'pipeline': 'aaf976c7c663a31fa039582d42f9e07101556a7c'}, 'duration': 2.589430093765259, 'iteration': 4, 'loss': 0.2544808950572157, 'max_history_score': 0.7455191049427843, 'max_history_score_std': 0.04843448308166839, 'max_history_step': 'joint', 'pipeline': {'features': ('features_NoneType', {}), 'normalizer': ('normalizer_PowerTransformer', {}), 'rebalance': ('rebalance_NoneType', {})}, 'score': 0.7455191049427843, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': None, 'max_features': 2, 'max_leaf_nodes': 5, 'min_samples_split': 5, 'n_estimators': 25}, 'config_hash': {'algorithm': 'fd8aeb6a05eaaba41e676d60596c8e0c71b35e0c', 'config': '1fc13606bca3aaf342ca6ea21139cb598b56f8db', 'pipeline': 'f00bd8de05642e026bbba4ad20d3a60088c86b6c'}, 'duration': 1.8779079914093018, 'iteration': 5, 'loss': 0.531551018758381, 'max_history_score': 0.7455191049427843, 'max_history_score_std': 0.04843448308166839, 'max_history_step': 'joint', 'pipeline': {'features': ('features_PCA', {'features__n_components': 2}), 'normalizer': ('normalizer_MinMaxScaler', {}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 5})}, 'score': 0.46844898124161904, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'entropy', 'max_depth': None, 'max_features': 2, 'max_leaf_nodes': None, 'min_samples_split': 2, 'n_estimators': 10}, 'config_hash': {'algorithm': 'a49ecb99e74217d6812f98ead7bc9d1fe4a53ba0', 'config': '6749af1a67b4dbcd2b4719e419d99908063c05e1', 'pipeline': '19bdf19a2eec5febce95ab8fa2a71040d75114aa'}, 'duration': 1.5498578548431396, 'iteration': 6, 'loss': 0.14471329609998995, 'max_history_score': 0.85528670390001, 'max_history_score_std': 0.02213730791268438, 'max_history_step': 'joint', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 4, 'features__selectkbest__k': 3}), 'normalizer': ('normalizer_NoneType', {}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 7})}, 'score': 0.85528670390001, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': 1, 'max_features': 3, 'max_leaf_nodes': 3, 'min_samples_split': 3, 'n_estimators': 75}, 'config_hash': {'algorithm': 'ebfb16234172ae811ff21185ff92bbdbb8f32f14', 'config': 'd92d4ada2394fc132733e176e926ee53acdc6a00', 'pipeline': '8071e7cbf86a5c3056493dc3aa40063aeb28cdfe'}, 'duration': 1.3618149757385254, 'iteration': 7, 'loss': 0.6158612049395463, 'max_history_score': 0.85528670390001, 'max_history_score_std': 0.02213730791268438, 'max_history_step': 'joint', 'pipeline': {'features': ('features_SelectKBest', {'features__k': 4}), 'normalizer': ('normalizer_StandardScaler', {'normalizer__with_mean': True, 'normalizer__with_std': True}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 5})}, 'score': 0.3841387950604537, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'entropy', 'max_depth': 1, 'max_features': 1, 'max_leaf_nodes': 5, 'min_samples_split': 2, 'n_estimators': 100}, 'config_hash': {'algorithm': '896b53c75a2db568fb7b6da3bfca2f7a1535a11b', 'config': 'f0d0b1d2cedc22ae15d9a208a3fc3fc133bf0d3d', 'pipeline': 'c9761c9a33bf75d6dcad0742c421548a7655ccc9'}, 'duration': 2.297278881072998, 'iteration': 8, 'loss': 0.40673663548410355, 'max_history_score': 0.85528670390001, 'max_history_score_std': 0.02213730791268438, 'max_history_step': 'joint', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 2, 'features__selectkbest__k': 4}), 'normalizer': ('normalizer_StandardScaler', {'normalizer__with_mean': False, 'normalizer__with_std': False}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 5})}, 'score': 0.5932633645158965, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'entropy', 'max_depth': 2, 'max_features': None, 'max_leaf_nodes': None, 'min_samples_split': 5, 'n_estimators': 25}, 'config_hash': {'algorithm': '0b0e954757c4f75343a6efb740ad93260ed781ae', 'config': '47584de0e60d0d12c7dbbf0dc60e5aea96e3f4b2', 'pipeline': 'b37ee32d59413053bf9a2a72c8ff7135f3701e05'}, 'duration': 0.7249000072479248, 'iteration': 9, 'loss': 0.6965910020393421, 'max_history_score': 0.85528670390001, 'max_history_score_std': 0.02213730791268438, 'max_history_step': 'joint', 'pipeline': {'features': ('features_SelectKBest', {'features__k': 3}), 'normalizer': ('normalizer_NoneType', {}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 7})}, 'score': 0.3034089979606579, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'gini', 'max_depth': 2, 'max_features': 2, 'max_leaf_nodes': 5, 'min_samples_split': 5, 'n_estimators': 75}, 'config_hash': {'algorithm': 'f1ead1d9e33ea927e1dd27d872a058fa3de4f832', 'config': 'eecb88ee2b1b95d741c1b5c7751534d31aae6a77', 'pipeline': '6746650871e8b61efc9302b092dc05f7cdb179d5'}, 'duration': 5.340634822845459, 'iteration': 10, 'loss': 0.7687016290977936, 'max_history_score': 0.85528670390001, 'max_history_score_std': 0.02213730791268438, 'max_history_step': 'joint', 'pipeline': {'features': ('features_SelectKBest', {'features__k': 3}), 'normalizer': ('normalizer_RobustScaler', {'normalizer__quantile_range': (...), 'normalizer__with_centering': False, 'normalizer__with_scaling': False}), 'rebalance': ('rebalance_CondensedNearestNeighbour', {'rebalance__n_neighbors': 1})}, 'score': 0.23129837090220637, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': 1, 'max_features': 2, 'max_leaf_nodes': 2, 'min_samples_split': 3, 'n_estimators': 75}, 'config_hash': {'algorithm': '531a3bb8ccf0baa06727af4b3de9e62d25e6eabf', 'config': '27a7ed0502b321ab7256b77c8ce79e90cb9da815', 'pipeline': '77e6d84e2217b92b3cf67cc6defef9dd3554cec0'}, 'duration': 1.775357961654663, 'iteration': 11, 'loss': 0.6313818737375694, 'max_history_score': 0.85528670390001, 'max_history_score_std': 0.02213730791268438, 'max_history_step': 'joint', 'pipeline': {'features': ('features_SelectKBest', {'features__k': 4}), 'normalizer': ('normalizer_MinMaxScaler', {}), 'rebalance': ('rebalance_NearMiss', {'rebalance__n_neighbors': 3})}, 'score': 0.3686181262624307, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'entropy', 'max_depth': 4, 'max_features': 3, 'max_leaf_nodes': 2, 'min_samples_split': 3, 'n_estimators': 10}, 'config_hash': {'algorithm': '93518f8ded6074d537900b26be72f8485782f933', 'config': '45f056102dd2d644bd8befa471f17b2311ac7954', 'pipeline': '5240329df25c9a533d025c1a401d49835a501b41'}, 'duration': 3.2622711658477783, 'iteration': 12, 'loss': 0.6120243191353301, 'max_history_score': 0.85528670390001, 'max_history_score_std': 0.02213730791268438, 'max_history_step': 'joint', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 4, 'features__selectkbest__k': 2}), 'normalizer': ('normalizer_PowerTransformer', {}), 'rebalance': ('rebalance_NearMiss', {'rebalance__n_neighbors': 1})}, 'score': 0.38797568086467, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'entropy', 'max_depth': None, 'max_features': 1, 'max_leaf_nodes': 5, 'min_samples_split': 3, 'n_estimators': 75}, 'config_hash': {'algorithm': 'e515d45b764fa43591032874a0ff9c25bf12fddd', 'config': 'ba108323623936872824ed8f1c41d615d25523b3', 'pipeline': '9d823bc0442f21b5ce8af67a5eb1237f64ffc2f8'}, 'duration': 2.5326571464538574, 'iteration': 13, 'loss': 0.6271427382991047, 'max_history_score': 0.85528670390001, 'max_history_score_std': 0.02213730791268438, 'max_history_step': 'joint', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 1, 'features__selectkbest__k': 1}), 'normalizer': ('normalizer_StandardScaler', {'normalizer__with_mean': True, 'normalizer__with_std': True}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 5})}, 'score': 0.3728572617008953, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'entropy', 'max_depth': 3, 'max_features': 2, 'max_leaf_nodes': 2, 'min_samples_split': 3, 'n_estimators': 25}, 'config_hash': {'algorithm': '2808e67f609eba5c8a97f81ac0c9413cd37cf7aa', 'config': 'dde4d3b5f37741629cb58bfc4051ed9f98c8f311', 'pipeline': 'bc52deabf1f5ee60968ba541d9d2574353c30a9c'}, 'duration': 0.7145559787750244, 'iteration': 14, 'loss': 0.6831045572696203, 'max_history_score': 0.85528670390001, 'max_history_score_std': 0.02213730791268438, 'max_history_step': 'joint', 'pipeline': {'features': ('features_SelectKBest', {'features__k': 3}), 'normalizer': ('normalizer_MinMaxScaler', {}), 'rebalance': ('rebalance_NearMiss', {'rebalance__n_neighbors': 1})}, 'score': 0.31689544273037973, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'gini', 'max_depth': 2, 'max_features': 2, 'max_leaf_nodes': None, 'min_samples_split': 5, 'n_estimators': 100}, 'config_hash': {'algorithm': 'b942acdead762d34afeb474bc2fe6f7fd0f23493', 'config': '1080c25b92da3f15a6f8eec003957f7e0a66324f', 'pipeline': 'cfa84fe703dc5bc0bbd2257a6d524fee2693b804'}, 'duration': 2.812459945678711, 'iteration': 15, 'loss': 0.6921421091202761, 'max_history_score': 0.85528670390001, 'max_history_score_std': 0.02213730791268438, 'max_history_step': 'joint', 'pipeline': {'features': ('features_SelectKBest', {'features__k': 2}), 'normalizer': ('normalizer_PowerTransformer', {}), 'rebalance': ('rebalance_NoneType', {})}, 'score': 0.3078578908797239, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'entropy', 'max_depth': 2, 'max_features': 3, 'max_leaf_nodes': 3, 'min_samples_split': 2, 'n_estimators': 75}, 'config_hash': {'algorithm': '250661ce4193a61ef44d2f77694b52b785ff032d', 'config': 'c3e8cf4eca5aafcae4ac31b0449e105ca127ffe2', 'pipeline': 'c4dd111513ea35f97dd3aec3e8e7f6268ce035da'}, 'duration': 1.0555319786071777, 'iteration': 16, 'loss': 1.0, 'max_history_score': 0.85528670390001, 'max_history_score_std': 0.02213730791268438, 'max_history_step': 'joint', 'pipeline': {'features': ('features_PCA', {'features__n_components': 2}), 'normalizer': ('normalizer_RobustScaler', {'normalizer__quantile_range': (...), 'normalizer__with_centering': False, 'normalizer__with_scaling': True}), 'rebalance': ('rebalance_NearMiss', {'rebalance__n_neighbors': 2})}, 'score': 0.0, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'entropy', 'max_depth': 3, 'max_features': 3, 'max_leaf_nodes': None, 'min_samples_split': 3, 'n_estimators': 25}, 'config_hash': {'algorithm': '05ac02bd045c65dc4089894902ad6253661a2692', 'config': '3449b4a1c2e488e26a7195ee9edca19b854ebd33', 'pipeline': '505d3f71b534917375d765e64b0611e7dfb83746'}, 'duration': 5.5412821769714355, 'iteration': 17, 'loss': 0.7289151155121668, 'max_history_score': 0.85528670390001, 'max_history_score_std': 0.02213730791268438, 'max_history_step': 'joint', 'pipeline': {'features': ('features_SelectKBest', {'features__k': 4}), 'normalizer': ('normalizer_MinMaxScaler', {}), 'rebalance': ('rebalance_CondensedNearestNeighbour', {'rebalance__n_neighbors': 2})}, 'score': 0.2710848844878332, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'entropy', 'max_depth': 2, 'max_features': None, 'max_leaf_nodes': None, 'min_samples_split': 2, 'n_estimators': 25}, 'config_hash': {'algorithm': 'de3b3a352ebb260e16c6b213a08c9144d17a744b', 'config': '224987ffdbbb9b6182cff18d8374518b917e4f2e', 'pipeline': '12c89200a558b2f3b91332566f41050143aecbe7'}, 'duration': 2.4646048545837402, 'iteration': 18, 'loss': 0.6545902512995826, 'max_history_score': 0.85528670390001, 'max_history_score_std': 0.02213730791268438, 'max_history_step': 'joint', 'pipeline': {'features': ('features_NoneType', {}), 'normalizer': ('normalizer_PowerTransformer', {}), 'rebalance': ('rebalance_NearMiss', {'rebalance__n_neighbors': 2})}, 'score': 0.3454097487004174, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'gini', 'max_depth': None, 'max_features': 1, 'max_leaf_nodes': None, 'min_samples_split': 3, 'n_estimators': 100}, 'config_hash': {'algorithm': '30ca111584767bbf0464df40b4c928cf7ddf9459', 'config': '97ca7d6a017c721084dec2a5d2e5a67e1e6ae2f0', 'pipeline': '789eca82ea4a42d61927670c538867b745fd81d3'}, 'duration': 7.164499044418335, 'iteration': 19, 'loss': 0.6536825403350528, 'max_history_score': 0.85528670390001, 'max_history_score_std': 0.02213730791268438, 'max_history_step': 'joint', 'pipeline': {'features': ('features_SelectKBest', {'features__k': 3}), 'normalizer': ('normalizer_RobustScaler', {'normalizer__quantile_range': (...), 'normalizer__with_centering': False, 'normalizer__with_scaling': True}), 'rebalance': ('rebalance_CondensedNearestNeighbour', {'rebalance__n_neighbors': 3})}, 'score': 0.3463174596649472, ...}, ...], 'history_hash': ['fd24b065dda6bdeb1077793f9df480ff318c7a37', 'fb22f80fb4358ae1ee4c9bd4a83543992be8d806', '8c97cdb885dd05cfd8c40ee3ac445b61e5c767a8', '16fbb5fd5cfbbacfddf27c61c0c7397a7f6d8ade', 'a77c698197c31308211b854e81a998178941f87d', '1fc13606bca3aaf342ca6ea21139cb598b56f8db', '6749af1a67b4dbcd2b4719e419d99908063c05e1', 'd92d4ada2394fc132733e176e926ee53acdc6a00', 'f0d0b1d2cedc22ae15d9a208a3fc3fc133bf0d3d', '47584de0e60d0d12c7dbbf0dc60e5aea96e3f4b2', 'eecb88ee2b1b95d741c1b5c7751534d31aae6a77', '27a7ed0502b321ab7256b77c8ce79e90cb9da815', '45f056102dd2d644bd8befa471f17b2311ac7954', 'ba108323623936872824ed8f1c41d615d25523b3', 'dde4d3b5f37741629cb58bfc4051ed9f98c8f311', '1080c25b92da3f15a6f8eec003957f7e0a66324f', 'c3e8cf4eca5aafcae4ac31b0449e105ca127ffe2', '3449b4a1c2e488e26a7195ee9edca19b854ebd33', '224987ffdbbb9b6182cff18d8374518b917e4f2e', '97ca7d6a017c721084dec2a5d2e5a67e1e6ae2f0', ...], 'history_index': {'05465becb12810ce291074be22a0275a42efbea8': 52, '064f53edf4748bb2df4ff59f147331aad21219e1': 48, '087efef4a19f272562d2d445dac0edd8096ba2fa': 58, '0fd4d71ca3a89c7d14af5087f2a2e2c1b1975351': 51, '1080c25b92da3f15a6f8eec003957f7e0a66324f': 15, '143679b59e16961765e77616142572b6ded0ee72': 62, '151b4a15037767108da13dafa0b63ae93222e93a': 53, '16fbb5fd5cfbbacfddf27c61c0c7397a7f6d8ade': 3, '1fc13606bca3aaf342ca6ea21139cb598b56f8db': 5, '2187b0ebdd42d61eb93839b9a1592ae8707ce4c5': 42, ...}, 'iteration': 63, 'max_history_score': 0.85528670390001, 'max_history_score_std': 0.02213730791268438, 'max_history_step': 'joint'}, config={'algorithm': 'RandomForest', 'seed': 42, 'time': 300})
    108 
    109 def objective_algo(algo_config, current_pipeline_config, algorithm, X, y, context, config):
    110     return objective(current_pipeline_config, algo_config, algorithm, X, y, context, config, step='algorithm')
    111 
    112 def objective_joint(wconfig, algorithm, X, y, context, config):
--> 113     return objective(wconfig['pipeline'], wconfig['algorithm'], algorithm, X, y, context, config, step='joint')
        wconfig = {'algorithm': {'bootstrap': True, 'criterion': 'entropy', 'max_depth': None, 'max_features': 2, 'max_leaf_nodes': None, 'min_samples_split': 3, 'n_estimators': 50}, 'pipeline': {'features': ('features_SelectKBest', {'features__k': 1}), 'normalizer': ('normalizer_NoneType', {}), 'rebalance': ('rebalance_CondensedNearestNeighbour', {'rebalance__n_neighbors': 1})}}
        algorithm = 'RandomForest'
        X = array([[ 0.,  0.,  5., ...,  0.,  0.,  0.],
    ...0.],
       [ 0.,  0., 10., ..., 12.,  1.,  0.]])
        y = array([0, 1, 2, ..., 8, 9, 8])
        context = {'baseline_score': 0.9272021217853512, 'baseline_score_std': 0.026919033284817703, 'best_config': {'algorithm': {'bootstrap': False, 'criterion': 'entropy', 'max_depth': None, 'max_features': 2, 'max_leaf_nodes': None, 'min_samples_split': 2, 'n_estimators': 10}, 'config_hash': {'algorithm': 'a49ecb99e74217d6812f98ead7bc9d1fe4a53ba0', 'config': '6749af1a67b4dbcd2b4719e419d99908063c05e1', 'pipeline': '19bdf19a2eec5febce95ab8fa2a71040d75114aa'}, 'duration': 1.5498578548431396, 'iteration': 6, 'loss': 0.14471329609998995, 'max_history_score': 0.85528670390001, 'max_history_score_std': 0.02213730791268438, 'max_history_step': 'joint', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 4, 'features__selectkbest__k': 3}), 'normalizer': ('normalizer_NoneType', {}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 7})}, 'score': 0.85528670390001, ...}, 'history': [{'algorithm': {'bootstrap': False, 'criterion': 'entropy', 'max_depth': 1, 'max_features': 3, 'max_leaf_nodes': 3, 'min_samples_split': 5, 'n_estimators': 50}, 'config_hash': {'algorithm': '752fa095cdab58a238ae606c613606188964cc0c', 'config': 'fd24b065dda6bdeb1077793f9df480ff318c7a37', 'pipeline': '13ea3359c453b8993fcec1e88bc0e19cd0a2b112'}, 'duration': 0.689669132232666, 'iteration': 0, 'loss': 0.6602879519109309, 'max_history_score': 0.3397120480890691, 'max_history_score_std': 0.03346542949100545, 'max_history_step': 'joint', 'pipeline': {'features': ('features_SelectKBest', {'features__k': 4}), 'normalizer': ('normalizer_MinMaxScaler', {}), 'rebalance': ('rebalance_NoneType', {})}, 'score': 0.3397120480890691, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'gini', 'max_depth': 4, 'max_features': 1, 'max_leaf_nodes': 5, 'min_samples_split': 3, 'n_estimators': 25}, 'config_hash': {'algorithm': '9d9de4aee820052ddfe83bfffca420f6b50837d3', 'config': 'fb22f80fb4358ae1ee4c9bd4a83543992be8d806', 'pipeline': '6251ad4bb7a110726a67f90c319f4717ac37a312'}, 'duration': 1.4300940036773682, 'iteration': 1, 'loss': 0.5122196101741096, 'max_history_score': 0.48778038982589045, 'max_history_score_std': 0.05486079759217226, 'max_history_step': 'joint', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 2, 'features__selectkbest__k': 2}), 'normalizer': ('normalizer_StandardScaler', {'normalizer__with_mean': True, 'normalizer__with_std': True}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 5})}, 'score': 0.48778038982589045, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': 4, 'max_features': 1, 'max_leaf_nodes': None, 'min_samples_split': 2, 'n_estimators': 10}, 'config_hash': {'algorithm': '2ed7d27df9a1b2d5e63da76f7cb309616c232022', 'config': '8c97cdb885dd05cfd8c40ee3ac445b61e5c767a8', 'pipeline': 'c0abb5e23a4739d3120740a9519fb36c43eb94d5'}, 'duration': 3.0036678314208984, 'iteration': 2, 'loss': 0.38319264175312906, 'max_history_score': 0.6168073582468709, 'max_history_score_std': 0.05286679173001824, 'max_history_step': 'joint', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 1, 'features__selectkbest__k': 4}), 'normalizer': ('normalizer_PowerTransformer', {}), 'rebalance': ('rebalance_NearMiss', {'rebalance__n_neighbors': 2})}, 'score': 0.6168073582468709, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'entropy', 'max_depth': None, 'max_features': None, 'max_leaf_nodes': 2, 'min_samples_split': 2, 'n_estimators': 100}, 'config_hash': {'algorithm': '17962655e3b76dfcd0843d1e5c2cb7a9db1c6a79', 'config': '16fbb5fd5cfbbacfddf27c61c0c7397a7f6d8ade', 'pipeline': '13ea3359c453b8993fcec1e88bc0e19cd0a2b112'}, 'duration': 1.3447980880737305, 'iteration': 3, 'loss': 0.6768840987778313, 'max_history_score': 0.6168073582468709, 'max_history_score_std': 0.05286679173001824, 'max_history_step': 'joint', 'pipeline': {'features': ('features_SelectKBest', {'features__k': 4}), 'normalizer': ('normalizer_MinMaxScaler', {}), 'rebalance': ('rebalance_NoneType', {})}, 'score': 0.32311590122216866, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'gini', 'max_depth': 2, 'max_features': 2, 'max_leaf_nodes': 2, 'min_samples_split': 3, 'n_estimators': 100}, 'config_hash': {'algorithm': '1ea8965b2247f86950e54510ee6d79399816341b', 'config': 'a77c698197c31308211b854e81a998178941f87d', 'pipeline': 'aaf976c7c663a31fa039582d42f9e07101556a7c'}, 'duration': 2.589430093765259, 'iteration': 4, 'loss': 0.2544808950572157, 'max_history_score': 0.7455191049427843, 'max_history_score_std': 0.04843448308166839, 'max_history_step': 'joint', 'pipeline': {'features': ('features_NoneType', {}), 'normalizer': ('normalizer_PowerTransformer', {}), 'rebalance': ('rebalance_NoneType', {})}, 'score': 0.7455191049427843, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': None, 'max_features': 2, 'max_leaf_nodes': 5, 'min_samples_split': 5, 'n_estimators': 25}, 'config_hash': {'algorithm': 'fd8aeb6a05eaaba41e676d60596c8e0c71b35e0c', 'config': '1fc13606bca3aaf342ca6ea21139cb598b56f8db', 'pipeline': 'f00bd8de05642e026bbba4ad20d3a60088c86b6c'}, 'duration': 1.8779079914093018, 'iteration': 5, 'loss': 0.531551018758381, 'max_history_score': 0.7455191049427843, 'max_history_score_std': 0.04843448308166839, 'max_history_step': 'joint', 'pipeline': {'features': ('features_PCA', {'features__n_components': 2}), 'normalizer': ('normalizer_MinMaxScaler', {}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 5})}, 'score': 0.46844898124161904, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'entropy', 'max_depth': None, 'max_features': 2, 'max_leaf_nodes': None, 'min_samples_split': 2, 'n_estimators': 10}, 'config_hash': {'algorithm': 'a49ecb99e74217d6812f98ead7bc9d1fe4a53ba0', 'config': '6749af1a67b4dbcd2b4719e419d99908063c05e1', 'pipeline': '19bdf19a2eec5febce95ab8fa2a71040d75114aa'}, 'duration': 1.5498578548431396, 'iteration': 6, 'loss': 0.14471329609998995, 'max_history_score': 0.85528670390001, 'max_history_score_std': 0.02213730791268438, 'max_history_step': 'joint', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 4, 'features__selectkbest__k': 3}), 'normalizer': ('normalizer_NoneType', {}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 7})}, 'score': 0.85528670390001, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': 1, 'max_features': 3, 'max_leaf_nodes': 3, 'min_samples_split': 3, 'n_estimators': 75}, 'config_hash': {'algorithm': 'ebfb16234172ae811ff21185ff92bbdbb8f32f14', 'config': 'd92d4ada2394fc132733e176e926ee53acdc6a00', 'pipeline': '8071e7cbf86a5c3056493dc3aa40063aeb28cdfe'}, 'duration': 1.3618149757385254, 'iteration': 7, 'loss': 0.6158612049395463, 'max_history_score': 0.85528670390001, 'max_history_score_std': 0.02213730791268438, 'max_history_step': 'joint', 'pipeline': {'features': ('features_SelectKBest', {'features__k': 4}), 'normalizer': ('normalizer_StandardScaler', {'normalizer__with_mean': True, 'normalizer__with_std': True}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 5})}, 'score': 0.3841387950604537, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'entropy', 'max_depth': 1, 'max_features': 1, 'max_leaf_nodes': 5, 'min_samples_split': 2, 'n_estimators': 100}, 'config_hash': {'algorithm': '896b53c75a2db568fb7b6da3bfca2f7a1535a11b', 'config': 'f0d0b1d2cedc22ae15d9a208a3fc3fc133bf0d3d', 'pipeline': 'c9761c9a33bf75d6dcad0742c421548a7655ccc9'}, 'duration': 2.297278881072998, 'iteration': 8, 'loss': 0.40673663548410355, 'max_history_score': 0.85528670390001, 'max_history_score_std': 0.02213730791268438, 'max_history_step': 'joint', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 2, 'features__selectkbest__k': 4}), 'normalizer': ('normalizer_StandardScaler', {'normalizer__with_mean': False, 'normalizer__with_std': False}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 5})}, 'score': 0.5932633645158965, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'entropy', 'max_depth': 2, 'max_features': None, 'max_leaf_nodes': None, 'min_samples_split': 5, 'n_estimators': 25}, 'config_hash': {'algorithm': '0b0e954757c4f75343a6efb740ad93260ed781ae', 'config': '47584de0e60d0d12c7dbbf0dc60e5aea96e3f4b2', 'pipeline': 'b37ee32d59413053bf9a2a72c8ff7135f3701e05'}, 'duration': 0.7249000072479248, 'iteration': 9, 'loss': 0.6965910020393421, 'max_history_score': 0.85528670390001, 'max_history_score_std': 0.02213730791268438, 'max_history_step': 'joint', 'pipeline': {'features': ('features_SelectKBest', {'features__k': 3}), 'normalizer': ('normalizer_NoneType', {}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 7})}, 'score': 0.3034089979606579, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'gini', 'max_depth': 2, 'max_features': 2, 'max_leaf_nodes': 5, 'min_samples_split': 5, 'n_estimators': 75}, 'config_hash': {'algorithm': 'f1ead1d9e33ea927e1dd27d872a058fa3de4f832', 'config': 'eecb88ee2b1b95d741c1b5c7751534d31aae6a77', 'pipeline': '6746650871e8b61efc9302b092dc05f7cdb179d5'}, 'duration': 5.340634822845459, 'iteration': 10, 'loss': 0.7687016290977936, 'max_history_score': 0.85528670390001, 'max_history_score_std': 0.02213730791268438, 'max_history_step': 'joint', 'pipeline': {'features': ('features_SelectKBest', {'features__k': 3}), 'normalizer': ('normalizer_RobustScaler', {'normalizer__quantile_range': (...), 'normalizer__with_centering': False, 'normalizer__with_scaling': False}), 'rebalance': ('rebalance_CondensedNearestNeighbour', {'rebalance__n_neighbors': 1})}, 'score': 0.23129837090220637, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': 1, 'max_features': 2, 'max_leaf_nodes': 2, 'min_samples_split': 3, 'n_estimators': 75}, 'config_hash': {'algorithm': '531a3bb8ccf0baa06727af4b3de9e62d25e6eabf', 'config': '27a7ed0502b321ab7256b77c8ce79e90cb9da815', 'pipeline': '77e6d84e2217b92b3cf67cc6defef9dd3554cec0'}, 'duration': 1.775357961654663, 'iteration': 11, 'loss': 0.6313818737375694, 'max_history_score': 0.85528670390001, 'max_history_score_std': 0.02213730791268438, 'max_history_step': 'joint', 'pipeline': {'features': ('features_SelectKBest', {'features__k': 4}), 'normalizer': ('normalizer_MinMaxScaler', {}), 'rebalance': ('rebalance_NearMiss', {'rebalance__n_neighbors': 3})}, 'score': 0.3686181262624307, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'entropy', 'max_depth': 4, 'max_features': 3, 'max_leaf_nodes': 2, 'min_samples_split': 3, 'n_estimators': 10}, 'config_hash': {'algorithm': '93518f8ded6074d537900b26be72f8485782f933', 'config': '45f056102dd2d644bd8befa471f17b2311ac7954', 'pipeline': '5240329df25c9a533d025c1a401d49835a501b41'}, 'duration': 3.2622711658477783, 'iteration': 12, 'loss': 0.6120243191353301, 'max_history_score': 0.85528670390001, 'max_history_score_std': 0.02213730791268438, 'max_history_step': 'joint', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 4, 'features__selectkbest__k': 2}), 'normalizer': ('normalizer_PowerTransformer', {}), 'rebalance': ('rebalance_NearMiss', {'rebalance__n_neighbors': 1})}, 'score': 0.38797568086467, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'entropy', 'max_depth': None, 'max_features': 1, 'max_leaf_nodes': 5, 'min_samples_split': 3, 'n_estimators': 75}, 'config_hash': {'algorithm': 'e515d45b764fa43591032874a0ff9c25bf12fddd', 'config': 'ba108323623936872824ed8f1c41d615d25523b3', 'pipeline': '9d823bc0442f21b5ce8af67a5eb1237f64ffc2f8'}, 'duration': 2.5326571464538574, 'iteration': 13, 'loss': 0.6271427382991047, 'max_history_score': 0.85528670390001, 'max_history_score_std': 0.02213730791268438, 'max_history_step': 'joint', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 1, 'features__selectkbest__k': 1}), 'normalizer': ('normalizer_StandardScaler', {'normalizer__with_mean': True, 'normalizer__with_std': True}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 5})}, 'score': 0.3728572617008953, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'entropy', 'max_depth': 3, 'max_features': 2, 'max_leaf_nodes': 2, 'min_samples_split': 3, 'n_estimators': 25}, 'config_hash': {'algorithm': '2808e67f609eba5c8a97f81ac0c9413cd37cf7aa', 'config': 'dde4d3b5f37741629cb58bfc4051ed9f98c8f311', 'pipeline': 'bc52deabf1f5ee60968ba541d9d2574353c30a9c'}, 'duration': 0.7145559787750244, 'iteration': 14, 'loss': 0.6831045572696203, 'max_history_score': 0.85528670390001, 'max_history_score_std': 0.02213730791268438, 'max_history_step': 'joint', 'pipeline': {'features': ('features_SelectKBest', {'features__k': 3}), 'normalizer': ('normalizer_MinMaxScaler', {}), 'rebalance': ('rebalance_NearMiss', {'rebalance__n_neighbors': 1})}, 'score': 0.31689544273037973, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'gini', 'max_depth': 2, 'max_features': 2, 'max_leaf_nodes': None, 'min_samples_split': 5, 'n_estimators': 100}, 'config_hash': {'algorithm': 'b942acdead762d34afeb474bc2fe6f7fd0f23493', 'config': '1080c25b92da3f15a6f8eec003957f7e0a66324f', 'pipeline': 'cfa84fe703dc5bc0bbd2257a6d524fee2693b804'}, 'duration': 2.812459945678711, 'iteration': 15, 'loss': 0.6921421091202761, 'max_history_score': 0.85528670390001, 'max_history_score_std': 0.02213730791268438, 'max_history_step': 'joint', 'pipeline': {'features': ('features_SelectKBest', {'features__k': 2}), 'normalizer': ('normalizer_PowerTransformer', {}), 'rebalance': ('rebalance_NoneType', {})}, 'score': 0.3078578908797239, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'entropy', 'max_depth': 2, 'max_features': 3, 'max_leaf_nodes': 3, 'min_samples_split': 2, 'n_estimators': 75}, 'config_hash': {'algorithm': '250661ce4193a61ef44d2f77694b52b785ff032d', 'config': 'c3e8cf4eca5aafcae4ac31b0449e105ca127ffe2', 'pipeline': 'c4dd111513ea35f97dd3aec3e8e7f6268ce035da'}, 'duration': 1.0555319786071777, 'iteration': 16, 'loss': 1.0, 'max_history_score': 0.85528670390001, 'max_history_score_std': 0.02213730791268438, 'max_history_step': 'joint', 'pipeline': {'features': ('features_PCA', {'features__n_components': 2}), 'normalizer': ('normalizer_RobustScaler', {'normalizer__quantile_range': (...), 'normalizer__with_centering': False, 'normalizer__with_scaling': True}), 'rebalance': ('rebalance_NearMiss', {'rebalance__n_neighbors': 2})}, 'score': 0.0, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'entropy', 'max_depth': 3, 'max_features': 3, 'max_leaf_nodes': None, 'min_samples_split': 3, 'n_estimators': 25}, 'config_hash': {'algorithm': '05ac02bd045c65dc4089894902ad6253661a2692', 'config': '3449b4a1c2e488e26a7195ee9edca19b854ebd33', 'pipeline': '505d3f71b534917375d765e64b0611e7dfb83746'}, 'duration': 5.5412821769714355, 'iteration': 17, 'loss': 0.7289151155121668, 'max_history_score': 0.85528670390001, 'max_history_score_std': 0.02213730791268438, 'max_history_step': 'joint', 'pipeline': {'features': ('features_SelectKBest', {'features__k': 4}), 'normalizer': ('normalizer_MinMaxScaler', {}), 'rebalance': ('rebalance_CondensedNearestNeighbour', {'rebalance__n_neighbors': 2})}, 'score': 0.2710848844878332, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'entropy', 'max_depth': 2, 'max_features': None, 'max_leaf_nodes': None, 'min_samples_split': 2, 'n_estimators': 25}, 'config_hash': {'algorithm': 'de3b3a352ebb260e16c6b213a08c9144d17a744b', 'config': '224987ffdbbb9b6182cff18d8374518b917e4f2e', 'pipeline': '12c89200a558b2f3b91332566f41050143aecbe7'}, 'duration': 2.4646048545837402, 'iteration': 18, 'loss': 0.6545902512995826, 'max_history_score': 0.85528670390001, 'max_history_score_std': 0.02213730791268438, 'max_history_step': 'joint', 'pipeline': {'features': ('features_NoneType', {}), 'normalizer': ('normalizer_PowerTransformer', {}), 'rebalance': ('rebalance_NearMiss', {'rebalance__n_neighbors': 2})}, 'score': 0.3454097487004174, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'gini', 'max_depth': None, 'max_features': 1, 'max_leaf_nodes': None, 'min_samples_split': 3, 'n_estimators': 100}, 'config_hash': {'algorithm': '30ca111584767bbf0464df40b4c928cf7ddf9459', 'config': '97ca7d6a017c721084dec2a5d2e5a67e1e6ae2f0', 'pipeline': '789eca82ea4a42d61927670c538867b745fd81d3'}, 'duration': 7.164499044418335, 'iteration': 19, 'loss': 0.6536825403350528, 'max_history_score': 0.85528670390001, 'max_history_score_std': 0.02213730791268438, 'max_history_step': 'joint', 'pipeline': {'features': ('features_SelectKBest', {'features__k': 3}), 'normalizer': ('normalizer_RobustScaler', {'normalizer__quantile_range': (...), 'normalizer__with_centering': False, 'normalizer__with_scaling': True}), 'rebalance': ('rebalance_CondensedNearestNeighbour', {'rebalance__n_neighbors': 3})}, 'score': 0.3463174596649472, ...}, ...], 'history_hash': ['fd24b065dda6bdeb1077793f9df480ff318c7a37', 'fb22f80fb4358ae1ee4c9bd4a83543992be8d806', '8c97cdb885dd05cfd8c40ee3ac445b61e5c767a8', '16fbb5fd5cfbbacfddf27c61c0c7397a7f6d8ade', 'a77c698197c31308211b854e81a998178941f87d', '1fc13606bca3aaf342ca6ea21139cb598b56f8db', '6749af1a67b4dbcd2b4719e419d99908063c05e1', 'd92d4ada2394fc132733e176e926ee53acdc6a00', 'f0d0b1d2cedc22ae15d9a208a3fc3fc133bf0d3d', '47584de0e60d0d12c7dbbf0dc60e5aea96e3f4b2', 'eecb88ee2b1b95d741c1b5c7751534d31aae6a77', '27a7ed0502b321ab7256b77c8ce79e90cb9da815', '45f056102dd2d644bd8befa471f17b2311ac7954', 'ba108323623936872824ed8f1c41d615d25523b3', 'dde4d3b5f37741629cb58bfc4051ed9f98c8f311', '1080c25b92da3f15a6f8eec003957f7e0a66324f', 'c3e8cf4eca5aafcae4ac31b0449e105ca127ffe2', '3449b4a1c2e488e26a7195ee9edca19b854ebd33', '224987ffdbbb9b6182cff18d8374518b917e4f2e', '97ca7d6a017c721084dec2a5d2e5a67e1e6ae2f0', ...], 'history_index': {'05465becb12810ce291074be22a0275a42efbea8': 52, '064f53edf4748bb2df4ff59f147331aad21219e1': 48, '087efef4a19f272562d2d445dac0edd8096ba2fa': 58, '0fd4d71ca3a89c7d14af5087f2a2e2c1b1975351': 51, '1080c25b92da3f15a6f8eec003957f7e0a66324f': 15, '143679b59e16961765e77616142572b6ded0ee72': 62, '151b4a15037767108da13dafa0b63ae93222e93a': 53, '16fbb5fd5cfbbacfddf27c61c0c7397a7f6d8ade': 3, '1fc13606bca3aaf342ca6ea21139cb598b56f8db': 5, '2187b0ebdd42d61eb93839b9a1592ae8707ce4c5': 42, ...}, 'iteration': 63, 'max_history_score': 0.85528670390001, 'max_history_score_std': 0.02213730791268438, 'max_history_step': 'joint'}
        config = {'algorithm': 'RandomForest', 'seed': 42, 'time': 300}
    114 
    115 
    116 def get_baseline_score(algorithm, X, y, seed):
    117     pipeline, _ = pipeline_conf_to_full_pipeline(

...........................................................................
/home/aquemy/dev/dp_hyperparameters/extension/experiment/objective.py in objective(pipeline_config={'features': ('features_SelectKBest', {'features__k': 1}), 'normalizer': ('normalizer_NoneType', {}), 'rebalance': ('rebalance_CondensedNearestNeighbour', {'rebalance__n_neighbors': 1})}, algo_config={'bootstrap': True, 'criterion': 'entropy', 'max_depth': None, 'max_features': 2, 'max_leaf_nodes': None, 'min_samples_split': 3, 'n_estimators': 50}, algorithm='RandomForest', X=array([[ 0.,  0.,  5., ...,  0.,  0.,  0.],
    ...0.],
       [ 0.,  0., 10., ..., 12.,  1.,  0.]]), y=array([0, 1, 2, ..., 8, 9, 8]), context={'baseline_score': 0.9272021217853512, 'baseline_score_std': 0.026919033284817703, 'best_config': {'algorithm': {'bootstrap': False, 'criterion': 'entropy', 'max_depth': None, 'max_features': 2, 'max_leaf_nodes': None, 'min_samples_split': 2, 'n_estimators': 10}, 'config_hash': {'algorithm': 'a49ecb99e74217d6812f98ead7bc9d1fe4a53ba0', 'config': '6749af1a67b4dbcd2b4719e419d99908063c05e1', 'pipeline': '19bdf19a2eec5febce95ab8fa2a71040d75114aa'}, 'duration': 1.5498578548431396, 'iteration': 6, 'loss': 0.14471329609998995, 'max_history_score': 0.85528670390001, 'max_history_score_std': 0.02213730791268438, 'max_history_step': 'joint', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 4, 'features__selectkbest__k': 3}), 'normalizer': ('normalizer_NoneType', {}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 7})}, 'score': 0.85528670390001, ...}, 'history': [{'algorithm': {'bootstrap': False, 'criterion': 'entropy', 'max_depth': 1, 'max_features': 3, 'max_leaf_nodes': 3, 'min_samples_split': 5, 'n_estimators': 50}, 'config_hash': {'algorithm': '752fa095cdab58a238ae606c613606188964cc0c', 'config': 'fd24b065dda6bdeb1077793f9df480ff318c7a37', 'pipeline': '13ea3359c453b8993fcec1e88bc0e19cd0a2b112'}, 'duration': 0.689669132232666, 'iteration': 0, 'loss': 0.6602879519109309, 'max_history_score': 0.3397120480890691, 'max_history_score_std': 0.03346542949100545, 'max_history_step': 'joint', 'pipeline': {'features': ('features_SelectKBest', {'features__k': 4}), 'normalizer': ('normalizer_MinMaxScaler', {}), 'rebalance': ('rebalance_NoneType', {})}, 'score': 0.3397120480890691, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'gini', 'max_depth': 4, 'max_features': 1, 'max_leaf_nodes': 5, 'min_samples_split': 3, 'n_estimators': 25}, 'config_hash': {'algorithm': '9d9de4aee820052ddfe83bfffca420f6b50837d3', 'config': 'fb22f80fb4358ae1ee4c9bd4a83543992be8d806', 'pipeline': '6251ad4bb7a110726a67f90c319f4717ac37a312'}, 'duration': 1.4300940036773682, 'iteration': 1, 'loss': 0.5122196101741096, 'max_history_score': 0.48778038982589045, 'max_history_score_std': 0.05486079759217226, 'max_history_step': 'joint', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 2, 'features__selectkbest__k': 2}), 'normalizer': ('normalizer_StandardScaler', {'normalizer__with_mean': True, 'normalizer__with_std': True}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 5})}, 'score': 0.48778038982589045, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': 4, 'max_features': 1, 'max_leaf_nodes': None, 'min_samples_split': 2, 'n_estimators': 10}, 'config_hash': {'algorithm': '2ed7d27df9a1b2d5e63da76f7cb309616c232022', 'config': '8c97cdb885dd05cfd8c40ee3ac445b61e5c767a8', 'pipeline': 'c0abb5e23a4739d3120740a9519fb36c43eb94d5'}, 'duration': 3.0036678314208984, 'iteration': 2, 'loss': 0.38319264175312906, 'max_history_score': 0.6168073582468709, 'max_history_score_std': 0.05286679173001824, 'max_history_step': 'joint', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 1, 'features__selectkbest__k': 4}), 'normalizer': ('normalizer_PowerTransformer', {}), 'rebalance': ('rebalance_NearMiss', {'rebalance__n_neighbors': 2})}, 'score': 0.6168073582468709, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'entropy', 'max_depth': None, 'max_features': None, 'max_leaf_nodes': 2, 'min_samples_split': 2, 'n_estimators': 100}, 'config_hash': {'algorithm': '17962655e3b76dfcd0843d1e5c2cb7a9db1c6a79', 'config': '16fbb5fd5cfbbacfddf27c61c0c7397a7f6d8ade', 'pipeline': '13ea3359c453b8993fcec1e88bc0e19cd0a2b112'}, 'duration': 1.3447980880737305, 'iteration': 3, 'loss': 0.6768840987778313, 'max_history_score': 0.6168073582468709, 'max_history_score_std': 0.05286679173001824, 'max_history_step': 'joint', 'pipeline': {'features': ('features_SelectKBest', {'features__k': 4}), 'normalizer': ('normalizer_MinMaxScaler', {}), 'rebalance': ('rebalance_NoneType', {})}, 'score': 0.32311590122216866, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'gini', 'max_depth': 2, 'max_features': 2, 'max_leaf_nodes': 2, 'min_samples_split': 3, 'n_estimators': 100}, 'config_hash': {'algorithm': '1ea8965b2247f86950e54510ee6d79399816341b', 'config': 'a77c698197c31308211b854e81a998178941f87d', 'pipeline': 'aaf976c7c663a31fa039582d42f9e07101556a7c'}, 'duration': 2.589430093765259, 'iteration': 4, 'loss': 0.2544808950572157, 'max_history_score': 0.7455191049427843, 'max_history_score_std': 0.04843448308166839, 'max_history_step': 'joint', 'pipeline': {'features': ('features_NoneType', {}), 'normalizer': ('normalizer_PowerTransformer', {}), 'rebalance': ('rebalance_NoneType', {})}, 'score': 0.7455191049427843, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': None, 'max_features': 2, 'max_leaf_nodes': 5, 'min_samples_split': 5, 'n_estimators': 25}, 'config_hash': {'algorithm': 'fd8aeb6a05eaaba41e676d60596c8e0c71b35e0c', 'config': '1fc13606bca3aaf342ca6ea21139cb598b56f8db', 'pipeline': 'f00bd8de05642e026bbba4ad20d3a60088c86b6c'}, 'duration': 1.8779079914093018, 'iteration': 5, 'loss': 0.531551018758381, 'max_history_score': 0.7455191049427843, 'max_history_score_std': 0.04843448308166839, 'max_history_step': 'joint', 'pipeline': {'features': ('features_PCA', {'features__n_components': 2}), 'normalizer': ('normalizer_MinMaxScaler', {}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 5})}, 'score': 0.46844898124161904, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'entropy', 'max_depth': None, 'max_features': 2, 'max_leaf_nodes': None, 'min_samples_split': 2, 'n_estimators': 10}, 'config_hash': {'algorithm': 'a49ecb99e74217d6812f98ead7bc9d1fe4a53ba0', 'config': '6749af1a67b4dbcd2b4719e419d99908063c05e1', 'pipeline': '19bdf19a2eec5febce95ab8fa2a71040d75114aa'}, 'duration': 1.5498578548431396, 'iteration': 6, 'loss': 0.14471329609998995, 'max_history_score': 0.85528670390001, 'max_history_score_std': 0.02213730791268438, 'max_history_step': 'joint', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 4, 'features__selectkbest__k': 3}), 'normalizer': ('normalizer_NoneType', {}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 7})}, 'score': 0.85528670390001, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': 1, 'max_features': 3, 'max_leaf_nodes': 3, 'min_samples_split': 3, 'n_estimators': 75}, 'config_hash': {'algorithm': 'ebfb16234172ae811ff21185ff92bbdbb8f32f14', 'config': 'd92d4ada2394fc132733e176e926ee53acdc6a00', 'pipeline': '8071e7cbf86a5c3056493dc3aa40063aeb28cdfe'}, 'duration': 1.3618149757385254, 'iteration': 7, 'loss': 0.6158612049395463, 'max_history_score': 0.85528670390001, 'max_history_score_std': 0.02213730791268438, 'max_history_step': 'joint', 'pipeline': {'features': ('features_SelectKBest', {'features__k': 4}), 'normalizer': ('normalizer_StandardScaler', {'normalizer__with_mean': True, 'normalizer__with_std': True}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 5})}, 'score': 0.3841387950604537, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'entropy', 'max_depth': 1, 'max_features': 1, 'max_leaf_nodes': 5, 'min_samples_split': 2, 'n_estimators': 100}, 'config_hash': {'algorithm': '896b53c75a2db568fb7b6da3bfca2f7a1535a11b', 'config': 'f0d0b1d2cedc22ae15d9a208a3fc3fc133bf0d3d', 'pipeline': 'c9761c9a33bf75d6dcad0742c421548a7655ccc9'}, 'duration': 2.297278881072998, 'iteration': 8, 'loss': 0.40673663548410355, 'max_history_score': 0.85528670390001, 'max_history_score_std': 0.02213730791268438, 'max_history_step': 'joint', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 2, 'features__selectkbest__k': 4}), 'normalizer': ('normalizer_StandardScaler', {'normalizer__with_mean': False, 'normalizer__with_std': False}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 5})}, 'score': 0.5932633645158965, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'entropy', 'max_depth': 2, 'max_features': None, 'max_leaf_nodes': None, 'min_samples_split': 5, 'n_estimators': 25}, 'config_hash': {'algorithm': '0b0e954757c4f75343a6efb740ad93260ed781ae', 'config': '47584de0e60d0d12c7dbbf0dc60e5aea96e3f4b2', 'pipeline': 'b37ee32d59413053bf9a2a72c8ff7135f3701e05'}, 'duration': 0.7249000072479248, 'iteration': 9, 'loss': 0.6965910020393421, 'max_history_score': 0.85528670390001, 'max_history_score_std': 0.02213730791268438, 'max_history_step': 'joint', 'pipeline': {'features': ('features_SelectKBest', {'features__k': 3}), 'normalizer': ('normalizer_NoneType', {}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 7})}, 'score': 0.3034089979606579, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'gini', 'max_depth': 2, 'max_features': 2, 'max_leaf_nodes': 5, 'min_samples_split': 5, 'n_estimators': 75}, 'config_hash': {'algorithm': 'f1ead1d9e33ea927e1dd27d872a058fa3de4f832', 'config': 'eecb88ee2b1b95d741c1b5c7751534d31aae6a77', 'pipeline': '6746650871e8b61efc9302b092dc05f7cdb179d5'}, 'duration': 5.340634822845459, 'iteration': 10, 'loss': 0.7687016290977936, 'max_history_score': 0.85528670390001, 'max_history_score_std': 0.02213730791268438, 'max_history_step': 'joint', 'pipeline': {'features': ('features_SelectKBest', {'features__k': 3}), 'normalizer': ('normalizer_RobustScaler', {'normalizer__quantile_range': (...), 'normalizer__with_centering': False, 'normalizer__with_scaling': False}), 'rebalance': ('rebalance_CondensedNearestNeighbour', {'rebalance__n_neighbors': 1})}, 'score': 0.23129837090220637, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': 1, 'max_features': 2, 'max_leaf_nodes': 2, 'min_samples_split': 3, 'n_estimators': 75}, 'config_hash': {'algorithm': '531a3bb8ccf0baa06727af4b3de9e62d25e6eabf', 'config': '27a7ed0502b321ab7256b77c8ce79e90cb9da815', 'pipeline': '77e6d84e2217b92b3cf67cc6defef9dd3554cec0'}, 'duration': 1.775357961654663, 'iteration': 11, 'loss': 0.6313818737375694, 'max_history_score': 0.85528670390001, 'max_history_score_std': 0.02213730791268438, 'max_history_step': 'joint', 'pipeline': {'features': ('features_SelectKBest', {'features__k': 4}), 'normalizer': ('normalizer_MinMaxScaler', {}), 'rebalance': ('rebalance_NearMiss', {'rebalance__n_neighbors': 3})}, 'score': 0.3686181262624307, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'entropy', 'max_depth': 4, 'max_features': 3, 'max_leaf_nodes': 2, 'min_samples_split': 3, 'n_estimators': 10}, 'config_hash': {'algorithm': '93518f8ded6074d537900b26be72f8485782f933', 'config': '45f056102dd2d644bd8befa471f17b2311ac7954', 'pipeline': '5240329df25c9a533d025c1a401d49835a501b41'}, 'duration': 3.2622711658477783, 'iteration': 12, 'loss': 0.6120243191353301, 'max_history_score': 0.85528670390001, 'max_history_score_std': 0.02213730791268438, 'max_history_step': 'joint', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 4, 'features__selectkbest__k': 2}), 'normalizer': ('normalizer_PowerTransformer', {}), 'rebalance': ('rebalance_NearMiss', {'rebalance__n_neighbors': 1})}, 'score': 0.38797568086467, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'entropy', 'max_depth': None, 'max_features': 1, 'max_leaf_nodes': 5, 'min_samples_split': 3, 'n_estimators': 75}, 'config_hash': {'algorithm': 'e515d45b764fa43591032874a0ff9c25bf12fddd', 'config': 'ba108323623936872824ed8f1c41d615d25523b3', 'pipeline': '9d823bc0442f21b5ce8af67a5eb1237f64ffc2f8'}, 'duration': 2.5326571464538574, 'iteration': 13, 'loss': 0.6271427382991047, 'max_history_score': 0.85528670390001, 'max_history_score_std': 0.02213730791268438, 'max_history_step': 'joint', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 1, 'features__selectkbest__k': 1}), 'normalizer': ('normalizer_StandardScaler', {'normalizer__with_mean': True, 'normalizer__with_std': True}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 5})}, 'score': 0.3728572617008953, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'entropy', 'max_depth': 3, 'max_features': 2, 'max_leaf_nodes': 2, 'min_samples_split': 3, 'n_estimators': 25}, 'config_hash': {'algorithm': '2808e67f609eba5c8a97f81ac0c9413cd37cf7aa', 'config': 'dde4d3b5f37741629cb58bfc4051ed9f98c8f311', 'pipeline': 'bc52deabf1f5ee60968ba541d9d2574353c30a9c'}, 'duration': 0.7145559787750244, 'iteration': 14, 'loss': 0.6831045572696203, 'max_history_score': 0.85528670390001, 'max_history_score_std': 0.02213730791268438, 'max_history_step': 'joint', 'pipeline': {'features': ('features_SelectKBest', {'features__k': 3}), 'normalizer': ('normalizer_MinMaxScaler', {}), 'rebalance': ('rebalance_NearMiss', {'rebalance__n_neighbors': 1})}, 'score': 0.31689544273037973, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'gini', 'max_depth': 2, 'max_features': 2, 'max_leaf_nodes': None, 'min_samples_split': 5, 'n_estimators': 100}, 'config_hash': {'algorithm': 'b942acdead762d34afeb474bc2fe6f7fd0f23493', 'config': '1080c25b92da3f15a6f8eec003957f7e0a66324f', 'pipeline': 'cfa84fe703dc5bc0bbd2257a6d524fee2693b804'}, 'duration': 2.812459945678711, 'iteration': 15, 'loss': 0.6921421091202761, 'max_history_score': 0.85528670390001, 'max_history_score_std': 0.02213730791268438, 'max_history_step': 'joint', 'pipeline': {'features': ('features_SelectKBest', {'features__k': 2}), 'normalizer': ('normalizer_PowerTransformer', {}), 'rebalance': ('rebalance_NoneType', {})}, 'score': 0.3078578908797239, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'entropy', 'max_depth': 2, 'max_features': 3, 'max_leaf_nodes': 3, 'min_samples_split': 2, 'n_estimators': 75}, 'config_hash': {'algorithm': '250661ce4193a61ef44d2f77694b52b785ff032d', 'config': 'c3e8cf4eca5aafcae4ac31b0449e105ca127ffe2', 'pipeline': 'c4dd111513ea35f97dd3aec3e8e7f6268ce035da'}, 'duration': 1.0555319786071777, 'iteration': 16, 'loss': 1.0, 'max_history_score': 0.85528670390001, 'max_history_score_std': 0.02213730791268438, 'max_history_step': 'joint', 'pipeline': {'features': ('features_PCA', {'features__n_components': 2}), 'normalizer': ('normalizer_RobustScaler', {'normalizer__quantile_range': (...), 'normalizer__with_centering': False, 'normalizer__with_scaling': True}), 'rebalance': ('rebalance_NearMiss', {'rebalance__n_neighbors': 2})}, 'score': 0.0, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'entropy', 'max_depth': 3, 'max_features': 3, 'max_leaf_nodes': None, 'min_samples_split': 3, 'n_estimators': 25}, 'config_hash': {'algorithm': '05ac02bd045c65dc4089894902ad6253661a2692', 'config': '3449b4a1c2e488e26a7195ee9edca19b854ebd33', 'pipeline': '505d3f71b534917375d765e64b0611e7dfb83746'}, 'duration': 5.5412821769714355, 'iteration': 17, 'loss': 0.7289151155121668, 'max_history_score': 0.85528670390001, 'max_history_score_std': 0.02213730791268438, 'max_history_step': 'joint', 'pipeline': {'features': ('features_SelectKBest', {'features__k': 4}), 'normalizer': ('normalizer_MinMaxScaler', {}), 'rebalance': ('rebalance_CondensedNearestNeighbour', {'rebalance__n_neighbors': 2})}, 'score': 0.2710848844878332, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'entropy', 'max_depth': 2, 'max_features': None, 'max_leaf_nodes': None, 'min_samples_split': 2, 'n_estimators': 25}, 'config_hash': {'algorithm': 'de3b3a352ebb260e16c6b213a08c9144d17a744b', 'config': '224987ffdbbb9b6182cff18d8374518b917e4f2e', 'pipeline': '12c89200a558b2f3b91332566f41050143aecbe7'}, 'duration': 2.4646048545837402, 'iteration': 18, 'loss': 0.6545902512995826, 'max_history_score': 0.85528670390001, 'max_history_score_std': 0.02213730791268438, 'max_history_step': 'joint', 'pipeline': {'features': ('features_NoneType', {}), 'normalizer': ('normalizer_PowerTransformer', {}), 'rebalance': ('rebalance_NearMiss', {'rebalance__n_neighbors': 2})}, 'score': 0.3454097487004174, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'gini', 'max_depth': None, 'max_features': 1, 'max_leaf_nodes': None, 'min_samples_split': 3, 'n_estimators': 100}, 'config_hash': {'algorithm': '30ca111584767bbf0464df40b4c928cf7ddf9459', 'config': '97ca7d6a017c721084dec2a5d2e5a67e1e6ae2f0', 'pipeline': '789eca82ea4a42d61927670c538867b745fd81d3'}, 'duration': 7.164499044418335, 'iteration': 19, 'loss': 0.6536825403350528, 'max_history_score': 0.85528670390001, 'max_history_score_std': 0.02213730791268438, 'max_history_step': 'joint', 'pipeline': {'features': ('features_SelectKBest', {'features__k': 3}), 'normalizer': ('normalizer_RobustScaler', {'normalizer__quantile_range': (...), 'normalizer__with_centering': False, 'normalizer__with_scaling': True}), 'rebalance': ('rebalance_CondensedNearestNeighbour', {'rebalance__n_neighbors': 3})}, 'score': 0.3463174596649472, ...}, ...], 'history_hash': ['fd24b065dda6bdeb1077793f9df480ff318c7a37', 'fb22f80fb4358ae1ee4c9bd4a83543992be8d806', '8c97cdb885dd05cfd8c40ee3ac445b61e5c767a8', '16fbb5fd5cfbbacfddf27c61c0c7397a7f6d8ade', 'a77c698197c31308211b854e81a998178941f87d', '1fc13606bca3aaf342ca6ea21139cb598b56f8db', '6749af1a67b4dbcd2b4719e419d99908063c05e1', 'd92d4ada2394fc132733e176e926ee53acdc6a00', 'f0d0b1d2cedc22ae15d9a208a3fc3fc133bf0d3d', '47584de0e60d0d12c7dbbf0dc60e5aea96e3f4b2', 'eecb88ee2b1b95d741c1b5c7751534d31aae6a77', '27a7ed0502b321ab7256b77c8ce79e90cb9da815', '45f056102dd2d644bd8befa471f17b2311ac7954', 'ba108323623936872824ed8f1c41d615d25523b3', 'dde4d3b5f37741629cb58bfc4051ed9f98c8f311', '1080c25b92da3f15a6f8eec003957f7e0a66324f', 'c3e8cf4eca5aafcae4ac31b0449e105ca127ffe2', '3449b4a1c2e488e26a7195ee9edca19b854ebd33', '224987ffdbbb9b6182cff18d8374518b917e4f2e', '97ca7d6a017c721084dec2a5d2e5a67e1e6ae2f0', ...], 'history_index': {'05465becb12810ce291074be22a0275a42efbea8': 52, '064f53edf4748bb2df4ff59f147331aad21219e1': 48, '087efef4a19f272562d2d445dac0edd8096ba2fa': 58, '0fd4d71ca3a89c7d14af5087f2a2e2c1b1975351': 51, '1080c25b92da3f15a6f8eec003957f7e0a66324f': 15, '143679b59e16961765e77616142572b6ded0ee72': 62, '151b4a15037767108da13dafa0b63ae93222e93a': 53, '16fbb5fd5cfbbacfddf27c61c0c7397a7f6d8ade': 3, '1fc13606bca3aaf342ca6ea21139cb598b56f8db': 5, '2187b0ebdd42d61eb93839b9a1592ae8707ce4c5': 42, ...}, 'iteration': 63, 'max_history_score': 0.85528670390001, 'max_history_score_std': 0.02213730791268438, 'max_history_step': 'joint'}, config={'algorithm': 'RandomForest', 'seed': 42, 'time': 300}, step='joint')
     45                 y,
     46                 cv=10,
     47                 n_jobs=-1,
     48                 return_estimator=False,
     49                 return_train_score=False,
---> 50                 verbose=0)
     51         score = np.mean(scores['test_score'])
     52         std = np.std(scores['test_score'])
     53         status = STATUS_OK
     54     except Exception as e:

...........................................................................
/home/aquemy/.local/lib/python2.7/site-packages/sklearn/model_selection/_validation.py in cross_validate(estimator=Pipeline(memory=None,
     steps=[('rebalance', ... random_state=42, verbose=0, warm_start=False))]), X=array([[ 0.,  0.,  5., ...,  0.,  0.,  0.],
    ...0.],
       [ 0.,  0., 10., ..., 12.,  1.,  0.]]), y=array([0, 1, 2, ..., 8, 9, 8]), groups=None, scoring=None, cv=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1, verbose=0, fit_params=None, pre_dispatch='2*n_jobs', return_train_score=False, return_estimator=False, error_score='raise-deprecating')
    235         delayed(_fit_and_score)(
    236             clone(estimator), X, y, scorers, train, test, verbose, None,
    237             fit_params, return_train_score=return_train_score,
    238             return_times=True, return_estimator=return_estimator,
    239             error_score=error_score)
--> 240         for train, test in cv.split(X, y, groups))
        cv.split = <bound method StratifiedKFold.split of Stratifie...d(n_splits=10, random_state=None, shuffle=False)>
        X = array([[ 0.,  0.,  5., ...,  0.,  0.,  0.],
    ...0.],
       [ 0.,  0., 10., ..., 12.,  1.,  0.]])
        y = array([0, 1, 2, ..., 8, 9, 8])
        groups = None
    241 
    242     zipped_scores = list(zip(*scores))
    243     if return_train_score:
    244         train_scores = zipped_scores.pop(0)

...........................................................................
/home/aquemy/.local/lib/python2.7/site-packages/sklearn/externals/joblib/parallel.py in __call__(self=Parallel(n_jobs=-1), iterable=<generator object <genexpr>>)
    925                 # No need to wait for async callbacks to trigger to
    926                 # consumption.
    927                 self._iterating = False
    928 
    929             with self._backend.retrieval_context():
--> 930                 self.retrieve()
        self.retrieve = <bound method Parallel.retrieve of Parallel(n_jobs=-1)>
    931             # Make sure that we get a last message telling us we are done
    932             elapsed_time = time.time() - self._start_time
    933             self._print('Done %3i out of %3i | elapsed: %s finished',
    934                         (len(self._output), len(self._output),

---------------------------------------------------------------------------
Joblib worker traceback:
---------------------------------------------------------------------------
ValueError                                         Mon Jun 17 13:08:11 2019
PID: 20248                                  Python 2.7.15+: /usr/bin/python
...........................................................................
/home/aquemy/.local/lib/python2.7/site-packages/sklearn/externals/joblib/parallel.py in __call__(self=<sklearn.externals.joblib.parallel.BatchedCalls object>)
    220     def __call__(self):
    221         # Set the default nested backend to self._backend but do not set the
    222         # change the default number of processes to -1
    223         with parallel_backend(self._backend, n_jobs=self._n_jobs):
    224             return [func(*args, **kwargs)
--> 225                     for func, args, kwargs in self.items]
        func = <function _fit_and_score>
        args = (Pipeline(memory=None,
     steps=[('rebalance', ... random_state=42, verbose=0, warm_start=False))]), array([[ 0.,  0.,  5., ...,  0.,  0.,  0.],
    ...0.],
       [ 0.,  0., 10., ..., 12.,  1.,  0.]]), array([0, 1, 2, ..., 8, 9, 8]), {'score': <function _passthrough_scorer>}, array([ 169,  176,  178, ..., 1794, 1795, 1796]), array([  0,   1,   2,   3,   4,   5,   6,   7,  ..., 181, 186, 188, 189, 190,
       194, 195, 198]), 0, None, None)
        kwargs = {'error_score': 'raise-deprecating', 'return_estimator': False, 'return_times': True, 'return_train_score': False}
        self.items = [(<function _fit_and_score>, (Pipeline(memory=None,
     steps=[('rebalance', ... random_state=42, verbose=0, warm_start=False))]), array([[ 0.,  0.,  5., ...,  0.,  0.,  0.],
    ...0.],
       [ 0.,  0., 10., ..., 12.,  1.,  0.]]), array([0, 1, 2, ..., 8, 9, 8]), {'score': <function _passthrough_scorer>}, array([ 169,  176,  178, ..., 1794, 1795, 1796]), array([  0,   1,   2,   3,   4,   5,   6,   7,  ..., 181, 186, 188, 189, 190,
       194, 195, 198]), 0, None, None), {'error_score': 'raise-deprecating', 'return_estimator': False, 'return_times': True, 'return_train_score': False})]
    226 
    227     def __len__(self):
    228         return self._size
    229 

...........................................................................
/home/aquemy/.local/lib/python2.7/site-packages/sklearn/model_selection/_validation.py in _fit_and_score(estimator=Pipeline(memory=None,
     steps=[('rebalance', ... random_state=42, verbose=0, warm_start=False))]), X=array([[ 0.,  0.,  5., ...,  0.,  0.,  0.],
    ...0.],
       [ 0.,  0., 10., ..., 12.,  1.,  0.]]), y=array([0, 1, 2, ..., 8, 9, 8]), scorer={'score': <function _passthrough_scorer>}, train=array([ 169,  176,  178, ..., 1794, 1795, 1796]), test=array([  0,   1,   2,   3,   4,   5,   6,   7,  ..., 181, 186, 188, 189, 190,
       194, 195, 198]), verbose=0, parameters=None, fit_params={}, return_train_score=False, return_parameters=False, return_n_test_samples=False, return_times=True, return_estimator=False, error_score='raise-deprecating')
    523 
    524     try:
    525         if y_train is None:
    526             estimator.fit(X_train, **fit_params)
    527         else:
--> 528             estimator.fit(X_train, y_train, **fit_params)
        estimator.fit = <bound method Pipeline.fit of Pipeline(memory=No...random_state=42, verbose=0, warm_start=False))])>
        X_train = array([[ 0.,  0.,  6., ...,  9.,  4.,  0.],
    ...0.],
       [ 0.,  0., 10., ..., 12.,  1.,  0.]])
        y_train = array([9, 5, 0, ..., 8, 9, 8])
        fit_params = {}
    529 
    530     except Exception as e:
    531         # Note fit time as time until error
    532         fit_time = time.time() - start_time

...........................................................................
/usr/local/lib/python2.7/dist-packages/imblearn/pipeline.py in fit(self=Pipeline(memory=None,
     steps=[('rebalance', ... random_state=42, verbose=0, warm_start=False))]), X=array([[ 0.,  0.,  6., ...,  9.,  4.,  0.],
    ...0.],
       [ 0.,  0., 10., ..., 12.,  1.,  0.]]), y=array([9, 5, 0, ..., 8, 9, 8]), **fit_params={})
    234             This estimator
    235 
    236         """
    237         Xt, yt, fit_params = self._fit(X, y, **fit_params)
    238         if self._final_estimator is not None:
--> 239             self._final_estimator.fit(Xt, yt, **fit_params)
        self._final_estimator.fit = <bound method RandomForestClassifier.fit of Rand...e, random_state=42, verbose=0, warm_start=False)>
        Xt = array([[ 4.],
       [ 8.],
       [ 2.],
      ...[ 0.],
       [ 0.],
       [ 0.],
       [ 0.]])
        yt = array([0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,...9, 9, 9,
       9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9])
        fit_params = {}
    240         return self
    241 
    242     def fit_transform(self, X, y=None, **fit_params):
    243         """Fit the model and transform with the final estimator

...........................................................................
/home/aquemy/.local/lib/python2.7/site-packages/sklearn/ensemble/forest.py in fit(self=RandomForestClassifier(bootstrap=True, class_wei...se, random_state=42, verbose=0, warm_start=False), X=array([[ 4.],
       [ 8.],
       [ 2.],
      ... 0.],
       [ 0.],
       [ 0.]], dtype=float32), y=array([[0.],
       [0.],
       [1.],
       [1...    [9.],
       [9.],
       [9.],
       [9.]]), sample_weight=None)
    328             trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,
    329                              **_joblib_parallel_args(prefer='threads'))(
    330                 delayed(_parallel_build_trees)(
    331                     t, self, X, y, sample_weight, i, len(trees),
    332                     verbose=self.verbose, class_weight=self.class_weight)
--> 333                 for i, t in enumerate(trees))
        i = 49
    334 
    335             # Collect newly grown trees
    336             self.estimators_.extend(trees)
    337 

...........................................................................
/home/aquemy/.local/lib/python2.7/site-packages/sklearn/externals/joblib/parallel.py in __call__(self=Parallel(n_jobs=1), iterable=<generator object <genexpr>>)
    912             # self._original_iterator is None, then this means either
    913             # that pre_dispatch == "all", n_jobs == 1 or that the first batch
    914             # was very quick and its callback already dispatched all the
    915             # remaining jobs.
    916             self._iterating = False
--> 917             if self.dispatch_one_batch(iterator):
        self.dispatch_one_batch = <bound method Parallel.dispatch_one_batch of Parallel(n_jobs=1)>
        iterator = <generator object <genexpr>>
    918                 self._iterating = self._original_iterator is not None
    919 
    920             while self.dispatch_one_batch(iterator):
    921                 pass

...........................................................................
/home/aquemy/.local/lib/python2.7/site-packages/sklearn/externals/joblib/parallel.py in dispatch_one_batch(self=Parallel(n_jobs=1), iterator=<generator object <genexpr>>)
    754                                  self._pickle_cache)
    755             if len(tasks) == 0:
    756                 # No more tasks available in the iterator: tell caller to stop.
    757                 return False
    758             else:
--> 759                 self._dispatch(tasks)
        self._dispatch = <bound method Parallel._dispatch of Parallel(n_jobs=1)>
        tasks = <sklearn.externals.joblib.parallel.BatchedCalls object>
    760                 return True
    761 
    762     def _print(self, msg, msg_args):
    763         """Display the message on stout or stderr depending on verbosity"""

...........................................................................
/home/aquemy/.local/lib/python2.7/site-packages/sklearn/externals/joblib/parallel.py in _dispatch(self=Parallel(n_jobs=1), batch=<sklearn.externals.joblib.parallel.BatchedCalls object>)
    711 
    712         dispatch_timestamp = time.time()
    713         cb = BatchCompletionCallBack(dispatch_timestamp, len(batch), self)
    714         with self._lock:
    715             job_idx = len(self._jobs)
--> 716             job = self._backend.apply_async(batch, callback=cb)
        job = undefined
        self._backend.apply_async = <bound method SequentialBackend.apply_async of <...lib._parallel_backends.SequentialBackend object>>
        batch = <sklearn.externals.joblib.parallel.BatchedCalls object>
        cb = <sklearn.externals.joblib.parallel.BatchCompletionCallBack object>
    717             # A job can complete so quickly than its callback is
    718             # called before we get here, causing self._jobs to
    719             # grow. To ensure correct results ordering, .insert is
    720             # used (rather than .append) in the following line

...........................................................................
/home/aquemy/.local/lib/python2.7/site-packages/sklearn/externals/joblib/_parallel_backends.py in apply_async(self=<sklearn.externals.joblib._parallel_backends.SequentialBackend object>, func=<sklearn.externals.joblib.parallel.BatchedCalls object>, callback=<sklearn.externals.joblib.parallel.BatchCompletionCallBack object>)
    177             raise ValueError('n_jobs == 0 in Parallel has no meaning')
    178         return 1
    179 
    180     def apply_async(self, func, callback=None):
    181         """Schedule a func to be run"""
--> 182         result = ImmediateResult(func)
        result = undefined
        func = <sklearn.externals.joblib.parallel.BatchedCalls object>
    183         if callback:
    184             callback(result)
    185         return result
    186 

...........................................................................
/home/aquemy/.local/lib/python2.7/site-packages/sklearn/externals/joblib/_parallel_backends.py in __init__(self=<sklearn.externals.joblib._parallel_backends.ImmediateResult object>, batch=<sklearn.externals.joblib.parallel.BatchedCalls object>)
    544 
    545 class ImmediateResult(object):
    546     def __init__(self, batch):
    547         # Don't delay the application, to avoid keeping the input
    548         # arguments in memory
--> 549         self.results = batch()
        self.results = undefined
        batch = <sklearn.externals.joblib.parallel.BatchedCalls object>
    550 
    551     def get(self):
    552         return self.results
    553 

...........................................................................
/home/aquemy/.local/lib/python2.7/site-packages/sklearn/externals/joblib/parallel.py in __call__(self=<sklearn.externals.joblib.parallel.BatchedCalls object>)
    220     def __call__(self):
    221         # Set the default nested backend to self._backend but do not set the
    222         # change the default number of processes to -1
    223         with parallel_backend(self._backend, n_jobs=self._n_jobs):
    224             return [func(*args, **kwargs)
--> 225                     for func, args, kwargs in self.items]
        func = <function _parallel_build_trees>
        args = (DecisionTreeClassifier(class_weight=None, criter...=False, random_state=1608637542, splitter='best'), RandomForestClassifier(bootstrap=True, class_wei...se, random_state=42, verbose=0, warm_start=False), array([[ 4.],
       [ 8.],
       [ 2.],
      ... 0.],
       [ 0.],
       [ 0.]], dtype=float32), array([[0.],
       [0.],
       [1.],
       [1...    [9.],
       [9.],
       [9.],
       [9.]]), None, 0, 50)
        kwargs = {'class_weight': None, 'verbose': 0}
        self.items = [(<function _parallel_build_trees>, (DecisionTreeClassifier(class_weight=None, criter...=False, random_state=1608637542, splitter='best'), RandomForestClassifier(bootstrap=True, class_wei...se, random_state=42, verbose=0, warm_start=False), array([[ 4.],
       [ 8.],
       [ 2.],
      ... 0.],
       [ 0.],
       [ 0.]], dtype=float32), array([[0.],
       [0.],
       [1.],
       [1...    [9.],
       [9.],
       [9.],
       [9.]]), None, 0, 50), {'class_weight': None, 'verbose': 0})]
    226 
    227     def __len__(self):
    228         return self._size
    229 

...........................................................................
/home/aquemy/.local/lib/python2.7/site-packages/sklearn/ensemble/forest.py in _parallel_build_trees(tree=DecisionTreeClassifier(class_weight=None, criter...=False, random_state=1608637542, splitter='best'), forest=RandomForestClassifier(bootstrap=True, class_wei...se, random_state=42, verbose=0, warm_start=False), X=array([[ 4.],
       [ 8.],
       [ 2.],
      ... 0.],
       [ 0.],
       [ 0.]], dtype=float32), y=array([[0.],
       [0.],
       [1.],
       [1...    [9.],
       [9.],
       [9.],
       [9.]]), sample_weight=None, tree_idx=0, n_trees=50, verbose=0, class_weight=None)
    114                 simplefilter('ignore', DeprecationWarning)
    115                 curr_sample_weight *= compute_sample_weight('auto', y, indices)
    116         elif class_weight == 'balanced_subsample':
    117             curr_sample_weight *= compute_sample_weight('balanced', y, indices)
    118 
--> 119         tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)
        tree.fit = <bound method DecisionTreeClassifier.fit of Deci...False, random_state=1608637542, splitter='best')>
        X = array([[ 4.],
       [ 8.],
       [ 2.],
      ... 0.],
       [ 0.],
       [ 0.]], dtype=float32)
        y = array([[0.],
       [0.],
       [1.],
       [1...    [9.],
       [9.],
       [9.],
       [9.]])
        sample_weight = None
        curr_sample_weight = array([3., 3., 0., 1., 1., 2., 2., 0., 1., 2., 0... 2., 2., 2., 2., 2., 0., 0., 0., 2., 0., 2., 0.])
    120     else:
    121         tree.fit(X, y, sample_weight=sample_weight, check_input=False)
    122 
    123     return tree

...........................................................................
/home/aquemy/.local/lib/python2.7/site-packages/sklearn/tree/tree.py in fit(self=DecisionTreeClassifier(class_weight=None, criter...=False, random_state=1608637542, splitter='best'), X=array([[ 4.],
       [ 8.],
       [ 2.],
      ... 0.],
       [ 0.],
       [ 0.]], dtype=float32), y=array([[0.],
       [0.],
       [1.],
       [1...    [9.],
       [9.],
       [9.],
       [9.]]), sample_weight=array([3., 3., 0., 1., 1., 2., 2., 0., 1., 2., 0... 2., 2., 2., 2., 2., 0., 0., 0., 2., 0., 2., 0.]), check_input=False, X_idx_sorted=None)
    796 
    797         super(DecisionTreeClassifier, self).fit(
    798             X, y,
    799             sample_weight=sample_weight,
    800             check_input=check_input,
--> 801             X_idx_sorted=X_idx_sorted)
        X_idx_sorted = None
    802         return self
    803 
    804     def predict_proba(self, X, check_input=True):
    805         """Predict class probabilities of the input samples X.

...........................................................................
/home/aquemy/.local/lib/python2.7/site-packages/sklearn/tree/tree.py in fit(self=DecisionTreeClassifier(class_weight=None, criter...=False, random_state=1608637542, splitter='best'), X=array([[ 4.],
       [ 8.],
       [ 2.],
      ... 0.],
       [ 0.],
       [ 0.]], dtype=float32), y=array([[0.],
       [0.],
       [1.],
       [1...    [9.],
       [9.],
       [9.],
       [9.]]), sample_weight=array([3., 3., 0., 1., 1., 2., 2., 0., 1., 2., 0... 2., 2., 2., 2., 2., 0., 0., 0., 2., 0., 2., 0.]), check_input=False, X_idx_sorted=None)
    237         if not 0 <= self.min_weight_fraction_leaf <= 0.5:
    238             raise ValueError("min_weight_fraction_leaf must in [0, 0.5]")
    239         if max_depth <= 0:
    240             raise ValueError("max_depth must be greater than zero. ")
    241         if not (0 < max_features <= self.n_features_):
--> 242             raise ValueError("max_features must be in (0, n_features]")
    243         if not isinstance(max_leaf_nodes, (numbers.Integral, np.integer)):
    244             raise ValueError("max_leaf_nodes must be integral number but was "
    245                              "%r" % max_leaf_nodes)
    246         if -1 < max_leaf_nodes < 2:

ValueError: max_features must be in (0, n_features]
___________________________________________________________________________
Best score: 0.8552867039 (0.0221373079127) [J] | Score: 0.0 (0.0) [J]
Best score: 0.923190438404 (0.030405158842) [J] | Score: 0.923190438404 (0.030405158842) [J]
Best score: 0.923190438404 (0.030405158842) [J] | Score: 0.695066830739 (0.0498615585358) [J]
Best score: 0.923190438404 (0.030405158842) [J] | Score: 0.821817155451 (0.0430063038218) [J]
Best score: 0.923190438404 (0.030405158842) [J] | Score: 0.653411808702 (0.0296992337038) [J]
Best score: 0.923190438404 (0.030405158842) [J] | Score: 0.343699839327 (0.0316140171382) [J]
Best score: 0.923190438404 (0.030405158842) [J] | Score: 0.818736294004 (0.0506499760993) [J]
Best score: 0.923190438404 (0.030405158842) [J] | Score: 0.557688582125 (0.0542219817134) [J]
Best score: 0.923190438404 (0.030405158842) [J] | Score: 0.0968163392773 (0.00179561960358) [J]
Best score: 0.923190438404 (0.030405158842) [J] | Score: 0.709163779833 (0.0612165690865) [J]
Best score: 0.923190438404 (0.030405158842) [J] | Score: 0.662529184167 (0.0358420816311) [J]
Best score: 0.923190438404 (0.030405158842) [J] | Score: 0.666217123434 (0.0492378150725) [J]
JoblibValueError
___________________________________________________________________________
...........................................................................
/home/aquemy/dev/dp_hyperparameters/extension/main.py in <module>()
     27 
     28     serializer.serialize_results(scenario, policy)
     29 
     30 if __name__ == "__main__":
     31     args = cli.parse_args()
---> 32     main(args)

...........................................................................
/home/aquemy/dev/dp_hyperparameters/extension/main.py in main(args=Namespace(customize=[(['control', 'seed'], '42')...='./scenarios/rf_digits_joint.yaml', verbosity=0))
     21         test_size=0.4, 
     22         random_state=scenario['control']['seed']
     23     )
     24 
     25     policy = policies.initiate(scenario['setup']['policy'], config)
---> 26     policy.run(X,y)
        policy.run = <bound method Joint.run of <experiment.policies.joint.Joint object>>
        X = array([[ 0.,  0.,  5., ...,  0.,  0.,  0.],
    ...0.],
       [ 0.,  0., 10., ..., 12.,  1.,  0.]])
        y = array([0, 1, 2, ..., 8, 9, 8])
     27 
     28     serializer.serialize_results(scenario, policy)
     29 
     30 if __name__ == "__main__":

...........................................................................
/home/aquemy/dev/dp_hyperparameters/extension/experiment/policies/joint.py in run(self=<experiment.policies.joint.Joint object>, X=array([[ 0.,  0.,  5., ...,  0.,  0.,  0.],
    ...0.],
       [ 0.,  0., 10., ..., 12.,  1.,  0.]]), y=array([0, 1, 2, ..., 8, 9, 8]))
     32             algo=tpe.suggest, 
     33             max_evals=None,
     34             max_time=self.config['time'],     
     35             trials=trials,
     36             show_progressbar=False,
---> 37             verbose=0
     38         )
     39 
     40         best_config = self.context['best_config']
     41         super(Joint, self).display_step_results(best_config)

...........................................................................
/home/aquemy/dev/dp_hyperparameters/extension/hyperopt/fmin.py in fmin(fn=<functools.partial object>, space={'algorithm': {'bootstrap': <hyperopt.pyll.base.Apply object>, 'criterion': <hyperopt.pyll.base.Apply object>, 'max_depth': <hyperopt.pyll.base.Apply object>, 'max_features': <hyperopt.pyll.base.Apply object>, 'max_leaf_nodes': <hyperopt.pyll.base.Apply object>, 'min_samples_split': <hyperopt.pyll.base.Apply object>, 'n_estimators': <hyperopt.pyll.base.Apply object>}, 'pipeline': {'features': <hyperopt.pyll.base.Apply object>, 'normalizer': <hyperopt.pyll.base.Apply object>, 'rebalance': <hyperopt.pyll.base.Apply object>}}, algo=<function suggest>, max_evals=9223372036854775807, max_time=300, trials=<hyperopt.base.Trials object>, rstate=<mtrand.RandomState object>, allow_trials_fmin=True, pass_expr_memo_ctrl=None, catch_eval_exceptions=False, verbose=0, return_argmin=True, points_to_evaluate=None, max_queue_len=1, show_progressbar=False)
    406             pass_expr_memo_ctrl=pass_expr_memo_ctrl,
    407             verbose=verbose,
    408             catch_eval_exceptions=catch_eval_exceptions,
    409             return_argmin=return_argmin,
    410             show_progressbar=show_progressbar,
--> 411             max_time=max_time
        max_time = 300
    412         )
    413 
    414     if trials is None:
    415         if points_to_evaluate is None:

...........................................................................
/home/aquemy/dev/dp_hyperparameters/extension/hyperopt/base.py in fmin(self=<hyperopt.base.Trials object>, fn=<functools.partial object>, space={'algorithm': {'bootstrap': <hyperopt.pyll.base.Apply object>, 'criterion': <hyperopt.pyll.base.Apply object>, 'max_depth': <hyperopt.pyll.base.Apply object>, 'max_features': <hyperopt.pyll.base.Apply object>, 'max_leaf_nodes': <hyperopt.pyll.base.Apply object>, 'min_samples_split': <hyperopt.pyll.base.Apply object>, 'n_estimators': <hyperopt.pyll.base.Apply object>}, 'pipeline': {'features': <hyperopt.pyll.base.Apply object>, 'normalizer': <hyperopt.pyll.base.Apply object>, 'rebalance': <hyperopt.pyll.base.Apply object>}}, algo=<function suggest>, max_evals=9223372036854775807, max_time=300, rstate=<mtrand.RandomState object>, verbose=0, pass_expr_memo_ctrl=None, catch_eval_exceptions=False, return_argmin=True, show_progressbar=False)
    636             verbose=verbose,
    637             allow_trials_fmin=False,  # -- prevent recursion
    638             pass_expr_memo_ctrl=pass_expr_memo_ctrl,
    639             catch_eval_exceptions=catch_eval_exceptions,
    640             return_argmin=return_argmin,
--> 641             show_progressbar=show_progressbar)
        show_progressbar = False
    642 
    643 
    644 def trials_from_docs(docs, validate=True, **kwargs):
    645     """Construct a Trials base class instance from a list of trials documents

...........................................................................
/home/aquemy/dev/dp_hyperparameters/extension/hyperopt/fmin.py in fmin(fn=<functools.partial object>, space={'algorithm': {'bootstrap': <hyperopt.pyll.base.Apply object>, 'criterion': <hyperopt.pyll.base.Apply object>, 'max_depth': <hyperopt.pyll.base.Apply object>, 'max_features': <hyperopt.pyll.base.Apply object>, 'max_leaf_nodes': <hyperopt.pyll.base.Apply object>, 'min_samples_split': <hyperopt.pyll.base.Apply object>, 'n_estimators': <hyperopt.pyll.base.Apply object>}, 'pipeline': {'features': <hyperopt.pyll.base.Apply object>, 'normalizer': <hyperopt.pyll.base.Apply object>, 'rebalance': <hyperopt.pyll.base.Apply object>}}, algo=<function suggest>, max_evals=9223372036854775807, max_time=300, trials=<hyperopt.base.Trials object>, rstate=<mtrand.RandomState object>, allow_trials_fmin=False, pass_expr_memo_ctrl=None, catch_eval_exceptions=False, verbose=0, return_argmin=True, points_to_evaluate=None, max_queue_len=1, show_progressbar=False)
    426                     verbose=verbose,
    427                     max_queue_len=max_queue_len,
    428                     show_progressbar=show_progressbar,
    429                     max_time=max_time)
    430     rval.catch_eval_exceptions = catch_eval_exceptions
--> 431     rval.exhaust()
        rval.exhaust = <bound method FMinIter.exhaust of <hyperopt.fmin.FMinIter object>>
    432     if return_argmin:
    433         return trials.argmin
    434     elif len(trials) > 0:
    435         # Only if there are some succesfull trail runs, return the best point in the evaluation space

...........................................................................
/home/aquemy/dev/dp_hyperparameters/extension/hyperopt/fmin.py in exhaust(self=<hyperopt.fmin.FMinIter object>)
    273             raise StopIteration()
    274         return self.trials
    275 
    276     def exhaust(self):
    277         n_done = len(self.trials)
--> 278         self.run(self.max_evals - n_done, block_until_done=self.asynchronous)
        self.run = <bound method FMinIter.run of <hyperopt.fmin.FMinIter object>>
        self.max_evals = 9223372036854775807
        n_done = 0
        self.asynchronous = False
    279         self.trials.refresh()
    280         return self
    281 
    282 

...........................................................................
/home/aquemy/dev/dp_hyperparameters/extension/hyperopt/fmin.py in run(self=<hyperopt.fmin.FMinIter object>, N=9223372036854775807, block_until_done=False)
    232                     if self.asynchronous:
    233                         # -- wait for workers to fill in the trials
    234                         time.sleep(self.poll_interval_secs)
    235                     else:
    236                         # -- loop over trials and do the jobs directly
--> 237                         self.serial_evaluate()
        self.serial_evaluate = <bound method FMinIter.serial_evaluate of <hyperopt.fmin.FMinIter object>>
    238                     try:
    239                         res = [d['result']['loss'] for d in
    240                                          self.trials.trials if
    241                                          d['result']['status'] == 'ok']

...........................................................................
/home/aquemy/dev/dp_hyperparameters/extension/hyperopt/fmin.py in serial_evaluate(self=<hyperopt.fmin.FMinIter object>, N=-1)
    138                 trial['book_time'] = now
    139                 trial['refresh_time'] = now
    140                 spec = base.spec_from_misc(trial['misc'])
    141                 ctrl = base.Ctrl(self.trials, current_trial=trial)
    142                 try:
--> 143                     result = self.domain.evaluate(spec, ctrl)
        result = undefined
        self.domain.evaluate = <bound method Domain.evaluate of <hyperopt.base.Domain object>>
        spec = {'bootstrap': 0, 'criterion': 1, 'features': 2, 'features_SelectKBest_features__k': 0, 'max_depth': 4, 'max_features': 1, 'max_leaf_nodes': 2, 'min_samples_split': 1, 'n_estimators': 1, 'normalizer': 2, ...}
        ctrl = <hyperopt.base.Ctrl object>
    144                 except Exception as e:
    145                     logger.info('job exception: %s' % str(e))
    146                     trial['state'] = base.JOB_STATE_ERROR
    147                     trial['misc']['error'] = (str(type(e)), str(e))

...........................................................................
/home/aquemy/dev/dp_hyperparameters/extension/hyperopt/base.py in evaluate(self=<hyperopt.base.Domain object>, config={'bootstrap': 0, 'criterion': 1, 'features': 2, 'features_SelectKBest_features__k': 0, 'max_depth': 4, 'max_features': 1, 'max_leaf_nodes': 2, 'min_samples_split': 1, 'n_estimators': 1, 'normalizer': 2, ...}, ctrl=<hyperopt.base.Ctrl object>, attach_attachments=True)
    841             #    or the normal Python part (self.fn)
    842             pyll_rval = pyll.rec_eval(
    843                 self.expr,
    844                 memo=memo,
    845                 print_node_on_error=self.rec_eval_print_node_on_error)
--> 846             rval = self.fn(pyll_rval)
        rval = undefined
        self.fn = <functools.partial object>
        pyll_rval = {'algorithm': {'bootstrap': True, 'criterion': 'entropy', 'max_depth': None, 'max_features': 2, 'max_leaf_nodes': 5, 'min_samples_split': 3, 'n_estimators': 25}, 'pipeline': {'features': ('features_SelectKBest', {'features__k': 1}), 'normalizer': ('normalizer_PowerTransformer', {}), 'rebalance': ('rebalance_NearMiss', {'rebalance__n_neighbors': 1})}}
    847 
    848         if isinstance(rval, (float, int, np.number)):
    849             dict_rval = {'loss': float(rval), 'status': STATUS_OK}
    850         else:

...........................................................................
/home/aquemy/dev/dp_hyperparameters/extension/experiment/objective.py in objective_joint(wconfig={'algorithm': {'bootstrap': True, 'criterion': 'entropy', 'max_depth': None, 'max_features': 2, 'max_leaf_nodes': 5, 'min_samples_split': 3, 'n_estimators': 25}, 'pipeline': {'features': ('features_SelectKBest', {'features__k': 1}), 'normalizer': ('normalizer_PowerTransformer', {}), 'rebalance': ('rebalance_NearMiss', {'rebalance__n_neighbors': 1})}}, algorithm='RandomForest', X=array([[ 0.,  0.,  5., ...,  0.,  0.,  0.],
    ...0.],
       [ 0.,  0., 10., ..., 12.,  1.,  0.]]), y=array([0, 1, 2, ..., 8, 9, 8]), context={'baseline_score': 0.9272021217853512, 'baseline_score_std': 0.026919033284817703, 'best_config': {'algorithm': {'bootstrap': True, 'criterion': 'entropy', 'max_depth': None, 'max_features': None, 'max_leaf_nodes': None, 'min_samples_split': 3, 'n_estimators': 75}, 'config_hash': {'algorithm': 'f42e45bee34ac9973699212f6c8b845daea9383a', 'config': 'ae61cfde4c8b4c792e42d6b6be4af4ffb3d90e13', 'pipeline': '15ff3d6270ac899763bb3f72417c48bcd56aa7d8'}, 'duration': 8.20555305480957, 'iteration': 65, 'loss': 0.07680956159632557, 'max_history_score': 0.9231904384036744, 'max_history_score_std': 0.03040515884196498, 'max_history_step': 'joint', 'pipeline': {'features': ('features_NoneType', {}), 'normalizer': ('normalizer_StandardScaler', {'normalizer__with_mean': True, 'normalizer__with_std': True}), 'rebalance': ('rebalance_NearMiss', {'rebalance__n_neighbors': 1})}, 'score': 0.9231904384036744, ...}, 'history': [{'algorithm': {'bootstrap': False, 'criterion': 'entropy', 'max_depth': 1, 'max_features': 3, 'max_leaf_nodes': 3, 'min_samples_split': 5, 'n_estimators': 50}, 'config_hash': {'algorithm': '752fa095cdab58a238ae606c613606188964cc0c', 'config': 'fd24b065dda6bdeb1077793f9df480ff318c7a37', 'pipeline': '13ea3359c453b8993fcec1e88bc0e19cd0a2b112'}, 'duration': 0.689669132232666, 'iteration': 0, 'loss': 0.6602879519109309, 'max_history_score': 0.3397120480890691, 'max_history_score_std': 0.03346542949100545, 'max_history_step': 'joint', 'pipeline': {'features': ('features_SelectKBest', {'features__k': 4}), 'normalizer': ('normalizer_MinMaxScaler', {}), 'rebalance': ('rebalance_NoneType', {})}, 'score': 0.3397120480890691, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'gini', 'max_depth': 4, 'max_features': 1, 'max_leaf_nodes': 5, 'min_samples_split': 3, 'n_estimators': 25}, 'config_hash': {'algorithm': '9d9de4aee820052ddfe83bfffca420f6b50837d3', 'config': 'fb22f80fb4358ae1ee4c9bd4a83543992be8d806', 'pipeline': '6251ad4bb7a110726a67f90c319f4717ac37a312'}, 'duration': 1.4300940036773682, 'iteration': 1, 'loss': 0.5122196101741096, 'max_history_score': 0.48778038982589045, 'max_history_score_std': 0.05486079759217226, 'max_history_step': 'joint', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 2, 'features__selectkbest__k': 2}), 'normalizer': ('normalizer_StandardScaler', {'normalizer__with_mean': True, 'normalizer__with_std': True}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 5})}, 'score': 0.48778038982589045, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': 4, 'max_features': 1, 'max_leaf_nodes': None, 'min_samples_split': 2, 'n_estimators': 10}, 'config_hash': {'algorithm': '2ed7d27df9a1b2d5e63da76f7cb309616c232022', 'config': '8c97cdb885dd05cfd8c40ee3ac445b61e5c767a8', 'pipeline': 'c0abb5e23a4739d3120740a9519fb36c43eb94d5'}, 'duration': 3.0036678314208984, 'iteration': 2, 'loss': 0.38319264175312906, 'max_history_score': 0.6168073582468709, 'max_history_score_std': 0.05286679173001824, 'max_history_step': 'joint', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 1, 'features__selectkbest__k': 4}), 'normalizer': ('normalizer_PowerTransformer', {}), 'rebalance': ('rebalance_NearMiss', {'rebalance__n_neighbors': 2})}, 'score': 0.6168073582468709, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'entropy', 'max_depth': None, 'max_features': None, 'max_leaf_nodes': 2, 'min_samples_split': 2, 'n_estimators': 100}, 'config_hash': {'algorithm': '17962655e3b76dfcd0843d1e5c2cb7a9db1c6a79', 'config': '16fbb5fd5cfbbacfddf27c61c0c7397a7f6d8ade', 'pipeline': '13ea3359c453b8993fcec1e88bc0e19cd0a2b112'}, 'duration': 1.3447980880737305, 'iteration': 3, 'loss': 0.6768840987778313, 'max_history_score': 0.6168073582468709, 'max_history_score_std': 0.05286679173001824, 'max_history_step': 'joint', 'pipeline': {'features': ('features_SelectKBest', {'features__k': 4}), 'normalizer': ('normalizer_MinMaxScaler', {}), 'rebalance': ('rebalance_NoneType', {})}, 'score': 0.32311590122216866, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'gini', 'max_depth': 2, 'max_features': 2, 'max_leaf_nodes': 2, 'min_samples_split': 3, 'n_estimators': 100}, 'config_hash': {'algorithm': '1ea8965b2247f86950e54510ee6d79399816341b', 'config': 'a77c698197c31308211b854e81a998178941f87d', 'pipeline': 'aaf976c7c663a31fa039582d42f9e07101556a7c'}, 'duration': 2.589430093765259, 'iteration': 4, 'loss': 0.2544808950572157, 'max_history_score': 0.7455191049427843, 'max_history_score_std': 0.04843448308166839, 'max_history_step': 'joint', 'pipeline': {'features': ('features_NoneType', {}), 'normalizer': ('normalizer_PowerTransformer', {}), 'rebalance': ('rebalance_NoneType', {})}, 'score': 0.7455191049427843, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': None, 'max_features': 2, 'max_leaf_nodes': 5, 'min_samples_split': 5, 'n_estimators': 25}, 'config_hash': {'algorithm': 'fd8aeb6a05eaaba41e676d60596c8e0c71b35e0c', 'config': '1fc13606bca3aaf342ca6ea21139cb598b56f8db', 'pipeline': 'f00bd8de05642e026bbba4ad20d3a60088c86b6c'}, 'duration': 1.8779079914093018, 'iteration': 5, 'loss': 0.531551018758381, 'max_history_score': 0.7455191049427843, 'max_history_score_std': 0.04843448308166839, 'max_history_step': 'joint', 'pipeline': {'features': ('features_PCA', {'features__n_components': 2}), 'normalizer': ('normalizer_MinMaxScaler', {}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 5})}, 'score': 0.46844898124161904, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'entropy', 'max_depth': None, 'max_features': 2, 'max_leaf_nodes': None, 'min_samples_split': 2, 'n_estimators': 10}, 'config_hash': {'algorithm': 'a49ecb99e74217d6812f98ead7bc9d1fe4a53ba0', 'config': '6749af1a67b4dbcd2b4719e419d99908063c05e1', 'pipeline': '19bdf19a2eec5febce95ab8fa2a71040d75114aa'}, 'duration': 1.5498578548431396, 'iteration': 6, 'loss': 0.14471329609998995, 'max_history_score': 0.85528670390001, 'max_history_score_std': 0.02213730791268438, 'max_history_step': 'joint', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 4, 'features__selectkbest__k': 3}), 'normalizer': ('normalizer_NoneType', {}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 7})}, 'score': 0.85528670390001, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': 1, 'max_features': 3, 'max_leaf_nodes': 3, 'min_samples_split': 3, 'n_estimators': 75}, 'config_hash': {'algorithm': 'ebfb16234172ae811ff21185ff92bbdbb8f32f14', 'config': 'd92d4ada2394fc132733e176e926ee53acdc6a00', 'pipeline': '8071e7cbf86a5c3056493dc3aa40063aeb28cdfe'}, 'duration': 1.3618149757385254, 'iteration': 7, 'loss': 0.6158612049395463, 'max_history_score': 0.85528670390001, 'max_history_score_std': 0.02213730791268438, 'max_history_step': 'joint', 'pipeline': {'features': ('features_SelectKBest', {'features__k': 4}), 'normalizer': ('normalizer_StandardScaler', {'normalizer__with_mean': True, 'normalizer__with_std': True}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 5})}, 'score': 0.3841387950604537, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'entropy', 'max_depth': 1, 'max_features': 1, 'max_leaf_nodes': 5, 'min_samples_split': 2, 'n_estimators': 100}, 'config_hash': {'algorithm': '896b53c75a2db568fb7b6da3bfca2f7a1535a11b', 'config': 'f0d0b1d2cedc22ae15d9a208a3fc3fc133bf0d3d', 'pipeline': 'c9761c9a33bf75d6dcad0742c421548a7655ccc9'}, 'duration': 2.297278881072998, 'iteration': 8, 'loss': 0.40673663548410355, 'max_history_score': 0.85528670390001, 'max_history_score_std': 0.02213730791268438, 'max_history_step': 'joint', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 2, 'features__selectkbest__k': 4}), 'normalizer': ('normalizer_StandardScaler', {'normalizer__with_mean': False, 'normalizer__with_std': False}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 5})}, 'score': 0.5932633645158965, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'entropy', 'max_depth': 2, 'max_features': None, 'max_leaf_nodes': None, 'min_samples_split': 5, 'n_estimators': 25}, 'config_hash': {'algorithm': '0b0e954757c4f75343a6efb740ad93260ed781ae', 'config': '47584de0e60d0d12c7dbbf0dc60e5aea96e3f4b2', 'pipeline': 'b37ee32d59413053bf9a2a72c8ff7135f3701e05'}, 'duration': 0.7249000072479248, 'iteration': 9, 'loss': 0.6965910020393421, 'max_history_score': 0.85528670390001, 'max_history_score_std': 0.02213730791268438, 'max_history_step': 'joint', 'pipeline': {'features': ('features_SelectKBest', {'features__k': 3}), 'normalizer': ('normalizer_NoneType', {}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 7})}, 'score': 0.3034089979606579, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'gini', 'max_depth': 2, 'max_features': 2, 'max_leaf_nodes': 5, 'min_samples_split': 5, 'n_estimators': 75}, 'config_hash': {'algorithm': 'f1ead1d9e33ea927e1dd27d872a058fa3de4f832', 'config': 'eecb88ee2b1b95d741c1b5c7751534d31aae6a77', 'pipeline': '6746650871e8b61efc9302b092dc05f7cdb179d5'}, 'duration': 5.340634822845459, 'iteration': 10, 'loss': 0.7687016290977936, 'max_history_score': 0.85528670390001, 'max_history_score_std': 0.02213730791268438, 'max_history_step': 'joint', 'pipeline': {'features': ('features_SelectKBest', {'features__k': 3}), 'normalizer': ('normalizer_RobustScaler', {'normalizer__quantile_range': (...), 'normalizer__with_centering': False, 'normalizer__with_scaling': False}), 'rebalance': ('rebalance_CondensedNearestNeighbour', {'rebalance__n_neighbors': 1})}, 'score': 0.23129837090220637, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': 1, 'max_features': 2, 'max_leaf_nodes': 2, 'min_samples_split': 3, 'n_estimators': 75}, 'config_hash': {'algorithm': '531a3bb8ccf0baa06727af4b3de9e62d25e6eabf', 'config': '27a7ed0502b321ab7256b77c8ce79e90cb9da815', 'pipeline': '77e6d84e2217b92b3cf67cc6defef9dd3554cec0'}, 'duration': 1.775357961654663, 'iteration': 11, 'loss': 0.6313818737375694, 'max_history_score': 0.85528670390001, 'max_history_score_std': 0.02213730791268438, 'max_history_step': 'joint', 'pipeline': {'features': ('features_SelectKBest', {'features__k': 4}), 'normalizer': ('normalizer_MinMaxScaler', {}), 'rebalance': ('rebalance_NearMiss', {'rebalance__n_neighbors': 3})}, 'score': 0.3686181262624307, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'entropy', 'max_depth': 4, 'max_features': 3, 'max_leaf_nodes': 2, 'min_samples_split': 3, 'n_estimators': 10}, 'config_hash': {'algorithm': '93518f8ded6074d537900b26be72f8485782f933', 'config': '45f056102dd2d644bd8befa471f17b2311ac7954', 'pipeline': '5240329df25c9a533d025c1a401d49835a501b41'}, 'duration': 3.2622711658477783, 'iteration': 12, 'loss': 0.6120243191353301, 'max_history_score': 0.85528670390001, 'max_history_score_std': 0.02213730791268438, 'max_history_step': 'joint', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 4, 'features__selectkbest__k': 2}), 'normalizer': ('normalizer_PowerTransformer', {}), 'rebalance': ('rebalance_NearMiss', {'rebalance__n_neighbors': 1})}, 'score': 0.38797568086467, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'entropy', 'max_depth': None, 'max_features': 1, 'max_leaf_nodes': 5, 'min_samples_split': 3, 'n_estimators': 75}, 'config_hash': {'algorithm': 'e515d45b764fa43591032874a0ff9c25bf12fddd', 'config': 'ba108323623936872824ed8f1c41d615d25523b3', 'pipeline': '9d823bc0442f21b5ce8af67a5eb1237f64ffc2f8'}, 'duration': 2.5326571464538574, 'iteration': 13, 'loss': 0.6271427382991047, 'max_history_score': 0.85528670390001, 'max_history_score_std': 0.02213730791268438, 'max_history_step': 'joint', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 1, 'features__selectkbest__k': 1}), 'normalizer': ('normalizer_StandardScaler', {'normalizer__with_mean': True, 'normalizer__with_std': True}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 5})}, 'score': 0.3728572617008953, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'entropy', 'max_depth': 3, 'max_features': 2, 'max_leaf_nodes': 2, 'min_samples_split': 3, 'n_estimators': 25}, 'config_hash': {'algorithm': '2808e67f609eba5c8a97f81ac0c9413cd37cf7aa', 'config': 'dde4d3b5f37741629cb58bfc4051ed9f98c8f311', 'pipeline': 'bc52deabf1f5ee60968ba541d9d2574353c30a9c'}, 'duration': 0.7145559787750244, 'iteration': 14, 'loss': 0.6831045572696203, 'max_history_score': 0.85528670390001, 'max_history_score_std': 0.02213730791268438, 'max_history_step': 'joint', 'pipeline': {'features': ('features_SelectKBest', {'features__k': 3}), 'normalizer': ('normalizer_MinMaxScaler', {}), 'rebalance': ('rebalance_NearMiss', {'rebalance__n_neighbors': 1})}, 'score': 0.31689544273037973, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'gini', 'max_depth': 2, 'max_features': 2, 'max_leaf_nodes': None, 'min_samples_split': 5, 'n_estimators': 100}, 'config_hash': {'algorithm': 'b942acdead762d34afeb474bc2fe6f7fd0f23493', 'config': '1080c25b92da3f15a6f8eec003957f7e0a66324f', 'pipeline': 'cfa84fe703dc5bc0bbd2257a6d524fee2693b804'}, 'duration': 2.812459945678711, 'iteration': 15, 'loss': 0.6921421091202761, 'max_history_score': 0.85528670390001, 'max_history_score_std': 0.02213730791268438, 'max_history_step': 'joint', 'pipeline': {'features': ('features_SelectKBest', {'features__k': 2}), 'normalizer': ('normalizer_PowerTransformer', {}), 'rebalance': ('rebalance_NoneType', {})}, 'score': 0.3078578908797239, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'entropy', 'max_depth': 2, 'max_features': 3, 'max_leaf_nodes': 3, 'min_samples_split': 2, 'n_estimators': 75}, 'config_hash': {'algorithm': '250661ce4193a61ef44d2f77694b52b785ff032d', 'config': 'c3e8cf4eca5aafcae4ac31b0449e105ca127ffe2', 'pipeline': 'c4dd111513ea35f97dd3aec3e8e7f6268ce035da'}, 'duration': 1.0555319786071777, 'iteration': 16, 'loss': 1.0, 'max_history_score': 0.85528670390001, 'max_history_score_std': 0.02213730791268438, 'max_history_step': 'joint', 'pipeline': {'features': ('features_PCA', {'features__n_components': 2}), 'normalizer': ('normalizer_RobustScaler', {'normalizer__quantile_range': (...), 'normalizer__with_centering': False, 'normalizer__with_scaling': True}), 'rebalance': ('rebalance_NearMiss', {'rebalance__n_neighbors': 2})}, 'score': 0.0, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'entropy', 'max_depth': 3, 'max_features': 3, 'max_leaf_nodes': None, 'min_samples_split': 3, 'n_estimators': 25}, 'config_hash': {'algorithm': '05ac02bd045c65dc4089894902ad6253661a2692', 'config': '3449b4a1c2e488e26a7195ee9edca19b854ebd33', 'pipeline': '505d3f71b534917375d765e64b0611e7dfb83746'}, 'duration': 5.5412821769714355, 'iteration': 17, 'loss': 0.7289151155121668, 'max_history_score': 0.85528670390001, 'max_history_score_std': 0.02213730791268438, 'max_history_step': 'joint', 'pipeline': {'features': ('features_SelectKBest', {'features__k': 4}), 'normalizer': ('normalizer_MinMaxScaler', {}), 'rebalance': ('rebalance_CondensedNearestNeighbour', {'rebalance__n_neighbors': 2})}, 'score': 0.2710848844878332, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'entropy', 'max_depth': 2, 'max_features': None, 'max_leaf_nodes': None, 'min_samples_split': 2, 'n_estimators': 25}, 'config_hash': {'algorithm': 'de3b3a352ebb260e16c6b213a08c9144d17a744b', 'config': '224987ffdbbb9b6182cff18d8374518b917e4f2e', 'pipeline': '12c89200a558b2f3b91332566f41050143aecbe7'}, 'duration': 2.4646048545837402, 'iteration': 18, 'loss': 0.6545902512995826, 'max_history_score': 0.85528670390001, 'max_history_score_std': 0.02213730791268438, 'max_history_step': 'joint', 'pipeline': {'features': ('features_NoneType', {}), 'normalizer': ('normalizer_PowerTransformer', {}), 'rebalance': ('rebalance_NearMiss', {'rebalance__n_neighbors': 2})}, 'score': 0.3454097487004174, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'gini', 'max_depth': None, 'max_features': 1, 'max_leaf_nodes': None, 'min_samples_split': 3, 'n_estimators': 100}, 'config_hash': {'algorithm': '30ca111584767bbf0464df40b4c928cf7ddf9459', 'config': '97ca7d6a017c721084dec2a5d2e5a67e1e6ae2f0', 'pipeline': '789eca82ea4a42d61927670c538867b745fd81d3'}, 'duration': 7.164499044418335, 'iteration': 19, 'loss': 0.6536825403350528, 'max_history_score': 0.85528670390001, 'max_history_score_std': 0.02213730791268438, 'max_history_step': 'joint', 'pipeline': {'features': ('features_SelectKBest', {'features__k': 3}), 'normalizer': ('normalizer_RobustScaler', {'normalizer__quantile_range': (...), 'normalizer__with_centering': False, 'normalizer__with_scaling': True}), 'rebalance': ('rebalance_CondensedNearestNeighbour', {'rebalance__n_neighbors': 3})}, 'score': 0.3463174596649472, ...}, ...], 'history_hash': ['fd24b065dda6bdeb1077793f9df480ff318c7a37', 'fb22f80fb4358ae1ee4c9bd4a83543992be8d806', '8c97cdb885dd05cfd8c40ee3ac445b61e5c767a8', '16fbb5fd5cfbbacfddf27c61c0c7397a7f6d8ade', 'a77c698197c31308211b854e81a998178941f87d', '1fc13606bca3aaf342ca6ea21139cb598b56f8db', '6749af1a67b4dbcd2b4719e419d99908063c05e1', 'd92d4ada2394fc132733e176e926ee53acdc6a00', 'f0d0b1d2cedc22ae15d9a208a3fc3fc133bf0d3d', '47584de0e60d0d12c7dbbf0dc60e5aea96e3f4b2', 'eecb88ee2b1b95d741c1b5c7751534d31aae6a77', '27a7ed0502b321ab7256b77c8ce79e90cb9da815', '45f056102dd2d644bd8befa471f17b2311ac7954', 'ba108323623936872824ed8f1c41d615d25523b3', 'dde4d3b5f37741629cb58bfc4051ed9f98c8f311', '1080c25b92da3f15a6f8eec003957f7e0a66324f', 'c3e8cf4eca5aafcae4ac31b0449e105ca127ffe2', '3449b4a1c2e488e26a7195ee9edca19b854ebd33', '224987ffdbbb9b6182cff18d8374518b917e4f2e', '97ca7d6a017c721084dec2a5d2e5a67e1e6ae2f0', ...], 'history_index': {'05465becb12810ce291074be22a0275a42efbea8': 52, '064f53edf4748bb2df4ff59f147331aad21219e1': 48, '087efef4a19f272562d2d445dac0edd8096ba2fa': 58, '0fd4d71ca3a89c7d14af5087f2a2e2c1b1975351': 51, '1080c25b92da3f15a6f8eec003957f7e0a66324f': 15, '143679b59e16961765e77616142572b6ded0ee72': 62, '151b4a15037767108da13dafa0b63ae93222e93a': 53, '16fbb5fd5cfbbacfddf27c61c0c7397a7f6d8ade': 3, '1d125af79272b5204b4ef7b042cf1e45bbca9e17': 70, '1fc13606bca3aaf342ca6ea21139cb598b56f8db': 5, ...}, 'iteration': 75, 'max_history_score': 0.9231904384036744, 'max_history_score_std': 0.03040515884196498, 'max_history_step': 'joint'}, config={'algorithm': 'RandomForest', 'seed': 42, 'time': 300})
    108 
    109 def objective_algo(algo_config, current_pipeline_config, algorithm, X, y, context, config):
    110     return objective(current_pipeline_config, algo_config, algorithm, X, y, context, config, step='algorithm')
    111 
    112 def objective_joint(wconfig, algorithm, X, y, context, config):
--> 113     return objective(wconfig['pipeline'], wconfig['algorithm'], algorithm, X, y, context, config, step='joint')
        wconfig = {'algorithm': {'bootstrap': True, 'criterion': 'entropy', 'max_depth': None, 'max_features': 2, 'max_leaf_nodes': 5, 'min_samples_split': 3, 'n_estimators': 25}, 'pipeline': {'features': ('features_SelectKBest', {'features__k': 1}), 'normalizer': ('normalizer_PowerTransformer', {}), 'rebalance': ('rebalance_NearMiss', {'rebalance__n_neighbors': 1})}}
        algorithm = 'RandomForest'
        X = array([[ 0.,  0.,  5., ...,  0.,  0.,  0.],
    ...0.],
       [ 0.,  0., 10., ..., 12.,  1.,  0.]])
        y = array([0, 1, 2, ..., 8, 9, 8])
        context = {'baseline_score': 0.9272021217853512, 'baseline_score_std': 0.026919033284817703, 'best_config': {'algorithm': {'bootstrap': True, 'criterion': 'entropy', 'max_depth': None, 'max_features': None, 'max_leaf_nodes': None, 'min_samples_split': 3, 'n_estimators': 75}, 'config_hash': {'algorithm': 'f42e45bee34ac9973699212f6c8b845daea9383a', 'config': 'ae61cfde4c8b4c792e42d6b6be4af4ffb3d90e13', 'pipeline': '15ff3d6270ac899763bb3f72417c48bcd56aa7d8'}, 'duration': 8.20555305480957, 'iteration': 65, 'loss': 0.07680956159632557, 'max_history_score': 0.9231904384036744, 'max_history_score_std': 0.03040515884196498, 'max_history_step': 'joint', 'pipeline': {'features': ('features_NoneType', {}), 'normalizer': ('normalizer_StandardScaler', {'normalizer__with_mean': True, 'normalizer__with_std': True}), 'rebalance': ('rebalance_NearMiss', {'rebalance__n_neighbors': 1})}, 'score': 0.9231904384036744, ...}, 'history': [{'algorithm': {'bootstrap': False, 'criterion': 'entropy', 'max_depth': 1, 'max_features': 3, 'max_leaf_nodes': 3, 'min_samples_split': 5, 'n_estimators': 50}, 'config_hash': {'algorithm': '752fa095cdab58a238ae606c613606188964cc0c', 'config': 'fd24b065dda6bdeb1077793f9df480ff318c7a37', 'pipeline': '13ea3359c453b8993fcec1e88bc0e19cd0a2b112'}, 'duration': 0.689669132232666, 'iteration': 0, 'loss': 0.6602879519109309, 'max_history_score': 0.3397120480890691, 'max_history_score_std': 0.03346542949100545, 'max_history_step': 'joint', 'pipeline': {'features': ('features_SelectKBest', {'features__k': 4}), 'normalizer': ('normalizer_MinMaxScaler', {}), 'rebalance': ('rebalance_NoneType', {})}, 'score': 0.3397120480890691, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'gini', 'max_depth': 4, 'max_features': 1, 'max_leaf_nodes': 5, 'min_samples_split': 3, 'n_estimators': 25}, 'config_hash': {'algorithm': '9d9de4aee820052ddfe83bfffca420f6b50837d3', 'config': 'fb22f80fb4358ae1ee4c9bd4a83543992be8d806', 'pipeline': '6251ad4bb7a110726a67f90c319f4717ac37a312'}, 'duration': 1.4300940036773682, 'iteration': 1, 'loss': 0.5122196101741096, 'max_history_score': 0.48778038982589045, 'max_history_score_std': 0.05486079759217226, 'max_history_step': 'joint', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 2, 'features__selectkbest__k': 2}), 'normalizer': ('normalizer_StandardScaler', {'normalizer__with_mean': True, 'normalizer__with_std': True}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 5})}, 'score': 0.48778038982589045, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': 4, 'max_features': 1, 'max_leaf_nodes': None, 'min_samples_split': 2, 'n_estimators': 10}, 'config_hash': {'algorithm': '2ed7d27df9a1b2d5e63da76f7cb309616c232022', 'config': '8c97cdb885dd05cfd8c40ee3ac445b61e5c767a8', 'pipeline': 'c0abb5e23a4739d3120740a9519fb36c43eb94d5'}, 'duration': 3.0036678314208984, 'iteration': 2, 'loss': 0.38319264175312906, 'max_history_score': 0.6168073582468709, 'max_history_score_std': 0.05286679173001824, 'max_history_step': 'joint', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 1, 'features__selectkbest__k': 4}), 'normalizer': ('normalizer_PowerTransformer', {}), 'rebalance': ('rebalance_NearMiss', {'rebalance__n_neighbors': 2})}, 'score': 0.6168073582468709, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'entropy', 'max_depth': None, 'max_features': None, 'max_leaf_nodes': 2, 'min_samples_split': 2, 'n_estimators': 100}, 'config_hash': {'algorithm': '17962655e3b76dfcd0843d1e5c2cb7a9db1c6a79', 'config': '16fbb5fd5cfbbacfddf27c61c0c7397a7f6d8ade', 'pipeline': '13ea3359c453b8993fcec1e88bc0e19cd0a2b112'}, 'duration': 1.3447980880737305, 'iteration': 3, 'loss': 0.6768840987778313, 'max_history_score': 0.6168073582468709, 'max_history_score_std': 0.05286679173001824, 'max_history_step': 'joint', 'pipeline': {'features': ('features_SelectKBest', {'features__k': 4}), 'normalizer': ('normalizer_MinMaxScaler', {}), 'rebalance': ('rebalance_NoneType', {})}, 'score': 0.32311590122216866, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'gini', 'max_depth': 2, 'max_features': 2, 'max_leaf_nodes': 2, 'min_samples_split': 3, 'n_estimators': 100}, 'config_hash': {'algorithm': '1ea8965b2247f86950e54510ee6d79399816341b', 'config': 'a77c698197c31308211b854e81a998178941f87d', 'pipeline': 'aaf976c7c663a31fa039582d42f9e07101556a7c'}, 'duration': 2.589430093765259, 'iteration': 4, 'loss': 0.2544808950572157, 'max_history_score': 0.7455191049427843, 'max_history_score_std': 0.04843448308166839, 'max_history_step': 'joint', 'pipeline': {'features': ('features_NoneType', {}), 'normalizer': ('normalizer_PowerTransformer', {}), 'rebalance': ('rebalance_NoneType', {})}, 'score': 0.7455191049427843, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': None, 'max_features': 2, 'max_leaf_nodes': 5, 'min_samples_split': 5, 'n_estimators': 25}, 'config_hash': {'algorithm': 'fd8aeb6a05eaaba41e676d60596c8e0c71b35e0c', 'config': '1fc13606bca3aaf342ca6ea21139cb598b56f8db', 'pipeline': 'f00bd8de05642e026bbba4ad20d3a60088c86b6c'}, 'duration': 1.8779079914093018, 'iteration': 5, 'loss': 0.531551018758381, 'max_history_score': 0.7455191049427843, 'max_history_score_std': 0.04843448308166839, 'max_history_step': 'joint', 'pipeline': {'features': ('features_PCA', {'features__n_components': 2}), 'normalizer': ('normalizer_MinMaxScaler', {}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 5})}, 'score': 0.46844898124161904, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'entropy', 'max_depth': None, 'max_features': 2, 'max_leaf_nodes': None, 'min_samples_split': 2, 'n_estimators': 10}, 'config_hash': {'algorithm': 'a49ecb99e74217d6812f98ead7bc9d1fe4a53ba0', 'config': '6749af1a67b4dbcd2b4719e419d99908063c05e1', 'pipeline': '19bdf19a2eec5febce95ab8fa2a71040d75114aa'}, 'duration': 1.5498578548431396, 'iteration': 6, 'loss': 0.14471329609998995, 'max_history_score': 0.85528670390001, 'max_history_score_std': 0.02213730791268438, 'max_history_step': 'joint', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 4, 'features__selectkbest__k': 3}), 'normalizer': ('normalizer_NoneType', {}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 7})}, 'score': 0.85528670390001, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': 1, 'max_features': 3, 'max_leaf_nodes': 3, 'min_samples_split': 3, 'n_estimators': 75}, 'config_hash': {'algorithm': 'ebfb16234172ae811ff21185ff92bbdbb8f32f14', 'config': 'd92d4ada2394fc132733e176e926ee53acdc6a00', 'pipeline': '8071e7cbf86a5c3056493dc3aa40063aeb28cdfe'}, 'duration': 1.3618149757385254, 'iteration': 7, 'loss': 0.6158612049395463, 'max_history_score': 0.85528670390001, 'max_history_score_std': 0.02213730791268438, 'max_history_step': 'joint', 'pipeline': {'features': ('features_SelectKBest', {'features__k': 4}), 'normalizer': ('normalizer_StandardScaler', {'normalizer__with_mean': True, 'normalizer__with_std': True}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 5})}, 'score': 0.3841387950604537, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'entropy', 'max_depth': 1, 'max_features': 1, 'max_leaf_nodes': 5, 'min_samples_split': 2, 'n_estimators': 100}, 'config_hash': {'algorithm': '896b53c75a2db568fb7b6da3bfca2f7a1535a11b', 'config': 'f0d0b1d2cedc22ae15d9a208a3fc3fc133bf0d3d', 'pipeline': 'c9761c9a33bf75d6dcad0742c421548a7655ccc9'}, 'duration': 2.297278881072998, 'iteration': 8, 'loss': 0.40673663548410355, 'max_history_score': 0.85528670390001, 'max_history_score_std': 0.02213730791268438, 'max_history_step': 'joint', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 2, 'features__selectkbest__k': 4}), 'normalizer': ('normalizer_StandardScaler', {'normalizer__with_mean': False, 'normalizer__with_std': False}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 5})}, 'score': 0.5932633645158965, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'entropy', 'max_depth': 2, 'max_features': None, 'max_leaf_nodes': None, 'min_samples_split': 5, 'n_estimators': 25}, 'config_hash': {'algorithm': '0b0e954757c4f75343a6efb740ad93260ed781ae', 'config': '47584de0e60d0d12c7dbbf0dc60e5aea96e3f4b2', 'pipeline': 'b37ee32d59413053bf9a2a72c8ff7135f3701e05'}, 'duration': 0.7249000072479248, 'iteration': 9, 'loss': 0.6965910020393421, 'max_history_score': 0.85528670390001, 'max_history_score_std': 0.02213730791268438, 'max_history_step': 'joint', 'pipeline': {'features': ('features_SelectKBest', {'features__k': 3}), 'normalizer': ('normalizer_NoneType', {}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 7})}, 'score': 0.3034089979606579, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'gini', 'max_depth': 2, 'max_features': 2, 'max_leaf_nodes': 5, 'min_samples_split': 5, 'n_estimators': 75}, 'config_hash': {'algorithm': 'f1ead1d9e33ea927e1dd27d872a058fa3de4f832', 'config': 'eecb88ee2b1b95d741c1b5c7751534d31aae6a77', 'pipeline': '6746650871e8b61efc9302b092dc05f7cdb179d5'}, 'duration': 5.340634822845459, 'iteration': 10, 'loss': 0.7687016290977936, 'max_history_score': 0.85528670390001, 'max_history_score_std': 0.02213730791268438, 'max_history_step': 'joint', 'pipeline': {'features': ('features_SelectKBest', {'features__k': 3}), 'normalizer': ('normalizer_RobustScaler', {'normalizer__quantile_range': (...), 'normalizer__with_centering': False, 'normalizer__with_scaling': False}), 'rebalance': ('rebalance_CondensedNearestNeighbour', {'rebalance__n_neighbors': 1})}, 'score': 0.23129837090220637, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': 1, 'max_features': 2, 'max_leaf_nodes': 2, 'min_samples_split': 3, 'n_estimators': 75}, 'config_hash': {'algorithm': '531a3bb8ccf0baa06727af4b3de9e62d25e6eabf', 'config': '27a7ed0502b321ab7256b77c8ce79e90cb9da815', 'pipeline': '77e6d84e2217b92b3cf67cc6defef9dd3554cec0'}, 'duration': 1.775357961654663, 'iteration': 11, 'loss': 0.6313818737375694, 'max_history_score': 0.85528670390001, 'max_history_score_std': 0.02213730791268438, 'max_history_step': 'joint', 'pipeline': {'features': ('features_SelectKBest', {'features__k': 4}), 'normalizer': ('normalizer_MinMaxScaler', {}), 'rebalance': ('rebalance_NearMiss', {'rebalance__n_neighbors': 3})}, 'score': 0.3686181262624307, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'entropy', 'max_depth': 4, 'max_features': 3, 'max_leaf_nodes': 2, 'min_samples_split': 3, 'n_estimators': 10}, 'config_hash': {'algorithm': '93518f8ded6074d537900b26be72f8485782f933', 'config': '45f056102dd2d644bd8befa471f17b2311ac7954', 'pipeline': '5240329df25c9a533d025c1a401d49835a501b41'}, 'duration': 3.2622711658477783, 'iteration': 12, 'loss': 0.6120243191353301, 'max_history_score': 0.85528670390001, 'max_history_score_std': 0.02213730791268438, 'max_history_step': 'joint', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 4, 'features__selectkbest__k': 2}), 'normalizer': ('normalizer_PowerTransformer', {}), 'rebalance': ('rebalance_NearMiss', {'rebalance__n_neighbors': 1})}, 'score': 0.38797568086467, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'entropy', 'max_depth': None, 'max_features': 1, 'max_leaf_nodes': 5, 'min_samples_split': 3, 'n_estimators': 75}, 'config_hash': {'algorithm': 'e515d45b764fa43591032874a0ff9c25bf12fddd', 'config': 'ba108323623936872824ed8f1c41d615d25523b3', 'pipeline': '9d823bc0442f21b5ce8af67a5eb1237f64ffc2f8'}, 'duration': 2.5326571464538574, 'iteration': 13, 'loss': 0.6271427382991047, 'max_history_score': 0.85528670390001, 'max_history_score_std': 0.02213730791268438, 'max_history_step': 'joint', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 1, 'features__selectkbest__k': 1}), 'normalizer': ('normalizer_StandardScaler', {'normalizer__with_mean': True, 'normalizer__with_std': True}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 5})}, 'score': 0.3728572617008953, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'entropy', 'max_depth': 3, 'max_features': 2, 'max_leaf_nodes': 2, 'min_samples_split': 3, 'n_estimators': 25}, 'config_hash': {'algorithm': '2808e67f609eba5c8a97f81ac0c9413cd37cf7aa', 'config': 'dde4d3b5f37741629cb58bfc4051ed9f98c8f311', 'pipeline': 'bc52deabf1f5ee60968ba541d9d2574353c30a9c'}, 'duration': 0.7145559787750244, 'iteration': 14, 'loss': 0.6831045572696203, 'max_history_score': 0.85528670390001, 'max_history_score_std': 0.02213730791268438, 'max_history_step': 'joint', 'pipeline': {'features': ('features_SelectKBest', {'features__k': 3}), 'normalizer': ('normalizer_MinMaxScaler', {}), 'rebalance': ('rebalance_NearMiss', {'rebalance__n_neighbors': 1})}, 'score': 0.31689544273037973, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'gini', 'max_depth': 2, 'max_features': 2, 'max_leaf_nodes': None, 'min_samples_split': 5, 'n_estimators': 100}, 'config_hash': {'algorithm': 'b942acdead762d34afeb474bc2fe6f7fd0f23493', 'config': '1080c25b92da3f15a6f8eec003957f7e0a66324f', 'pipeline': 'cfa84fe703dc5bc0bbd2257a6d524fee2693b804'}, 'duration': 2.812459945678711, 'iteration': 15, 'loss': 0.6921421091202761, 'max_history_score': 0.85528670390001, 'max_history_score_std': 0.02213730791268438, 'max_history_step': 'joint', 'pipeline': {'features': ('features_SelectKBest', {'features__k': 2}), 'normalizer': ('normalizer_PowerTransformer', {}), 'rebalance': ('rebalance_NoneType', {})}, 'score': 0.3078578908797239, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'entropy', 'max_depth': 2, 'max_features': 3, 'max_leaf_nodes': 3, 'min_samples_split': 2, 'n_estimators': 75}, 'config_hash': {'algorithm': '250661ce4193a61ef44d2f77694b52b785ff032d', 'config': 'c3e8cf4eca5aafcae4ac31b0449e105ca127ffe2', 'pipeline': 'c4dd111513ea35f97dd3aec3e8e7f6268ce035da'}, 'duration': 1.0555319786071777, 'iteration': 16, 'loss': 1.0, 'max_history_score': 0.85528670390001, 'max_history_score_std': 0.02213730791268438, 'max_history_step': 'joint', 'pipeline': {'features': ('features_PCA', {'features__n_components': 2}), 'normalizer': ('normalizer_RobustScaler', {'normalizer__quantile_range': (...), 'normalizer__with_centering': False, 'normalizer__with_scaling': True}), 'rebalance': ('rebalance_NearMiss', {'rebalance__n_neighbors': 2})}, 'score': 0.0, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'entropy', 'max_depth': 3, 'max_features': 3, 'max_leaf_nodes': None, 'min_samples_split': 3, 'n_estimators': 25}, 'config_hash': {'algorithm': '05ac02bd045c65dc4089894902ad6253661a2692', 'config': '3449b4a1c2e488e26a7195ee9edca19b854ebd33', 'pipeline': '505d3f71b534917375d765e64b0611e7dfb83746'}, 'duration': 5.5412821769714355, 'iteration': 17, 'loss': 0.7289151155121668, 'max_history_score': 0.85528670390001, 'max_history_score_std': 0.02213730791268438, 'max_history_step': 'joint', 'pipeline': {'features': ('features_SelectKBest', {'features__k': 4}), 'normalizer': ('normalizer_MinMaxScaler', {}), 'rebalance': ('rebalance_CondensedNearestNeighbour', {'rebalance__n_neighbors': 2})}, 'score': 0.2710848844878332, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'entropy', 'max_depth': 2, 'max_features': None, 'max_leaf_nodes': None, 'min_samples_split': 2, 'n_estimators': 25}, 'config_hash': {'algorithm': 'de3b3a352ebb260e16c6b213a08c9144d17a744b', 'config': '224987ffdbbb9b6182cff18d8374518b917e4f2e', 'pipeline': '12c89200a558b2f3b91332566f41050143aecbe7'}, 'duration': 2.4646048545837402, 'iteration': 18, 'loss': 0.6545902512995826, 'max_history_score': 0.85528670390001, 'max_history_score_std': 0.02213730791268438, 'max_history_step': 'joint', 'pipeline': {'features': ('features_NoneType', {}), 'normalizer': ('normalizer_PowerTransformer', {}), 'rebalance': ('rebalance_NearMiss', {'rebalance__n_neighbors': 2})}, 'score': 0.3454097487004174, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'gini', 'max_depth': None, 'max_features': 1, 'max_leaf_nodes': None, 'min_samples_split': 3, 'n_estimators': 100}, 'config_hash': {'algorithm': '30ca111584767bbf0464df40b4c928cf7ddf9459', 'config': '97ca7d6a017c721084dec2a5d2e5a67e1e6ae2f0', 'pipeline': '789eca82ea4a42d61927670c538867b745fd81d3'}, 'duration': 7.164499044418335, 'iteration': 19, 'loss': 0.6536825403350528, 'max_history_score': 0.85528670390001, 'max_history_score_std': 0.02213730791268438, 'max_history_step': 'joint', 'pipeline': {'features': ('features_SelectKBest', {'features__k': 3}), 'normalizer': ('normalizer_RobustScaler', {'normalizer__quantile_range': (...), 'normalizer__with_centering': False, 'normalizer__with_scaling': True}), 'rebalance': ('rebalance_CondensedNearestNeighbour', {'rebalance__n_neighbors': 3})}, 'score': 0.3463174596649472, ...}, ...], 'history_hash': ['fd24b065dda6bdeb1077793f9df480ff318c7a37', 'fb22f80fb4358ae1ee4c9bd4a83543992be8d806', '8c97cdb885dd05cfd8c40ee3ac445b61e5c767a8', '16fbb5fd5cfbbacfddf27c61c0c7397a7f6d8ade', 'a77c698197c31308211b854e81a998178941f87d', '1fc13606bca3aaf342ca6ea21139cb598b56f8db', '6749af1a67b4dbcd2b4719e419d99908063c05e1', 'd92d4ada2394fc132733e176e926ee53acdc6a00', 'f0d0b1d2cedc22ae15d9a208a3fc3fc133bf0d3d', '47584de0e60d0d12c7dbbf0dc60e5aea96e3f4b2', 'eecb88ee2b1b95d741c1b5c7751534d31aae6a77', '27a7ed0502b321ab7256b77c8ce79e90cb9da815', '45f056102dd2d644bd8befa471f17b2311ac7954', 'ba108323623936872824ed8f1c41d615d25523b3', 'dde4d3b5f37741629cb58bfc4051ed9f98c8f311', '1080c25b92da3f15a6f8eec003957f7e0a66324f', 'c3e8cf4eca5aafcae4ac31b0449e105ca127ffe2', '3449b4a1c2e488e26a7195ee9edca19b854ebd33', '224987ffdbbb9b6182cff18d8374518b917e4f2e', '97ca7d6a017c721084dec2a5d2e5a67e1e6ae2f0', ...], 'history_index': {'05465becb12810ce291074be22a0275a42efbea8': 52, '064f53edf4748bb2df4ff59f147331aad21219e1': 48, '087efef4a19f272562d2d445dac0edd8096ba2fa': 58, '0fd4d71ca3a89c7d14af5087f2a2e2c1b1975351': 51, '1080c25b92da3f15a6f8eec003957f7e0a66324f': 15, '143679b59e16961765e77616142572b6ded0ee72': 62, '151b4a15037767108da13dafa0b63ae93222e93a': 53, '16fbb5fd5cfbbacfddf27c61c0c7397a7f6d8ade': 3, '1d125af79272b5204b4ef7b042cf1e45bbca9e17': 70, '1fc13606bca3aaf342ca6ea21139cb598b56f8db': 5, ...}, 'iteration': 75, 'max_history_score': 0.9231904384036744, 'max_history_score_std': 0.03040515884196498, 'max_history_step': 'joint'}
        config = {'algorithm': 'RandomForest', 'seed': 42, 'time': 300}
    114 
    115 
    116 def get_baseline_score(algorithm, X, y, seed):
    117     pipeline, _ = pipeline_conf_to_full_pipeline(

...........................................................................
/home/aquemy/dev/dp_hyperparameters/extension/experiment/objective.py in objective(pipeline_config={'features': ('features_SelectKBest', {'features__k': 1}), 'normalizer': ('normalizer_PowerTransformer', {}), 'rebalance': ('rebalance_NearMiss', {'rebalance__n_neighbors': 1})}, algo_config={'bootstrap': True, 'criterion': 'entropy', 'max_depth': None, 'max_features': 2, 'max_leaf_nodes': 5, 'min_samples_split': 3, 'n_estimators': 25}, algorithm='RandomForest', X=array([[ 0.,  0.,  5., ...,  0.,  0.,  0.],
    ...0.],
       [ 0.,  0., 10., ..., 12.,  1.,  0.]]), y=array([0, 1, 2, ..., 8, 9, 8]), context={'baseline_score': 0.9272021217853512, 'baseline_score_std': 0.026919033284817703, 'best_config': {'algorithm': {'bootstrap': True, 'criterion': 'entropy', 'max_depth': None, 'max_features': None, 'max_leaf_nodes': None, 'min_samples_split': 3, 'n_estimators': 75}, 'config_hash': {'algorithm': 'f42e45bee34ac9973699212f6c8b845daea9383a', 'config': 'ae61cfde4c8b4c792e42d6b6be4af4ffb3d90e13', 'pipeline': '15ff3d6270ac899763bb3f72417c48bcd56aa7d8'}, 'duration': 8.20555305480957, 'iteration': 65, 'loss': 0.07680956159632557, 'max_history_score': 0.9231904384036744, 'max_history_score_std': 0.03040515884196498, 'max_history_step': 'joint', 'pipeline': {'features': ('features_NoneType', {}), 'normalizer': ('normalizer_StandardScaler', {'normalizer__with_mean': True, 'normalizer__with_std': True}), 'rebalance': ('rebalance_NearMiss', {'rebalance__n_neighbors': 1})}, 'score': 0.9231904384036744, ...}, 'history': [{'algorithm': {'bootstrap': False, 'criterion': 'entropy', 'max_depth': 1, 'max_features': 3, 'max_leaf_nodes': 3, 'min_samples_split': 5, 'n_estimators': 50}, 'config_hash': {'algorithm': '752fa095cdab58a238ae606c613606188964cc0c', 'config': 'fd24b065dda6bdeb1077793f9df480ff318c7a37', 'pipeline': '13ea3359c453b8993fcec1e88bc0e19cd0a2b112'}, 'duration': 0.689669132232666, 'iteration': 0, 'loss': 0.6602879519109309, 'max_history_score': 0.3397120480890691, 'max_history_score_std': 0.03346542949100545, 'max_history_step': 'joint', 'pipeline': {'features': ('features_SelectKBest', {'features__k': 4}), 'normalizer': ('normalizer_MinMaxScaler', {}), 'rebalance': ('rebalance_NoneType', {})}, 'score': 0.3397120480890691, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'gini', 'max_depth': 4, 'max_features': 1, 'max_leaf_nodes': 5, 'min_samples_split': 3, 'n_estimators': 25}, 'config_hash': {'algorithm': '9d9de4aee820052ddfe83bfffca420f6b50837d3', 'config': 'fb22f80fb4358ae1ee4c9bd4a83543992be8d806', 'pipeline': '6251ad4bb7a110726a67f90c319f4717ac37a312'}, 'duration': 1.4300940036773682, 'iteration': 1, 'loss': 0.5122196101741096, 'max_history_score': 0.48778038982589045, 'max_history_score_std': 0.05486079759217226, 'max_history_step': 'joint', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 2, 'features__selectkbest__k': 2}), 'normalizer': ('normalizer_StandardScaler', {'normalizer__with_mean': True, 'normalizer__with_std': True}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 5})}, 'score': 0.48778038982589045, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': 4, 'max_features': 1, 'max_leaf_nodes': None, 'min_samples_split': 2, 'n_estimators': 10}, 'config_hash': {'algorithm': '2ed7d27df9a1b2d5e63da76f7cb309616c232022', 'config': '8c97cdb885dd05cfd8c40ee3ac445b61e5c767a8', 'pipeline': 'c0abb5e23a4739d3120740a9519fb36c43eb94d5'}, 'duration': 3.0036678314208984, 'iteration': 2, 'loss': 0.38319264175312906, 'max_history_score': 0.6168073582468709, 'max_history_score_std': 0.05286679173001824, 'max_history_step': 'joint', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 1, 'features__selectkbest__k': 4}), 'normalizer': ('normalizer_PowerTransformer', {}), 'rebalance': ('rebalance_NearMiss', {'rebalance__n_neighbors': 2})}, 'score': 0.6168073582468709, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'entropy', 'max_depth': None, 'max_features': None, 'max_leaf_nodes': 2, 'min_samples_split': 2, 'n_estimators': 100}, 'config_hash': {'algorithm': '17962655e3b76dfcd0843d1e5c2cb7a9db1c6a79', 'config': '16fbb5fd5cfbbacfddf27c61c0c7397a7f6d8ade', 'pipeline': '13ea3359c453b8993fcec1e88bc0e19cd0a2b112'}, 'duration': 1.3447980880737305, 'iteration': 3, 'loss': 0.6768840987778313, 'max_history_score': 0.6168073582468709, 'max_history_score_std': 0.05286679173001824, 'max_history_step': 'joint', 'pipeline': {'features': ('features_SelectKBest', {'features__k': 4}), 'normalizer': ('normalizer_MinMaxScaler', {}), 'rebalance': ('rebalance_NoneType', {})}, 'score': 0.32311590122216866, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'gini', 'max_depth': 2, 'max_features': 2, 'max_leaf_nodes': 2, 'min_samples_split': 3, 'n_estimators': 100}, 'config_hash': {'algorithm': '1ea8965b2247f86950e54510ee6d79399816341b', 'config': 'a77c698197c31308211b854e81a998178941f87d', 'pipeline': 'aaf976c7c663a31fa039582d42f9e07101556a7c'}, 'duration': 2.589430093765259, 'iteration': 4, 'loss': 0.2544808950572157, 'max_history_score': 0.7455191049427843, 'max_history_score_std': 0.04843448308166839, 'max_history_step': 'joint', 'pipeline': {'features': ('features_NoneType', {}), 'normalizer': ('normalizer_PowerTransformer', {}), 'rebalance': ('rebalance_NoneType', {})}, 'score': 0.7455191049427843, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': None, 'max_features': 2, 'max_leaf_nodes': 5, 'min_samples_split': 5, 'n_estimators': 25}, 'config_hash': {'algorithm': 'fd8aeb6a05eaaba41e676d60596c8e0c71b35e0c', 'config': '1fc13606bca3aaf342ca6ea21139cb598b56f8db', 'pipeline': 'f00bd8de05642e026bbba4ad20d3a60088c86b6c'}, 'duration': 1.8779079914093018, 'iteration': 5, 'loss': 0.531551018758381, 'max_history_score': 0.7455191049427843, 'max_history_score_std': 0.04843448308166839, 'max_history_step': 'joint', 'pipeline': {'features': ('features_PCA', {'features__n_components': 2}), 'normalizer': ('normalizer_MinMaxScaler', {}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 5})}, 'score': 0.46844898124161904, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'entropy', 'max_depth': None, 'max_features': 2, 'max_leaf_nodes': None, 'min_samples_split': 2, 'n_estimators': 10}, 'config_hash': {'algorithm': 'a49ecb99e74217d6812f98ead7bc9d1fe4a53ba0', 'config': '6749af1a67b4dbcd2b4719e419d99908063c05e1', 'pipeline': '19bdf19a2eec5febce95ab8fa2a71040d75114aa'}, 'duration': 1.5498578548431396, 'iteration': 6, 'loss': 0.14471329609998995, 'max_history_score': 0.85528670390001, 'max_history_score_std': 0.02213730791268438, 'max_history_step': 'joint', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 4, 'features__selectkbest__k': 3}), 'normalizer': ('normalizer_NoneType', {}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 7})}, 'score': 0.85528670390001, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': 1, 'max_features': 3, 'max_leaf_nodes': 3, 'min_samples_split': 3, 'n_estimators': 75}, 'config_hash': {'algorithm': 'ebfb16234172ae811ff21185ff92bbdbb8f32f14', 'config': 'd92d4ada2394fc132733e176e926ee53acdc6a00', 'pipeline': '8071e7cbf86a5c3056493dc3aa40063aeb28cdfe'}, 'duration': 1.3618149757385254, 'iteration': 7, 'loss': 0.6158612049395463, 'max_history_score': 0.85528670390001, 'max_history_score_std': 0.02213730791268438, 'max_history_step': 'joint', 'pipeline': {'features': ('features_SelectKBest', {'features__k': 4}), 'normalizer': ('normalizer_StandardScaler', {'normalizer__with_mean': True, 'normalizer__with_std': True}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 5})}, 'score': 0.3841387950604537, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'entropy', 'max_depth': 1, 'max_features': 1, 'max_leaf_nodes': 5, 'min_samples_split': 2, 'n_estimators': 100}, 'config_hash': {'algorithm': '896b53c75a2db568fb7b6da3bfca2f7a1535a11b', 'config': 'f0d0b1d2cedc22ae15d9a208a3fc3fc133bf0d3d', 'pipeline': 'c9761c9a33bf75d6dcad0742c421548a7655ccc9'}, 'duration': 2.297278881072998, 'iteration': 8, 'loss': 0.40673663548410355, 'max_history_score': 0.85528670390001, 'max_history_score_std': 0.02213730791268438, 'max_history_step': 'joint', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 2, 'features__selectkbest__k': 4}), 'normalizer': ('normalizer_StandardScaler', {'normalizer__with_mean': False, 'normalizer__with_std': False}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 5})}, 'score': 0.5932633645158965, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'entropy', 'max_depth': 2, 'max_features': None, 'max_leaf_nodes': None, 'min_samples_split': 5, 'n_estimators': 25}, 'config_hash': {'algorithm': '0b0e954757c4f75343a6efb740ad93260ed781ae', 'config': '47584de0e60d0d12c7dbbf0dc60e5aea96e3f4b2', 'pipeline': 'b37ee32d59413053bf9a2a72c8ff7135f3701e05'}, 'duration': 0.7249000072479248, 'iteration': 9, 'loss': 0.6965910020393421, 'max_history_score': 0.85528670390001, 'max_history_score_std': 0.02213730791268438, 'max_history_step': 'joint', 'pipeline': {'features': ('features_SelectKBest', {'features__k': 3}), 'normalizer': ('normalizer_NoneType', {}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 7})}, 'score': 0.3034089979606579, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'gini', 'max_depth': 2, 'max_features': 2, 'max_leaf_nodes': 5, 'min_samples_split': 5, 'n_estimators': 75}, 'config_hash': {'algorithm': 'f1ead1d9e33ea927e1dd27d872a058fa3de4f832', 'config': 'eecb88ee2b1b95d741c1b5c7751534d31aae6a77', 'pipeline': '6746650871e8b61efc9302b092dc05f7cdb179d5'}, 'duration': 5.340634822845459, 'iteration': 10, 'loss': 0.7687016290977936, 'max_history_score': 0.85528670390001, 'max_history_score_std': 0.02213730791268438, 'max_history_step': 'joint', 'pipeline': {'features': ('features_SelectKBest', {'features__k': 3}), 'normalizer': ('normalizer_RobustScaler', {'normalizer__quantile_range': (...), 'normalizer__with_centering': False, 'normalizer__with_scaling': False}), 'rebalance': ('rebalance_CondensedNearestNeighbour', {'rebalance__n_neighbors': 1})}, 'score': 0.23129837090220637, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': 1, 'max_features': 2, 'max_leaf_nodes': 2, 'min_samples_split': 3, 'n_estimators': 75}, 'config_hash': {'algorithm': '531a3bb8ccf0baa06727af4b3de9e62d25e6eabf', 'config': '27a7ed0502b321ab7256b77c8ce79e90cb9da815', 'pipeline': '77e6d84e2217b92b3cf67cc6defef9dd3554cec0'}, 'duration': 1.775357961654663, 'iteration': 11, 'loss': 0.6313818737375694, 'max_history_score': 0.85528670390001, 'max_history_score_std': 0.02213730791268438, 'max_history_step': 'joint', 'pipeline': {'features': ('features_SelectKBest', {'features__k': 4}), 'normalizer': ('normalizer_MinMaxScaler', {}), 'rebalance': ('rebalance_NearMiss', {'rebalance__n_neighbors': 3})}, 'score': 0.3686181262624307, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'entropy', 'max_depth': 4, 'max_features': 3, 'max_leaf_nodes': 2, 'min_samples_split': 3, 'n_estimators': 10}, 'config_hash': {'algorithm': '93518f8ded6074d537900b26be72f8485782f933', 'config': '45f056102dd2d644bd8befa471f17b2311ac7954', 'pipeline': '5240329df25c9a533d025c1a401d49835a501b41'}, 'duration': 3.2622711658477783, 'iteration': 12, 'loss': 0.6120243191353301, 'max_history_score': 0.85528670390001, 'max_history_score_std': 0.02213730791268438, 'max_history_step': 'joint', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 4, 'features__selectkbest__k': 2}), 'normalizer': ('normalizer_PowerTransformer', {}), 'rebalance': ('rebalance_NearMiss', {'rebalance__n_neighbors': 1})}, 'score': 0.38797568086467, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'entropy', 'max_depth': None, 'max_features': 1, 'max_leaf_nodes': 5, 'min_samples_split': 3, 'n_estimators': 75}, 'config_hash': {'algorithm': 'e515d45b764fa43591032874a0ff9c25bf12fddd', 'config': 'ba108323623936872824ed8f1c41d615d25523b3', 'pipeline': '9d823bc0442f21b5ce8af67a5eb1237f64ffc2f8'}, 'duration': 2.5326571464538574, 'iteration': 13, 'loss': 0.6271427382991047, 'max_history_score': 0.85528670390001, 'max_history_score_std': 0.02213730791268438, 'max_history_step': 'joint', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 1, 'features__selectkbest__k': 1}), 'normalizer': ('normalizer_StandardScaler', {'normalizer__with_mean': True, 'normalizer__with_std': True}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 5})}, 'score': 0.3728572617008953, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'entropy', 'max_depth': 3, 'max_features': 2, 'max_leaf_nodes': 2, 'min_samples_split': 3, 'n_estimators': 25}, 'config_hash': {'algorithm': '2808e67f609eba5c8a97f81ac0c9413cd37cf7aa', 'config': 'dde4d3b5f37741629cb58bfc4051ed9f98c8f311', 'pipeline': 'bc52deabf1f5ee60968ba541d9d2574353c30a9c'}, 'duration': 0.7145559787750244, 'iteration': 14, 'loss': 0.6831045572696203, 'max_history_score': 0.85528670390001, 'max_history_score_std': 0.02213730791268438, 'max_history_step': 'joint', 'pipeline': {'features': ('features_SelectKBest', {'features__k': 3}), 'normalizer': ('normalizer_MinMaxScaler', {}), 'rebalance': ('rebalance_NearMiss', {'rebalance__n_neighbors': 1})}, 'score': 0.31689544273037973, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'gini', 'max_depth': 2, 'max_features': 2, 'max_leaf_nodes': None, 'min_samples_split': 5, 'n_estimators': 100}, 'config_hash': {'algorithm': 'b942acdead762d34afeb474bc2fe6f7fd0f23493', 'config': '1080c25b92da3f15a6f8eec003957f7e0a66324f', 'pipeline': 'cfa84fe703dc5bc0bbd2257a6d524fee2693b804'}, 'duration': 2.812459945678711, 'iteration': 15, 'loss': 0.6921421091202761, 'max_history_score': 0.85528670390001, 'max_history_score_std': 0.02213730791268438, 'max_history_step': 'joint', 'pipeline': {'features': ('features_SelectKBest', {'features__k': 2}), 'normalizer': ('normalizer_PowerTransformer', {}), 'rebalance': ('rebalance_NoneType', {})}, 'score': 0.3078578908797239, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'entropy', 'max_depth': 2, 'max_features': 3, 'max_leaf_nodes': 3, 'min_samples_split': 2, 'n_estimators': 75}, 'config_hash': {'algorithm': '250661ce4193a61ef44d2f77694b52b785ff032d', 'config': 'c3e8cf4eca5aafcae4ac31b0449e105ca127ffe2', 'pipeline': 'c4dd111513ea35f97dd3aec3e8e7f6268ce035da'}, 'duration': 1.0555319786071777, 'iteration': 16, 'loss': 1.0, 'max_history_score': 0.85528670390001, 'max_history_score_std': 0.02213730791268438, 'max_history_step': 'joint', 'pipeline': {'features': ('features_PCA', {'features__n_components': 2}), 'normalizer': ('normalizer_RobustScaler', {'normalizer__quantile_range': (...), 'normalizer__with_centering': False, 'normalizer__with_scaling': True}), 'rebalance': ('rebalance_NearMiss', {'rebalance__n_neighbors': 2})}, 'score': 0.0, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'entropy', 'max_depth': 3, 'max_features': 3, 'max_leaf_nodes': None, 'min_samples_split': 3, 'n_estimators': 25}, 'config_hash': {'algorithm': '05ac02bd045c65dc4089894902ad6253661a2692', 'config': '3449b4a1c2e488e26a7195ee9edca19b854ebd33', 'pipeline': '505d3f71b534917375d765e64b0611e7dfb83746'}, 'duration': 5.5412821769714355, 'iteration': 17, 'loss': 0.7289151155121668, 'max_history_score': 0.85528670390001, 'max_history_score_std': 0.02213730791268438, 'max_history_step': 'joint', 'pipeline': {'features': ('features_SelectKBest', {'features__k': 4}), 'normalizer': ('normalizer_MinMaxScaler', {}), 'rebalance': ('rebalance_CondensedNearestNeighbour', {'rebalance__n_neighbors': 2})}, 'score': 0.2710848844878332, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'entropy', 'max_depth': 2, 'max_features': None, 'max_leaf_nodes': None, 'min_samples_split': 2, 'n_estimators': 25}, 'config_hash': {'algorithm': 'de3b3a352ebb260e16c6b213a08c9144d17a744b', 'config': '224987ffdbbb9b6182cff18d8374518b917e4f2e', 'pipeline': '12c89200a558b2f3b91332566f41050143aecbe7'}, 'duration': 2.4646048545837402, 'iteration': 18, 'loss': 0.6545902512995826, 'max_history_score': 0.85528670390001, 'max_history_score_std': 0.02213730791268438, 'max_history_step': 'joint', 'pipeline': {'features': ('features_NoneType', {}), 'normalizer': ('normalizer_PowerTransformer', {}), 'rebalance': ('rebalance_NearMiss', {'rebalance__n_neighbors': 2})}, 'score': 0.3454097487004174, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'gini', 'max_depth': None, 'max_features': 1, 'max_leaf_nodes': None, 'min_samples_split': 3, 'n_estimators': 100}, 'config_hash': {'algorithm': '30ca111584767bbf0464df40b4c928cf7ddf9459', 'config': '97ca7d6a017c721084dec2a5d2e5a67e1e6ae2f0', 'pipeline': '789eca82ea4a42d61927670c538867b745fd81d3'}, 'duration': 7.164499044418335, 'iteration': 19, 'loss': 0.6536825403350528, 'max_history_score': 0.85528670390001, 'max_history_score_std': 0.02213730791268438, 'max_history_step': 'joint', 'pipeline': {'features': ('features_SelectKBest', {'features__k': 3}), 'normalizer': ('normalizer_RobustScaler', {'normalizer__quantile_range': (...), 'normalizer__with_centering': False, 'normalizer__with_scaling': True}), 'rebalance': ('rebalance_CondensedNearestNeighbour', {'rebalance__n_neighbors': 3})}, 'score': 0.3463174596649472, ...}, ...], 'history_hash': ['fd24b065dda6bdeb1077793f9df480ff318c7a37', 'fb22f80fb4358ae1ee4c9bd4a83543992be8d806', '8c97cdb885dd05cfd8c40ee3ac445b61e5c767a8', '16fbb5fd5cfbbacfddf27c61c0c7397a7f6d8ade', 'a77c698197c31308211b854e81a998178941f87d', '1fc13606bca3aaf342ca6ea21139cb598b56f8db', '6749af1a67b4dbcd2b4719e419d99908063c05e1', 'd92d4ada2394fc132733e176e926ee53acdc6a00', 'f0d0b1d2cedc22ae15d9a208a3fc3fc133bf0d3d', '47584de0e60d0d12c7dbbf0dc60e5aea96e3f4b2', 'eecb88ee2b1b95d741c1b5c7751534d31aae6a77', '27a7ed0502b321ab7256b77c8ce79e90cb9da815', '45f056102dd2d644bd8befa471f17b2311ac7954', 'ba108323623936872824ed8f1c41d615d25523b3', 'dde4d3b5f37741629cb58bfc4051ed9f98c8f311', '1080c25b92da3f15a6f8eec003957f7e0a66324f', 'c3e8cf4eca5aafcae4ac31b0449e105ca127ffe2', '3449b4a1c2e488e26a7195ee9edca19b854ebd33', '224987ffdbbb9b6182cff18d8374518b917e4f2e', '97ca7d6a017c721084dec2a5d2e5a67e1e6ae2f0', ...], 'history_index': {'05465becb12810ce291074be22a0275a42efbea8': 52, '064f53edf4748bb2df4ff59f147331aad21219e1': 48, '087efef4a19f272562d2d445dac0edd8096ba2fa': 58, '0fd4d71ca3a89c7d14af5087f2a2e2c1b1975351': 51, '1080c25b92da3f15a6f8eec003957f7e0a66324f': 15, '143679b59e16961765e77616142572b6ded0ee72': 62, '151b4a15037767108da13dafa0b63ae93222e93a': 53, '16fbb5fd5cfbbacfddf27c61c0c7397a7f6d8ade': 3, '1d125af79272b5204b4ef7b042cf1e45bbca9e17': 70, '1fc13606bca3aaf342ca6ea21139cb598b56f8db': 5, ...}, 'iteration': 75, 'max_history_score': 0.9231904384036744, 'max_history_score_std': 0.03040515884196498, 'max_history_step': 'joint'}, config={'algorithm': 'RandomForest', 'seed': 42, 'time': 300}, step='joint')
     45                 y,
     46                 cv=10,
     47                 n_jobs=-1,
     48                 return_estimator=False,
     49                 return_train_score=False,
---> 50                 verbose=0)
     51         score = np.mean(scores['test_score'])
     52         std = np.std(scores['test_score'])
     53         status = STATUS_OK
     54     except Exception as e:

...........................................................................
/home/aquemy/.local/lib/python2.7/site-packages/sklearn/model_selection/_validation.py in cross_validate(estimator=Pipeline(memory=None,
     steps=[('rebalance', ... random_state=42, verbose=0, warm_start=False))]), X=array([[ 0.,  0.,  5., ...,  0.,  0.,  0.],
    ...0.],
       [ 0.,  0., 10., ..., 12.,  1.,  0.]]), y=array([0, 1, 2, ..., 8, 9, 8]), groups=None, scoring=None, cv=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1, verbose=0, fit_params=None, pre_dispatch='2*n_jobs', return_train_score=False, return_estimator=False, error_score='raise-deprecating')
    235         delayed(_fit_and_score)(
    236             clone(estimator), X, y, scorers, train, test, verbose, None,
    237             fit_params, return_train_score=return_train_score,
    238             return_times=True, return_estimator=return_estimator,
    239             error_score=error_score)
--> 240         for train, test in cv.split(X, y, groups))
        cv.split = <bound method StratifiedKFold.split of Stratifie...d(n_splits=10, random_state=None, shuffle=False)>
        X = array([[ 0.,  0.,  5., ...,  0.,  0.,  0.],
    ...0.],
       [ 0.,  0., 10., ..., 12.,  1.,  0.]])
        y = array([0, 1, 2, ..., 8, 9, 8])
        groups = None
    241 
    242     zipped_scores = list(zip(*scores))
    243     if return_train_score:
    244         train_scores = zipped_scores.pop(0)

...........................................................................
/home/aquemy/.local/lib/python2.7/site-packages/sklearn/externals/joblib/parallel.py in __call__(self=Parallel(n_jobs=-1), iterable=<generator object <genexpr>>)
    925                 # No need to wait for async callbacks to trigger to
    926                 # consumption.
    927                 self._iterating = False
    928 
    929             with self._backend.retrieval_context():
--> 930                 self.retrieve()
        self.retrieve = <bound method Parallel.retrieve of Parallel(n_jobs=-1)>
    931             # Make sure that we get a last message telling us we are done
    932             elapsed_time = time.time() - self._start_time
    933             self._print('Done %3i out of %3i | elapsed: %s finished',
    934                         (len(self._output), len(self._output),

---------------------------------------------------------------------------
Joblib worker traceback:
---------------------------------------------------------------------------
ValueError                                         Mon Jun 17 13:08:49 2019
PID: 20338                                  Python 2.7.15+: /usr/bin/python
...........................................................................
/home/aquemy/.local/lib/python2.7/site-packages/sklearn/externals/joblib/parallel.py in __call__(self=<sklearn.externals.joblib.parallel.BatchedCalls object>)
    220     def __call__(self):
    221         # Set the default nested backend to self._backend but do not set the
    222         # change the default number of processes to -1
    223         with parallel_backend(self._backend, n_jobs=self._n_jobs):
    224             return [func(*args, **kwargs)
--> 225                     for func, args, kwargs in self.items]
        func = <function _fit_and_score>
        args = (Pipeline(memory=None,
     steps=[('rebalance', ... random_state=42, verbose=0, warm_start=False))]), array([[ 0.,  0.,  5., ...,  0.,  0.,  0.],
    ...0.],
       [ 0.,  0., 10., ..., 12.,  1.,  0.]]), array([0, 1, 2, ..., 8, 9, 8]), {'score': <function _passthrough_scorer>}, array([ 169,  176,  178, ..., 1794, 1795, 1796]), array([  0,   1,   2,   3,   4,   5,   6,   7,  ..., 181, 186, 188, 189, 190,
       194, 195, 198]), 0, None, None)
        kwargs = {'error_score': 'raise-deprecating', 'return_estimator': False, 'return_times': True, 'return_train_score': False}
        self.items = [(<function _fit_and_score>, (Pipeline(memory=None,
     steps=[('rebalance', ... random_state=42, verbose=0, warm_start=False))]), array([[ 0.,  0.,  5., ...,  0.,  0.,  0.],
    ...0.],
       [ 0.,  0., 10., ..., 12.,  1.,  0.]]), array([0, 1, 2, ..., 8, 9, 8]), {'score': <function _passthrough_scorer>}, array([ 169,  176,  178, ..., 1794, 1795, 1796]), array([  0,   1,   2,   3,   4,   5,   6,   7,  ..., 181, 186, 188, 189, 190,
       194, 195, 198]), 0, None, None), {'error_score': 'raise-deprecating', 'return_estimator': False, 'return_times': True, 'return_train_score': False})]
    226 
    227     def __len__(self):
    228         return self._size
    229 

...........................................................................
/home/aquemy/.local/lib/python2.7/site-packages/sklearn/model_selection/_validation.py in _fit_and_score(estimator=Pipeline(memory=None,
     steps=[('rebalance', ... random_state=42, verbose=0, warm_start=False))]), X=array([[ 0.,  0.,  5., ...,  0.,  0.,  0.],
    ...0.],
       [ 0.,  0., 10., ..., 12.,  1.,  0.]]), y=array([0, 1, 2, ..., 8, 9, 8]), scorer={'score': <function _passthrough_scorer>}, train=array([ 169,  176,  178, ..., 1794, 1795, 1796]), test=array([  0,   1,   2,   3,   4,   5,   6,   7,  ..., 181, 186, 188, 189, 190,
       194, 195, 198]), verbose=0, parameters=None, fit_params={}, return_train_score=False, return_parameters=False, return_n_test_samples=False, return_times=True, return_estimator=False, error_score='raise-deprecating')
    523 
    524     try:
    525         if y_train is None:
    526             estimator.fit(X_train, **fit_params)
    527         else:
--> 528             estimator.fit(X_train, y_train, **fit_params)
        estimator.fit = <bound method Pipeline.fit of Pipeline(memory=No...random_state=42, verbose=0, warm_start=False))])>
        X_train = array([[ 0.,  0.,  6., ...,  9.,  4.,  0.],
    ...0.],
       [ 0.,  0., 10., ..., 12.,  1.,  0.]])
        y_train = array([9, 5, 0, ..., 8, 9, 8])
        fit_params = {}
    529 
    530     except Exception as e:
    531         # Note fit time as time until error
    532         fit_time = time.time() - start_time

...........................................................................
/usr/local/lib/python2.7/dist-packages/imblearn/pipeline.py in fit(self=Pipeline(memory=None,
     steps=[('rebalance', ... random_state=42, verbose=0, warm_start=False))]), X=array([[ 0.,  0.,  6., ...,  9.,  4.,  0.],
    ...0.],
       [ 0.,  0., 10., ..., 12.,  1.,  0.]]), y=array([9, 5, 0, ..., 8, 9, 8]), **fit_params={})
    234             This estimator
    235 
    236         """
    237         Xt, yt, fit_params = self._fit(X, y, **fit_params)
    238         if self._final_estimator is not None:
--> 239             self._final_estimator.fit(Xt, yt, **fit_params)
        self._final_estimator.fit = <bound method RandomForestClassifier.fit of Rand...e, random_state=42, verbose=0, warm_start=False)>
        Xt = array([[ 1.14164567],
       [ 1.14164567],
    ...13],
       [ 0.32947977],
       [-0.82361613]])
        yt = array([0, 0, 0, ..., 9, 9, 9])
        fit_params = {}
    240         return self
    241 
    242     def fit_transform(self, X, y=None, **fit_params):
    243         """Fit the model and transform with the final estimator

...........................................................................
/home/aquemy/.local/lib/python2.7/site-packages/sklearn/ensemble/forest.py in fit(self=RandomForestClassifier(bootstrap=True, class_wei...se, random_state=42, verbose=0, warm_start=False), X=array([[ 1.1416457 ],
       [ 1.1416457 ],
    ....32947975],
       [-0.82361615]], dtype=float32), y=array([[0.],
       [0.],
       [0.],
       ...,
       [9.],
       [9.],
       [9.]]), sample_weight=None)
    328             trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,
    329                              **_joblib_parallel_args(prefer='threads'))(
    330                 delayed(_parallel_build_trees)(
    331                     t, self, X, y, sample_weight, i, len(trees),
    332                     verbose=self.verbose, class_weight=self.class_weight)
--> 333                 for i, t in enumerate(trees))
        i = 24
    334 
    335             # Collect newly grown trees
    336             self.estimators_.extend(trees)
    337 

...........................................................................
/home/aquemy/.local/lib/python2.7/site-packages/sklearn/externals/joblib/parallel.py in __call__(self=Parallel(n_jobs=1), iterable=<generator object <genexpr>>)
    912             # self._original_iterator is None, then this means either
    913             # that pre_dispatch == "all", n_jobs == 1 or that the first batch
    914             # was very quick and its callback already dispatched all the
    915             # remaining jobs.
    916             self._iterating = False
--> 917             if self.dispatch_one_batch(iterator):
        self.dispatch_one_batch = <bound method Parallel.dispatch_one_batch of Parallel(n_jobs=1)>
        iterator = <generator object <genexpr>>
    918                 self._iterating = self._original_iterator is not None
    919 
    920             while self.dispatch_one_batch(iterator):
    921                 pass

...........................................................................
/home/aquemy/.local/lib/python2.7/site-packages/sklearn/externals/joblib/parallel.py in dispatch_one_batch(self=Parallel(n_jobs=1), iterator=<generator object <genexpr>>)
    754                                  self._pickle_cache)
    755             if len(tasks) == 0:
    756                 # No more tasks available in the iterator: tell caller to stop.
    757                 return False
    758             else:
--> 759                 self._dispatch(tasks)
        self._dispatch = <bound method Parallel._dispatch of Parallel(n_jobs=1)>
        tasks = <sklearn.externals.joblib.parallel.BatchedCalls object>
    760                 return True
    761 
    762     def _print(self, msg, msg_args):
    763         """Display the message on stout or stderr depending on verbosity"""

...........................................................................
/home/aquemy/.local/lib/python2.7/site-packages/sklearn/externals/joblib/parallel.py in _dispatch(self=Parallel(n_jobs=1), batch=<sklearn.externals.joblib.parallel.BatchedCalls object>)
    711 
    712         dispatch_timestamp = time.time()
    713         cb = BatchCompletionCallBack(dispatch_timestamp, len(batch), self)
    714         with self._lock:
    715             job_idx = len(self._jobs)
--> 716             job = self._backend.apply_async(batch, callback=cb)
        job = undefined
        self._backend.apply_async = <bound method SequentialBackend.apply_async of <...lib._parallel_backends.SequentialBackend object>>
        batch = <sklearn.externals.joblib.parallel.BatchedCalls object>
        cb = <sklearn.externals.joblib.parallel.BatchCompletionCallBack object>
    717             # A job can complete so quickly than its callback is
    718             # called before we get here, causing self._jobs to
    719             # grow. To ensure correct results ordering, .insert is
    720             # used (rather than .append) in the following line

...........................................................................
/home/aquemy/.local/lib/python2.7/site-packages/sklearn/externals/joblib/_parallel_backends.py in apply_async(self=<sklearn.externals.joblib._parallel_backends.SequentialBackend object>, func=<sklearn.externals.joblib.parallel.BatchedCalls object>, callback=<sklearn.externals.joblib.parallel.BatchCompletionCallBack object>)
    177             raise ValueError('n_jobs == 0 in Parallel has no meaning')
    178         return 1
    179 
    180     def apply_async(self, func, callback=None):
    181         """Schedule a func to be run"""
--> 182         result = ImmediateResult(func)
        result = undefined
        func = <sklearn.externals.joblib.parallel.BatchedCalls object>
    183         if callback:
    184             callback(result)
    185         return result
    186 

...........................................................................
/home/aquemy/.local/lib/python2.7/site-packages/sklearn/externals/joblib/_parallel_backends.py in __init__(self=<sklearn.externals.joblib._parallel_backends.ImmediateResult object>, batch=<sklearn.externals.joblib.parallel.BatchedCalls object>)
    544 
    545 class ImmediateResult(object):
    546     def __init__(self, batch):
    547         # Don't delay the application, to avoid keeping the input
    548         # arguments in memory
--> 549         self.results = batch()
        self.results = undefined
        batch = <sklearn.externals.joblib.parallel.BatchedCalls object>
    550 
    551     def get(self):
    552         return self.results
    553 

...........................................................................
/home/aquemy/.local/lib/python2.7/site-packages/sklearn/externals/joblib/parallel.py in __call__(self=<sklearn.externals.joblib.parallel.BatchedCalls object>)
    220     def __call__(self):
    221         # Set the default nested backend to self._backend but do not set the
    222         # change the default number of processes to -1
    223         with parallel_backend(self._backend, n_jobs=self._n_jobs):
    224             return [func(*args, **kwargs)
--> 225                     for func, args, kwargs in self.items]
        func = <function _parallel_build_trees>
        args = (DecisionTreeClassifier(class_weight=None, criter...=False, random_state=1608637542, splitter='best'), RandomForestClassifier(bootstrap=True, class_wei...se, random_state=42, verbose=0, warm_start=False), array([[ 1.1416457 ],
       [ 1.1416457 ],
    ....32947975],
       [-0.82361615]], dtype=float32), array([[0.],
       [0.],
       [0.],
       ...,
       [9.],
       [9.],
       [9.]]), None, 0, 25)
        kwargs = {'class_weight': None, 'verbose': 0}
        self.items = [(<function _parallel_build_trees>, (DecisionTreeClassifier(class_weight=None, criter...=False, random_state=1608637542, splitter='best'), RandomForestClassifier(bootstrap=True, class_wei...se, random_state=42, verbose=0, warm_start=False), array([[ 1.1416457 ],
       [ 1.1416457 ],
    ....32947975],
       [-0.82361615]], dtype=float32), array([[0.],
       [0.],
       [0.],
       ...,
       [9.],
       [9.],
       [9.]]), None, 0, 25), {'class_weight': None, 'verbose': 0})]
    226 
    227     def __len__(self):
    228         return self._size
    229 

...........................................................................
/home/aquemy/.local/lib/python2.7/site-packages/sklearn/ensemble/forest.py in _parallel_build_trees(tree=DecisionTreeClassifier(class_weight=None, criter...=False, random_state=1608637542, splitter='best'), forest=RandomForestClassifier(bootstrap=True, class_wei...se, random_state=42, verbose=0, warm_start=False), X=array([[ 1.1416457 ],
       [ 1.1416457 ],
    ....32947975],
       [-0.82361615]], dtype=float32), y=array([[0.],
       [0.],
       [0.],
       ...,
       [9.],
       [9.],
       [9.]]), sample_weight=None, tree_idx=0, n_trees=25, verbose=0, class_weight=None)
    114                 simplefilter('ignore', DeprecationWarning)
    115                 curr_sample_weight *= compute_sample_weight('auto', y, indices)
    116         elif class_weight == 'balanced_subsample':
    117             curr_sample_weight *= compute_sample_weight('balanced', y, indices)
    118 
--> 119         tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)
        tree.fit = <bound method DecisionTreeClassifier.fit of Deci...False, random_state=1608637542, splitter='best')>
        X = array([[ 1.1416457 ],
       [ 1.1416457 ],
    ....32947975],
       [-0.82361615]], dtype=float32)
        y = array([[0.],
       [0.],
       [0.],
       ...,
       [9.],
       [9.],
       [9.]])
        sample_weight = None
        curr_sample_weight = array([1., 2., 0., ..., 0., 0., 2.])
    120     else:
    121         tree.fit(X, y, sample_weight=sample_weight, check_input=False)
    122 
    123     return tree

...........................................................................
/home/aquemy/.local/lib/python2.7/site-packages/sklearn/tree/tree.py in fit(self=DecisionTreeClassifier(class_weight=None, criter...=False, random_state=1608637542, splitter='best'), X=array([[ 1.1416457 ],
       [ 1.1416457 ],
    ....32947975],
       [-0.82361615]], dtype=float32), y=array([[0.],
       [0.],
       [0.],
       ...,
       [9.],
       [9.],
       [9.]]), sample_weight=array([1., 2., 0., ..., 0., 0., 2.]), check_input=False, X_idx_sorted=None)
    796 
    797         super(DecisionTreeClassifier, self).fit(
    798             X, y,
    799             sample_weight=sample_weight,
    800             check_input=check_input,
--> 801             X_idx_sorted=X_idx_sorted)
        X_idx_sorted = None
    802         return self
    803 
    804     def predict_proba(self, X, check_input=True):
    805         """Predict class probabilities of the input samples X.

...........................................................................
/home/aquemy/.local/lib/python2.7/site-packages/sklearn/tree/tree.py in fit(self=DecisionTreeClassifier(class_weight=None, criter...=False, random_state=1608637542, splitter='best'), X=array([[ 1.1416457 ],
       [ 1.1416457 ],
    ....32947975],
       [-0.82361615]], dtype=float32), y=array([[0.],
       [0.],
       [0.],
       ...,
       [9.],
       [9.],
       [9.]]), sample_weight=array([1., 2., 0., ..., 0., 0., 2.]), check_input=False, X_idx_sorted=None)
    237         if not 0 <= self.min_weight_fraction_leaf <= 0.5:
    238             raise ValueError("min_weight_fraction_leaf must in [0, 0.5]")
    239         if max_depth <= 0:
    240             raise ValueError("max_depth must be greater than zero. ")
    241         if not (0 < max_features <= self.n_features_):
--> 242             raise ValueError("max_features must be in (0, n_features]")
    243         if not isinstance(max_leaf_nodes, (numbers.Integral, np.integer)):
    244             raise ValueError("max_leaf_nodes must be integral number but was "
    245                              "%r" % max_leaf_nodes)
    246         if -1 < max_leaf_nodes < 2:

ValueError: max_features must be in (0, n_features]
___________________________________________________________________________
Best score: 0.923190438404 (0.030405158842) [J] | Score: 0.0 (0.0) [J]
Best score: 0.923190438404 (0.030405158842) [J] | Score: 0.430657703273 (0.0339337455021) [J]
Best score: 0.923190438404 (0.030405158842) [J] | Score: 0.0968163392773 (0.00179561960358) [J]
Best score: 0.923190438404 (0.030405158842) [J] | Score: 0.503959975805 (0.0504231037732) [J]
Best score: 0.923190438404 (0.030405158842) [J] | Score: 0.52495852568 (0.068532906074) [J]
Best score: 0.923190438404 (0.030405158842) [J] | Score: 0.458876989498 (0.0495421959751) [J]
Best score: 0.923190438404 (0.030405158842) [J] | Score: 0.326782464516 (0.0395010337167) [J]
Best score: 0.923190438404 (0.030405158842) [J] | Score: 0.647470733165 (0.0453710475931) [J]
Best score: 0.923190438404 (0.030405158842) [J] | Score: 0.0968163392773 (0.00179561960358) [J]
Best score: 0.923190438404 (0.030405158842) [J] | Score: 0.823413194497 (0.0470975876208) [J]
Best score: 0.923190438404 (0.030405158842) [J] | Score: 0.484626900659 (0.0638745273557) [J]
Best score: 0.923190438404 (0.030405158842) [J] | Score: 0.599758923644 (0.0337219294926) [J]
Best score: 0.923190438404 (0.030405158842) [J] | Score: 0.741221130561 (0.0293120116697) [J]
JoblibValueError
___________________________________________________________________________
...........................................................................
/home/aquemy/dev/dp_hyperparameters/extension/main.py in <module>()
     27 
     28     serializer.serialize_results(scenario, policy)
     29 
     30 if __name__ == "__main__":
     31     args = cli.parse_args()
---> 32     main(args)

...........................................................................
/home/aquemy/dev/dp_hyperparameters/extension/main.py in main(args=Namespace(customize=[(['control', 'seed'], '42')...='./scenarios/rf_digits_joint.yaml', verbosity=0))
     21         test_size=0.4, 
     22         random_state=scenario['control']['seed']
     23     )
     24 
     25     policy = policies.initiate(scenario['setup']['policy'], config)
---> 26     policy.run(X,y)
        policy.run = <bound method Joint.run of <experiment.policies.joint.Joint object>>
        X = array([[ 0.,  0.,  5., ...,  0.,  0.,  0.],
    ...0.],
       [ 0.,  0., 10., ..., 12.,  1.,  0.]])
        y = array([0, 1, 2, ..., 8, 9, 8])
     27 
     28     serializer.serialize_results(scenario, policy)
     29 
     30 if __name__ == "__main__":

...........................................................................
/home/aquemy/dev/dp_hyperparameters/extension/experiment/policies/joint.py in run(self=<experiment.policies.joint.Joint object>, X=array([[ 0.,  0.,  5., ...,  0.,  0.,  0.],
    ...0.],
       [ 0.,  0., 10., ..., 12.,  1.,  0.]]), y=array([0, 1, 2, ..., 8, 9, 8]))
     32             algo=tpe.suggest, 
     33             max_evals=None,
     34             max_time=self.config['time'],     
     35             trials=trials,
     36             show_progressbar=False,
---> 37             verbose=0
     38         )
     39 
     40         best_config = self.context['best_config']
     41         super(Joint, self).display_step_results(best_config)

...........................................................................
/home/aquemy/dev/dp_hyperparameters/extension/hyperopt/fmin.py in fmin(fn=<functools.partial object>, space={'algorithm': {'bootstrap': <hyperopt.pyll.base.Apply object>, 'criterion': <hyperopt.pyll.base.Apply object>, 'max_depth': <hyperopt.pyll.base.Apply object>, 'max_features': <hyperopt.pyll.base.Apply object>, 'max_leaf_nodes': <hyperopt.pyll.base.Apply object>, 'min_samples_split': <hyperopt.pyll.base.Apply object>, 'n_estimators': <hyperopt.pyll.base.Apply object>}, 'pipeline': {'features': <hyperopt.pyll.base.Apply object>, 'normalizer': <hyperopt.pyll.base.Apply object>, 'rebalance': <hyperopt.pyll.base.Apply object>}}, algo=<function suggest>, max_evals=9223372036854775807, max_time=300, trials=<hyperopt.base.Trials object>, rstate=<mtrand.RandomState object>, allow_trials_fmin=True, pass_expr_memo_ctrl=None, catch_eval_exceptions=False, verbose=0, return_argmin=True, points_to_evaluate=None, max_queue_len=1, show_progressbar=False)
    406             pass_expr_memo_ctrl=pass_expr_memo_ctrl,
    407             verbose=verbose,
    408             catch_eval_exceptions=catch_eval_exceptions,
    409             return_argmin=return_argmin,
    410             show_progressbar=show_progressbar,
--> 411             max_time=max_time
        max_time = 300
    412         )
    413 
    414     if trials is None:
    415         if points_to_evaluate is None:

...........................................................................
/home/aquemy/dev/dp_hyperparameters/extension/hyperopt/base.py in fmin(self=<hyperopt.base.Trials object>, fn=<functools.partial object>, space={'algorithm': {'bootstrap': <hyperopt.pyll.base.Apply object>, 'criterion': <hyperopt.pyll.base.Apply object>, 'max_depth': <hyperopt.pyll.base.Apply object>, 'max_features': <hyperopt.pyll.base.Apply object>, 'max_leaf_nodes': <hyperopt.pyll.base.Apply object>, 'min_samples_split': <hyperopt.pyll.base.Apply object>, 'n_estimators': <hyperopt.pyll.base.Apply object>}, 'pipeline': {'features': <hyperopt.pyll.base.Apply object>, 'normalizer': <hyperopt.pyll.base.Apply object>, 'rebalance': <hyperopt.pyll.base.Apply object>}}, algo=<function suggest>, max_evals=9223372036854775807, max_time=300, rstate=<mtrand.RandomState object>, verbose=0, pass_expr_memo_ctrl=None, catch_eval_exceptions=False, return_argmin=True, show_progressbar=False)
    636             verbose=verbose,
    637             allow_trials_fmin=False,  # -- prevent recursion
    638             pass_expr_memo_ctrl=pass_expr_memo_ctrl,
    639             catch_eval_exceptions=catch_eval_exceptions,
    640             return_argmin=return_argmin,
--> 641             show_progressbar=show_progressbar)
        show_progressbar = False
    642 
    643 
    644 def trials_from_docs(docs, validate=True, **kwargs):
    645     """Construct a Trials base class instance from a list of trials documents

...........................................................................
/home/aquemy/dev/dp_hyperparameters/extension/hyperopt/fmin.py in fmin(fn=<functools.partial object>, space={'algorithm': {'bootstrap': <hyperopt.pyll.base.Apply object>, 'criterion': <hyperopt.pyll.base.Apply object>, 'max_depth': <hyperopt.pyll.base.Apply object>, 'max_features': <hyperopt.pyll.base.Apply object>, 'max_leaf_nodes': <hyperopt.pyll.base.Apply object>, 'min_samples_split': <hyperopt.pyll.base.Apply object>, 'n_estimators': <hyperopt.pyll.base.Apply object>}, 'pipeline': {'features': <hyperopt.pyll.base.Apply object>, 'normalizer': <hyperopt.pyll.base.Apply object>, 'rebalance': <hyperopt.pyll.base.Apply object>}}, algo=<function suggest>, max_evals=9223372036854775807, max_time=300, trials=<hyperopt.base.Trials object>, rstate=<mtrand.RandomState object>, allow_trials_fmin=False, pass_expr_memo_ctrl=None, catch_eval_exceptions=False, verbose=0, return_argmin=True, points_to_evaluate=None, max_queue_len=1, show_progressbar=False)
    426                     verbose=verbose,
    427                     max_queue_len=max_queue_len,
    428                     show_progressbar=show_progressbar,
    429                     max_time=max_time)
    430     rval.catch_eval_exceptions = catch_eval_exceptions
--> 431     rval.exhaust()
        rval.exhaust = <bound method FMinIter.exhaust of <hyperopt.fmin.FMinIter object>>
    432     if return_argmin:
    433         return trials.argmin
    434     elif len(trials) > 0:
    435         # Only if there are some succesfull trail runs, return the best point in the evaluation space

...........................................................................
/home/aquemy/dev/dp_hyperparameters/extension/hyperopt/fmin.py in exhaust(self=<hyperopt.fmin.FMinIter object>)
    273             raise StopIteration()
    274         return self.trials
    275 
    276     def exhaust(self):
    277         n_done = len(self.trials)
--> 278         self.run(self.max_evals - n_done, block_until_done=self.asynchronous)
        self.run = <bound method FMinIter.run of <hyperopt.fmin.FMinIter object>>
        self.max_evals = 9223372036854775807
        n_done = 0
        self.asynchronous = False
    279         self.trials.refresh()
    280         return self
    281 
    282 

...........................................................................
/home/aquemy/dev/dp_hyperparameters/extension/hyperopt/fmin.py in run(self=<hyperopt.fmin.FMinIter object>, N=9223372036854775807, block_until_done=False)
    232                     if self.asynchronous:
    233                         # -- wait for workers to fill in the trials
    234                         time.sleep(self.poll_interval_secs)
    235                     else:
    236                         # -- loop over trials and do the jobs directly
--> 237                         self.serial_evaluate()
        self.serial_evaluate = <bound method FMinIter.serial_evaluate of <hyperopt.fmin.FMinIter object>>
    238                     try:
    239                         res = [d['result']['loss'] for d in
    240                                          self.trials.trials if
    241                                          d['result']['status'] == 'ok']

...........................................................................
/home/aquemy/dev/dp_hyperparameters/extension/hyperopt/fmin.py in serial_evaluate(self=<hyperopt.fmin.FMinIter object>, N=-1)
    138                 trial['book_time'] = now
    139                 trial['refresh_time'] = now
    140                 spec = base.spec_from_misc(trial['misc'])
    141                 ctrl = base.Ctrl(self.trials, current_trial=trial)
    142                 try:
--> 143                     result = self.domain.evaluate(spec, ctrl)
        result = undefined
        self.domain.evaluate = <bound method Domain.evaluate of <hyperopt.base.Domain object>>
        spec = {'bootstrap': 1, 'criterion': 1, 'features': 2, 'features_SelectKBest_features__k': 1, 'max_depth': 2, 'max_features': 2, 'max_leaf_nodes': 2, 'min_samples_split': 0, 'n_estimators': 3, 'normalizer': 0, ...}
        ctrl = <hyperopt.base.Ctrl object>
    144                 except Exception as e:
    145                     logger.info('job exception: %s' % str(e))
    146                     trial['state'] = base.JOB_STATE_ERROR
    147                     trial['misc']['error'] = (str(type(e)), str(e))

...........................................................................
/home/aquemy/dev/dp_hyperparameters/extension/hyperopt/base.py in evaluate(self=<hyperopt.base.Domain object>, config={'bootstrap': 1, 'criterion': 1, 'features': 2, 'features_SelectKBest_features__k': 1, 'max_depth': 2, 'max_features': 2, 'max_leaf_nodes': 2, 'min_samples_split': 0, 'n_estimators': 3, 'normalizer': 0, ...}, ctrl=<hyperopt.base.Ctrl object>, attach_attachments=True)
    841             #    or the normal Python part (self.fn)
    842             pyll_rval = pyll.rec_eval(
    843                 self.expr,
    844                 memo=memo,
    845                 print_node_on_error=self.rec_eval_print_node_on_error)
--> 846             rval = self.fn(pyll_rval)
        rval = undefined
        self.fn = <functools.partial object>
        pyll_rval = {'algorithm': {'bootstrap': False, 'criterion': 'entropy', 'max_depth': 3, 'max_features': 3, 'max_leaf_nodes': 5, 'min_samples_split': 2, 'n_estimators': 75}, 'pipeline': {'features': ('features_SelectKBest', {'features__k': 2}), 'normalizer': ('normalizer_NoneType', {}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 5})}}
    847 
    848         if isinstance(rval, (float, int, np.number)):
    849             dict_rval = {'loss': float(rval), 'status': STATUS_OK}
    850         else:

...........................................................................
/home/aquemy/dev/dp_hyperparameters/extension/experiment/objective.py in objective_joint(wconfig={'algorithm': {'bootstrap': False, 'criterion': 'entropy', 'max_depth': 3, 'max_features': 3, 'max_leaf_nodes': 5, 'min_samples_split': 2, 'n_estimators': 75}, 'pipeline': {'features': ('features_SelectKBest', {'features__k': 2}), 'normalizer': ('normalizer_NoneType', {}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 5})}}, algorithm='RandomForest', X=array([[ 0.,  0.,  5., ...,  0.,  0.,  0.],
    ...0.],
       [ 0.,  0., 10., ..., 12.,  1.,  0.]]), y=array([0, 1, 2, ..., 8, 9, 8]), context={'baseline_score': 0.9272021217853512, 'baseline_score_std': 0.026919033284817703, 'best_config': {'algorithm': {'bootstrap': True, 'criterion': 'entropy', 'max_depth': None, 'max_features': None, 'max_leaf_nodes': None, 'min_samples_split': 3, 'n_estimators': 75}, 'config_hash': {'algorithm': 'f42e45bee34ac9973699212f6c8b845daea9383a', 'config': 'ae61cfde4c8b4c792e42d6b6be4af4ffb3d90e13', 'pipeline': '15ff3d6270ac899763bb3f72417c48bcd56aa7d8'}, 'duration': 8.20555305480957, 'iteration': 65, 'loss': 0.07680956159632557, 'max_history_score': 0.9231904384036744, 'max_history_score_std': 0.03040515884196498, 'max_history_step': 'joint', 'pipeline': {'features': ('features_NoneType', {}), 'normalizer': ('normalizer_StandardScaler', {'normalizer__with_mean': True, 'normalizer__with_std': True}), 'rebalance': ('rebalance_NearMiss', {'rebalance__n_neighbors': 1})}, 'score': 0.9231904384036744, ...}, 'history': [{'algorithm': {'bootstrap': False, 'criterion': 'entropy', 'max_depth': 1, 'max_features': 3, 'max_leaf_nodes': 3, 'min_samples_split': 5, 'n_estimators': 50}, 'config_hash': {'algorithm': '752fa095cdab58a238ae606c613606188964cc0c', 'config': 'fd24b065dda6bdeb1077793f9df480ff318c7a37', 'pipeline': '13ea3359c453b8993fcec1e88bc0e19cd0a2b112'}, 'duration': 0.689669132232666, 'iteration': 0, 'loss': 0.6602879519109309, 'max_history_score': 0.3397120480890691, 'max_history_score_std': 0.03346542949100545, 'max_history_step': 'joint', 'pipeline': {'features': ('features_SelectKBest', {'features__k': 4}), 'normalizer': ('normalizer_MinMaxScaler', {}), 'rebalance': ('rebalance_NoneType', {})}, 'score': 0.3397120480890691, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'gini', 'max_depth': 4, 'max_features': 1, 'max_leaf_nodes': 5, 'min_samples_split': 3, 'n_estimators': 25}, 'config_hash': {'algorithm': '9d9de4aee820052ddfe83bfffca420f6b50837d3', 'config': 'fb22f80fb4358ae1ee4c9bd4a83543992be8d806', 'pipeline': '6251ad4bb7a110726a67f90c319f4717ac37a312'}, 'duration': 1.4300940036773682, 'iteration': 1, 'loss': 0.5122196101741096, 'max_history_score': 0.48778038982589045, 'max_history_score_std': 0.05486079759217226, 'max_history_step': 'joint', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 2, 'features__selectkbest__k': 2}), 'normalizer': ('normalizer_StandardScaler', {'normalizer__with_mean': True, 'normalizer__with_std': True}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 5})}, 'score': 0.48778038982589045, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': 4, 'max_features': 1, 'max_leaf_nodes': None, 'min_samples_split': 2, 'n_estimators': 10}, 'config_hash': {'algorithm': '2ed7d27df9a1b2d5e63da76f7cb309616c232022', 'config': '8c97cdb885dd05cfd8c40ee3ac445b61e5c767a8', 'pipeline': 'c0abb5e23a4739d3120740a9519fb36c43eb94d5'}, 'duration': 3.0036678314208984, 'iteration': 2, 'loss': 0.38319264175312906, 'max_history_score': 0.6168073582468709, 'max_history_score_std': 0.05286679173001824, 'max_history_step': 'joint', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 1, 'features__selectkbest__k': 4}), 'normalizer': ('normalizer_PowerTransformer', {}), 'rebalance': ('rebalance_NearMiss', {'rebalance__n_neighbors': 2})}, 'score': 0.6168073582468709, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'entropy', 'max_depth': None, 'max_features': None, 'max_leaf_nodes': 2, 'min_samples_split': 2, 'n_estimators': 100}, 'config_hash': {'algorithm': '17962655e3b76dfcd0843d1e5c2cb7a9db1c6a79', 'config': '16fbb5fd5cfbbacfddf27c61c0c7397a7f6d8ade', 'pipeline': '13ea3359c453b8993fcec1e88bc0e19cd0a2b112'}, 'duration': 1.3447980880737305, 'iteration': 3, 'loss': 0.6768840987778313, 'max_history_score': 0.6168073582468709, 'max_history_score_std': 0.05286679173001824, 'max_history_step': 'joint', 'pipeline': {'features': ('features_SelectKBest', {'features__k': 4}), 'normalizer': ('normalizer_MinMaxScaler', {}), 'rebalance': ('rebalance_NoneType', {})}, 'score': 0.32311590122216866, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'gini', 'max_depth': 2, 'max_features': 2, 'max_leaf_nodes': 2, 'min_samples_split': 3, 'n_estimators': 100}, 'config_hash': {'algorithm': '1ea8965b2247f86950e54510ee6d79399816341b', 'config': 'a77c698197c31308211b854e81a998178941f87d', 'pipeline': 'aaf976c7c663a31fa039582d42f9e07101556a7c'}, 'duration': 2.589430093765259, 'iteration': 4, 'loss': 0.2544808950572157, 'max_history_score': 0.7455191049427843, 'max_history_score_std': 0.04843448308166839, 'max_history_step': 'joint', 'pipeline': {'features': ('features_NoneType', {}), 'normalizer': ('normalizer_PowerTransformer', {}), 'rebalance': ('rebalance_NoneType', {})}, 'score': 0.7455191049427843, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': None, 'max_features': 2, 'max_leaf_nodes': 5, 'min_samples_split': 5, 'n_estimators': 25}, 'config_hash': {'algorithm': 'fd8aeb6a05eaaba41e676d60596c8e0c71b35e0c', 'config': '1fc13606bca3aaf342ca6ea21139cb598b56f8db', 'pipeline': 'f00bd8de05642e026bbba4ad20d3a60088c86b6c'}, 'duration': 1.8779079914093018, 'iteration': 5, 'loss': 0.531551018758381, 'max_history_score': 0.7455191049427843, 'max_history_score_std': 0.04843448308166839, 'max_history_step': 'joint', 'pipeline': {'features': ('features_PCA', {'features__n_components': 2}), 'normalizer': ('normalizer_MinMaxScaler', {}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 5})}, 'score': 0.46844898124161904, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'entropy', 'max_depth': None, 'max_features': 2, 'max_leaf_nodes': None, 'min_samples_split': 2, 'n_estimators': 10}, 'config_hash': {'algorithm': 'a49ecb99e74217d6812f98ead7bc9d1fe4a53ba0', 'config': '6749af1a67b4dbcd2b4719e419d99908063c05e1', 'pipeline': '19bdf19a2eec5febce95ab8fa2a71040d75114aa'}, 'duration': 1.5498578548431396, 'iteration': 6, 'loss': 0.14471329609998995, 'max_history_score': 0.85528670390001, 'max_history_score_std': 0.02213730791268438, 'max_history_step': 'joint', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 4, 'features__selectkbest__k': 3}), 'normalizer': ('normalizer_NoneType', {}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 7})}, 'score': 0.85528670390001, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': 1, 'max_features': 3, 'max_leaf_nodes': 3, 'min_samples_split': 3, 'n_estimators': 75}, 'config_hash': {'algorithm': 'ebfb16234172ae811ff21185ff92bbdbb8f32f14', 'config': 'd92d4ada2394fc132733e176e926ee53acdc6a00', 'pipeline': '8071e7cbf86a5c3056493dc3aa40063aeb28cdfe'}, 'duration': 1.3618149757385254, 'iteration': 7, 'loss': 0.6158612049395463, 'max_history_score': 0.85528670390001, 'max_history_score_std': 0.02213730791268438, 'max_history_step': 'joint', 'pipeline': {'features': ('features_SelectKBest', {'features__k': 4}), 'normalizer': ('normalizer_StandardScaler', {'normalizer__with_mean': True, 'normalizer__with_std': True}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 5})}, 'score': 0.3841387950604537, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'entropy', 'max_depth': 1, 'max_features': 1, 'max_leaf_nodes': 5, 'min_samples_split': 2, 'n_estimators': 100}, 'config_hash': {'algorithm': '896b53c75a2db568fb7b6da3bfca2f7a1535a11b', 'config': 'f0d0b1d2cedc22ae15d9a208a3fc3fc133bf0d3d', 'pipeline': 'c9761c9a33bf75d6dcad0742c421548a7655ccc9'}, 'duration': 2.297278881072998, 'iteration': 8, 'loss': 0.40673663548410355, 'max_history_score': 0.85528670390001, 'max_history_score_std': 0.02213730791268438, 'max_history_step': 'joint', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 2, 'features__selectkbest__k': 4}), 'normalizer': ('normalizer_StandardScaler', {'normalizer__with_mean': False, 'normalizer__with_std': False}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 5})}, 'score': 0.5932633645158965, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'entropy', 'max_depth': 2, 'max_features': None, 'max_leaf_nodes': None, 'min_samples_split': 5, 'n_estimators': 25}, 'config_hash': {'algorithm': '0b0e954757c4f75343a6efb740ad93260ed781ae', 'config': '47584de0e60d0d12c7dbbf0dc60e5aea96e3f4b2', 'pipeline': 'b37ee32d59413053bf9a2a72c8ff7135f3701e05'}, 'duration': 0.7249000072479248, 'iteration': 9, 'loss': 0.6965910020393421, 'max_history_score': 0.85528670390001, 'max_history_score_std': 0.02213730791268438, 'max_history_step': 'joint', 'pipeline': {'features': ('features_SelectKBest', {'features__k': 3}), 'normalizer': ('normalizer_NoneType', {}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 7})}, 'score': 0.3034089979606579, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'gini', 'max_depth': 2, 'max_features': 2, 'max_leaf_nodes': 5, 'min_samples_split': 5, 'n_estimators': 75}, 'config_hash': {'algorithm': 'f1ead1d9e33ea927e1dd27d872a058fa3de4f832', 'config': 'eecb88ee2b1b95d741c1b5c7751534d31aae6a77', 'pipeline': '6746650871e8b61efc9302b092dc05f7cdb179d5'}, 'duration': 5.340634822845459, 'iteration': 10, 'loss': 0.7687016290977936, 'max_history_score': 0.85528670390001, 'max_history_score_std': 0.02213730791268438, 'max_history_step': 'joint', 'pipeline': {'features': ('features_SelectKBest', {'features__k': 3}), 'normalizer': ('normalizer_RobustScaler', {'normalizer__quantile_range': (...), 'normalizer__with_centering': False, 'normalizer__with_scaling': False}), 'rebalance': ('rebalance_CondensedNearestNeighbour', {'rebalance__n_neighbors': 1})}, 'score': 0.23129837090220637, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': 1, 'max_features': 2, 'max_leaf_nodes': 2, 'min_samples_split': 3, 'n_estimators': 75}, 'config_hash': {'algorithm': '531a3bb8ccf0baa06727af4b3de9e62d25e6eabf', 'config': '27a7ed0502b321ab7256b77c8ce79e90cb9da815', 'pipeline': '77e6d84e2217b92b3cf67cc6defef9dd3554cec0'}, 'duration': 1.775357961654663, 'iteration': 11, 'loss': 0.6313818737375694, 'max_history_score': 0.85528670390001, 'max_history_score_std': 0.02213730791268438, 'max_history_step': 'joint', 'pipeline': {'features': ('features_SelectKBest', {'features__k': 4}), 'normalizer': ('normalizer_MinMaxScaler', {}), 'rebalance': ('rebalance_NearMiss', {'rebalance__n_neighbors': 3})}, 'score': 0.3686181262624307, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'entropy', 'max_depth': 4, 'max_features': 3, 'max_leaf_nodes': 2, 'min_samples_split': 3, 'n_estimators': 10}, 'config_hash': {'algorithm': '93518f8ded6074d537900b26be72f8485782f933', 'config': '45f056102dd2d644bd8befa471f17b2311ac7954', 'pipeline': '5240329df25c9a533d025c1a401d49835a501b41'}, 'duration': 3.2622711658477783, 'iteration': 12, 'loss': 0.6120243191353301, 'max_history_score': 0.85528670390001, 'max_history_score_std': 0.02213730791268438, 'max_history_step': 'joint', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 4, 'features__selectkbest__k': 2}), 'normalizer': ('normalizer_PowerTransformer', {}), 'rebalance': ('rebalance_NearMiss', {'rebalance__n_neighbors': 1})}, 'score': 0.38797568086467, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'entropy', 'max_depth': None, 'max_features': 1, 'max_leaf_nodes': 5, 'min_samples_split': 3, 'n_estimators': 75}, 'config_hash': {'algorithm': 'e515d45b764fa43591032874a0ff9c25bf12fddd', 'config': 'ba108323623936872824ed8f1c41d615d25523b3', 'pipeline': '9d823bc0442f21b5ce8af67a5eb1237f64ffc2f8'}, 'duration': 2.5326571464538574, 'iteration': 13, 'loss': 0.6271427382991047, 'max_history_score': 0.85528670390001, 'max_history_score_std': 0.02213730791268438, 'max_history_step': 'joint', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 1, 'features__selectkbest__k': 1}), 'normalizer': ('normalizer_StandardScaler', {'normalizer__with_mean': True, 'normalizer__with_std': True}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 5})}, 'score': 0.3728572617008953, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'entropy', 'max_depth': 3, 'max_features': 2, 'max_leaf_nodes': 2, 'min_samples_split': 3, 'n_estimators': 25}, 'config_hash': {'algorithm': '2808e67f609eba5c8a97f81ac0c9413cd37cf7aa', 'config': 'dde4d3b5f37741629cb58bfc4051ed9f98c8f311', 'pipeline': 'bc52deabf1f5ee60968ba541d9d2574353c30a9c'}, 'duration': 0.7145559787750244, 'iteration': 14, 'loss': 0.6831045572696203, 'max_history_score': 0.85528670390001, 'max_history_score_std': 0.02213730791268438, 'max_history_step': 'joint', 'pipeline': {'features': ('features_SelectKBest', {'features__k': 3}), 'normalizer': ('normalizer_MinMaxScaler', {}), 'rebalance': ('rebalance_NearMiss', {'rebalance__n_neighbors': 1})}, 'score': 0.31689544273037973, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'gini', 'max_depth': 2, 'max_features': 2, 'max_leaf_nodes': None, 'min_samples_split': 5, 'n_estimators': 100}, 'config_hash': {'algorithm': 'b942acdead762d34afeb474bc2fe6f7fd0f23493', 'config': '1080c25b92da3f15a6f8eec003957f7e0a66324f', 'pipeline': 'cfa84fe703dc5bc0bbd2257a6d524fee2693b804'}, 'duration': 2.812459945678711, 'iteration': 15, 'loss': 0.6921421091202761, 'max_history_score': 0.85528670390001, 'max_history_score_std': 0.02213730791268438, 'max_history_step': 'joint', 'pipeline': {'features': ('features_SelectKBest', {'features__k': 2}), 'normalizer': ('normalizer_PowerTransformer', {}), 'rebalance': ('rebalance_NoneType', {})}, 'score': 0.3078578908797239, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'entropy', 'max_depth': 2, 'max_features': 3, 'max_leaf_nodes': 3, 'min_samples_split': 2, 'n_estimators': 75}, 'config_hash': {'algorithm': '250661ce4193a61ef44d2f77694b52b785ff032d', 'config': 'c3e8cf4eca5aafcae4ac31b0449e105ca127ffe2', 'pipeline': 'c4dd111513ea35f97dd3aec3e8e7f6268ce035da'}, 'duration': 1.0555319786071777, 'iteration': 16, 'loss': 1.0, 'max_history_score': 0.85528670390001, 'max_history_score_std': 0.02213730791268438, 'max_history_step': 'joint', 'pipeline': {'features': ('features_PCA', {'features__n_components': 2}), 'normalizer': ('normalizer_RobustScaler', {'normalizer__quantile_range': (...), 'normalizer__with_centering': False, 'normalizer__with_scaling': True}), 'rebalance': ('rebalance_NearMiss', {'rebalance__n_neighbors': 2})}, 'score': 0.0, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'entropy', 'max_depth': 3, 'max_features': 3, 'max_leaf_nodes': None, 'min_samples_split': 3, 'n_estimators': 25}, 'config_hash': {'algorithm': '05ac02bd045c65dc4089894902ad6253661a2692', 'config': '3449b4a1c2e488e26a7195ee9edca19b854ebd33', 'pipeline': '505d3f71b534917375d765e64b0611e7dfb83746'}, 'duration': 5.5412821769714355, 'iteration': 17, 'loss': 0.7289151155121668, 'max_history_score': 0.85528670390001, 'max_history_score_std': 0.02213730791268438, 'max_history_step': 'joint', 'pipeline': {'features': ('features_SelectKBest', {'features__k': 4}), 'normalizer': ('normalizer_MinMaxScaler', {}), 'rebalance': ('rebalance_CondensedNearestNeighbour', {'rebalance__n_neighbors': 2})}, 'score': 0.2710848844878332, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'entropy', 'max_depth': 2, 'max_features': None, 'max_leaf_nodes': None, 'min_samples_split': 2, 'n_estimators': 25}, 'config_hash': {'algorithm': 'de3b3a352ebb260e16c6b213a08c9144d17a744b', 'config': '224987ffdbbb9b6182cff18d8374518b917e4f2e', 'pipeline': '12c89200a558b2f3b91332566f41050143aecbe7'}, 'duration': 2.4646048545837402, 'iteration': 18, 'loss': 0.6545902512995826, 'max_history_score': 0.85528670390001, 'max_history_score_std': 0.02213730791268438, 'max_history_step': 'joint', 'pipeline': {'features': ('features_NoneType', {}), 'normalizer': ('normalizer_PowerTransformer', {}), 'rebalance': ('rebalance_NearMiss', {'rebalance__n_neighbors': 2})}, 'score': 0.3454097487004174, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'gini', 'max_depth': None, 'max_features': 1, 'max_leaf_nodes': None, 'min_samples_split': 3, 'n_estimators': 100}, 'config_hash': {'algorithm': '30ca111584767bbf0464df40b4c928cf7ddf9459', 'config': '97ca7d6a017c721084dec2a5d2e5a67e1e6ae2f0', 'pipeline': '789eca82ea4a42d61927670c538867b745fd81d3'}, 'duration': 7.164499044418335, 'iteration': 19, 'loss': 0.6536825403350528, 'max_history_score': 0.85528670390001, 'max_history_score_std': 0.02213730791268438, 'max_history_step': 'joint', 'pipeline': {'features': ('features_SelectKBest', {'features__k': 3}), 'normalizer': ('normalizer_RobustScaler', {'normalizer__quantile_range': (...), 'normalizer__with_centering': False, 'normalizer__with_scaling': True}), 'rebalance': ('rebalance_CondensedNearestNeighbour', {'rebalance__n_neighbors': 3})}, 'score': 0.3463174596649472, ...}, ...], 'history_hash': ['fd24b065dda6bdeb1077793f9df480ff318c7a37', 'fb22f80fb4358ae1ee4c9bd4a83543992be8d806', '8c97cdb885dd05cfd8c40ee3ac445b61e5c767a8', '16fbb5fd5cfbbacfddf27c61c0c7397a7f6d8ade', 'a77c698197c31308211b854e81a998178941f87d', '1fc13606bca3aaf342ca6ea21139cb598b56f8db', '6749af1a67b4dbcd2b4719e419d99908063c05e1', 'd92d4ada2394fc132733e176e926ee53acdc6a00', 'f0d0b1d2cedc22ae15d9a208a3fc3fc133bf0d3d', '47584de0e60d0d12c7dbbf0dc60e5aea96e3f4b2', 'eecb88ee2b1b95d741c1b5c7751534d31aae6a77', '27a7ed0502b321ab7256b77c8ce79e90cb9da815', '45f056102dd2d644bd8befa471f17b2311ac7954', 'ba108323623936872824ed8f1c41d615d25523b3', 'dde4d3b5f37741629cb58bfc4051ed9f98c8f311', '1080c25b92da3f15a6f8eec003957f7e0a66324f', 'c3e8cf4eca5aafcae4ac31b0449e105ca127ffe2', '3449b4a1c2e488e26a7195ee9edca19b854ebd33', '224987ffdbbb9b6182cff18d8374518b917e4f2e', '97ca7d6a017c721084dec2a5d2e5a67e1e6ae2f0', ...], 'history_index': {'01b68ec8d6fe15ffdadf1adfd0d809307d3ce41e': 81, '05465becb12810ce291074be22a0275a42efbea8': 52, '064f53edf4748bb2df4ff59f147331aad21219e1': 48, '087efef4a19f272562d2d445dac0edd8096ba2fa': 58, '0fd4d71ca3a89c7d14af5087f2a2e2c1b1975351': 51, '1080c25b92da3f15a6f8eec003957f7e0a66324f': 15, '10ca1ab51b6af0696dab2c8cbaf8de5e3812a6de': 78, '143679b59e16961765e77616142572b6ded0ee72': 62, '151b4a15037767108da13dafa0b63ae93222e93a': 53, '16fbb5fd5cfbbacfddf27c61c0c7397a7f6d8ade': 3, ...}, 'iteration': 88, 'max_history_score': 0.9231904384036744, 'max_history_score_std': 0.03040515884196498, 'max_history_step': 'joint'}, config={'algorithm': 'RandomForest', 'seed': 42, 'time': 300})
    108 
    109 def objective_algo(algo_config, current_pipeline_config, algorithm, X, y, context, config):
    110     return objective(current_pipeline_config, algo_config, algorithm, X, y, context, config, step='algorithm')
    111 
    112 def objective_joint(wconfig, algorithm, X, y, context, config):
--> 113     return objective(wconfig['pipeline'], wconfig['algorithm'], algorithm, X, y, context, config, step='joint')
        wconfig = {'algorithm': {'bootstrap': False, 'criterion': 'entropy', 'max_depth': 3, 'max_features': 3, 'max_leaf_nodes': 5, 'min_samples_split': 2, 'n_estimators': 75}, 'pipeline': {'features': ('features_SelectKBest', {'features__k': 2}), 'normalizer': ('normalizer_NoneType', {}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 5})}}
        algorithm = 'RandomForest'
        X = array([[ 0.,  0.,  5., ...,  0.,  0.,  0.],
    ...0.],
       [ 0.,  0., 10., ..., 12.,  1.,  0.]])
        y = array([0, 1, 2, ..., 8, 9, 8])
        context = {'baseline_score': 0.9272021217853512, 'baseline_score_std': 0.026919033284817703, 'best_config': {'algorithm': {'bootstrap': True, 'criterion': 'entropy', 'max_depth': None, 'max_features': None, 'max_leaf_nodes': None, 'min_samples_split': 3, 'n_estimators': 75}, 'config_hash': {'algorithm': 'f42e45bee34ac9973699212f6c8b845daea9383a', 'config': 'ae61cfde4c8b4c792e42d6b6be4af4ffb3d90e13', 'pipeline': '15ff3d6270ac899763bb3f72417c48bcd56aa7d8'}, 'duration': 8.20555305480957, 'iteration': 65, 'loss': 0.07680956159632557, 'max_history_score': 0.9231904384036744, 'max_history_score_std': 0.03040515884196498, 'max_history_step': 'joint', 'pipeline': {'features': ('features_NoneType', {}), 'normalizer': ('normalizer_StandardScaler', {'normalizer__with_mean': True, 'normalizer__with_std': True}), 'rebalance': ('rebalance_NearMiss', {'rebalance__n_neighbors': 1})}, 'score': 0.9231904384036744, ...}, 'history': [{'algorithm': {'bootstrap': False, 'criterion': 'entropy', 'max_depth': 1, 'max_features': 3, 'max_leaf_nodes': 3, 'min_samples_split': 5, 'n_estimators': 50}, 'config_hash': {'algorithm': '752fa095cdab58a238ae606c613606188964cc0c', 'config': 'fd24b065dda6bdeb1077793f9df480ff318c7a37', 'pipeline': '13ea3359c453b8993fcec1e88bc0e19cd0a2b112'}, 'duration': 0.689669132232666, 'iteration': 0, 'loss': 0.6602879519109309, 'max_history_score': 0.3397120480890691, 'max_history_score_std': 0.03346542949100545, 'max_history_step': 'joint', 'pipeline': {'features': ('features_SelectKBest', {'features__k': 4}), 'normalizer': ('normalizer_MinMaxScaler', {}), 'rebalance': ('rebalance_NoneType', {})}, 'score': 0.3397120480890691, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'gini', 'max_depth': 4, 'max_features': 1, 'max_leaf_nodes': 5, 'min_samples_split': 3, 'n_estimators': 25}, 'config_hash': {'algorithm': '9d9de4aee820052ddfe83bfffca420f6b50837d3', 'config': 'fb22f80fb4358ae1ee4c9bd4a83543992be8d806', 'pipeline': '6251ad4bb7a110726a67f90c319f4717ac37a312'}, 'duration': 1.4300940036773682, 'iteration': 1, 'loss': 0.5122196101741096, 'max_history_score': 0.48778038982589045, 'max_history_score_std': 0.05486079759217226, 'max_history_step': 'joint', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 2, 'features__selectkbest__k': 2}), 'normalizer': ('normalizer_StandardScaler', {'normalizer__with_mean': True, 'normalizer__with_std': True}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 5})}, 'score': 0.48778038982589045, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': 4, 'max_features': 1, 'max_leaf_nodes': None, 'min_samples_split': 2, 'n_estimators': 10}, 'config_hash': {'algorithm': '2ed7d27df9a1b2d5e63da76f7cb309616c232022', 'config': '8c97cdb885dd05cfd8c40ee3ac445b61e5c767a8', 'pipeline': 'c0abb5e23a4739d3120740a9519fb36c43eb94d5'}, 'duration': 3.0036678314208984, 'iteration': 2, 'loss': 0.38319264175312906, 'max_history_score': 0.6168073582468709, 'max_history_score_std': 0.05286679173001824, 'max_history_step': 'joint', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 1, 'features__selectkbest__k': 4}), 'normalizer': ('normalizer_PowerTransformer', {}), 'rebalance': ('rebalance_NearMiss', {'rebalance__n_neighbors': 2})}, 'score': 0.6168073582468709, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'entropy', 'max_depth': None, 'max_features': None, 'max_leaf_nodes': 2, 'min_samples_split': 2, 'n_estimators': 100}, 'config_hash': {'algorithm': '17962655e3b76dfcd0843d1e5c2cb7a9db1c6a79', 'config': '16fbb5fd5cfbbacfddf27c61c0c7397a7f6d8ade', 'pipeline': '13ea3359c453b8993fcec1e88bc0e19cd0a2b112'}, 'duration': 1.3447980880737305, 'iteration': 3, 'loss': 0.6768840987778313, 'max_history_score': 0.6168073582468709, 'max_history_score_std': 0.05286679173001824, 'max_history_step': 'joint', 'pipeline': {'features': ('features_SelectKBest', {'features__k': 4}), 'normalizer': ('normalizer_MinMaxScaler', {}), 'rebalance': ('rebalance_NoneType', {})}, 'score': 0.32311590122216866, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'gini', 'max_depth': 2, 'max_features': 2, 'max_leaf_nodes': 2, 'min_samples_split': 3, 'n_estimators': 100}, 'config_hash': {'algorithm': '1ea8965b2247f86950e54510ee6d79399816341b', 'config': 'a77c698197c31308211b854e81a998178941f87d', 'pipeline': 'aaf976c7c663a31fa039582d42f9e07101556a7c'}, 'duration': 2.589430093765259, 'iteration': 4, 'loss': 0.2544808950572157, 'max_history_score': 0.7455191049427843, 'max_history_score_std': 0.04843448308166839, 'max_history_step': 'joint', 'pipeline': {'features': ('features_NoneType', {}), 'normalizer': ('normalizer_PowerTransformer', {}), 'rebalance': ('rebalance_NoneType', {})}, 'score': 0.7455191049427843, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': None, 'max_features': 2, 'max_leaf_nodes': 5, 'min_samples_split': 5, 'n_estimators': 25}, 'config_hash': {'algorithm': 'fd8aeb6a05eaaba41e676d60596c8e0c71b35e0c', 'config': '1fc13606bca3aaf342ca6ea21139cb598b56f8db', 'pipeline': 'f00bd8de05642e026bbba4ad20d3a60088c86b6c'}, 'duration': 1.8779079914093018, 'iteration': 5, 'loss': 0.531551018758381, 'max_history_score': 0.7455191049427843, 'max_history_score_std': 0.04843448308166839, 'max_history_step': 'joint', 'pipeline': {'features': ('features_PCA', {'features__n_components': 2}), 'normalizer': ('normalizer_MinMaxScaler', {}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 5})}, 'score': 0.46844898124161904, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'entropy', 'max_depth': None, 'max_features': 2, 'max_leaf_nodes': None, 'min_samples_split': 2, 'n_estimators': 10}, 'config_hash': {'algorithm': 'a49ecb99e74217d6812f98ead7bc9d1fe4a53ba0', 'config': '6749af1a67b4dbcd2b4719e419d99908063c05e1', 'pipeline': '19bdf19a2eec5febce95ab8fa2a71040d75114aa'}, 'duration': 1.5498578548431396, 'iteration': 6, 'loss': 0.14471329609998995, 'max_history_score': 0.85528670390001, 'max_history_score_std': 0.02213730791268438, 'max_history_step': 'joint', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 4, 'features__selectkbest__k': 3}), 'normalizer': ('normalizer_NoneType', {}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 7})}, 'score': 0.85528670390001, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': 1, 'max_features': 3, 'max_leaf_nodes': 3, 'min_samples_split': 3, 'n_estimators': 75}, 'config_hash': {'algorithm': 'ebfb16234172ae811ff21185ff92bbdbb8f32f14', 'config': 'd92d4ada2394fc132733e176e926ee53acdc6a00', 'pipeline': '8071e7cbf86a5c3056493dc3aa40063aeb28cdfe'}, 'duration': 1.3618149757385254, 'iteration': 7, 'loss': 0.6158612049395463, 'max_history_score': 0.85528670390001, 'max_history_score_std': 0.02213730791268438, 'max_history_step': 'joint', 'pipeline': {'features': ('features_SelectKBest', {'features__k': 4}), 'normalizer': ('normalizer_StandardScaler', {'normalizer__with_mean': True, 'normalizer__with_std': True}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 5})}, 'score': 0.3841387950604537, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'entropy', 'max_depth': 1, 'max_features': 1, 'max_leaf_nodes': 5, 'min_samples_split': 2, 'n_estimators': 100}, 'config_hash': {'algorithm': '896b53c75a2db568fb7b6da3bfca2f7a1535a11b', 'config': 'f0d0b1d2cedc22ae15d9a208a3fc3fc133bf0d3d', 'pipeline': 'c9761c9a33bf75d6dcad0742c421548a7655ccc9'}, 'duration': 2.297278881072998, 'iteration': 8, 'loss': 0.40673663548410355, 'max_history_score': 0.85528670390001, 'max_history_score_std': 0.02213730791268438, 'max_history_step': 'joint', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 2, 'features__selectkbest__k': 4}), 'normalizer': ('normalizer_StandardScaler', {'normalizer__with_mean': False, 'normalizer__with_std': False}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 5})}, 'score': 0.5932633645158965, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'entropy', 'max_depth': 2, 'max_features': None, 'max_leaf_nodes': None, 'min_samples_split': 5, 'n_estimators': 25}, 'config_hash': {'algorithm': '0b0e954757c4f75343a6efb740ad93260ed781ae', 'config': '47584de0e60d0d12c7dbbf0dc60e5aea96e3f4b2', 'pipeline': 'b37ee32d59413053bf9a2a72c8ff7135f3701e05'}, 'duration': 0.7249000072479248, 'iteration': 9, 'loss': 0.6965910020393421, 'max_history_score': 0.85528670390001, 'max_history_score_std': 0.02213730791268438, 'max_history_step': 'joint', 'pipeline': {'features': ('features_SelectKBest', {'features__k': 3}), 'normalizer': ('normalizer_NoneType', {}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 7})}, 'score': 0.3034089979606579, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'gini', 'max_depth': 2, 'max_features': 2, 'max_leaf_nodes': 5, 'min_samples_split': 5, 'n_estimators': 75}, 'config_hash': {'algorithm': 'f1ead1d9e33ea927e1dd27d872a058fa3de4f832', 'config': 'eecb88ee2b1b95d741c1b5c7751534d31aae6a77', 'pipeline': '6746650871e8b61efc9302b092dc05f7cdb179d5'}, 'duration': 5.340634822845459, 'iteration': 10, 'loss': 0.7687016290977936, 'max_history_score': 0.85528670390001, 'max_history_score_std': 0.02213730791268438, 'max_history_step': 'joint', 'pipeline': {'features': ('features_SelectKBest', {'features__k': 3}), 'normalizer': ('normalizer_RobustScaler', {'normalizer__quantile_range': (...), 'normalizer__with_centering': False, 'normalizer__with_scaling': False}), 'rebalance': ('rebalance_CondensedNearestNeighbour', {'rebalance__n_neighbors': 1})}, 'score': 0.23129837090220637, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': 1, 'max_features': 2, 'max_leaf_nodes': 2, 'min_samples_split': 3, 'n_estimators': 75}, 'config_hash': {'algorithm': '531a3bb8ccf0baa06727af4b3de9e62d25e6eabf', 'config': '27a7ed0502b321ab7256b77c8ce79e90cb9da815', 'pipeline': '77e6d84e2217b92b3cf67cc6defef9dd3554cec0'}, 'duration': 1.775357961654663, 'iteration': 11, 'loss': 0.6313818737375694, 'max_history_score': 0.85528670390001, 'max_history_score_std': 0.02213730791268438, 'max_history_step': 'joint', 'pipeline': {'features': ('features_SelectKBest', {'features__k': 4}), 'normalizer': ('normalizer_MinMaxScaler', {}), 'rebalance': ('rebalance_NearMiss', {'rebalance__n_neighbors': 3})}, 'score': 0.3686181262624307, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'entropy', 'max_depth': 4, 'max_features': 3, 'max_leaf_nodes': 2, 'min_samples_split': 3, 'n_estimators': 10}, 'config_hash': {'algorithm': '93518f8ded6074d537900b26be72f8485782f933', 'config': '45f056102dd2d644bd8befa471f17b2311ac7954', 'pipeline': '5240329df25c9a533d025c1a401d49835a501b41'}, 'duration': 3.2622711658477783, 'iteration': 12, 'loss': 0.6120243191353301, 'max_history_score': 0.85528670390001, 'max_history_score_std': 0.02213730791268438, 'max_history_step': 'joint', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 4, 'features__selectkbest__k': 2}), 'normalizer': ('normalizer_PowerTransformer', {}), 'rebalance': ('rebalance_NearMiss', {'rebalance__n_neighbors': 1})}, 'score': 0.38797568086467, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'entropy', 'max_depth': None, 'max_features': 1, 'max_leaf_nodes': 5, 'min_samples_split': 3, 'n_estimators': 75}, 'config_hash': {'algorithm': 'e515d45b764fa43591032874a0ff9c25bf12fddd', 'config': 'ba108323623936872824ed8f1c41d615d25523b3', 'pipeline': '9d823bc0442f21b5ce8af67a5eb1237f64ffc2f8'}, 'duration': 2.5326571464538574, 'iteration': 13, 'loss': 0.6271427382991047, 'max_history_score': 0.85528670390001, 'max_history_score_std': 0.02213730791268438, 'max_history_step': 'joint', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 1, 'features__selectkbest__k': 1}), 'normalizer': ('normalizer_StandardScaler', {'normalizer__with_mean': True, 'normalizer__with_std': True}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 5})}, 'score': 0.3728572617008953, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'entropy', 'max_depth': 3, 'max_features': 2, 'max_leaf_nodes': 2, 'min_samples_split': 3, 'n_estimators': 25}, 'config_hash': {'algorithm': '2808e67f609eba5c8a97f81ac0c9413cd37cf7aa', 'config': 'dde4d3b5f37741629cb58bfc4051ed9f98c8f311', 'pipeline': 'bc52deabf1f5ee60968ba541d9d2574353c30a9c'}, 'duration': 0.7145559787750244, 'iteration': 14, 'loss': 0.6831045572696203, 'max_history_score': 0.85528670390001, 'max_history_score_std': 0.02213730791268438, 'max_history_step': 'joint', 'pipeline': {'features': ('features_SelectKBest', {'features__k': 3}), 'normalizer': ('normalizer_MinMaxScaler', {}), 'rebalance': ('rebalance_NearMiss', {'rebalance__n_neighbors': 1})}, 'score': 0.31689544273037973, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'gini', 'max_depth': 2, 'max_features': 2, 'max_leaf_nodes': None, 'min_samples_split': 5, 'n_estimators': 100}, 'config_hash': {'algorithm': 'b942acdead762d34afeb474bc2fe6f7fd0f23493', 'config': '1080c25b92da3f15a6f8eec003957f7e0a66324f', 'pipeline': 'cfa84fe703dc5bc0bbd2257a6d524fee2693b804'}, 'duration': 2.812459945678711, 'iteration': 15, 'loss': 0.6921421091202761, 'max_history_score': 0.85528670390001, 'max_history_score_std': 0.02213730791268438, 'max_history_step': 'joint', 'pipeline': {'features': ('features_SelectKBest', {'features__k': 2}), 'normalizer': ('normalizer_PowerTransformer', {}), 'rebalance': ('rebalance_NoneType', {})}, 'score': 0.3078578908797239, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'entropy', 'max_depth': 2, 'max_features': 3, 'max_leaf_nodes': 3, 'min_samples_split': 2, 'n_estimators': 75}, 'config_hash': {'algorithm': '250661ce4193a61ef44d2f77694b52b785ff032d', 'config': 'c3e8cf4eca5aafcae4ac31b0449e105ca127ffe2', 'pipeline': 'c4dd111513ea35f97dd3aec3e8e7f6268ce035da'}, 'duration': 1.0555319786071777, 'iteration': 16, 'loss': 1.0, 'max_history_score': 0.85528670390001, 'max_history_score_std': 0.02213730791268438, 'max_history_step': 'joint', 'pipeline': {'features': ('features_PCA', {'features__n_components': 2}), 'normalizer': ('normalizer_RobustScaler', {'normalizer__quantile_range': (...), 'normalizer__with_centering': False, 'normalizer__with_scaling': True}), 'rebalance': ('rebalance_NearMiss', {'rebalance__n_neighbors': 2})}, 'score': 0.0, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'entropy', 'max_depth': 3, 'max_features': 3, 'max_leaf_nodes': None, 'min_samples_split': 3, 'n_estimators': 25}, 'config_hash': {'algorithm': '05ac02bd045c65dc4089894902ad6253661a2692', 'config': '3449b4a1c2e488e26a7195ee9edca19b854ebd33', 'pipeline': '505d3f71b534917375d765e64b0611e7dfb83746'}, 'duration': 5.5412821769714355, 'iteration': 17, 'loss': 0.7289151155121668, 'max_history_score': 0.85528670390001, 'max_history_score_std': 0.02213730791268438, 'max_history_step': 'joint', 'pipeline': {'features': ('features_SelectKBest', {'features__k': 4}), 'normalizer': ('normalizer_MinMaxScaler', {}), 'rebalance': ('rebalance_CondensedNearestNeighbour', {'rebalance__n_neighbors': 2})}, 'score': 0.2710848844878332, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'entropy', 'max_depth': 2, 'max_features': None, 'max_leaf_nodes': None, 'min_samples_split': 2, 'n_estimators': 25}, 'config_hash': {'algorithm': 'de3b3a352ebb260e16c6b213a08c9144d17a744b', 'config': '224987ffdbbb9b6182cff18d8374518b917e4f2e', 'pipeline': '12c89200a558b2f3b91332566f41050143aecbe7'}, 'duration': 2.4646048545837402, 'iteration': 18, 'loss': 0.6545902512995826, 'max_history_score': 0.85528670390001, 'max_history_score_std': 0.02213730791268438, 'max_history_step': 'joint', 'pipeline': {'features': ('features_NoneType', {}), 'normalizer': ('normalizer_PowerTransformer', {}), 'rebalance': ('rebalance_NearMiss', {'rebalance__n_neighbors': 2})}, 'score': 0.3454097487004174, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'gini', 'max_depth': None, 'max_features': 1, 'max_leaf_nodes': None, 'min_samples_split': 3, 'n_estimators': 100}, 'config_hash': {'algorithm': '30ca111584767bbf0464df40b4c928cf7ddf9459', 'config': '97ca7d6a017c721084dec2a5d2e5a67e1e6ae2f0', 'pipeline': '789eca82ea4a42d61927670c538867b745fd81d3'}, 'duration': 7.164499044418335, 'iteration': 19, 'loss': 0.6536825403350528, 'max_history_score': 0.85528670390001, 'max_history_score_std': 0.02213730791268438, 'max_history_step': 'joint', 'pipeline': {'features': ('features_SelectKBest', {'features__k': 3}), 'normalizer': ('normalizer_RobustScaler', {'normalizer__quantile_range': (...), 'normalizer__with_centering': False, 'normalizer__with_scaling': True}), 'rebalance': ('rebalance_CondensedNearestNeighbour', {'rebalance__n_neighbors': 3})}, 'score': 0.3463174596649472, ...}, ...], 'history_hash': ['fd24b065dda6bdeb1077793f9df480ff318c7a37', 'fb22f80fb4358ae1ee4c9bd4a83543992be8d806', '8c97cdb885dd05cfd8c40ee3ac445b61e5c767a8', '16fbb5fd5cfbbacfddf27c61c0c7397a7f6d8ade', 'a77c698197c31308211b854e81a998178941f87d', '1fc13606bca3aaf342ca6ea21139cb598b56f8db', '6749af1a67b4dbcd2b4719e419d99908063c05e1', 'd92d4ada2394fc132733e176e926ee53acdc6a00', 'f0d0b1d2cedc22ae15d9a208a3fc3fc133bf0d3d', '47584de0e60d0d12c7dbbf0dc60e5aea96e3f4b2', 'eecb88ee2b1b95d741c1b5c7751534d31aae6a77', '27a7ed0502b321ab7256b77c8ce79e90cb9da815', '45f056102dd2d644bd8befa471f17b2311ac7954', 'ba108323623936872824ed8f1c41d615d25523b3', 'dde4d3b5f37741629cb58bfc4051ed9f98c8f311', '1080c25b92da3f15a6f8eec003957f7e0a66324f', 'c3e8cf4eca5aafcae4ac31b0449e105ca127ffe2', '3449b4a1c2e488e26a7195ee9edca19b854ebd33', '224987ffdbbb9b6182cff18d8374518b917e4f2e', '97ca7d6a017c721084dec2a5d2e5a67e1e6ae2f0', ...], 'history_index': {'01b68ec8d6fe15ffdadf1adfd0d809307d3ce41e': 81, '05465becb12810ce291074be22a0275a42efbea8': 52, '064f53edf4748bb2df4ff59f147331aad21219e1': 48, '087efef4a19f272562d2d445dac0edd8096ba2fa': 58, '0fd4d71ca3a89c7d14af5087f2a2e2c1b1975351': 51, '1080c25b92da3f15a6f8eec003957f7e0a66324f': 15, '10ca1ab51b6af0696dab2c8cbaf8de5e3812a6de': 78, '143679b59e16961765e77616142572b6ded0ee72': 62, '151b4a15037767108da13dafa0b63ae93222e93a': 53, '16fbb5fd5cfbbacfddf27c61c0c7397a7f6d8ade': 3, ...}, 'iteration': 88, 'max_history_score': 0.9231904384036744, 'max_history_score_std': 0.03040515884196498, 'max_history_step': 'joint'}
        config = {'algorithm': 'RandomForest', 'seed': 42, 'time': 300}
    114 
    115 
    116 def get_baseline_score(algorithm, X, y, seed):
    117     pipeline, _ = pipeline_conf_to_full_pipeline(

...........................................................................
/home/aquemy/dev/dp_hyperparameters/extension/experiment/objective.py in objective(pipeline_config={'features': ('features_SelectKBest', {'features__k': 2}), 'normalizer': ('normalizer_NoneType', {}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 5})}, algo_config={'bootstrap': False, 'criterion': 'entropy', 'max_depth': 3, 'max_features': 3, 'max_leaf_nodes': 5, 'min_samples_split': 2, 'n_estimators': 75}, algorithm='RandomForest', X=array([[ 0.,  0.,  5., ...,  0.,  0.,  0.],
    ...0.],
       [ 0.,  0., 10., ..., 12.,  1.,  0.]]), y=array([0, 1, 2, ..., 8, 9, 8]), context={'baseline_score': 0.9272021217853512, 'baseline_score_std': 0.026919033284817703, 'best_config': {'algorithm': {'bootstrap': True, 'criterion': 'entropy', 'max_depth': None, 'max_features': None, 'max_leaf_nodes': None, 'min_samples_split': 3, 'n_estimators': 75}, 'config_hash': {'algorithm': 'f42e45bee34ac9973699212f6c8b845daea9383a', 'config': 'ae61cfde4c8b4c792e42d6b6be4af4ffb3d90e13', 'pipeline': '15ff3d6270ac899763bb3f72417c48bcd56aa7d8'}, 'duration': 8.20555305480957, 'iteration': 65, 'loss': 0.07680956159632557, 'max_history_score': 0.9231904384036744, 'max_history_score_std': 0.03040515884196498, 'max_history_step': 'joint', 'pipeline': {'features': ('features_NoneType', {}), 'normalizer': ('normalizer_StandardScaler', {'normalizer__with_mean': True, 'normalizer__with_std': True}), 'rebalance': ('rebalance_NearMiss', {'rebalance__n_neighbors': 1})}, 'score': 0.9231904384036744, ...}, 'history': [{'algorithm': {'bootstrap': False, 'criterion': 'entropy', 'max_depth': 1, 'max_features': 3, 'max_leaf_nodes': 3, 'min_samples_split': 5, 'n_estimators': 50}, 'config_hash': {'algorithm': '752fa095cdab58a238ae606c613606188964cc0c', 'config': 'fd24b065dda6bdeb1077793f9df480ff318c7a37', 'pipeline': '13ea3359c453b8993fcec1e88bc0e19cd0a2b112'}, 'duration': 0.689669132232666, 'iteration': 0, 'loss': 0.6602879519109309, 'max_history_score': 0.3397120480890691, 'max_history_score_std': 0.03346542949100545, 'max_history_step': 'joint', 'pipeline': {'features': ('features_SelectKBest', {'features__k': 4}), 'normalizer': ('normalizer_MinMaxScaler', {}), 'rebalance': ('rebalance_NoneType', {})}, 'score': 0.3397120480890691, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'gini', 'max_depth': 4, 'max_features': 1, 'max_leaf_nodes': 5, 'min_samples_split': 3, 'n_estimators': 25}, 'config_hash': {'algorithm': '9d9de4aee820052ddfe83bfffca420f6b50837d3', 'config': 'fb22f80fb4358ae1ee4c9bd4a83543992be8d806', 'pipeline': '6251ad4bb7a110726a67f90c319f4717ac37a312'}, 'duration': 1.4300940036773682, 'iteration': 1, 'loss': 0.5122196101741096, 'max_history_score': 0.48778038982589045, 'max_history_score_std': 0.05486079759217226, 'max_history_step': 'joint', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 2, 'features__selectkbest__k': 2}), 'normalizer': ('normalizer_StandardScaler', {'normalizer__with_mean': True, 'normalizer__with_std': True}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 5})}, 'score': 0.48778038982589045, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': 4, 'max_features': 1, 'max_leaf_nodes': None, 'min_samples_split': 2, 'n_estimators': 10}, 'config_hash': {'algorithm': '2ed7d27df9a1b2d5e63da76f7cb309616c232022', 'config': '8c97cdb885dd05cfd8c40ee3ac445b61e5c767a8', 'pipeline': 'c0abb5e23a4739d3120740a9519fb36c43eb94d5'}, 'duration': 3.0036678314208984, 'iteration': 2, 'loss': 0.38319264175312906, 'max_history_score': 0.6168073582468709, 'max_history_score_std': 0.05286679173001824, 'max_history_step': 'joint', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 1, 'features__selectkbest__k': 4}), 'normalizer': ('normalizer_PowerTransformer', {}), 'rebalance': ('rebalance_NearMiss', {'rebalance__n_neighbors': 2})}, 'score': 0.6168073582468709, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'entropy', 'max_depth': None, 'max_features': None, 'max_leaf_nodes': 2, 'min_samples_split': 2, 'n_estimators': 100}, 'config_hash': {'algorithm': '17962655e3b76dfcd0843d1e5c2cb7a9db1c6a79', 'config': '16fbb5fd5cfbbacfddf27c61c0c7397a7f6d8ade', 'pipeline': '13ea3359c453b8993fcec1e88bc0e19cd0a2b112'}, 'duration': 1.3447980880737305, 'iteration': 3, 'loss': 0.6768840987778313, 'max_history_score': 0.6168073582468709, 'max_history_score_std': 0.05286679173001824, 'max_history_step': 'joint', 'pipeline': {'features': ('features_SelectKBest', {'features__k': 4}), 'normalizer': ('normalizer_MinMaxScaler', {}), 'rebalance': ('rebalance_NoneType', {})}, 'score': 0.32311590122216866, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'gini', 'max_depth': 2, 'max_features': 2, 'max_leaf_nodes': 2, 'min_samples_split': 3, 'n_estimators': 100}, 'config_hash': {'algorithm': '1ea8965b2247f86950e54510ee6d79399816341b', 'config': 'a77c698197c31308211b854e81a998178941f87d', 'pipeline': 'aaf976c7c663a31fa039582d42f9e07101556a7c'}, 'duration': 2.589430093765259, 'iteration': 4, 'loss': 0.2544808950572157, 'max_history_score': 0.7455191049427843, 'max_history_score_std': 0.04843448308166839, 'max_history_step': 'joint', 'pipeline': {'features': ('features_NoneType', {}), 'normalizer': ('normalizer_PowerTransformer', {}), 'rebalance': ('rebalance_NoneType', {})}, 'score': 0.7455191049427843, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': None, 'max_features': 2, 'max_leaf_nodes': 5, 'min_samples_split': 5, 'n_estimators': 25}, 'config_hash': {'algorithm': 'fd8aeb6a05eaaba41e676d60596c8e0c71b35e0c', 'config': '1fc13606bca3aaf342ca6ea21139cb598b56f8db', 'pipeline': 'f00bd8de05642e026bbba4ad20d3a60088c86b6c'}, 'duration': 1.8779079914093018, 'iteration': 5, 'loss': 0.531551018758381, 'max_history_score': 0.7455191049427843, 'max_history_score_std': 0.04843448308166839, 'max_history_step': 'joint', 'pipeline': {'features': ('features_PCA', {'features__n_components': 2}), 'normalizer': ('normalizer_MinMaxScaler', {}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 5})}, 'score': 0.46844898124161904, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'entropy', 'max_depth': None, 'max_features': 2, 'max_leaf_nodes': None, 'min_samples_split': 2, 'n_estimators': 10}, 'config_hash': {'algorithm': 'a49ecb99e74217d6812f98ead7bc9d1fe4a53ba0', 'config': '6749af1a67b4dbcd2b4719e419d99908063c05e1', 'pipeline': '19bdf19a2eec5febce95ab8fa2a71040d75114aa'}, 'duration': 1.5498578548431396, 'iteration': 6, 'loss': 0.14471329609998995, 'max_history_score': 0.85528670390001, 'max_history_score_std': 0.02213730791268438, 'max_history_step': 'joint', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 4, 'features__selectkbest__k': 3}), 'normalizer': ('normalizer_NoneType', {}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 7})}, 'score': 0.85528670390001, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': 1, 'max_features': 3, 'max_leaf_nodes': 3, 'min_samples_split': 3, 'n_estimators': 75}, 'config_hash': {'algorithm': 'ebfb16234172ae811ff21185ff92bbdbb8f32f14', 'config': 'd92d4ada2394fc132733e176e926ee53acdc6a00', 'pipeline': '8071e7cbf86a5c3056493dc3aa40063aeb28cdfe'}, 'duration': 1.3618149757385254, 'iteration': 7, 'loss': 0.6158612049395463, 'max_history_score': 0.85528670390001, 'max_history_score_std': 0.02213730791268438, 'max_history_step': 'joint', 'pipeline': {'features': ('features_SelectKBest', {'features__k': 4}), 'normalizer': ('normalizer_StandardScaler', {'normalizer__with_mean': True, 'normalizer__with_std': True}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 5})}, 'score': 0.3841387950604537, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'entropy', 'max_depth': 1, 'max_features': 1, 'max_leaf_nodes': 5, 'min_samples_split': 2, 'n_estimators': 100}, 'config_hash': {'algorithm': '896b53c75a2db568fb7b6da3bfca2f7a1535a11b', 'config': 'f0d0b1d2cedc22ae15d9a208a3fc3fc133bf0d3d', 'pipeline': 'c9761c9a33bf75d6dcad0742c421548a7655ccc9'}, 'duration': 2.297278881072998, 'iteration': 8, 'loss': 0.40673663548410355, 'max_history_score': 0.85528670390001, 'max_history_score_std': 0.02213730791268438, 'max_history_step': 'joint', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 2, 'features__selectkbest__k': 4}), 'normalizer': ('normalizer_StandardScaler', {'normalizer__with_mean': False, 'normalizer__with_std': False}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 5})}, 'score': 0.5932633645158965, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'entropy', 'max_depth': 2, 'max_features': None, 'max_leaf_nodes': None, 'min_samples_split': 5, 'n_estimators': 25}, 'config_hash': {'algorithm': '0b0e954757c4f75343a6efb740ad93260ed781ae', 'config': '47584de0e60d0d12c7dbbf0dc60e5aea96e3f4b2', 'pipeline': 'b37ee32d59413053bf9a2a72c8ff7135f3701e05'}, 'duration': 0.7249000072479248, 'iteration': 9, 'loss': 0.6965910020393421, 'max_history_score': 0.85528670390001, 'max_history_score_std': 0.02213730791268438, 'max_history_step': 'joint', 'pipeline': {'features': ('features_SelectKBest', {'features__k': 3}), 'normalizer': ('normalizer_NoneType', {}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 7})}, 'score': 0.3034089979606579, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'gini', 'max_depth': 2, 'max_features': 2, 'max_leaf_nodes': 5, 'min_samples_split': 5, 'n_estimators': 75}, 'config_hash': {'algorithm': 'f1ead1d9e33ea927e1dd27d872a058fa3de4f832', 'config': 'eecb88ee2b1b95d741c1b5c7751534d31aae6a77', 'pipeline': '6746650871e8b61efc9302b092dc05f7cdb179d5'}, 'duration': 5.340634822845459, 'iteration': 10, 'loss': 0.7687016290977936, 'max_history_score': 0.85528670390001, 'max_history_score_std': 0.02213730791268438, 'max_history_step': 'joint', 'pipeline': {'features': ('features_SelectKBest', {'features__k': 3}), 'normalizer': ('normalizer_RobustScaler', {'normalizer__quantile_range': (...), 'normalizer__with_centering': False, 'normalizer__with_scaling': False}), 'rebalance': ('rebalance_CondensedNearestNeighbour', {'rebalance__n_neighbors': 1})}, 'score': 0.23129837090220637, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': 1, 'max_features': 2, 'max_leaf_nodes': 2, 'min_samples_split': 3, 'n_estimators': 75}, 'config_hash': {'algorithm': '531a3bb8ccf0baa06727af4b3de9e62d25e6eabf', 'config': '27a7ed0502b321ab7256b77c8ce79e90cb9da815', 'pipeline': '77e6d84e2217b92b3cf67cc6defef9dd3554cec0'}, 'duration': 1.775357961654663, 'iteration': 11, 'loss': 0.6313818737375694, 'max_history_score': 0.85528670390001, 'max_history_score_std': 0.02213730791268438, 'max_history_step': 'joint', 'pipeline': {'features': ('features_SelectKBest', {'features__k': 4}), 'normalizer': ('normalizer_MinMaxScaler', {}), 'rebalance': ('rebalance_NearMiss', {'rebalance__n_neighbors': 3})}, 'score': 0.3686181262624307, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'entropy', 'max_depth': 4, 'max_features': 3, 'max_leaf_nodes': 2, 'min_samples_split': 3, 'n_estimators': 10}, 'config_hash': {'algorithm': '93518f8ded6074d537900b26be72f8485782f933', 'config': '45f056102dd2d644bd8befa471f17b2311ac7954', 'pipeline': '5240329df25c9a533d025c1a401d49835a501b41'}, 'duration': 3.2622711658477783, 'iteration': 12, 'loss': 0.6120243191353301, 'max_history_score': 0.85528670390001, 'max_history_score_std': 0.02213730791268438, 'max_history_step': 'joint', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 4, 'features__selectkbest__k': 2}), 'normalizer': ('normalizer_PowerTransformer', {}), 'rebalance': ('rebalance_NearMiss', {'rebalance__n_neighbors': 1})}, 'score': 0.38797568086467, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'entropy', 'max_depth': None, 'max_features': 1, 'max_leaf_nodes': 5, 'min_samples_split': 3, 'n_estimators': 75}, 'config_hash': {'algorithm': 'e515d45b764fa43591032874a0ff9c25bf12fddd', 'config': 'ba108323623936872824ed8f1c41d615d25523b3', 'pipeline': '9d823bc0442f21b5ce8af67a5eb1237f64ffc2f8'}, 'duration': 2.5326571464538574, 'iteration': 13, 'loss': 0.6271427382991047, 'max_history_score': 0.85528670390001, 'max_history_score_std': 0.02213730791268438, 'max_history_step': 'joint', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 1, 'features__selectkbest__k': 1}), 'normalizer': ('normalizer_StandardScaler', {'normalizer__with_mean': True, 'normalizer__with_std': True}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 5})}, 'score': 0.3728572617008953, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'entropy', 'max_depth': 3, 'max_features': 2, 'max_leaf_nodes': 2, 'min_samples_split': 3, 'n_estimators': 25}, 'config_hash': {'algorithm': '2808e67f609eba5c8a97f81ac0c9413cd37cf7aa', 'config': 'dde4d3b5f37741629cb58bfc4051ed9f98c8f311', 'pipeline': 'bc52deabf1f5ee60968ba541d9d2574353c30a9c'}, 'duration': 0.7145559787750244, 'iteration': 14, 'loss': 0.6831045572696203, 'max_history_score': 0.85528670390001, 'max_history_score_std': 0.02213730791268438, 'max_history_step': 'joint', 'pipeline': {'features': ('features_SelectKBest', {'features__k': 3}), 'normalizer': ('normalizer_MinMaxScaler', {}), 'rebalance': ('rebalance_NearMiss', {'rebalance__n_neighbors': 1})}, 'score': 0.31689544273037973, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'gini', 'max_depth': 2, 'max_features': 2, 'max_leaf_nodes': None, 'min_samples_split': 5, 'n_estimators': 100}, 'config_hash': {'algorithm': 'b942acdead762d34afeb474bc2fe6f7fd0f23493', 'config': '1080c25b92da3f15a6f8eec003957f7e0a66324f', 'pipeline': 'cfa84fe703dc5bc0bbd2257a6d524fee2693b804'}, 'duration': 2.812459945678711, 'iteration': 15, 'loss': 0.6921421091202761, 'max_history_score': 0.85528670390001, 'max_history_score_std': 0.02213730791268438, 'max_history_step': 'joint', 'pipeline': {'features': ('features_SelectKBest', {'features__k': 2}), 'normalizer': ('normalizer_PowerTransformer', {}), 'rebalance': ('rebalance_NoneType', {})}, 'score': 0.3078578908797239, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'entropy', 'max_depth': 2, 'max_features': 3, 'max_leaf_nodes': 3, 'min_samples_split': 2, 'n_estimators': 75}, 'config_hash': {'algorithm': '250661ce4193a61ef44d2f77694b52b785ff032d', 'config': 'c3e8cf4eca5aafcae4ac31b0449e105ca127ffe2', 'pipeline': 'c4dd111513ea35f97dd3aec3e8e7f6268ce035da'}, 'duration': 1.0555319786071777, 'iteration': 16, 'loss': 1.0, 'max_history_score': 0.85528670390001, 'max_history_score_std': 0.02213730791268438, 'max_history_step': 'joint', 'pipeline': {'features': ('features_PCA', {'features__n_components': 2}), 'normalizer': ('normalizer_RobustScaler', {'normalizer__quantile_range': (...), 'normalizer__with_centering': False, 'normalizer__with_scaling': True}), 'rebalance': ('rebalance_NearMiss', {'rebalance__n_neighbors': 2})}, 'score': 0.0, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'entropy', 'max_depth': 3, 'max_features': 3, 'max_leaf_nodes': None, 'min_samples_split': 3, 'n_estimators': 25}, 'config_hash': {'algorithm': '05ac02bd045c65dc4089894902ad6253661a2692', 'config': '3449b4a1c2e488e26a7195ee9edca19b854ebd33', 'pipeline': '505d3f71b534917375d765e64b0611e7dfb83746'}, 'duration': 5.5412821769714355, 'iteration': 17, 'loss': 0.7289151155121668, 'max_history_score': 0.85528670390001, 'max_history_score_std': 0.02213730791268438, 'max_history_step': 'joint', 'pipeline': {'features': ('features_SelectKBest', {'features__k': 4}), 'normalizer': ('normalizer_MinMaxScaler', {}), 'rebalance': ('rebalance_CondensedNearestNeighbour', {'rebalance__n_neighbors': 2})}, 'score': 0.2710848844878332, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'entropy', 'max_depth': 2, 'max_features': None, 'max_leaf_nodes': None, 'min_samples_split': 2, 'n_estimators': 25}, 'config_hash': {'algorithm': 'de3b3a352ebb260e16c6b213a08c9144d17a744b', 'config': '224987ffdbbb9b6182cff18d8374518b917e4f2e', 'pipeline': '12c89200a558b2f3b91332566f41050143aecbe7'}, 'duration': 2.4646048545837402, 'iteration': 18, 'loss': 0.6545902512995826, 'max_history_score': 0.85528670390001, 'max_history_score_std': 0.02213730791268438, 'max_history_step': 'joint', 'pipeline': {'features': ('features_NoneType', {}), 'normalizer': ('normalizer_PowerTransformer', {}), 'rebalance': ('rebalance_NearMiss', {'rebalance__n_neighbors': 2})}, 'score': 0.3454097487004174, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'gini', 'max_depth': None, 'max_features': 1, 'max_leaf_nodes': None, 'min_samples_split': 3, 'n_estimators': 100}, 'config_hash': {'algorithm': '30ca111584767bbf0464df40b4c928cf7ddf9459', 'config': '97ca7d6a017c721084dec2a5d2e5a67e1e6ae2f0', 'pipeline': '789eca82ea4a42d61927670c538867b745fd81d3'}, 'duration': 7.164499044418335, 'iteration': 19, 'loss': 0.6536825403350528, 'max_history_score': 0.85528670390001, 'max_history_score_std': 0.02213730791268438, 'max_history_step': 'joint', 'pipeline': {'features': ('features_SelectKBest', {'features__k': 3}), 'normalizer': ('normalizer_RobustScaler', {'normalizer__quantile_range': (...), 'normalizer__with_centering': False, 'normalizer__with_scaling': True}), 'rebalance': ('rebalance_CondensedNearestNeighbour', {'rebalance__n_neighbors': 3})}, 'score': 0.3463174596649472, ...}, ...], 'history_hash': ['fd24b065dda6bdeb1077793f9df480ff318c7a37', 'fb22f80fb4358ae1ee4c9bd4a83543992be8d806', '8c97cdb885dd05cfd8c40ee3ac445b61e5c767a8', '16fbb5fd5cfbbacfddf27c61c0c7397a7f6d8ade', 'a77c698197c31308211b854e81a998178941f87d', '1fc13606bca3aaf342ca6ea21139cb598b56f8db', '6749af1a67b4dbcd2b4719e419d99908063c05e1', 'd92d4ada2394fc132733e176e926ee53acdc6a00', 'f0d0b1d2cedc22ae15d9a208a3fc3fc133bf0d3d', '47584de0e60d0d12c7dbbf0dc60e5aea96e3f4b2', 'eecb88ee2b1b95d741c1b5c7751534d31aae6a77', '27a7ed0502b321ab7256b77c8ce79e90cb9da815', '45f056102dd2d644bd8befa471f17b2311ac7954', 'ba108323623936872824ed8f1c41d615d25523b3', 'dde4d3b5f37741629cb58bfc4051ed9f98c8f311', '1080c25b92da3f15a6f8eec003957f7e0a66324f', 'c3e8cf4eca5aafcae4ac31b0449e105ca127ffe2', '3449b4a1c2e488e26a7195ee9edca19b854ebd33', '224987ffdbbb9b6182cff18d8374518b917e4f2e', '97ca7d6a017c721084dec2a5d2e5a67e1e6ae2f0', ...], 'history_index': {'01b68ec8d6fe15ffdadf1adfd0d809307d3ce41e': 81, '05465becb12810ce291074be22a0275a42efbea8': 52, '064f53edf4748bb2df4ff59f147331aad21219e1': 48, '087efef4a19f272562d2d445dac0edd8096ba2fa': 58, '0fd4d71ca3a89c7d14af5087f2a2e2c1b1975351': 51, '1080c25b92da3f15a6f8eec003957f7e0a66324f': 15, '10ca1ab51b6af0696dab2c8cbaf8de5e3812a6de': 78, '143679b59e16961765e77616142572b6ded0ee72': 62, '151b4a15037767108da13dafa0b63ae93222e93a': 53, '16fbb5fd5cfbbacfddf27c61c0c7397a7f6d8ade': 3, ...}, 'iteration': 88, 'max_history_score': 0.9231904384036744, 'max_history_score_std': 0.03040515884196498, 'max_history_step': 'joint'}, config={'algorithm': 'RandomForest', 'seed': 42, 'time': 300}, step='joint')
     45                 y,
     46                 cv=10,
     47                 n_jobs=-1,
     48                 return_estimator=False,
     49                 return_train_score=False,
---> 50                 verbose=0)
     51         score = np.mean(scores['test_score'])
     52         std = np.std(scores['test_score'])
     53         status = STATUS_OK
     54     except Exception as e:

...........................................................................
/home/aquemy/.local/lib/python2.7/site-packages/sklearn/model_selection/_validation.py in cross_validate(estimator=Pipeline(memory=None,
     steps=[('rebalance', ...e=42,
            verbose=0, warm_start=False))]), X=array([[ 0.,  0.,  5., ...,  0.,  0.,  0.],
    ...0.],
       [ 0.,  0., 10., ..., 12.,  1.,  0.]]), y=array([0, 1, 2, ..., 8, 9, 8]), groups=None, scoring=None, cv=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1, verbose=0, fit_params=None, pre_dispatch='2*n_jobs', return_train_score=False, return_estimator=False, error_score='raise-deprecating')
    235         delayed(_fit_and_score)(
    236             clone(estimator), X, y, scorers, train, test, verbose, None,
    237             fit_params, return_train_score=return_train_score,
    238             return_times=True, return_estimator=return_estimator,
    239             error_score=error_score)
--> 240         for train, test in cv.split(X, y, groups))
        cv.split = <bound method StratifiedKFold.split of Stratifie...d(n_splits=10, random_state=None, shuffle=False)>
        X = array([[ 0.,  0.,  5., ...,  0.,  0.,  0.],
    ...0.],
       [ 0.,  0., 10., ..., 12.,  1.,  0.]])
        y = array([0, 1, 2, ..., 8, 9, 8])
        groups = None
    241 
    242     zipped_scores = list(zip(*scores))
    243     if return_train_score:
    244         train_scores = zipped_scores.pop(0)

...........................................................................
/home/aquemy/.local/lib/python2.7/site-packages/sklearn/externals/joblib/parallel.py in __call__(self=Parallel(n_jobs=-1), iterable=<generator object <genexpr>>)
    925                 # No need to wait for async callbacks to trigger to
    926                 # consumption.
    927                 self._iterating = False
    928 
    929             with self._backend.retrieval_context():
--> 930                 self.retrieve()
        self.retrieve = <bound method Parallel.retrieve of Parallel(n_jobs=-1)>
    931             # Make sure that we get a last message telling us we are done
    932             elapsed_time = time.time() - self._start_time
    933             self._print('Done %3i out of %3i | elapsed: %s finished',
    934                         (len(self._output), len(self._output),

---------------------------------------------------------------------------
Joblib worker traceback:
---------------------------------------------------------------------------
ValueError                                         Mon Jun 17 13:09:22 2019
PID: 20416                                  Python 2.7.15+: /usr/bin/python
...........................................................................
/home/aquemy/.local/lib/python2.7/site-packages/sklearn/externals/joblib/parallel.py in __call__(self=<sklearn.externals.joblib.parallel.BatchedCalls object>)
    220     def __call__(self):
    221         # Set the default nested backend to self._backend but do not set the
    222         # change the default number of processes to -1
    223         with parallel_backend(self._backend, n_jobs=self._n_jobs):
    224             return [func(*args, **kwargs)
--> 225                     for func, args, kwargs in self.items]
        func = <function _fit_and_score>
        args = (Pipeline(memory=None,
     steps=[('rebalance', ...e=42,
            verbose=0, warm_start=False))]), array([[ 0.,  0.,  5., ...,  0.,  0.,  0.],
    ...0.],
       [ 0.,  0., 10., ..., 12.,  1.,  0.]]), array([0, 1, 2, ..., 8, 9, 8]), {'score': <function _passthrough_scorer>}, array([ 169,  176,  178, ..., 1794, 1795, 1796]), array([  0,   1,   2,   3,   4,   5,   6,   7,  ..., 181, 186, 188, 189, 190,
       194, 195, 198]), 0, None, None)
        kwargs = {'error_score': 'raise-deprecating', 'return_estimator': False, 'return_times': True, 'return_train_score': False}
        self.items = [(<function _fit_and_score>, (Pipeline(memory=None,
     steps=[('rebalance', ...e=42,
            verbose=0, warm_start=False))]), array([[ 0.,  0.,  5., ...,  0.,  0.,  0.],
    ...0.],
       [ 0.,  0., 10., ..., 12.,  1.,  0.]]), array([0, 1, 2, ..., 8, 9, 8]), {'score': <function _passthrough_scorer>}, array([ 169,  176,  178, ..., 1794, 1795, 1796]), array([  0,   1,   2,   3,   4,   5,   6,   7,  ..., 181, 186, 188, 189, 190,
       194, 195, 198]), 0, None, None), {'error_score': 'raise-deprecating', 'return_estimator': False, 'return_times': True, 'return_train_score': False})]
    226 
    227     def __len__(self):
    228         return self._size
    229 

...........................................................................
/home/aquemy/.local/lib/python2.7/site-packages/sklearn/model_selection/_validation.py in _fit_and_score(estimator=Pipeline(memory=None,
     steps=[('rebalance', ...e=42,
            verbose=0, warm_start=False))]), X=array([[ 0.,  0.,  5., ...,  0.,  0.,  0.],
    ...0.],
       [ 0.,  0., 10., ..., 12.,  1.,  0.]]), y=array([0, 1, 2, ..., 8, 9, 8]), scorer={'score': <function _passthrough_scorer>}, train=array([ 169,  176,  178, ..., 1794, 1795, 1796]), test=array([  0,   1,   2,   3,   4,   5,   6,   7,  ..., 181, 186, 188, 189, 190,
       194, 195, 198]), verbose=0, parameters=None, fit_params={}, return_train_score=False, return_parameters=False, return_n_test_samples=False, return_times=True, return_estimator=False, error_score='raise-deprecating')
    523 
    524     try:
    525         if y_train is None:
    526             estimator.fit(X_train, **fit_params)
    527         else:
--> 528             estimator.fit(X_train, y_train, **fit_params)
        estimator.fit = <bound method Pipeline.fit of Pipeline(memory=No...=42,
            verbose=0, warm_start=False))])>
        X_train = array([[ 0.,  0.,  6., ...,  9.,  4.,  0.],
    ...0.],
       [ 0.,  0., 10., ..., 12.,  1.,  0.]])
        y_train = array([9, 5, 0, ..., 8, 9, 8])
        fit_params = {}
    529 
    530     except Exception as e:
    531         # Note fit time as time until error
    532         fit_time = time.time() - start_time

...........................................................................
/usr/local/lib/python2.7/dist-packages/imblearn/pipeline.py in fit(self=Pipeline(memory=None,
     steps=[('rebalance', ...e=42,
            verbose=0, warm_start=False))]), X=array([[ 0.,  0.,  6., ...,  9.,  4.,  0.],
    ...0.],
       [ 0.,  0., 10., ..., 12.,  1.,  0.]]), y=array([9, 5, 0, ..., 8, 9, 8]), **fit_params={})
    234             This estimator
    235 
    236         """
    237         Xt, yt, fit_params = self._fit(X, y, **fit_params)
    238         if self._final_estimator is not None:
--> 239             self._final_estimator.fit(Xt, yt, **fit_params)
        self._final_estimator.fit = <bound method RandomForestClassifier.fit of Rand...ate=42,
            verbose=0, warm_start=False)>
        Xt = array([[ 5.        ,  0.        ],
       [16.  ... 0.        ],
       [12.23648754,  0.        ]])
        yt = array([9, 5, 0, ..., 8, 9, 9])
        fit_params = {}
    240         return self
    241 
    242     def fit_transform(self, X, y=None, **fit_params):
    243         """Fit the model and transform with the final estimator

...........................................................................
/home/aquemy/.local/lib/python2.7/site-packages/sklearn/ensemble/forest.py in fit(self=RandomForestClassifier(bootstrap=False, class_we...tate=42,
            verbose=0, warm_start=False), X=array([[ 5.        ,  0.        ],
       [16.  ...      [12.236487  ,  0.        ]], dtype=float32), y=array([[9.],
       [5.],
       [0.],
       ...,
       [8.],
       [9.],
       [9.]]), sample_weight=None)
    328             trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,
    329                              **_joblib_parallel_args(prefer='threads'))(
    330                 delayed(_parallel_build_trees)(
    331                     t, self, X, y, sample_weight, i, len(trees),
    332                     verbose=self.verbose, class_weight=self.class_weight)
--> 333                 for i, t in enumerate(trees))
        i = 74
    334 
    335             # Collect newly grown trees
    336             self.estimators_.extend(trees)
    337 

...........................................................................
/home/aquemy/.local/lib/python2.7/site-packages/sklearn/externals/joblib/parallel.py in __call__(self=Parallel(n_jobs=1), iterable=<generator object <genexpr>>)
    912             # self._original_iterator is None, then this means either
    913             # that pre_dispatch == "all", n_jobs == 1 or that the first batch
    914             # was very quick and its callback already dispatched all the
    915             # remaining jobs.
    916             self._iterating = False
--> 917             if self.dispatch_one_batch(iterator):
        self.dispatch_one_batch = <bound method Parallel.dispatch_one_batch of Parallel(n_jobs=1)>
        iterator = <generator object <genexpr>>
    918                 self._iterating = self._original_iterator is not None
    919 
    920             while self.dispatch_one_batch(iterator):
    921                 pass

...........................................................................
/home/aquemy/.local/lib/python2.7/site-packages/sklearn/externals/joblib/parallel.py in dispatch_one_batch(self=Parallel(n_jobs=1), iterator=<generator object <genexpr>>)
    754                                  self._pickle_cache)
    755             if len(tasks) == 0:
    756                 # No more tasks available in the iterator: tell caller to stop.
    757                 return False
    758             else:
--> 759                 self._dispatch(tasks)
        self._dispatch = <bound method Parallel._dispatch of Parallel(n_jobs=1)>
        tasks = <sklearn.externals.joblib.parallel.BatchedCalls object>
    760                 return True
    761 
    762     def _print(self, msg, msg_args):
    763         """Display the message on stout or stderr depending on verbosity"""

...........................................................................
/home/aquemy/.local/lib/python2.7/site-packages/sklearn/externals/joblib/parallel.py in _dispatch(self=Parallel(n_jobs=1), batch=<sklearn.externals.joblib.parallel.BatchedCalls object>)
    711 
    712         dispatch_timestamp = time.time()
    713         cb = BatchCompletionCallBack(dispatch_timestamp, len(batch), self)
    714         with self._lock:
    715             job_idx = len(self._jobs)
--> 716             job = self._backend.apply_async(batch, callback=cb)
        job = undefined
        self._backend.apply_async = <bound method SequentialBackend.apply_async of <...lib._parallel_backends.SequentialBackend object>>
        batch = <sklearn.externals.joblib.parallel.BatchedCalls object>
        cb = <sklearn.externals.joblib.parallel.BatchCompletionCallBack object>
    717             # A job can complete so quickly than its callback is
    718             # called before we get here, causing self._jobs to
    719             # grow. To ensure correct results ordering, .insert is
    720             # used (rather than .append) in the following line

...........................................................................
/home/aquemy/.local/lib/python2.7/site-packages/sklearn/externals/joblib/_parallel_backends.py in apply_async(self=<sklearn.externals.joblib._parallel_backends.SequentialBackend object>, func=<sklearn.externals.joblib.parallel.BatchedCalls object>, callback=<sklearn.externals.joblib.parallel.BatchCompletionCallBack object>)
    177             raise ValueError('n_jobs == 0 in Parallel has no meaning')
    178         return 1
    179 
    180     def apply_async(self, func, callback=None):
    181         """Schedule a func to be run"""
--> 182         result = ImmediateResult(func)
        result = undefined
        func = <sklearn.externals.joblib.parallel.BatchedCalls object>
    183         if callback:
    184             callback(result)
    185         return result
    186 

...........................................................................
/home/aquemy/.local/lib/python2.7/site-packages/sklearn/externals/joblib/_parallel_backends.py in __init__(self=<sklearn.externals.joblib._parallel_backends.ImmediateResult object>, batch=<sklearn.externals.joblib.parallel.BatchedCalls object>)
    544 
    545 class ImmediateResult(object):
    546     def __init__(self, batch):
    547         # Don't delay the application, to avoid keeping the input
    548         # arguments in memory
--> 549         self.results = batch()
        self.results = undefined
        batch = <sklearn.externals.joblib.parallel.BatchedCalls object>
    550 
    551     def get(self):
    552         return self.results
    553 

...........................................................................
/home/aquemy/.local/lib/python2.7/site-packages/sklearn/externals/joblib/parallel.py in __call__(self=<sklearn.externals.joblib.parallel.BatchedCalls object>)
    220     def __call__(self):
    221         # Set the default nested backend to self._backend but do not set the
    222         # change the default number of processes to -1
    223         with parallel_backend(self._backend, n_jobs=self._n_jobs):
    224             return [func(*args, **kwargs)
--> 225                     for func, args, kwargs in self.items]
        func = <function _parallel_build_trees>
        args = (DecisionTreeClassifier(class_weight=None, criter...=False, random_state=1608637542, splitter='best'), RandomForestClassifier(bootstrap=False, class_we...tate=42,
            verbose=0, warm_start=False), array([[ 5.        ,  0.        ],
       [16.  ...      [12.236487  ,  0.        ]], dtype=float32), array([[9.],
       [5.],
       [0.],
       ...,
       [8.],
       [9.],
       [9.]]), None, 0, 75)
        kwargs = {'class_weight': None, 'verbose': 0}
        self.items = [(<function _parallel_build_trees>, (DecisionTreeClassifier(class_weight=None, criter...=False, random_state=1608637542, splitter='best'), RandomForestClassifier(bootstrap=False, class_we...tate=42,
            verbose=0, warm_start=False), array([[ 5.        ,  0.        ],
       [16.  ...      [12.236487  ,  0.        ]], dtype=float32), array([[9.],
       [5.],
       [0.],
       ...,
       [8.],
       [9.],
       [9.]]), None, 0, 75), {'class_weight': None, 'verbose': 0})]
    226 
    227     def __len__(self):
    228         return self._size
    229 

...........................................................................
/home/aquemy/.local/lib/python2.7/site-packages/sklearn/ensemble/forest.py in _parallel_build_trees(tree=DecisionTreeClassifier(class_weight=None, criter...=False, random_state=1608637542, splitter='best'), forest=RandomForestClassifier(bootstrap=False, class_we...tate=42,
            verbose=0, warm_start=False), X=array([[ 5.        ,  0.        ],
       [16.  ...      [12.236487  ,  0.        ]], dtype=float32), y=array([[9.],
       [5.],
       [0.],
       ...,
       [8.],
       [9.],
       [9.]]), sample_weight=None, tree_idx=0, n_trees=75, verbose=0, class_weight=None)
    116         elif class_weight == 'balanced_subsample':
    117             curr_sample_weight *= compute_sample_weight('balanced', y, indices)
    118 
    119         tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)
    120     else:
--> 121         tree.fit(X, y, sample_weight=sample_weight, check_input=False)
        tree.fit = <bound method DecisionTreeClassifier.fit of Deci...False, random_state=1608637542, splitter='best')>
        X = array([[ 5.        ,  0.        ],
       [16.  ...      [12.236487  ,  0.        ]], dtype=float32)
        y = array([[9.],
       [5.],
       [0.],
       ...,
       [8.],
       [9.],
       [9.]])
        sample_weight = None
    122 
    123     return tree
    124 
    125 

...........................................................................
/home/aquemy/.local/lib/python2.7/site-packages/sklearn/tree/tree.py in fit(self=DecisionTreeClassifier(class_weight=None, criter...=False, random_state=1608637542, splitter='best'), X=array([[ 5.        ,  0.        ],
       [16.  ...      [12.236487  ,  0.        ]], dtype=float32), y=array([[9.],
       [5.],
       [0.],
       ...,
       [8.],
       [9.],
       [9.]]), sample_weight=None, check_input=False, X_idx_sorted=None)
    796 
    797         super(DecisionTreeClassifier, self).fit(
    798             X, y,
    799             sample_weight=sample_weight,
    800             check_input=check_input,
--> 801             X_idx_sorted=X_idx_sorted)
        X_idx_sorted = None
    802         return self
    803 
    804     def predict_proba(self, X, check_input=True):
    805         """Predict class probabilities of the input samples X.

...........................................................................
/home/aquemy/.local/lib/python2.7/site-packages/sklearn/tree/tree.py in fit(self=DecisionTreeClassifier(class_weight=None, criter...=False, random_state=1608637542, splitter='best'), X=array([[ 5.        ,  0.        ],
       [16.  ...      [12.236487  ,  0.        ]], dtype=float32), y=array([[9.],
       [5.],
       [0.],
       ...,
       [8.],
       [9.],
       [9.]]), sample_weight=None, check_input=False, X_idx_sorted=None)
    237         if not 0 <= self.min_weight_fraction_leaf <= 0.5:
    238             raise ValueError("min_weight_fraction_leaf must in [0, 0.5]")
    239         if max_depth <= 0:
    240             raise ValueError("max_depth must be greater than zero. ")
    241         if not (0 < max_features <= self.n_features_):
--> 242             raise ValueError("max_features must be in (0, n_features]")
    243         if not isinstance(max_leaf_nodes, (numbers.Integral, np.integer)):
    244             raise ValueError("max_leaf_nodes must be integral number but was "
    245                              "%r" % max_leaf_nodes)
    246         if -1 < max_leaf_nodes < 2:

ValueError: max_features must be in (0, n_features]
___________________________________________________________________________
Best score: 0.923190438404 (0.030405158842) [J] | Score: 0.0 (0.0) [J]
Best score: 0.923190438404 (0.030405158842) [J] | Score: 0.602566477555 (0.0251911210157) [J]
Best score: 0.923190438404 (0.030405158842) [J] | Score: 0.679979917527 (0.0427108004374) [J]
Best score: 0.923190438404 (0.030405158842) [J] | Score: 0.773504923874 (0.0379382535942) [J]
Best score: 0.923190438404 (0.030405158842) [J] | Score: 0.658346099822 (0.0459998487859) [J]
Best score: 0.923190438404 (0.030405158842) [J] | Score: 0.855235246314 (0.0395325927664) [J]
JoblibValueError
___________________________________________________________________________
...........................................................................
/home/aquemy/dev/dp_hyperparameters/extension/main.py in <module>()
     27 
     28     serializer.serialize_results(scenario, policy)
     29 
     30 if __name__ == "__main__":
     31     args = cli.parse_args()
---> 32     main(args)

...........................................................................
/home/aquemy/dev/dp_hyperparameters/extension/main.py in main(args=Namespace(customize=[(['control', 'seed'], '42')...='./scenarios/rf_digits_joint.yaml', verbosity=0))
     21         test_size=0.4, 
     22         random_state=scenario['control']['seed']
     23     )
     24 
     25     policy = policies.initiate(scenario['setup']['policy'], config)
---> 26     policy.run(X,y)
        policy.run = <bound method Joint.run of <experiment.policies.joint.Joint object>>
        X = array([[ 0.,  0.,  5., ...,  0.,  0.,  0.],
    ...0.],
       [ 0.,  0., 10., ..., 12.,  1.,  0.]])
        y = array([0, 1, 2, ..., 8, 9, 8])
     27 
     28     serializer.serialize_results(scenario, policy)
     29 
     30 if __name__ == "__main__":

...........................................................................
/home/aquemy/dev/dp_hyperparameters/extension/experiment/policies/joint.py in run(self=<experiment.policies.joint.Joint object>, X=array([[ 0.,  0.,  5., ...,  0.,  0.,  0.],
    ...0.],
       [ 0.,  0., 10., ..., 12.,  1.,  0.]]), y=array([0, 1, 2, ..., 8, 9, 8]))
     32             algo=tpe.suggest, 
     33             max_evals=None,
     34             max_time=self.config['time'],     
     35             trials=trials,
     36             show_progressbar=False,
---> 37             verbose=0
     38         )
     39 
     40         best_config = self.context['best_config']
     41         super(Joint, self).display_step_results(best_config)

...........................................................................
/home/aquemy/dev/dp_hyperparameters/extension/hyperopt/fmin.py in fmin(fn=<functools.partial object>, space={'algorithm': {'bootstrap': <hyperopt.pyll.base.Apply object>, 'criterion': <hyperopt.pyll.base.Apply object>, 'max_depth': <hyperopt.pyll.base.Apply object>, 'max_features': <hyperopt.pyll.base.Apply object>, 'max_leaf_nodes': <hyperopt.pyll.base.Apply object>, 'min_samples_split': <hyperopt.pyll.base.Apply object>, 'n_estimators': <hyperopt.pyll.base.Apply object>}, 'pipeline': {'features': <hyperopt.pyll.base.Apply object>, 'normalizer': <hyperopt.pyll.base.Apply object>, 'rebalance': <hyperopt.pyll.base.Apply object>}}, algo=<function suggest>, max_evals=9223372036854775807, max_time=300, trials=<hyperopt.base.Trials object>, rstate=<mtrand.RandomState object>, allow_trials_fmin=True, pass_expr_memo_ctrl=None, catch_eval_exceptions=False, verbose=0, return_argmin=True, points_to_evaluate=None, max_queue_len=1, show_progressbar=False)
    406             pass_expr_memo_ctrl=pass_expr_memo_ctrl,
    407             verbose=verbose,
    408             catch_eval_exceptions=catch_eval_exceptions,
    409             return_argmin=return_argmin,
    410             show_progressbar=show_progressbar,
--> 411             max_time=max_time
        max_time = 300
    412         )
    413 
    414     if trials is None:
    415         if points_to_evaluate is None:

...........................................................................
/home/aquemy/dev/dp_hyperparameters/extension/hyperopt/base.py in fmin(self=<hyperopt.base.Trials object>, fn=<functools.partial object>, space={'algorithm': {'bootstrap': <hyperopt.pyll.base.Apply object>, 'criterion': <hyperopt.pyll.base.Apply object>, 'max_depth': <hyperopt.pyll.base.Apply object>, 'max_features': <hyperopt.pyll.base.Apply object>, 'max_leaf_nodes': <hyperopt.pyll.base.Apply object>, 'min_samples_split': <hyperopt.pyll.base.Apply object>, 'n_estimators': <hyperopt.pyll.base.Apply object>}, 'pipeline': {'features': <hyperopt.pyll.base.Apply object>, 'normalizer': <hyperopt.pyll.base.Apply object>, 'rebalance': <hyperopt.pyll.base.Apply object>}}, algo=<function suggest>, max_evals=9223372036854775807, max_time=300, rstate=<mtrand.RandomState object>, verbose=0, pass_expr_memo_ctrl=None, catch_eval_exceptions=False, return_argmin=True, show_progressbar=False)
    636             verbose=verbose,
    637             allow_trials_fmin=False,  # -- prevent recursion
    638             pass_expr_memo_ctrl=pass_expr_memo_ctrl,
    639             catch_eval_exceptions=catch_eval_exceptions,
    640             return_argmin=return_argmin,
--> 641             show_progressbar=show_progressbar)
        show_progressbar = False
    642 
    643 
    644 def trials_from_docs(docs, validate=True, **kwargs):
    645     """Construct a Trials base class instance from a list of trials documents

...........................................................................
/home/aquemy/dev/dp_hyperparameters/extension/hyperopt/fmin.py in fmin(fn=<functools.partial object>, space={'algorithm': {'bootstrap': <hyperopt.pyll.base.Apply object>, 'criterion': <hyperopt.pyll.base.Apply object>, 'max_depth': <hyperopt.pyll.base.Apply object>, 'max_features': <hyperopt.pyll.base.Apply object>, 'max_leaf_nodes': <hyperopt.pyll.base.Apply object>, 'min_samples_split': <hyperopt.pyll.base.Apply object>, 'n_estimators': <hyperopt.pyll.base.Apply object>}, 'pipeline': {'features': <hyperopt.pyll.base.Apply object>, 'normalizer': <hyperopt.pyll.base.Apply object>, 'rebalance': <hyperopt.pyll.base.Apply object>}}, algo=<function suggest>, max_evals=9223372036854775807, max_time=300, trials=<hyperopt.base.Trials object>, rstate=<mtrand.RandomState object>, allow_trials_fmin=False, pass_expr_memo_ctrl=None, catch_eval_exceptions=False, verbose=0, return_argmin=True, points_to_evaluate=None, max_queue_len=1, show_progressbar=False)
    426                     verbose=verbose,
    427                     max_queue_len=max_queue_len,
    428                     show_progressbar=show_progressbar,
    429                     max_time=max_time)
    430     rval.catch_eval_exceptions = catch_eval_exceptions
--> 431     rval.exhaust()
        rval.exhaust = <bound method FMinIter.exhaust of <hyperopt.fmin.FMinIter object>>
    432     if return_argmin:
    433         return trials.argmin
    434     elif len(trials) > 0:
    435         # Only if there are some succesfull trail runs, return the best point in the evaluation space

...........................................................................
/home/aquemy/dev/dp_hyperparameters/extension/hyperopt/fmin.py in exhaust(self=<hyperopt.fmin.FMinIter object>)
    273             raise StopIteration()
    274         return self.trials
    275 
    276     def exhaust(self):
    277         n_done = len(self.trials)
--> 278         self.run(self.max_evals - n_done, block_until_done=self.asynchronous)
        self.run = <bound method FMinIter.run of <hyperopt.fmin.FMinIter object>>
        self.max_evals = 9223372036854775807
        n_done = 0
        self.asynchronous = False
    279         self.trials.refresh()
    280         return self
    281 
    282 

...........................................................................
/home/aquemy/dev/dp_hyperparameters/extension/hyperopt/fmin.py in run(self=<hyperopt.fmin.FMinIter object>, N=9223372036854775807, block_until_done=False)
    232                     if self.asynchronous:
    233                         # -- wait for workers to fill in the trials
    234                         time.sleep(self.poll_interval_secs)
    235                     else:
    236                         # -- loop over trials and do the jobs directly
--> 237                         self.serial_evaluate()
        self.serial_evaluate = <bound method FMinIter.serial_evaluate of <hyperopt.fmin.FMinIter object>>
    238                     try:
    239                         res = [d['result']['loss'] for d in
    240                                          self.trials.trials if
    241                                          d['result']['status'] == 'ok']

...........................................................................
/home/aquemy/dev/dp_hyperparameters/extension/hyperopt/fmin.py in serial_evaluate(self=<hyperopt.fmin.FMinIter object>, N=-1)
    138                 trial['book_time'] = now
    139                 trial['refresh_time'] = now
    140                 spec = base.spec_from_misc(trial['misc'])
    141                 ctrl = base.Ctrl(self.trials, current_trial=trial)
    142                 try:
--> 143                     result = self.domain.evaluate(spec, ctrl)
        result = undefined
        self.domain.evaluate = <bound method Domain.evaluate of <hyperopt.base.Domain object>>
        spec = {'bootstrap': 1, 'criterion': 1, 'features': 2, 'features_SelectKBest_features__k': 0, 'max_depth': 2, 'max_features': 1, 'max_leaf_nodes': 3, 'min_samples_split': 0, 'n_estimators': 4, 'normalizer': 4, ...}
        ctrl = <hyperopt.base.Ctrl object>
    144                 except Exception as e:
    145                     logger.info('job exception: %s' % str(e))
    146                     trial['state'] = base.JOB_STATE_ERROR
    147                     trial['misc']['error'] = (str(type(e)), str(e))

...........................................................................
/home/aquemy/dev/dp_hyperparameters/extension/hyperopt/base.py in evaluate(self=<hyperopt.base.Domain object>, config={'bootstrap': 1, 'criterion': 1, 'features': 2, 'features_SelectKBest_features__k': 0, 'max_depth': 2, 'max_features': 1, 'max_leaf_nodes': 3, 'min_samples_split': 0, 'n_estimators': 4, 'normalizer': 4, ...}, ctrl=<hyperopt.base.Ctrl object>, attach_attachments=True)
    841             #    or the normal Python part (self.fn)
    842             pyll_rval = pyll.rec_eval(
    843                 self.expr,
    844                 memo=memo,
    845                 print_node_on_error=self.rec_eval_print_node_on_error)
--> 846             rval = self.fn(pyll_rval)
        rval = undefined
        self.fn = <functools.partial object>
        pyll_rval = {'algorithm': {'bootstrap': False, 'criterion': 'entropy', 'max_depth': 3, 'max_features': 2, 'max_leaf_nodes': None, 'min_samples_split': 2, 'n_estimators': 100}, 'pipeline': {'features': ('features_SelectKBest', {'features__k': 1}), 'normalizer': ('normalizer_RobustScaler', {'normalizer__quantile_range': (25.0, 75.0), 'normalizer__with_centering': False, 'normalizer__with_scaling': False}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 5})}}
    847 
    848         if isinstance(rval, (float, int, np.number)):
    849             dict_rval = {'loss': float(rval), 'status': STATUS_OK}
    850         else:

...........................................................................
/home/aquemy/dev/dp_hyperparameters/extension/experiment/objective.py in objective_joint(wconfig={'algorithm': {'bootstrap': False, 'criterion': 'entropy', 'max_depth': 3, 'max_features': 2, 'max_leaf_nodes': None, 'min_samples_split': 2, 'n_estimators': 100}, 'pipeline': {'features': ('features_SelectKBest', {'features__k': 1}), 'normalizer': ('normalizer_RobustScaler', {'normalizer__quantile_range': (25.0, 75.0), 'normalizer__with_centering': False, 'normalizer__with_scaling': False}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 5})}}, algorithm='RandomForest', X=array([[ 0.,  0.,  5., ...,  0.,  0.,  0.],
    ...0.],
       [ 0.,  0., 10., ..., 12.,  1.,  0.]]), y=array([0, 1, 2, ..., 8, 9, 8]), context={'baseline_score': 0.9272021217853512, 'baseline_score_std': 0.026919033284817703, 'best_config': {'algorithm': {'bootstrap': True, 'criterion': 'entropy', 'max_depth': None, 'max_features': None, 'max_leaf_nodes': None, 'min_samples_split': 3, 'n_estimators': 75}, 'config_hash': {'algorithm': 'f42e45bee34ac9973699212f6c8b845daea9383a', 'config': 'ae61cfde4c8b4c792e42d6b6be4af4ffb3d90e13', 'pipeline': '15ff3d6270ac899763bb3f72417c48bcd56aa7d8'}, 'duration': 8.20555305480957, 'iteration': 65, 'loss': 0.07680956159632557, 'max_history_score': 0.9231904384036744, 'max_history_score_std': 0.03040515884196498, 'max_history_step': 'joint', 'pipeline': {'features': ('features_NoneType', {}), 'normalizer': ('normalizer_StandardScaler', {'normalizer__with_mean': True, 'normalizer__with_std': True}), 'rebalance': ('rebalance_NearMiss', {'rebalance__n_neighbors': 1})}, 'score': 0.9231904384036744, ...}, 'history': [{'algorithm': {'bootstrap': False, 'criterion': 'entropy', 'max_depth': 1, 'max_features': 3, 'max_leaf_nodes': 3, 'min_samples_split': 5, 'n_estimators': 50}, 'config_hash': {'algorithm': '752fa095cdab58a238ae606c613606188964cc0c', 'config': 'fd24b065dda6bdeb1077793f9df480ff318c7a37', 'pipeline': '13ea3359c453b8993fcec1e88bc0e19cd0a2b112'}, 'duration': 0.689669132232666, 'iteration': 0, 'loss': 0.6602879519109309, 'max_history_score': 0.3397120480890691, 'max_history_score_std': 0.03346542949100545, 'max_history_step': 'joint', 'pipeline': {'features': ('features_SelectKBest', {'features__k': 4}), 'normalizer': ('normalizer_MinMaxScaler', {}), 'rebalance': ('rebalance_NoneType', {})}, 'score': 0.3397120480890691, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'gini', 'max_depth': 4, 'max_features': 1, 'max_leaf_nodes': 5, 'min_samples_split': 3, 'n_estimators': 25}, 'config_hash': {'algorithm': '9d9de4aee820052ddfe83bfffca420f6b50837d3', 'config': 'fb22f80fb4358ae1ee4c9bd4a83543992be8d806', 'pipeline': '6251ad4bb7a110726a67f90c319f4717ac37a312'}, 'duration': 1.4300940036773682, 'iteration': 1, 'loss': 0.5122196101741096, 'max_history_score': 0.48778038982589045, 'max_history_score_std': 0.05486079759217226, 'max_history_step': 'joint', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 2, 'features__selectkbest__k': 2}), 'normalizer': ('normalizer_StandardScaler', {'normalizer__with_mean': True, 'normalizer__with_std': True}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 5})}, 'score': 0.48778038982589045, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': 4, 'max_features': 1, 'max_leaf_nodes': None, 'min_samples_split': 2, 'n_estimators': 10}, 'config_hash': {'algorithm': '2ed7d27df9a1b2d5e63da76f7cb309616c232022', 'config': '8c97cdb885dd05cfd8c40ee3ac445b61e5c767a8', 'pipeline': 'c0abb5e23a4739d3120740a9519fb36c43eb94d5'}, 'duration': 3.0036678314208984, 'iteration': 2, 'loss': 0.38319264175312906, 'max_history_score': 0.6168073582468709, 'max_history_score_std': 0.05286679173001824, 'max_history_step': 'joint', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 1, 'features__selectkbest__k': 4}), 'normalizer': ('normalizer_PowerTransformer', {}), 'rebalance': ('rebalance_NearMiss', {'rebalance__n_neighbors': 2})}, 'score': 0.6168073582468709, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'entropy', 'max_depth': None, 'max_features': None, 'max_leaf_nodes': 2, 'min_samples_split': 2, 'n_estimators': 100}, 'config_hash': {'algorithm': '17962655e3b76dfcd0843d1e5c2cb7a9db1c6a79', 'config': '16fbb5fd5cfbbacfddf27c61c0c7397a7f6d8ade', 'pipeline': '13ea3359c453b8993fcec1e88bc0e19cd0a2b112'}, 'duration': 1.3447980880737305, 'iteration': 3, 'loss': 0.6768840987778313, 'max_history_score': 0.6168073582468709, 'max_history_score_std': 0.05286679173001824, 'max_history_step': 'joint', 'pipeline': {'features': ('features_SelectKBest', {'features__k': 4}), 'normalizer': ('normalizer_MinMaxScaler', {}), 'rebalance': ('rebalance_NoneType', {})}, 'score': 0.32311590122216866, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'gini', 'max_depth': 2, 'max_features': 2, 'max_leaf_nodes': 2, 'min_samples_split': 3, 'n_estimators': 100}, 'config_hash': {'algorithm': '1ea8965b2247f86950e54510ee6d79399816341b', 'config': 'a77c698197c31308211b854e81a998178941f87d', 'pipeline': 'aaf976c7c663a31fa039582d42f9e07101556a7c'}, 'duration': 2.589430093765259, 'iteration': 4, 'loss': 0.2544808950572157, 'max_history_score': 0.7455191049427843, 'max_history_score_std': 0.04843448308166839, 'max_history_step': 'joint', 'pipeline': {'features': ('features_NoneType', {}), 'normalizer': ('normalizer_PowerTransformer', {}), 'rebalance': ('rebalance_NoneType', {})}, 'score': 0.7455191049427843, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': None, 'max_features': 2, 'max_leaf_nodes': 5, 'min_samples_split': 5, 'n_estimators': 25}, 'config_hash': {'algorithm': 'fd8aeb6a05eaaba41e676d60596c8e0c71b35e0c', 'config': '1fc13606bca3aaf342ca6ea21139cb598b56f8db', 'pipeline': 'f00bd8de05642e026bbba4ad20d3a60088c86b6c'}, 'duration': 1.8779079914093018, 'iteration': 5, 'loss': 0.531551018758381, 'max_history_score': 0.7455191049427843, 'max_history_score_std': 0.04843448308166839, 'max_history_step': 'joint', 'pipeline': {'features': ('features_PCA', {'features__n_components': 2}), 'normalizer': ('normalizer_MinMaxScaler', {}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 5})}, 'score': 0.46844898124161904, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'entropy', 'max_depth': None, 'max_features': 2, 'max_leaf_nodes': None, 'min_samples_split': 2, 'n_estimators': 10}, 'config_hash': {'algorithm': 'a49ecb99e74217d6812f98ead7bc9d1fe4a53ba0', 'config': '6749af1a67b4dbcd2b4719e419d99908063c05e1', 'pipeline': '19bdf19a2eec5febce95ab8fa2a71040d75114aa'}, 'duration': 1.5498578548431396, 'iteration': 6, 'loss': 0.14471329609998995, 'max_history_score': 0.85528670390001, 'max_history_score_std': 0.02213730791268438, 'max_history_step': 'joint', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 4, 'features__selectkbest__k': 3}), 'normalizer': ('normalizer_NoneType', {}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 7})}, 'score': 0.85528670390001, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': 1, 'max_features': 3, 'max_leaf_nodes': 3, 'min_samples_split': 3, 'n_estimators': 75}, 'config_hash': {'algorithm': 'ebfb16234172ae811ff21185ff92bbdbb8f32f14', 'config': 'd92d4ada2394fc132733e176e926ee53acdc6a00', 'pipeline': '8071e7cbf86a5c3056493dc3aa40063aeb28cdfe'}, 'duration': 1.3618149757385254, 'iteration': 7, 'loss': 0.6158612049395463, 'max_history_score': 0.85528670390001, 'max_history_score_std': 0.02213730791268438, 'max_history_step': 'joint', 'pipeline': {'features': ('features_SelectKBest', {'features__k': 4}), 'normalizer': ('normalizer_StandardScaler', {'normalizer__with_mean': True, 'normalizer__with_std': True}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 5})}, 'score': 0.3841387950604537, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'entropy', 'max_depth': 1, 'max_features': 1, 'max_leaf_nodes': 5, 'min_samples_split': 2, 'n_estimators': 100}, 'config_hash': {'algorithm': '896b53c75a2db568fb7b6da3bfca2f7a1535a11b', 'config': 'f0d0b1d2cedc22ae15d9a208a3fc3fc133bf0d3d', 'pipeline': 'c9761c9a33bf75d6dcad0742c421548a7655ccc9'}, 'duration': 2.297278881072998, 'iteration': 8, 'loss': 0.40673663548410355, 'max_history_score': 0.85528670390001, 'max_history_score_std': 0.02213730791268438, 'max_history_step': 'joint', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 2, 'features__selectkbest__k': 4}), 'normalizer': ('normalizer_StandardScaler', {'normalizer__with_mean': False, 'normalizer__with_std': False}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 5})}, 'score': 0.5932633645158965, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'entropy', 'max_depth': 2, 'max_features': None, 'max_leaf_nodes': None, 'min_samples_split': 5, 'n_estimators': 25}, 'config_hash': {'algorithm': '0b0e954757c4f75343a6efb740ad93260ed781ae', 'config': '47584de0e60d0d12c7dbbf0dc60e5aea96e3f4b2', 'pipeline': 'b37ee32d59413053bf9a2a72c8ff7135f3701e05'}, 'duration': 0.7249000072479248, 'iteration': 9, 'loss': 0.6965910020393421, 'max_history_score': 0.85528670390001, 'max_history_score_std': 0.02213730791268438, 'max_history_step': 'joint', 'pipeline': {'features': ('features_SelectKBest', {'features__k': 3}), 'normalizer': ('normalizer_NoneType', {}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 7})}, 'score': 0.3034089979606579, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'gini', 'max_depth': 2, 'max_features': 2, 'max_leaf_nodes': 5, 'min_samples_split': 5, 'n_estimators': 75}, 'config_hash': {'algorithm': 'f1ead1d9e33ea927e1dd27d872a058fa3de4f832', 'config': 'eecb88ee2b1b95d741c1b5c7751534d31aae6a77', 'pipeline': '6746650871e8b61efc9302b092dc05f7cdb179d5'}, 'duration': 5.340634822845459, 'iteration': 10, 'loss': 0.7687016290977936, 'max_history_score': 0.85528670390001, 'max_history_score_std': 0.02213730791268438, 'max_history_step': 'joint', 'pipeline': {'features': ('features_SelectKBest', {'features__k': 3}), 'normalizer': ('normalizer_RobustScaler', {'normalizer__quantile_range': (...), 'normalizer__with_centering': False, 'normalizer__with_scaling': False}), 'rebalance': ('rebalance_CondensedNearestNeighbour', {'rebalance__n_neighbors': 1})}, 'score': 0.23129837090220637, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': 1, 'max_features': 2, 'max_leaf_nodes': 2, 'min_samples_split': 3, 'n_estimators': 75}, 'config_hash': {'algorithm': '531a3bb8ccf0baa06727af4b3de9e62d25e6eabf', 'config': '27a7ed0502b321ab7256b77c8ce79e90cb9da815', 'pipeline': '77e6d84e2217b92b3cf67cc6defef9dd3554cec0'}, 'duration': 1.775357961654663, 'iteration': 11, 'loss': 0.6313818737375694, 'max_history_score': 0.85528670390001, 'max_history_score_std': 0.02213730791268438, 'max_history_step': 'joint', 'pipeline': {'features': ('features_SelectKBest', {'features__k': 4}), 'normalizer': ('normalizer_MinMaxScaler', {}), 'rebalance': ('rebalance_NearMiss', {'rebalance__n_neighbors': 3})}, 'score': 0.3686181262624307, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'entropy', 'max_depth': 4, 'max_features': 3, 'max_leaf_nodes': 2, 'min_samples_split': 3, 'n_estimators': 10}, 'config_hash': {'algorithm': '93518f8ded6074d537900b26be72f8485782f933', 'config': '45f056102dd2d644bd8befa471f17b2311ac7954', 'pipeline': '5240329df25c9a533d025c1a401d49835a501b41'}, 'duration': 3.2622711658477783, 'iteration': 12, 'loss': 0.6120243191353301, 'max_history_score': 0.85528670390001, 'max_history_score_std': 0.02213730791268438, 'max_history_step': 'joint', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 4, 'features__selectkbest__k': 2}), 'normalizer': ('normalizer_PowerTransformer', {}), 'rebalance': ('rebalance_NearMiss', {'rebalance__n_neighbors': 1})}, 'score': 0.38797568086467, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'entropy', 'max_depth': None, 'max_features': 1, 'max_leaf_nodes': 5, 'min_samples_split': 3, 'n_estimators': 75}, 'config_hash': {'algorithm': 'e515d45b764fa43591032874a0ff9c25bf12fddd', 'config': 'ba108323623936872824ed8f1c41d615d25523b3', 'pipeline': '9d823bc0442f21b5ce8af67a5eb1237f64ffc2f8'}, 'duration': 2.5326571464538574, 'iteration': 13, 'loss': 0.6271427382991047, 'max_history_score': 0.85528670390001, 'max_history_score_std': 0.02213730791268438, 'max_history_step': 'joint', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 1, 'features__selectkbest__k': 1}), 'normalizer': ('normalizer_StandardScaler', {'normalizer__with_mean': True, 'normalizer__with_std': True}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 5})}, 'score': 0.3728572617008953, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'entropy', 'max_depth': 3, 'max_features': 2, 'max_leaf_nodes': 2, 'min_samples_split': 3, 'n_estimators': 25}, 'config_hash': {'algorithm': '2808e67f609eba5c8a97f81ac0c9413cd37cf7aa', 'config': 'dde4d3b5f37741629cb58bfc4051ed9f98c8f311', 'pipeline': 'bc52deabf1f5ee60968ba541d9d2574353c30a9c'}, 'duration': 0.7145559787750244, 'iteration': 14, 'loss': 0.6831045572696203, 'max_history_score': 0.85528670390001, 'max_history_score_std': 0.02213730791268438, 'max_history_step': 'joint', 'pipeline': {'features': ('features_SelectKBest', {'features__k': 3}), 'normalizer': ('normalizer_MinMaxScaler', {}), 'rebalance': ('rebalance_NearMiss', {'rebalance__n_neighbors': 1})}, 'score': 0.31689544273037973, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'gini', 'max_depth': 2, 'max_features': 2, 'max_leaf_nodes': None, 'min_samples_split': 5, 'n_estimators': 100}, 'config_hash': {'algorithm': 'b942acdead762d34afeb474bc2fe6f7fd0f23493', 'config': '1080c25b92da3f15a6f8eec003957f7e0a66324f', 'pipeline': 'cfa84fe703dc5bc0bbd2257a6d524fee2693b804'}, 'duration': 2.812459945678711, 'iteration': 15, 'loss': 0.6921421091202761, 'max_history_score': 0.85528670390001, 'max_history_score_std': 0.02213730791268438, 'max_history_step': 'joint', 'pipeline': {'features': ('features_SelectKBest', {'features__k': 2}), 'normalizer': ('normalizer_PowerTransformer', {}), 'rebalance': ('rebalance_NoneType', {})}, 'score': 0.3078578908797239, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'entropy', 'max_depth': 2, 'max_features': 3, 'max_leaf_nodes': 3, 'min_samples_split': 2, 'n_estimators': 75}, 'config_hash': {'algorithm': '250661ce4193a61ef44d2f77694b52b785ff032d', 'config': 'c3e8cf4eca5aafcae4ac31b0449e105ca127ffe2', 'pipeline': 'c4dd111513ea35f97dd3aec3e8e7f6268ce035da'}, 'duration': 1.0555319786071777, 'iteration': 16, 'loss': 1.0, 'max_history_score': 0.85528670390001, 'max_history_score_std': 0.02213730791268438, 'max_history_step': 'joint', 'pipeline': {'features': ('features_PCA', {'features__n_components': 2}), 'normalizer': ('normalizer_RobustScaler', {'normalizer__quantile_range': (...), 'normalizer__with_centering': False, 'normalizer__with_scaling': True}), 'rebalance': ('rebalance_NearMiss', {'rebalance__n_neighbors': 2})}, 'score': 0.0, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'entropy', 'max_depth': 3, 'max_features': 3, 'max_leaf_nodes': None, 'min_samples_split': 3, 'n_estimators': 25}, 'config_hash': {'algorithm': '05ac02bd045c65dc4089894902ad6253661a2692', 'config': '3449b4a1c2e488e26a7195ee9edca19b854ebd33', 'pipeline': '505d3f71b534917375d765e64b0611e7dfb83746'}, 'duration': 5.5412821769714355, 'iteration': 17, 'loss': 0.7289151155121668, 'max_history_score': 0.85528670390001, 'max_history_score_std': 0.02213730791268438, 'max_history_step': 'joint', 'pipeline': {'features': ('features_SelectKBest', {'features__k': 4}), 'normalizer': ('normalizer_MinMaxScaler', {}), 'rebalance': ('rebalance_CondensedNearestNeighbour', {'rebalance__n_neighbors': 2})}, 'score': 0.2710848844878332, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'entropy', 'max_depth': 2, 'max_features': None, 'max_leaf_nodes': None, 'min_samples_split': 2, 'n_estimators': 25}, 'config_hash': {'algorithm': 'de3b3a352ebb260e16c6b213a08c9144d17a744b', 'config': '224987ffdbbb9b6182cff18d8374518b917e4f2e', 'pipeline': '12c89200a558b2f3b91332566f41050143aecbe7'}, 'duration': 2.4646048545837402, 'iteration': 18, 'loss': 0.6545902512995826, 'max_history_score': 0.85528670390001, 'max_history_score_std': 0.02213730791268438, 'max_history_step': 'joint', 'pipeline': {'features': ('features_NoneType', {}), 'normalizer': ('normalizer_PowerTransformer', {}), 'rebalance': ('rebalance_NearMiss', {'rebalance__n_neighbors': 2})}, 'score': 0.3454097487004174, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'gini', 'max_depth': None, 'max_features': 1, 'max_leaf_nodes': None, 'min_samples_split': 3, 'n_estimators': 100}, 'config_hash': {'algorithm': '30ca111584767bbf0464df40b4c928cf7ddf9459', 'config': '97ca7d6a017c721084dec2a5d2e5a67e1e6ae2f0', 'pipeline': '789eca82ea4a42d61927670c538867b745fd81d3'}, 'duration': 7.164499044418335, 'iteration': 19, 'loss': 0.6536825403350528, 'max_history_score': 0.85528670390001, 'max_history_score_std': 0.02213730791268438, 'max_history_step': 'joint', 'pipeline': {'features': ('features_SelectKBest', {'features__k': 3}), 'normalizer': ('normalizer_RobustScaler', {'normalizer__quantile_range': (...), 'normalizer__with_centering': False, 'normalizer__with_scaling': True}), 'rebalance': ('rebalance_CondensedNearestNeighbour', {'rebalance__n_neighbors': 3})}, 'score': 0.3463174596649472, ...}, ...], 'history_hash': ['fd24b065dda6bdeb1077793f9df480ff318c7a37', 'fb22f80fb4358ae1ee4c9bd4a83543992be8d806', '8c97cdb885dd05cfd8c40ee3ac445b61e5c767a8', '16fbb5fd5cfbbacfddf27c61c0c7397a7f6d8ade', 'a77c698197c31308211b854e81a998178941f87d', '1fc13606bca3aaf342ca6ea21139cb598b56f8db', '6749af1a67b4dbcd2b4719e419d99908063c05e1', 'd92d4ada2394fc132733e176e926ee53acdc6a00', 'f0d0b1d2cedc22ae15d9a208a3fc3fc133bf0d3d', '47584de0e60d0d12c7dbbf0dc60e5aea96e3f4b2', 'eecb88ee2b1b95d741c1b5c7751534d31aae6a77', '27a7ed0502b321ab7256b77c8ce79e90cb9da815', '45f056102dd2d644bd8befa471f17b2311ac7954', 'ba108323623936872824ed8f1c41d615d25523b3', 'dde4d3b5f37741629cb58bfc4051ed9f98c8f311', '1080c25b92da3f15a6f8eec003957f7e0a66324f', 'c3e8cf4eca5aafcae4ac31b0449e105ca127ffe2', '3449b4a1c2e488e26a7195ee9edca19b854ebd33', '224987ffdbbb9b6182cff18d8374518b917e4f2e', '97ca7d6a017c721084dec2a5d2e5a67e1e6ae2f0', ...], 'history_index': {'01b68ec8d6fe15ffdadf1adfd0d809307d3ce41e': 81, '05465becb12810ce291074be22a0275a42efbea8': 52, '064f53edf4748bb2df4ff59f147331aad21219e1': 48, '087efef4a19f272562d2d445dac0edd8096ba2fa': 58, '0fd4d71ca3a89c7d14af5087f2a2e2c1b1975351': 51, '1080c25b92da3f15a6f8eec003957f7e0a66324f': 15, '10ca1ab51b6af0696dab2c8cbaf8de5e3812a6de': 78, '10cb7f1ca9feb52539f61b654f31107801dadc1c': 89, '143679b59e16961765e77616142572b6ded0ee72': 62, '151b4a15037767108da13dafa0b63ae93222e93a': 53, ...}, 'iteration': 94, 'max_history_score': 0.9231904384036744, 'max_history_score_std': 0.03040515884196498, 'max_history_step': 'joint'}, config={'algorithm': 'RandomForest', 'seed': 42, 'time': 300})
    108 
    109 def objective_algo(algo_config, current_pipeline_config, algorithm, X, y, context, config):
    110     return objective(current_pipeline_config, algo_config, algorithm, X, y, context, config, step='algorithm')
    111 
    112 def objective_joint(wconfig, algorithm, X, y, context, config):
--> 113     return objective(wconfig['pipeline'], wconfig['algorithm'], algorithm, X, y, context, config, step='joint')
        wconfig = {'algorithm': {'bootstrap': False, 'criterion': 'entropy', 'max_depth': 3, 'max_features': 2, 'max_leaf_nodes': None, 'min_samples_split': 2, 'n_estimators': 100}, 'pipeline': {'features': ('features_SelectKBest', {'features__k': 1}), 'normalizer': ('normalizer_RobustScaler', {'normalizer__quantile_range': (25.0, 75.0), 'normalizer__with_centering': False, 'normalizer__with_scaling': False}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 5})}}
        algorithm = 'RandomForest'
        X = array([[ 0.,  0.,  5., ...,  0.,  0.,  0.],
    ...0.],
       [ 0.,  0., 10., ..., 12.,  1.,  0.]])
        y = array([0, 1, 2, ..., 8, 9, 8])
        context = {'baseline_score': 0.9272021217853512, 'baseline_score_std': 0.026919033284817703, 'best_config': {'algorithm': {'bootstrap': True, 'criterion': 'entropy', 'max_depth': None, 'max_features': None, 'max_leaf_nodes': None, 'min_samples_split': 3, 'n_estimators': 75}, 'config_hash': {'algorithm': 'f42e45bee34ac9973699212f6c8b845daea9383a', 'config': 'ae61cfde4c8b4c792e42d6b6be4af4ffb3d90e13', 'pipeline': '15ff3d6270ac899763bb3f72417c48bcd56aa7d8'}, 'duration': 8.20555305480957, 'iteration': 65, 'loss': 0.07680956159632557, 'max_history_score': 0.9231904384036744, 'max_history_score_std': 0.03040515884196498, 'max_history_step': 'joint', 'pipeline': {'features': ('features_NoneType', {}), 'normalizer': ('normalizer_StandardScaler', {'normalizer__with_mean': True, 'normalizer__with_std': True}), 'rebalance': ('rebalance_NearMiss', {'rebalance__n_neighbors': 1})}, 'score': 0.9231904384036744, ...}, 'history': [{'algorithm': {'bootstrap': False, 'criterion': 'entropy', 'max_depth': 1, 'max_features': 3, 'max_leaf_nodes': 3, 'min_samples_split': 5, 'n_estimators': 50}, 'config_hash': {'algorithm': '752fa095cdab58a238ae606c613606188964cc0c', 'config': 'fd24b065dda6bdeb1077793f9df480ff318c7a37', 'pipeline': '13ea3359c453b8993fcec1e88bc0e19cd0a2b112'}, 'duration': 0.689669132232666, 'iteration': 0, 'loss': 0.6602879519109309, 'max_history_score': 0.3397120480890691, 'max_history_score_std': 0.03346542949100545, 'max_history_step': 'joint', 'pipeline': {'features': ('features_SelectKBest', {'features__k': 4}), 'normalizer': ('normalizer_MinMaxScaler', {}), 'rebalance': ('rebalance_NoneType', {})}, 'score': 0.3397120480890691, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'gini', 'max_depth': 4, 'max_features': 1, 'max_leaf_nodes': 5, 'min_samples_split': 3, 'n_estimators': 25}, 'config_hash': {'algorithm': '9d9de4aee820052ddfe83bfffca420f6b50837d3', 'config': 'fb22f80fb4358ae1ee4c9bd4a83543992be8d806', 'pipeline': '6251ad4bb7a110726a67f90c319f4717ac37a312'}, 'duration': 1.4300940036773682, 'iteration': 1, 'loss': 0.5122196101741096, 'max_history_score': 0.48778038982589045, 'max_history_score_std': 0.05486079759217226, 'max_history_step': 'joint', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 2, 'features__selectkbest__k': 2}), 'normalizer': ('normalizer_StandardScaler', {'normalizer__with_mean': True, 'normalizer__with_std': True}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 5})}, 'score': 0.48778038982589045, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': 4, 'max_features': 1, 'max_leaf_nodes': None, 'min_samples_split': 2, 'n_estimators': 10}, 'config_hash': {'algorithm': '2ed7d27df9a1b2d5e63da76f7cb309616c232022', 'config': '8c97cdb885dd05cfd8c40ee3ac445b61e5c767a8', 'pipeline': 'c0abb5e23a4739d3120740a9519fb36c43eb94d5'}, 'duration': 3.0036678314208984, 'iteration': 2, 'loss': 0.38319264175312906, 'max_history_score': 0.6168073582468709, 'max_history_score_std': 0.05286679173001824, 'max_history_step': 'joint', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 1, 'features__selectkbest__k': 4}), 'normalizer': ('normalizer_PowerTransformer', {}), 'rebalance': ('rebalance_NearMiss', {'rebalance__n_neighbors': 2})}, 'score': 0.6168073582468709, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'entropy', 'max_depth': None, 'max_features': None, 'max_leaf_nodes': 2, 'min_samples_split': 2, 'n_estimators': 100}, 'config_hash': {'algorithm': '17962655e3b76dfcd0843d1e5c2cb7a9db1c6a79', 'config': '16fbb5fd5cfbbacfddf27c61c0c7397a7f6d8ade', 'pipeline': '13ea3359c453b8993fcec1e88bc0e19cd0a2b112'}, 'duration': 1.3447980880737305, 'iteration': 3, 'loss': 0.6768840987778313, 'max_history_score': 0.6168073582468709, 'max_history_score_std': 0.05286679173001824, 'max_history_step': 'joint', 'pipeline': {'features': ('features_SelectKBest', {'features__k': 4}), 'normalizer': ('normalizer_MinMaxScaler', {}), 'rebalance': ('rebalance_NoneType', {})}, 'score': 0.32311590122216866, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'gini', 'max_depth': 2, 'max_features': 2, 'max_leaf_nodes': 2, 'min_samples_split': 3, 'n_estimators': 100}, 'config_hash': {'algorithm': '1ea8965b2247f86950e54510ee6d79399816341b', 'config': 'a77c698197c31308211b854e81a998178941f87d', 'pipeline': 'aaf976c7c663a31fa039582d42f9e07101556a7c'}, 'duration': 2.589430093765259, 'iteration': 4, 'loss': 0.2544808950572157, 'max_history_score': 0.7455191049427843, 'max_history_score_std': 0.04843448308166839, 'max_history_step': 'joint', 'pipeline': {'features': ('features_NoneType', {}), 'normalizer': ('normalizer_PowerTransformer', {}), 'rebalance': ('rebalance_NoneType', {})}, 'score': 0.7455191049427843, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': None, 'max_features': 2, 'max_leaf_nodes': 5, 'min_samples_split': 5, 'n_estimators': 25}, 'config_hash': {'algorithm': 'fd8aeb6a05eaaba41e676d60596c8e0c71b35e0c', 'config': '1fc13606bca3aaf342ca6ea21139cb598b56f8db', 'pipeline': 'f00bd8de05642e026bbba4ad20d3a60088c86b6c'}, 'duration': 1.8779079914093018, 'iteration': 5, 'loss': 0.531551018758381, 'max_history_score': 0.7455191049427843, 'max_history_score_std': 0.04843448308166839, 'max_history_step': 'joint', 'pipeline': {'features': ('features_PCA', {'features__n_components': 2}), 'normalizer': ('normalizer_MinMaxScaler', {}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 5})}, 'score': 0.46844898124161904, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'entropy', 'max_depth': None, 'max_features': 2, 'max_leaf_nodes': None, 'min_samples_split': 2, 'n_estimators': 10}, 'config_hash': {'algorithm': 'a49ecb99e74217d6812f98ead7bc9d1fe4a53ba0', 'config': '6749af1a67b4dbcd2b4719e419d99908063c05e1', 'pipeline': '19bdf19a2eec5febce95ab8fa2a71040d75114aa'}, 'duration': 1.5498578548431396, 'iteration': 6, 'loss': 0.14471329609998995, 'max_history_score': 0.85528670390001, 'max_history_score_std': 0.02213730791268438, 'max_history_step': 'joint', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 4, 'features__selectkbest__k': 3}), 'normalizer': ('normalizer_NoneType', {}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 7})}, 'score': 0.85528670390001, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': 1, 'max_features': 3, 'max_leaf_nodes': 3, 'min_samples_split': 3, 'n_estimators': 75}, 'config_hash': {'algorithm': 'ebfb16234172ae811ff21185ff92bbdbb8f32f14', 'config': 'd92d4ada2394fc132733e176e926ee53acdc6a00', 'pipeline': '8071e7cbf86a5c3056493dc3aa40063aeb28cdfe'}, 'duration': 1.3618149757385254, 'iteration': 7, 'loss': 0.6158612049395463, 'max_history_score': 0.85528670390001, 'max_history_score_std': 0.02213730791268438, 'max_history_step': 'joint', 'pipeline': {'features': ('features_SelectKBest', {'features__k': 4}), 'normalizer': ('normalizer_StandardScaler', {'normalizer__with_mean': True, 'normalizer__with_std': True}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 5})}, 'score': 0.3841387950604537, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'entropy', 'max_depth': 1, 'max_features': 1, 'max_leaf_nodes': 5, 'min_samples_split': 2, 'n_estimators': 100}, 'config_hash': {'algorithm': '896b53c75a2db568fb7b6da3bfca2f7a1535a11b', 'config': 'f0d0b1d2cedc22ae15d9a208a3fc3fc133bf0d3d', 'pipeline': 'c9761c9a33bf75d6dcad0742c421548a7655ccc9'}, 'duration': 2.297278881072998, 'iteration': 8, 'loss': 0.40673663548410355, 'max_history_score': 0.85528670390001, 'max_history_score_std': 0.02213730791268438, 'max_history_step': 'joint', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 2, 'features__selectkbest__k': 4}), 'normalizer': ('normalizer_StandardScaler', {'normalizer__with_mean': False, 'normalizer__with_std': False}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 5})}, 'score': 0.5932633645158965, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'entropy', 'max_depth': 2, 'max_features': None, 'max_leaf_nodes': None, 'min_samples_split': 5, 'n_estimators': 25}, 'config_hash': {'algorithm': '0b0e954757c4f75343a6efb740ad93260ed781ae', 'config': '47584de0e60d0d12c7dbbf0dc60e5aea96e3f4b2', 'pipeline': 'b37ee32d59413053bf9a2a72c8ff7135f3701e05'}, 'duration': 0.7249000072479248, 'iteration': 9, 'loss': 0.6965910020393421, 'max_history_score': 0.85528670390001, 'max_history_score_std': 0.02213730791268438, 'max_history_step': 'joint', 'pipeline': {'features': ('features_SelectKBest', {'features__k': 3}), 'normalizer': ('normalizer_NoneType', {}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 7})}, 'score': 0.3034089979606579, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'gini', 'max_depth': 2, 'max_features': 2, 'max_leaf_nodes': 5, 'min_samples_split': 5, 'n_estimators': 75}, 'config_hash': {'algorithm': 'f1ead1d9e33ea927e1dd27d872a058fa3de4f832', 'config': 'eecb88ee2b1b95d741c1b5c7751534d31aae6a77', 'pipeline': '6746650871e8b61efc9302b092dc05f7cdb179d5'}, 'duration': 5.340634822845459, 'iteration': 10, 'loss': 0.7687016290977936, 'max_history_score': 0.85528670390001, 'max_history_score_std': 0.02213730791268438, 'max_history_step': 'joint', 'pipeline': {'features': ('features_SelectKBest', {'features__k': 3}), 'normalizer': ('normalizer_RobustScaler', {'normalizer__quantile_range': (...), 'normalizer__with_centering': False, 'normalizer__with_scaling': False}), 'rebalance': ('rebalance_CondensedNearestNeighbour', {'rebalance__n_neighbors': 1})}, 'score': 0.23129837090220637, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': 1, 'max_features': 2, 'max_leaf_nodes': 2, 'min_samples_split': 3, 'n_estimators': 75}, 'config_hash': {'algorithm': '531a3bb8ccf0baa06727af4b3de9e62d25e6eabf', 'config': '27a7ed0502b321ab7256b77c8ce79e90cb9da815', 'pipeline': '77e6d84e2217b92b3cf67cc6defef9dd3554cec0'}, 'duration': 1.775357961654663, 'iteration': 11, 'loss': 0.6313818737375694, 'max_history_score': 0.85528670390001, 'max_history_score_std': 0.02213730791268438, 'max_history_step': 'joint', 'pipeline': {'features': ('features_SelectKBest', {'features__k': 4}), 'normalizer': ('normalizer_MinMaxScaler', {}), 'rebalance': ('rebalance_NearMiss', {'rebalance__n_neighbors': 3})}, 'score': 0.3686181262624307, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'entropy', 'max_depth': 4, 'max_features': 3, 'max_leaf_nodes': 2, 'min_samples_split': 3, 'n_estimators': 10}, 'config_hash': {'algorithm': '93518f8ded6074d537900b26be72f8485782f933', 'config': '45f056102dd2d644bd8befa471f17b2311ac7954', 'pipeline': '5240329df25c9a533d025c1a401d49835a501b41'}, 'duration': 3.2622711658477783, 'iteration': 12, 'loss': 0.6120243191353301, 'max_history_score': 0.85528670390001, 'max_history_score_std': 0.02213730791268438, 'max_history_step': 'joint', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 4, 'features__selectkbest__k': 2}), 'normalizer': ('normalizer_PowerTransformer', {}), 'rebalance': ('rebalance_NearMiss', {'rebalance__n_neighbors': 1})}, 'score': 0.38797568086467, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'entropy', 'max_depth': None, 'max_features': 1, 'max_leaf_nodes': 5, 'min_samples_split': 3, 'n_estimators': 75}, 'config_hash': {'algorithm': 'e515d45b764fa43591032874a0ff9c25bf12fddd', 'config': 'ba108323623936872824ed8f1c41d615d25523b3', 'pipeline': '9d823bc0442f21b5ce8af67a5eb1237f64ffc2f8'}, 'duration': 2.5326571464538574, 'iteration': 13, 'loss': 0.6271427382991047, 'max_history_score': 0.85528670390001, 'max_history_score_std': 0.02213730791268438, 'max_history_step': 'joint', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 1, 'features__selectkbest__k': 1}), 'normalizer': ('normalizer_StandardScaler', {'normalizer__with_mean': True, 'normalizer__with_std': True}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 5})}, 'score': 0.3728572617008953, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'entropy', 'max_depth': 3, 'max_features': 2, 'max_leaf_nodes': 2, 'min_samples_split': 3, 'n_estimators': 25}, 'config_hash': {'algorithm': '2808e67f609eba5c8a97f81ac0c9413cd37cf7aa', 'config': 'dde4d3b5f37741629cb58bfc4051ed9f98c8f311', 'pipeline': 'bc52deabf1f5ee60968ba541d9d2574353c30a9c'}, 'duration': 0.7145559787750244, 'iteration': 14, 'loss': 0.6831045572696203, 'max_history_score': 0.85528670390001, 'max_history_score_std': 0.02213730791268438, 'max_history_step': 'joint', 'pipeline': {'features': ('features_SelectKBest', {'features__k': 3}), 'normalizer': ('normalizer_MinMaxScaler', {}), 'rebalance': ('rebalance_NearMiss', {'rebalance__n_neighbors': 1})}, 'score': 0.31689544273037973, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'gini', 'max_depth': 2, 'max_features': 2, 'max_leaf_nodes': None, 'min_samples_split': 5, 'n_estimators': 100}, 'config_hash': {'algorithm': 'b942acdead762d34afeb474bc2fe6f7fd0f23493', 'config': '1080c25b92da3f15a6f8eec003957f7e0a66324f', 'pipeline': 'cfa84fe703dc5bc0bbd2257a6d524fee2693b804'}, 'duration': 2.812459945678711, 'iteration': 15, 'loss': 0.6921421091202761, 'max_history_score': 0.85528670390001, 'max_history_score_std': 0.02213730791268438, 'max_history_step': 'joint', 'pipeline': {'features': ('features_SelectKBest', {'features__k': 2}), 'normalizer': ('normalizer_PowerTransformer', {}), 'rebalance': ('rebalance_NoneType', {})}, 'score': 0.3078578908797239, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'entropy', 'max_depth': 2, 'max_features': 3, 'max_leaf_nodes': 3, 'min_samples_split': 2, 'n_estimators': 75}, 'config_hash': {'algorithm': '250661ce4193a61ef44d2f77694b52b785ff032d', 'config': 'c3e8cf4eca5aafcae4ac31b0449e105ca127ffe2', 'pipeline': 'c4dd111513ea35f97dd3aec3e8e7f6268ce035da'}, 'duration': 1.0555319786071777, 'iteration': 16, 'loss': 1.0, 'max_history_score': 0.85528670390001, 'max_history_score_std': 0.02213730791268438, 'max_history_step': 'joint', 'pipeline': {'features': ('features_PCA', {'features__n_components': 2}), 'normalizer': ('normalizer_RobustScaler', {'normalizer__quantile_range': (...), 'normalizer__with_centering': False, 'normalizer__with_scaling': True}), 'rebalance': ('rebalance_NearMiss', {'rebalance__n_neighbors': 2})}, 'score': 0.0, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'entropy', 'max_depth': 3, 'max_features': 3, 'max_leaf_nodes': None, 'min_samples_split': 3, 'n_estimators': 25}, 'config_hash': {'algorithm': '05ac02bd045c65dc4089894902ad6253661a2692', 'config': '3449b4a1c2e488e26a7195ee9edca19b854ebd33', 'pipeline': '505d3f71b534917375d765e64b0611e7dfb83746'}, 'duration': 5.5412821769714355, 'iteration': 17, 'loss': 0.7289151155121668, 'max_history_score': 0.85528670390001, 'max_history_score_std': 0.02213730791268438, 'max_history_step': 'joint', 'pipeline': {'features': ('features_SelectKBest', {'features__k': 4}), 'normalizer': ('normalizer_MinMaxScaler', {}), 'rebalance': ('rebalance_CondensedNearestNeighbour', {'rebalance__n_neighbors': 2})}, 'score': 0.2710848844878332, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'entropy', 'max_depth': 2, 'max_features': None, 'max_leaf_nodes': None, 'min_samples_split': 2, 'n_estimators': 25}, 'config_hash': {'algorithm': 'de3b3a352ebb260e16c6b213a08c9144d17a744b', 'config': '224987ffdbbb9b6182cff18d8374518b917e4f2e', 'pipeline': '12c89200a558b2f3b91332566f41050143aecbe7'}, 'duration': 2.4646048545837402, 'iteration': 18, 'loss': 0.6545902512995826, 'max_history_score': 0.85528670390001, 'max_history_score_std': 0.02213730791268438, 'max_history_step': 'joint', 'pipeline': {'features': ('features_NoneType', {}), 'normalizer': ('normalizer_PowerTransformer', {}), 'rebalance': ('rebalance_NearMiss', {'rebalance__n_neighbors': 2})}, 'score': 0.3454097487004174, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'gini', 'max_depth': None, 'max_features': 1, 'max_leaf_nodes': None, 'min_samples_split': 3, 'n_estimators': 100}, 'config_hash': {'algorithm': '30ca111584767bbf0464df40b4c928cf7ddf9459', 'config': '97ca7d6a017c721084dec2a5d2e5a67e1e6ae2f0', 'pipeline': '789eca82ea4a42d61927670c538867b745fd81d3'}, 'duration': 7.164499044418335, 'iteration': 19, 'loss': 0.6536825403350528, 'max_history_score': 0.85528670390001, 'max_history_score_std': 0.02213730791268438, 'max_history_step': 'joint', 'pipeline': {'features': ('features_SelectKBest', {'features__k': 3}), 'normalizer': ('normalizer_RobustScaler', {'normalizer__quantile_range': (...), 'normalizer__with_centering': False, 'normalizer__with_scaling': True}), 'rebalance': ('rebalance_CondensedNearestNeighbour', {'rebalance__n_neighbors': 3})}, 'score': 0.3463174596649472, ...}, ...], 'history_hash': ['fd24b065dda6bdeb1077793f9df480ff318c7a37', 'fb22f80fb4358ae1ee4c9bd4a83543992be8d806', '8c97cdb885dd05cfd8c40ee3ac445b61e5c767a8', '16fbb5fd5cfbbacfddf27c61c0c7397a7f6d8ade', 'a77c698197c31308211b854e81a998178941f87d', '1fc13606bca3aaf342ca6ea21139cb598b56f8db', '6749af1a67b4dbcd2b4719e419d99908063c05e1', 'd92d4ada2394fc132733e176e926ee53acdc6a00', 'f0d0b1d2cedc22ae15d9a208a3fc3fc133bf0d3d', '47584de0e60d0d12c7dbbf0dc60e5aea96e3f4b2', 'eecb88ee2b1b95d741c1b5c7751534d31aae6a77', '27a7ed0502b321ab7256b77c8ce79e90cb9da815', '45f056102dd2d644bd8befa471f17b2311ac7954', 'ba108323623936872824ed8f1c41d615d25523b3', 'dde4d3b5f37741629cb58bfc4051ed9f98c8f311', '1080c25b92da3f15a6f8eec003957f7e0a66324f', 'c3e8cf4eca5aafcae4ac31b0449e105ca127ffe2', '3449b4a1c2e488e26a7195ee9edca19b854ebd33', '224987ffdbbb9b6182cff18d8374518b917e4f2e', '97ca7d6a017c721084dec2a5d2e5a67e1e6ae2f0', ...], 'history_index': {'01b68ec8d6fe15ffdadf1adfd0d809307d3ce41e': 81, '05465becb12810ce291074be22a0275a42efbea8': 52, '064f53edf4748bb2df4ff59f147331aad21219e1': 48, '087efef4a19f272562d2d445dac0edd8096ba2fa': 58, '0fd4d71ca3a89c7d14af5087f2a2e2c1b1975351': 51, '1080c25b92da3f15a6f8eec003957f7e0a66324f': 15, '10ca1ab51b6af0696dab2c8cbaf8de5e3812a6de': 78, '10cb7f1ca9feb52539f61b654f31107801dadc1c': 89, '143679b59e16961765e77616142572b6ded0ee72': 62, '151b4a15037767108da13dafa0b63ae93222e93a': 53, ...}, 'iteration': 94, 'max_history_score': 0.9231904384036744, 'max_history_score_std': 0.03040515884196498, 'max_history_step': 'joint'}
        config = {'algorithm': 'RandomForest', 'seed': 42, 'time': 300}
    114 
    115 
    116 def get_baseline_score(algorithm, X, y, seed):
    117     pipeline, _ = pipeline_conf_to_full_pipeline(

...........................................................................
/home/aquemy/dev/dp_hyperparameters/extension/experiment/objective.py in objective(pipeline_config={'features': ('features_SelectKBest', {'features__k': 1}), 'normalizer': ('normalizer_RobustScaler', {'normalizer__quantile_range': (25.0, 75.0), 'normalizer__with_centering': False, 'normalizer__with_scaling': False}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 5})}, algo_config={'bootstrap': False, 'criterion': 'entropy', 'max_depth': 3, 'max_features': 2, 'max_leaf_nodes': None, 'min_samples_split': 2, 'n_estimators': 100}, algorithm='RandomForest', X=array([[ 0.,  0.,  5., ...,  0.,  0.,  0.],
    ...0.],
       [ 0.,  0., 10., ..., 12.,  1.,  0.]]), y=array([0, 1, 2, ..., 8, 9, 8]), context={'baseline_score': 0.9272021217853512, 'baseline_score_std': 0.026919033284817703, 'best_config': {'algorithm': {'bootstrap': True, 'criterion': 'entropy', 'max_depth': None, 'max_features': None, 'max_leaf_nodes': None, 'min_samples_split': 3, 'n_estimators': 75}, 'config_hash': {'algorithm': 'f42e45bee34ac9973699212f6c8b845daea9383a', 'config': 'ae61cfde4c8b4c792e42d6b6be4af4ffb3d90e13', 'pipeline': '15ff3d6270ac899763bb3f72417c48bcd56aa7d8'}, 'duration': 8.20555305480957, 'iteration': 65, 'loss': 0.07680956159632557, 'max_history_score': 0.9231904384036744, 'max_history_score_std': 0.03040515884196498, 'max_history_step': 'joint', 'pipeline': {'features': ('features_NoneType', {}), 'normalizer': ('normalizer_StandardScaler', {'normalizer__with_mean': True, 'normalizer__with_std': True}), 'rebalance': ('rebalance_NearMiss', {'rebalance__n_neighbors': 1})}, 'score': 0.9231904384036744, ...}, 'history': [{'algorithm': {'bootstrap': False, 'criterion': 'entropy', 'max_depth': 1, 'max_features': 3, 'max_leaf_nodes': 3, 'min_samples_split': 5, 'n_estimators': 50}, 'config_hash': {'algorithm': '752fa095cdab58a238ae606c613606188964cc0c', 'config': 'fd24b065dda6bdeb1077793f9df480ff318c7a37', 'pipeline': '13ea3359c453b8993fcec1e88bc0e19cd0a2b112'}, 'duration': 0.689669132232666, 'iteration': 0, 'loss': 0.6602879519109309, 'max_history_score': 0.3397120480890691, 'max_history_score_std': 0.03346542949100545, 'max_history_step': 'joint', 'pipeline': {'features': ('features_SelectKBest', {'features__k': 4}), 'normalizer': ('normalizer_MinMaxScaler', {}), 'rebalance': ('rebalance_NoneType', {})}, 'score': 0.3397120480890691, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'gini', 'max_depth': 4, 'max_features': 1, 'max_leaf_nodes': 5, 'min_samples_split': 3, 'n_estimators': 25}, 'config_hash': {'algorithm': '9d9de4aee820052ddfe83bfffca420f6b50837d3', 'config': 'fb22f80fb4358ae1ee4c9bd4a83543992be8d806', 'pipeline': '6251ad4bb7a110726a67f90c319f4717ac37a312'}, 'duration': 1.4300940036773682, 'iteration': 1, 'loss': 0.5122196101741096, 'max_history_score': 0.48778038982589045, 'max_history_score_std': 0.05486079759217226, 'max_history_step': 'joint', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 2, 'features__selectkbest__k': 2}), 'normalizer': ('normalizer_StandardScaler', {'normalizer__with_mean': True, 'normalizer__with_std': True}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 5})}, 'score': 0.48778038982589045, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': 4, 'max_features': 1, 'max_leaf_nodes': None, 'min_samples_split': 2, 'n_estimators': 10}, 'config_hash': {'algorithm': '2ed7d27df9a1b2d5e63da76f7cb309616c232022', 'config': '8c97cdb885dd05cfd8c40ee3ac445b61e5c767a8', 'pipeline': 'c0abb5e23a4739d3120740a9519fb36c43eb94d5'}, 'duration': 3.0036678314208984, 'iteration': 2, 'loss': 0.38319264175312906, 'max_history_score': 0.6168073582468709, 'max_history_score_std': 0.05286679173001824, 'max_history_step': 'joint', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 1, 'features__selectkbest__k': 4}), 'normalizer': ('normalizer_PowerTransformer', {}), 'rebalance': ('rebalance_NearMiss', {'rebalance__n_neighbors': 2})}, 'score': 0.6168073582468709, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'entropy', 'max_depth': None, 'max_features': None, 'max_leaf_nodes': 2, 'min_samples_split': 2, 'n_estimators': 100}, 'config_hash': {'algorithm': '17962655e3b76dfcd0843d1e5c2cb7a9db1c6a79', 'config': '16fbb5fd5cfbbacfddf27c61c0c7397a7f6d8ade', 'pipeline': '13ea3359c453b8993fcec1e88bc0e19cd0a2b112'}, 'duration': 1.3447980880737305, 'iteration': 3, 'loss': 0.6768840987778313, 'max_history_score': 0.6168073582468709, 'max_history_score_std': 0.05286679173001824, 'max_history_step': 'joint', 'pipeline': {'features': ('features_SelectKBest', {'features__k': 4}), 'normalizer': ('normalizer_MinMaxScaler', {}), 'rebalance': ('rebalance_NoneType', {})}, 'score': 0.32311590122216866, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'gini', 'max_depth': 2, 'max_features': 2, 'max_leaf_nodes': 2, 'min_samples_split': 3, 'n_estimators': 100}, 'config_hash': {'algorithm': '1ea8965b2247f86950e54510ee6d79399816341b', 'config': 'a77c698197c31308211b854e81a998178941f87d', 'pipeline': 'aaf976c7c663a31fa039582d42f9e07101556a7c'}, 'duration': 2.589430093765259, 'iteration': 4, 'loss': 0.2544808950572157, 'max_history_score': 0.7455191049427843, 'max_history_score_std': 0.04843448308166839, 'max_history_step': 'joint', 'pipeline': {'features': ('features_NoneType', {}), 'normalizer': ('normalizer_PowerTransformer', {}), 'rebalance': ('rebalance_NoneType', {})}, 'score': 0.7455191049427843, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': None, 'max_features': 2, 'max_leaf_nodes': 5, 'min_samples_split': 5, 'n_estimators': 25}, 'config_hash': {'algorithm': 'fd8aeb6a05eaaba41e676d60596c8e0c71b35e0c', 'config': '1fc13606bca3aaf342ca6ea21139cb598b56f8db', 'pipeline': 'f00bd8de05642e026bbba4ad20d3a60088c86b6c'}, 'duration': 1.8779079914093018, 'iteration': 5, 'loss': 0.531551018758381, 'max_history_score': 0.7455191049427843, 'max_history_score_std': 0.04843448308166839, 'max_history_step': 'joint', 'pipeline': {'features': ('features_PCA', {'features__n_components': 2}), 'normalizer': ('normalizer_MinMaxScaler', {}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 5})}, 'score': 0.46844898124161904, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'entropy', 'max_depth': None, 'max_features': 2, 'max_leaf_nodes': None, 'min_samples_split': 2, 'n_estimators': 10}, 'config_hash': {'algorithm': 'a49ecb99e74217d6812f98ead7bc9d1fe4a53ba0', 'config': '6749af1a67b4dbcd2b4719e419d99908063c05e1', 'pipeline': '19bdf19a2eec5febce95ab8fa2a71040d75114aa'}, 'duration': 1.5498578548431396, 'iteration': 6, 'loss': 0.14471329609998995, 'max_history_score': 0.85528670390001, 'max_history_score_std': 0.02213730791268438, 'max_history_step': 'joint', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 4, 'features__selectkbest__k': 3}), 'normalizer': ('normalizer_NoneType', {}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 7})}, 'score': 0.85528670390001, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': 1, 'max_features': 3, 'max_leaf_nodes': 3, 'min_samples_split': 3, 'n_estimators': 75}, 'config_hash': {'algorithm': 'ebfb16234172ae811ff21185ff92bbdbb8f32f14', 'config': 'd92d4ada2394fc132733e176e926ee53acdc6a00', 'pipeline': '8071e7cbf86a5c3056493dc3aa40063aeb28cdfe'}, 'duration': 1.3618149757385254, 'iteration': 7, 'loss': 0.6158612049395463, 'max_history_score': 0.85528670390001, 'max_history_score_std': 0.02213730791268438, 'max_history_step': 'joint', 'pipeline': {'features': ('features_SelectKBest', {'features__k': 4}), 'normalizer': ('normalizer_StandardScaler', {'normalizer__with_mean': True, 'normalizer__with_std': True}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 5})}, 'score': 0.3841387950604537, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'entropy', 'max_depth': 1, 'max_features': 1, 'max_leaf_nodes': 5, 'min_samples_split': 2, 'n_estimators': 100}, 'config_hash': {'algorithm': '896b53c75a2db568fb7b6da3bfca2f7a1535a11b', 'config': 'f0d0b1d2cedc22ae15d9a208a3fc3fc133bf0d3d', 'pipeline': 'c9761c9a33bf75d6dcad0742c421548a7655ccc9'}, 'duration': 2.297278881072998, 'iteration': 8, 'loss': 0.40673663548410355, 'max_history_score': 0.85528670390001, 'max_history_score_std': 0.02213730791268438, 'max_history_step': 'joint', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 2, 'features__selectkbest__k': 4}), 'normalizer': ('normalizer_StandardScaler', {'normalizer__with_mean': False, 'normalizer__with_std': False}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 5})}, 'score': 0.5932633645158965, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'entropy', 'max_depth': 2, 'max_features': None, 'max_leaf_nodes': None, 'min_samples_split': 5, 'n_estimators': 25}, 'config_hash': {'algorithm': '0b0e954757c4f75343a6efb740ad93260ed781ae', 'config': '47584de0e60d0d12c7dbbf0dc60e5aea96e3f4b2', 'pipeline': 'b37ee32d59413053bf9a2a72c8ff7135f3701e05'}, 'duration': 0.7249000072479248, 'iteration': 9, 'loss': 0.6965910020393421, 'max_history_score': 0.85528670390001, 'max_history_score_std': 0.02213730791268438, 'max_history_step': 'joint', 'pipeline': {'features': ('features_SelectKBest', {'features__k': 3}), 'normalizer': ('normalizer_NoneType', {}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 7})}, 'score': 0.3034089979606579, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'gini', 'max_depth': 2, 'max_features': 2, 'max_leaf_nodes': 5, 'min_samples_split': 5, 'n_estimators': 75}, 'config_hash': {'algorithm': 'f1ead1d9e33ea927e1dd27d872a058fa3de4f832', 'config': 'eecb88ee2b1b95d741c1b5c7751534d31aae6a77', 'pipeline': '6746650871e8b61efc9302b092dc05f7cdb179d5'}, 'duration': 5.340634822845459, 'iteration': 10, 'loss': 0.7687016290977936, 'max_history_score': 0.85528670390001, 'max_history_score_std': 0.02213730791268438, 'max_history_step': 'joint', 'pipeline': {'features': ('features_SelectKBest', {'features__k': 3}), 'normalizer': ('normalizer_RobustScaler', {'normalizer__quantile_range': (...), 'normalizer__with_centering': False, 'normalizer__with_scaling': False}), 'rebalance': ('rebalance_CondensedNearestNeighbour', {'rebalance__n_neighbors': 1})}, 'score': 0.23129837090220637, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': 1, 'max_features': 2, 'max_leaf_nodes': 2, 'min_samples_split': 3, 'n_estimators': 75}, 'config_hash': {'algorithm': '531a3bb8ccf0baa06727af4b3de9e62d25e6eabf', 'config': '27a7ed0502b321ab7256b77c8ce79e90cb9da815', 'pipeline': '77e6d84e2217b92b3cf67cc6defef9dd3554cec0'}, 'duration': 1.775357961654663, 'iteration': 11, 'loss': 0.6313818737375694, 'max_history_score': 0.85528670390001, 'max_history_score_std': 0.02213730791268438, 'max_history_step': 'joint', 'pipeline': {'features': ('features_SelectKBest', {'features__k': 4}), 'normalizer': ('normalizer_MinMaxScaler', {}), 'rebalance': ('rebalance_NearMiss', {'rebalance__n_neighbors': 3})}, 'score': 0.3686181262624307, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'entropy', 'max_depth': 4, 'max_features': 3, 'max_leaf_nodes': 2, 'min_samples_split': 3, 'n_estimators': 10}, 'config_hash': {'algorithm': '93518f8ded6074d537900b26be72f8485782f933', 'config': '45f056102dd2d644bd8befa471f17b2311ac7954', 'pipeline': '5240329df25c9a533d025c1a401d49835a501b41'}, 'duration': 3.2622711658477783, 'iteration': 12, 'loss': 0.6120243191353301, 'max_history_score': 0.85528670390001, 'max_history_score_std': 0.02213730791268438, 'max_history_step': 'joint', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 4, 'features__selectkbest__k': 2}), 'normalizer': ('normalizer_PowerTransformer', {}), 'rebalance': ('rebalance_NearMiss', {'rebalance__n_neighbors': 1})}, 'score': 0.38797568086467, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'entropy', 'max_depth': None, 'max_features': 1, 'max_leaf_nodes': 5, 'min_samples_split': 3, 'n_estimators': 75}, 'config_hash': {'algorithm': 'e515d45b764fa43591032874a0ff9c25bf12fddd', 'config': 'ba108323623936872824ed8f1c41d615d25523b3', 'pipeline': '9d823bc0442f21b5ce8af67a5eb1237f64ffc2f8'}, 'duration': 2.5326571464538574, 'iteration': 13, 'loss': 0.6271427382991047, 'max_history_score': 0.85528670390001, 'max_history_score_std': 0.02213730791268438, 'max_history_step': 'joint', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 1, 'features__selectkbest__k': 1}), 'normalizer': ('normalizer_StandardScaler', {'normalizer__with_mean': True, 'normalizer__with_std': True}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 5})}, 'score': 0.3728572617008953, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'entropy', 'max_depth': 3, 'max_features': 2, 'max_leaf_nodes': 2, 'min_samples_split': 3, 'n_estimators': 25}, 'config_hash': {'algorithm': '2808e67f609eba5c8a97f81ac0c9413cd37cf7aa', 'config': 'dde4d3b5f37741629cb58bfc4051ed9f98c8f311', 'pipeline': 'bc52deabf1f5ee60968ba541d9d2574353c30a9c'}, 'duration': 0.7145559787750244, 'iteration': 14, 'loss': 0.6831045572696203, 'max_history_score': 0.85528670390001, 'max_history_score_std': 0.02213730791268438, 'max_history_step': 'joint', 'pipeline': {'features': ('features_SelectKBest', {'features__k': 3}), 'normalizer': ('normalizer_MinMaxScaler', {}), 'rebalance': ('rebalance_NearMiss', {'rebalance__n_neighbors': 1})}, 'score': 0.31689544273037973, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'gini', 'max_depth': 2, 'max_features': 2, 'max_leaf_nodes': None, 'min_samples_split': 5, 'n_estimators': 100}, 'config_hash': {'algorithm': 'b942acdead762d34afeb474bc2fe6f7fd0f23493', 'config': '1080c25b92da3f15a6f8eec003957f7e0a66324f', 'pipeline': 'cfa84fe703dc5bc0bbd2257a6d524fee2693b804'}, 'duration': 2.812459945678711, 'iteration': 15, 'loss': 0.6921421091202761, 'max_history_score': 0.85528670390001, 'max_history_score_std': 0.02213730791268438, 'max_history_step': 'joint', 'pipeline': {'features': ('features_SelectKBest', {'features__k': 2}), 'normalizer': ('normalizer_PowerTransformer', {}), 'rebalance': ('rebalance_NoneType', {})}, 'score': 0.3078578908797239, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'entropy', 'max_depth': 2, 'max_features': 3, 'max_leaf_nodes': 3, 'min_samples_split': 2, 'n_estimators': 75}, 'config_hash': {'algorithm': '250661ce4193a61ef44d2f77694b52b785ff032d', 'config': 'c3e8cf4eca5aafcae4ac31b0449e105ca127ffe2', 'pipeline': 'c4dd111513ea35f97dd3aec3e8e7f6268ce035da'}, 'duration': 1.0555319786071777, 'iteration': 16, 'loss': 1.0, 'max_history_score': 0.85528670390001, 'max_history_score_std': 0.02213730791268438, 'max_history_step': 'joint', 'pipeline': {'features': ('features_PCA', {'features__n_components': 2}), 'normalizer': ('normalizer_RobustScaler', {'normalizer__quantile_range': (...), 'normalizer__with_centering': False, 'normalizer__with_scaling': True}), 'rebalance': ('rebalance_NearMiss', {'rebalance__n_neighbors': 2})}, 'score': 0.0, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'entropy', 'max_depth': 3, 'max_features': 3, 'max_leaf_nodes': None, 'min_samples_split': 3, 'n_estimators': 25}, 'config_hash': {'algorithm': '05ac02bd045c65dc4089894902ad6253661a2692', 'config': '3449b4a1c2e488e26a7195ee9edca19b854ebd33', 'pipeline': '505d3f71b534917375d765e64b0611e7dfb83746'}, 'duration': 5.5412821769714355, 'iteration': 17, 'loss': 0.7289151155121668, 'max_history_score': 0.85528670390001, 'max_history_score_std': 0.02213730791268438, 'max_history_step': 'joint', 'pipeline': {'features': ('features_SelectKBest', {'features__k': 4}), 'normalizer': ('normalizer_MinMaxScaler', {}), 'rebalance': ('rebalance_CondensedNearestNeighbour', {'rebalance__n_neighbors': 2})}, 'score': 0.2710848844878332, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'entropy', 'max_depth': 2, 'max_features': None, 'max_leaf_nodes': None, 'min_samples_split': 2, 'n_estimators': 25}, 'config_hash': {'algorithm': 'de3b3a352ebb260e16c6b213a08c9144d17a744b', 'config': '224987ffdbbb9b6182cff18d8374518b917e4f2e', 'pipeline': '12c89200a558b2f3b91332566f41050143aecbe7'}, 'duration': 2.4646048545837402, 'iteration': 18, 'loss': 0.6545902512995826, 'max_history_score': 0.85528670390001, 'max_history_score_std': 0.02213730791268438, 'max_history_step': 'joint', 'pipeline': {'features': ('features_NoneType', {}), 'normalizer': ('normalizer_PowerTransformer', {}), 'rebalance': ('rebalance_NearMiss', {'rebalance__n_neighbors': 2})}, 'score': 0.3454097487004174, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'gini', 'max_depth': None, 'max_features': 1, 'max_leaf_nodes': None, 'min_samples_split': 3, 'n_estimators': 100}, 'config_hash': {'algorithm': '30ca111584767bbf0464df40b4c928cf7ddf9459', 'config': '97ca7d6a017c721084dec2a5d2e5a67e1e6ae2f0', 'pipeline': '789eca82ea4a42d61927670c538867b745fd81d3'}, 'duration': 7.164499044418335, 'iteration': 19, 'loss': 0.6536825403350528, 'max_history_score': 0.85528670390001, 'max_history_score_std': 0.02213730791268438, 'max_history_step': 'joint', 'pipeline': {'features': ('features_SelectKBest', {'features__k': 3}), 'normalizer': ('normalizer_RobustScaler', {'normalizer__quantile_range': (...), 'normalizer__with_centering': False, 'normalizer__with_scaling': True}), 'rebalance': ('rebalance_CondensedNearestNeighbour', {'rebalance__n_neighbors': 3})}, 'score': 0.3463174596649472, ...}, ...], 'history_hash': ['fd24b065dda6bdeb1077793f9df480ff318c7a37', 'fb22f80fb4358ae1ee4c9bd4a83543992be8d806', '8c97cdb885dd05cfd8c40ee3ac445b61e5c767a8', '16fbb5fd5cfbbacfddf27c61c0c7397a7f6d8ade', 'a77c698197c31308211b854e81a998178941f87d', '1fc13606bca3aaf342ca6ea21139cb598b56f8db', '6749af1a67b4dbcd2b4719e419d99908063c05e1', 'd92d4ada2394fc132733e176e926ee53acdc6a00', 'f0d0b1d2cedc22ae15d9a208a3fc3fc133bf0d3d', '47584de0e60d0d12c7dbbf0dc60e5aea96e3f4b2', 'eecb88ee2b1b95d741c1b5c7751534d31aae6a77', '27a7ed0502b321ab7256b77c8ce79e90cb9da815', '45f056102dd2d644bd8befa471f17b2311ac7954', 'ba108323623936872824ed8f1c41d615d25523b3', 'dde4d3b5f37741629cb58bfc4051ed9f98c8f311', '1080c25b92da3f15a6f8eec003957f7e0a66324f', 'c3e8cf4eca5aafcae4ac31b0449e105ca127ffe2', '3449b4a1c2e488e26a7195ee9edca19b854ebd33', '224987ffdbbb9b6182cff18d8374518b917e4f2e', '97ca7d6a017c721084dec2a5d2e5a67e1e6ae2f0', ...], 'history_index': {'01b68ec8d6fe15ffdadf1adfd0d809307d3ce41e': 81, '05465becb12810ce291074be22a0275a42efbea8': 52, '064f53edf4748bb2df4ff59f147331aad21219e1': 48, '087efef4a19f272562d2d445dac0edd8096ba2fa': 58, '0fd4d71ca3a89c7d14af5087f2a2e2c1b1975351': 51, '1080c25b92da3f15a6f8eec003957f7e0a66324f': 15, '10ca1ab51b6af0696dab2c8cbaf8de5e3812a6de': 78, '10cb7f1ca9feb52539f61b654f31107801dadc1c': 89, '143679b59e16961765e77616142572b6ded0ee72': 62, '151b4a15037767108da13dafa0b63ae93222e93a': 53, ...}, 'iteration': 94, 'max_history_score': 0.9231904384036744, 'max_history_score_std': 0.03040515884196498, 'max_history_step': 'joint'}, config={'algorithm': 'RandomForest', 'seed': 42, 'time': 300}, step='joint')
     45                 y,
     46                 cv=10,
     47                 n_jobs=-1,
     48                 return_estimator=False,
     49                 return_train_score=False,
---> 50                 verbose=0)
     51         score = np.mean(scores['test_score'])
     52         std = np.std(scores['test_score'])
     53         status = STATUS_OK
     54     except Exception as e:

...........................................................................
/home/aquemy/.local/lib/python2.7/site-packages/sklearn/model_selection/_validation.py in cross_validate(estimator=Pipeline(memory=None,
     steps=[('rebalance', ... random_state=42, verbose=0, warm_start=False))]), X=array([[ 0.,  0.,  5., ...,  0.,  0.,  0.],
    ...0.],
       [ 0.,  0., 10., ..., 12.,  1.,  0.]]), y=array([0, 1, 2, ..., 8, 9, 8]), groups=None, scoring=None, cv=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1, verbose=0, fit_params=None, pre_dispatch='2*n_jobs', return_train_score=False, return_estimator=False, error_score='raise-deprecating')
    235         delayed(_fit_and_score)(
    236             clone(estimator), X, y, scorers, train, test, verbose, None,
    237             fit_params, return_train_score=return_train_score,
    238             return_times=True, return_estimator=return_estimator,
    239             error_score=error_score)
--> 240         for train, test in cv.split(X, y, groups))
        cv.split = <bound method StratifiedKFold.split of Stratifie...d(n_splits=10, random_state=None, shuffle=False)>
        X = array([[ 0.,  0.,  5., ...,  0.,  0.,  0.],
    ...0.],
       [ 0.,  0., 10., ..., 12.,  1.,  0.]])
        y = array([0, 1, 2, ..., 8, 9, 8])
        groups = None
    241 
    242     zipped_scores = list(zip(*scores))
    243     if return_train_score:
    244         train_scores = zipped_scores.pop(0)

...........................................................................
/home/aquemy/.local/lib/python2.7/site-packages/sklearn/externals/joblib/parallel.py in __call__(self=Parallel(n_jobs=-1), iterable=<generator object <genexpr>>)
    925                 # No need to wait for async callbacks to trigger to
    926                 # consumption.
    927                 self._iterating = False
    928 
    929             with self._backend.retrieval_context():
--> 930                 self.retrieve()
        self.retrieve = <bound method Parallel.retrieve of Parallel(n_jobs=-1)>
    931             # Make sure that we get a last message telling us we are done
    932             elapsed_time = time.time() - self._start_time
    933             self._print('Done %3i out of %3i | elapsed: %s finished',
    934                         (len(self._output), len(self._output),

---------------------------------------------------------------------------
Joblib worker traceback:
---------------------------------------------------------------------------
ValueError                                         Mon Jun 17 13:09:38 2019
PID: 20503                                  Python 2.7.15+: /usr/bin/python
...........................................................................
/home/aquemy/.local/lib/python2.7/site-packages/sklearn/externals/joblib/parallel.py in __call__(self=<sklearn.externals.joblib.parallel.BatchedCalls object>)
    220     def __call__(self):
    221         # Set the default nested backend to self._backend but do not set the
    222         # change the default number of processes to -1
    223         with parallel_backend(self._backend, n_jobs=self._n_jobs):
    224             return [func(*args, **kwargs)
--> 225                     for func, args, kwargs in self.items]
        func = <function _fit_and_score>
        args = (Pipeline(memory=None,
     steps=[('rebalance', ... random_state=42, verbose=0, warm_start=False))]), array([[ 0.,  0.,  5., ...,  0.,  0.,  0.],
    ...0.],
       [ 0.,  0., 10., ..., 12.,  1.,  0.]]), array([0, 1, 2, ..., 8, 9, 8]), {'score': <function _passthrough_scorer>}, array([ 169,  176,  178, ..., 1794, 1795, 1796]), array([  0,   1,   2,   3,   4,   5,   6,   7,  ..., 181, 186, 188, 189, 190,
       194, 195, 198]), 0, None, None)
        kwargs = {'error_score': 'raise-deprecating', 'return_estimator': False, 'return_times': True, 'return_train_score': False}
        self.items = [(<function _fit_and_score>, (Pipeline(memory=None,
     steps=[('rebalance', ... random_state=42, verbose=0, warm_start=False))]), array([[ 0.,  0.,  5., ...,  0.,  0.,  0.],
    ...0.],
       [ 0.,  0., 10., ..., 12.,  1.,  0.]]), array([0, 1, 2, ..., 8, 9, 8]), {'score': <function _passthrough_scorer>}, array([ 169,  176,  178, ..., 1794, 1795, 1796]), array([  0,   1,   2,   3,   4,   5,   6,   7,  ..., 181, 186, 188, 189, 190,
       194, 195, 198]), 0, None, None), {'error_score': 'raise-deprecating', 'return_estimator': False, 'return_times': True, 'return_train_score': False})]
    226 
    227     def __len__(self):
    228         return self._size
    229 

...........................................................................
/home/aquemy/.local/lib/python2.7/site-packages/sklearn/model_selection/_validation.py in _fit_and_score(estimator=Pipeline(memory=None,
     steps=[('rebalance', ... random_state=42, verbose=0, warm_start=False))]), X=array([[ 0.,  0.,  5., ...,  0.,  0.,  0.],
    ...0.],
       [ 0.,  0., 10., ..., 12.,  1.,  0.]]), y=array([0, 1, 2, ..., 8, 9, 8]), scorer={'score': <function _passthrough_scorer>}, train=array([ 169,  176,  178, ..., 1794, 1795, 1796]), test=array([  0,   1,   2,   3,   4,   5,   6,   7,  ..., 181, 186, 188, 189, 190,
       194, 195, 198]), verbose=0, parameters=None, fit_params={}, return_train_score=False, return_parameters=False, return_n_test_samples=False, return_times=True, return_estimator=False, error_score='raise-deprecating')
    523 
    524     try:
    525         if y_train is None:
    526             estimator.fit(X_train, **fit_params)
    527         else:
--> 528             estimator.fit(X_train, y_train, **fit_params)
        estimator.fit = <bound method Pipeline.fit of Pipeline(memory=No...random_state=42, verbose=0, warm_start=False))])>
        X_train = array([[ 0.,  0.,  6., ...,  9.,  4.,  0.],
    ...0.],
       [ 0.,  0., 10., ..., 12.,  1.,  0.]])
        y_train = array([9, 5, 0, ..., 8, 9, 8])
        fit_params = {}
    529 
    530     except Exception as e:
    531         # Note fit time as time until error
    532         fit_time = time.time() - start_time

...........................................................................
/usr/local/lib/python2.7/dist-packages/imblearn/pipeline.py in fit(self=Pipeline(memory=None,
     steps=[('rebalance', ... random_state=42, verbose=0, warm_start=False))]), X=array([[ 0.,  0.,  6., ...,  9.,  4.,  0.],
    ...0.],
       [ 0.,  0., 10., ..., 12.,  1.,  0.]]), y=array([9, 5, 0, ..., 8, 9, 8]), **fit_params={})
    234             This estimator
    235 
    236         """
    237         Xt, yt, fit_params = self._fit(X, y, **fit_params)
    238         if self._final_estimator is not None:
--> 239             self._final_estimator.fit(Xt, yt, **fit_params)
        self._final_estimator.fit = <bound method RandomForestClassifier.fit of Rand...   random_state=42, verbose=0, warm_start=False)>
        Xt = array([[0.],
       [0.],
       [8.],
       ...,
       [0.],
       [0.],
       [0.]])
        yt = array([9, 5, 0, ..., 8, 9, 9])
        fit_params = {}
    240         return self
    241 
    242     def fit_transform(self, X, y=None, **fit_params):
    243         """Fit the model and transform with the final estimator

...........................................................................
/home/aquemy/.local/lib/python2.7/site-packages/sklearn/ensemble/forest.py in fit(self=RandomForestClassifier(bootstrap=False, class_we...    random_state=42, verbose=0, warm_start=False), X=array([[0.],
       [0.],
       [8.],
       .....  [0.],
       [0.],
       [0.]], dtype=float32), y=array([[9.],
       [5.],
       [0.],
       ...,
       [8.],
       [9.],
       [9.]]), sample_weight=None)
    328             trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,
    329                              **_joblib_parallel_args(prefer='threads'))(
    330                 delayed(_parallel_build_trees)(
    331                     t, self, X, y, sample_weight, i, len(trees),
    332                     verbose=self.verbose, class_weight=self.class_weight)
--> 333                 for i, t in enumerate(trees))
        i = 99
    334 
    335             # Collect newly grown trees
    336             self.estimators_.extend(trees)
    337 

...........................................................................
/home/aquemy/.local/lib/python2.7/site-packages/sklearn/externals/joblib/parallel.py in __call__(self=Parallel(n_jobs=1), iterable=<generator object <genexpr>>)
    912             # self._original_iterator is None, then this means either
    913             # that pre_dispatch == "all", n_jobs == 1 or that the first batch
    914             # was very quick and its callback already dispatched all the
    915             # remaining jobs.
    916             self._iterating = False
--> 917             if self.dispatch_one_batch(iterator):
        self.dispatch_one_batch = <bound method Parallel.dispatch_one_batch of Parallel(n_jobs=1)>
        iterator = <generator object <genexpr>>
    918                 self._iterating = self._original_iterator is not None
    919 
    920             while self.dispatch_one_batch(iterator):
    921                 pass

...........................................................................
/home/aquemy/.local/lib/python2.7/site-packages/sklearn/externals/joblib/parallel.py in dispatch_one_batch(self=Parallel(n_jobs=1), iterator=<generator object <genexpr>>)
    754                                  self._pickle_cache)
    755             if len(tasks) == 0:
    756                 # No more tasks available in the iterator: tell caller to stop.
    757                 return False
    758             else:
--> 759                 self._dispatch(tasks)
        self._dispatch = <bound method Parallel._dispatch of Parallel(n_jobs=1)>
        tasks = <sklearn.externals.joblib.parallel.BatchedCalls object>
    760                 return True
    761 
    762     def _print(self, msg, msg_args):
    763         """Display the message on stout or stderr depending on verbosity"""

...........................................................................
/home/aquemy/.local/lib/python2.7/site-packages/sklearn/externals/joblib/parallel.py in _dispatch(self=Parallel(n_jobs=1), batch=<sklearn.externals.joblib.parallel.BatchedCalls object>)
    711 
    712         dispatch_timestamp = time.time()
    713         cb = BatchCompletionCallBack(dispatch_timestamp, len(batch), self)
    714         with self._lock:
    715             job_idx = len(self._jobs)
--> 716             job = self._backend.apply_async(batch, callback=cb)
        job = undefined
        self._backend.apply_async = <bound method SequentialBackend.apply_async of <...lib._parallel_backends.SequentialBackend object>>
        batch = <sklearn.externals.joblib.parallel.BatchedCalls object>
        cb = <sklearn.externals.joblib.parallel.BatchCompletionCallBack object>
    717             # A job can complete so quickly than its callback is
    718             # called before we get here, causing self._jobs to
    719             # grow. To ensure correct results ordering, .insert is
    720             # used (rather than .append) in the following line

...........................................................................
/home/aquemy/.local/lib/python2.7/site-packages/sklearn/externals/joblib/_parallel_backends.py in apply_async(self=<sklearn.externals.joblib._parallel_backends.SequentialBackend object>, func=<sklearn.externals.joblib.parallel.BatchedCalls object>, callback=<sklearn.externals.joblib.parallel.BatchCompletionCallBack object>)
    177             raise ValueError('n_jobs == 0 in Parallel has no meaning')
    178         return 1
    179 
    180     def apply_async(self, func, callback=None):
    181         """Schedule a func to be run"""
--> 182         result = ImmediateResult(func)
        result = undefined
        func = <sklearn.externals.joblib.parallel.BatchedCalls object>
    183         if callback:
    184             callback(result)
    185         return result
    186 

...........................................................................
/home/aquemy/.local/lib/python2.7/site-packages/sklearn/externals/joblib/_parallel_backends.py in __init__(self=<sklearn.externals.joblib._parallel_backends.ImmediateResult object>, batch=<sklearn.externals.joblib.parallel.BatchedCalls object>)
    544 
    545 class ImmediateResult(object):
    546     def __init__(self, batch):
    547         # Don't delay the application, to avoid keeping the input
    548         # arguments in memory
--> 549         self.results = batch()
        self.results = undefined
        batch = <sklearn.externals.joblib.parallel.BatchedCalls object>
    550 
    551     def get(self):
    552         return self.results
    553 

...........................................................................
/home/aquemy/.local/lib/python2.7/site-packages/sklearn/externals/joblib/parallel.py in __call__(self=<sklearn.externals.joblib.parallel.BatchedCalls object>)
    220     def __call__(self):
    221         # Set the default nested backend to self._backend but do not set the
    222         # change the default number of processes to -1
    223         with parallel_backend(self._backend, n_jobs=self._n_jobs):
    224             return [func(*args, **kwargs)
--> 225                     for func, args, kwargs in self.items]
        func = <function _parallel_build_trees>
        args = (DecisionTreeClassifier(class_weight=None, criter...=False, random_state=1608637542, splitter='best'), RandomForestClassifier(bootstrap=False, class_we...    random_state=42, verbose=0, warm_start=False), array([[0.],
       [0.],
       [8.],
       .....  [0.],
       [0.],
       [0.]], dtype=float32), array([[9.],
       [5.],
       [0.],
       ...,
       [8.],
       [9.],
       [9.]]), None, 0, 100)
        kwargs = {'class_weight': None, 'verbose': 0}
        self.items = [(<function _parallel_build_trees>, (DecisionTreeClassifier(class_weight=None, criter...=False, random_state=1608637542, splitter='best'), RandomForestClassifier(bootstrap=False, class_we...    random_state=42, verbose=0, warm_start=False), array([[0.],
       [0.],
       [8.],
       .....  [0.],
       [0.],
       [0.]], dtype=float32), array([[9.],
       [5.],
       [0.],
       ...,
       [8.],
       [9.],
       [9.]]), None, 0, 100), {'class_weight': None, 'verbose': 0})]
    226 
    227     def __len__(self):
    228         return self._size
    229 

...........................................................................
/home/aquemy/.local/lib/python2.7/site-packages/sklearn/ensemble/forest.py in _parallel_build_trees(tree=DecisionTreeClassifier(class_weight=None, criter...=False, random_state=1608637542, splitter='best'), forest=RandomForestClassifier(bootstrap=False, class_we...    random_state=42, verbose=0, warm_start=False), X=array([[0.],
       [0.],
       [8.],
       .....  [0.],
       [0.],
       [0.]], dtype=float32), y=array([[9.],
       [5.],
       [0.],
       ...,
       [8.],
       [9.],
       [9.]]), sample_weight=None, tree_idx=0, n_trees=100, verbose=0, class_weight=None)
    116         elif class_weight == 'balanced_subsample':
    117             curr_sample_weight *= compute_sample_weight('balanced', y, indices)
    118 
    119         tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)
    120     else:
--> 121         tree.fit(X, y, sample_weight=sample_weight, check_input=False)
        tree.fit = <bound method DecisionTreeClassifier.fit of Deci...False, random_state=1608637542, splitter='best')>
        X = array([[0.],
       [0.],
       [8.],
       .....  [0.],
       [0.],
       [0.]], dtype=float32)
        y = array([[9.],
       [5.],
       [0.],
       ...,
       [8.],
       [9.],
       [9.]])
        sample_weight = None
    122 
    123     return tree
    124 
    125 

...........................................................................
/home/aquemy/.local/lib/python2.7/site-packages/sklearn/tree/tree.py in fit(self=DecisionTreeClassifier(class_weight=None, criter...=False, random_state=1608637542, splitter='best'), X=array([[0.],
       [0.],
       [8.],
       .....  [0.],
       [0.],
       [0.]], dtype=float32), y=array([[9.],
       [5.],
       [0.],
       ...,
       [8.],
       [9.],
       [9.]]), sample_weight=None, check_input=False, X_idx_sorted=None)
    796 
    797         super(DecisionTreeClassifier, self).fit(
    798             X, y,
    799             sample_weight=sample_weight,
    800             check_input=check_input,
--> 801             X_idx_sorted=X_idx_sorted)
        X_idx_sorted = None
    802         return self
    803 
    804     def predict_proba(self, X, check_input=True):
    805         """Predict class probabilities of the input samples X.

...........................................................................
/home/aquemy/.local/lib/python2.7/site-packages/sklearn/tree/tree.py in fit(self=DecisionTreeClassifier(class_weight=None, criter...=False, random_state=1608637542, splitter='best'), X=array([[0.],
       [0.],
       [8.],
       .....  [0.],
       [0.],
       [0.]], dtype=float32), y=array([[9.],
       [5.],
       [0.],
       ...,
       [8.],
       [9.],
       [9.]]), sample_weight=None, check_input=False, X_idx_sorted=None)
    237         if not 0 <= self.min_weight_fraction_leaf <= 0.5:
    238             raise ValueError("min_weight_fraction_leaf must in [0, 0.5]")
    239         if max_depth <= 0:
    240             raise ValueError("max_depth must be greater than zero. ")
    241         if not (0 < max_features <= self.n_features_):
--> 242             raise ValueError("max_features must be in (0, n_features]")
    243         if not isinstance(max_leaf_nodes, (numbers.Integral, np.integer)):
    244             raise ValueError("max_leaf_nodes must be integral number but was "
    245                              "%r" % max_leaf_nodes)
    246         if -1 < max_leaf_nodes < 2:

ValueError: max_features must be in (0, n_features]
___________________________________________________________________________
Best score: 0.923190438404 (0.030405158842) [J] | Score: 0.0 (0.0) [J]
Best score: 0.923190438404 (0.030405158842) [J] | Score: 0.670010038258 (0.0619441408405) [J]
Best score: 0.923190438404 (0.030405158842) [J] | Score: 0.855806586229 (0.0387822695351) [J]
Best score: 0.923190438404 (0.030405158842) [J] | Score: 0.585980738323 (0.0417091420292) [J]
Best score: 0.923190438404 (0.030405158842) [J] | Score: 0.860809672341 (0.0437339964964) [J]
Best score: 0.923190438404 (0.030405158842) [J] | Score: 0.861344581905 (0.0416737867843) [J]
Best score: 0.923190438404 (0.030405158842) [J] | Score: 0.860785514493 (0.0361674964051) [J]
Best score: 0.923190438404 (0.030405158842) [J] | Score: 0.859100120066 (0.0378887817407) [J]
Best score: 0.923190438404 (0.030405158842) [J] | Score: 0.0968163392773 (0.00179561960358) [J]
Best score: 0.923190438404 (0.030405158842) [J] | Score: 0.758394445539 (0.0532063410377) [J]
Best score: 0.923190438404 (0.030405158842) [J] | Score: 0.865175631117 (0.0418001961923) [J]
Best score: 0.923190438404 (0.030405158842) [J] | Score: 0.747230337956 (0.0460179603509) [J]
JoblibValueError
___________________________________________________________________________
...........................................................................
/home/aquemy/dev/dp_hyperparameters/extension/main.py in <module>()
     27 
     28     serializer.serialize_results(scenario, policy)
     29 
     30 if __name__ == "__main__":
     31     args = cli.parse_args()
---> 32     main(args)

...........................................................................
/home/aquemy/dev/dp_hyperparameters/extension/main.py in main(args=Namespace(customize=[(['control', 'seed'], '42')...='./scenarios/rf_digits_joint.yaml', verbosity=0))
     21         test_size=0.4, 
     22         random_state=scenario['control']['seed']
     23     )
     24 
     25     policy = policies.initiate(scenario['setup']['policy'], config)
---> 26     policy.run(X,y)
        policy.run = <bound method Joint.run of <experiment.policies.joint.Joint object>>
        X = array([[ 0.,  0.,  5., ...,  0.,  0.,  0.],
    ...0.],
       [ 0.,  0., 10., ..., 12.,  1.,  0.]])
        y = array([0, 1, 2, ..., 8, 9, 8])
     27 
     28     serializer.serialize_results(scenario, policy)
     29 
     30 if __name__ == "__main__":

...........................................................................
/home/aquemy/dev/dp_hyperparameters/extension/experiment/policies/joint.py in run(self=<experiment.policies.joint.Joint object>, X=array([[ 0.,  0.,  5., ...,  0.,  0.,  0.],
    ...0.],
       [ 0.,  0., 10., ..., 12.,  1.,  0.]]), y=array([0, 1, 2, ..., 8, 9, 8]))
     32             algo=tpe.suggest, 
     33             max_evals=None,
     34             max_time=self.config['time'],     
     35             trials=trials,
     36             show_progressbar=False,
---> 37             verbose=0
     38         )
     39 
     40         best_config = self.context['best_config']
     41         super(Joint, self).display_step_results(best_config)

...........................................................................
/home/aquemy/dev/dp_hyperparameters/extension/hyperopt/fmin.py in fmin(fn=<functools.partial object>, space={'algorithm': {'bootstrap': <hyperopt.pyll.base.Apply object>, 'criterion': <hyperopt.pyll.base.Apply object>, 'max_depth': <hyperopt.pyll.base.Apply object>, 'max_features': <hyperopt.pyll.base.Apply object>, 'max_leaf_nodes': <hyperopt.pyll.base.Apply object>, 'min_samples_split': <hyperopt.pyll.base.Apply object>, 'n_estimators': <hyperopt.pyll.base.Apply object>}, 'pipeline': {'features': <hyperopt.pyll.base.Apply object>, 'normalizer': <hyperopt.pyll.base.Apply object>, 'rebalance': <hyperopt.pyll.base.Apply object>}}, algo=<function suggest>, max_evals=9223372036854775807, max_time=300, trials=<hyperopt.base.Trials object>, rstate=<mtrand.RandomState object>, allow_trials_fmin=True, pass_expr_memo_ctrl=None, catch_eval_exceptions=False, verbose=0, return_argmin=True, points_to_evaluate=None, max_queue_len=1, show_progressbar=False)
    406             pass_expr_memo_ctrl=pass_expr_memo_ctrl,
    407             verbose=verbose,
    408             catch_eval_exceptions=catch_eval_exceptions,
    409             return_argmin=return_argmin,
    410             show_progressbar=show_progressbar,
--> 411             max_time=max_time
        max_time = 300
    412         )
    413 
    414     if trials is None:
    415         if points_to_evaluate is None:

...........................................................................
/home/aquemy/dev/dp_hyperparameters/extension/hyperopt/base.py in fmin(self=<hyperopt.base.Trials object>, fn=<functools.partial object>, space={'algorithm': {'bootstrap': <hyperopt.pyll.base.Apply object>, 'criterion': <hyperopt.pyll.base.Apply object>, 'max_depth': <hyperopt.pyll.base.Apply object>, 'max_features': <hyperopt.pyll.base.Apply object>, 'max_leaf_nodes': <hyperopt.pyll.base.Apply object>, 'min_samples_split': <hyperopt.pyll.base.Apply object>, 'n_estimators': <hyperopt.pyll.base.Apply object>}, 'pipeline': {'features': <hyperopt.pyll.base.Apply object>, 'normalizer': <hyperopt.pyll.base.Apply object>, 'rebalance': <hyperopt.pyll.base.Apply object>}}, algo=<function suggest>, max_evals=9223372036854775807, max_time=300, rstate=<mtrand.RandomState object>, verbose=0, pass_expr_memo_ctrl=None, catch_eval_exceptions=False, return_argmin=True, show_progressbar=False)
    636             verbose=verbose,
    637             allow_trials_fmin=False,  # -- prevent recursion
    638             pass_expr_memo_ctrl=pass_expr_memo_ctrl,
    639             catch_eval_exceptions=catch_eval_exceptions,
    640             return_argmin=return_argmin,
--> 641             show_progressbar=show_progressbar)
        show_progressbar = False
    642 
    643 
    644 def trials_from_docs(docs, validate=True, **kwargs):
    645     """Construct a Trials base class instance from a list of trials documents

...........................................................................
/home/aquemy/dev/dp_hyperparameters/extension/hyperopt/fmin.py in fmin(fn=<functools.partial object>, space={'algorithm': {'bootstrap': <hyperopt.pyll.base.Apply object>, 'criterion': <hyperopt.pyll.base.Apply object>, 'max_depth': <hyperopt.pyll.base.Apply object>, 'max_features': <hyperopt.pyll.base.Apply object>, 'max_leaf_nodes': <hyperopt.pyll.base.Apply object>, 'min_samples_split': <hyperopt.pyll.base.Apply object>, 'n_estimators': <hyperopt.pyll.base.Apply object>}, 'pipeline': {'features': <hyperopt.pyll.base.Apply object>, 'normalizer': <hyperopt.pyll.base.Apply object>, 'rebalance': <hyperopt.pyll.base.Apply object>}}, algo=<function suggest>, max_evals=9223372036854775807, max_time=300, trials=<hyperopt.base.Trials object>, rstate=<mtrand.RandomState object>, allow_trials_fmin=False, pass_expr_memo_ctrl=None, catch_eval_exceptions=False, verbose=0, return_argmin=True, points_to_evaluate=None, max_queue_len=1, show_progressbar=False)
    426                     verbose=verbose,
    427                     max_queue_len=max_queue_len,
    428                     show_progressbar=show_progressbar,
    429                     max_time=max_time)
    430     rval.catch_eval_exceptions = catch_eval_exceptions
--> 431     rval.exhaust()
        rval.exhaust = <bound method FMinIter.exhaust of <hyperopt.fmin.FMinIter object>>
    432     if return_argmin:
    433         return trials.argmin
    434     elif len(trials) > 0:
    435         # Only if there are some succesfull trail runs, return the best point in the evaluation space

...........................................................................
/home/aquemy/dev/dp_hyperparameters/extension/hyperopt/fmin.py in exhaust(self=<hyperopt.fmin.FMinIter object>)
    273             raise StopIteration()
    274         return self.trials
    275 
    276     def exhaust(self):
    277         n_done = len(self.trials)
--> 278         self.run(self.max_evals - n_done, block_until_done=self.asynchronous)
        self.run = <bound method FMinIter.run of <hyperopt.fmin.FMinIter object>>
        self.max_evals = 9223372036854775807
        n_done = 0
        self.asynchronous = False
    279         self.trials.refresh()
    280         return self
    281 
    282 

...........................................................................
/home/aquemy/dev/dp_hyperparameters/extension/hyperopt/fmin.py in run(self=<hyperopt.fmin.FMinIter object>, N=9223372036854775807, block_until_done=False)
    232                     if self.asynchronous:
    233                         # -- wait for workers to fill in the trials
    234                         time.sleep(self.poll_interval_secs)
    235                     else:
    236                         # -- loop over trials and do the jobs directly
--> 237                         self.serial_evaluate()
        self.serial_evaluate = <bound method FMinIter.serial_evaluate of <hyperopt.fmin.FMinIter object>>
    238                     try:
    239                         res = [d['result']['loss'] for d in
    240                                          self.trials.trials if
    241                                          d['result']['status'] == 'ok']

...........................................................................
/home/aquemy/dev/dp_hyperparameters/extension/hyperopt/fmin.py in serial_evaluate(self=<hyperopt.fmin.FMinIter object>, N=-1)
    138                 trial['book_time'] = now
    139                 trial['refresh_time'] = now
    140                 spec = base.spec_from_misc(trial['misc'])
    141                 ctrl = base.Ctrl(self.trials, current_trial=trial)
    142                 try:
--> 143                     result = self.domain.evaluate(spec, ctrl)
        result = undefined
        self.domain.evaluate = <bound method Domain.evaluate of <hyperopt.base.Domain object>>
        spec = {'bootstrap': 1, 'criterion': 0, 'features': 1, 'features_PCA_features__n_components': 1, 'max_depth': 1, 'max_features': 2, 'max_leaf_nodes': 3, 'min_samples_split': 2, 'n_estimators': 3, 'normalizer': 1, ...}
        ctrl = <hyperopt.base.Ctrl object>
    144                 except Exception as e:
    145                     logger.info('job exception: %s' % str(e))
    146                     trial['state'] = base.JOB_STATE_ERROR
    147                     trial['misc']['error'] = (str(type(e)), str(e))

...........................................................................
/home/aquemy/dev/dp_hyperparameters/extension/hyperopt/base.py in evaluate(self=<hyperopt.base.Domain object>, config={'bootstrap': 1, 'criterion': 0, 'features': 1, 'features_PCA_features__n_components': 1, 'max_depth': 1, 'max_features': 2, 'max_leaf_nodes': 3, 'min_samples_split': 2, 'n_estimators': 3, 'normalizer': 1, ...}, ctrl=<hyperopt.base.Ctrl object>, attach_attachments=True)
    841             #    or the normal Python part (self.fn)
    842             pyll_rval = pyll.rec_eval(
    843                 self.expr,
    844                 memo=memo,
    845                 print_node_on_error=self.rec_eval_print_node_on_error)
--> 846             rval = self.fn(pyll_rval)
        rval = undefined
        self.fn = <functools.partial object>
        pyll_rval = {'algorithm': {'bootstrap': False, 'criterion': 'gini', 'max_depth': 2, 'max_features': 3, 'max_leaf_nodes': None, 'min_samples_split': 5, 'n_estimators': 75}, 'pipeline': {'features': ('features_PCA', {'features__n_components': 2}), 'normalizer': ('normalizer_StandardScaler', {'normalizer__with_mean': False, 'normalizer__with_std': False}), 'rebalance': ('rebalance_CondensedNearestNeighbour', {'rebalance__n_neighbors': 1})}}
    847 
    848         if isinstance(rval, (float, int, np.number)):
    849             dict_rval = {'loss': float(rval), 'status': STATUS_OK}
    850         else:

...........................................................................
/home/aquemy/dev/dp_hyperparameters/extension/experiment/objective.py in objective_joint(wconfig={'algorithm': {'bootstrap': False, 'criterion': 'gini', 'max_depth': 2, 'max_features': 3, 'max_leaf_nodes': None, 'min_samples_split': 5, 'n_estimators': 75}, 'pipeline': {'features': ('features_PCA', {'features__n_components': 2}), 'normalizer': ('normalizer_StandardScaler', {'normalizer__with_mean': False, 'normalizer__with_std': False}), 'rebalance': ('rebalance_CondensedNearestNeighbour', {'rebalance__n_neighbors': 1})}}, algorithm='RandomForest', X=array([[ 0.,  0.,  5., ...,  0.,  0.,  0.],
    ...0.],
       [ 0.,  0., 10., ..., 12.,  1.,  0.]]), y=array([0, 1, 2, ..., 8, 9, 8]), context={'baseline_score': 0.9272021217853512, 'baseline_score_std': 0.026919033284817703, 'best_config': {'algorithm': {'bootstrap': True, 'criterion': 'entropy', 'max_depth': None, 'max_features': None, 'max_leaf_nodes': None, 'min_samples_split': 3, 'n_estimators': 75}, 'config_hash': {'algorithm': 'f42e45bee34ac9973699212f6c8b845daea9383a', 'config': 'ae61cfde4c8b4c792e42d6b6be4af4ffb3d90e13', 'pipeline': '15ff3d6270ac899763bb3f72417c48bcd56aa7d8'}, 'duration': 8.20555305480957, 'iteration': 65, 'loss': 0.07680956159632557, 'max_history_score': 0.9231904384036744, 'max_history_score_std': 0.03040515884196498, 'max_history_step': 'joint', 'pipeline': {'features': ('features_NoneType', {}), 'normalizer': ('normalizer_StandardScaler', {'normalizer__with_mean': True, 'normalizer__with_std': True}), 'rebalance': ('rebalance_NearMiss', {'rebalance__n_neighbors': 1})}, 'score': 0.9231904384036744, ...}, 'history': [{'algorithm': {'bootstrap': False, 'criterion': 'entropy', 'max_depth': 1, 'max_features': 3, 'max_leaf_nodes': 3, 'min_samples_split': 5, 'n_estimators': 50}, 'config_hash': {'algorithm': '752fa095cdab58a238ae606c613606188964cc0c', 'config': 'fd24b065dda6bdeb1077793f9df480ff318c7a37', 'pipeline': '13ea3359c453b8993fcec1e88bc0e19cd0a2b112'}, 'duration': 0.689669132232666, 'iteration': 0, 'loss': 0.6602879519109309, 'max_history_score': 0.3397120480890691, 'max_history_score_std': 0.03346542949100545, 'max_history_step': 'joint', 'pipeline': {'features': ('features_SelectKBest', {'features__k': 4}), 'normalizer': ('normalizer_MinMaxScaler', {}), 'rebalance': ('rebalance_NoneType', {})}, 'score': 0.3397120480890691, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'gini', 'max_depth': 4, 'max_features': 1, 'max_leaf_nodes': 5, 'min_samples_split': 3, 'n_estimators': 25}, 'config_hash': {'algorithm': '9d9de4aee820052ddfe83bfffca420f6b50837d3', 'config': 'fb22f80fb4358ae1ee4c9bd4a83543992be8d806', 'pipeline': '6251ad4bb7a110726a67f90c319f4717ac37a312'}, 'duration': 1.4300940036773682, 'iteration': 1, 'loss': 0.5122196101741096, 'max_history_score': 0.48778038982589045, 'max_history_score_std': 0.05486079759217226, 'max_history_step': 'joint', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 2, 'features__selectkbest__k': 2}), 'normalizer': ('normalizer_StandardScaler', {'normalizer__with_mean': True, 'normalizer__with_std': True}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 5})}, 'score': 0.48778038982589045, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': 4, 'max_features': 1, 'max_leaf_nodes': None, 'min_samples_split': 2, 'n_estimators': 10}, 'config_hash': {'algorithm': '2ed7d27df9a1b2d5e63da76f7cb309616c232022', 'config': '8c97cdb885dd05cfd8c40ee3ac445b61e5c767a8', 'pipeline': 'c0abb5e23a4739d3120740a9519fb36c43eb94d5'}, 'duration': 3.0036678314208984, 'iteration': 2, 'loss': 0.38319264175312906, 'max_history_score': 0.6168073582468709, 'max_history_score_std': 0.05286679173001824, 'max_history_step': 'joint', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 1, 'features__selectkbest__k': 4}), 'normalizer': ('normalizer_PowerTransformer', {}), 'rebalance': ('rebalance_NearMiss', {'rebalance__n_neighbors': 2})}, 'score': 0.6168073582468709, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'entropy', 'max_depth': None, 'max_features': None, 'max_leaf_nodes': 2, 'min_samples_split': 2, 'n_estimators': 100}, 'config_hash': {'algorithm': '17962655e3b76dfcd0843d1e5c2cb7a9db1c6a79', 'config': '16fbb5fd5cfbbacfddf27c61c0c7397a7f6d8ade', 'pipeline': '13ea3359c453b8993fcec1e88bc0e19cd0a2b112'}, 'duration': 1.3447980880737305, 'iteration': 3, 'loss': 0.6768840987778313, 'max_history_score': 0.6168073582468709, 'max_history_score_std': 0.05286679173001824, 'max_history_step': 'joint', 'pipeline': {'features': ('features_SelectKBest', {'features__k': 4}), 'normalizer': ('normalizer_MinMaxScaler', {}), 'rebalance': ('rebalance_NoneType', {})}, 'score': 0.32311590122216866, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'gini', 'max_depth': 2, 'max_features': 2, 'max_leaf_nodes': 2, 'min_samples_split': 3, 'n_estimators': 100}, 'config_hash': {'algorithm': '1ea8965b2247f86950e54510ee6d79399816341b', 'config': 'a77c698197c31308211b854e81a998178941f87d', 'pipeline': 'aaf976c7c663a31fa039582d42f9e07101556a7c'}, 'duration': 2.589430093765259, 'iteration': 4, 'loss': 0.2544808950572157, 'max_history_score': 0.7455191049427843, 'max_history_score_std': 0.04843448308166839, 'max_history_step': 'joint', 'pipeline': {'features': ('features_NoneType', {}), 'normalizer': ('normalizer_PowerTransformer', {}), 'rebalance': ('rebalance_NoneType', {})}, 'score': 0.7455191049427843, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': None, 'max_features': 2, 'max_leaf_nodes': 5, 'min_samples_split': 5, 'n_estimators': 25}, 'config_hash': {'algorithm': 'fd8aeb6a05eaaba41e676d60596c8e0c71b35e0c', 'config': '1fc13606bca3aaf342ca6ea21139cb598b56f8db', 'pipeline': 'f00bd8de05642e026bbba4ad20d3a60088c86b6c'}, 'duration': 1.8779079914093018, 'iteration': 5, 'loss': 0.531551018758381, 'max_history_score': 0.7455191049427843, 'max_history_score_std': 0.04843448308166839, 'max_history_step': 'joint', 'pipeline': {'features': ('features_PCA', {'features__n_components': 2}), 'normalizer': ('normalizer_MinMaxScaler', {}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 5})}, 'score': 0.46844898124161904, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'entropy', 'max_depth': None, 'max_features': 2, 'max_leaf_nodes': None, 'min_samples_split': 2, 'n_estimators': 10}, 'config_hash': {'algorithm': 'a49ecb99e74217d6812f98ead7bc9d1fe4a53ba0', 'config': '6749af1a67b4dbcd2b4719e419d99908063c05e1', 'pipeline': '19bdf19a2eec5febce95ab8fa2a71040d75114aa'}, 'duration': 1.5498578548431396, 'iteration': 6, 'loss': 0.14471329609998995, 'max_history_score': 0.85528670390001, 'max_history_score_std': 0.02213730791268438, 'max_history_step': 'joint', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 4, 'features__selectkbest__k': 3}), 'normalizer': ('normalizer_NoneType', {}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 7})}, 'score': 0.85528670390001, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': 1, 'max_features': 3, 'max_leaf_nodes': 3, 'min_samples_split': 3, 'n_estimators': 75}, 'config_hash': {'algorithm': 'ebfb16234172ae811ff21185ff92bbdbb8f32f14', 'config': 'd92d4ada2394fc132733e176e926ee53acdc6a00', 'pipeline': '8071e7cbf86a5c3056493dc3aa40063aeb28cdfe'}, 'duration': 1.3618149757385254, 'iteration': 7, 'loss': 0.6158612049395463, 'max_history_score': 0.85528670390001, 'max_history_score_std': 0.02213730791268438, 'max_history_step': 'joint', 'pipeline': {'features': ('features_SelectKBest', {'features__k': 4}), 'normalizer': ('normalizer_StandardScaler', {'normalizer__with_mean': True, 'normalizer__with_std': True}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 5})}, 'score': 0.3841387950604537, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'entropy', 'max_depth': 1, 'max_features': 1, 'max_leaf_nodes': 5, 'min_samples_split': 2, 'n_estimators': 100}, 'config_hash': {'algorithm': '896b53c75a2db568fb7b6da3bfca2f7a1535a11b', 'config': 'f0d0b1d2cedc22ae15d9a208a3fc3fc133bf0d3d', 'pipeline': 'c9761c9a33bf75d6dcad0742c421548a7655ccc9'}, 'duration': 2.297278881072998, 'iteration': 8, 'loss': 0.40673663548410355, 'max_history_score': 0.85528670390001, 'max_history_score_std': 0.02213730791268438, 'max_history_step': 'joint', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 2, 'features__selectkbest__k': 4}), 'normalizer': ('normalizer_StandardScaler', {'normalizer__with_mean': False, 'normalizer__with_std': False}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 5})}, 'score': 0.5932633645158965, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'entropy', 'max_depth': 2, 'max_features': None, 'max_leaf_nodes': None, 'min_samples_split': 5, 'n_estimators': 25}, 'config_hash': {'algorithm': '0b0e954757c4f75343a6efb740ad93260ed781ae', 'config': '47584de0e60d0d12c7dbbf0dc60e5aea96e3f4b2', 'pipeline': 'b37ee32d59413053bf9a2a72c8ff7135f3701e05'}, 'duration': 0.7249000072479248, 'iteration': 9, 'loss': 0.6965910020393421, 'max_history_score': 0.85528670390001, 'max_history_score_std': 0.02213730791268438, 'max_history_step': 'joint', 'pipeline': {'features': ('features_SelectKBest', {'features__k': 3}), 'normalizer': ('normalizer_NoneType', {}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 7})}, 'score': 0.3034089979606579, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'gini', 'max_depth': 2, 'max_features': 2, 'max_leaf_nodes': 5, 'min_samples_split': 5, 'n_estimators': 75}, 'config_hash': {'algorithm': 'f1ead1d9e33ea927e1dd27d872a058fa3de4f832', 'config': 'eecb88ee2b1b95d741c1b5c7751534d31aae6a77', 'pipeline': '6746650871e8b61efc9302b092dc05f7cdb179d5'}, 'duration': 5.340634822845459, 'iteration': 10, 'loss': 0.7687016290977936, 'max_history_score': 0.85528670390001, 'max_history_score_std': 0.02213730791268438, 'max_history_step': 'joint', 'pipeline': {'features': ('features_SelectKBest', {'features__k': 3}), 'normalizer': ('normalizer_RobustScaler', {'normalizer__quantile_range': (...), 'normalizer__with_centering': False, 'normalizer__with_scaling': False}), 'rebalance': ('rebalance_CondensedNearestNeighbour', {'rebalance__n_neighbors': 1})}, 'score': 0.23129837090220637, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': 1, 'max_features': 2, 'max_leaf_nodes': 2, 'min_samples_split': 3, 'n_estimators': 75}, 'config_hash': {'algorithm': '531a3bb8ccf0baa06727af4b3de9e62d25e6eabf', 'config': '27a7ed0502b321ab7256b77c8ce79e90cb9da815', 'pipeline': '77e6d84e2217b92b3cf67cc6defef9dd3554cec0'}, 'duration': 1.775357961654663, 'iteration': 11, 'loss': 0.6313818737375694, 'max_history_score': 0.85528670390001, 'max_history_score_std': 0.02213730791268438, 'max_history_step': 'joint', 'pipeline': {'features': ('features_SelectKBest', {'features__k': 4}), 'normalizer': ('normalizer_MinMaxScaler', {}), 'rebalance': ('rebalance_NearMiss', {'rebalance__n_neighbors': 3})}, 'score': 0.3686181262624307, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'entropy', 'max_depth': 4, 'max_features': 3, 'max_leaf_nodes': 2, 'min_samples_split': 3, 'n_estimators': 10}, 'config_hash': {'algorithm': '93518f8ded6074d537900b26be72f8485782f933', 'config': '45f056102dd2d644bd8befa471f17b2311ac7954', 'pipeline': '5240329df25c9a533d025c1a401d49835a501b41'}, 'duration': 3.2622711658477783, 'iteration': 12, 'loss': 0.6120243191353301, 'max_history_score': 0.85528670390001, 'max_history_score_std': 0.02213730791268438, 'max_history_step': 'joint', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 4, 'features__selectkbest__k': 2}), 'normalizer': ('normalizer_PowerTransformer', {}), 'rebalance': ('rebalance_NearMiss', {'rebalance__n_neighbors': 1})}, 'score': 0.38797568086467, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'entropy', 'max_depth': None, 'max_features': 1, 'max_leaf_nodes': 5, 'min_samples_split': 3, 'n_estimators': 75}, 'config_hash': {'algorithm': 'e515d45b764fa43591032874a0ff9c25bf12fddd', 'config': 'ba108323623936872824ed8f1c41d615d25523b3', 'pipeline': '9d823bc0442f21b5ce8af67a5eb1237f64ffc2f8'}, 'duration': 2.5326571464538574, 'iteration': 13, 'loss': 0.6271427382991047, 'max_history_score': 0.85528670390001, 'max_history_score_std': 0.02213730791268438, 'max_history_step': 'joint', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 1, 'features__selectkbest__k': 1}), 'normalizer': ('normalizer_StandardScaler', {'normalizer__with_mean': True, 'normalizer__with_std': True}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 5})}, 'score': 0.3728572617008953, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'entropy', 'max_depth': 3, 'max_features': 2, 'max_leaf_nodes': 2, 'min_samples_split': 3, 'n_estimators': 25}, 'config_hash': {'algorithm': '2808e67f609eba5c8a97f81ac0c9413cd37cf7aa', 'config': 'dde4d3b5f37741629cb58bfc4051ed9f98c8f311', 'pipeline': 'bc52deabf1f5ee60968ba541d9d2574353c30a9c'}, 'duration': 0.7145559787750244, 'iteration': 14, 'loss': 0.6831045572696203, 'max_history_score': 0.85528670390001, 'max_history_score_std': 0.02213730791268438, 'max_history_step': 'joint', 'pipeline': {'features': ('features_SelectKBest', {'features__k': 3}), 'normalizer': ('normalizer_MinMaxScaler', {}), 'rebalance': ('rebalance_NearMiss', {'rebalance__n_neighbors': 1})}, 'score': 0.31689544273037973, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'gini', 'max_depth': 2, 'max_features': 2, 'max_leaf_nodes': None, 'min_samples_split': 5, 'n_estimators': 100}, 'config_hash': {'algorithm': 'b942acdead762d34afeb474bc2fe6f7fd0f23493', 'config': '1080c25b92da3f15a6f8eec003957f7e0a66324f', 'pipeline': 'cfa84fe703dc5bc0bbd2257a6d524fee2693b804'}, 'duration': 2.812459945678711, 'iteration': 15, 'loss': 0.6921421091202761, 'max_history_score': 0.85528670390001, 'max_history_score_std': 0.02213730791268438, 'max_history_step': 'joint', 'pipeline': {'features': ('features_SelectKBest', {'features__k': 2}), 'normalizer': ('normalizer_PowerTransformer', {}), 'rebalance': ('rebalance_NoneType', {})}, 'score': 0.3078578908797239, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'entropy', 'max_depth': 2, 'max_features': 3, 'max_leaf_nodes': 3, 'min_samples_split': 2, 'n_estimators': 75}, 'config_hash': {'algorithm': '250661ce4193a61ef44d2f77694b52b785ff032d', 'config': 'c3e8cf4eca5aafcae4ac31b0449e105ca127ffe2', 'pipeline': 'c4dd111513ea35f97dd3aec3e8e7f6268ce035da'}, 'duration': 1.0555319786071777, 'iteration': 16, 'loss': 1.0, 'max_history_score': 0.85528670390001, 'max_history_score_std': 0.02213730791268438, 'max_history_step': 'joint', 'pipeline': {'features': ('features_PCA', {'features__n_components': 2}), 'normalizer': ('normalizer_RobustScaler', {'normalizer__quantile_range': (...), 'normalizer__with_centering': False, 'normalizer__with_scaling': True}), 'rebalance': ('rebalance_NearMiss', {'rebalance__n_neighbors': 2})}, 'score': 0.0, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'entropy', 'max_depth': 3, 'max_features': 3, 'max_leaf_nodes': None, 'min_samples_split': 3, 'n_estimators': 25}, 'config_hash': {'algorithm': '05ac02bd045c65dc4089894902ad6253661a2692', 'config': '3449b4a1c2e488e26a7195ee9edca19b854ebd33', 'pipeline': '505d3f71b534917375d765e64b0611e7dfb83746'}, 'duration': 5.5412821769714355, 'iteration': 17, 'loss': 0.7289151155121668, 'max_history_score': 0.85528670390001, 'max_history_score_std': 0.02213730791268438, 'max_history_step': 'joint', 'pipeline': {'features': ('features_SelectKBest', {'features__k': 4}), 'normalizer': ('normalizer_MinMaxScaler', {}), 'rebalance': ('rebalance_CondensedNearestNeighbour', {'rebalance__n_neighbors': 2})}, 'score': 0.2710848844878332, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'entropy', 'max_depth': 2, 'max_features': None, 'max_leaf_nodes': None, 'min_samples_split': 2, 'n_estimators': 25}, 'config_hash': {'algorithm': 'de3b3a352ebb260e16c6b213a08c9144d17a744b', 'config': '224987ffdbbb9b6182cff18d8374518b917e4f2e', 'pipeline': '12c89200a558b2f3b91332566f41050143aecbe7'}, 'duration': 2.4646048545837402, 'iteration': 18, 'loss': 0.6545902512995826, 'max_history_score': 0.85528670390001, 'max_history_score_std': 0.02213730791268438, 'max_history_step': 'joint', 'pipeline': {'features': ('features_NoneType', {}), 'normalizer': ('normalizer_PowerTransformer', {}), 'rebalance': ('rebalance_NearMiss', {'rebalance__n_neighbors': 2})}, 'score': 0.3454097487004174, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'gini', 'max_depth': None, 'max_features': 1, 'max_leaf_nodes': None, 'min_samples_split': 3, 'n_estimators': 100}, 'config_hash': {'algorithm': '30ca111584767bbf0464df40b4c928cf7ddf9459', 'config': '97ca7d6a017c721084dec2a5d2e5a67e1e6ae2f0', 'pipeline': '789eca82ea4a42d61927670c538867b745fd81d3'}, 'duration': 7.164499044418335, 'iteration': 19, 'loss': 0.6536825403350528, 'max_history_score': 0.85528670390001, 'max_history_score_std': 0.02213730791268438, 'max_history_step': 'joint', 'pipeline': {'features': ('features_SelectKBest', {'features__k': 3}), 'normalizer': ('normalizer_RobustScaler', {'normalizer__quantile_range': (...), 'normalizer__with_centering': False, 'normalizer__with_scaling': True}), 'rebalance': ('rebalance_CondensedNearestNeighbour', {'rebalance__n_neighbors': 3})}, 'score': 0.3463174596649472, ...}, ...], 'history_hash': ['fd24b065dda6bdeb1077793f9df480ff318c7a37', 'fb22f80fb4358ae1ee4c9bd4a83543992be8d806', '8c97cdb885dd05cfd8c40ee3ac445b61e5c767a8', '16fbb5fd5cfbbacfddf27c61c0c7397a7f6d8ade', 'a77c698197c31308211b854e81a998178941f87d', '1fc13606bca3aaf342ca6ea21139cb598b56f8db', '6749af1a67b4dbcd2b4719e419d99908063c05e1', 'd92d4ada2394fc132733e176e926ee53acdc6a00', 'f0d0b1d2cedc22ae15d9a208a3fc3fc133bf0d3d', '47584de0e60d0d12c7dbbf0dc60e5aea96e3f4b2', 'eecb88ee2b1b95d741c1b5c7751534d31aae6a77', '27a7ed0502b321ab7256b77c8ce79e90cb9da815', '45f056102dd2d644bd8befa471f17b2311ac7954', 'ba108323623936872824ed8f1c41d615d25523b3', 'dde4d3b5f37741629cb58bfc4051ed9f98c8f311', '1080c25b92da3f15a6f8eec003957f7e0a66324f', 'c3e8cf4eca5aafcae4ac31b0449e105ca127ffe2', '3449b4a1c2e488e26a7195ee9edca19b854ebd33', '224987ffdbbb9b6182cff18d8374518b917e4f2e', '97ca7d6a017c721084dec2a5d2e5a67e1e6ae2f0', ...], 'history_index': {'00e8f4ca31525b847c5f1d5de869962edbe23b64': 99, '01b68ec8d6fe15ffdadf1adfd0d809307d3ce41e': 81, '05465becb12810ce291074be22a0275a42efbea8': 52, '064f53edf4748bb2df4ff59f147331aad21219e1': 48, '087efef4a19f272562d2d445dac0edd8096ba2fa': 58, '0fd4d71ca3a89c7d14af5087f2a2e2c1b1975351': 51, '1080c25b92da3f15a6f8eec003957f7e0a66324f': 15, '10ca1ab51b6af0696dab2c8cbaf8de5e3812a6de': 78, '10cb7f1ca9feb52539f61b654f31107801dadc1c': 89, '143679b59e16961765e77616142572b6ded0ee72': 62, ...}, 'iteration': 106, 'max_history_score': 0.9231904384036744, 'max_history_score_std': 0.03040515884196498, 'max_history_step': 'joint'}, config={'algorithm': 'RandomForest', 'seed': 42, 'time': 300})
    108 
    109 def objective_algo(algo_config, current_pipeline_config, algorithm, X, y, context, config):
    110     return objective(current_pipeline_config, algo_config, algorithm, X, y, context, config, step='algorithm')
    111 
    112 def objective_joint(wconfig, algorithm, X, y, context, config):
--> 113     return objective(wconfig['pipeline'], wconfig['algorithm'], algorithm, X, y, context, config, step='joint')
        wconfig = {'algorithm': {'bootstrap': False, 'criterion': 'gini', 'max_depth': 2, 'max_features': 3, 'max_leaf_nodes': None, 'min_samples_split': 5, 'n_estimators': 75}, 'pipeline': {'features': ('features_PCA', {'features__n_components': 2}), 'normalizer': ('normalizer_StandardScaler', {'normalizer__with_mean': False, 'normalizer__with_std': False}), 'rebalance': ('rebalance_CondensedNearestNeighbour', {'rebalance__n_neighbors': 1})}}
        algorithm = 'RandomForest'
        X = array([[ 0.,  0.,  5., ...,  0.,  0.,  0.],
    ...0.],
       [ 0.,  0., 10., ..., 12.,  1.,  0.]])
        y = array([0, 1, 2, ..., 8, 9, 8])
        context = {'baseline_score': 0.9272021217853512, 'baseline_score_std': 0.026919033284817703, 'best_config': {'algorithm': {'bootstrap': True, 'criterion': 'entropy', 'max_depth': None, 'max_features': None, 'max_leaf_nodes': None, 'min_samples_split': 3, 'n_estimators': 75}, 'config_hash': {'algorithm': 'f42e45bee34ac9973699212f6c8b845daea9383a', 'config': 'ae61cfde4c8b4c792e42d6b6be4af4ffb3d90e13', 'pipeline': '15ff3d6270ac899763bb3f72417c48bcd56aa7d8'}, 'duration': 8.20555305480957, 'iteration': 65, 'loss': 0.07680956159632557, 'max_history_score': 0.9231904384036744, 'max_history_score_std': 0.03040515884196498, 'max_history_step': 'joint', 'pipeline': {'features': ('features_NoneType', {}), 'normalizer': ('normalizer_StandardScaler', {'normalizer__with_mean': True, 'normalizer__with_std': True}), 'rebalance': ('rebalance_NearMiss', {'rebalance__n_neighbors': 1})}, 'score': 0.9231904384036744, ...}, 'history': [{'algorithm': {'bootstrap': False, 'criterion': 'entropy', 'max_depth': 1, 'max_features': 3, 'max_leaf_nodes': 3, 'min_samples_split': 5, 'n_estimators': 50}, 'config_hash': {'algorithm': '752fa095cdab58a238ae606c613606188964cc0c', 'config': 'fd24b065dda6bdeb1077793f9df480ff318c7a37', 'pipeline': '13ea3359c453b8993fcec1e88bc0e19cd0a2b112'}, 'duration': 0.689669132232666, 'iteration': 0, 'loss': 0.6602879519109309, 'max_history_score': 0.3397120480890691, 'max_history_score_std': 0.03346542949100545, 'max_history_step': 'joint', 'pipeline': {'features': ('features_SelectKBest', {'features__k': 4}), 'normalizer': ('normalizer_MinMaxScaler', {}), 'rebalance': ('rebalance_NoneType', {})}, 'score': 0.3397120480890691, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'gini', 'max_depth': 4, 'max_features': 1, 'max_leaf_nodes': 5, 'min_samples_split': 3, 'n_estimators': 25}, 'config_hash': {'algorithm': '9d9de4aee820052ddfe83bfffca420f6b50837d3', 'config': 'fb22f80fb4358ae1ee4c9bd4a83543992be8d806', 'pipeline': '6251ad4bb7a110726a67f90c319f4717ac37a312'}, 'duration': 1.4300940036773682, 'iteration': 1, 'loss': 0.5122196101741096, 'max_history_score': 0.48778038982589045, 'max_history_score_std': 0.05486079759217226, 'max_history_step': 'joint', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 2, 'features__selectkbest__k': 2}), 'normalizer': ('normalizer_StandardScaler', {'normalizer__with_mean': True, 'normalizer__with_std': True}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 5})}, 'score': 0.48778038982589045, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': 4, 'max_features': 1, 'max_leaf_nodes': None, 'min_samples_split': 2, 'n_estimators': 10}, 'config_hash': {'algorithm': '2ed7d27df9a1b2d5e63da76f7cb309616c232022', 'config': '8c97cdb885dd05cfd8c40ee3ac445b61e5c767a8', 'pipeline': 'c0abb5e23a4739d3120740a9519fb36c43eb94d5'}, 'duration': 3.0036678314208984, 'iteration': 2, 'loss': 0.38319264175312906, 'max_history_score': 0.6168073582468709, 'max_history_score_std': 0.05286679173001824, 'max_history_step': 'joint', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 1, 'features__selectkbest__k': 4}), 'normalizer': ('normalizer_PowerTransformer', {}), 'rebalance': ('rebalance_NearMiss', {'rebalance__n_neighbors': 2})}, 'score': 0.6168073582468709, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'entropy', 'max_depth': None, 'max_features': None, 'max_leaf_nodes': 2, 'min_samples_split': 2, 'n_estimators': 100}, 'config_hash': {'algorithm': '17962655e3b76dfcd0843d1e5c2cb7a9db1c6a79', 'config': '16fbb5fd5cfbbacfddf27c61c0c7397a7f6d8ade', 'pipeline': '13ea3359c453b8993fcec1e88bc0e19cd0a2b112'}, 'duration': 1.3447980880737305, 'iteration': 3, 'loss': 0.6768840987778313, 'max_history_score': 0.6168073582468709, 'max_history_score_std': 0.05286679173001824, 'max_history_step': 'joint', 'pipeline': {'features': ('features_SelectKBest', {'features__k': 4}), 'normalizer': ('normalizer_MinMaxScaler', {}), 'rebalance': ('rebalance_NoneType', {})}, 'score': 0.32311590122216866, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'gini', 'max_depth': 2, 'max_features': 2, 'max_leaf_nodes': 2, 'min_samples_split': 3, 'n_estimators': 100}, 'config_hash': {'algorithm': '1ea8965b2247f86950e54510ee6d79399816341b', 'config': 'a77c698197c31308211b854e81a998178941f87d', 'pipeline': 'aaf976c7c663a31fa039582d42f9e07101556a7c'}, 'duration': 2.589430093765259, 'iteration': 4, 'loss': 0.2544808950572157, 'max_history_score': 0.7455191049427843, 'max_history_score_std': 0.04843448308166839, 'max_history_step': 'joint', 'pipeline': {'features': ('features_NoneType', {}), 'normalizer': ('normalizer_PowerTransformer', {}), 'rebalance': ('rebalance_NoneType', {})}, 'score': 0.7455191049427843, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': None, 'max_features': 2, 'max_leaf_nodes': 5, 'min_samples_split': 5, 'n_estimators': 25}, 'config_hash': {'algorithm': 'fd8aeb6a05eaaba41e676d60596c8e0c71b35e0c', 'config': '1fc13606bca3aaf342ca6ea21139cb598b56f8db', 'pipeline': 'f00bd8de05642e026bbba4ad20d3a60088c86b6c'}, 'duration': 1.8779079914093018, 'iteration': 5, 'loss': 0.531551018758381, 'max_history_score': 0.7455191049427843, 'max_history_score_std': 0.04843448308166839, 'max_history_step': 'joint', 'pipeline': {'features': ('features_PCA', {'features__n_components': 2}), 'normalizer': ('normalizer_MinMaxScaler', {}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 5})}, 'score': 0.46844898124161904, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'entropy', 'max_depth': None, 'max_features': 2, 'max_leaf_nodes': None, 'min_samples_split': 2, 'n_estimators': 10}, 'config_hash': {'algorithm': 'a49ecb99e74217d6812f98ead7bc9d1fe4a53ba0', 'config': '6749af1a67b4dbcd2b4719e419d99908063c05e1', 'pipeline': '19bdf19a2eec5febce95ab8fa2a71040d75114aa'}, 'duration': 1.5498578548431396, 'iteration': 6, 'loss': 0.14471329609998995, 'max_history_score': 0.85528670390001, 'max_history_score_std': 0.02213730791268438, 'max_history_step': 'joint', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 4, 'features__selectkbest__k': 3}), 'normalizer': ('normalizer_NoneType', {}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 7})}, 'score': 0.85528670390001, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': 1, 'max_features': 3, 'max_leaf_nodes': 3, 'min_samples_split': 3, 'n_estimators': 75}, 'config_hash': {'algorithm': 'ebfb16234172ae811ff21185ff92bbdbb8f32f14', 'config': 'd92d4ada2394fc132733e176e926ee53acdc6a00', 'pipeline': '8071e7cbf86a5c3056493dc3aa40063aeb28cdfe'}, 'duration': 1.3618149757385254, 'iteration': 7, 'loss': 0.6158612049395463, 'max_history_score': 0.85528670390001, 'max_history_score_std': 0.02213730791268438, 'max_history_step': 'joint', 'pipeline': {'features': ('features_SelectKBest', {'features__k': 4}), 'normalizer': ('normalizer_StandardScaler', {'normalizer__with_mean': True, 'normalizer__with_std': True}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 5})}, 'score': 0.3841387950604537, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'entropy', 'max_depth': 1, 'max_features': 1, 'max_leaf_nodes': 5, 'min_samples_split': 2, 'n_estimators': 100}, 'config_hash': {'algorithm': '896b53c75a2db568fb7b6da3bfca2f7a1535a11b', 'config': 'f0d0b1d2cedc22ae15d9a208a3fc3fc133bf0d3d', 'pipeline': 'c9761c9a33bf75d6dcad0742c421548a7655ccc9'}, 'duration': 2.297278881072998, 'iteration': 8, 'loss': 0.40673663548410355, 'max_history_score': 0.85528670390001, 'max_history_score_std': 0.02213730791268438, 'max_history_step': 'joint', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 2, 'features__selectkbest__k': 4}), 'normalizer': ('normalizer_StandardScaler', {'normalizer__with_mean': False, 'normalizer__with_std': False}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 5})}, 'score': 0.5932633645158965, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'entropy', 'max_depth': 2, 'max_features': None, 'max_leaf_nodes': None, 'min_samples_split': 5, 'n_estimators': 25}, 'config_hash': {'algorithm': '0b0e954757c4f75343a6efb740ad93260ed781ae', 'config': '47584de0e60d0d12c7dbbf0dc60e5aea96e3f4b2', 'pipeline': 'b37ee32d59413053bf9a2a72c8ff7135f3701e05'}, 'duration': 0.7249000072479248, 'iteration': 9, 'loss': 0.6965910020393421, 'max_history_score': 0.85528670390001, 'max_history_score_std': 0.02213730791268438, 'max_history_step': 'joint', 'pipeline': {'features': ('features_SelectKBest', {'features__k': 3}), 'normalizer': ('normalizer_NoneType', {}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 7})}, 'score': 0.3034089979606579, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'gini', 'max_depth': 2, 'max_features': 2, 'max_leaf_nodes': 5, 'min_samples_split': 5, 'n_estimators': 75}, 'config_hash': {'algorithm': 'f1ead1d9e33ea927e1dd27d872a058fa3de4f832', 'config': 'eecb88ee2b1b95d741c1b5c7751534d31aae6a77', 'pipeline': '6746650871e8b61efc9302b092dc05f7cdb179d5'}, 'duration': 5.340634822845459, 'iteration': 10, 'loss': 0.7687016290977936, 'max_history_score': 0.85528670390001, 'max_history_score_std': 0.02213730791268438, 'max_history_step': 'joint', 'pipeline': {'features': ('features_SelectKBest', {'features__k': 3}), 'normalizer': ('normalizer_RobustScaler', {'normalizer__quantile_range': (...), 'normalizer__with_centering': False, 'normalizer__with_scaling': False}), 'rebalance': ('rebalance_CondensedNearestNeighbour', {'rebalance__n_neighbors': 1})}, 'score': 0.23129837090220637, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': 1, 'max_features': 2, 'max_leaf_nodes': 2, 'min_samples_split': 3, 'n_estimators': 75}, 'config_hash': {'algorithm': '531a3bb8ccf0baa06727af4b3de9e62d25e6eabf', 'config': '27a7ed0502b321ab7256b77c8ce79e90cb9da815', 'pipeline': '77e6d84e2217b92b3cf67cc6defef9dd3554cec0'}, 'duration': 1.775357961654663, 'iteration': 11, 'loss': 0.6313818737375694, 'max_history_score': 0.85528670390001, 'max_history_score_std': 0.02213730791268438, 'max_history_step': 'joint', 'pipeline': {'features': ('features_SelectKBest', {'features__k': 4}), 'normalizer': ('normalizer_MinMaxScaler', {}), 'rebalance': ('rebalance_NearMiss', {'rebalance__n_neighbors': 3})}, 'score': 0.3686181262624307, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'entropy', 'max_depth': 4, 'max_features': 3, 'max_leaf_nodes': 2, 'min_samples_split': 3, 'n_estimators': 10}, 'config_hash': {'algorithm': '93518f8ded6074d537900b26be72f8485782f933', 'config': '45f056102dd2d644bd8befa471f17b2311ac7954', 'pipeline': '5240329df25c9a533d025c1a401d49835a501b41'}, 'duration': 3.2622711658477783, 'iteration': 12, 'loss': 0.6120243191353301, 'max_history_score': 0.85528670390001, 'max_history_score_std': 0.02213730791268438, 'max_history_step': 'joint', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 4, 'features__selectkbest__k': 2}), 'normalizer': ('normalizer_PowerTransformer', {}), 'rebalance': ('rebalance_NearMiss', {'rebalance__n_neighbors': 1})}, 'score': 0.38797568086467, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'entropy', 'max_depth': None, 'max_features': 1, 'max_leaf_nodes': 5, 'min_samples_split': 3, 'n_estimators': 75}, 'config_hash': {'algorithm': 'e515d45b764fa43591032874a0ff9c25bf12fddd', 'config': 'ba108323623936872824ed8f1c41d615d25523b3', 'pipeline': '9d823bc0442f21b5ce8af67a5eb1237f64ffc2f8'}, 'duration': 2.5326571464538574, 'iteration': 13, 'loss': 0.6271427382991047, 'max_history_score': 0.85528670390001, 'max_history_score_std': 0.02213730791268438, 'max_history_step': 'joint', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 1, 'features__selectkbest__k': 1}), 'normalizer': ('normalizer_StandardScaler', {'normalizer__with_mean': True, 'normalizer__with_std': True}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 5})}, 'score': 0.3728572617008953, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'entropy', 'max_depth': 3, 'max_features': 2, 'max_leaf_nodes': 2, 'min_samples_split': 3, 'n_estimators': 25}, 'config_hash': {'algorithm': '2808e67f609eba5c8a97f81ac0c9413cd37cf7aa', 'config': 'dde4d3b5f37741629cb58bfc4051ed9f98c8f311', 'pipeline': 'bc52deabf1f5ee60968ba541d9d2574353c30a9c'}, 'duration': 0.7145559787750244, 'iteration': 14, 'loss': 0.6831045572696203, 'max_history_score': 0.85528670390001, 'max_history_score_std': 0.02213730791268438, 'max_history_step': 'joint', 'pipeline': {'features': ('features_SelectKBest', {'features__k': 3}), 'normalizer': ('normalizer_MinMaxScaler', {}), 'rebalance': ('rebalance_NearMiss', {'rebalance__n_neighbors': 1})}, 'score': 0.31689544273037973, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'gini', 'max_depth': 2, 'max_features': 2, 'max_leaf_nodes': None, 'min_samples_split': 5, 'n_estimators': 100}, 'config_hash': {'algorithm': 'b942acdead762d34afeb474bc2fe6f7fd0f23493', 'config': '1080c25b92da3f15a6f8eec003957f7e0a66324f', 'pipeline': 'cfa84fe703dc5bc0bbd2257a6d524fee2693b804'}, 'duration': 2.812459945678711, 'iteration': 15, 'loss': 0.6921421091202761, 'max_history_score': 0.85528670390001, 'max_history_score_std': 0.02213730791268438, 'max_history_step': 'joint', 'pipeline': {'features': ('features_SelectKBest', {'features__k': 2}), 'normalizer': ('normalizer_PowerTransformer', {}), 'rebalance': ('rebalance_NoneType', {})}, 'score': 0.3078578908797239, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'entropy', 'max_depth': 2, 'max_features': 3, 'max_leaf_nodes': 3, 'min_samples_split': 2, 'n_estimators': 75}, 'config_hash': {'algorithm': '250661ce4193a61ef44d2f77694b52b785ff032d', 'config': 'c3e8cf4eca5aafcae4ac31b0449e105ca127ffe2', 'pipeline': 'c4dd111513ea35f97dd3aec3e8e7f6268ce035da'}, 'duration': 1.0555319786071777, 'iteration': 16, 'loss': 1.0, 'max_history_score': 0.85528670390001, 'max_history_score_std': 0.02213730791268438, 'max_history_step': 'joint', 'pipeline': {'features': ('features_PCA', {'features__n_components': 2}), 'normalizer': ('normalizer_RobustScaler', {'normalizer__quantile_range': (...), 'normalizer__with_centering': False, 'normalizer__with_scaling': True}), 'rebalance': ('rebalance_NearMiss', {'rebalance__n_neighbors': 2})}, 'score': 0.0, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'entropy', 'max_depth': 3, 'max_features': 3, 'max_leaf_nodes': None, 'min_samples_split': 3, 'n_estimators': 25}, 'config_hash': {'algorithm': '05ac02bd045c65dc4089894902ad6253661a2692', 'config': '3449b4a1c2e488e26a7195ee9edca19b854ebd33', 'pipeline': '505d3f71b534917375d765e64b0611e7dfb83746'}, 'duration': 5.5412821769714355, 'iteration': 17, 'loss': 0.7289151155121668, 'max_history_score': 0.85528670390001, 'max_history_score_std': 0.02213730791268438, 'max_history_step': 'joint', 'pipeline': {'features': ('features_SelectKBest', {'features__k': 4}), 'normalizer': ('normalizer_MinMaxScaler', {}), 'rebalance': ('rebalance_CondensedNearestNeighbour', {'rebalance__n_neighbors': 2})}, 'score': 0.2710848844878332, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'entropy', 'max_depth': 2, 'max_features': None, 'max_leaf_nodes': None, 'min_samples_split': 2, 'n_estimators': 25}, 'config_hash': {'algorithm': 'de3b3a352ebb260e16c6b213a08c9144d17a744b', 'config': '224987ffdbbb9b6182cff18d8374518b917e4f2e', 'pipeline': '12c89200a558b2f3b91332566f41050143aecbe7'}, 'duration': 2.4646048545837402, 'iteration': 18, 'loss': 0.6545902512995826, 'max_history_score': 0.85528670390001, 'max_history_score_std': 0.02213730791268438, 'max_history_step': 'joint', 'pipeline': {'features': ('features_NoneType', {}), 'normalizer': ('normalizer_PowerTransformer', {}), 'rebalance': ('rebalance_NearMiss', {'rebalance__n_neighbors': 2})}, 'score': 0.3454097487004174, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'gini', 'max_depth': None, 'max_features': 1, 'max_leaf_nodes': None, 'min_samples_split': 3, 'n_estimators': 100}, 'config_hash': {'algorithm': '30ca111584767bbf0464df40b4c928cf7ddf9459', 'config': '97ca7d6a017c721084dec2a5d2e5a67e1e6ae2f0', 'pipeline': '789eca82ea4a42d61927670c538867b745fd81d3'}, 'duration': 7.164499044418335, 'iteration': 19, 'loss': 0.6536825403350528, 'max_history_score': 0.85528670390001, 'max_history_score_std': 0.02213730791268438, 'max_history_step': 'joint', 'pipeline': {'features': ('features_SelectKBest', {'features__k': 3}), 'normalizer': ('normalizer_RobustScaler', {'normalizer__quantile_range': (...), 'normalizer__with_centering': False, 'normalizer__with_scaling': True}), 'rebalance': ('rebalance_CondensedNearestNeighbour', {'rebalance__n_neighbors': 3})}, 'score': 0.3463174596649472, ...}, ...], 'history_hash': ['fd24b065dda6bdeb1077793f9df480ff318c7a37', 'fb22f80fb4358ae1ee4c9bd4a83543992be8d806', '8c97cdb885dd05cfd8c40ee3ac445b61e5c767a8', '16fbb5fd5cfbbacfddf27c61c0c7397a7f6d8ade', 'a77c698197c31308211b854e81a998178941f87d', '1fc13606bca3aaf342ca6ea21139cb598b56f8db', '6749af1a67b4dbcd2b4719e419d99908063c05e1', 'd92d4ada2394fc132733e176e926ee53acdc6a00', 'f0d0b1d2cedc22ae15d9a208a3fc3fc133bf0d3d', '47584de0e60d0d12c7dbbf0dc60e5aea96e3f4b2', 'eecb88ee2b1b95d741c1b5c7751534d31aae6a77', '27a7ed0502b321ab7256b77c8ce79e90cb9da815', '45f056102dd2d644bd8befa471f17b2311ac7954', 'ba108323623936872824ed8f1c41d615d25523b3', 'dde4d3b5f37741629cb58bfc4051ed9f98c8f311', '1080c25b92da3f15a6f8eec003957f7e0a66324f', 'c3e8cf4eca5aafcae4ac31b0449e105ca127ffe2', '3449b4a1c2e488e26a7195ee9edca19b854ebd33', '224987ffdbbb9b6182cff18d8374518b917e4f2e', '97ca7d6a017c721084dec2a5d2e5a67e1e6ae2f0', ...], 'history_index': {'00e8f4ca31525b847c5f1d5de869962edbe23b64': 99, '01b68ec8d6fe15ffdadf1adfd0d809307d3ce41e': 81, '05465becb12810ce291074be22a0275a42efbea8': 52, '064f53edf4748bb2df4ff59f147331aad21219e1': 48, '087efef4a19f272562d2d445dac0edd8096ba2fa': 58, '0fd4d71ca3a89c7d14af5087f2a2e2c1b1975351': 51, '1080c25b92da3f15a6f8eec003957f7e0a66324f': 15, '10ca1ab51b6af0696dab2c8cbaf8de5e3812a6de': 78, '10cb7f1ca9feb52539f61b654f31107801dadc1c': 89, '143679b59e16961765e77616142572b6ded0ee72': 62, ...}, 'iteration': 106, 'max_history_score': 0.9231904384036744, 'max_history_score_std': 0.03040515884196498, 'max_history_step': 'joint'}
        config = {'algorithm': 'RandomForest', 'seed': 42, 'time': 300}
    114 
    115 
    116 def get_baseline_score(algorithm, X, y, seed):
    117     pipeline, _ = pipeline_conf_to_full_pipeline(

...........................................................................
/home/aquemy/dev/dp_hyperparameters/extension/experiment/objective.py in objective(pipeline_config={'features': ('features_PCA', {'features__n_components': 2}), 'normalizer': ('normalizer_StandardScaler', {'normalizer__with_mean': False, 'normalizer__with_std': False}), 'rebalance': ('rebalance_CondensedNearestNeighbour', {'rebalance__n_neighbors': 1})}, algo_config={'bootstrap': False, 'criterion': 'gini', 'max_depth': 2, 'max_features': 3, 'max_leaf_nodes': None, 'min_samples_split': 5, 'n_estimators': 75}, algorithm='RandomForest', X=array([[ 0.,  0.,  5., ...,  0.,  0.,  0.],
    ...0.],
       [ 0.,  0., 10., ..., 12.,  1.,  0.]]), y=array([0, 1, 2, ..., 8, 9, 8]), context={'baseline_score': 0.9272021217853512, 'baseline_score_std': 0.026919033284817703, 'best_config': {'algorithm': {'bootstrap': True, 'criterion': 'entropy', 'max_depth': None, 'max_features': None, 'max_leaf_nodes': None, 'min_samples_split': 3, 'n_estimators': 75}, 'config_hash': {'algorithm': 'f42e45bee34ac9973699212f6c8b845daea9383a', 'config': 'ae61cfde4c8b4c792e42d6b6be4af4ffb3d90e13', 'pipeline': '15ff3d6270ac899763bb3f72417c48bcd56aa7d8'}, 'duration': 8.20555305480957, 'iteration': 65, 'loss': 0.07680956159632557, 'max_history_score': 0.9231904384036744, 'max_history_score_std': 0.03040515884196498, 'max_history_step': 'joint', 'pipeline': {'features': ('features_NoneType', {}), 'normalizer': ('normalizer_StandardScaler', {'normalizer__with_mean': True, 'normalizer__with_std': True}), 'rebalance': ('rebalance_NearMiss', {'rebalance__n_neighbors': 1})}, 'score': 0.9231904384036744, ...}, 'history': [{'algorithm': {'bootstrap': False, 'criterion': 'entropy', 'max_depth': 1, 'max_features': 3, 'max_leaf_nodes': 3, 'min_samples_split': 5, 'n_estimators': 50}, 'config_hash': {'algorithm': '752fa095cdab58a238ae606c613606188964cc0c', 'config': 'fd24b065dda6bdeb1077793f9df480ff318c7a37', 'pipeline': '13ea3359c453b8993fcec1e88bc0e19cd0a2b112'}, 'duration': 0.689669132232666, 'iteration': 0, 'loss': 0.6602879519109309, 'max_history_score': 0.3397120480890691, 'max_history_score_std': 0.03346542949100545, 'max_history_step': 'joint', 'pipeline': {'features': ('features_SelectKBest', {'features__k': 4}), 'normalizer': ('normalizer_MinMaxScaler', {}), 'rebalance': ('rebalance_NoneType', {})}, 'score': 0.3397120480890691, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'gini', 'max_depth': 4, 'max_features': 1, 'max_leaf_nodes': 5, 'min_samples_split': 3, 'n_estimators': 25}, 'config_hash': {'algorithm': '9d9de4aee820052ddfe83bfffca420f6b50837d3', 'config': 'fb22f80fb4358ae1ee4c9bd4a83543992be8d806', 'pipeline': '6251ad4bb7a110726a67f90c319f4717ac37a312'}, 'duration': 1.4300940036773682, 'iteration': 1, 'loss': 0.5122196101741096, 'max_history_score': 0.48778038982589045, 'max_history_score_std': 0.05486079759217226, 'max_history_step': 'joint', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 2, 'features__selectkbest__k': 2}), 'normalizer': ('normalizer_StandardScaler', {'normalizer__with_mean': True, 'normalizer__with_std': True}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 5})}, 'score': 0.48778038982589045, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': 4, 'max_features': 1, 'max_leaf_nodes': None, 'min_samples_split': 2, 'n_estimators': 10}, 'config_hash': {'algorithm': '2ed7d27df9a1b2d5e63da76f7cb309616c232022', 'config': '8c97cdb885dd05cfd8c40ee3ac445b61e5c767a8', 'pipeline': 'c0abb5e23a4739d3120740a9519fb36c43eb94d5'}, 'duration': 3.0036678314208984, 'iteration': 2, 'loss': 0.38319264175312906, 'max_history_score': 0.6168073582468709, 'max_history_score_std': 0.05286679173001824, 'max_history_step': 'joint', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 1, 'features__selectkbest__k': 4}), 'normalizer': ('normalizer_PowerTransformer', {}), 'rebalance': ('rebalance_NearMiss', {'rebalance__n_neighbors': 2})}, 'score': 0.6168073582468709, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'entropy', 'max_depth': None, 'max_features': None, 'max_leaf_nodes': 2, 'min_samples_split': 2, 'n_estimators': 100}, 'config_hash': {'algorithm': '17962655e3b76dfcd0843d1e5c2cb7a9db1c6a79', 'config': '16fbb5fd5cfbbacfddf27c61c0c7397a7f6d8ade', 'pipeline': '13ea3359c453b8993fcec1e88bc0e19cd0a2b112'}, 'duration': 1.3447980880737305, 'iteration': 3, 'loss': 0.6768840987778313, 'max_history_score': 0.6168073582468709, 'max_history_score_std': 0.05286679173001824, 'max_history_step': 'joint', 'pipeline': {'features': ('features_SelectKBest', {'features__k': 4}), 'normalizer': ('normalizer_MinMaxScaler', {}), 'rebalance': ('rebalance_NoneType', {})}, 'score': 0.32311590122216866, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'gini', 'max_depth': 2, 'max_features': 2, 'max_leaf_nodes': 2, 'min_samples_split': 3, 'n_estimators': 100}, 'config_hash': {'algorithm': '1ea8965b2247f86950e54510ee6d79399816341b', 'config': 'a77c698197c31308211b854e81a998178941f87d', 'pipeline': 'aaf976c7c663a31fa039582d42f9e07101556a7c'}, 'duration': 2.589430093765259, 'iteration': 4, 'loss': 0.2544808950572157, 'max_history_score': 0.7455191049427843, 'max_history_score_std': 0.04843448308166839, 'max_history_step': 'joint', 'pipeline': {'features': ('features_NoneType', {}), 'normalizer': ('normalizer_PowerTransformer', {}), 'rebalance': ('rebalance_NoneType', {})}, 'score': 0.7455191049427843, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': None, 'max_features': 2, 'max_leaf_nodes': 5, 'min_samples_split': 5, 'n_estimators': 25}, 'config_hash': {'algorithm': 'fd8aeb6a05eaaba41e676d60596c8e0c71b35e0c', 'config': '1fc13606bca3aaf342ca6ea21139cb598b56f8db', 'pipeline': 'f00bd8de05642e026bbba4ad20d3a60088c86b6c'}, 'duration': 1.8779079914093018, 'iteration': 5, 'loss': 0.531551018758381, 'max_history_score': 0.7455191049427843, 'max_history_score_std': 0.04843448308166839, 'max_history_step': 'joint', 'pipeline': {'features': ('features_PCA', {'features__n_components': 2}), 'normalizer': ('normalizer_MinMaxScaler', {}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 5})}, 'score': 0.46844898124161904, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'entropy', 'max_depth': None, 'max_features': 2, 'max_leaf_nodes': None, 'min_samples_split': 2, 'n_estimators': 10}, 'config_hash': {'algorithm': 'a49ecb99e74217d6812f98ead7bc9d1fe4a53ba0', 'config': '6749af1a67b4dbcd2b4719e419d99908063c05e1', 'pipeline': '19bdf19a2eec5febce95ab8fa2a71040d75114aa'}, 'duration': 1.5498578548431396, 'iteration': 6, 'loss': 0.14471329609998995, 'max_history_score': 0.85528670390001, 'max_history_score_std': 0.02213730791268438, 'max_history_step': 'joint', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 4, 'features__selectkbest__k': 3}), 'normalizer': ('normalizer_NoneType', {}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 7})}, 'score': 0.85528670390001, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': 1, 'max_features': 3, 'max_leaf_nodes': 3, 'min_samples_split': 3, 'n_estimators': 75}, 'config_hash': {'algorithm': 'ebfb16234172ae811ff21185ff92bbdbb8f32f14', 'config': 'd92d4ada2394fc132733e176e926ee53acdc6a00', 'pipeline': '8071e7cbf86a5c3056493dc3aa40063aeb28cdfe'}, 'duration': 1.3618149757385254, 'iteration': 7, 'loss': 0.6158612049395463, 'max_history_score': 0.85528670390001, 'max_history_score_std': 0.02213730791268438, 'max_history_step': 'joint', 'pipeline': {'features': ('features_SelectKBest', {'features__k': 4}), 'normalizer': ('normalizer_StandardScaler', {'normalizer__with_mean': True, 'normalizer__with_std': True}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 5})}, 'score': 0.3841387950604537, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'entropy', 'max_depth': 1, 'max_features': 1, 'max_leaf_nodes': 5, 'min_samples_split': 2, 'n_estimators': 100}, 'config_hash': {'algorithm': '896b53c75a2db568fb7b6da3bfca2f7a1535a11b', 'config': 'f0d0b1d2cedc22ae15d9a208a3fc3fc133bf0d3d', 'pipeline': 'c9761c9a33bf75d6dcad0742c421548a7655ccc9'}, 'duration': 2.297278881072998, 'iteration': 8, 'loss': 0.40673663548410355, 'max_history_score': 0.85528670390001, 'max_history_score_std': 0.02213730791268438, 'max_history_step': 'joint', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 2, 'features__selectkbest__k': 4}), 'normalizer': ('normalizer_StandardScaler', {'normalizer__with_mean': False, 'normalizer__with_std': False}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 5})}, 'score': 0.5932633645158965, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'entropy', 'max_depth': 2, 'max_features': None, 'max_leaf_nodes': None, 'min_samples_split': 5, 'n_estimators': 25}, 'config_hash': {'algorithm': '0b0e954757c4f75343a6efb740ad93260ed781ae', 'config': '47584de0e60d0d12c7dbbf0dc60e5aea96e3f4b2', 'pipeline': 'b37ee32d59413053bf9a2a72c8ff7135f3701e05'}, 'duration': 0.7249000072479248, 'iteration': 9, 'loss': 0.6965910020393421, 'max_history_score': 0.85528670390001, 'max_history_score_std': 0.02213730791268438, 'max_history_step': 'joint', 'pipeline': {'features': ('features_SelectKBest', {'features__k': 3}), 'normalizer': ('normalizer_NoneType', {}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 7})}, 'score': 0.3034089979606579, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'gini', 'max_depth': 2, 'max_features': 2, 'max_leaf_nodes': 5, 'min_samples_split': 5, 'n_estimators': 75}, 'config_hash': {'algorithm': 'f1ead1d9e33ea927e1dd27d872a058fa3de4f832', 'config': 'eecb88ee2b1b95d741c1b5c7751534d31aae6a77', 'pipeline': '6746650871e8b61efc9302b092dc05f7cdb179d5'}, 'duration': 5.340634822845459, 'iteration': 10, 'loss': 0.7687016290977936, 'max_history_score': 0.85528670390001, 'max_history_score_std': 0.02213730791268438, 'max_history_step': 'joint', 'pipeline': {'features': ('features_SelectKBest', {'features__k': 3}), 'normalizer': ('normalizer_RobustScaler', {'normalizer__quantile_range': (...), 'normalizer__with_centering': False, 'normalizer__with_scaling': False}), 'rebalance': ('rebalance_CondensedNearestNeighbour', {'rebalance__n_neighbors': 1})}, 'score': 0.23129837090220637, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': 1, 'max_features': 2, 'max_leaf_nodes': 2, 'min_samples_split': 3, 'n_estimators': 75}, 'config_hash': {'algorithm': '531a3bb8ccf0baa06727af4b3de9e62d25e6eabf', 'config': '27a7ed0502b321ab7256b77c8ce79e90cb9da815', 'pipeline': '77e6d84e2217b92b3cf67cc6defef9dd3554cec0'}, 'duration': 1.775357961654663, 'iteration': 11, 'loss': 0.6313818737375694, 'max_history_score': 0.85528670390001, 'max_history_score_std': 0.02213730791268438, 'max_history_step': 'joint', 'pipeline': {'features': ('features_SelectKBest', {'features__k': 4}), 'normalizer': ('normalizer_MinMaxScaler', {}), 'rebalance': ('rebalance_NearMiss', {'rebalance__n_neighbors': 3})}, 'score': 0.3686181262624307, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'entropy', 'max_depth': 4, 'max_features': 3, 'max_leaf_nodes': 2, 'min_samples_split': 3, 'n_estimators': 10}, 'config_hash': {'algorithm': '93518f8ded6074d537900b26be72f8485782f933', 'config': '45f056102dd2d644bd8befa471f17b2311ac7954', 'pipeline': '5240329df25c9a533d025c1a401d49835a501b41'}, 'duration': 3.2622711658477783, 'iteration': 12, 'loss': 0.6120243191353301, 'max_history_score': 0.85528670390001, 'max_history_score_std': 0.02213730791268438, 'max_history_step': 'joint', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 4, 'features__selectkbest__k': 2}), 'normalizer': ('normalizer_PowerTransformer', {}), 'rebalance': ('rebalance_NearMiss', {'rebalance__n_neighbors': 1})}, 'score': 0.38797568086467, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'entropy', 'max_depth': None, 'max_features': 1, 'max_leaf_nodes': 5, 'min_samples_split': 3, 'n_estimators': 75}, 'config_hash': {'algorithm': 'e515d45b764fa43591032874a0ff9c25bf12fddd', 'config': 'ba108323623936872824ed8f1c41d615d25523b3', 'pipeline': '9d823bc0442f21b5ce8af67a5eb1237f64ffc2f8'}, 'duration': 2.5326571464538574, 'iteration': 13, 'loss': 0.6271427382991047, 'max_history_score': 0.85528670390001, 'max_history_score_std': 0.02213730791268438, 'max_history_step': 'joint', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 1, 'features__selectkbest__k': 1}), 'normalizer': ('normalizer_StandardScaler', {'normalizer__with_mean': True, 'normalizer__with_std': True}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 5})}, 'score': 0.3728572617008953, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'entropy', 'max_depth': 3, 'max_features': 2, 'max_leaf_nodes': 2, 'min_samples_split': 3, 'n_estimators': 25}, 'config_hash': {'algorithm': '2808e67f609eba5c8a97f81ac0c9413cd37cf7aa', 'config': 'dde4d3b5f37741629cb58bfc4051ed9f98c8f311', 'pipeline': 'bc52deabf1f5ee60968ba541d9d2574353c30a9c'}, 'duration': 0.7145559787750244, 'iteration': 14, 'loss': 0.6831045572696203, 'max_history_score': 0.85528670390001, 'max_history_score_std': 0.02213730791268438, 'max_history_step': 'joint', 'pipeline': {'features': ('features_SelectKBest', {'features__k': 3}), 'normalizer': ('normalizer_MinMaxScaler', {}), 'rebalance': ('rebalance_NearMiss', {'rebalance__n_neighbors': 1})}, 'score': 0.31689544273037973, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'gini', 'max_depth': 2, 'max_features': 2, 'max_leaf_nodes': None, 'min_samples_split': 5, 'n_estimators': 100}, 'config_hash': {'algorithm': 'b942acdead762d34afeb474bc2fe6f7fd0f23493', 'config': '1080c25b92da3f15a6f8eec003957f7e0a66324f', 'pipeline': 'cfa84fe703dc5bc0bbd2257a6d524fee2693b804'}, 'duration': 2.812459945678711, 'iteration': 15, 'loss': 0.6921421091202761, 'max_history_score': 0.85528670390001, 'max_history_score_std': 0.02213730791268438, 'max_history_step': 'joint', 'pipeline': {'features': ('features_SelectKBest', {'features__k': 2}), 'normalizer': ('normalizer_PowerTransformer', {}), 'rebalance': ('rebalance_NoneType', {})}, 'score': 0.3078578908797239, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'entropy', 'max_depth': 2, 'max_features': 3, 'max_leaf_nodes': 3, 'min_samples_split': 2, 'n_estimators': 75}, 'config_hash': {'algorithm': '250661ce4193a61ef44d2f77694b52b785ff032d', 'config': 'c3e8cf4eca5aafcae4ac31b0449e105ca127ffe2', 'pipeline': 'c4dd111513ea35f97dd3aec3e8e7f6268ce035da'}, 'duration': 1.0555319786071777, 'iteration': 16, 'loss': 1.0, 'max_history_score': 0.85528670390001, 'max_history_score_std': 0.02213730791268438, 'max_history_step': 'joint', 'pipeline': {'features': ('features_PCA', {'features__n_components': 2}), 'normalizer': ('normalizer_RobustScaler', {'normalizer__quantile_range': (...), 'normalizer__with_centering': False, 'normalizer__with_scaling': True}), 'rebalance': ('rebalance_NearMiss', {'rebalance__n_neighbors': 2})}, 'score': 0.0, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'entropy', 'max_depth': 3, 'max_features': 3, 'max_leaf_nodes': None, 'min_samples_split': 3, 'n_estimators': 25}, 'config_hash': {'algorithm': '05ac02bd045c65dc4089894902ad6253661a2692', 'config': '3449b4a1c2e488e26a7195ee9edca19b854ebd33', 'pipeline': '505d3f71b534917375d765e64b0611e7dfb83746'}, 'duration': 5.5412821769714355, 'iteration': 17, 'loss': 0.7289151155121668, 'max_history_score': 0.85528670390001, 'max_history_score_std': 0.02213730791268438, 'max_history_step': 'joint', 'pipeline': {'features': ('features_SelectKBest', {'features__k': 4}), 'normalizer': ('normalizer_MinMaxScaler', {}), 'rebalance': ('rebalance_CondensedNearestNeighbour', {'rebalance__n_neighbors': 2})}, 'score': 0.2710848844878332, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'entropy', 'max_depth': 2, 'max_features': None, 'max_leaf_nodes': None, 'min_samples_split': 2, 'n_estimators': 25}, 'config_hash': {'algorithm': 'de3b3a352ebb260e16c6b213a08c9144d17a744b', 'config': '224987ffdbbb9b6182cff18d8374518b917e4f2e', 'pipeline': '12c89200a558b2f3b91332566f41050143aecbe7'}, 'duration': 2.4646048545837402, 'iteration': 18, 'loss': 0.6545902512995826, 'max_history_score': 0.85528670390001, 'max_history_score_std': 0.02213730791268438, 'max_history_step': 'joint', 'pipeline': {'features': ('features_NoneType', {}), 'normalizer': ('normalizer_PowerTransformer', {}), 'rebalance': ('rebalance_NearMiss', {'rebalance__n_neighbors': 2})}, 'score': 0.3454097487004174, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'gini', 'max_depth': None, 'max_features': 1, 'max_leaf_nodes': None, 'min_samples_split': 3, 'n_estimators': 100}, 'config_hash': {'algorithm': '30ca111584767bbf0464df40b4c928cf7ddf9459', 'config': '97ca7d6a017c721084dec2a5d2e5a67e1e6ae2f0', 'pipeline': '789eca82ea4a42d61927670c538867b745fd81d3'}, 'duration': 7.164499044418335, 'iteration': 19, 'loss': 0.6536825403350528, 'max_history_score': 0.85528670390001, 'max_history_score_std': 0.02213730791268438, 'max_history_step': 'joint', 'pipeline': {'features': ('features_SelectKBest', {'features__k': 3}), 'normalizer': ('normalizer_RobustScaler', {'normalizer__quantile_range': (...), 'normalizer__with_centering': False, 'normalizer__with_scaling': True}), 'rebalance': ('rebalance_CondensedNearestNeighbour', {'rebalance__n_neighbors': 3})}, 'score': 0.3463174596649472, ...}, ...], 'history_hash': ['fd24b065dda6bdeb1077793f9df480ff318c7a37', 'fb22f80fb4358ae1ee4c9bd4a83543992be8d806', '8c97cdb885dd05cfd8c40ee3ac445b61e5c767a8', '16fbb5fd5cfbbacfddf27c61c0c7397a7f6d8ade', 'a77c698197c31308211b854e81a998178941f87d', '1fc13606bca3aaf342ca6ea21139cb598b56f8db', '6749af1a67b4dbcd2b4719e419d99908063c05e1', 'd92d4ada2394fc132733e176e926ee53acdc6a00', 'f0d0b1d2cedc22ae15d9a208a3fc3fc133bf0d3d', '47584de0e60d0d12c7dbbf0dc60e5aea96e3f4b2', 'eecb88ee2b1b95d741c1b5c7751534d31aae6a77', '27a7ed0502b321ab7256b77c8ce79e90cb9da815', '45f056102dd2d644bd8befa471f17b2311ac7954', 'ba108323623936872824ed8f1c41d615d25523b3', 'dde4d3b5f37741629cb58bfc4051ed9f98c8f311', '1080c25b92da3f15a6f8eec003957f7e0a66324f', 'c3e8cf4eca5aafcae4ac31b0449e105ca127ffe2', '3449b4a1c2e488e26a7195ee9edca19b854ebd33', '224987ffdbbb9b6182cff18d8374518b917e4f2e', '97ca7d6a017c721084dec2a5d2e5a67e1e6ae2f0', ...], 'history_index': {'00e8f4ca31525b847c5f1d5de869962edbe23b64': 99, '01b68ec8d6fe15ffdadf1adfd0d809307d3ce41e': 81, '05465becb12810ce291074be22a0275a42efbea8': 52, '064f53edf4748bb2df4ff59f147331aad21219e1': 48, '087efef4a19f272562d2d445dac0edd8096ba2fa': 58, '0fd4d71ca3a89c7d14af5087f2a2e2c1b1975351': 51, '1080c25b92da3f15a6f8eec003957f7e0a66324f': 15, '10ca1ab51b6af0696dab2c8cbaf8de5e3812a6de': 78, '10cb7f1ca9feb52539f61b654f31107801dadc1c': 89, '143679b59e16961765e77616142572b6ded0ee72': 62, ...}, 'iteration': 106, 'max_history_score': 0.9231904384036744, 'max_history_score_std': 0.03040515884196498, 'max_history_step': 'joint'}, config={'algorithm': 'RandomForest', 'seed': 42, 'time': 300}, step='joint')
     45                 y,
     46                 cv=10,
     47                 n_jobs=-1,
     48                 return_estimator=False,
     49                 return_train_score=False,
---> 50                 verbose=0)
     51         score = np.mean(scores['test_score'])
     52         std = np.std(scores['test_score'])
     53         status = STATUS_OK
     54     except Exception as e:

...........................................................................
/home/aquemy/.local/lib/python2.7/site-packages/sklearn/model_selection/_validation.py in cross_validate(estimator=Pipeline(memory=None,
     steps=[('rebalance', ... random_state=42, verbose=0, warm_start=False))]), X=array([[ 0.,  0.,  5., ...,  0.,  0.,  0.],
    ...0.],
       [ 0.,  0., 10., ..., 12.,  1.,  0.]]), y=array([0, 1, 2, ..., 8, 9, 8]), groups=None, scoring=None, cv=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1, verbose=0, fit_params=None, pre_dispatch='2*n_jobs', return_train_score=False, return_estimator=False, error_score='raise-deprecating')
    235         delayed(_fit_and_score)(
    236             clone(estimator), X, y, scorers, train, test, verbose, None,
    237             fit_params, return_train_score=return_train_score,
    238             return_times=True, return_estimator=return_estimator,
    239             error_score=error_score)
--> 240         for train, test in cv.split(X, y, groups))
        cv.split = <bound method StratifiedKFold.split of Stratifie...d(n_splits=10, random_state=None, shuffle=False)>
        X = array([[ 0.,  0.,  5., ...,  0.,  0.,  0.],
    ...0.],
       [ 0.,  0., 10., ..., 12.,  1.,  0.]])
        y = array([0, 1, 2, ..., 8, 9, 8])
        groups = None
    241 
    242     zipped_scores = list(zip(*scores))
    243     if return_train_score:
    244         train_scores = zipped_scores.pop(0)

...........................................................................
/home/aquemy/.local/lib/python2.7/site-packages/sklearn/externals/joblib/parallel.py in __call__(self=Parallel(n_jobs=-1), iterable=<generator object <genexpr>>)
    925                 # No need to wait for async callbacks to trigger to
    926                 # consumption.
    927                 self._iterating = False
    928 
    929             with self._backend.retrieval_context():
--> 930                 self.retrieve()
        self.retrieve = <bound method Parallel.retrieve of Parallel(n_jobs=-1)>
    931             # Make sure that we get a last message telling us we are done
    932             elapsed_time = time.time() - self._start_time
    933             self._print('Done %3i out of %3i | elapsed: %s finished',
    934                         (len(self._output), len(self._output),

---------------------------------------------------------------------------
Joblib worker traceback:
---------------------------------------------------------------------------
ValueError                                         Mon Jun 17 13:10:04 2019
PID: 20578                                  Python 2.7.15+: /usr/bin/python
...........................................................................
/home/aquemy/.local/lib/python2.7/site-packages/sklearn/externals/joblib/parallel.py in __call__(self=<sklearn.externals.joblib.parallel.BatchedCalls object>)
    220     def __call__(self):
    221         # Set the default nested backend to self._backend but do not set the
    222         # change the default number of processes to -1
    223         with parallel_backend(self._backend, n_jobs=self._n_jobs):
    224             return [func(*args, **kwargs)
--> 225                     for func, args, kwargs in self.items]
        func = <function _fit_and_score>
        args = (Pipeline(memory=None,
     steps=[('rebalance', ... random_state=42, verbose=0, warm_start=False))]), array([[ 0.,  0.,  5., ...,  0.,  0.,  0.],
    ...0.],
       [ 0.,  0., 10., ..., 12.,  1.,  0.]]), array([0, 1, 2, ..., 8, 9, 8]), {'score': <function _passthrough_scorer>}, array([ 169,  176,  178, ..., 1794, 1795, 1796]), array([  0,   1,   2,   3,   4,   5,   6,   7,  ..., 181, 186, 188, 189, 190,
       194, 195, 198]), 0, None, None)
        kwargs = {'error_score': 'raise-deprecating', 'return_estimator': False, 'return_times': True, 'return_train_score': False}
        self.items = [(<function _fit_and_score>, (Pipeline(memory=None,
     steps=[('rebalance', ... random_state=42, verbose=0, warm_start=False))]), array([[ 0.,  0.,  5., ...,  0.,  0.,  0.],
    ...0.],
       [ 0.,  0., 10., ..., 12.,  1.,  0.]]), array([0, 1, 2, ..., 8, 9, 8]), {'score': <function _passthrough_scorer>}, array([ 169,  176,  178, ..., 1794, 1795, 1796]), array([  0,   1,   2,   3,   4,   5,   6,   7,  ..., 181, 186, 188, 189, 190,
       194, 195, 198]), 0, None, None), {'error_score': 'raise-deprecating', 'return_estimator': False, 'return_times': True, 'return_train_score': False})]
    226 
    227     def __len__(self):
    228         return self._size
    229 

...........................................................................
/home/aquemy/.local/lib/python2.7/site-packages/sklearn/model_selection/_validation.py in _fit_and_score(estimator=Pipeline(memory=None,
     steps=[('rebalance', ... random_state=42, verbose=0, warm_start=False))]), X=array([[ 0.,  0.,  5., ...,  0.,  0.,  0.],
    ...0.],
       [ 0.,  0., 10., ..., 12.,  1.,  0.]]), y=array([0, 1, 2, ..., 8, 9, 8]), scorer={'score': <function _passthrough_scorer>}, train=array([ 169,  176,  178, ..., 1794, 1795, 1796]), test=array([  0,   1,   2,   3,   4,   5,   6,   7,  ..., 181, 186, 188, 189, 190,
       194, 195, 198]), verbose=0, parameters=None, fit_params={}, return_train_score=False, return_parameters=False, return_n_test_samples=False, return_times=True, return_estimator=False, error_score='raise-deprecating')
    523 
    524     try:
    525         if y_train is None:
    526             estimator.fit(X_train, **fit_params)
    527         else:
--> 528             estimator.fit(X_train, y_train, **fit_params)
        estimator.fit = <bound method Pipeline.fit of Pipeline(memory=No...random_state=42, verbose=0, warm_start=False))])>
        X_train = array([[ 0.,  0.,  6., ...,  9.,  4.,  0.],
    ...0.],
       [ 0.,  0., 10., ..., 12.,  1.,  0.]])
        y_train = array([9, 5, 0, ..., 8, 9, 8])
        fit_params = {}
    529 
    530     except Exception as e:
    531         # Note fit time as time until error
    532         fit_time = time.time() - start_time

...........................................................................
/usr/local/lib/python2.7/dist-packages/imblearn/pipeline.py in fit(self=Pipeline(memory=None,
     steps=[('rebalance', ... random_state=42, verbose=0, warm_start=False))]), X=array([[ 0.,  0.,  6., ...,  9.,  4.,  0.],
    ...0.],
       [ 0.,  0., 10., ..., 12.,  1.,  0.]]), y=array([9, 5, 0, ..., 8, 9, 8]), **fit_params={})
    234             This estimator
    235 
    236         """
    237         Xt, yt, fit_params = self._fit(X, y, **fit_params)
    238         if self._final_estimator is not None:
--> 239             self._final_estimator.fit(Xt, yt, **fit_params)
        self._final_estimator.fit = <bound method RandomForestClassifier.fit of Rand...e, random_state=42, verbose=0, warm_start=False)>
        Xt = array([[-1.07895333e+01,  5.40091592e+00],
     ...+01],
       [-2.35741537e+01,  5.23191902e-01]])
        yt = array([0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,...9, 9,
       9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9])
        fit_params = {}
    240         return self
    241 
    242     def fit_transform(self, X, y=None, **fit_params):
    243         """Fit the model and transform with the final estimator

...........................................................................
/home/aquemy/.local/lib/python2.7/site-packages/sklearn/ensemble/forest.py in fit(self=RandomForestClassifier(bootstrap=False, class_we...se, random_state=42, verbose=0, warm_start=False), X=array([[-1.07895336e+01,  5.40091610e+00],
     ...2.35741539e+01,  5.23191929e-01]], dtype=float32), y=array([[0.],
       [0.],
       [1.],
       [1...    [9.],
       [9.],
       [9.],
       [9.]]), sample_weight=None)
    328             trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,
    329                              **_joblib_parallel_args(prefer='threads'))(
    330                 delayed(_parallel_build_trees)(
    331                     t, self, X, y, sample_weight, i, len(trees),
    332                     verbose=self.verbose, class_weight=self.class_weight)
--> 333                 for i, t in enumerate(trees))
        i = 74
    334 
    335             # Collect newly grown trees
    336             self.estimators_.extend(trees)
    337 

...........................................................................
/home/aquemy/.local/lib/python2.7/site-packages/sklearn/externals/joblib/parallel.py in __call__(self=Parallel(n_jobs=1), iterable=<generator object <genexpr>>)
    912             # self._original_iterator is None, then this means either
    913             # that pre_dispatch == "all", n_jobs == 1 or that the first batch
    914             # was very quick and its callback already dispatched all the
    915             # remaining jobs.
    916             self._iterating = False
--> 917             if self.dispatch_one_batch(iterator):
        self.dispatch_one_batch = <bound method Parallel.dispatch_one_batch of Parallel(n_jobs=1)>
        iterator = <generator object <genexpr>>
    918                 self._iterating = self._original_iterator is not None
    919 
    920             while self.dispatch_one_batch(iterator):
    921                 pass

...........................................................................
/home/aquemy/.local/lib/python2.7/site-packages/sklearn/externals/joblib/parallel.py in dispatch_one_batch(self=Parallel(n_jobs=1), iterator=<generator object <genexpr>>)
    754                                  self._pickle_cache)
    755             if len(tasks) == 0:
    756                 # No more tasks available in the iterator: tell caller to stop.
    757                 return False
    758             else:
--> 759                 self._dispatch(tasks)
        self._dispatch = <bound method Parallel._dispatch of Parallel(n_jobs=1)>
        tasks = <sklearn.externals.joblib.parallel.BatchedCalls object>
    760                 return True
    761 
    762     def _print(self, msg, msg_args):
    763         """Display the message on stout or stderr depending on verbosity"""

...........................................................................
/home/aquemy/.local/lib/python2.7/site-packages/sklearn/externals/joblib/parallel.py in _dispatch(self=Parallel(n_jobs=1), batch=<sklearn.externals.joblib.parallel.BatchedCalls object>)
    711 
    712         dispatch_timestamp = time.time()
    713         cb = BatchCompletionCallBack(dispatch_timestamp, len(batch), self)
    714         with self._lock:
    715             job_idx = len(self._jobs)
--> 716             job = self._backend.apply_async(batch, callback=cb)
        job = undefined
        self._backend.apply_async = <bound method SequentialBackend.apply_async of <...lib._parallel_backends.SequentialBackend object>>
        batch = <sklearn.externals.joblib.parallel.BatchedCalls object>
        cb = <sklearn.externals.joblib.parallel.BatchCompletionCallBack object>
    717             # A job can complete so quickly than its callback is
    718             # called before we get here, causing self._jobs to
    719             # grow. To ensure correct results ordering, .insert is
    720             # used (rather than .append) in the following line

...........................................................................
/home/aquemy/.local/lib/python2.7/site-packages/sklearn/externals/joblib/_parallel_backends.py in apply_async(self=<sklearn.externals.joblib._parallel_backends.SequentialBackend object>, func=<sklearn.externals.joblib.parallel.BatchedCalls object>, callback=<sklearn.externals.joblib.parallel.BatchCompletionCallBack object>)
    177             raise ValueError('n_jobs == 0 in Parallel has no meaning')
    178         return 1
    179 
    180     def apply_async(self, func, callback=None):
    181         """Schedule a func to be run"""
--> 182         result = ImmediateResult(func)
        result = undefined
        func = <sklearn.externals.joblib.parallel.BatchedCalls object>
    183         if callback:
    184             callback(result)
    185         return result
    186 

...........................................................................
/home/aquemy/.local/lib/python2.7/site-packages/sklearn/externals/joblib/_parallel_backends.py in __init__(self=<sklearn.externals.joblib._parallel_backends.ImmediateResult object>, batch=<sklearn.externals.joblib.parallel.BatchedCalls object>)
    544 
    545 class ImmediateResult(object):
    546     def __init__(self, batch):
    547         # Don't delay the application, to avoid keeping the input
    548         # arguments in memory
--> 549         self.results = batch()
        self.results = undefined
        batch = <sklearn.externals.joblib.parallel.BatchedCalls object>
    550 
    551     def get(self):
    552         return self.results
    553 

...........................................................................
/home/aquemy/.local/lib/python2.7/site-packages/sklearn/externals/joblib/parallel.py in __call__(self=<sklearn.externals.joblib.parallel.BatchedCalls object>)
    220     def __call__(self):
    221         # Set the default nested backend to self._backend but do not set the
    222         # change the default number of processes to -1
    223         with parallel_backend(self._backend, n_jobs=self._n_jobs):
    224             return [func(*args, **kwargs)
--> 225                     for func, args, kwargs in self.items]
        func = <function _parallel_build_trees>
        args = (DecisionTreeClassifier(class_weight=None, criter...=False, random_state=1608637542, splitter='best'), RandomForestClassifier(bootstrap=False, class_we...se, random_state=42, verbose=0, warm_start=False), array([[-1.07895336e+01,  5.40091610e+00],
     ...2.35741539e+01,  5.23191929e-01]], dtype=float32), array([[0.],
       [0.],
       [1.],
       [1...    [9.],
       [9.],
       [9.],
       [9.]]), None, 0, 75)
        kwargs = {'class_weight': None, 'verbose': 0}
        self.items = [(<function _parallel_build_trees>, (DecisionTreeClassifier(class_weight=None, criter...=False, random_state=1608637542, splitter='best'), RandomForestClassifier(bootstrap=False, class_we...se, random_state=42, verbose=0, warm_start=False), array([[-1.07895336e+01,  5.40091610e+00],
     ...2.35741539e+01,  5.23191929e-01]], dtype=float32), array([[0.],
       [0.],
       [1.],
       [1...    [9.],
       [9.],
       [9.],
       [9.]]), None, 0, 75), {'class_weight': None, 'verbose': 0})]
    226 
    227     def __len__(self):
    228         return self._size
    229 

...........................................................................
/home/aquemy/.local/lib/python2.7/site-packages/sklearn/ensemble/forest.py in _parallel_build_trees(tree=DecisionTreeClassifier(class_weight=None, criter...=False, random_state=1608637542, splitter='best'), forest=RandomForestClassifier(bootstrap=False, class_we...se, random_state=42, verbose=0, warm_start=False), X=array([[-1.07895336e+01,  5.40091610e+00],
     ...2.35741539e+01,  5.23191929e-01]], dtype=float32), y=array([[0.],
       [0.],
       [1.],
       [1...    [9.],
       [9.],
       [9.],
       [9.]]), sample_weight=None, tree_idx=0, n_trees=75, verbose=0, class_weight=None)
    116         elif class_weight == 'balanced_subsample':
    117             curr_sample_weight *= compute_sample_weight('balanced', y, indices)
    118 
    119         tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)
    120     else:
--> 121         tree.fit(X, y, sample_weight=sample_weight, check_input=False)
        tree.fit = <bound method DecisionTreeClassifier.fit of Deci...False, random_state=1608637542, splitter='best')>
        X = array([[-1.07895336e+01,  5.40091610e+00],
     ...2.35741539e+01,  5.23191929e-01]], dtype=float32)
        y = array([[0.],
       [0.],
       [1.],
       [1...    [9.],
       [9.],
       [9.],
       [9.]])
        sample_weight = None
    122 
    123     return tree
    124 
    125 

...........................................................................
/home/aquemy/.local/lib/python2.7/site-packages/sklearn/tree/tree.py in fit(self=DecisionTreeClassifier(class_weight=None, criter...=False, random_state=1608637542, splitter='best'), X=array([[-1.07895336e+01,  5.40091610e+00],
     ...2.35741539e+01,  5.23191929e-01]], dtype=float32), y=array([[0.],
       [0.],
       [1.],
       [1...    [9.],
       [9.],
       [9.],
       [9.]]), sample_weight=None, check_input=False, X_idx_sorted=None)
    796 
    797         super(DecisionTreeClassifier, self).fit(
    798             X, y,
    799             sample_weight=sample_weight,
    800             check_input=check_input,
--> 801             X_idx_sorted=X_idx_sorted)
        X_idx_sorted = None
    802         return self
    803 
    804     def predict_proba(self, X, check_input=True):
    805         """Predict class probabilities of the input samples X.

...........................................................................
/home/aquemy/.local/lib/python2.7/site-packages/sklearn/tree/tree.py in fit(self=DecisionTreeClassifier(class_weight=None, criter...=False, random_state=1608637542, splitter='best'), X=array([[-1.07895336e+01,  5.40091610e+00],
     ...2.35741539e+01,  5.23191929e-01]], dtype=float32), y=array([[0.],
       [0.],
       [1.],
       [1...    [9.],
       [9.],
       [9.],
       [9.]]), sample_weight=None, check_input=False, X_idx_sorted=None)
    237         if not 0 <= self.min_weight_fraction_leaf <= 0.5:
    238             raise ValueError("min_weight_fraction_leaf must in [0, 0.5]")
    239         if max_depth <= 0:
    240             raise ValueError("max_depth must be greater than zero. ")
    241         if not (0 < max_features <= self.n_features_):
--> 242             raise ValueError("max_features must be in (0, n_features]")
    243         if not isinstance(max_leaf_nodes, (numbers.Integral, np.integer)):
    244             raise ValueError("max_leaf_nodes must be integral number but was "
    245                              "%r" % max_leaf_nodes)
    246         if -1 < max_leaf_nodes < 2:

ValueError: max_features must be in (0, n_features]
___________________________________________________________________________
Best score: 0.923190438404 (0.030405158842) [J] | Score: 0.0 (0.0) [J]
Best score: 0.923190438404 (0.030405158842) [J] | Score: 0.253097225066 (0.0141137865415) [J]
Best score: 0.923190438404 (0.030405158842) [J] | Score: 0.760580036156 (0.0566344977199) [J]
Best score: 0.923190438404 (0.030405158842) [J] | Score: 0.756709277108 (0.0481661958365) [J]
Best score: 0.923190438404 (0.030405158842) [J] | Score: 0.859100120066 (0.0378887817407) [J]
JoblibValueError
___________________________________________________________________________
...........................................................................
/home/aquemy/dev/dp_hyperparameters/extension/main.py in <module>()
     27 
     28     serializer.serialize_results(scenario, policy)
     29 
     30 if __name__ == "__main__":
     31     args = cli.parse_args()
---> 32     main(args)

...........................................................................
/home/aquemy/dev/dp_hyperparameters/extension/main.py in main(args=Namespace(customize=[(['control', 'seed'], '42')...='./scenarios/rf_digits_joint.yaml', verbosity=0))
     21         test_size=0.4, 
     22         random_state=scenario['control']['seed']
     23     )
     24 
     25     policy = policies.initiate(scenario['setup']['policy'], config)
---> 26     policy.run(X,y)
        policy.run = <bound method Joint.run of <experiment.policies.joint.Joint object>>
        X = array([[ 0.,  0.,  5., ...,  0.,  0.,  0.],
    ...0.],
       [ 0.,  0., 10., ..., 12.,  1.,  0.]])
        y = array([0, 1, 2, ..., 8, 9, 8])
     27 
     28     serializer.serialize_results(scenario, policy)
     29 
     30 if __name__ == "__main__":

...........................................................................
/home/aquemy/dev/dp_hyperparameters/extension/experiment/policies/joint.py in run(self=<experiment.policies.joint.Joint object>, X=array([[ 0.,  0.,  5., ...,  0.,  0.,  0.],
    ...0.],
       [ 0.,  0., 10., ..., 12.,  1.,  0.]]), y=array([0, 1, 2, ..., 8, 9, 8]))
     32             algo=tpe.suggest, 
     33             max_evals=None,
     34             max_time=self.config['time'],     
     35             trials=trials,
     36             show_progressbar=False,
---> 37             verbose=0
     38         )
     39 
     40         best_config = self.context['best_config']
     41         super(Joint, self).display_step_results(best_config)

...........................................................................
/home/aquemy/dev/dp_hyperparameters/extension/hyperopt/fmin.py in fmin(fn=<functools.partial object>, space={'algorithm': {'bootstrap': <hyperopt.pyll.base.Apply object>, 'criterion': <hyperopt.pyll.base.Apply object>, 'max_depth': <hyperopt.pyll.base.Apply object>, 'max_features': <hyperopt.pyll.base.Apply object>, 'max_leaf_nodes': <hyperopt.pyll.base.Apply object>, 'min_samples_split': <hyperopt.pyll.base.Apply object>, 'n_estimators': <hyperopt.pyll.base.Apply object>}, 'pipeline': {'features': <hyperopt.pyll.base.Apply object>, 'normalizer': <hyperopt.pyll.base.Apply object>, 'rebalance': <hyperopt.pyll.base.Apply object>}}, algo=<function suggest>, max_evals=9223372036854775807, max_time=300, trials=<hyperopt.base.Trials object>, rstate=<mtrand.RandomState object>, allow_trials_fmin=True, pass_expr_memo_ctrl=None, catch_eval_exceptions=False, verbose=0, return_argmin=True, points_to_evaluate=None, max_queue_len=1, show_progressbar=False)
    406             pass_expr_memo_ctrl=pass_expr_memo_ctrl,
    407             verbose=verbose,
    408             catch_eval_exceptions=catch_eval_exceptions,
    409             return_argmin=return_argmin,
    410             show_progressbar=show_progressbar,
--> 411             max_time=max_time
        max_time = 300
    412         )
    413 
    414     if trials is None:
    415         if points_to_evaluate is None:

...........................................................................
/home/aquemy/dev/dp_hyperparameters/extension/hyperopt/base.py in fmin(self=<hyperopt.base.Trials object>, fn=<functools.partial object>, space={'algorithm': {'bootstrap': <hyperopt.pyll.base.Apply object>, 'criterion': <hyperopt.pyll.base.Apply object>, 'max_depth': <hyperopt.pyll.base.Apply object>, 'max_features': <hyperopt.pyll.base.Apply object>, 'max_leaf_nodes': <hyperopt.pyll.base.Apply object>, 'min_samples_split': <hyperopt.pyll.base.Apply object>, 'n_estimators': <hyperopt.pyll.base.Apply object>}, 'pipeline': {'features': <hyperopt.pyll.base.Apply object>, 'normalizer': <hyperopt.pyll.base.Apply object>, 'rebalance': <hyperopt.pyll.base.Apply object>}}, algo=<function suggest>, max_evals=9223372036854775807, max_time=300, rstate=<mtrand.RandomState object>, verbose=0, pass_expr_memo_ctrl=None, catch_eval_exceptions=False, return_argmin=True, show_progressbar=False)
    636             verbose=verbose,
    637             allow_trials_fmin=False,  # -- prevent recursion
    638             pass_expr_memo_ctrl=pass_expr_memo_ctrl,
    639             catch_eval_exceptions=catch_eval_exceptions,
    640             return_argmin=return_argmin,
--> 641             show_progressbar=show_progressbar)
        show_progressbar = False
    642 
    643 
    644 def trials_from_docs(docs, validate=True, **kwargs):
    645     """Construct a Trials base class instance from a list of trials documents

...........................................................................
/home/aquemy/dev/dp_hyperparameters/extension/hyperopt/fmin.py in fmin(fn=<functools.partial object>, space={'algorithm': {'bootstrap': <hyperopt.pyll.base.Apply object>, 'criterion': <hyperopt.pyll.base.Apply object>, 'max_depth': <hyperopt.pyll.base.Apply object>, 'max_features': <hyperopt.pyll.base.Apply object>, 'max_leaf_nodes': <hyperopt.pyll.base.Apply object>, 'min_samples_split': <hyperopt.pyll.base.Apply object>, 'n_estimators': <hyperopt.pyll.base.Apply object>}, 'pipeline': {'features': <hyperopt.pyll.base.Apply object>, 'normalizer': <hyperopt.pyll.base.Apply object>, 'rebalance': <hyperopt.pyll.base.Apply object>}}, algo=<function suggest>, max_evals=9223372036854775807, max_time=300, trials=<hyperopt.base.Trials object>, rstate=<mtrand.RandomState object>, allow_trials_fmin=False, pass_expr_memo_ctrl=None, catch_eval_exceptions=False, verbose=0, return_argmin=True, points_to_evaluate=None, max_queue_len=1, show_progressbar=False)
    426                     verbose=verbose,
    427                     max_queue_len=max_queue_len,
    428                     show_progressbar=show_progressbar,
    429                     max_time=max_time)
    430     rval.catch_eval_exceptions = catch_eval_exceptions
--> 431     rval.exhaust()
        rval.exhaust = <bound method FMinIter.exhaust of <hyperopt.fmin.FMinIter object>>
    432     if return_argmin:
    433         return trials.argmin
    434     elif len(trials) > 0:
    435         # Only if there are some succesfull trail runs, return the best point in the evaluation space

...........................................................................
/home/aquemy/dev/dp_hyperparameters/extension/hyperopt/fmin.py in exhaust(self=<hyperopt.fmin.FMinIter object>)
    273             raise StopIteration()
    274         return self.trials
    275 
    276     def exhaust(self):
    277         n_done = len(self.trials)
--> 278         self.run(self.max_evals - n_done, block_until_done=self.asynchronous)
        self.run = <bound method FMinIter.run of <hyperopt.fmin.FMinIter object>>
        self.max_evals = 9223372036854775807
        n_done = 0
        self.asynchronous = False
    279         self.trials.refresh()
    280         return self
    281 
    282 

...........................................................................
/home/aquemy/dev/dp_hyperparameters/extension/hyperopt/fmin.py in run(self=<hyperopt.fmin.FMinIter object>, N=9223372036854775807, block_until_done=False)
    232                     if self.asynchronous:
    233                         # -- wait for workers to fill in the trials
    234                         time.sleep(self.poll_interval_secs)
    235                     else:
    236                         # -- loop over trials and do the jobs directly
--> 237                         self.serial_evaluate()
        self.serial_evaluate = <bound method FMinIter.serial_evaluate of <hyperopt.fmin.FMinIter object>>
    238                     try:
    239                         res = [d['result']['loss'] for d in
    240                                          self.trials.trials if
    241                                          d['result']['status'] == 'ok']

...........................................................................
/home/aquemy/dev/dp_hyperparameters/extension/hyperopt/fmin.py in serial_evaluate(self=<hyperopt.fmin.FMinIter object>, N=-1)
    138                 trial['book_time'] = now
    139                 trial['refresh_time'] = now
    140                 spec = base.spec_from_misc(trial['misc'])
    141                 ctrl = base.Ctrl(self.trials, current_trial=trial)
    142                 try:
--> 143                     result = self.domain.evaluate(spec, ctrl)
        result = undefined
        self.domain.evaluate = <bound method Domain.evaluate of <hyperopt.base.Domain object>>
        spec = {'bootstrap': 1, 'criterion': 0, 'features': 1, 'features_PCA_features__n_components': 0, 'max_depth': 1, 'max_features': 2, 'max_leaf_nodes': 3, 'min_samples_split': 2, 'n_estimators': 3, 'normalizer': 1, ...}
        ctrl = <hyperopt.base.Ctrl object>
    144                 except Exception as e:
    145                     logger.info('job exception: %s' % str(e))
    146                     trial['state'] = base.JOB_STATE_ERROR
    147                     trial['misc']['error'] = (str(type(e)), str(e))

...........................................................................
/home/aquemy/dev/dp_hyperparameters/extension/hyperopt/base.py in evaluate(self=<hyperopt.base.Domain object>, config={'bootstrap': 1, 'criterion': 0, 'features': 1, 'features_PCA_features__n_components': 0, 'max_depth': 1, 'max_features': 2, 'max_leaf_nodes': 3, 'min_samples_split': 2, 'n_estimators': 3, 'normalizer': 1, ...}, ctrl=<hyperopt.base.Ctrl object>, attach_attachments=True)
    841             #    or the normal Python part (self.fn)
    842             pyll_rval = pyll.rec_eval(
    843                 self.expr,
    844                 memo=memo,
    845                 print_node_on_error=self.rec_eval_print_node_on_error)
--> 846             rval = self.fn(pyll_rval)
        rval = undefined
        self.fn = <functools.partial object>
        pyll_rval = {'algorithm': {'bootstrap': False, 'criterion': 'gini', 'max_depth': 2, 'max_features': 3, 'max_leaf_nodes': None, 'min_samples_split': 5, 'n_estimators': 75}, 'pipeline': {'features': ('features_PCA', {'features__n_components': 1}), 'normalizer': ('normalizer_StandardScaler', {'normalizer__with_mean': False, 'normalizer__with_std': False}), 'rebalance': ('rebalance_CondensedNearestNeighbour', {'rebalance__n_neighbors': 2})}}
    847 
    848         if isinstance(rval, (float, int, np.number)):
    849             dict_rval = {'loss': float(rval), 'status': STATUS_OK}
    850         else:

...........................................................................
/home/aquemy/dev/dp_hyperparameters/extension/experiment/objective.py in objective_joint(wconfig={'algorithm': {'bootstrap': False, 'criterion': 'gini', 'max_depth': 2, 'max_features': 3, 'max_leaf_nodes': None, 'min_samples_split': 5, 'n_estimators': 75}, 'pipeline': {'features': ('features_PCA', {'features__n_components': 1}), 'normalizer': ('normalizer_StandardScaler', {'normalizer__with_mean': False, 'normalizer__with_std': False}), 'rebalance': ('rebalance_CondensedNearestNeighbour', {'rebalance__n_neighbors': 2})}}, algorithm='RandomForest', X=array([[ 0.,  0.,  5., ...,  0.,  0.,  0.],
    ...0.],
       [ 0.,  0., 10., ..., 12.,  1.,  0.]]), y=array([0, 1, 2, ..., 8, 9, 8]), context={'baseline_score': 0.9272021217853512, 'baseline_score_std': 0.026919033284817703, 'best_config': {'algorithm': {'bootstrap': True, 'criterion': 'entropy', 'max_depth': None, 'max_features': None, 'max_leaf_nodes': None, 'min_samples_split': 3, 'n_estimators': 75}, 'config_hash': {'algorithm': 'f42e45bee34ac9973699212f6c8b845daea9383a', 'config': 'ae61cfde4c8b4c792e42d6b6be4af4ffb3d90e13', 'pipeline': '15ff3d6270ac899763bb3f72417c48bcd56aa7d8'}, 'duration': 8.20555305480957, 'iteration': 65, 'loss': 0.07680956159632557, 'max_history_score': 0.9231904384036744, 'max_history_score_std': 0.03040515884196498, 'max_history_step': 'joint', 'pipeline': {'features': ('features_NoneType', {}), 'normalizer': ('normalizer_StandardScaler', {'normalizer__with_mean': True, 'normalizer__with_std': True}), 'rebalance': ('rebalance_NearMiss', {'rebalance__n_neighbors': 1})}, 'score': 0.9231904384036744, ...}, 'history': [{'algorithm': {'bootstrap': False, 'criterion': 'entropy', 'max_depth': 1, 'max_features': 3, 'max_leaf_nodes': 3, 'min_samples_split': 5, 'n_estimators': 50}, 'config_hash': {'algorithm': '752fa095cdab58a238ae606c613606188964cc0c', 'config': 'fd24b065dda6bdeb1077793f9df480ff318c7a37', 'pipeline': '13ea3359c453b8993fcec1e88bc0e19cd0a2b112'}, 'duration': 0.689669132232666, 'iteration': 0, 'loss': 0.6602879519109309, 'max_history_score': 0.3397120480890691, 'max_history_score_std': 0.03346542949100545, 'max_history_step': 'joint', 'pipeline': {'features': ('features_SelectKBest', {'features__k': 4}), 'normalizer': ('normalizer_MinMaxScaler', {}), 'rebalance': ('rebalance_NoneType', {})}, 'score': 0.3397120480890691, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'gini', 'max_depth': 4, 'max_features': 1, 'max_leaf_nodes': 5, 'min_samples_split': 3, 'n_estimators': 25}, 'config_hash': {'algorithm': '9d9de4aee820052ddfe83bfffca420f6b50837d3', 'config': 'fb22f80fb4358ae1ee4c9bd4a83543992be8d806', 'pipeline': '6251ad4bb7a110726a67f90c319f4717ac37a312'}, 'duration': 1.4300940036773682, 'iteration': 1, 'loss': 0.5122196101741096, 'max_history_score': 0.48778038982589045, 'max_history_score_std': 0.05486079759217226, 'max_history_step': 'joint', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 2, 'features__selectkbest__k': 2}), 'normalizer': ('normalizer_StandardScaler', {'normalizer__with_mean': True, 'normalizer__with_std': True}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 5})}, 'score': 0.48778038982589045, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': 4, 'max_features': 1, 'max_leaf_nodes': None, 'min_samples_split': 2, 'n_estimators': 10}, 'config_hash': {'algorithm': '2ed7d27df9a1b2d5e63da76f7cb309616c232022', 'config': '8c97cdb885dd05cfd8c40ee3ac445b61e5c767a8', 'pipeline': 'c0abb5e23a4739d3120740a9519fb36c43eb94d5'}, 'duration': 3.0036678314208984, 'iteration': 2, 'loss': 0.38319264175312906, 'max_history_score': 0.6168073582468709, 'max_history_score_std': 0.05286679173001824, 'max_history_step': 'joint', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 1, 'features__selectkbest__k': 4}), 'normalizer': ('normalizer_PowerTransformer', {}), 'rebalance': ('rebalance_NearMiss', {'rebalance__n_neighbors': 2})}, 'score': 0.6168073582468709, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'entropy', 'max_depth': None, 'max_features': None, 'max_leaf_nodes': 2, 'min_samples_split': 2, 'n_estimators': 100}, 'config_hash': {'algorithm': '17962655e3b76dfcd0843d1e5c2cb7a9db1c6a79', 'config': '16fbb5fd5cfbbacfddf27c61c0c7397a7f6d8ade', 'pipeline': '13ea3359c453b8993fcec1e88bc0e19cd0a2b112'}, 'duration': 1.3447980880737305, 'iteration': 3, 'loss': 0.6768840987778313, 'max_history_score': 0.6168073582468709, 'max_history_score_std': 0.05286679173001824, 'max_history_step': 'joint', 'pipeline': {'features': ('features_SelectKBest', {'features__k': 4}), 'normalizer': ('normalizer_MinMaxScaler', {}), 'rebalance': ('rebalance_NoneType', {})}, 'score': 0.32311590122216866, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'gini', 'max_depth': 2, 'max_features': 2, 'max_leaf_nodes': 2, 'min_samples_split': 3, 'n_estimators': 100}, 'config_hash': {'algorithm': '1ea8965b2247f86950e54510ee6d79399816341b', 'config': 'a77c698197c31308211b854e81a998178941f87d', 'pipeline': 'aaf976c7c663a31fa039582d42f9e07101556a7c'}, 'duration': 2.589430093765259, 'iteration': 4, 'loss': 0.2544808950572157, 'max_history_score': 0.7455191049427843, 'max_history_score_std': 0.04843448308166839, 'max_history_step': 'joint', 'pipeline': {'features': ('features_NoneType', {}), 'normalizer': ('normalizer_PowerTransformer', {}), 'rebalance': ('rebalance_NoneType', {})}, 'score': 0.7455191049427843, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': None, 'max_features': 2, 'max_leaf_nodes': 5, 'min_samples_split': 5, 'n_estimators': 25}, 'config_hash': {'algorithm': 'fd8aeb6a05eaaba41e676d60596c8e0c71b35e0c', 'config': '1fc13606bca3aaf342ca6ea21139cb598b56f8db', 'pipeline': 'f00bd8de05642e026bbba4ad20d3a60088c86b6c'}, 'duration': 1.8779079914093018, 'iteration': 5, 'loss': 0.531551018758381, 'max_history_score': 0.7455191049427843, 'max_history_score_std': 0.04843448308166839, 'max_history_step': 'joint', 'pipeline': {'features': ('features_PCA', {'features__n_components': 2}), 'normalizer': ('normalizer_MinMaxScaler', {}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 5})}, 'score': 0.46844898124161904, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'entropy', 'max_depth': None, 'max_features': 2, 'max_leaf_nodes': None, 'min_samples_split': 2, 'n_estimators': 10}, 'config_hash': {'algorithm': 'a49ecb99e74217d6812f98ead7bc9d1fe4a53ba0', 'config': '6749af1a67b4dbcd2b4719e419d99908063c05e1', 'pipeline': '19bdf19a2eec5febce95ab8fa2a71040d75114aa'}, 'duration': 1.5498578548431396, 'iteration': 6, 'loss': 0.14471329609998995, 'max_history_score': 0.85528670390001, 'max_history_score_std': 0.02213730791268438, 'max_history_step': 'joint', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 4, 'features__selectkbest__k': 3}), 'normalizer': ('normalizer_NoneType', {}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 7})}, 'score': 0.85528670390001, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': 1, 'max_features': 3, 'max_leaf_nodes': 3, 'min_samples_split': 3, 'n_estimators': 75}, 'config_hash': {'algorithm': 'ebfb16234172ae811ff21185ff92bbdbb8f32f14', 'config': 'd92d4ada2394fc132733e176e926ee53acdc6a00', 'pipeline': '8071e7cbf86a5c3056493dc3aa40063aeb28cdfe'}, 'duration': 1.3618149757385254, 'iteration': 7, 'loss': 0.6158612049395463, 'max_history_score': 0.85528670390001, 'max_history_score_std': 0.02213730791268438, 'max_history_step': 'joint', 'pipeline': {'features': ('features_SelectKBest', {'features__k': 4}), 'normalizer': ('normalizer_StandardScaler', {'normalizer__with_mean': True, 'normalizer__with_std': True}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 5})}, 'score': 0.3841387950604537, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'entropy', 'max_depth': 1, 'max_features': 1, 'max_leaf_nodes': 5, 'min_samples_split': 2, 'n_estimators': 100}, 'config_hash': {'algorithm': '896b53c75a2db568fb7b6da3bfca2f7a1535a11b', 'config': 'f0d0b1d2cedc22ae15d9a208a3fc3fc133bf0d3d', 'pipeline': 'c9761c9a33bf75d6dcad0742c421548a7655ccc9'}, 'duration': 2.297278881072998, 'iteration': 8, 'loss': 0.40673663548410355, 'max_history_score': 0.85528670390001, 'max_history_score_std': 0.02213730791268438, 'max_history_step': 'joint', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 2, 'features__selectkbest__k': 4}), 'normalizer': ('normalizer_StandardScaler', {'normalizer__with_mean': False, 'normalizer__with_std': False}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 5})}, 'score': 0.5932633645158965, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'entropy', 'max_depth': 2, 'max_features': None, 'max_leaf_nodes': None, 'min_samples_split': 5, 'n_estimators': 25}, 'config_hash': {'algorithm': '0b0e954757c4f75343a6efb740ad93260ed781ae', 'config': '47584de0e60d0d12c7dbbf0dc60e5aea96e3f4b2', 'pipeline': 'b37ee32d59413053bf9a2a72c8ff7135f3701e05'}, 'duration': 0.7249000072479248, 'iteration': 9, 'loss': 0.6965910020393421, 'max_history_score': 0.85528670390001, 'max_history_score_std': 0.02213730791268438, 'max_history_step': 'joint', 'pipeline': {'features': ('features_SelectKBest', {'features__k': 3}), 'normalizer': ('normalizer_NoneType', {}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 7})}, 'score': 0.3034089979606579, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'gini', 'max_depth': 2, 'max_features': 2, 'max_leaf_nodes': 5, 'min_samples_split': 5, 'n_estimators': 75}, 'config_hash': {'algorithm': 'f1ead1d9e33ea927e1dd27d872a058fa3de4f832', 'config': 'eecb88ee2b1b95d741c1b5c7751534d31aae6a77', 'pipeline': '6746650871e8b61efc9302b092dc05f7cdb179d5'}, 'duration': 5.340634822845459, 'iteration': 10, 'loss': 0.7687016290977936, 'max_history_score': 0.85528670390001, 'max_history_score_std': 0.02213730791268438, 'max_history_step': 'joint', 'pipeline': {'features': ('features_SelectKBest', {'features__k': 3}), 'normalizer': ('normalizer_RobustScaler', {'normalizer__quantile_range': (...), 'normalizer__with_centering': False, 'normalizer__with_scaling': False}), 'rebalance': ('rebalance_CondensedNearestNeighbour', {'rebalance__n_neighbors': 1})}, 'score': 0.23129837090220637, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': 1, 'max_features': 2, 'max_leaf_nodes': 2, 'min_samples_split': 3, 'n_estimators': 75}, 'config_hash': {'algorithm': '531a3bb8ccf0baa06727af4b3de9e62d25e6eabf', 'config': '27a7ed0502b321ab7256b77c8ce79e90cb9da815', 'pipeline': '77e6d84e2217b92b3cf67cc6defef9dd3554cec0'}, 'duration': 1.775357961654663, 'iteration': 11, 'loss': 0.6313818737375694, 'max_history_score': 0.85528670390001, 'max_history_score_std': 0.02213730791268438, 'max_history_step': 'joint', 'pipeline': {'features': ('features_SelectKBest', {'features__k': 4}), 'normalizer': ('normalizer_MinMaxScaler', {}), 'rebalance': ('rebalance_NearMiss', {'rebalance__n_neighbors': 3})}, 'score': 0.3686181262624307, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'entropy', 'max_depth': 4, 'max_features': 3, 'max_leaf_nodes': 2, 'min_samples_split': 3, 'n_estimators': 10}, 'config_hash': {'algorithm': '93518f8ded6074d537900b26be72f8485782f933', 'config': '45f056102dd2d644bd8befa471f17b2311ac7954', 'pipeline': '5240329df25c9a533d025c1a401d49835a501b41'}, 'duration': 3.2622711658477783, 'iteration': 12, 'loss': 0.6120243191353301, 'max_history_score': 0.85528670390001, 'max_history_score_std': 0.02213730791268438, 'max_history_step': 'joint', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 4, 'features__selectkbest__k': 2}), 'normalizer': ('normalizer_PowerTransformer', {}), 'rebalance': ('rebalance_NearMiss', {'rebalance__n_neighbors': 1})}, 'score': 0.38797568086467, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'entropy', 'max_depth': None, 'max_features': 1, 'max_leaf_nodes': 5, 'min_samples_split': 3, 'n_estimators': 75}, 'config_hash': {'algorithm': 'e515d45b764fa43591032874a0ff9c25bf12fddd', 'config': 'ba108323623936872824ed8f1c41d615d25523b3', 'pipeline': '9d823bc0442f21b5ce8af67a5eb1237f64ffc2f8'}, 'duration': 2.5326571464538574, 'iteration': 13, 'loss': 0.6271427382991047, 'max_history_score': 0.85528670390001, 'max_history_score_std': 0.02213730791268438, 'max_history_step': 'joint', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 1, 'features__selectkbest__k': 1}), 'normalizer': ('normalizer_StandardScaler', {'normalizer__with_mean': True, 'normalizer__with_std': True}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 5})}, 'score': 0.3728572617008953, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'entropy', 'max_depth': 3, 'max_features': 2, 'max_leaf_nodes': 2, 'min_samples_split': 3, 'n_estimators': 25}, 'config_hash': {'algorithm': '2808e67f609eba5c8a97f81ac0c9413cd37cf7aa', 'config': 'dde4d3b5f37741629cb58bfc4051ed9f98c8f311', 'pipeline': 'bc52deabf1f5ee60968ba541d9d2574353c30a9c'}, 'duration': 0.7145559787750244, 'iteration': 14, 'loss': 0.6831045572696203, 'max_history_score': 0.85528670390001, 'max_history_score_std': 0.02213730791268438, 'max_history_step': 'joint', 'pipeline': {'features': ('features_SelectKBest', {'features__k': 3}), 'normalizer': ('normalizer_MinMaxScaler', {}), 'rebalance': ('rebalance_NearMiss', {'rebalance__n_neighbors': 1})}, 'score': 0.31689544273037973, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'gini', 'max_depth': 2, 'max_features': 2, 'max_leaf_nodes': None, 'min_samples_split': 5, 'n_estimators': 100}, 'config_hash': {'algorithm': 'b942acdead762d34afeb474bc2fe6f7fd0f23493', 'config': '1080c25b92da3f15a6f8eec003957f7e0a66324f', 'pipeline': 'cfa84fe703dc5bc0bbd2257a6d524fee2693b804'}, 'duration': 2.812459945678711, 'iteration': 15, 'loss': 0.6921421091202761, 'max_history_score': 0.85528670390001, 'max_history_score_std': 0.02213730791268438, 'max_history_step': 'joint', 'pipeline': {'features': ('features_SelectKBest', {'features__k': 2}), 'normalizer': ('normalizer_PowerTransformer', {}), 'rebalance': ('rebalance_NoneType', {})}, 'score': 0.3078578908797239, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'entropy', 'max_depth': 2, 'max_features': 3, 'max_leaf_nodes': 3, 'min_samples_split': 2, 'n_estimators': 75}, 'config_hash': {'algorithm': '250661ce4193a61ef44d2f77694b52b785ff032d', 'config': 'c3e8cf4eca5aafcae4ac31b0449e105ca127ffe2', 'pipeline': 'c4dd111513ea35f97dd3aec3e8e7f6268ce035da'}, 'duration': 1.0555319786071777, 'iteration': 16, 'loss': 1.0, 'max_history_score': 0.85528670390001, 'max_history_score_std': 0.02213730791268438, 'max_history_step': 'joint', 'pipeline': {'features': ('features_PCA', {'features__n_components': 2}), 'normalizer': ('normalizer_RobustScaler', {'normalizer__quantile_range': (...), 'normalizer__with_centering': False, 'normalizer__with_scaling': True}), 'rebalance': ('rebalance_NearMiss', {'rebalance__n_neighbors': 2})}, 'score': 0.0, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'entropy', 'max_depth': 3, 'max_features': 3, 'max_leaf_nodes': None, 'min_samples_split': 3, 'n_estimators': 25}, 'config_hash': {'algorithm': '05ac02bd045c65dc4089894902ad6253661a2692', 'config': '3449b4a1c2e488e26a7195ee9edca19b854ebd33', 'pipeline': '505d3f71b534917375d765e64b0611e7dfb83746'}, 'duration': 5.5412821769714355, 'iteration': 17, 'loss': 0.7289151155121668, 'max_history_score': 0.85528670390001, 'max_history_score_std': 0.02213730791268438, 'max_history_step': 'joint', 'pipeline': {'features': ('features_SelectKBest', {'features__k': 4}), 'normalizer': ('normalizer_MinMaxScaler', {}), 'rebalance': ('rebalance_CondensedNearestNeighbour', {'rebalance__n_neighbors': 2})}, 'score': 0.2710848844878332, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'entropy', 'max_depth': 2, 'max_features': None, 'max_leaf_nodes': None, 'min_samples_split': 2, 'n_estimators': 25}, 'config_hash': {'algorithm': 'de3b3a352ebb260e16c6b213a08c9144d17a744b', 'config': '224987ffdbbb9b6182cff18d8374518b917e4f2e', 'pipeline': '12c89200a558b2f3b91332566f41050143aecbe7'}, 'duration': 2.4646048545837402, 'iteration': 18, 'loss': 0.6545902512995826, 'max_history_score': 0.85528670390001, 'max_history_score_std': 0.02213730791268438, 'max_history_step': 'joint', 'pipeline': {'features': ('features_NoneType', {}), 'normalizer': ('normalizer_PowerTransformer', {}), 'rebalance': ('rebalance_NearMiss', {'rebalance__n_neighbors': 2})}, 'score': 0.3454097487004174, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'gini', 'max_depth': None, 'max_features': 1, 'max_leaf_nodes': None, 'min_samples_split': 3, 'n_estimators': 100}, 'config_hash': {'algorithm': '30ca111584767bbf0464df40b4c928cf7ddf9459', 'config': '97ca7d6a017c721084dec2a5d2e5a67e1e6ae2f0', 'pipeline': '789eca82ea4a42d61927670c538867b745fd81d3'}, 'duration': 7.164499044418335, 'iteration': 19, 'loss': 0.6536825403350528, 'max_history_score': 0.85528670390001, 'max_history_score_std': 0.02213730791268438, 'max_history_step': 'joint', 'pipeline': {'features': ('features_SelectKBest', {'features__k': 3}), 'normalizer': ('normalizer_RobustScaler', {'normalizer__quantile_range': (...), 'normalizer__with_centering': False, 'normalizer__with_scaling': True}), 'rebalance': ('rebalance_CondensedNearestNeighbour', {'rebalance__n_neighbors': 3})}, 'score': 0.3463174596649472, ...}, ...], 'history_hash': ['fd24b065dda6bdeb1077793f9df480ff318c7a37', 'fb22f80fb4358ae1ee4c9bd4a83543992be8d806', '8c97cdb885dd05cfd8c40ee3ac445b61e5c767a8', '16fbb5fd5cfbbacfddf27c61c0c7397a7f6d8ade', 'a77c698197c31308211b854e81a998178941f87d', '1fc13606bca3aaf342ca6ea21139cb598b56f8db', '6749af1a67b4dbcd2b4719e419d99908063c05e1', 'd92d4ada2394fc132733e176e926ee53acdc6a00', 'f0d0b1d2cedc22ae15d9a208a3fc3fc133bf0d3d', '47584de0e60d0d12c7dbbf0dc60e5aea96e3f4b2', 'eecb88ee2b1b95d741c1b5c7751534d31aae6a77', '27a7ed0502b321ab7256b77c8ce79e90cb9da815', '45f056102dd2d644bd8befa471f17b2311ac7954', 'ba108323623936872824ed8f1c41d615d25523b3', 'dde4d3b5f37741629cb58bfc4051ed9f98c8f311', '1080c25b92da3f15a6f8eec003957f7e0a66324f', 'c3e8cf4eca5aafcae4ac31b0449e105ca127ffe2', '3449b4a1c2e488e26a7195ee9edca19b854ebd33', '224987ffdbbb9b6182cff18d8374518b917e4f2e', '97ca7d6a017c721084dec2a5d2e5a67e1e6ae2f0', ...], 'history_index': {'00e8f4ca31525b847c5f1d5de869962edbe23b64': 99, '0114519a520f59f3b000aba3a54f4681935d0c6f': 110, '01b68ec8d6fe15ffdadf1adfd0d809307d3ce41e': 81, '05465becb12810ce291074be22a0275a42efbea8': 52, '064f53edf4748bb2df4ff59f147331aad21219e1': 48, '087efef4a19f272562d2d445dac0edd8096ba2fa': 58, '0fd4d71ca3a89c7d14af5087f2a2e2c1b1975351': 51, '1080c25b92da3f15a6f8eec003957f7e0a66324f': 15, '10ca1ab51b6af0696dab2c8cbaf8de5e3812a6de': 78, '10cb7f1ca9feb52539f61b654f31107801dadc1c': 89, ...}, 'iteration': 111, 'max_history_score': 0.9231904384036744, 'max_history_score_std': 0.03040515884196498, 'max_history_step': 'joint'}, config={'algorithm': 'RandomForest', 'seed': 42, 'time': 300})
    108 
    109 def objective_algo(algo_config, current_pipeline_config, algorithm, X, y, context, config):
    110     return objective(current_pipeline_config, algo_config, algorithm, X, y, context, config, step='algorithm')
    111 
    112 def objective_joint(wconfig, algorithm, X, y, context, config):
--> 113     return objective(wconfig['pipeline'], wconfig['algorithm'], algorithm, X, y, context, config, step='joint')
        wconfig = {'algorithm': {'bootstrap': False, 'criterion': 'gini', 'max_depth': 2, 'max_features': 3, 'max_leaf_nodes': None, 'min_samples_split': 5, 'n_estimators': 75}, 'pipeline': {'features': ('features_PCA', {'features__n_components': 1}), 'normalizer': ('normalizer_StandardScaler', {'normalizer__with_mean': False, 'normalizer__with_std': False}), 'rebalance': ('rebalance_CondensedNearestNeighbour', {'rebalance__n_neighbors': 2})}}
        algorithm = 'RandomForest'
        X = array([[ 0.,  0.,  5., ...,  0.,  0.,  0.],
    ...0.],
       [ 0.,  0., 10., ..., 12.,  1.,  0.]])
        y = array([0, 1, 2, ..., 8, 9, 8])
        context = {'baseline_score': 0.9272021217853512, 'baseline_score_std': 0.026919033284817703, 'best_config': {'algorithm': {'bootstrap': True, 'criterion': 'entropy', 'max_depth': None, 'max_features': None, 'max_leaf_nodes': None, 'min_samples_split': 3, 'n_estimators': 75}, 'config_hash': {'algorithm': 'f42e45bee34ac9973699212f6c8b845daea9383a', 'config': 'ae61cfde4c8b4c792e42d6b6be4af4ffb3d90e13', 'pipeline': '15ff3d6270ac899763bb3f72417c48bcd56aa7d8'}, 'duration': 8.20555305480957, 'iteration': 65, 'loss': 0.07680956159632557, 'max_history_score': 0.9231904384036744, 'max_history_score_std': 0.03040515884196498, 'max_history_step': 'joint', 'pipeline': {'features': ('features_NoneType', {}), 'normalizer': ('normalizer_StandardScaler', {'normalizer__with_mean': True, 'normalizer__with_std': True}), 'rebalance': ('rebalance_NearMiss', {'rebalance__n_neighbors': 1})}, 'score': 0.9231904384036744, ...}, 'history': [{'algorithm': {'bootstrap': False, 'criterion': 'entropy', 'max_depth': 1, 'max_features': 3, 'max_leaf_nodes': 3, 'min_samples_split': 5, 'n_estimators': 50}, 'config_hash': {'algorithm': '752fa095cdab58a238ae606c613606188964cc0c', 'config': 'fd24b065dda6bdeb1077793f9df480ff318c7a37', 'pipeline': '13ea3359c453b8993fcec1e88bc0e19cd0a2b112'}, 'duration': 0.689669132232666, 'iteration': 0, 'loss': 0.6602879519109309, 'max_history_score': 0.3397120480890691, 'max_history_score_std': 0.03346542949100545, 'max_history_step': 'joint', 'pipeline': {'features': ('features_SelectKBest', {'features__k': 4}), 'normalizer': ('normalizer_MinMaxScaler', {}), 'rebalance': ('rebalance_NoneType', {})}, 'score': 0.3397120480890691, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'gini', 'max_depth': 4, 'max_features': 1, 'max_leaf_nodes': 5, 'min_samples_split': 3, 'n_estimators': 25}, 'config_hash': {'algorithm': '9d9de4aee820052ddfe83bfffca420f6b50837d3', 'config': 'fb22f80fb4358ae1ee4c9bd4a83543992be8d806', 'pipeline': '6251ad4bb7a110726a67f90c319f4717ac37a312'}, 'duration': 1.4300940036773682, 'iteration': 1, 'loss': 0.5122196101741096, 'max_history_score': 0.48778038982589045, 'max_history_score_std': 0.05486079759217226, 'max_history_step': 'joint', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 2, 'features__selectkbest__k': 2}), 'normalizer': ('normalizer_StandardScaler', {'normalizer__with_mean': True, 'normalizer__with_std': True}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 5})}, 'score': 0.48778038982589045, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': 4, 'max_features': 1, 'max_leaf_nodes': None, 'min_samples_split': 2, 'n_estimators': 10}, 'config_hash': {'algorithm': '2ed7d27df9a1b2d5e63da76f7cb309616c232022', 'config': '8c97cdb885dd05cfd8c40ee3ac445b61e5c767a8', 'pipeline': 'c0abb5e23a4739d3120740a9519fb36c43eb94d5'}, 'duration': 3.0036678314208984, 'iteration': 2, 'loss': 0.38319264175312906, 'max_history_score': 0.6168073582468709, 'max_history_score_std': 0.05286679173001824, 'max_history_step': 'joint', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 1, 'features__selectkbest__k': 4}), 'normalizer': ('normalizer_PowerTransformer', {}), 'rebalance': ('rebalance_NearMiss', {'rebalance__n_neighbors': 2})}, 'score': 0.6168073582468709, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'entropy', 'max_depth': None, 'max_features': None, 'max_leaf_nodes': 2, 'min_samples_split': 2, 'n_estimators': 100}, 'config_hash': {'algorithm': '17962655e3b76dfcd0843d1e5c2cb7a9db1c6a79', 'config': '16fbb5fd5cfbbacfddf27c61c0c7397a7f6d8ade', 'pipeline': '13ea3359c453b8993fcec1e88bc0e19cd0a2b112'}, 'duration': 1.3447980880737305, 'iteration': 3, 'loss': 0.6768840987778313, 'max_history_score': 0.6168073582468709, 'max_history_score_std': 0.05286679173001824, 'max_history_step': 'joint', 'pipeline': {'features': ('features_SelectKBest', {'features__k': 4}), 'normalizer': ('normalizer_MinMaxScaler', {}), 'rebalance': ('rebalance_NoneType', {})}, 'score': 0.32311590122216866, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'gini', 'max_depth': 2, 'max_features': 2, 'max_leaf_nodes': 2, 'min_samples_split': 3, 'n_estimators': 100}, 'config_hash': {'algorithm': '1ea8965b2247f86950e54510ee6d79399816341b', 'config': 'a77c698197c31308211b854e81a998178941f87d', 'pipeline': 'aaf976c7c663a31fa039582d42f9e07101556a7c'}, 'duration': 2.589430093765259, 'iteration': 4, 'loss': 0.2544808950572157, 'max_history_score': 0.7455191049427843, 'max_history_score_std': 0.04843448308166839, 'max_history_step': 'joint', 'pipeline': {'features': ('features_NoneType', {}), 'normalizer': ('normalizer_PowerTransformer', {}), 'rebalance': ('rebalance_NoneType', {})}, 'score': 0.7455191049427843, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': None, 'max_features': 2, 'max_leaf_nodes': 5, 'min_samples_split': 5, 'n_estimators': 25}, 'config_hash': {'algorithm': 'fd8aeb6a05eaaba41e676d60596c8e0c71b35e0c', 'config': '1fc13606bca3aaf342ca6ea21139cb598b56f8db', 'pipeline': 'f00bd8de05642e026bbba4ad20d3a60088c86b6c'}, 'duration': 1.8779079914093018, 'iteration': 5, 'loss': 0.531551018758381, 'max_history_score': 0.7455191049427843, 'max_history_score_std': 0.04843448308166839, 'max_history_step': 'joint', 'pipeline': {'features': ('features_PCA', {'features__n_components': 2}), 'normalizer': ('normalizer_MinMaxScaler', {}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 5})}, 'score': 0.46844898124161904, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'entropy', 'max_depth': None, 'max_features': 2, 'max_leaf_nodes': None, 'min_samples_split': 2, 'n_estimators': 10}, 'config_hash': {'algorithm': 'a49ecb99e74217d6812f98ead7bc9d1fe4a53ba0', 'config': '6749af1a67b4dbcd2b4719e419d99908063c05e1', 'pipeline': '19bdf19a2eec5febce95ab8fa2a71040d75114aa'}, 'duration': 1.5498578548431396, 'iteration': 6, 'loss': 0.14471329609998995, 'max_history_score': 0.85528670390001, 'max_history_score_std': 0.02213730791268438, 'max_history_step': 'joint', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 4, 'features__selectkbest__k': 3}), 'normalizer': ('normalizer_NoneType', {}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 7})}, 'score': 0.85528670390001, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': 1, 'max_features': 3, 'max_leaf_nodes': 3, 'min_samples_split': 3, 'n_estimators': 75}, 'config_hash': {'algorithm': 'ebfb16234172ae811ff21185ff92bbdbb8f32f14', 'config': 'd92d4ada2394fc132733e176e926ee53acdc6a00', 'pipeline': '8071e7cbf86a5c3056493dc3aa40063aeb28cdfe'}, 'duration': 1.3618149757385254, 'iteration': 7, 'loss': 0.6158612049395463, 'max_history_score': 0.85528670390001, 'max_history_score_std': 0.02213730791268438, 'max_history_step': 'joint', 'pipeline': {'features': ('features_SelectKBest', {'features__k': 4}), 'normalizer': ('normalizer_StandardScaler', {'normalizer__with_mean': True, 'normalizer__with_std': True}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 5})}, 'score': 0.3841387950604537, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'entropy', 'max_depth': 1, 'max_features': 1, 'max_leaf_nodes': 5, 'min_samples_split': 2, 'n_estimators': 100}, 'config_hash': {'algorithm': '896b53c75a2db568fb7b6da3bfca2f7a1535a11b', 'config': 'f0d0b1d2cedc22ae15d9a208a3fc3fc133bf0d3d', 'pipeline': 'c9761c9a33bf75d6dcad0742c421548a7655ccc9'}, 'duration': 2.297278881072998, 'iteration': 8, 'loss': 0.40673663548410355, 'max_history_score': 0.85528670390001, 'max_history_score_std': 0.02213730791268438, 'max_history_step': 'joint', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 2, 'features__selectkbest__k': 4}), 'normalizer': ('normalizer_StandardScaler', {'normalizer__with_mean': False, 'normalizer__with_std': False}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 5})}, 'score': 0.5932633645158965, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'entropy', 'max_depth': 2, 'max_features': None, 'max_leaf_nodes': None, 'min_samples_split': 5, 'n_estimators': 25}, 'config_hash': {'algorithm': '0b0e954757c4f75343a6efb740ad93260ed781ae', 'config': '47584de0e60d0d12c7dbbf0dc60e5aea96e3f4b2', 'pipeline': 'b37ee32d59413053bf9a2a72c8ff7135f3701e05'}, 'duration': 0.7249000072479248, 'iteration': 9, 'loss': 0.6965910020393421, 'max_history_score': 0.85528670390001, 'max_history_score_std': 0.02213730791268438, 'max_history_step': 'joint', 'pipeline': {'features': ('features_SelectKBest', {'features__k': 3}), 'normalizer': ('normalizer_NoneType', {}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 7})}, 'score': 0.3034089979606579, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'gini', 'max_depth': 2, 'max_features': 2, 'max_leaf_nodes': 5, 'min_samples_split': 5, 'n_estimators': 75}, 'config_hash': {'algorithm': 'f1ead1d9e33ea927e1dd27d872a058fa3de4f832', 'config': 'eecb88ee2b1b95d741c1b5c7751534d31aae6a77', 'pipeline': '6746650871e8b61efc9302b092dc05f7cdb179d5'}, 'duration': 5.340634822845459, 'iteration': 10, 'loss': 0.7687016290977936, 'max_history_score': 0.85528670390001, 'max_history_score_std': 0.02213730791268438, 'max_history_step': 'joint', 'pipeline': {'features': ('features_SelectKBest', {'features__k': 3}), 'normalizer': ('normalizer_RobustScaler', {'normalizer__quantile_range': (...), 'normalizer__with_centering': False, 'normalizer__with_scaling': False}), 'rebalance': ('rebalance_CondensedNearestNeighbour', {'rebalance__n_neighbors': 1})}, 'score': 0.23129837090220637, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': 1, 'max_features': 2, 'max_leaf_nodes': 2, 'min_samples_split': 3, 'n_estimators': 75}, 'config_hash': {'algorithm': '531a3bb8ccf0baa06727af4b3de9e62d25e6eabf', 'config': '27a7ed0502b321ab7256b77c8ce79e90cb9da815', 'pipeline': '77e6d84e2217b92b3cf67cc6defef9dd3554cec0'}, 'duration': 1.775357961654663, 'iteration': 11, 'loss': 0.6313818737375694, 'max_history_score': 0.85528670390001, 'max_history_score_std': 0.02213730791268438, 'max_history_step': 'joint', 'pipeline': {'features': ('features_SelectKBest', {'features__k': 4}), 'normalizer': ('normalizer_MinMaxScaler', {}), 'rebalance': ('rebalance_NearMiss', {'rebalance__n_neighbors': 3})}, 'score': 0.3686181262624307, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'entropy', 'max_depth': 4, 'max_features': 3, 'max_leaf_nodes': 2, 'min_samples_split': 3, 'n_estimators': 10}, 'config_hash': {'algorithm': '93518f8ded6074d537900b26be72f8485782f933', 'config': '45f056102dd2d644bd8befa471f17b2311ac7954', 'pipeline': '5240329df25c9a533d025c1a401d49835a501b41'}, 'duration': 3.2622711658477783, 'iteration': 12, 'loss': 0.6120243191353301, 'max_history_score': 0.85528670390001, 'max_history_score_std': 0.02213730791268438, 'max_history_step': 'joint', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 4, 'features__selectkbest__k': 2}), 'normalizer': ('normalizer_PowerTransformer', {}), 'rebalance': ('rebalance_NearMiss', {'rebalance__n_neighbors': 1})}, 'score': 0.38797568086467, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'entropy', 'max_depth': None, 'max_features': 1, 'max_leaf_nodes': 5, 'min_samples_split': 3, 'n_estimators': 75}, 'config_hash': {'algorithm': 'e515d45b764fa43591032874a0ff9c25bf12fddd', 'config': 'ba108323623936872824ed8f1c41d615d25523b3', 'pipeline': '9d823bc0442f21b5ce8af67a5eb1237f64ffc2f8'}, 'duration': 2.5326571464538574, 'iteration': 13, 'loss': 0.6271427382991047, 'max_history_score': 0.85528670390001, 'max_history_score_std': 0.02213730791268438, 'max_history_step': 'joint', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 1, 'features__selectkbest__k': 1}), 'normalizer': ('normalizer_StandardScaler', {'normalizer__with_mean': True, 'normalizer__with_std': True}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 5})}, 'score': 0.3728572617008953, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'entropy', 'max_depth': 3, 'max_features': 2, 'max_leaf_nodes': 2, 'min_samples_split': 3, 'n_estimators': 25}, 'config_hash': {'algorithm': '2808e67f609eba5c8a97f81ac0c9413cd37cf7aa', 'config': 'dde4d3b5f37741629cb58bfc4051ed9f98c8f311', 'pipeline': 'bc52deabf1f5ee60968ba541d9d2574353c30a9c'}, 'duration': 0.7145559787750244, 'iteration': 14, 'loss': 0.6831045572696203, 'max_history_score': 0.85528670390001, 'max_history_score_std': 0.02213730791268438, 'max_history_step': 'joint', 'pipeline': {'features': ('features_SelectKBest', {'features__k': 3}), 'normalizer': ('normalizer_MinMaxScaler', {}), 'rebalance': ('rebalance_NearMiss', {'rebalance__n_neighbors': 1})}, 'score': 0.31689544273037973, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'gini', 'max_depth': 2, 'max_features': 2, 'max_leaf_nodes': None, 'min_samples_split': 5, 'n_estimators': 100}, 'config_hash': {'algorithm': 'b942acdead762d34afeb474bc2fe6f7fd0f23493', 'config': '1080c25b92da3f15a6f8eec003957f7e0a66324f', 'pipeline': 'cfa84fe703dc5bc0bbd2257a6d524fee2693b804'}, 'duration': 2.812459945678711, 'iteration': 15, 'loss': 0.6921421091202761, 'max_history_score': 0.85528670390001, 'max_history_score_std': 0.02213730791268438, 'max_history_step': 'joint', 'pipeline': {'features': ('features_SelectKBest', {'features__k': 2}), 'normalizer': ('normalizer_PowerTransformer', {}), 'rebalance': ('rebalance_NoneType', {})}, 'score': 0.3078578908797239, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'entropy', 'max_depth': 2, 'max_features': 3, 'max_leaf_nodes': 3, 'min_samples_split': 2, 'n_estimators': 75}, 'config_hash': {'algorithm': '250661ce4193a61ef44d2f77694b52b785ff032d', 'config': 'c3e8cf4eca5aafcae4ac31b0449e105ca127ffe2', 'pipeline': 'c4dd111513ea35f97dd3aec3e8e7f6268ce035da'}, 'duration': 1.0555319786071777, 'iteration': 16, 'loss': 1.0, 'max_history_score': 0.85528670390001, 'max_history_score_std': 0.02213730791268438, 'max_history_step': 'joint', 'pipeline': {'features': ('features_PCA', {'features__n_components': 2}), 'normalizer': ('normalizer_RobustScaler', {'normalizer__quantile_range': (...), 'normalizer__with_centering': False, 'normalizer__with_scaling': True}), 'rebalance': ('rebalance_NearMiss', {'rebalance__n_neighbors': 2})}, 'score': 0.0, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'entropy', 'max_depth': 3, 'max_features': 3, 'max_leaf_nodes': None, 'min_samples_split': 3, 'n_estimators': 25}, 'config_hash': {'algorithm': '05ac02bd045c65dc4089894902ad6253661a2692', 'config': '3449b4a1c2e488e26a7195ee9edca19b854ebd33', 'pipeline': '505d3f71b534917375d765e64b0611e7dfb83746'}, 'duration': 5.5412821769714355, 'iteration': 17, 'loss': 0.7289151155121668, 'max_history_score': 0.85528670390001, 'max_history_score_std': 0.02213730791268438, 'max_history_step': 'joint', 'pipeline': {'features': ('features_SelectKBest', {'features__k': 4}), 'normalizer': ('normalizer_MinMaxScaler', {}), 'rebalance': ('rebalance_CondensedNearestNeighbour', {'rebalance__n_neighbors': 2})}, 'score': 0.2710848844878332, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'entropy', 'max_depth': 2, 'max_features': None, 'max_leaf_nodes': None, 'min_samples_split': 2, 'n_estimators': 25}, 'config_hash': {'algorithm': 'de3b3a352ebb260e16c6b213a08c9144d17a744b', 'config': '224987ffdbbb9b6182cff18d8374518b917e4f2e', 'pipeline': '12c89200a558b2f3b91332566f41050143aecbe7'}, 'duration': 2.4646048545837402, 'iteration': 18, 'loss': 0.6545902512995826, 'max_history_score': 0.85528670390001, 'max_history_score_std': 0.02213730791268438, 'max_history_step': 'joint', 'pipeline': {'features': ('features_NoneType', {}), 'normalizer': ('normalizer_PowerTransformer', {}), 'rebalance': ('rebalance_NearMiss', {'rebalance__n_neighbors': 2})}, 'score': 0.3454097487004174, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'gini', 'max_depth': None, 'max_features': 1, 'max_leaf_nodes': None, 'min_samples_split': 3, 'n_estimators': 100}, 'config_hash': {'algorithm': '30ca111584767bbf0464df40b4c928cf7ddf9459', 'config': '97ca7d6a017c721084dec2a5d2e5a67e1e6ae2f0', 'pipeline': '789eca82ea4a42d61927670c538867b745fd81d3'}, 'duration': 7.164499044418335, 'iteration': 19, 'loss': 0.6536825403350528, 'max_history_score': 0.85528670390001, 'max_history_score_std': 0.02213730791268438, 'max_history_step': 'joint', 'pipeline': {'features': ('features_SelectKBest', {'features__k': 3}), 'normalizer': ('normalizer_RobustScaler', {'normalizer__quantile_range': (...), 'normalizer__with_centering': False, 'normalizer__with_scaling': True}), 'rebalance': ('rebalance_CondensedNearestNeighbour', {'rebalance__n_neighbors': 3})}, 'score': 0.3463174596649472, ...}, ...], 'history_hash': ['fd24b065dda6bdeb1077793f9df480ff318c7a37', 'fb22f80fb4358ae1ee4c9bd4a83543992be8d806', '8c97cdb885dd05cfd8c40ee3ac445b61e5c767a8', '16fbb5fd5cfbbacfddf27c61c0c7397a7f6d8ade', 'a77c698197c31308211b854e81a998178941f87d', '1fc13606bca3aaf342ca6ea21139cb598b56f8db', '6749af1a67b4dbcd2b4719e419d99908063c05e1', 'd92d4ada2394fc132733e176e926ee53acdc6a00', 'f0d0b1d2cedc22ae15d9a208a3fc3fc133bf0d3d', '47584de0e60d0d12c7dbbf0dc60e5aea96e3f4b2', 'eecb88ee2b1b95d741c1b5c7751534d31aae6a77', '27a7ed0502b321ab7256b77c8ce79e90cb9da815', '45f056102dd2d644bd8befa471f17b2311ac7954', 'ba108323623936872824ed8f1c41d615d25523b3', 'dde4d3b5f37741629cb58bfc4051ed9f98c8f311', '1080c25b92da3f15a6f8eec003957f7e0a66324f', 'c3e8cf4eca5aafcae4ac31b0449e105ca127ffe2', '3449b4a1c2e488e26a7195ee9edca19b854ebd33', '224987ffdbbb9b6182cff18d8374518b917e4f2e', '97ca7d6a017c721084dec2a5d2e5a67e1e6ae2f0', ...], 'history_index': {'00e8f4ca31525b847c5f1d5de869962edbe23b64': 99, '0114519a520f59f3b000aba3a54f4681935d0c6f': 110, '01b68ec8d6fe15ffdadf1adfd0d809307d3ce41e': 81, '05465becb12810ce291074be22a0275a42efbea8': 52, '064f53edf4748bb2df4ff59f147331aad21219e1': 48, '087efef4a19f272562d2d445dac0edd8096ba2fa': 58, '0fd4d71ca3a89c7d14af5087f2a2e2c1b1975351': 51, '1080c25b92da3f15a6f8eec003957f7e0a66324f': 15, '10ca1ab51b6af0696dab2c8cbaf8de5e3812a6de': 78, '10cb7f1ca9feb52539f61b654f31107801dadc1c': 89, ...}, 'iteration': 111, 'max_history_score': 0.9231904384036744, 'max_history_score_std': 0.03040515884196498, 'max_history_step': 'joint'}
        config = {'algorithm': 'RandomForest', 'seed': 42, 'time': 300}
    114 
    115 
    116 def get_baseline_score(algorithm, X, y, seed):
    117     pipeline, _ = pipeline_conf_to_full_pipeline(

...........................................................................
/home/aquemy/dev/dp_hyperparameters/extension/experiment/objective.py in objective(pipeline_config={'features': ('features_PCA', {'features__n_components': 1}), 'normalizer': ('normalizer_StandardScaler', {'normalizer__with_mean': False, 'normalizer__with_std': False}), 'rebalance': ('rebalance_CondensedNearestNeighbour', {'rebalance__n_neighbors': 2})}, algo_config={'bootstrap': False, 'criterion': 'gini', 'max_depth': 2, 'max_features': 3, 'max_leaf_nodes': None, 'min_samples_split': 5, 'n_estimators': 75}, algorithm='RandomForest', X=array([[ 0.,  0.,  5., ...,  0.,  0.,  0.],
    ...0.],
       [ 0.,  0., 10., ..., 12.,  1.,  0.]]), y=array([0, 1, 2, ..., 8, 9, 8]), context={'baseline_score': 0.9272021217853512, 'baseline_score_std': 0.026919033284817703, 'best_config': {'algorithm': {'bootstrap': True, 'criterion': 'entropy', 'max_depth': None, 'max_features': None, 'max_leaf_nodes': None, 'min_samples_split': 3, 'n_estimators': 75}, 'config_hash': {'algorithm': 'f42e45bee34ac9973699212f6c8b845daea9383a', 'config': 'ae61cfde4c8b4c792e42d6b6be4af4ffb3d90e13', 'pipeline': '15ff3d6270ac899763bb3f72417c48bcd56aa7d8'}, 'duration': 8.20555305480957, 'iteration': 65, 'loss': 0.07680956159632557, 'max_history_score': 0.9231904384036744, 'max_history_score_std': 0.03040515884196498, 'max_history_step': 'joint', 'pipeline': {'features': ('features_NoneType', {}), 'normalizer': ('normalizer_StandardScaler', {'normalizer__with_mean': True, 'normalizer__with_std': True}), 'rebalance': ('rebalance_NearMiss', {'rebalance__n_neighbors': 1})}, 'score': 0.9231904384036744, ...}, 'history': [{'algorithm': {'bootstrap': False, 'criterion': 'entropy', 'max_depth': 1, 'max_features': 3, 'max_leaf_nodes': 3, 'min_samples_split': 5, 'n_estimators': 50}, 'config_hash': {'algorithm': '752fa095cdab58a238ae606c613606188964cc0c', 'config': 'fd24b065dda6bdeb1077793f9df480ff318c7a37', 'pipeline': '13ea3359c453b8993fcec1e88bc0e19cd0a2b112'}, 'duration': 0.689669132232666, 'iteration': 0, 'loss': 0.6602879519109309, 'max_history_score': 0.3397120480890691, 'max_history_score_std': 0.03346542949100545, 'max_history_step': 'joint', 'pipeline': {'features': ('features_SelectKBest', {'features__k': 4}), 'normalizer': ('normalizer_MinMaxScaler', {}), 'rebalance': ('rebalance_NoneType', {})}, 'score': 0.3397120480890691, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'gini', 'max_depth': 4, 'max_features': 1, 'max_leaf_nodes': 5, 'min_samples_split': 3, 'n_estimators': 25}, 'config_hash': {'algorithm': '9d9de4aee820052ddfe83bfffca420f6b50837d3', 'config': 'fb22f80fb4358ae1ee4c9bd4a83543992be8d806', 'pipeline': '6251ad4bb7a110726a67f90c319f4717ac37a312'}, 'duration': 1.4300940036773682, 'iteration': 1, 'loss': 0.5122196101741096, 'max_history_score': 0.48778038982589045, 'max_history_score_std': 0.05486079759217226, 'max_history_step': 'joint', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 2, 'features__selectkbest__k': 2}), 'normalizer': ('normalizer_StandardScaler', {'normalizer__with_mean': True, 'normalizer__with_std': True}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 5})}, 'score': 0.48778038982589045, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': 4, 'max_features': 1, 'max_leaf_nodes': None, 'min_samples_split': 2, 'n_estimators': 10}, 'config_hash': {'algorithm': '2ed7d27df9a1b2d5e63da76f7cb309616c232022', 'config': '8c97cdb885dd05cfd8c40ee3ac445b61e5c767a8', 'pipeline': 'c0abb5e23a4739d3120740a9519fb36c43eb94d5'}, 'duration': 3.0036678314208984, 'iteration': 2, 'loss': 0.38319264175312906, 'max_history_score': 0.6168073582468709, 'max_history_score_std': 0.05286679173001824, 'max_history_step': 'joint', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 1, 'features__selectkbest__k': 4}), 'normalizer': ('normalizer_PowerTransformer', {}), 'rebalance': ('rebalance_NearMiss', {'rebalance__n_neighbors': 2})}, 'score': 0.6168073582468709, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'entropy', 'max_depth': None, 'max_features': None, 'max_leaf_nodes': 2, 'min_samples_split': 2, 'n_estimators': 100}, 'config_hash': {'algorithm': '17962655e3b76dfcd0843d1e5c2cb7a9db1c6a79', 'config': '16fbb5fd5cfbbacfddf27c61c0c7397a7f6d8ade', 'pipeline': '13ea3359c453b8993fcec1e88bc0e19cd0a2b112'}, 'duration': 1.3447980880737305, 'iteration': 3, 'loss': 0.6768840987778313, 'max_history_score': 0.6168073582468709, 'max_history_score_std': 0.05286679173001824, 'max_history_step': 'joint', 'pipeline': {'features': ('features_SelectKBest', {'features__k': 4}), 'normalizer': ('normalizer_MinMaxScaler', {}), 'rebalance': ('rebalance_NoneType', {})}, 'score': 0.32311590122216866, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'gini', 'max_depth': 2, 'max_features': 2, 'max_leaf_nodes': 2, 'min_samples_split': 3, 'n_estimators': 100}, 'config_hash': {'algorithm': '1ea8965b2247f86950e54510ee6d79399816341b', 'config': 'a77c698197c31308211b854e81a998178941f87d', 'pipeline': 'aaf976c7c663a31fa039582d42f9e07101556a7c'}, 'duration': 2.589430093765259, 'iteration': 4, 'loss': 0.2544808950572157, 'max_history_score': 0.7455191049427843, 'max_history_score_std': 0.04843448308166839, 'max_history_step': 'joint', 'pipeline': {'features': ('features_NoneType', {}), 'normalizer': ('normalizer_PowerTransformer', {}), 'rebalance': ('rebalance_NoneType', {})}, 'score': 0.7455191049427843, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': None, 'max_features': 2, 'max_leaf_nodes': 5, 'min_samples_split': 5, 'n_estimators': 25}, 'config_hash': {'algorithm': 'fd8aeb6a05eaaba41e676d60596c8e0c71b35e0c', 'config': '1fc13606bca3aaf342ca6ea21139cb598b56f8db', 'pipeline': 'f00bd8de05642e026bbba4ad20d3a60088c86b6c'}, 'duration': 1.8779079914093018, 'iteration': 5, 'loss': 0.531551018758381, 'max_history_score': 0.7455191049427843, 'max_history_score_std': 0.04843448308166839, 'max_history_step': 'joint', 'pipeline': {'features': ('features_PCA', {'features__n_components': 2}), 'normalizer': ('normalizer_MinMaxScaler', {}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 5})}, 'score': 0.46844898124161904, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'entropy', 'max_depth': None, 'max_features': 2, 'max_leaf_nodes': None, 'min_samples_split': 2, 'n_estimators': 10}, 'config_hash': {'algorithm': 'a49ecb99e74217d6812f98ead7bc9d1fe4a53ba0', 'config': '6749af1a67b4dbcd2b4719e419d99908063c05e1', 'pipeline': '19bdf19a2eec5febce95ab8fa2a71040d75114aa'}, 'duration': 1.5498578548431396, 'iteration': 6, 'loss': 0.14471329609998995, 'max_history_score': 0.85528670390001, 'max_history_score_std': 0.02213730791268438, 'max_history_step': 'joint', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 4, 'features__selectkbest__k': 3}), 'normalizer': ('normalizer_NoneType', {}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 7})}, 'score': 0.85528670390001, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': 1, 'max_features': 3, 'max_leaf_nodes': 3, 'min_samples_split': 3, 'n_estimators': 75}, 'config_hash': {'algorithm': 'ebfb16234172ae811ff21185ff92bbdbb8f32f14', 'config': 'd92d4ada2394fc132733e176e926ee53acdc6a00', 'pipeline': '8071e7cbf86a5c3056493dc3aa40063aeb28cdfe'}, 'duration': 1.3618149757385254, 'iteration': 7, 'loss': 0.6158612049395463, 'max_history_score': 0.85528670390001, 'max_history_score_std': 0.02213730791268438, 'max_history_step': 'joint', 'pipeline': {'features': ('features_SelectKBest', {'features__k': 4}), 'normalizer': ('normalizer_StandardScaler', {'normalizer__with_mean': True, 'normalizer__with_std': True}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 5})}, 'score': 0.3841387950604537, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'entropy', 'max_depth': 1, 'max_features': 1, 'max_leaf_nodes': 5, 'min_samples_split': 2, 'n_estimators': 100}, 'config_hash': {'algorithm': '896b53c75a2db568fb7b6da3bfca2f7a1535a11b', 'config': 'f0d0b1d2cedc22ae15d9a208a3fc3fc133bf0d3d', 'pipeline': 'c9761c9a33bf75d6dcad0742c421548a7655ccc9'}, 'duration': 2.297278881072998, 'iteration': 8, 'loss': 0.40673663548410355, 'max_history_score': 0.85528670390001, 'max_history_score_std': 0.02213730791268438, 'max_history_step': 'joint', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 2, 'features__selectkbest__k': 4}), 'normalizer': ('normalizer_StandardScaler', {'normalizer__with_mean': False, 'normalizer__with_std': False}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 5})}, 'score': 0.5932633645158965, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'entropy', 'max_depth': 2, 'max_features': None, 'max_leaf_nodes': None, 'min_samples_split': 5, 'n_estimators': 25}, 'config_hash': {'algorithm': '0b0e954757c4f75343a6efb740ad93260ed781ae', 'config': '47584de0e60d0d12c7dbbf0dc60e5aea96e3f4b2', 'pipeline': 'b37ee32d59413053bf9a2a72c8ff7135f3701e05'}, 'duration': 0.7249000072479248, 'iteration': 9, 'loss': 0.6965910020393421, 'max_history_score': 0.85528670390001, 'max_history_score_std': 0.02213730791268438, 'max_history_step': 'joint', 'pipeline': {'features': ('features_SelectKBest', {'features__k': 3}), 'normalizer': ('normalizer_NoneType', {}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 7})}, 'score': 0.3034089979606579, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'gini', 'max_depth': 2, 'max_features': 2, 'max_leaf_nodes': 5, 'min_samples_split': 5, 'n_estimators': 75}, 'config_hash': {'algorithm': 'f1ead1d9e33ea927e1dd27d872a058fa3de4f832', 'config': 'eecb88ee2b1b95d741c1b5c7751534d31aae6a77', 'pipeline': '6746650871e8b61efc9302b092dc05f7cdb179d5'}, 'duration': 5.340634822845459, 'iteration': 10, 'loss': 0.7687016290977936, 'max_history_score': 0.85528670390001, 'max_history_score_std': 0.02213730791268438, 'max_history_step': 'joint', 'pipeline': {'features': ('features_SelectKBest', {'features__k': 3}), 'normalizer': ('normalizer_RobustScaler', {'normalizer__quantile_range': (...), 'normalizer__with_centering': False, 'normalizer__with_scaling': False}), 'rebalance': ('rebalance_CondensedNearestNeighbour', {'rebalance__n_neighbors': 1})}, 'score': 0.23129837090220637, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': 1, 'max_features': 2, 'max_leaf_nodes': 2, 'min_samples_split': 3, 'n_estimators': 75}, 'config_hash': {'algorithm': '531a3bb8ccf0baa06727af4b3de9e62d25e6eabf', 'config': '27a7ed0502b321ab7256b77c8ce79e90cb9da815', 'pipeline': '77e6d84e2217b92b3cf67cc6defef9dd3554cec0'}, 'duration': 1.775357961654663, 'iteration': 11, 'loss': 0.6313818737375694, 'max_history_score': 0.85528670390001, 'max_history_score_std': 0.02213730791268438, 'max_history_step': 'joint', 'pipeline': {'features': ('features_SelectKBest', {'features__k': 4}), 'normalizer': ('normalizer_MinMaxScaler', {}), 'rebalance': ('rebalance_NearMiss', {'rebalance__n_neighbors': 3})}, 'score': 0.3686181262624307, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'entropy', 'max_depth': 4, 'max_features': 3, 'max_leaf_nodes': 2, 'min_samples_split': 3, 'n_estimators': 10}, 'config_hash': {'algorithm': '93518f8ded6074d537900b26be72f8485782f933', 'config': '45f056102dd2d644bd8befa471f17b2311ac7954', 'pipeline': '5240329df25c9a533d025c1a401d49835a501b41'}, 'duration': 3.2622711658477783, 'iteration': 12, 'loss': 0.6120243191353301, 'max_history_score': 0.85528670390001, 'max_history_score_std': 0.02213730791268438, 'max_history_step': 'joint', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 4, 'features__selectkbest__k': 2}), 'normalizer': ('normalizer_PowerTransformer', {}), 'rebalance': ('rebalance_NearMiss', {'rebalance__n_neighbors': 1})}, 'score': 0.38797568086467, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'entropy', 'max_depth': None, 'max_features': 1, 'max_leaf_nodes': 5, 'min_samples_split': 3, 'n_estimators': 75}, 'config_hash': {'algorithm': 'e515d45b764fa43591032874a0ff9c25bf12fddd', 'config': 'ba108323623936872824ed8f1c41d615d25523b3', 'pipeline': '9d823bc0442f21b5ce8af67a5eb1237f64ffc2f8'}, 'duration': 2.5326571464538574, 'iteration': 13, 'loss': 0.6271427382991047, 'max_history_score': 0.85528670390001, 'max_history_score_std': 0.02213730791268438, 'max_history_step': 'joint', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 1, 'features__selectkbest__k': 1}), 'normalizer': ('normalizer_StandardScaler', {'normalizer__with_mean': True, 'normalizer__with_std': True}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 5})}, 'score': 0.3728572617008953, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'entropy', 'max_depth': 3, 'max_features': 2, 'max_leaf_nodes': 2, 'min_samples_split': 3, 'n_estimators': 25}, 'config_hash': {'algorithm': '2808e67f609eba5c8a97f81ac0c9413cd37cf7aa', 'config': 'dde4d3b5f37741629cb58bfc4051ed9f98c8f311', 'pipeline': 'bc52deabf1f5ee60968ba541d9d2574353c30a9c'}, 'duration': 0.7145559787750244, 'iteration': 14, 'loss': 0.6831045572696203, 'max_history_score': 0.85528670390001, 'max_history_score_std': 0.02213730791268438, 'max_history_step': 'joint', 'pipeline': {'features': ('features_SelectKBest', {'features__k': 3}), 'normalizer': ('normalizer_MinMaxScaler', {}), 'rebalance': ('rebalance_NearMiss', {'rebalance__n_neighbors': 1})}, 'score': 0.31689544273037973, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'gini', 'max_depth': 2, 'max_features': 2, 'max_leaf_nodes': None, 'min_samples_split': 5, 'n_estimators': 100}, 'config_hash': {'algorithm': 'b942acdead762d34afeb474bc2fe6f7fd0f23493', 'config': '1080c25b92da3f15a6f8eec003957f7e0a66324f', 'pipeline': 'cfa84fe703dc5bc0bbd2257a6d524fee2693b804'}, 'duration': 2.812459945678711, 'iteration': 15, 'loss': 0.6921421091202761, 'max_history_score': 0.85528670390001, 'max_history_score_std': 0.02213730791268438, 'max_history_step': 'joint', 'pipeline': {'features': ('features_SelectKBest', {'features__k': 2}), 'normalizer': ('normalizer_PowerTransformer', {}), 'rebalance': ('rebalance_NoneType', {})}, 'score': 0.3078578908797239, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'entropy', 'max_depth': 2, 'max_features': 3, 'max_leaf_nodes': 3, 'min_samples_split': 2, 'n_estimators': 75}, 'config_hash': {'algorithm': '250661ce4193a61ef44d2f77694b52b785ff032d', 'config': 'c3e8cf4eca5aafcae4ac31b0449e105ca127ffe2', 'pipeline': 'c4dd111513ea35f97dd3aec3e8e7f6268ce035da'}, 'duration': 1.0555319786071777, 'iteration': 16, 'loss': 1.0, 'max_history_score': 0.85528670390001, 'max_history_score_std': 0.02213730791268438, 'max_history_step': 'joint', 'pipeline': {'features': ('features_PCA', {'features__n_components': 2}), 'normalizer': ('normalizer_RobustScaler', {'normalizer__quantile_range': (...), 'normalizer__with_centering': False, 'normalizer__with_scaling': True}), 'rebalance': ('rebalance_NearMiss', {'rebalance__n_neighbors': 2})}, 'score': 0.0, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'entropy', 'max_depth': 3, 'max_features': 3, 'max_leaf_nodes': None, 'min_samples_split': 3, 'n_estimators': 25}, 'config_hash': {'algorithm': '05ac02bd045c65dc4089894902ad6253661a2692', 'config': '3449b4a1c2e488e26a7195ee9edca19b854ebd33', 'pipeline': '505d3f71b534917375d765e64b0611e7dfb83746'}, 'duration': 5.5412821769714355, 'iteration': 17, 'loss': 0.7289151155121668, 'max_history_score': 0.85528670390001, 'max_history_score_std': 0.02213730791268438, 'max_history_step': 'joint', 'pipeline': {'features': ('features_SelectKBest', {'features__k': 4}), 'normalizer': ('normalizer_MinMaxScaler', {}), 'rebalance': ('rebalance_CondensedNearestNeighbour', {'rebalance__n_neighbors': 2})}, 'score': 0.2710848844878332, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'entropy', 'max_depth': 2, 'max_features': None, 'max_leaf_nodes': None, 'min_samples_split': 2, 'n_estimators': 25}, 'config_hash': {'algorithm': 'de3b3a352ebb260e16c6b213a08c9144d17a744b', 'config': '224987ffdbbb9b6182cff18d8374518b917e4f2e', 'pipeline': '12c89200a558b2f3b91332566f41050143aecbe7'}, 'duration': 2.4646048545837402, 'iteration': 18, 'loss': 0.6545902512995826, 'max_history_score': 0.85528670390001, 'max_history_score_std': 0.02213730791268438, 'max_history_step': 'joint', 'pipeline': {'features': ('features_NoneType', {}), 'normalizer': ('normalizer_PowerTransformer', {}), 'rebalance': ('rebalance_NearMiss', {'rebalance__n_neighbors': 2})}, 'score': 0.3454097487004174, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'gini', 'max_depth': None, 'max_features': 1, 'max_leaf_nodes': None, 'min_samples_split': 3, 'n_estimators': 100}, 'config_hash': {'algorithm': '30ca111584767bbf0464df40b4c928cf7ddf9459', 'config': '97ca7d6a017c721084dec2a5d2e5a67e1e6ae2f0', 'pipeline': '789eca82ea4a42d61927670c538867b745fd81d3'}, 'duration': 7.164499044418335, 'iteration': 19, 'loss': 0.6536825403350528, 'max_history_score': 0.85528670390001, 'max_history_score_std': 0.02213730791268438, 'max_history_step': 'joint', 'pipeline': {'features': ('features_SelectKBest', {'features__k': 3}), 'normalizer': ('normalizer_RobustScaler', {'normalizer__quantile_range': (...), 'normalizer__with_centering': False, 'normalizer__with_scaling': True}), 'rebalance': ('rebalance_CondensedNearestNeighbour', {'rebalance__n_neighbors': 3})}, 'score': 0.3463174596649472, ...}, ...], 'history_hash': ['fd24b065dda6bdeb1077793f9df480ff318c7a37', 'fb22f80fb4358ae1ee4c9bd4a83543992be8d806', '8c97cdb885dd05cfd8c40ee3ac445b61e5c767a8', '16fbb5fd5cfbbacfddf27c61c0c7397a7f6d8ade', 'a77c698197c31308211b854e81a998178941f87d', '1fc13606bca3aaf342ca6ea21139cb598b56f8db', '6749af1a67b4dbcd2b4719e419d99908063c05e1', 'd92d4ada2394fc132733e176e926ee53acdc6a00', 'f0d0b1d2cedc22ae15d9a208a3fc3fc133bf0d3d', '47584de0e60d0d12c7dbbf0dc60e5aea96e3f4b2', 'eecb88ee2b1b95d741c1b5c7751534d31aae6a77', '27a7ed0502b321ab7256b77c8ce79e90cb9da815', '45f056102dd2d644bd8befa471f17b2311ac7954', 'ba108323623936872824ed8f1c41d615d25523b3', 'dde4d3b5f37741629cb58bfc4051ed9f98c8f311', '1080c25b92da3f15a6f8eec003957f7e0a66324f', 'c3e8cf4eca5aafcae4ac31b0449e105ca127ffe2', '3449b4a1c2e488e26a7195ee9edca19b854ebd33', '224987ffdbbb9b6182cff18d8374518b917e4f2e', '97ca7d6a017c721084dec2a5d2e5a67e1e6ae2f0', ...], 'history_index': {'00e8f4ca31525b847c5f1d5de869962edbe23b64': 99, '0114519a520f59f3b000aba3a54f4681935d0c6f': 110, '01b68ec8d6fe15ffdadf1adfd0d809307d3ce41e': 81, '05465becb12810ce291074be22a0275a42efbea8': 52, '064f53edf4748bb2df4ff59f147331aad21219e1': 48, '087efef4a19f272562d2d445dac0edd8096ba2fa': 58, '0fd4d71ca3a89c7d14af5087f2a2e2c1b1975351': 51, '1080c25b92da3f15a6f8eec003957f7e0a66324f': 15, '10ca1ab51b6af0696dab2c8cbaf8de5e3812a6de': 78, '10cb7f1ca9feb52539f61b654f31107801dadc1c': 89, ...}, 'iteration': 111, 'max_history_score': 0.9231904384036744, 'max_history_score_std': 0.03040515884196498, 'max_history_step': 'joint'}, config={'algorithm': 'RandomForest', 'seed': 42, 'time': 300}, step='joint')
     45                 y,
     46                 cv=10,
     47                 n_jobs=-1,
     48                 return_estimator=False,
     49                 return_train_score=False,
---> 50                 verbose=0)
     51         score = np.mean(scores['test_score'])
     52         std = np.std(scores['test_score'])
     53         status = STATUS_OK
     54     except Exception as e:

...........................................................................
/home/aquemy/.local/lib/python2.7/site-packages/sklearn/model_selection/_validation.py in cross_validate(estimator=Pipeline(memory=None,
     steps=[('rebalance', ... random_state=42, verbose=0, warm_start=False))]), X=array([[ 0.,  0.,  5., ...,  0.,  0.,  0.],
    ...0.],
       [ 0.,  0., 10., ..., 12.,  1.,  0.]]), y=array([0, 1, 2, ..., 8, 9, 8]), groups=None, scoring=None, cv=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1, verbose=0, fit_params=None, pre_dispatch='2*n_jobs', return_train_score=False, return_estimator=False, error_score='raise-deprecating')
    235         delayed(_fit_and_score)(
    236             clone(estimator), X, y, scorers, train, test, verbose, None,
    237             fit_params, return_train_score=return_train_score,
    238             return_times=True, return_estimator=return_estimator,
    239             error_score=error_score)
--> 240         for train, test in cv.split(X, y, groups))
        cv.split = <bound method StratifiedKFold.split of Stratifie...d(n_splits=10, random_state=None, shuffle=False)>
        X = array([[ 0.,  0.,  5., ...,  0.,  0.,  0.],
    ...0.],
       [ 0.,  0., 10., ..., 12.,  1.,  0.]])
        y = array([0, 1, 2, ..., 8, 9, 8])
        groups = None
    241 
    242     zipped_scores = list(zip(*scores))
    243     if return_train_score:
    244         train_scores = zipped_scores.pop(0)

...........................................................................
/home/aquemy/.local/lib/python2.7/site-packages/sklearn/externals/joblib/parallel.py in __call__(self=Parallel(n_jobs=-1), iterable=<generator object <genexpr>>)
    925                 # No need to wait for async callbacks to trigger to
    926                 # consumption.
    927                 self._iterating = False
    928 
    929             with self._backend.retrieval_context():
--> 930                 self.retrieve()
        self.retrieve = <bound method Parallel.retrieve of Parallel(n_jobs=-1)>
    931             # Make sure that we get a last message telling us we are done
    932             elapsed_time = time.time() - self._start_time
    933             self._print('Done %3i out of %3i | elapsed: %s finished',
    934                         (len(self._output), len(self._output),

---------------------------------------------------------------------------
Joblib worker traceback:
---------------------------------------------------------------------------
ValueError                                         Mon Jun 17 13:10:13 2019
PID: 20688                                  Python 2.7.15+: /usr/bin/python
...........................................................................
/home/aquemy/.local/lib/python2.7/site-packages/sklearn/externals/joblib/parallel.py in __call__(self=<sklearn.externals.joblib.parallel.BatchedCalls object>)
    220     def __call__(self):
    221         # Set the default nested backend to self._backend but do not set the
    222         # change the default number of processes to -1
    223         with parallel_backend(self._backend, n_jobs=self._n_jobs):
    224             return [func(*args, **kwargs)
--> 225                     for func, args, kwargs in self.items]
        func = <function _fit_and_score>
        args = (Pipeline(memory=None,
     steps=[('rebalance', ... random_state=42, verbose=0, warm_start=False))]), array([[ 0.,  0.,  5., ...,  0.,  0.,  0.],
    ...0.],
       [ 0.,  0., 10., ..., 12.,  1.,  0.]]), array([0, 1, 2, ..., 8, 9, 8]), {'score': <function _passthrough_scorer>}, array([ 169,  176,  178, ..., 1794, 1795, 1796]), array([  0,   1,   2,   3,   4,   5,   6,   7,  ..., 181, 186, 188, 189, 190,
       194, 195, 198]), 0, None, None)
        kwargs = {'error_score': 'raise-deprecating', 'return_estimator': False, 'return_times': True, 'return_train_score': False}
        self.items = [(<function _fit_and_score>, (Pipeline(memory=None,
     steps=[('rebalance', ... random_state=42, verbose=0, warm_start=False))]), array([[ 0.,  0.,  5., ...,  0.,  0.,  0.],
    ...0.],
       [ 0.,  0., 10., ..., 12.,  1.,  0.]]), array([0, 1, 2, ..., 8, 9, 8]), {'score': <function _passthrough_scorer>}, array([ 169,  176,  178, ..., 1794, 1795, 1796]), array([  0,   1,   2,   3,   4,   5,   6,   7,  ..., 181, 186, 188, 189, 190,
       194, 195, 198]), 0, None, None), {'error_score': 'raise-deprecating', 'return_estimator': False, 'return_times': True, 'return_train_score': False})]
    226 
    227     def __len__(self):
    228         return self._size
    229 

...........................................................................
/home/aquemy/.local/lib/python2.7/site-packages/sklearn/model_selection/_validation.py in _fit_and_score(estimator=Pipeline(memory=None,
     steps=[('rebalance', ... random_state=42, verbose=0, warm_start=False))]), X=array([[ 0.,  0.,  5., ...,  0.,  0.,  0.],
    ...0.],
       [ 0.,  0., 10., ..., 12.,  1.,  0.]]), y=array([0, 1, 2, ..., 8, 9, 8]), scorer={'score': <function _passthrough_scorer>}, train=array([ 169,  176,  178, ..., 1794, 1795, 1796]), test=array([  0,   1,   2,   3,   4,   5,   6,   7,  ..., 181, 186, 188, 189, 190,
       194, 195, 198]), verbose=0, parameters=None, fit_params={}, return_train_score=False, return_parameters=False, return_n_test_samples=False, return_times=True, return_estimator=False, error_score='raise-deprecating')
    523 
    524     try:
    525         if y_train is None:
    526             estimator.fit(X_train, **fit_params)
    527         else:
--> 528             estimator.fit(X_train, y_train, **fit_params)
        estimator.fit = <bound method Pipeline.fit of Pipeline(memory=No...random_state=42, verbose=0, warm_start=False))])>
        X_train = array([[ 0.,  0.,  6., ...,  9.,  4.,  0.],
    ...0.],
       [ 0.,  0., 10., ..., 12.,  1.,  0.]])
        y_train = array([9, 5, 0, ..., 8, 9, 8])
        fit_params = {}
    529 
    530     except Exception as e:
    531         # Note fit time as time until error
    532         fit_time = time.time() - start_time

...........................................................................
/usr/local/lib/python2.7/dist-packages/imblearn/pipeline.py in fit(self=Pipeline(memory=None,
     steps=[('rebalance', ... random_state=42, verbose=0, warm_start=False))]), X=array([[ 0.,  0.,  6., ...,  9.,  4.,  0.],
    ...0.],
       [ 0.,  0., 10., ..., 12.,  1.,  0.]]), y=array([9, 5, 0, ..., 8, 9, 8]), **fit_params={})
    234             This estimator
    235 
    236         """
    237         Xt, yt, fit_params = self._fit(X, y, **fit_params)
    238         if self._final_estimator is not None:
--> 239             self._final_estimator.fit(Xt, yt, **fit_params)
        self._final_estimator.fit = <bound method RandomForestClassifier.fit of Rand...e, random_state=42, verbose=0, warm_start=False)>
        Xt = array([[ -2.25621143],
       [ -9.94557286],
  ...],
       [ 15.05889812],
       [-23.05675235]])
        yt = array([0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,...9, 9, 9, 9, 9,
       9, 9, 9, 9, 9, 9, 9, 9, 9])
        fit_params = {}
    240         return self
    241 
    242     def fit_transform(self, X, y=None, **fit_params):
    243         """Fit the model and transform with the final estimator

...........................................................................
/home/aquemy/.local/lib/python2.7/site-packages/sklearn/ensemble/forest.py in fit(self=RandomForestClassifier(bootstrap=False, class_we...se, random_state=42, verbose=0, warm_start=False), X=array([[ -2.2562115 ],
       [ -9.945573  ],
  ...058898  ],
       [-23.056753  ]], dtype=float32), y=array([[0.],
       [0.],
       [0.],
       [1...    [9.],
       [9.],
       [9.],
       [9.]]), sample_weight=None)
    328             trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,
    329                              **_joblib_parallel_args(prefer='threads'))(
    330                 delayed(_parallel_build_trees)(
    331                     t, self, X, y, sample_weight, i, len(trees),
    332                     verbose=self.verbose, class_weight=self.class_weight)
--> 333                 for i, t in enumerate(trees))
        i = 74
    334 
    335             # Collect newly grown trees
    336             self.estimators_.extend(trees)
    337 

...........................................................................
/home/aquemy/.local/lib/python2.7/site-packages/sklearn/externals/joblib/parallel.py in __call__(self=Parallel(n_jobs=1), iterable=<generator object <genexpr>>)
    912             # self._original_iterator is None, then this means either
    913             # that pre_dispatch == "all", n_jobs == 1 or that the first batch
    914             # was very quick and its callback already dispatched all the
    915             # remaining jobs.
    916             self._iterating = False
--> 917             if self.dispatch_one_batch(iterator):
        self.dispatch_one_batch = <bound method Parallel.dispatch_one_batch of Parallel(n_jobs=1)>
        iterator = <generator object <genexpr>>
    918                 self._iterating = self._original_iterator is not None
    919 
    920             while self.dispatch_one_batch(iterator):
    921                 pass

...........................................................................
/home/aquemy/.local/lib/python2.7/site-packages/sklearn/externals/joblib/parallel.py in dispatch_one_batch(self=Parallel(n_jobs=1), iterator=<generator object <genexpr>>)
    754                                  self._pickle_cache)
    755             if len(tasks) == 0:
    756                 # No more tasks available in the iterator: tell caller to stop.
    757                 return False
    758             else:
--> 759                 self._dispatch(tasks)
        self._dispatch = <bound method Parallel._dispatch of Parallel(n_jobs=1)>
        tasks = <sklearn.externals.joblib.parallel.BatchedCalls object>
    760                 return True
    761 
    762     def _print(self, msg, msg_args):
    763         """Display the message on stout or stderr depending on verbosity"""

...........................................................................
/home/aquemy/.local/lib/python2.7/site-packages/sklearn/externals/joblib/parallel.py in _dispatch(self=Parallel(n_jobs=1), batch=<sklearn.externals.joblib.parallel.BatchedCalls object>)
    711 
    712         dispatch_timestamp = time.time()
    713         cb = BatchCompletionCallBack(dispatch_timestamp, len(batch), self)
    714         with self._lock:
    715             job_idx = len(self._jobs)
--> 716             job = self._backend.apply_async(batch, callback=cb)
        job = undefined
        self._backend.apply_async = <bound method SequentialBackend.apply_async of <...lib._parallel_backends.SequentialBackend object>>
        batch = <sklearn.externals.joblib.parallel.BatchedCalls object>
        cb = <sklearn.externals.joblib.parallel.BatchCompletionCallBack object>
    717             # A job can complete so quickly than its callback is
    718             # called before we get here, causing self._jobs to
    719             # grow. To ensure correct results ordering, .insert is
    720             # used (rather than .append) in the following line

...........................................................................
/home/aquemy/.local/lib/python2.7/site-packages/sklearn/externals/joblib/_parallel_backends.py in apply_async(self=<sklearn.externals.joblib._parallel_backends.SequentialBackend object>, func=<sklearn.externals.joblib.parallel.BatchedCalls object>, callback=<sklearn.externals.joblib.parallel.BatchCompletionCallBack object>)
    177             raise ValueError('n_jobs == 0 in Parallel has no meaning')
    178         return 1
    179 
    180     def apply_async(self, func, callback=None):
    181         """Schedule a func to be run"""
--> 182         result = ImmediateResult(func)
        result = undefined
        func = <sklearn.externals.joblib.parallel.BatchedCalls object>
    183         if callback:
    184             callback(result)
    185         return result
    186 

...........................................................................
/home/aquemy/.local/lib/python2.7/site-packages/sklearn/externals/joblib/_parallel_backends.py in __init__(self=<sklearn.externals.joblib._parallel_backends.ImmediateResult object>, batch=<sklearn.externals.joblib.parallel.BatchedCalls object>)
    544 
    545 class ImmediateResult(object):
    546     def __init__(self, batch):
    547         # Don't delay the application, to avoid keeping the input
    548         # arguments in memory
--> 549         self.results = batch()
        self.results = undefined
        batch = <sklearn.externals.joblib.parallel.BatchedCalls object>
    550 
    551     def get(self):
    552         return self.results
    553 

...........................................................................
/home/aquemy/.local/lib/python2.7/site-packages/sklearn/externals/joblib/parallel.py in __call__(self=<sklearn.externals.joblib.parallel.BatchedCalls object>)
    220     def __call__(self):
    221         # Set the default nested backend to self._backend but do not set the
    222         # change the default number of processes to -1
    223         with parallel_backend(self._backend, n_jobs=self._n_jobs):
    224             return [func(*args, **kwargs)
--> 225                     for func, args, kwargs in self.items]
        func = <function _parallel_build_trees>
        args = (DecisionTreeClassifier(class_weight=None, criter...=False, random_state=1608637542, splitter='best'), RandomForestClassifier(bootstrap=False, class_we...se, random_state=42, verbose=0, warm_start=False), array([[ -2.2562115 ],
       [ -9.945573  ],
  ...058898  ],
       [-23.056753  ]], dtype=float32), array([[0.],
       [0.],
       [0.],
       [1...    [9.],
       [9.],
       [9.],
       [9.]]), None, 0, 75)
        kwargs = {'class_weight': None, 'verbose': 0}
        self.items = [(<function _parallel_build_trees>, (DecisionTreeClassifier(class_weight=None, criter...=False, random_state=1608637542, splitter='best'), RandomForestClassifier(bootstrap=False, class_we...se, random_state=42, verbose=0, warm_start=False), array([[ -2.2562115 ],
       [ -9.945573  ],
  ...058898  ],
       [-23.056753  ]], dtype=float32), array([[0.],
       [0.],
       [0.],
       [1...    [9.],
       [9.],
       [9.],
       [9.]]), None, 0, 75), {'class_weight': None, 'verbose': 0})]
    226 
    227     def __len__(self):
    228         return self._size
    229 

...........................................................................
/home/aquemy/.local/lib/python2.7/site-packages/sklearn/ensemble/forest.py in _parallel_build_trees(tree=DecisionTreeClassifier(class_weight=None, criter...=False, random_state=1608637542, splitter='best'), forest=RandomForestClassifier(bootstrap=False, class_we...se, random_state=42, verbose=0, warm_start=False), X=array([[ -2.2562115 ],
       [ -9.945573  ],
  ...058898  ],
       [-23.056753  ]], dtype=float32), y=array([[0.],
       [0.],
       [0.],
       [1...    [9.],
       [9.],
       [9.],
       [9.]]), sample_weight=None, tree_idx=0, n_trees=75, verbose=0, class_weight=None)
    116         elif class_weight == 'balanced_subsample':
    117             curr_sample_weight *= compute_sample_weight('balanced', y, indices)
    118 
    119         tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)
    120     else:
--> 121         tree.fit(X, y, sample_weight=sample_weight, check_input=False)
        tree.fit = <bound method DecisionTreeClassifier.fit of Deci...False, random_state=1608637542, splitter='best')>
        X = array([[ -2.2562115 ],
       [ -9.945573  ],
  ...058898  ],
       [-23.056753  ]], dtype=float32)
        y = array([[0.],
       [0.],
       [0.],
       [1...    [9.],
       [9.],
       [9.],
       [9.]])
        sample_weight = None
    122 
    123     return tree
    124 
    125 

...........................................................................
/home/aquemy/.local/lib/python2.7/site-packages/sklearn/tree/tree.py in fit(self=DecisionTreeClassifier(class_weight=None, criter...=False, random_state=1608637542, splitter='best'), X=array([[ -2.2562115 ],
       [ -9.945573  ],
  ...058898  ],
       [-23.056753  ]], dtype=float32), y=array([[0.],
       [0.],
       [0.],
       [1...    [9.],
       [9.],
       [9.],
       [9.]]), sample_weight=None, check_input=False, X_idx_sorted=None)
    796 
    797         super(DecisionTreeClassifier, self).fit(
    798             X, y,
    799             sample_weight=sample_weight,
    800             check_input=check_input,
--> 801             X_idx_sorted=X_idx_sorted)
        X_idx_sorted = None
    802         return self
    803 
    804     def predict_proba(self, X, check_input=True):
    805         """Predict class probabilities of the input samples X.

...........................................................................
/home/aquemy/.local/lib/python2.7/site-packages/sklearn/tree/tree.py in fit(self=DecisionTreeClassifier(class_weight=None, criter...=False, random_state=1608637542, splitter='best'), X=array([[ -2.2562115 ],
       [ -9.945573  ],
  ...058898  ],
       [-23.056753  ]], dtype=float32), y=array([[0.],
       [0.],
       [0.],
       [1...    [9.],
       [9.],
       [9.],
       [9.]]), sample_weight=None, check_input=False, X_idx_sorted=None)
    237         if not 0 <= self.min_weight_fraction_leaf <= 0.5:
    238             raise ValueError("min_weight_fraction_leaf must in [0, 0.5]")
    239         if max_depth <= 0:
    240             raise ValueError("max_depth must be greater than zero. ")
    241         if not (0 < max_features <= self.n_features_):
--> 242             raise ValueError("max_features must be in (0, n_features]")
    243         if not isinstance(max_leaf_nodes, (numbers.Integral, np.integer)):
    244             raise ValueError("max_leaf_nodes must be integral number but was "
    245                              "%r" % max_leaf_nodes)
    246         if -1 < max_leaf_nodes < 2:

ValueError: max_features must be in (0, n_features]
___________________________________________________________________________
Best score: 0.923190438404 (0.030405158842) [J] | Score: 0.0 (0.0) [J]
JoblibValueError
___________________________________________________________________________
...........................................................................
/home/aquemy/dev/dp_hyperparameters/extension/main.py in <module>()
     27 
     28     serializer.serialize_results(scenario, policy)
     29 
     30 if __name__ == "__main__":
     31     args = cli.parse_args()
---> 32     main(args)

...........................................................................
/home/aquemy/dev/dp_hyperparameters/extension/main.py in main(args=Namespace(customize=[(['control', 'seed'], '42')...='./scenarios/rf_digits_joint.yaml', verbosity=0))
     21         test_size=0.4, 
     22         random_state=scenario['control']['seed']
     23     )
     24 
     25     policy = policies.initiate(scenario['setup']['policy'], config)
---> 26     policy.run(X,y)
        policy.run = <bound method Joint.run of <experiment.policies.joint.Joint object>>
        X = array([[ 0.,  0.,  5., ...,  0.,  0.,  0.],
    ...0.],
       [ 0.,  0., 10., ..., 12.,  1.,  0.]])
        y = array([0, 1, 2, ..., 8, 9, 8])
     27 
     28     serializer.serialize_results(scenario, policy)
     29 
     30 if __name__ == "__main__":

...........................................................................
/home/aquemy/dev/dp_hyperparameters/extension/experiment/policies/joint.py in run(self=<experiment.policies.joint.Joint object>, X=array([[ 0.,  0.,  5., ...,  0.,  0.,  0.],
    ...0.],
       [ 0.,  0., 10., ..., 12.,  1.,  0.]]), y=array([0, 1, 2, ..., 8, 9, 8]))
     32             algo=tpe.suggest, 
     33             max_evals=None,
     34             max_time=self.config['time'],     
     35             trials=trials,
     36             show_progressbar=False,
---> 37             verbose=0
     38         )
     39 
     40         best_config = self.context['best_config']
     41         super(Joint, self).display_step_results(best_config)

...........................................................................
/home/aquemy/dev/dp_hyperparameters/extension/hyperopt/fmin.py in fmin(fn=<functools.partial object>, space={'algorithm': {'bootstrap': <hyperopt.pyll.base.Apply object>, 'criterion': <hyperopt.pyll.base.Apply object>, 'max_depth': <hyperopt.pyll.base.Apply object>, 'max_features': <hyperopt.pyll.base.Apply object>, 'max_leaf_nodes': <hyperopt.pyll.base.Apply object>, 'min_samples_split': <hyperopt.pyll.base.Apply object>, 'n_estimators': <hyperopt.pyll.base.Apply object>}, 'pipeline': {'features': <hyperopt.pyll.base.Apply object>, 'normalizer': <hyperopt.pyll.base.Apply object>, 'rebalance': <hyperopt.pyll.base.Apply object>}}, algo=<function suggest>, max_evals=9223372036854775807, max_time=300, trials=<hyperopt.base.Trials object>, rstate=<mtrand.RandomState object>, allow_trials_fmin=True, pass_expr_memo_ctrl=None, catch_eval_exceptions=False, verbose=0, return_argmin=True, points_to_evaluate=None, max_queue_len=1, show_progressbar=False)
    406             pass_expr_memo_ctrl=pass_expr_memo_ctrl,
    407             verbose=verbose,
    408             catch_eval_exceptions=catch_eval_exceptions,
    409             return_argmin=return_argmin,
    410             show_progressbar=show_progressbar,
--> 411             max_time=max_time
        max_time = 300
    412         )
    413 
    414     if trials is None:
    415         if points_to_evaluate is None:

...........................................................................
/home/aquemy/dev/dp_hyperparameters/extension/hyperopt/base.py in fmin(self=<hyperopt.base.Trials object>, fn=<functools.partial object>, space={'algorithm': {'bootstrap': <hyperopt.pyll.base.Apply object>, 'criterion': <hyperopt.pyll.base.Apply object>, 'max_depth': <hyperopt.pyll.base.Apply object>, 'max_features': <hyperopt.pyll.base.Apply object>, 'max_leaf_nodes': <hyperopt.pyll.base.Apply object>, 'min_samples_split': <hyperopt.pyll.base.Apply object>, 'n_estimators': <hyperopt.pyll.base.Apply object>}, 'pipeline': {'features': <hyperopt.pyll.base.Apply object>, 'normalizer': <hyperopt.pyll.base.Apply object>, 'rebalance': <hyperopt.pyll.base.Apply object>}}, algo=<function suggest>, max_evals=9223372036854775807, max_time=300, rstate=<mtrand.RandomState object>, verbose=0, pass_expr_memo_ctrl=None, catch_eval_exceptions=False, return_argmin=True, show_progressbar=False)
    636             verbose=verbose,
    637             allow_trials_fmin=False,  # -- prevent recursion
    638             pass_expr_memo_ctrl=pass_expr_memo_ctrl,
    639             catch_eval_exceptions=catch_eval_exceptions,
    640             return_argmin=return_argmin,
--> 641             show_progressbar=show_progressbar)
        show_progressbar = False
    642 
    643 
    644 def trials_from_docs(docs, validate=True, **kwargs):
    645     """Construct a Trials base class instance from a list of trials documents

...........................................................................
/home/aquemy/dev/dp_hyperparameters/extension/hyperopt/fmin.py in fmin(fn=<functools.partial object>, space={'algorithm': {'bootstrap': <hyperopt.pyll.base.Apply object>, 'criterion': <hyperopt.pyll.base.Apply object>, 'max_depth': <hyperopt.pyll.base.Apply object>, 'max_features': <hyperopt.pyll.base.Apply object>, 'max_leaf_nodes': <hyperopt.pyll.base.Apply object>, 'min_samples_split': <hyperopt.pyll.base.Apply object>, 'n_estimators': <hyperopt.pyll.base.Apply object>}, 'pipeline': {'features': <hyperopt.pyll.base.Apply object>, 'normalizer': <hyperopt.pyll.base.Apply object>, 'rebalance': <hyperopt.pyll.base.Apply object>}}, algo=<function suggest>, max_evals=9223372036854775807, max_time=300, trials=<hyperopt.base.Trials object>, rstate=<mtrand.RandomState object>, allow_trials_fmin=False, pass_expr_memo_ctrl=None, catch_eval_exceptions=False, verbose=0, return_argmin=True, points_to_evaluate=None, max_queue_len=1, show_progressbar=False)
    426                     verbose=verbose,
    427                     max_queue_len=max_queue_len,
    428                     show_progressbar=show_progressbar,
    429                     max_time=max_time)
    430     rval.catch_eval_exceptions = catch_eval_exceptions
--> 431     rval.exhaust()
        rval.exhaust = <bound method FMinIter.exhaust of <hyperopt.fmin.FMinIter object>>
    432     if return_argmin:
    433         return trials.argmin
    434     elif len(trials) > 0:
    435         # Only if there are some succesfull trail runs, return the best point in the evaluation space

...........................................................................
/home/aquemy/dev/dp_hyperparameters/extension/hyperopt/fmin.py in exhaust(self=<hyperopt.fmin.FMinIter object>)
    273             raise StopIteration()
    274         return self.trials
    275 
    276     def exhaust(self):
    277         n_done = len(self.trials)
--> 278         self.run(self.max_evals - n_done, block_until_done=self.asynchronous)
        self.run = <bound method FMinIter.run of <hyperopt.fmin.FMinIter object>>
        self.max_evals = 9223372036854775807
        n_done = 0
        self.asynchronous = False
    279         self.trials.refresh()
    280         return self
    281 
    282 

...........................................................................
/home/aquemy/dev/dp_hyperparameters/extension/hyperopt/fmin.py in run(self=<hyperopt.fmin.FMinIter object>, N=9223372036854775807, block_until_done=False)
    232                     if self.asynchronous:
    233                         # -- wait for workers to fill in the trials
    234                         time.sleep(self.poll_interval_secs)
    235                     else:
    236                         # -- loop over trials and do the jobs directly
--> 237                         self.serial_evaluate()
        self.serial_evaluate = <bound method FMinIter.serial_evaluate of <hyperopt.fmin.FMinIter object>>
    238                     try:
    239                         res = [d['result']['loss'] for d in
    240                                          self.trials.trials if
    241                                          d['result']['status'] == 'ok']

...........................................................................
/home/aquemy/dev/dp_hyperparameters/extension/hyperopt/fmin.py in serial_evaluate(self=<hyperopt.fmin.FMinIter object>, N=-1)
    138                 trial['book_time'] = now
    139                 trial['refresh_time'] = now
    140                 spec = base.spec_from_misc(trial['misc'])
    141                 ctrl = base.Ctrl(self.trials, current_trial=trial)
    142                 try:
--> 143                     result = self.domain.evaluate(spec, ctrl)
        result = undefined
        self.domain.evaluate = <bound method Domain.evaluate of <hyperopt.base.Domain object>>
        spec = {'bootstrap': 1, 'criterion': 0, 'features': 2, 'features_SelectKBest_features__k': 1, 'max_depth': 2, 'max_features': 2, 'max_leaf_nodes': 3, 'min_samples_split': 2, 'n_estimators': 4, 'normalizer': 3, ...}
        ctrl = <hyperopt.base.Ctrl object>
    144                 except Exception as e:
    145                     logger.info('job exception: %s' % str(e))
    146                     trial['state'] = base.JOB_STATE_ERROR
    147                     trial['misc']['error'] = (str(type(e)), str(e))

...........................................................................
/home/aquemy/dev/dp_hyperparameters/extension/hyperopt/base.py in evaluate(self=<hyperopt.base.Domain object>, config={'bootstrap': 1, 'criterion': 0, 'features': 2, 'features_SelectKBest_features__k': 1, 'max_depth': 2, 'max_features': 2, 'max_leaf_nodes': 3, 'min_samples_split': 2, 'n_estimators': 4, 'normalizer': 3, ...}, ctrl=<hyperopt.base.Ctrl object>, attach_attachments=True)
    841             #    or the normal Python part (self.fn)
    842             pyll_rval = pyll.rec_eval(
    843                 self.expr,
    844                 memo=memo,
    845                 print_node_on_error=self.rec_eval_print_node_on_error)
--> 846             rval = self.fn(pyll_rval)
        rval = undefined
        self.fn = <functools.partial object>
        pyll_rval = {'algorithm': {'bootstrap': False, 'criterion': 'gini', 'max_depth': 3, 'max_features': 3, 'max_leaf_nodes': None, 'min_samples_split': 5, 'n_estimators': 100}, 'pipeline': {'features': ('features_SelectKBest', {'features__k': 2}), 'normalizer': ('normalizer_MinMaxScaler', {}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 6})}}
    847 
    848         if isinstance(rval, (float, int, np.number)):
    849             dict_rval = {'loss': float(rval), 'status': STATUS_OK}
    850         else:

...........................................................................
/home/aquemy/dev/dp_hyperparameters/extension/experiment/objective.py in objective_joint(wconfig={'algorithm': {'bootstrap': False, 'criterion': 'gini', 'max_depth': 3, 'max_features': 3, 'max_leaf_nodes': None, 'min_samples_split': 5, 'n_estimators': 100}, 'pipeline': {'features': ('features_SelectKBest', {'features__k': 2}), 'normalizer': ('normalizer_MinMaxScaler', {}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 6})}}, algorithm='RandomForest', X=array([[ 0.,  0.,  5., ...,  0.,  0.,  0.],
    ...0.],
       [ 0.,  0., 10., ..., 12.,  1.,  0.]]), y=array([0, 1, 2, ..., 8, 9, 8]), context={'baseline_score': 0.9272021217853512, 'baseline_score_std': 0.026919033284817703, 'best_config': {'algorithm': {'bootstrap': True, 'criterion': 'entropy', 'max_depth': None, 'max_features': None, 'max_leaf_nodes': None, 'min_samples_split': 3, 'n_estimators': 75}, 'config_hash': {'algorithm': 'f42e45bee34ac9973699212f6c8b845daea9383a', 'config': 'ae61cfde4c8b4c792e42d6b6be4af4ffb3d90e13', 'pipeline': '15ff3d6270ac899763bb3f72417c48bcd56aa7d8'}, 'duration': 8.20555305480957, 'iteration': 65, 'loss': 0.07680956159632557, 'max_history_score': 0.9231904384036744, 'max_history_score_std': 0.03040515884196498, 'max_history_step': 'joint', 'pipeline': {'features': ('features_NoneType', {}), 'normalizer': ('normalizer_StandardScaler', {'normalizer__with_mean': True, 'normalizer__with_std': True}), 'rebalance': ('rebalance_NearMiss', {'rebalance__n_neighbors': 1})}, 'score': 0.9231904384036744, ...}, 'history': [{'algorithm': {'bootstrap': False, 'criterion': 'entropy', 'max_depth': 1, 'max_features': 3, 'max_leaf_nodes': 3, 'min_samples_split': 5, 'n_estimators': 50}, 'config_hash': {'algorithm': '752fa095cdab58a238ae606c613606188964cc0c', 'config': 'fd24b065dda6bdeb1077793f9df480ff318c7a37', 'pipeline': '13ea3359c453b8993fcec1e88bc0e19cd0a2b112'}, 'duration': 0.689669132232666, 'iteration': 0, 'loss': 0.6602879519109309, 'max_history_score': 0.3397120480890691, 'max_history_score_std': 0.03346542949100545, 'max_history_step': 'joint', 'pipeline': {'features': ('features_SelectKBest', {'features__k': 4}), 'normalizer': ('normalizer_MinMaxScaler', {}), 'rebalance': ('rebalance_NoneType', {})}, 'score': 0.3397120480890691, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'gini', 'max_depth': 4, 'max_features': 1, 'max_leaf_nodes': 5, 'min_samples_split': 3, 'n_estimators': 25}, 'config_hash': {'algorithm': '9d9de4aee820052ddfe83bfffca420f6b50837d3', 'config': 'fb22f80fb4358ae1ee4c9bd4a83543992be8d806', 'pipeline': '6251ad4bb7a110726a67f90c319f4717ac37a312'}, 'duration': 1.4300940036773682, 'iteration': 1, 'loss': 0.5122196101741096, 'max_history_score': 0.48778038982589045, 'max_history_score_std': 0.05486079759217226, 'max_history_step': 'joint', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 2, 'features__selectkbest__k': 2}), 'normalizer': ('normalizer_StandardScaler', {'normalizer__with_mean': True, 'normalizer__with_std': True}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 5})}, 'score': 0.48778038982589045, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': 4, 'max_features': 1, 'max_leaf_nodes': None, 'min_samples_split': 2, 'n_estimators': 10}, 'config_hash': {'algorithm': '2ed7d27df9a1b2d5e63da76f7cb309616c232022', 'config': '8c97cdb885dd05cfd8c40ee3ac445b61e5c767a8', 'pipeline': 'c0abb5e23a4739d3120740a9519fb36c43eb94d5'}, 'duration': 3.0036678314208984, 'iteration': 2, 'loss': 0.38319264175312906, 'max_history_score': 0.6168073582468709, 'max_history_score_std': 0.05286679173001824, 'max_history_step': 'joint', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 1, 'features__selectkbest__k': 4}), 'normalizer': ('normalizer_PowerTransformer', {}), 'rebalance': ('rebalance_NearMiss', {'rebalance__n_neighbors': 2})}, 'score': 0.6168073582468709, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'entropy', 'max_depth': None, 'max_features': None, 'max_leaf_nodes': 2, 'min_samples_split': 2, 'n_estimators': 100}, 'config_hash': {'algorithm': '17962655e3b76dfcd0843d1e5c2cb7a9db1c6a79', 'config': '16fbb5fd5cfbbacfddf27c61c0c7397a7f6d8ade', 'pipeline': '13ea3359c453b8993fcec1e88bc0e19cd0a2b112'}, 'duration': 1.3447980880737305, 'iteration': 3, 'loss': 0.6768840987778313, 'max_history_score': 0.6168073582468709, 'max_history_score_std': 0.05286679173001824, 'max_history_step': 'joint', 'pipeline': {'features': ('features_SelectKBest', {'features__k': 4}), 'normalizer': ('normalizer_MinMaxScaler', {}), 'rebalance': ('rebalance_NoneType', {})}, 'score': 0.32311590122216866, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'gini', 'max_depth': 2, 'max_features': 2, 'max_leaf_nodes': 2, 'min_samples_split': 3, 'n_estimators': 100}, 'config_hash': {'algorithm': '1ea8965b2247f86950e54510ee6d79399816341b', 'config': 'a77c698197c31308211b854e81a998178941f87d', 'pipeline': 'aaf976c7c663a31fa039582d42f9e07101556a7c'}, 'duration': 2.589430093765259, 'iteration': 4, 'loss': 0.2544808950572157, 'max_history_score': 0.7455191049427843, 'max_history_score_std': 0.04843448308166839, 'max_history_step': 'joint', 'pipeline': {'features': ('features_NoneType', {}), 'normalizer': ('normalizer_PowerTransformer', {}), 'rebalance': ('rebalance_NoneType', {})}, 'score': 0.7455191049427843, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': None, 'max_features': 2, 'max_leaf_nodes': 5, 'min_samples_split': 5, 'n_estimators': 25}, 'config_hash': {'algorithm': 'fd8aeb6a05eaaba41e676d60596c8e0c71b35e0c', 'config': '1fc13606bca3aaf342ca6ea21139cb598b56f8db', 'pipeline': 'f00bd8de05642e026bbba4ad20d3a60088c86b6c'}, 'duration': 1.8779079914093018, 'iteration': 5, 'loss': 0.531551018758381, 'max_history_score': 0.7455191049427843, 'max_history_score_std': 0.04843448308166839, 'max_history_step': 'joint', 'pipeline': {'features': ('features_PCA', {'features__n_components': 2}), 'normalizer': ('normalizer_MinMaxScaler', {}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 5})}, 'score': 0.46844898124161904, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'entropy', 'max_depth': None, 'max_features': 2, 'max_leaf_nodes': None, 'min_samples_split': 2, 'n_estimators': 10}, 'config_hash': {'algorithm': 'a49ecb99e74217d6812f98ead7bc9d1fe4a53ba0', 'config': '6749af1a67b4dbcd2b4719e419d99908063c05e1', 'pipeline': '19bdf19a2eec5febce95ab8fa2a71040d75114aa'}, 'duration': 1.5498578548431396, 'iteration': 6, 'loss': 0.14471329609998995, 'max_history_score': 0.85528670390001, 'max_history_score_std': 0.02213730791268438, 'max_history_step': 'joint', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 4, 'features__selectkbest__k': 3}), 'normalizer': ('normalizer_NoneType', {}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 7})}, 'score': 0.85528670390001, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': 1, 'max_features': 3, 'max_leaf_nodes': 3, 'min_samples_split': 3, 'n_estimators': 75}, 'config_hash': {'algorithm': 'ebfb16234172ae811ff21185ff92bbdbb8f32f14', 'config': 'd92d4ada2394fc132733e176e926ee53acdc6a00', 'pipeline': '8071e7cbf86a5c3056493dc3aa40063aeb28cdfe'}, 'duration': 1.3618149757385254, 'iteration': 7, 'loss': 0.6158612049395463, 'max_history_score': 0.85528670390001, 'max_history_score_std': 0.02213730791268438, 'max_history_step': 'joint', 'pipeline': {'features': ('features_SelectKBest', {'features__k': 4}), 'normalizer': ('normalizer_StandardScaler', {'normalizer__with_mean': True, 'normalizer__with_std': True}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 5})}, 'score': 0.3841387950604537, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'entropy', 'max_depth': 1, 'max_features': 1, 'max_leaf_nodes': 5, 'min_samples_split': 2, 'n_estimators': 100}, 'config_hash': {'algorithm': '896b53c75a2db568fb7b6da3bfca2f7a1535a11b', 'config': 'f0d0b1d2cedc22ae15d9a208a3fc3fc133bf0d3d', 'pipeline': 'c9761c9a33bf75d6dcad0742c421548a7655ccc9'}, 'duration': 2.297278881072998, 'iteration': 8, 'loss': 0.40673663548410355, 'max_history_score': 0.85528670390001, 'max_history_score_std': 0.02213730791268438, 'max_history_step': 'joint', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 2, 'features__selectkbest__k': 4}), 'normalizer': ('normalizer_StandardScaler', {'normalizer__with_mean': False, 'normalizer__with_std': False}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 5})}, 'score': 0.5932633645158965, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'entropy', 'max_depth': 2, 'max_features': None, 'max_leaf_nodes': None, 'min_samples_split': 5, 'n_estimators': 25}, 'config_hash': {'algorithm': '0b0e954757c4f75343a6efb740ad93260ed781ae', 'config': '47584de0e60d0d12c7dbbf0dc60e5aea96e3f4b2', 'pipeline': 'b37ee32d59413053bf9a2a72c8ff7135f3701e05'}, 'duration': 0.7249000072479248, 'iteration': 9, 'loss': 0.6965910020393421, 'max_history_score': 0.85528670390001, 'max_history_score_std': 0.02213730791268438, 'max_history_step': 'joint', 'pipeline': {'features': ('features_SelectKBest', {'features__k': 3}), 'normalizer': ('normalizer_NoneType', {}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 7})}, 'score': 0.3034089979606579, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'gini', 'max_depth': 2, 'max_features': 2, 'max_leaf_nodes': 5, 'min_samples_split': 5, 'n_estimators': 75}, 'config_hash': {'algorithm': 'f1ead1d9e33ea927e1dd27d872a058fa3de4f832', 'config': 'eecb88ee2b1b95d741c1b5c7751534d31aae6a77', 'pipeline': '6746650871e8b61efc9302b092dc05f7cdb179d5'}, 'duration': 5.340634822845459, 'iteration': 10, 'loss': 0.7687016290977936, 'max_history_score': 0.85528670390001, 'max_history_score_std': 0.02213730791268438, 'max_history_step': 'joint', 'pipeline': {'features': ('features_SelectKBest', {'features__k': 3}), 'normalizer': ('normalizer_RobustScaler', {'normalizer__quantile_range': (...), 'normalizer__with_centering': False, 'normalizer__with_scaling': False}), 'rebalance': ('rebalance_CondensedNearestNeighbour', {'rebalance__n_neighbors': 1})}, 'score': 0.23129837090220637, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': 1, 'max_features': 2, 'max_leaf_nodes': 2, 'min_samples_split': 3, 'n_estimators': 75}, 'config_hash': {'algorithm': '531a3bb8ccf0baa06727af4b3de9e62d25e6eabf', 'config': '27a7ed0502b321ab7256b77c8ce79e90cb9da815', 'pipeline': '77e6d84e2217b92b3cf67cc6defef9dd3554cec0'}, 'duration': 1.775357961654663, 'iteration': 11, 'loss': 0.6313818737375694, 'max_history_score': 0.85528670390001, 'max_history_score_std': 0.02213730791268438, 'max_history_step': 'joint', 'pipeline': {'features': ('features_SelectKBest', {'features__k': 4}), 'normalizer': ('normalizer_MinMaxScaler', {}), 'rebalance': ('rebalance_NearMiss', {'rebalance__n_neighbors': 3})}, 'score': 0.3686181262624307, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'entropy', 'max_depth': 4, 'max_features': 3, 'max_leaf_nodes': 2, 'min_samples_split': 3, 'n_estimators': 10}, 'config_hash': {'algorithm': '93518f8ded6074d537900b26be72f8485782f933', 'config': '45f056102dd2d644bd8befa471f17b2311ac7954', 'pipeline': '5240329df25c9a533d025c1a401d49835a501b41'}, 'duration': 3.2622711658477783, 'iteration': 12, 'loss': 0.6120243191353301, 'max_history_score': 0.85528670390001, 'max_history_score_std': 0.02213730791268438, 'max_history_step': 'joint', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 4, 'features__selectkbest__k': 2}), 'normalizer': ('normalizer_PowerTransformer', {}), 'rebalance': ('rebalance_NearMiss', {'rebalance__n_neighbors': 1})}, 'score': 0.38797568086467, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'entropy', 'max_depth': None, 'max_features': 1, 'max_leaf_nodes': 5, 'min_samples_split': 3, 'n_estimators': 75}, 'config_hash': {'algorithm': 'e515d45b764fa43591032874a0ff9c25bf12fddd', 'config': 'ba108323623936872824ed8f1c41d615d25523b3', 'pipeline': '9d823bc0442f21b5ce8af67a5eb1237f64ffc2f8'}, 'duration': 2.5326571464538574, 'iteration': 13, 'loss': 0.6271427382991047, 'max_history_score': 0.85528670390001, 'max_history_score_std': 0.02213730791268438, 'max_history_step': 'joint', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 1, 'features__selectkbest__k': 1}), 'normalizer': ('normalizer_StandardScaler', {'normalizer__with_mean': True, 'normalizer__with_std': True}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 5})}, 'score': 0.3728572617008953, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'entropy', 'max_depth': 3, 'max_features': 2, 'max_leaf_nodes': 2, 'min_samples_split': 3, 'n_estimators': 25}, 'config_hash': {'algorithm': '2808e67f609eba5c8a97f81ac0c9413cd37cf7aa', 'config': 'dde4d3b5f37741629cb58bfc4051ed9f98c8f311', 'pipeline': 'bc52deabf1f5ee60968ba541d9d2574353c30a9c'}, 'duration': 0.7145559787750244, 'iteration': 14, 'loss': 0.6831045572696203, 'max_history_score': 0.85528670390001, 'max_history_score_std': 0.02213730791268438, 'max_history_step': 'joint', 'pipeline': {'features': ('features_SelectKBest', {'features__k': 3}), 'normalizer': ('normalizer_MinMaxScaler', {}), 'rebalance': ('rebalance_NearMiss', {'rebalance__n_neighbors': 1})}, 'score': 0.31689544273037973, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'gini', 'max_depth': 2, 'max_features': 2, 'max_leaf_nodes': None, 'min_samples_split': 5, 'n_estimators': 100}, 'config_hash': {'algorithm': 'b942acdead762d34afeb474bc2fe6f7fd0f23493', 'config': '1080c25b92da3f15a6f8eec003957f7e0a66324f', 'pipeline': 'cfa84fe703dc5bc0bbd2257a6d524fee2693b804'}, 'duration': 2.812459945678711, 'iteration': 15, 'loss': 0.6921421091202761, 'max_history_score': 0.85528670390001, 'max_history_score_std': 0.02213730791268438, 'max_history_step': 'joint', 'pipeline': {'features': ('features_SelectKBest', {'features__k': 2}), 'normalizer': ('normalizer_PowerTransformer', {}), 'rebalance': ('rebalance_NoneType', {})}, 'score': 0.3078578908797239, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'entropy', 'max_depth': 2, 'max_features': 3, 'max_leaf_nodes': 3, 'min_samples_split': 2, 'n_estimators': 75}, 'config_hash': {'algorithm': '250661ce4193a61ef44d2f77694b52b785ff032d', 'config': 'c3e8cf4eca5aafcae4ac31b0449e105ca127ffe2', 'pipeline': 'c4dd111513ea35f97dd3aec3e8e7f6268ce035da'}, 'duration': 1.0555319786071777, 'iteration': 16, 'loss': 1.0, 'max_history_score': 0.85528670390001, 'max_history_score_std': 0.02213730791268438, 'max_history_step': 'joint', 'pipeline': {'features': ('features_PCA', {'features__n_components': 2}), 'normalizer': ('normalizer_RobustScaler', {'normalizer__quantile_range': (...), 'normalizer__with_centering': False, 'normalizer__with_scaling': True}), 'rebalance': ('rebalance_NearMiss', {'rebalance__n_neighbors': 2})}, 'score': 0.0, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'entropy', 'max_depth': 3, 'max_features': 3, 'max_leaf_nodes': None, 'min_samples_split': 3, 'n_estimators': 25}, 'config_hash': {'algorithm': '05ac02bd045c65dc4089894902ad6253661a2692', 'config': '3449b4a1c2e488e26a7195ee9edca19b854ebd33', 'pipeline': '505d3f71b534917375d765e64b0611e7dfb83746'}, 'duration': 5.5412821769714355, 'iteration': 17, 'loss': 0.7289151155121668, 'max_history_score': 0.85528670390001, 'max_history_score_std': 0.02213730791268438, 'max_history_step': 'joint', 'pipeline': {'features': ('features_SelectKBest', {'features__k': 4}), 'normalizer': ('normalizer_MinMaxScaler', {}), 'rebalance': ('rebalance_CondensedNearestNeighbour', {'rebalance__n_neighbors': 2})}, 'score': 0.2710848844878332, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'entropy', 'max_depth': 2, 'max_features': None, 'max_leaf_nodes': None, 'min_samples_split': 2, 'n_estimators': 25}, 'config_hash': {'algorithm': 'de3b3a352ebb260e16c6b213a08c9144d17a744b', 'config': '224987ffdbbb9b6182cff18d8374518b917e4f2e', 'pipeline': '12c89200a558b2f3b91332566f41050143aecbe7'}, 'duration': 2.4646048545837402, 'iteration': 18, 'loss': 0.6545902512995826, 'max_history_score': 0.85528670390001, 'max_history_score_std': 0.02213730791268438, 'max_history_step': 'joint', 'pipeline': {'features': ('features_NoneType', {}), 'normalizer': ('normalizer_PowerTransformer', {}), 'rebalance': ('rebalance_NearMiss', {'rebalance__n_neighbors': 2})}, 'score': 0.3454097487004174, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'gini', 'max_depth': None, 'max_features': 1, 'max_leaf_nodes': None, 'min_samples_split': 3, 'n_estimators': 100}, 'config_hash': {'algorithm': '30ca111584767bbf0464df40b4c928cf7ddf9459', 'config': '97ca7d6a017c721084dec2a5d2e5a67e1e6ae2f0', 'pipeline': '789eca82ea4a42d61927670c538867b745fd81d3'}, 'duration': 7.164499044418335, 'iteration': 19, 'loss': 0.6536825403350528, 'max_history_score': 0.85528670390001, 'max_history_score_std': 0.02213730791268438, 'max_history_step': 'joint', 'pipeline': {'features': ('features_SelectKBest', {'features__k': 3}), 'normalizer': ('normalizer_RobustScaler', {'normalizer__quantile_range': (...), 'normalizer__with_centering': False, 'normalizer__with_scaling': True}), 'rebalance': ('rebalance_CondensedNearestNeighbour', {'rebalance__n_neighbors': 3})}, 'score': 0.3463174596649472, ...}, ...], 'history_hash': ['fd24b065dda6bdeb1077793f9df480ff318c7a37', 'fb22f80fb4358ae1ee4c9bd4a83543992be8d806', '8c97cdb885dd05cfd8c40ee3ac445b61e5c767a8', '16fbb5fd5cfbbacfddf27c61c0c7397a7f6d8ade', 'a77c698197c31308211b854e81a998178941f87d', '1fc13606bca3aaf342ca6ea21139cb598b56f8db', '6749af1a67b4dbcd2b4719e419d99908063c05e1', 'd92d4ada2394fc132733e176e926ee53acdc6a00', 'f0d0b1d2cedc22ae15d9a208a3fc3fc133bf0d3d', '47584de0e60d0d12c7dbbf0dc60e5aea96e3f4b2', 'eecb88ee2b1b95d741c1b5c7751534d31aae6a77', '27a7ed0502b321ab7256b77c8ce79e90cb9da815', '45f056102dd2d644bd8befa471f17b2311ac7954', 'ba108323623936872824ed8f1c41d615d25523b3', 'dde4d3b5f37741629cb58bfc4051ed9f98c8f311', '1080c25b92da3f15a6f8eec003957f7e0a66324f', 'c3e8cf4eca5aafcae4ac31b0449e105ca127ffe2', '3449b4a1c2e488e26a7195ee9edca19b854ebd33', '224987ffdbbb9b6182cff18d8374518b917e4f2e', '97ca7d6a017c721084dec2a5d2e5a67e1e6ae2f0', ...], 'history_index': {'00e8f4ca31525b847c5f1d5de869962edbe23b64': 99, '0114519a520f59f3b000aba3a54f4681935d0c6f': 110, '01b68ec8d6fe15ffdadf1adfd0d809307d3ce41e': 81, '05465becb12810ce291074be22a0275a42efbea8': 52, '064f53edf4748bb2df4ff59f147331aad21219e1': 48, '087efef4a19f272562d2d445dac0edd8096ba2fa': 58, '0fd4d71ca3a89c7d14af5087f2a2e2c1b1975351': 51, '1080c25b92da3f15a6f8eec003957f7e0a66324f': 15, '10ca1ab51b6af0696dab2c8cbaf8de5e3812a6de': 78, '10cb7f1ca9feb52539f61b654f31107801dadc1c': 89, ...}, 'iteration': 112, 'max_history_score': 0.9231904384036744, 'max_history_score_std': 0.03040515884196498, 'max_history_step': 'joint'}, config={'algorithm': 'RandomForest', 'seed': 42, 'time': 300})
    108 
    109 def objective_algo(algo_config, current_pipeline_config, algorithm, X, y, context, config):
    110     return objective(current_pipeline_config, algo_config, algorithm, X, y, context, config, step='algorithm')
    111 
    112 def objective_joint(wconfig, algorithm, X, y, context, config):
--> 113     return objective(wconfig['pipeline'], wconfig['algorithm'], algorithm, X, y, context, config, step='joint')
        wconfig = {'algorithm': {'bootstrap': False, 'criterion': 'gini', 'max_depth': 3, 'max_features': 3, 'max_leaf_nodes': None, 'min_samples_split': 5, 'n_estimators': 100}, 'pipeline': {'features': ('features_SelectKBest', {'features__k': 2}), 'normalizer': ('normalizer_MinMaxScaler', {}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 6})}}
        algorithm = 'RandomForest'
        X = array([[ 0.,  0.,  5., ...,  0.,  0.,  0.],
    ...0.],
       [ 0.,  0., 10., ..., 12.,  1.,  0.]])
        y = array([0, 1, 2, ..., 8, 9, 8])
        context = {'baseline_score': 0.9272021217853512, 'baseline_score_std': 0.026919033284817703, 'best_config': {'algorithm': {'bootstrap': True, 'criterion': 'entropy', 'max_depth': None, 'max_features': None, 'max_leaf_nodes': None, 'min_samples_split': 3, 'n_estimators': 75}, 'config_hash': {'algorithm': 'f42e45bee34ac9973699212f6c8b845daea9383a', 'config': 'ae61cfde4c8b4c792e42d6b6be4af4ffb3d90e13', 'pipeline': '15ff3d6270ac899763bb3f72417c48bcd56aa7d8'}, 'duration': 8.20555305480957, 'iteration': 65, 'loss': 0.07680956159632557, 'max_history_score': 0.9231904384036744, 'max_history_score_std': 0.03040515884196498, 'max_history_step': 'joint', 'pipeline': {'features': ('features_NoneType', {}), 'normalizer': ('normalizer_StandardScaler', {'normalizer__with_mean': True, 'normalizer__with_std': True}), 'rebalance': ('rebalance_NearMiss', {'rebalance__n_neighbors': 1})}, 'score': 0.9231904384036744, ...}, 'history': [{'algorithm': {'bootstrap': False, 'criterion': 'entropy', 'max_depth': 1, 'max_features': 3, 'max_leaf_nodes': 3, 'min_samples_split': 5, 'n_estimators': 50}, 'config_hash': {'algorithm': '752fa095cdab58a238ae606c613606188964cc0c', 'config': 'fd24b065dda6bdeb1077793f9df480ff318c7a37', 'pipeline': '13ea3359c453b8993fcec1e88bc0e19cd0a2b112'}, 'duration': 0.689669132232666, 'iteration': 0, 'loss': 0.6602879519109309, 'max_history_score': 0.3397120480890691, 'max_history_score_std': 0.03346542949100545, 'max_history_step': 'joint', 'pipeline': {'features': ('features_SelectKBest', {'features__k': 4}), 'normalizer': ('normalizer_MinMaxScaler', {}), 'rebalance': ('rebalance_NoneType', {})}, 'score': 0.3397120480890691, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'gini', 'max_depth': 4, 'max_features': 1, 'max_leaf_nodes': 5, 'min_samples_split': 3, 'n_estimators': 25}, 'config_hash': {'algorithm': '9d9de4aee820052ddfe83bfffca420f6b50837d3', 'config': 'fb22f80fb4358ae1ee4c9bd4a83543992be8d806', 'pipeline': '6251ad4bb7a110726a67f90c319f4717ac37a312'}, 'duration': 1.4300940036773682, 'iteration': 1, 'loss': 0.5122196101741096, 'max_history_score': 0.48778038982589045, 'max_history_score_std': 0.05486079759217226, 'max_history_step': 'joint', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 2, 'features__selectkbest__k': 2}), 'normalizer': ('normalizer_StandardScaler', {'normalizer__with_mean': True, 'normalizer__with_std': True}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 5})}, 'score': 0.48778038982589045, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': 4, 'max_features': 1, 'max_leaf_nodes': None, 'min_samples_split': 2, 'n_estimators': 10}, 'config_hash': {'algorithm': '2ed7d27df9a1b2d5e63da76f7cb309616c232022', 'config': '8c97cdb885dd05cfd8c40ee3ac445b61e5c767a8', 'pipeline': 'c0abb5e23a4739d3120740a9519fb36c43eb94d5'}, 'duration': 3.0036678314208984, 'iteration': 2, 'loss': 0.38319264175312906, 'max_history_score': 0.6168073582468709, 'max_history_score_std': 0.05286679173001824, 'max_history_step': 'joint', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 1, 'features__selectkbest__k': 4}), 'normalizer': ('normalizer_PowerTransformer', {}), 'rebalance': ('rebalance_NearMiss', {'rebalance__n_neighbors': 2})}, 'score': 0.6168073582468709, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'entropy', 'max_depth': None, 'max_features': None, 'max_leaf_nodes': 2, 'min_samples_split': 2, 'n_estimators': 100}, 'config_hash': {'algorithm': '17962655e3b76dfcd0843d1e5c2cb7a9db1c6a79', 'config': '16fbb5fd5cfbbacfddf27c61c0c7397a7f6d8ade', 'pipeline': '13ea3359c453b8993fcec1e88bc0e19cd0a2b112'}, 'duration': 1.3447980880737305, 'iteration': 3, 'loss': 0.6768840987778313, 'max_history_score': 0.6168073582468709, 'max_history_score_std': 0.05286679173001824, 'max_history_step': 'joint', 'pipeline': {'features': ('features_SelectKBest', {'features__k': 4}), 'normalizer': ('normalizer_MinMaxScaler', {}), 'rebalance': ('rebalance_NoneType', {})}, 'score': 0.32311590122216866, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'gini', 'max_depth': 2, 'max_features': 2, 'max_leaf_nodes': 2, 'min_samples_split': 3, 'n_estimators': 100}, 'config_hash': {'algorithm': '1ea8965b2247f86950e54510ee6d79399816341b', 'config': 'a77c698197c31308211b854e81a998178941f87d', 'pipeline': 'aaf976c7c663a31fa039582d42f9e07101556a7c'}, 'duration': 2.589430093765259, 'iteration': 4, 'loss': 0.2544808950572157, 'max_history_score': 0.7455191049427843, 'max_history_score_std': 0.04843448308166839, 'max_history_step': 'joint', 'pipeline': {'features': ('features_NoneType', {}), 'normalizer': ('normalizer_PowerTransformer', {}), 'rebalance': ('rebalance_NoneType', {})}, 'score': 0.7455191049427843, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': None, 'max_features': 2, 'max_leaf_nodes': 5, 'min_samples_split': 5, 'n_estimators': 25}, 'config_hash': {'algorithm': 'fd8aeb6a05eaaba41e676d60596c8e0c71b35e0c', 'config': '1fc13606bca3aaf342ca6ea21139cb598b56f8db', 'pipeline': 'f00bd8de05642e026bbba4ad20d3a60088c86b6c'}, 'duration': 1.8779079914093018, 'iteration': 5, 'loss': 0.531551018758381, 'max_history_score': 0.7455191049427843, 'max_history_score_std': 0.04843448308166839, 'max_history_step': 'joint', 'pipeline': {'features': ('features_PCA', {'features__n_components': 2}), 'normalizer': ('normalizer_MinMaxScaler', {}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 5})}, 'score': 0.46844898124161904, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'entropy', 'max_depth': None, 'max_features': 2, 'max_leaf_nodes': None, 'min_samples_split': 2, 'n_estimators': 10}, 'config_hash': {'algorithm': 'a49ecb99e74217d6812f98ead7bc9d1fe4a53ba0', 'config': '6749af1a67b4dbcd2b4719e419d99908063c05e1', 'pipeline': '19bdf19a2eec5febce95ab8fa2a71040d75114aa'}, 'duration': 1.5498578548431396, 'iteration': 6, 'loss': 0.14471329609998995, 'max_history_score': 0.85528670390001, 'max_history_score_std': 0.02213730791268438, 'max_history_step': 'joint', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 4, 'features__selectkbest__k': 3}), 'normalizer': ('normalizer_NoneType', {}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 7})}, 'score': 0.85528670390001, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': 1, 'max_features': 3, 'max_leaf_nodes': 3, 'min_samples_split': 3, 'n_estimators': 75}, 'config_hash': {'algorithm': 'ebfb16234172ae811ff21185ff92bbdbb8f32f14', 'config': 'd92d4ada2394fc132733e176e926ee53acdc6a00', 'pipeline': '8071e7cbf86a5c3056493dc3aa40063aeb28cdfe'}, 'duration': 1.3618149757385254, 'iteration': 7, 'loss': 0.6158612049395463, 'max_history_score': 0.85528670390001, 'max_history_score_std': 0.02213730791268438, 'max_history_step': 'joint', 'pipeline': {'features': ('features_SelectKBest', {'features__k': 4}), 'normalizer': ('normalizer_StandardScaler', {'normalizer__with_mean': True, 'normalizer__with_std': True}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 5})}, 'score': 0.3841387950604537, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'entropy', 'max_depth': 1, 'max_features': 1, 'max_leaf_nodes': 5, 'min_samples_split': 2, 'n_estimators': 100}, 'config_hash': {'algorithm': '896b53c75a2db568fb7b6da3bfca2f7a1535a11b', 'config': 'f0d0b1d2cedc22ae15d9a208a3fc3fc133bf0d3d', 'pipeline': 'c9761c9a33bf75d6dcad0742c421548a7655ccc9'}, 'duration': 2.297278881072998, 'iteration': 8, 'loss': 0.40673663548410355, 'max_history_score': 0.85528670390001, 'max_history_score_std': 0.02213730791268438, 'max_history_step': 'joint', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 2, 'features__selectkbest__k': 4}), 'normalizer': ('normalizer_StandardScaler', {'normalizer__with_mean': False, 'normalizer__with_std': False}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 5})}, 'score': 0.5932633645158965, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'entropy', 'max_depth': 2, 'max_features': None, 'max_leaf_nodes': None, 'min_samples_split': 5, 'n_estimators': 25}, 'config_hash': {'algorithm': '0b0e954757c4f75343a6efb740ad93260ed781ae', 'config': '47584de0e60d0d12c7dbbf0dc60e5aea96e3f4b2', 'pipeline': 'b37ee32d59413053bf9a2a72c8ff7135f3701e05'}, 'duration': 0.7249000072479248, 'iteration': 9, 'loss': 0.6965910020393421, 'max_history_score': 0.85528670390001, 'max_history_score_std': 0.02213730791268438, 'max_history_step': 'joint', 'pipeline': {'features': ('features_SelectKBest', {'features__k': 3}), 'normalizer': ('normalizer_NoneType', {}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 7})}, 'score': 0.3034089979606579, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'gini', 'max_depth': 2, 'max_features': 2, 'max_leaf_nodes': 5, 'min_samples_split': 5, 'n_estimators': 75}, 'config_hash': {'algorithm': 'f1ead1d9e33ea927e1dd27d872a058fa3de4f832', 'config': 'eecb88ee2b1b95d741c1b5c7751534d31aae6a77', 'pipeline': '6746650871e8b61efc9302b092dc05f7cdb179d5'}, 'duration': 5.340634822845459, 'iteration': 10, 'loss': 0.7687016290977936, 'max_history_score': 0.85528670390001, 'max_history_score_std': 0.02213730791268438, 'max_history_step': 'joint', 'pipeline': {'features': ('features_SelectKBest', {'features__k': 3}), 'normalizer': ('normalizer_RobustScaler', {'normalizer__quantile_range': (...), 'normalizer__with_centering': False, 'normalizer__with_scaling': False}), 'rebalance': ('rebalance_CondensedNearestNeighbour', {'rebalance__n_neighbors': 1})}, 'score': 0.23129837090220637, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': 1, 'max_features': 2, 'max_leaf_nodes': 2, 'min_samples_split': 3, 'n_estimators': 75}, 'config_hash': {'algorithm': '531a3bb8ccf0baa06727af4b3de9e62d25e6eabf', 'config': '27a7ed0502b321ab7256b77c8ce79e90cb9da815', 'pipeline': '77e6d84e2217b92b3cf67cc6defef9dd3554cec0'}, 'duration': 1.775357961654663, 'iteration': 11, 'loss': 0.6313818737375694, 'max_history_score': 0.85528670390001, 'max_history_score_std': 0.02213730791268438, 'max_history_step': 'joint', 'pipeline': {'features': ('features_SelectKBest', {'features__k': 4}), 'normalizer': ('normalizer_MinMaxScaler', {}), 'rebalance': ('rebalance_NearMiss', {'rebalance__n_neighbors': 3})}, 'score': 0.3686181262624307, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'entropy', 'max_depth': 4, 'max_features': 3, 'max_leaf_nodes': 2, 'min_samples_split': 3, 'n_estimators': 10}, 'config_hash': {'algorithm': '93518f8ded6074d537900b26be72f8485782f933', 'config': '45f056102dd2d644bd8befa471f17b2311ac7954', 'pipeline': '5240329df25c9a533d025c1a401d49835a501b41'}, 'duration': 3.2622711658477783, 'iteration': 12, 'loss': 0.6120243191353301, 'max_history_score': 0.85528670390001, 'max_history_score_std': 0.02213730791268438, 'max_history_step': 'joint', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 4, 'features__selectkbest__k': 2}), 'normalizer': ('normalizer_PowerTransformer', {}), 'rebalance': ('rebalance_NearMiss', {'rebalance__n_neighbors': 1})}, 'score': 0.38797568086467, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'entropy', 'max_depth': None, 'max_features': 1, 'max_leaf_nodes': 5, 'min_samples_split': 3, 'n_estimators': 75}, 'config_hash': {'algorithm': 'e515d45b764fa43591032874a0ff9c25bf12fddd', 'config': 'ba108323623936872824ed8f1c41d615d25523b3', 'pipeline': '9d823bc0442f21b5ce8af67a5eb1237f64ffc2f8'}, 'duration': 2.5326571464538574, 'iteration': 13, 'loss': 0.6271427382991047, 'max_history_score': 0.85528670390001, 'max_history_score_std': 0.02213730791268438, 'max_history_step': 'joint', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 1, 'features__selectkbest__k': 1}), 'normalizer': ('normalizer_StandardScaler', {'normalizer__with_mean': True, 'normalizer__with_std': True}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 5})}, 'score': 0.3728572617008953, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'entropy', 'max_depth': 3, 'max_features': 2, 'max_leaf_nodes': 2, 'min_samples_split': 3, 'n_estimators': 25}, 'config_hash': {'algorithm': '2808e67f609eba5c8a97f81ac0c9413cd37cf7aa', 'config': 'dde4d3b5f37741629cb58bfc4051ed9f98c8f311', 'pipeline': 'bc52deabf1f5ee60968ba541d9d2574353c30a9c'}, 'duration': 0.7145559787750244, 'iteration': 14, 'loss': 0.6831045572696203, 'max_history_score': 0.85528670390001, 'max_history_score_std': 0.02213730791268438, 'max_history_step': 'joint', 'pipeline': {'features': ('features_SelectKBest', {'features__k': 3}), 'normalizer': ('normalizer_MinMaxScaler', {}), 'rebalance': ('rebalance_NearMiss', {'rebalance__n_neighbors': 1})}, 'score': 0.31689544273037973, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'gini', 'max_depth': 2, 'max_features': 2, 'max_leaf_nodes': None, 'min_samples_split': 5, 'n_estimators': 100}, 'config_hash': {'algorithm': 'b942acdead762d34afeb474bc2fe6f7fd0f23493', 'config': '1080c25b92da3f15a6f8eec003957f7e0a66324f', 'pipeline': 'cfa84fe703dc5bc0bbd2257a6d524fee2693b804'}, 'duration': 2.812459945678711, 'iteration': 15, 'loss': 0.6921421091202761, 'max_history_score': 0.85528670390001, 'max_history_score_std': 0.02213730791268438, 'max_history_step': 'joint', 'pipeline': {'features': ('features_SelectKBest', {'features__k': 2}), 'normalizer': ('normalizer_PowerTransformer', {}), 'rebalance': ('rebalance_NoneType', {})}, 'score': 0.3078578908797239, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'entropy', 'max_depth': 2, 'max_features': 3, 'max_leaf_nodes': 3, 'min_samples_split': 2, 'n_estimators': 75}, 'config_hash': {'algorithm': '250661ce4193a61ef44d2f77694b52b785ff032d', 'config': 'c3e8cf4eca5aafcae4ac31b0449e105ca127ffe2', 'pipeline': 'c4dd111513ea35f97dd3aec3e8e7f6268ce035da'}, 'duration': 1.0555319786071777, 'iteration': 16, 'loss': 1.0, 'max_history_score': 0.85528670390001, 'max_history_score_std': 0.02213730791268438, 'max_history_step': 'joint', 'pipeline': {'features': ('features_PCA', {'features__n_components': 2}), 'normalizer': ('normalizer_RobustScaler', {'normalizer__quantile_range': (...), 'normalizer__with_centering': False, 'normalizer__with_scaling': True}), 'rebalance': ('rebalance_NearMiss', {'rebalance__n_neighbors': 2})}, 'score': 0.0, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'entropy', 'max_depth': 3, 'max_features': 3, 'max_leaf_nodes': None, 'min_samples_split': 3, 'n_estimators': 25}, 'config_hash': {'algorithm': '05ac02bd045c65dc4089894902ad6253661a2692', 'config': '3449b4a1c2e488e26a7195ee9edca19b854ebd33', 'pipeline': '505d3f71b534917375d765e64b0611e7dfb83746'}, 'duration': 5.5412821769714355, 'iteration': 17, 'loss': 0.7289151155121668, 'max_history_score': 0.85528670390001, 'max_history_score_std': 0.02213730791268438, 'max_history_step': 'joint', 'pipeline': {'features': ('features_SelectKBest', {'features__k': 4}), 'normalizer': ('normalizer_MinMaxScaler', {}), 'rebalance': ('rebalance_CondensedNearestNeighbour', {'rebalance__n_neighbors': 2})}, 'score': 0.2710848844878332, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'entropy', 'max_depth': 2, 'max_features': None, 'max_leaf_nodes': None, 'min_samples_split': 2, 'n_estimators': 25}, 'config_hash': {'algorithm': 'de3b3a352ebb260e16c6b213a08c9144d17a744b', 'config': '224987ffdbbb9b6182cff18d8374518b917e4f2e', 'pipeline': '12c89200a558b2f3b91332566f41050143aecbe7'}, 'duration': 2.4646048545837402, 'iteration': 18, 'loss': 0.6545902512995826, 'max_history_score': 0.85528670390001, 'max_history_score_std': 0.02213730791268438, 'max_history_step': 'joint', 'pipeline': {'features': ('features_NoneType', {}), 'normalizer': ('normalizer_PowerTransformer', {}), 'rebalance': ('rebalance_NearMiss', {'rebalance__n_neighbors': 2})}, 'score': 0.3454097487004174, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'gini', 'max_depth': None, 'max_features': 1, 'max_leaf_nodes': None, 'min_samples_split': 3, 'n_estimators': 100}, 'config_hash': {'algorithm': '30ca111584767bbf0464df40b4c928cf7ddf9459', 'config': '97ca7d6a017c721084dec2a5d2e5a67e1e6ae2f0', 'pipeline': '789eca82ea4a42d61927670c538867b745fd81d3'}, 'duration': 7.164499044418335, 'iteration': 19, 'loss': 0.6536825403350528, 'max_history_score': 0.85528670390001, 'max_history_score_std': 0.02213730791268438, 'max_history_step': 'joint', 'pipeline': {'features': ('features_SelectKBest', {'features__k': 3}), 'normalizer': ('normalizer_RobustScaler', {'normalizer__quantile_range': (...), 'normalizer__with_centering': False, 'normalizer__with_scaling': True}), 'rebalance': ('rebalance_CondensedNearestNeighbour', {'rebalance__n_neighbors': 3})}, 'score': 0.3463174596649472, ...}, ...], 'history_hash': ['fd24b065dda6bdeb1077793f9df480ff318c7a37', 'fb22f80fb4358ae1ee4c9bd4a83543992be8d806', '8c97cdb885dd05cfd8c40ee3ac445b61e5c767a8', '16fbb5fd5cfbbacfddf27c61c0c7397a7f6d8ade', 'a77c698197c31308211b854e81a998178941f87d', '1fc13606bca3aaf342ca6ea21139cb598b56f8db', '6749af1a67b4dbcd2b4719e419d99908063c05e1', 'd92d4ada2394fc132733e176e926ee53acdc6a00', 'f0d0b1d2cedc22ae15d9a208a3fc3fc133bf0d3d', '47584de0e60d0d12c7dbbf0dc60e5aea96e3f4b2', 'eecb88ee2b1b95d741c1b5c7751534d31aae6a77', '27a7ed0502b321ab7256b77c8ce79e90cb9da815', '45f056102dd2d644bd8befa471f17b2311ac7954', 'ba108323623936872824ed8f1c41d615d25523b3', 'dde4d3b5f37741629cb58bfc4051ed9f98c8f311', '1080c25b92da3f15a6f8eec003957f7e0a66324f', 'c3e8cf4eca5aafcae4ac31b0449e105ca127ffe2', '3449b4a1c2e488e26a7195ee9edca19b854ebd33', '224987ffdbbb9b6182cff18d8374518b917e4f2e', '97ca7d6a017c721084dec2a5d2e5a67e1e6ae2f0', ...], 'history_index': {'00e8f4ca31525b847c5f1d5de869962edbe23b64': 99, '0114519a520f59f3b000aba3a54f4681935d0c6f': 110, '01b68ec8d6fe15ffdadf1adfd0d809307d3ce41e': 81, '05465becb12810ce291074be22a0275a42efbea8': 52, '064f53edf4748bb2df4ff59f147331aad21219e1': 48, '087efef4a19f272562d2d445dac0edd8096ba2fa': 58, '0fd4d71ca3a89c7d14af5087f2a2e2c1b1975351': 51, '1080c25b92da3f15a6f8eec003957f7e0a66324f': 15, '10ca1ab51b6af0696dab2c8cbaf8de5e3812a6de': 78, '10cb7f1ca9feb52539f61b654f31107801dadc1c': 89, ...}, 'iteration': 112, 'max_history_score': 0.9231904384036744, 'max_history_score_std': 0.03040515884196498, 'max_history_step': 'joint'}
        config = {'algorithm': 'RandomForest', 'seed': 42, 'time': 300}
    114 
    115 
    116 def get_baseline_score(algorithm, X, y, seed):
    117     pipeline, _ = pipeline_conf_to_full_pipeline(

...........................................................................
/home/aquemy/dev/dp_hyperparameters/extension/experiment/objective.py in objective(pipeline_config={'features': ('features_SelectKBest', {'features__k': 2}), 'normalizer': ('normalizer_MinMaxScaler', {}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 6})}, algo_config={'bootstrap': False, 'criterion': 'gini', 'max_depth': 3, 'max_features': 3, 'max_leaf_nodes': None, 'min_samples_split': 5, 'n_estimators': 100}, algorithm='RandomForest', X=array([[ 0.,  0.,  5., ...,  0.,  0.,  0.],
    ...0.],
       [ 0.,  0., 10., ..., 12.,  1.,  0.]]), y=array([0, 1, 2, ..., 8, 9, 8]), context={'baseline_score': 0.9272021217853512, 'baseline_score_std': 0.026919033284817703, 'best_config': {'algorithm': {'bootstrap': True, 'criterion': 'entropy', 'max_depth': None, 'max_features': None, 'max_leaf_nodes': None, 'min_samples_split': 3, 'n_estimators': 75}, 'config_hash': {'algorithm': 'f42e45bee34ac9973699212f6c8b845daea9383a', 'config': 'ae61cfde4c8b4c792e42d6b6be4af4ffb3d90e13', 'pipeline': '15ff3d6270ac899763bb3f72417c48bcd56aa7d8'}, 'duration': 8.20555305480957, 'iteration': 65, 'loss': 0.07680956159632557, 'max_history_score': 0.9231904384036744, 'max_history_score_std': 0.03040515884196498, 'max_history_step': 'joint', 'pipeline': {'features': ('features_NoneType', {}), 'normalizer': ('normalizer_StandardScaler', {'normalizer__with_mean': True, 'normalizer__with_std': True}), 'rebalance': ('rebalance_NearMiss', {'rebalance__n_neighbors': 1})}, 'score': 0.9231904384036744, ...}, 'history': [{'algorithm': {'bootstrap': False, 'criterion': 'entropy', 'max_depth': 1, 'max_features': 3, 'max_leaf_nodes': 3, 'min_samples_split': 5, 'n_estimators': 50}, 'config_hash': {'algorithm': '752fa095cdab58a238ae606c613606188964cc0c', 'config': 'fd24b065dda6bdeb1077793f9df480ff318c7a37', 'pipeline': '13ea3359c453b8993fcec1e88bc0e19cd0a2b112'}, 'duration': 0.689669132232666, 'iteration': 0, 'loss': 0.6602879519109309, 'max_history_score': 0.3397120480890691, 'max_history_score_std': 0.03346542949100545, 'max_history_step': 'joint', 'pipeline': {'features': ('features_SelectKBest', {'features__k': 4}), 'normalizer': ('normalizer_MinMaxScaler', {}), 'rebalance': ('rebalance_NoneType', {})}, 'score': 0.3397120480890691, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'gini', 'max_depth': 4, 'max_features': 1, 'max_leaf_nodes': 5, 'min_samples_split': 3, 'n_estimators': 25}, 'config_hash': {'algorithm': '9d9de4aee820052ddfe83bfffca420f6b50837d3', 'config': 'fb22f80fb4358ae1ee4c9bd4a83543992be8d806', 'pipeline': '6251ad4bb7a110726a67f90c319f4717ac37a312'}, 'duration': 1.4300940036773682, 'iteration': 1, 'loss': 0.5122196101741096, 'max_history_score': 0.48778038982589045, 'max_history_score_std': 0.05486079759217226, 'max_history_step': 'joint', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 2, 'features__selectkbest__k': 2}), 'normalizer': ('normalizer_StandardScaler', {'normalizer__with_mean': True, 'normalizer__with_std': True}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 5})}, 'score': 0.48778038982589045, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': 4, 'max_features': 1, 'max_leaf_nodes': None, 'min_samples_split': 2, 'n_estimators': 10}, 'config_hash': {'algorithm': '2ed7d27df9a1b2d5e63da76f7cb309616c232022', 'config': '8c97cdb885dd05cfd8c40ee3ac445b61e5c767a8', 'pipeline': 'c0abb5e23a4739d3120740a9519fb36c43eb94d5'}, 'duration': 3.0036678314208984, 'iteration': 2, 'loss': 0.38319264175312906, 'max_history_score': 0.6168073582468709, 'max_history_score_std': 0.05286679173001824, 'max_history_step': 'joint', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 1, 'features__selectkbest__k': 4}), 'normalizer': ('normalizer_PowerTransformer', {}), 'rebalance': ('rebalance_NearMiss', {'rebalance__n_neighbors': 2})}, 'score': 0.6168073582468709, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'entropy', 'max_depth': None, 'max_features': None, 'max_leaf_nodes': 2, 'min_samples_split': 2, 'n_estimators': 100}, 'config_hash': {'algorithm': '17962655e3b76dfcd0843d1e5c2cb7a9db1c6a79', 'config': '16fbb5fd5cfbbacfddf27c61c0c7397a7f6d8ade', 'pipeline': '13ea3359c453b8993fcec1e88bc0e19cd0a2b112'}, 'duration': 1.3447980880737305, 'iteration': 3, 'loss': 0.6768840987778313, 'max_history_score': 0.6168073582468709, 'max_history_score_std': 0.05286679173001824, 'max_history_step': 'joint', 'pipeline': {'features': ('features_SelectKBest', {'features__k': 4}), 'normalizer': ('normalizer_MinMaxScaler', {}), 'rebalance': ('rebalance_NoneType', {})}, 'score': 0.32311590122216866, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'gini', 'max_depth': 2, 'max_features': 2, 'max_leaf_nodes': 2, 'min_samples_split': 3, 'n_estimators': 100}, 'config_hash': {'algorithm': '1ea8965b2247f86950e54510ee6d79399816341b', 'config': 'a77c698197c31308211b854e81a998178941f87d', 'pipeline': 'aaf976c7c663a31fa039582d42f9e07101556a7c'}, 'duration': 2.589430093765259, 'iteration': 4, 'loss': 0.2544808950572157, 'max_history_score': 0.7455191049427843, 'max_history_score_std': 0.04843448308166839, 'max_history_step': 'joint', 'pipeline': {'features': ('features_NoneType', {}), 'normalizer': ('normalizer_PowerTransformer', {}), 'rebalance': ('rebalance_NoneType', {})}, 'score': 0.7455191049427843, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': None, 'max_features': 2, 'max_leaf_nodes': 5, 'min_samples_split': 5, 'n_estimators': 25}, 'config_hash': {'algorithm': 'fd8aeb6a05eaaba41e676d60596c8e0c71b35e0c', 'config': '1fc13606bca3aaf342ca6ea21139cb598b56f8db', 'pipeline': 'f00bd8de05642e026bbba4ad20d3a60088c86b6c'}, 'duration': 1.8779079914093018, 'iteration': 5, 'loss': 0.531551018758381, 'max_history_score': 0.7455191049427843, 'max_history_score_std': 0.04843448308166839, 'max_history_step': 'joint', 'pipeline': {'features': ('features_PCA', {'features__n_components': 2}), 'normalizer': ('normalizer_MinMaxScaler', {}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 5})}, 'score': 0.46844898124161904, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'entropy', 'max_depth': None, 'max_features': 2, 'max_leaf_nodes': None, 'min_samples_split': 2, 'n_estimators': 10}, 'config_hash': {'algorithm': 'a49ecb99e74217d6812f98ead7bc9d1fe4a53ba0', 'config': '6749af1a67b4dbcd2b4719e419d99908063c05e1', 'pipeline': '19bdf19a2eec5febce95ab8fa2a71040d75114aa'}, 'duration': 1.5498578548431396, 'iteration': 6, 'loss': 0.14471329609998995, 'max_history_score': 0.85528670390001, 'max_history_score_std': 0.02213730791268438, 'max_history_step': 'joint', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 4, 'features__selectkbest__k': 3}), 'normalizer': ('normalizer_NoneType', {}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 7})}, 'score': 0.85528670390001, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': 1, 'max_features': 3, 'max_leaf_nodes': 3, 'min_samples_split': 3, 'n_estimators': 75}, 'config_hash': {'algorithm': 'ebfb16234172ae811ff21185ff92bbdbb8f32f14', 'config': 'd92d4ada2394fc132733e176e926ee53acdc6a00', 'pipeline': '8071e7cbf86a5c3056493dc3aa40063aeb28cdfe'}, 'duration': 1.3618149757385254, 'iteration': 7, 'loss': 0.6158612049395463, 'max_history_score': 0.85528670390001, 'max_history_score_std': 0.02213730791268438, 'max_history_step': 'joint', 'pipeline': {'features': ('features_SelectKBest', {'features__k': 4}), 'normalizer': ('normalizer_StandardScaler', {'normalizer__with_mean': True, 'normalizer__with_std': True}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 5})}, 'score': 0.3841387950604537, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'entropy', 'max_depth': 1, 'max_features': 1, 'max_leaf_nodes': 5, 'min_samples_split': 2, 'n_estimators': 100}, 'config_hash': {'algorithm': '896b53c75a2db568fb7b6da3bfca2f7a1535a11b', 'config': 'f0d0b1d2cedc22ae15d9a208a3fc3fc133bf0d3d', 'pipeline': 'c9761c9a33bf75d6dcad0742c421548a7655ccc9'}, 'duration': 2.297278881072998, 'iteration': 8, 'loss': 0.40673663548410355, 'max_history_score': 0.85528670390001, 'max_history_score_std': 0.02213730791268438, 'max_history_step': 'joint', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 2, 'features__selectkbest__k': 4}), 'normalizer': ('normalizer_StandardScaler', {'normalizer__with_mean': False, 'normalizer__with_std': False}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 5})}, 'score': 0.5932633645158965, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'entropy', 'max_depth': 2, 'max_features': None, 'max_leaf_nodes': None, 'min_samples_split': 5, 'n_estimators': 25}, 'config_hash': {'algorithm': '0b0e954757c4f75343a6efb740ad93260ed781ae', 'config': '47584de0e60d0d12c7dbbf0dc60e5aea96e3f4b2', 'pipeline': 'b37ee32d59413053bf9a2a72c8ff7135f3701e05'}, 'duration': 0.7249000072479248, 'iteration': 9, 'loss': 0.6965910020393421, 'max_history_score': 0.85528670390001, 'max_history_score_std': 0.02213730791268438, 'max_history_step': 'joint', 'pipeline': {'features': ('features_SelectKBest', {'features__k': 3}), 'normalizer': ('normalizer_NoneType', {}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 7})}, 'score': 0.3034089979606579, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'gini', 'max_depth': 2, 'max_features': 2, 'max_leaf_nodes': 5, 'min_samples_split': 5, 'n_estimators': 75}, 'config_hash': {'algorithm': 'f1ead1d9e33ea927e1dd27d872a058fa3de4f832', 'config': 'eecb88ee2b1b95d741c1b5c7751534d31aae6a77', 'pipeline': '6746650871e8b61efc9302b092dc05f7cdb179d5'}, 'duration': 5.340634822845459, 'iteration': 10, 'loss': 0.7687016290977936, 'max_history_score': 0.85528670390001, 'max_history_score_std': 0.02213730791268438, 'max_history_step': 'joint', 'pipeline': {'features': ('features_SelectKBest', {'features__k': 3}), 'normalizer': ('normalizer_RobustScaler', {'normalizer__quantile_range': (...), 'normalizer__with_centering': False, 'normalizer__with_scaling': False}), 'rebalance': ('rebalance_CondensedNearestNeighbour', {'rebalance__n_neighbors': 1})}, 'score': 0.23129837090220637, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': 1, 'max_features': 2, 'max_leaf_nodes': 2, 'min_samples_split': 3, 'n_estimators': 75}, 'config_hash': {'algorithm': '531a3bb8ccf0baa06727af4b3de9e62d25e6eabf', 'config': '27a7ed0502b321ab7256b77c8ce79e90cb9da815', 'pipeline': '77e6d84e2217b92b3cf67cc6defef9dd3554cec0'}, 'duration': 1.775357961654663, 'iteration': 11, 'loss': 0.6313818737375694, 'max_history_score': 0.85528670390001, 'max_history_score_std': 0.02213730791268438, 'max_history_step': 'joint', 'pipeline': {'features': ('features_SelectKBest', {'features__k': 4}), 'normalizer': ('normalizer_MinMaxScaler', {}), 'rebalance': ('rebalance_NearMiss', {'rebalance__n_neighbors': 3})}, 'score': 0.3686181262624307, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'entropy', 'max_depth': 4, 'max_features': 3, 'max_leaf_nodes': 2, 'min_samples_split': 3, 'n_estimators': 10}, 'config_hash': {'algorithm': '93518f8ded6074d537900b26be72f8485782f933', 'config': '45f056102dd2d644bd8befa471f17b2311ac7954', 'pipeline': '5240329df25c9a533d025c1a401d49835a501b41'}, 'duration': 3.2622711658477783, 'iteration': 12, 'loss': 0.6120243191353301, 'max_history_score': 0.85528670390001, 'max_history_score_std': 0.02213730791268438, 'max_history_step': 'joint', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 4, 'features__selectkbest__k': 2}), 'normalizer': ('normalizer_PowerTransformer', {}), 'rebalance': ('rebalance_NearMiss', {'rebalance__n_neighbors': 1})}, 'score': 0.38797568086467, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'entropy', 'max_depth': None, 'max_features': 1, 'max_leaf_nodes': 5, 'min_samples_split': 3, 'n_estimators': 75}, 'config_hash': {'algorithm': 'e515d45b764fa43591032874a0ff9c25bf12fddd', 'config': 'ba108323623936872824ed8f1c41d615d25523b3', 'pipeline': '9d823bc0442f21b5ce8af67a5eb1237f64ffc2f8'}, 'duration': 2.5326571464538574, 'iteration': 13, 'loss': 0.6271427382991047, 'max_history_score': 0.85528670390001, 'max_history_score_std': 0.02213730791268438, 'max_history_step': 'joint', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 1, 'features__selectkbest__k': 1}), 'normalizer': ('normalizer_StandardScaler', {'normalizer__with_mean': True, 'normalizer__with_std': True}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 5})}, 'score': 0.3728572617008953, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'entropy', 'max_depth': 3, 'max_features': 2, 'max_leaf_nodes': 2, 'min_samples_split': 3, 'n_estimators': 25}, 'config_hash': {'algorithm': '2808e67f609eba5c8a97f81ac0c9413cd37cf7aa', 'config': 'dde4d3b5f37741629cb58bfc4051ed9f98c8f311', 'pipeline': 'bc52deabf1f5ee60968ba541d9d2574353c30a9c'}, 'duration': 0.7145559787750244, 'iteration': 14, 'loss': 0.6831045572696203, 'max_history_score': 0.85528670390001, 'max_history_score_std': 0.02213730791268438, 'max_history_step': 'joint', 'pipeline': {'features': ('features_SelectKBest', {'features__k': 3}), 'normalizer': ('normalizer_MinMaxScaler', {}), 'rebalance': ('rebalance_NearMiss', {'rebalance__n_neighbors': 1})}, 'score': 0.31689544273037973, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'gini', 'max_depth': 2, 'max_features': 2, 'max_leaf_nodes': None, 'min_samples_split': 5, 'n_estimators': 100}, 'config_hash': {'algorithm': 'b942acdead762d34afeb474bc2fe6f7fd0f23493', 'config': '1080c25b92da3f15a6f8eec003957f7e0a66324f', 'pipeline': 'cfa84fe703dc5bc0bbd2257a6d524fee2693b804'}, 'duration': 2.812459945678711, 'iteration': 15, 'loss': 0.6921421091202761, 'max_history_score': 0.85528670390001, 'max_history_score_std': 0.02213730791268438, 'max_history_step': 'joint', 'pipeline': {'features': ('features_SelectKBest', {'features__k': 2}), 'normalizer': ('normalizer_PowerTransformer', {}), 'rebalance': ('rebalance_NoneType', {})}, 'score': 0.3078578908797239, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'entropy', 'max_depth': 2, 'max_features': 3, 'max_leaf_nodes': 3, 'min_samples_split': 2, 'n_estimators': 75}, 'config_hash': {'algorithm': '250661ce4193a61ef44d2f77694b52b785ff032d', 'config': 'c3e8cf4eca5aafcae4ac31b0449e105ca127ffe2', 'pipeline': 'c4dd111513ea35f97dd3aec3e8e7f6268ce035da'}, 'duration': 1.0555319786071777, 'iteration': 16, 'loss': 1.0, 'max_history_score': 0.85528670390001, 'max_history_score_std': 0.02213730791268438, 'max_history_step': 'joint', 'pipeline': {'features': ('features_PCA', {'features__n_components': 2}), 'normalizer': ('normalizer_RobustScaler', {'normalizer__quantile_range': (...), 'normalizer__with_centering': False, 'normalizer__with_scaling': True}), 'rebalance': ('rebalance_NearMiss', {'rebalance__n_neighbors': 2})}, 'score': 0.0, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'entropy', 'max_depth': 3, 'max_features': 3, 'max_leaf_nodes': None, 'min_samples_split': 3, 'n_estimators': 25}, 'config_hash': {'algorithm': '05ac02bd045c65dc4089894902ad6253661a2692', 'config': '3449b4a1c2e488e26a7195ee9edca19b854ebd33', 'pipeline': '505d3f71b534917375d765e64b0611e7dfb83746'}, 'duration': 5.5412821769714355, 'iteration': 17, 'loss': 0.7289151155121668, 'max_history_score': 0.85528670390001, 'max_history_score_std': 0.02213730791268438, 'max_history_step': 'joint', 'pipeline': {'features': ('features_SelectKBest', {'features__k': 4}), 'normalizer': ('normalizer_MinMaxScaler', {}), 'rebalance': ('rebalance_CondensedNearestNeighbour', {'rebalance__n_neighbors': 2})}, 'score': 0.2710848844878332, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'entropy', 'max_depth': 2, 'max_features': None, 'max_leaf_nodes': None, 'min_samples_split': 2, 'n_estimators': 25}, 'config_hash': {'algorithm': 'de3b3a352ebb260e16c6b213a08c9144d17a744b', 'config': '224987ffdbbb9b6182cff18d8374518b917e4f2e', 'pipeline': '12c89200a558b2f3b91332566f41050143aecbe7'}, 'duration': 2.4646048545837402, 'iteration': 18, 'loss': 0.6545902512995826, 'max_history_score': 0.85528670390001, 'max_history_score_std': 0.02213730791268438, 'max_history_step': 'joint', 'pipeline': {'features': ('features_NoneType', {}), 'normalizer': ('normalizer_PowerTransformer', {}), 'rebalance': ('rebalance_NearMiss', {'rebalance__n_neighbors': 2})}, 'score': 0.3454097487004174, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'gini', 'max_depth': None, 'max_features': 1, 'max_leaf_nodes': None, 'min_samples_split': 3, 'n_estimators': 100}, 'config_hash': {'algorithm': '30ca111584767bbf0464df40b4c928cf7ddf9459', 'config': '97ca7d6a017c721084dec2a5d2e5a67e1e6ae2f0', 'pipeline': '789eca82ea4a42d61927670c538867b745fd81d3'}, 'duration': 7.164499044418335, 'iteration': 19, 'loss': 0.6536825403350528, 'max_history_score': 0.85528670390001, 'max_history_score_std': 0.02213730791268438, 'max_history_step': 'joint', 'pipeline': {'features': ('features_SelectKBest', {'features__k': 3}), 'normalizer': ('normalizer_RobustScaler', {'normalizer__quantile_range': (...), 'normalizer__with_centering': False, 'normalizer__with_scaling': True}), 'rebalance': ('rebalance_CondensedNearestNeighbour', {'rebalance__n_neighbors': 3})}, 'score': 0.3463174596649472, ...}, ...], 'history_hash': ['fd24b065dda6bdeb1077793f9df480ff318c7a37', 'fb22f80fb4358ae1ee4c9bd4a83543992be8d806', '8c97cdb885dd05cfd8c40ee3ac445b61e5c767a8', '16fbb5fd5cfbbacfddf27c61c0c7397a7f6d8ade', 'a77c698197c31308211b854e81a998178941f87d', '1fc13606bca3aaf342ca6ea21139cb598b56f8db', '6749af1a67b4dbcd2b4719e419d99908063c05e1', 'd92d4ada2394fc132733e176e926ee53acdc6a00', 'f0d0b1d2cedc22ae15d9a208a3fc3fc133bf0d3d', '47584de0e60d0d12c7dbbf0dc60e5aea96e3f4b2', 'eecb88ee2b1b95d741c1b5c7751534d31aae6a77', '27a7ed0502b321ab7256b77c8ce79e90cb9da815', '45f056102dd2d644bd8befa471f17b2311ac7954', 'ba108323623936872824ed8f1c41d615d25523b3', 'dde4d3b5f37741629cb58bfc4051ed9f98c8f311', '1080c25b92da3f15a6f8eec003957f7e0a66324f', 'c3e8cf4eca5aafcae4ac31b0449e105ca127ffe2', '3449b4a1c2e488e26a7195ee9edca19b854ebd33', '224987ffdbbb9b6182cff18d8374518b917e4f2e', '97ca7d6a017c721084dec2a5d2e5a67e1e6ae2f0', ...], 'history_index': {'00e8f4ca31525b847c5f1d5de869962edbe23b64': 99, '0114519a520f59f3b000aba3a54f4681935d0c6f': 110, '01b68ec8d6fe15ffdadf1adfd0d809307d3ce41e': 81, '05465becb12810ce291074be22a0275a42efbea8': 52, '064f53edf4748bb2df4ff59f147331aad21219e1': 48, '087efef4a19f272562d2d445dac0edd8096ba2fa': 58, '0fd4d71ca3a89c7d14af5087f2a2e2c1b1975351': 51, '1080c25b92da3f15a6f8eec003957f7e0a66324f': 15, '10ca1ab51b6af0696dab2c8cbaf8de5e3812a6de': 78, '10cb7f1ca9feb52539f61b654f31107801dadc1c': 89, ...}, 'iteration': 112, 'max_history_score': 0.9231904384036744, 'max_history_score_std': 0.03040515884196498, 'max_history_step': 'joint'}, config={'algorithm': 'RandomForest', 'seed': 42, 'time': 300}, step='joint')
     45                 y,
     46                 cv=10,
     47                 n_jobs=-1,
     48                 return_estimator=False,
     49                 return_train_score=False,
---> 50                 verbose=0)
     51         score = np.mean(scores['test_score'])
     52         std = np.std(scores['test_score'])
     53         status = STATUS_OK
     54     except Exception as e:

...........................................................................
/home/aquemy/.local/lib/python2.7/site-packages/sklearn/model_selection/_validation.py in cross_validate(estimator=Pipeline(memory=None,
     steps=[('rebalance', ... random_state=42, verbose=0, warm_start=False))]), X=array([[ 0.,  0.,  5., ...,  0.,  0.,  0.],
    ...0.],
       [ 0.,  0., 10., ..., 12.,  1.,  0.]]), y=array([0, 1, 2, ..., 8, 9, 8]), groups=None, scoring=None, cv=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1, verbose=0, fit_params=None, pre_dispatch='2*n_jobs', return_train_score=False, return_estimator=False, error_score='raise-deprecating')
    235         delayed(_fit_and_score)(
    236             clone(estimator), X, y, scorers, train, test, verbose, None,
    237             fit_params, return_train_score=return_train_score,
    238             return_times=True, return_estimator=return_estimator,
    239             error_score=error_score)
--> 240         for train, test in cv.split(X, y, groups))
        cv.split = <bound method StratifiedKFold.split of Stratifie...d(n_splits=10, random_state=None, shuffle=False)>
        X = array([[ 0.,  0.,  5., ...,  0.,  0.,  0.],
    ...0.],
       [ 0.,  0., 10., ..., 12.,  1.,  0.]])
        y = array([0, 1, 2, ..., 8, 9, 8])
        groups = None
    241 
    242     zipped_scores = list(zip(*scores))
    243     if return_train_score:
    244         train_scores = zipped_scores.pop(0)

...........................................................................
/home/aquemy/.local/lib/python2.7/site-packages/sklearn/externals/joblib/parallel.py in __call__(self=Parallel(n_jobs=-1), iterable=<generator object <genexpr>>)
    925                 # No need to wait for async callbacks to trigger to
    926                 # consumption.
    927                 self._iterating = False
    928 
    929             with self._backend.retrieval_context():
--> 930                 self.retrieve()
        self.retrieve = <bound method Parallel.retrieve of Parallel(n_jobs=-1)>
    931             # Make sure that we get a last message telling us we are done
    932             elapsed_time = time.time() - self._start_time
    933             self._print('Done %3i out of %3i | elapsed: %s finished',
    934                         (len(self._output), len(self._output),

---------------------------------------------------------------------------
Joblib worker traceback:
---------------------------------------------------------------------------
ValueError                                         Mon Jun 17 13:10:14 2019
PID: 20745                                  Python 2.7.15+: /usr/bin/python
...........................................................................
/home/aquemy/.local/lib/python2.7/site-packages/sklearn/externals/joblib/parallel.py in __call__(self=<sklearn.externals.joblib.parallel.BatchedCalls object>)
    220     def __call__(self):
    221         # Set the default nested backend to self._backend but do not set the
    222         # change the default number of processes to -1
    223         with parallel_backend(self._backend, n_jobs=self._n_jobs):
    224             return [func(*args, **kwargs)
--> 225                     for func, args, kwargs in self.items]
        func = <function _fit_and_score>
        args = (Pipeline(memory=None,
     steps=[('rebalance', ... random_state=42, verbose=0, warm_start=False))]), array([[ 0.,  0.,  5., ...,  0.,  0.,  0.],
    ...0.],
       [ 0.,  0., 10., ..., 12.,  1.,  0.]]), array([0, 1, 2, ..., 8, 9, 8]), {'score': <function _passthrough_scorer>}, array([ 169,  176,  178, ..., 1794, 1795, 1796]), array([  0,   1,   2,   3,   4,   5,   6,   7,  ..., 181, 186, 188, 189, 190,
       194, 195, 198]), 0, None, None)
        kwargs = {'error_score': 'raise-deprecating', 'return_estimator': False, 'return_times': True, 'return_train_score': False}
        self.items = [(<function _fit_and_score>, (Pipeline(memory=None,
     steps=[('rebalance', ... random_state=42, verbose=0, warm_start=False))]), array([[ 0.,  0.,  5., ...,  0.,  0.,  0.],
    ...0.],
       [ 0.,  0., 10., ..., 12.,  1.,  0.]]), array([0, 1, 2, ..., 8, 9, 8]), {'score': <function _passthrough_scorer>}, array([ 169,  176,  178, ..., 1794, 1795, 1796]), array([  0,   1,   2,   3,   4,   5,   6,   7,  ..., 181, 186, 188, 189, 190,
       194, 195, 198]), 0, None, None), {'error_score': 'raise-deprecating', 'return_estimator': False, 'return_times': True, 'return_train_score': False})]
    226 
    227     def __len__(self):
    228         return self._size
    229 

...........................................................................
/home/aquemy/.local/lib/python2.7/site-packages/sklearn/model_selection/_validation.py in _fit_and_score(estimator=Pipeline(memory=None,
     steps=[('rebalance', ... random_state=42, verbose=0, warm_start=False))]), X=array([[ 0.,  0.,  5., ...,  0.,  0.,  0.],
    ...0.],
       [ 0.,  0., 10., ..., 12.,  1.,  0.]]), y=array([0, 1, 2, ..., 8, 9, 8]), scorer={'score': <function _passthrough_scorer>}, train=array([ 169,  176,  178, ..., 1794, 1795, 1796]), test=array([  0,   1,   2,   3,   4,   5,   6,   7,  ..., 181, 186, 188, 189, 190,
       194, 195, 198]), verbose=0, parameters=None, fit_params={}, return_train_score=False, return_parameters=False, return_n_test_samples=False, return_times=True, return_estimator=False, error_score='raise-deprecating')
    523 
    524     try:
    525         if y_train is None:
    526             estimator.fit(X_train, **fit_params)
    527         else:
--> 528             estimator.fit(X_train, y_train, **fit_params)
        estimator.fit = <bound method Pipeline.fit of Pipeline(memory=No...random_state=42, verbose=0, warm_start=False))])>
        X_train = array([[ 0.,  0.,  6., ...,  9.,  4.,  0.],
    ...0.],
       [ 0.,  0., 10., ..., 12.,  1.,  0.]])
        y_train = array([9, 5, 0, ..., 8, 9, 8])
        fit_params = {}
    529 
    530     except Exception as e:
    531         # Note fit time as time until error
    532         fit_time = time.time() - start_time

...........................................................................
/usr/local/lib/python2.7/dist-packages/imblearn/pipeline.py in fit(self=Pipeline(memory=None,
     steps=[('rebalance', ... random_state=42, verbose=0, warm_start=False))]), X=array([[ 0.,  0.,  6., ...,  9.,  4.,  0.],
    ...0.],
       [ 0.,  0., 10., ..., 12.,  1.,  0.]]), y=array([9, 5, 0, ..., 8, 9, 8]), **fit_params={})
    234             This estimator
    235 
    236         """
    237         Xt, yt, fit_params = self._fit(X, y, **fit_params)
    238         if self._final_estimator is not None:
--> 239             self._final_estimator.fit(Xt, yt, **fit_params)
        self._final_estimator.fit = <bound method RandomForestClassifier.fit of Rand...e, random_state=42, verbose=0, warm_start=False)>
        Xt = array([[0.3125    , 0.        ],
       [1.     ...4, 0.        ],
       [0.7351869 , 0.        ]])
        yt = array([9, 5, 0, ..., 8, 9, 9])
        fit_params = {}
    240         return self
    241 
    242     def fit_transform(self, X, y=None, **fit_params):
    243         """Fit the model and transform with the final estimator

...........................................................................
/home/aquemy/.local/lib/python2.7/site-packages/sklearn/ensemble/forest.py in fit(self=RandomForestClassifier(bootstrap=False, class_we...se, random_state=42, verbose=0, warm_start=False), X=array([[0.3125    , 0.        ],
       [1.     ...
       [0.7351869 , 0.        ]], dtype=float32), y=array([[9.],
       [5.],
       [0.],
       ...,
       [8.],
       [9.],
       [9.]]), sample_weight=None)
    328             trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,
    329                              **_joblib_parallel_args(prefer='threads'))(
    330                 delayed(_parallel_build_trees)(
    331                     t, self, X, y, sample_weight, i, len(trees),
    332                     verbose=self.verbose, class_weight=self.class_weight)
--> 333                 for i, t in enumerate(trees))
        i = 99
    334 
    335             # Collect newly grown trees
    336             self.estimators_.extend(trees)
    337 

...........................................................................
/home/aquemy/.local/lib/python2.7/site-packages/sklearn/externals/joblib/parallel.py in __call__(self=Parallel(n_jobs=1), iterable=<generator object <genexpr>>)
    912             # self._original_iterator is None, then this means either
    913             # that pre_dispatch == "all", n_jobs == 1 or that the first batch
    914             # was very quick and its callback already dispatched all the
    915             # remaining jobs.
    916             self._iterating = False
--> 917             if self.dispatch_one_batch(iterator):
        self.dispatch_one_batch = <bound method Parallel.dispatch_one_batch of Parallel(n_jobs=1)>
        iterator = <generator object <genexpr>>
    918                 self._iterating = self._original_iterator is not None
    919 
    920             while self.dispatch_one_batch(iterator):
    921                 pass

...........................................................................
/home/aquemy/.local/lib/python2.7/site-packages/sklearn/externals/joblib/parallel.py in dispatch_one_batch(self=Parallel(n_jobs=1), iterator=<generator object <genexpr>>)
    754                                  self._pickle_cache)
    755             if len(tasks) == 0:
    756                 # No more tasks available in the iterator: tell caller to stop.
    757                 return False
    758             else:
--> 759                 self._dispatch(tasks)
        self._dispatch = <bound method Parallel._dispatch of Parallel(n_jobs=1)>
        tasks = <sklearn.externals.joblib.parallel.BatchedCalls object>
    760                 return True
    761 
    762     def _print(self, msg, msg_args):
    763         """Display the message on stout or stderr depending on verbosity"""

...........................................................................
/home/aquemy/.local/lib/python2.7/site-packages/sklearn/externals/joblib/parallel.py in _dispatch(self=Parallel(n_jobs=1), batch=<sklearn.externals.joblib.parallel.BatchedCalls object>)
    711 
    712         dispatch_timestamp = time.time()
    713         cb = BatchCompletionCallBack(dispatch_timestamp, len(batch), self)
    714         with self._lock:
    715             job_idx = len(self._jobs)
--> 716             job = self._backend.apply_async(batch, callback=cb)
        job = undefined
        self._backend.apply_async = <bound method SequentialBackend.apply_async of <...lib._parallel_backends.SequentialBackend object>>
        batch = <sklearn.externals.joblib.parallel.BatchedCalls object>
        cb = <sklearn.externals.joblib.parallel.BatchCompletionCallBack object>
    717             # A job can complete so quickly than its callback is
    718             # called before we get here, causing self._jobs to
    719             # grow. To ensure correct results ordering, .insert is
    720             # used (rather than .append) in the following line

...........................................................................
/home/aquemy/.local/lib/python2.7/site-packages/sklearn/externals/joblib/_parallel_backends.py in apply_async(self=<sklearn.externals.joblib._parallel_backends.SequentialBackend object>, func=<sklearn.externals.joblib.parallel.BatchedCalls object>, callback=<sklearn.externals.joblib.parallel.BatchCompletionCallBack object>)
    177             raise ValueError('n_jobs == 0 in Parallel has no meaning')
    178         return 1
    179 
    180     def apply_async(self, func, callback=None):
    181         """Schedule a func to be run"""
--> 182         result = ImmediateResult(func)
        result = undefined
        func = <sklearn.externals.joblib.parallel.BatchedCalls object>
    183         if callback:
    184             callback(result)
    185         return result
    186 

...........................................................................
/home/aquemy/.local/lib/python2.7/site-packages/sklearn/externals/joblib/_parallel_backends.py in __init__(self=<sklearn.externals.joblib._parallel_backends.ImmediateResult object>, batch=<sklearn.externals.joblib.parallel.BatchedCalls object>)
    544 
    545 class ImmediateResult(object):
    546     def __init__(self, batch):
    547         # Don't delay the application, to avoid keeping the input
    548         # arguments in memory
--> 549         self.results = batch()
        self.results = undefined
        batch = <sklearn.externals.joblib.parallel.BatchedCalls object>
    550 
    551     def get(self):
    552         return self.results
    553 

...........................................................................
/home/aquemy/.local/lib/python2.7/site-packages/sklearn/externals/joblib/parallel.py in __call__(self=<sklearn.externals.joblib.parallel.BatchedCalls object>)
    220     def __call__(self):
    221         # Set the default nested backend to self._backend but do not set the
    222         # change the default number of processes to -1
    223         with parallel_backend(self._backend, n_jobs=self._n_jobs):
    224             return [func(*args, **kwargs)
--> 225                     for func, args, kwargs in self.items]
        func = <function _parallel_build_trees>
        args = (DecisionTreeClassifier(class_weight=None, criter...=False, random_state=1608637542, splitter='best'), RandomForestClassifier(bootstrap=False, class_we...se, random_state=42, verbose=0, warm_start=False), array([[0.3125    , 0.        ],
       [1.     ...
       [0.7351869 , 0.        ]], dtype=float32), array([[9.],
       [5.],
       [0.],
       ...,
       [8.],
       [9.],
       [9.]]), None, 0, 100)
        kwargs = {'class_weight': None, 'verbose': 0}
        self.items = [(<function _parallel_build_trees>, (DecisionTreeClassifier(class_weight=None, criter...=False, random_state=1608637542, splitter='best'), RandomForestClassifier(bootstrap=False, class_we...se, random_state=42, verbose=0, warm_start=False), array([[0.3125    , 0.        ],
       [1.     ...
       [0.7351869 , 0.        ]], dtype=float32), array([[9.],
       [5.],
       [0.],
       ...,
       [8.],
       [9.],
       [9.]]), None, 0, 100), {'class_weight': None, 'verbose': 0})]
    226 
    227     def __len__(self):
    228         return self._size
    229 

...........................................................................
/home/aquemy/.local/lib/python2.7/site-packages/sklearn/ensemble/forest.py in _parallel_build_trees(tree=DecisionTreeClassifier(class_weight=None, criter...=False, random_state=1608637542, splitter='best'), forest=RandomForestClassifier(bootstrap=False, class_we...se, random_state=42, verbose=0, warm_start=False), X=array([[0.3125    , 0.        ],
       [1.     ...
       [0.7351869 , 0.        ]], dtype=float32), y=array([[9.],
       [5.],
       [0.],
       ...,
       [8.],
       [9.],
       [9.]]), sample_weight=None, tree_idx=0, n_trees=100, verbose=0, class_weight=None)
    116         elif class_weight == 'balanced_subsample':
    117             curr_sample_weight *= compute_sample_weight('balanced', y, indices)
    118 
    119         tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)
    120     else:
--> 121         tree.fit(X, y, sample_weight=sample_weight, check_input=False)
        tree.fit = <bound method DecisionTreeClassifier.fit of Deci...False, random_state=1608637542, splitter='best')>
        X = array([[0.3125    , 0.        ],
       [1.     ...
       [0.7351869 , 0.        ]], dtype=float32)
        y = array([[9.],
       [5.],
       [0.],
       ...,
       [8.],
       [9.],
       [9.]])
        sample_weight = None
    122 
    123     return tree
    124 
    125 

...........................................................................
/home/aquemy/.local/lib/python2.7/site-packages/sklearn/tree/tree.py in fit(self=DecisionTreeClassifier(class_weight=None, criter...=False, random_state=1608637542, splitter='best'), X=array([[0.3125    , 0.        ],
       [1.     ...
       [0.7351869 , 0.        ]], dtype=float32), y=array([[9.],
       [5.],
       [0.],
       ...,
       [8.],
       [9.],
       [9.]]), sample_weight=None, check_input=False, X_idx_sorted=None)
    796 
    797         super(DecisionTreeClassifier, self).fit(
    798             X, y,
    799             sample_weight=sample_weight,
    800             check_input=check_input,
--> 801             X_idx_sorted=X_idx_sorted)
        X_idx_sorted = None
    802         return self
    803 
    804     def predict_proba(self, X, check_input=True):
    805         """Predict class probabilities of the input samples X.

...........................................................................
/home/aquemy/.local/lib/python2.7/site-packages/sklearn/tree/tree.py in fit(self=DecisionTreeClassifier(class_weight=None, criter...=False, random_state=1608637542, splitter='best'), X=array([[0.3125    , 0.        ],
       [1.     ...
       [0.7351869 , 0.        ]], dtype=float32), y=array([[9.],
       [5.],
       [0.],
       ...,
       [8.],
       [9.],
       [9.]]), sample_weight=None, check_input=False, X_idx_sorted=None)
    237         if not 0 <= self.min_weight_fraction_leaf <= 0.5:
    238             raise ValueError("min_weight_fraction_leaf must in [0, 0.5]")
    239         if max_depth <= 0:
    240             raise ValueError("max_depth must be greater than zero. ")
    241         if not (0 < max_features <= self.n_features_):
--> 242             raise ValueError("max_features must be in (0, n_features]")
    243         if not isinstance(max_leaf_nodes, (numbers.Integral, np.integer)):
    244             raise ValueError("max_leaf_nodes must be integral number but was "
    245                              "%r" % max_leaf_nodes)
    246         if -1 < max_leaf_nodes < 2:

ValueError: max_features must be in (0, n_features]
___________________________________________________________________________
Best score: 0.923190438404 (0.030405158842) [J] | Score: 0.0 (0.0) [J]
Best score: 0.923190438404 (0.030405158842) [J] | Score: 0.731516144114 (0.0470402593739) [J]
Best score: 0.923190438404 (0.030405158842) [J] | Score: 0.751682279424 (0.0438940481851) [J]
Best score: 0.923190438404 (0.030405158842) [J] | Score: 0.308382283496 (0.0145949203842) [J]
Best score: 0.923190438404 (0.030405158842) [J] | Score: 0.100693800535 (0.00506600662396) [J]
Best score: 0.923190438404 (0.030405158842) [J] | Score: 0.45675296075 (0.0407132257182) [J]
Best score: 0.923190438404 (0.030405158842) [J] | Score: 0.258701535509 (0.0202887118756) [J]
Best score: 0.923190438404 (0.030405158842) [J] | Score: 0.859593837692 (0.0449198000621) [J]
#################### STEP RESULT ####################
BEST PIPELINE:
 {
    "features": [
        "features_NoneType", 
        {}
    ], 
    "normalizer": [
        "normalizer_StandardScaler", 
        {
            "normalizer__with_mean": true, 
            "normalizer__with_std": true
        }
    ], 
    "rebalance": [
        "rebalance_NearMiss", 
        {
            "rebalance__n_neighbors": 1
        }
    ]
}
BEST ALGO CONFIG:
 {
    "bootstrap": true, 
    "criterion": "entropy", 
    "max_depth": null, 
    "max_features": null, 
    "max_leaf_nodes": null, 
    "min_samples_split": 3, 
    "n_estimators": 75
}
BEST SCORE: 0.923190438404 (0.030405158842)
##################################################
