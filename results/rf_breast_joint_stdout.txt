SCENARIO:
 {
    "control": {
        "seed": 42
    }, 
    "file_name": "rf_breast_joint", 
    "policy": null, 
    "setup": {
        "algorithm": "RandomForest", 
        "dataset": "breast", 
        "policy": "joint", 
        "runtime": 300
    }, 
    "title": "Random Forest on Breast with Joint policy"
}
Best score: 0.933445683173 (0.0381939913966) [J] | Score: 0.933445683173 (0.0381939913966) [J]
Best score: 0.945635640826 (0.040053650786) [J] | Score: 0.945635640826 (0.040053650786) [J]
Best score: 0.945635640826 (0.040053650786) [J] | Score: 0.923041439806 (0.037733169211) [J]
Best score: 0.945635640826 (0.040053650786) [J] | Score: 0.924640264454 (0.036919918685) [J]
Best score: 0.945635640826 (0.040053650786) [J] | Score: 0.908787053842 (0.053744486454) [J]
Best score: 0.945635640826 (0.040053650786) [J] | Score: 0.84528670815 (0.0779027003752) [J]
Best score: 0.945635640826 (0.040053650786) [J] | Score: 0.829336271714 (0.0562464034904) [J]
Best score: 0.945635640826 (0.040053650786) [J] | Score: 0.938741249676 (0.0337854056695) [J]
Best score: 0.945635640826 (0.040053650786) [J] | Score: 0.935168740818 (0.0325436481818) [J]
Best score: 0.945635640826 (0.040053650786) [J] | Score: 0.929935830957 (0.0296223484026) [J]
Best score: 0.945635640826 (0.040053650786) [J] | Score: 0.924671592775 (0.0369611073894) [J]
Best score: 0.945635640826 (0.040053650786) [J] | Score: 0.931815530205 (0.0411284104852) [J]
Best score: 0.945635640826 (0.040053650786) [J] | Score: 0.871662993691 (0.019421684497) [J]
Best score: 0.945635640826 (0.040053650786) [J] | Score: 0.885853642728 (0.03671804199) [J]
Best score: 0.945635640826 (0.040053650786) [J] | Score: 0.859380131363 (0.0564634290077) [J]
Best score: 0.945635640826 (0.040053650786) [J] | Score: 0.912299066632 (0.0287458102784) [J]
Best score: 0.945635640826 (0.040053650786) [J] | Score: 0.910511191773 (0.0246687509809) [J]
JoblibValueError
___________________________________________________________________________
...........................................................................
/home/aquemy/dev/dp_hyperparameters/extension/main.py in <module>()
     27 
     28     serializer.serialize_results(scenario, policy)
     29 
     30 if __name__ == "__main__":
     31     args = cli.parse_args()
---> 32     main(args)

...........................................................................
/home/aquemy/dev/dp_hyperparameters/extension/main.py in main(args=Namespace(customize=[(['control', 'seed'], '42')...='./scenarios/rf_breast_joint.yaml', verbosity=0))
     21         test_size=0.4, 
     22         random_state=scenario['control']['seed']
     23     )
     24 
     25     policy = policies.initiate(scenario['setup']['policy'], config)
---> 26     policy.run(X,y)
        policy.run = <bound method Joint.run of <experiment.policies.joint.Joint object>>
        X = array([[1.799e+01, 1.038e+01, 1.228e+02, ..., 2...., ..., 0.000e+00, 2.871e-01,
        7.039e-02]])
        y = array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,... 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1])
     27 
     28     serializer.serialize_results(scenario, policy)
     29 
     30 if __name__ == "__main__":

...........................................................................
/home/aquemy/dev/dp_hyperparameters/extension/experiment/policies/joint.py in run(self=<experiment.policies.joint.Joint object>, X=array([[1.799e+01, 1.038e+01, 1.228e+02, ..., 2...., ..., 0.000e+00, 2.871e-01,
        7.039e-02]]), y=array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,... 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1]))
     32             algo=tpe.suggest, 
     33             max_evals=None,
     34             max_time=self.config['time'],     
     35             trials=trials,
     36             show_progressbar=False,
---> 37             verbose=0
     38         )
     39 
     40         best_config = self.context['best_config']
     41         super(Joint, self).display_step_results(best_config)

...........................................................................
/home/aquemy/dev/dp_hyperparameters/extension/hyperopt/fmin.py in fmin(fn=<functools.partial object>, space={'algorithm': {'bootstrap': <hyperopt.pyll.base.Apply object>, 'criterion': <hyperopt.pyll.base.Apply object>, 'max_depth': <hyperopt.pyll.base.Apply object>, 'max_features': <hyperopt.pyll.base.Apply object>, 'max_leaf_nodes': <hyperopt.pyll.base.Apply object>, 'min_samples_split': <hyperopt.pyll.base.Apply object>, 'n_estimators': <hyperopt.pyll.base.Apply object>}, 'pipeline': {'features': <hyperopt.pyll.base.Apply object>, 'normalizer': <hyperopt.pyll.base.Apply object>, 'rebalance': <hyperopt.pyll.base.Apply object>}}, algo=<function suggest>, max_evals=9223372036854775807, max_time=300, trials=<hyperopt.base.Trials object>, rstate=<mtrand.RandomState object>, allow_trials_fmin=True, pass_expr_memo_ctrl=None, catch_eval_exceptions=False, verbose=0, return_argmin=True, points_to_evaluate=None, max_queue_len=1, show_progressbar=False)
    406             pass_expr_memo_ctrl=pass_expr_memo_ctrl,
    407             verbose=verbose,
    408             catch_eval_exceptions=catch_eval_exceptions,
    409             return_argmin=return_argmin,
    410             show_progressbar=show_progressbar,
--> 411             max_time=max_time
        max_time = 300
    412         )
    413 
    414     if trials is None:
    415         if points_to_evaluate is None:

...........................................................................
/home/aquemy/dev/dp_hyperparameters/extension/hyperopt/base.py in fmin(self=<hyperopt.base.Trials object>, fn=<functools.partial object>, space={'algorithm': {'bootstrap': <hyperopt.pyll.base.Apply object>, 'criterion': <hyperopt.pyll.base.Apply object>, 'max_depth': <hyperopt.pyll.base.Apply object>, 'max_features': <hyperopt.pyll.base.Apply object>, 'max_leaf_nodes': <hyperopt.pyll.base.Apply object>, 'min_samples_split': <hyperopt.pyll.base.Apply object>, 'n_estimators': <hyperopt.pyll.base.Apply object>}, 'pipeline': {'features': <hyperopt.pyll.base.Apply object>, 'normalizer': <hyperopt.pyll.base.Apply object>, 'rebalance': <hyperopt.pyll.base.Apply object>}}, algo=<function suggest>, max_evals=9223372036854775807, max_time=300, rstate=<mtrand.RandomState object>, verbose=0, pass_expr_memo_ctrl=None, catch_eval_exceptions=False, return_argmin=True, show_progressbar=False)
    636             verbose=verbose,
    637             allow_trials_fmin=False,  # -- prevent recursion
    638             pass_expr_memo_ctrl=pass_expr_memo_ctrl,
    639             catch_eval_exceptions=catch_eval_exceptions,
    640             return_argmin=return_argmin,
--> 641             show_progressbar=show_progressbar)
        show_progressbar = False
    642 
    643 
    644 def trials_from_docs(docs, validate=True, **kwargs):
    645     """Construct a Trials base class instance from a list of trials documents

...........................................................................
/home/aquemy/dev/dp_hyperparameters/extension/hyperopt/fmin.py in fmin(fn=<functools.partial object>, space={'algorithm': {'bootstrap': <hyperopt.pyll.base.Apply object>, 'criterion': <hyperopt.pyll.base.Apply object>, 'max_depth': <hyperopt.pyll.base.Apply object>, 'max_features': <hyperopt.pyll.base.Apply object>, 'max_leaf_nodes': <hyperopt.pyll.base.Apply object>, 'min_samples_split': <hyperopt.pyll.base.Apply object>, 'n_estimators': <hyperopt.pyll.base.Apply object>}, 'pipeline': {'features': <hyperopt.pyll.base.Apply object>, 'normalizer': <hyperopt.pyll.base.Apply object>, 'rebalance': <hyperopt.pyll.base.Apply object>}}, algo=<function suggest>, max_evals=9223372036854775807, max_time=300, trials=<hyperopt.base.Trials object>, rstate=<mtrand.RandomState object>, allow_trials_fmin=False, pass_expr_memo_ctrl=None, catch_eval_exceptions=False, verbose=0, return_argmin=True, points_to_evaluate=None, max_queue_len=1, show_progressbar=False)
    426                     verbose=verbose,
    427                     max_queue_len=max_queue_len,
    428                     show_progressbar=show_progressbar,
    429                     max_time=max_time)
    430     rval.catch_eval_exceptions = catch_eval_exceptions
--> 431     rval.exhaust()
        rval.exhaust = <bound method FMinIter.exhaust of <hyperopt.fmin.FMinIter object>>
    432     if return_argmin:
    433         return trials.argmin
    434     elif len(trials) > 0:
    435         # Only if there are some succesfull trail runs, return the best point in the evaluation space

...........................................................................
/home/aquemy/dev/dp_hyperparameters/extension/hyperopt/fmin.py in exhaust(self=<hyperopt.fmin.FMinIter object>)
    273             raise StopIteration()
    274         return self.trials
    275 
    276     def exhaust(self):
    277         n_done = len(self.trials)
--> 278         self.run(self.max_evals - n_done, block_until_done=self.asynchronous)
        self.run = <bound method FMinIter.run of <hyperopt.fmin.FMinIter object>>
        self.max_evals = 9223372036854775807
        n_done = 0
        self.asynchronous = False
    279         self.trials.refresh()
    280         return self
    281 
    282 

...........................................................................
/home/aquemy/dev/dp_hyperparameters/extension/hyperopt/fmin.py in run(self=<hyperopt.fmin.FMinIter object>, N=9223372036854775807, block_until_done=False)
    232                     if self.asynchronous:
    233                         # -- wait for workers to fill in the trials
    234                         time.sleep(self.poll_interval_secs)
    235                     else:
    236                         # -- loop over trials and do the jobs directly
--> 237                         self.serial_evaluate()
        self.serial_evaluate = <bound method FMinIter.serial_evaluate of <hyperopt.fmin.FMinIter object>>
    238                     try:
    239                         res = [d['result']['loss'] for d in
    240                                          self.trials.trials if
    241                                          d['result']['status'] == 'ok']

...........................................................................
/home/aquemy/dev/dp_hyperparameters/extension/hyperopt/fmin.py in serial_evaluate(self=<hyperopt.fmin.FMinIter object>, N=-1)
    138                 trial['book_time'] = now
    139                 trial['refresh_time'] = now
    140                 spec = base.spec_from_misc(trial['misc'])
    141                 ctrl = base.Ctrl(self.trials, current_trial=trial)
    142                 try:
--> 143                     result = self.domain.evaluate(spec, ctrl)
        result = undefined
        self.domain.evaluate = <bound method Domain.evaluate of <hyperopt.base.Domain object>>
        spec = {'bootstrap': 0, 'criterion': 0, 'features': 2, 'features_SelectKBest_features__k': 1, 'max_depth': 1, 'max_features': 2, 'max_leaf_nodes': 1, 'min_samples_split': 1, 'n_estimators': 4, 'normalizer': 2, ...}
        ctrl = <hyperopt.base.Ctrl object>
    144                 except Exception as e:
    145                     logger.info('job exception: %s' % str(e))
    146                     trial['state'] = base.JOB_STATE_ERROR
    147                     trial['misc']['error'] = (str(type(e)), str(e))

...........................................................................
/home/aquemy/dev/dp_hyperparameters/extension/hyperopt/base.py in evaluate(self=<hyperopt.base.Domain object>, config={'bootstrap': 0, 'criterion': 0, 'features': 2, 'features_SelectKBest_features__k': 1, 'max_depth': 1, 'max_features': 2, 'max_leaf_nodes': 1, 'min_samples_split': 1, 'n_estimators': 4, 'normalizer': 2, ...}, ctrl=<hyperopt.base.Ctrl object>, attach_attachments=True)
    841             #    or the normal Python part (self.fn)
    842             pyll_rval = pyll.rec_eval(
    843                 self.expr,
    844                 memo=memo,
    845                 print_node_on_error=self.rec_eval_print_node_on_error)
--> 846             rval = self.fn(pyll_rval)
        rval = undefined
        self.fn = <functools.partial object>
        pyll_rval = {'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': 2, 'max_features': 3, 'max_leaf_nodes': 3, 'min_samples_split': 3, 'n_estimators': 100}, 'pipeline': {'features': ('features_SelectKBest', {'features__k': 2}), 'normalizer': ('normalizer_PowerTransformer', {}), 'rebalance': ('rebalance_NearMiss', {'rebalance__n_neighbors': 1})}}
    847 
    848         if isinstance(rval, (float, int, np.number)):
    849             dict_rval = {'loss': float(rval), 'status': STATUS_OK}
    850         else:

...........................................................................
/home/aquemy/dev/dp_hyperparameters/extension/experiment/objective.py in objective_joint(wconfig={'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': 2, 'max_features': 3, 'max_leaf_nodes': 3, 'min_samples_split': 3, 'n_estimators': 100}, 'pipeline': {'features': ('features_SelectKBest', {'features__k': 2}), 'normalizer': ('normalizer_PowerTransformer', {}), 'rebalance': ('rebalance_NearMiss', {'rebalance__n_neighbors': 1})}}, algorithm='RandomForest', X=array([[1.799e+01, 1.038e+01, 1.228e+02, ..., 2...., ..., 0.000e+00, 2.871e-01,
        7.039e-02]]), y=array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,... 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1]), context={'baseline_score': 0.9545944602886527, 'baseline_score_std': 0.03716322883281839, 'best_config': {'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': None, 'max_features': 2, 'max_leaf_nodes': 3, 'min_samples_split': 2, 'n_estimators': 100}, 'config_hash': {'algorithm': '1b32258c630f07e01ab481ab925ab80aa757e482', 'config': '9e54ffcb6a727de032a0a2cd45c5cc37cc150756', 'pipeline': '37e72d4a97f5e784c9d3133e6379b91bfc3be803'}, 'duration': 1.3065669536590576, 'iteration': 1, 'loss': 0.05436435917379645, 'max_history_score': 0.9456356408262035, 'max_history_score_std': 0.040053650785990214, 'max_history_step': 'joint', 'pipeline': {'features': ('features_NoneType', {}), 'normalizer': ('normalizer_StandardScaler', {'normalizer__with_mean': True, 'normalizer__with_std': True}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 6})}, 'score': 0.9456356408262035, ...}, 'history': [{'algorithm': {'bootstrap': True, 'criterion': 'entropy', 'max_depth': 4, 'max_features': 3, 'max_leaf_nodes': 3, 'min_samples_split': 2, 'n_estimators': 10}, 'config_hash': {'algorithm': '42527c4120073c2a488d1b8df28732f486d1578c', 'config': '51144ca42f9ea5ab2d8d58606e3b3e4d89c6d7b3', 'pipeline': '52f07bda29f9d3a95fabb87e591d0b2581ca8209'}, 'duration': 0.26703310012817383, 'iteration': 0, 'loss': 0.06655431682654922, 'max_history_score': 0.9334456831734508, 'max_history_score_std': 0.03819399139659311, 'max_history_step': 'joint', 'pipeline': {'features': ('features_NoneType', {}), 'normalizer': ('normalizer_RobustScaler', {'normalizer__quantile_range': (...), 'normalizer__with_centering': False, 'normalizer__with_scaling': False}), 'rebalance': ('rebalance_NearMiss', {'rebalance__n_neighbors': 1})}, 'score': 0.9334456831734508, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': None, 'max_features': 2, 'max_leaf_nodes': 3, 'min_samples_split': 2, 'n_estimators': 100}, 'config_hash': {'algorithm': '1b32258c630f07e01ab481ab925ab80aa757e482', 'config': '9e54ffcb6a727de032a0a2cd45c5cc37cc150756', 'pipeline': '37e72d4a97f5e784c9d3133e6379b91bfc3be803'}, 'duration': 1.3065669536590576, 'iteration': 1, 'loss': 0.05436435917379645, 'max_history_score': 0.9456356408262035, 'max_history_score_std': 0.040053650785990214, 'max_history_step': 'joint', 'pipeline': {'features': ('features_NoneType', {}), 'normalizer': ('normalizer_StandardScaler', {'normalizer__with_mean': True, 'normalizer__with_std': True}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 6})}, 'score': 0.9456356408262035, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'entropy', 'max_depth': 1, 'max_features': 1, 'max_leaf_nodes': 2, 'min_samples_split': 3, 'n_estimators': 25}, 'config_hash': {'algorithm': '68ab9059aa7ec74e0da87c81734b9664243b3eb4', 'config': 'e5241eee9ddf3f4ee29a4711f5bcc92a4d24cd09', 'pipeline': '62463de065924498cdcd2f2f1f7e68535cdb33a5'}, 'duration': 0.6592490673065186, 'iteration': 2, 'loss': 0.07695856019358727, 'max_history_score': 0.9456356408262035, 'max_history_score_std': 0.040053650785990214, 'max_history_step': 'joint', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 1, 'features__selectkbest__k': 2}), 'normalizer': ('normalizer_NoneType', {}), 'rebalance': ('rebalance_NoneType', {})}, 'score': 0.9230414398064127, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': 3, 'max_features': 2, 'max_leaf_nodes': 2, 'min_samples_split': 2, 'n_estimators': 25}, 'config_hash': {'algorithm': 'e3f1f7d7783557a38f40f0476369091edd87092b', 'config': '18ee4d3d1627472ec190326308d8755371a6dc62', 'pipeline': 'c6d1263e344ed8c71b2e6e4ba8e0db2fb6c777c0'}, 'duration': 0.879349946975708, 'iteration': 3, 'loss': 0.07535973554576114, 'max_history_score': 0.9456356408262035, 'max_history_score_std': 0.040053650785990214, 'max_history_step': 'joint', 'pipeline': {'features': ('features_NoneType', {}), 'normalizer': ('normalizer_RobustScaler', {'normalizer__quantile_range': (...), 'normalizer__with_centering': True, 'normalizer__with_scaling': True}), 'rebalance': ('rebalance_NearMiss', {'rebalance__n_neighbors': 2})}, 'score': 0.9246402644542389, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'gini', 'max_depth': 4, 'max_features': 2, 'max_leaf_nodes': 5, 'min_samples_split': 2, 'n_estimators': 50}, 'config_hash': {'algorithm': '47581af7253940f9647ad16d37347d34baf13e5f', 'config': '2af4f82b045c0c48ecb89d42728d1039fbff8878', 'pipeline': '2928b22ed834303cb7bac6e6608531eaddd7df67'}, 'duration': 4.372632026672363, 'iteration': 4, 'loss': 0.09121294615849984, 'max_history_score': 0.9456356408262035, 'max_history_score_std': 0.040053650785990214, 'max_history_step': 'joint', 'pipeline': {'features': ('features_NoneType', {}), 'normalizer': ('normalizer_MinMaxScaler', {}), 'rebalance': ('rebalance_CondensedNearestNeighbour', {'rebalance__n_neighbors': 2})}, 'score': 0.9087870538415002, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'entropy', 'max_depth': 2, 'max_features': 2, 'max_leaf_nodes': None, 'min_samples_split': 2, 'n_estimators': 10}, 'config_hash': {'algorithm': '0a85f98ca2d06103287f153633d88f7a0535e7e8', 'config': '17b2a1e5814f3e933137158708a5b6e9b2475495', 'pipeline': '95defa3bdd8357f11f872d3c280d50a6d8ee398d'}, 'duration': 2.625814914703369, 'iteration': 5, 'loss': 0.15471329185031535, 'max_history_score': 0.9456356408262035, 'max_history_score_std': 0.040053650785990214, 'max_history_step': 'joint', 'pipeline': {'features': ('features_SelectKBest', {'features__k': 2}), 'normalizer': ('normalizer_StandardScaler', {'normalizer__with_mean': False, 'normalizer__with_std': False}), 'rebalance': ('rebalance_CondensedNearestNeighbour', {'rebalance__n_neighbors': 1})}, 'score': 0.8452867081496847, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': 3, 'max_features': None, 'max_leaf_nodes': None, 'min_samples_split': 5, 'n_estimators': 75}, 'config_hash': {'algorithm': 'd7466a2c1d5cb3fa95029d73dc030f4c3c45a159', 'config': 'fa020a592ec5ac234f9f91aac28abc2cd1ec9d33', 'pipeline': '71e0d26f923d42cfe0e2fa748931ef2afe72ed86'}, 'duration': 3.62078595161438, 'iteration': 6, 'loss': 0.17066372828623277, 'max_history_score': 0.9456356408262035, 'max_history_score_std': 0.040053650785990214, 'max_history_step': 'joint', 'pipeline': {'features': ('features_SelectKBest', {'features__k': 1}), 'normalizer': ('normalizer_RobustScaler', {'normalizer__quantile_range': (...), 'normalizer__with_centering': True, 'normalizer__with_scaling': True}), 'rebalance': ('rebalance_CondensedNearestNeighbour', {'rebalance__n_neighbors': 1})}, 'score': 0.8293362717137672, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'entropy', 'max_depth': 3, 'max_features': 3, 'max_leaf_nodes': 5, 'min_samples_split': 5, 'n_estimators': 50}, 'config_hash': {'algorithm': '735caa9785596076014572a24050cde8dc338973', 'config': '0da4498002d6f452c59bb61756abb3ded841e786', 'pipeline': '51a53ea6ef5a2521ee65f76eb2da220ab7086513'}, 'duration': 0.6934049129486084, 'iteration': 7, 'loss': 0.06125875032408601, 'max_history_score': 0.9456356408262035, 'max_history_score_std': 0.040053650785990214, 'max_history_step': 'joint', 'pipeline': {'features': ('features_NoneType', {}), 'normalizer': ('normalizer_NoneType', {}), 'rebalance': ('rebalance_NearMiss', {'rebalance__n_neighbors': 3})}, 'score': 0.938741249675914, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': 4, 'max_features': 2, 'max_leaf_nodes': None, 'min_samples_split': 3, 'n_estimators': 75}, 'config_hash': {'algorithm': 'e71a1fe9515b6805f07914a61f2e7594be9e9afe', 'config': '344e4756fb1bec455d6af51d3727e33b0d27725f', 'pipeline': '248dad1d8b30a17a5de1d0bbdfe3e2acb7a1962b'}, 'duration': 1.3036692142486572, 'iteration': 8, 'loss': 0.06483125918243893, 'max_history_score': 0.9456356408262035, 'max_history_score_std': 0.040053650785990214, 'max_history_step': 'joint', 'pipeline': {'features': ('features_PCA', {'features__n_components': 2}), 'normalizer': ('normalizer_StandardScaler', {'normalizer__with_mean': False, 'normalizer__with_std': True}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 7})}, 'score': 0.9351687408175611, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'entropy', 'max_depth': 2, 'max_features': 2, 'max_leaf_nodes': 2, 'min_samples_split': 3, 'n_estimators': 10}, 'config_hash': {'algorithm': '0a507823f2ad8605ed5950e1fe61df0560f11a00', 'config': '4a538fdcf8e07f90e92a421c0d5c479d651629c7', 'pipeline': '5240329df25c9a533d025c1a401d49835a501b41'}, 'duration': 1.3821029663085938, 'iteration': 9, 'loss': 0.07006416904329793, 'max_history_score': 0.9456356408262035, 'max_history_score_std': 0.040053650785990214, 'max_history_step': 'joint', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 4, 'features__selectkbest__k': 2}), 'normalizer': ('normalizer_PowerTransformer', {}), 'rebalance': ('rebalance_NearMiss', {'rebalance__n_neighbors': 1})}, 'score': 0.9299358309567021, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'gini', 'max_depth': 1, 'max_features': 3, 'max_leaf_nodes': 5, 'min_samples_split': 3, 'n_estimators': 10}, 'config_hash': {'algorithm': 'd32739750d351948f8ff34a87c7d55b0c5e0d90f', 'config': 'c1609e71f1ce8486335adc70bb69a955580ba2c8', 'pipeline': 'f48b42ec5cf999279659966160a16353b75bdaa3'}, 'duration': 0.9055681228637695, 'iteration': 10, 'loss': 0.07532840722495904, 'max_history_score': 0.9456356408262035, 'max_history_score_std': 0.040053650785990214, 'max_history_step': 'joint', 'pipeline': {'features': ('features_PCA', {'features__n_components': 4}), 'normalizer': ('normalizer_PowerTransformer', {}), 'rebalance': ('rebalance_NearMiss', {'rebalance__n_neighbors': 1})}, 'score': 0.924671592775041, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': 3, 'max_features': 1, 'max_leaf_nodes': 5, 'min_samples_split': 3, 'n_estimators': 25}, 'config_hash': {'algorithm': 'f69bac35e71cbec1bfc1fb5942328a3390e7c252', 'config': 'abe36f188644e53e56ed3224236fa157107ed3b2', 'pipeline': 'aaf976c7c663a31fa039582d42f9e07101556a7c'}, 'duration': 0.764197826385498, 'iteration': 11, 'loss': 0.06818446979517778, 'max_history_score': 0.9456356408262035, 'max_history_score_std': 0.040053650785990214, 'max_history_step': 'joint', 'pipeline': {'features': ('features_NoneType', {}), 'normalizer': ('normalizer_PowerTransformer', {}), 'rebalance': ('rebalance_NoneType', {})}, 'score': 0.9318155302048222, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'entropy', 'max_depth': None, 'max_features': None, 'max_leaf_nodes': None, 'min_samples_split': 5, 'n_estimators': 25}, 'config_hash': {'algorithm': 'a0a27aec00db5ddf71eab96663f9bd61c845f5e3', 'config': '76aa002c3c9d4d9722466c60daf5119c18a41d2a', 'pipeline': '1ce34b7894ef342571d974bb19e8ec821a512c6b'}, 'duration': 1.1636500358581543, 'iteration': 12, 'loss': 0.12833700630887557, 'max_history_score': 0.9456356408262035, 'max_history_score_std': 0.040053650785990214, 'max_history_step': 'joint', 'pipeline': {'features': ('features_PCA', {'features__n_components': 1}), 'normalizer': ('normalizer_PowerTransformer', {}), 'rebalance': ('rebalance_NoneType', {})}, 'score': 0.8716629936911244, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'gini', 'max_depth': 1, 'max_features': 2, 'max_leaf_nodes': 2, 'min_samples_split': 2, 'n_estimators': 100}, 'config_hash': {'algorithm': '985c99dff1da9b2c87e4211c5335a9159aa9dbcb', 'config': 'f56a7a9e43a0a699e992dc1262e550b8b7c88538', 'pipeline': '5c934f6d9a8ad1f9afe762986a9cf2074fc95d79'}, 'duration': 2.235443115234375, 'iteration': 13, 'loss': 0.11414635727249167, 'max_history_score': 0.9456356408262035, 'max_history_score_std': 0.040053650785990214, 'max_history_step': 'joint', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 1, 'features__selectkbest__k': 1}), 'normalizer': ('normalizer_RobustScaler', {'normalizer__quantile_range': (...), 'normalizer__with_centering': False, 'normalizer__with_scaling': True}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 6})}, 'score': 0.8858536427275083, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'gini', 'max_depth': 1, 'max_features': 1, 'max_leaf_nodes': None, 'min_samples_split': 5, 'n_estimators': 10}, 'config_hash': {'algorithm': '7d74a39aac2579264a402aef2b6fa7943c19f3d3', 'config': '53f44c0ad925c5c08c25d4fadf5e9ee9d7c181cd', 'pipeline': '6eff5ef31d7d1d534db31913bb67529c8a24c42e'}, 'duration': 2.7847659587860107, 'iteration': 14, 'loss': 0.14061986863711007, 'max_history_score': 0.9456356408262035, 'max_history_score_std': 0.040053650785990214, 'max_history_step': 'joint', 'pipeline': {'features': ('features_PCA', {'features__n_components': 1}), 'normalizer': ('normalizer_RobustScaler', {'normalizer__quantile_range': (...), 'normalizer__with_centering': True, 'normalizer__with_scaling': True}), 'rebalance': ('rebalance_CondensedNearestNeighbour', {'rebalance__n_neighbors': 3})}, 'score': 0.8593801313628899, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'entropy', 'max_depth': 3, 'max_features': None, 'max_leaf_nodes': 5, 'min_samples_split': 2, 'n_estimators': 100}, 'config_hash': {'algorithm': 'c62d7c671832e4414b6b2d7c36cba5ddc83a0ed0', 'config': '5faee50671eaa0ac586722bff234e36a857e662d', 'pipeline': '8b29a55de2add78c49114b9bbe5e800e5524c59d'}, 'duration': 2.3916029930114746, 'iteration': 15, 'loss': 0.08770093336790252, 'max_history_score': 0.9456356408262035, 'max_history_score_std': 0.040053650785990214, 'max_history_step': 'joint', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 3, 'features__selectkbest__k': 4}), 'normalizer': ('normalizer_RobustScaler', {'normalizer__quantile_range': (...), 'normalizer__with_centering': True, 'normalizer__with_scaling': True}), 'rebalance': ('rebalance_NoneType', {})}, 'score': 0.9122990666320975, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': None, 'max_features': 1, 'max_leaf_nodes': 5, 'min_samples_split': 5, 'n_estimators': 10}, 'config_hash': {'algorithm': '290772bfb9b8ed15c48a72829e822fb0a07481d6', 'config': '9a04f25d8eb3db5b2f831abd341a6d384c73a957', 'pipeline': '1ce34b7894ef342571d974bb19e8ec821a512c6b'}, 'duration': 1.4364500045776367, 'iteration': 16, 'loss': 0.08948880822746508, 'max_history_score': 0.9456356408262035, 'max_history_score_std': 0.040053650785990214, 'max_history_step': 'joint', 'pipeline': {'features': ('features_PCA', {'features__n_components': 1}), 'normalizer': ('normalizer_PowerTransformer', {}), 'rebalance': ('rebalance_NoneType', {})}, 'score': 0.9105111917725349, ...}], 'history_hash': ['51144ca42f9ea5ab2d8d58606e3b3e4d89c6d7b3', '9e54ffcb6a727de032a0a2cd45c5cc37cc150756', 'e5241eee9ddf3f4ee29a4711f5bcc92a4d24cd09', '18ee4d3d1627472ec190326308d8755371a6dc62', '2af4f82b045c0c48ecb89d42728d1039fbff8878', '17b2a1e5814f3e933137158708a5b6e9b2475495', 'fa020a592ec5ac234f9f91aac28abc2cd1ec9d33', '0da4498002d6f452c59bb61756abb3ded841e786', '344e4756fb1bec455d6af51d3727e33b0d27725f', '4a538fdcf8e07f90e92a421c0d5c479d651629c7', 'c1609e71f1ce8486335adc70bb69a955580ba2c8', 'abe36f188644e53e56ed3224236fa157107ed3b2', '76aa002c3c9d4d9722466c60daf5119c18a41d2a', 'f56a7a9e43a0a699e992dc1262e550b8b7c88538', '53f44c0ad925c5c08c25d4fadf5e9ee9d7c181cd', '5faee50671eaa0ac586722bff234e36a857e662d', '9a04f25d8eb3db5b2f831abd341a6d384c73a957'], 'history_index': {'0da4498002d6f452c59bb61756abb3ded841e786': 7, '17b2a1e5814f3e933137158708a5b6e9b2475495': 5, '18ee4d3d1627472ec190326308d8755371a6dc62': 3, '2af4f82b045c0c48ecb89d42728d1039fbff8878': 4, '344e4756fb1bec455d6af51d3727e33b0d27725f': 8, '4a538fdcf8e07f90e92a421c0d5c479d651629c7': 9, '51144ca42f9ea5ab2d8d58606e3b3e4d89c6d7b3': 0, '53f44c0ad925c5c08c25d4fadf5e9ee9d7c181cd': 14, '5faee50671eaa0ac586722bff234e36a857e662d': 15, '76aa002c3c9d4d9722466c60daf5119c18a41d2a': 12, ...}, 'iteration': 16, 'max_history_score': 0.9456356408262035, 'max_history_score_std': 0.040053650785990214, 'max_history_step': 'joint'}, config={'algorithm': 'RandomForest', 'seed': 42, 'time': 300})
    108 
    109 def objective_algo(algo_config, current_pipeline_config, algorithm, X, y, context, config):
    110     return objective(current_pipeline_config, algo_config, algorithm, X, y, context, config, step='algorithm')
    111 
    112 def objective_joint(wconfig, algorithm, X, y, context, config):
--> 113     return objective(wconfig['pipeline'], wconfig['algorithm'], algorithm, X, y, context, config, step='joint')
        wconfig = {'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': 2, 'max_features': 3, 'max_leaf_nodes': 3, 'min_samples_split': 3, 'n_estimators': 100}, 'pipeline': {'features': ('features_SelectKBest', {'features__k': 2}), 'normalizer': ('normalizer_PowerTransformer', {}), 'rebalance': ('rebalance_NearMiss', {'rebalance__n_neighbors': 1})}}
        algorithm = 'RandomForest'
        X = array([[1.799e+01, 1.038e+01, 1.228e+02, ..., 2...., ..., 0.000e+00, 2.871e-01,
        7.039e-02]])
        y = array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,... 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1])
        context = {'baseline_score': 0.9545944602886527, 'baseline_score_std': 0.03716322883281839, 'best_config': {'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': None, 'max_features': 2, 'max_leaf_nodes': 3, 'min_samples_split': 2, 'n_estimators': 100}, 'config_hash': {'algorithm': '1b32258c630f07e01ab481ab925ab80aa757e482', 'config': '9e54ffcb6a727de032a0a2cd45c5cc37cc150756', 'pipeline': '37e72d4a97f5e784c9d3133e6379b91bfc3be803'}, 'duration': 1.3065669536590576, 'iteration': 1, 'loss': 0.05436435917379645, 'max_history_score': 0.9456356408262035, 'max_history_score_std': 0.040053650785990214, 'max_history_step': 'joint', 'pipeline': {'features': ('features_NoneType', {}), 'normalizer': ('normalizer_StandardScaler', {'normalizer__with_mean': True, 'normalizer__with_std': True}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 6})}, 'score': 0.9456356408262035, ...}, 'history': [{'algorithm': {'bootstrap': True, 'criterion': 'entropy', 'max_depth': 4, 'max_features': 3, 'max_leaf_nodes': 3, 'min_samples_split': 2, 'n_estimators': 10}, 'config_hash': {'algorithm': '42527c4120073c2a488d1b8df28732f486d1578c', 'config': '51144ca42f9ea5ab2d8d58606e3b3e4d89c6d7b3', 'pipeline': '52f07bda29f9d3a95fabb87e591d0b2581ca8209'}, 'duration': 0.26703310012817383, 'iteration': 0, 'loss': 0.06655431682654922, 'max_history_score': 0.9334456831734508, 'max_history_score_std': 0.03819399139659311, 'max_history_step': 'joint', 'pipeline': {'features': ('features_NoneType', {}), 'normalizer': ('normalizer_RobustScaler', {'normalizer__quantile_range': (...), 'normalizer__with_centering': False, 'normalizer__with_scaling': False}), 'rebalance': ('rebalance_NearMiss', {'rebalance__n_neighbors': 1})}, 'score': 0.9334456831734508, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': None, 'max_features': 2, 'max_leaf_nodes': 3, 'min_samples_split': 2, 'n_estimators': 100}, 'config_hash': {'algorithm': '1b32258c630f07e01ab481ab925ab80aa757e482', 'config': '9e54ffcb6a727de032a0a2cd45c5cc37cc150756', 'pipeline': '37e72d4a97f5e784c9d3133e6379b91bfc3be803'}, 'duration': 1.3065669536590576, 'iteration': 1, 'loss': 0.05436435917379645, 'max_history_score': 0.9456356408262035, 'max_history_score_std': 0.040053650785990214, 'max_history_step': 'joint', 'pipeline': {'features': ('features_NoneType', {}), 'normalizer': ('normalizer_StandardScaler', {'normalizer__with_mean': True, 'normalizer__with_std': True}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 6})}, 'score': 0.9456356408262035, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'entropy', 'max_depth': 1, 'max_features': 1, 'max_leaf_nodes': 2, 'min_samples_split': 3, 'n_estimators': 25}, 'config_hash': {'algorithm': '68ab9059aa7ec74e0da87c81734b9664243b3eb4', 'config': 'e5241eee9ddf3f4ee29a4711f5bcc92a4d24cd09', 'pipeline': '62463de065924498cdcd2f2f1f7e68535cdb33a5'}, 'duration': 0.6592490673065186, 'iteration': 2, 'loss': 0.07695856019358727, 'max_history_score': 0.9456356408262035, 'max_history_score_std': 0.040053650785990214, 'max_history_step': 'joint', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 1, 'features__selectkbest__k': 2}), 'normalizer': ('normalizer_NoneType', {}), 'rebalance': ('rebalance_NoneType', {})}, 'score': 0.9230414398064127, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': 3, 'max_features': 2, 'max_leaf_nodes': 2, 'min_samples_split': 2, 'n_estimators': 25}, 'config_hash': {'algorithm': 'e3f1f7d7783557a38f40f0476369091edd87092b', 'config': '18ee4d3d1627472ec190326308d8755371a6dc62', 'pipeline': 'c6d1263e344ed8c71b2e6e4ba8e0db2fb6c777c0'}, 'duration': 0.879349946975708, 'iteration': 3, 'loss': 0.07535973554576114, 'max_history_score': 0.9456356408262035, 'max_history_score_std': 0.040053650785990214, 'max_history_step': 'joint', 'pipeline': {'features': ('features_NoneType', {}), 'normalizer': ('normalizer_RobustScaler', {'normalizer__quantile_range': (...), 'normalizer__with_centering': True, 'normalizer__with_scaling': True}), 'rebalance': ('rebalance_NearMiss', {'rebalance__n_neighbors': 2})}, 'score': 0.9246402644542389, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'gini', 'max_depth': 4, 'max_features': 2, 'max_leaf_nodes': 5, 'min_samples_split': 2, 'n_estimators': 50}, 'config_hash': {'algorithm': '47581af7253940f9647ad16d37347d34baf13e5f', 'config': '2af4f82b045c0c48ecb89d42728d1039fbff8878', 'pipeline': '2928b22ed834303cb7bac6e6608531eaddd7df67'}, 'duration': 4.372632026672363, 'iteration': 4, 'loss': 0.09121294615849984, 'max_history_score': 0.9456356408262035, 'max_history_score_std': 0.040053650785990214, 'max_history_step': 'joint', 'pipeline': {'features': ('features_NoneType', {}), 'normalizer': ('normalizer_MinMaxScaler', {}), 'rebalance': ('rebalance_CondensedNearestNeighbour', {'rebalance__n_neighbors': 2})}, 'score': 0.9087870538415002, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'entropy', 'max_depth': 2, 'max_features': 2, 'max_leaf_nodes': None, 'min_samples_split': 2, 'n_estimators': 10}, 'config_hash': {'algorithm': '0a85f98ca2d06103287f153633d88f7a0535e7e8', 'config': '17b2a1e5814f3e933137158708a5b6e9b2475495', 'pipeline': '95defa3bdd8357f11f872d3c280d50a6d8ee398d'}, 'duration': 2.625814914703369, 'iteration': 5, 'loss': 0.15471329185031535, 'max_history_score': 0.9456356408262035, 'max_history_score_std': 0.040053650785990214, 'max_history_step': 'joint', 'pipeline': {'features': ('features_SelectKBest', {'features__k': 2}), 'normalizer': ('normalizer_StandardScaler', {'normalizer__with_mean': False, 'normalizer__with_std': False}), 'rebalance': ('rebalance_CondensedNearestNeighbour', {'rebalance__n_neighbors': 1})}, 'score': 0.8452867081496847, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': 3, 'max_features': None, 'max_leaf_nodes': None, 'min_samples_split': 5, 'n_estimators': 75}, 'config_hash': {'algorithm': 'd7466a2c1d5cb3fa95029d73dc030f4c3c45a159', 'config': 'fa020a592ec5ac234f9f91aac28abc2cd1ec9d33', 'pipeline': '71e0d26f923d42cfe0e2fa748931ef2afe72ed86'}, 'duration': 3.62078595161438, 'iteration': 6, 'loss': 0.17066372828623277, 'max_history_score': 0.9456356408262035, 'max_history_score_std': 0.040053650785990214, 'max_history_step': 'joint', 'pipeline': {'features': ('features_SelectKBest', {'features__k': 1}), 'normalizer': ('normalizer_RobustScaler', {'normalizer__quantile_range': (...), 'normalizer__with_centering': True, 'normalizer__with_scaling': True}), 'rebalance': ('rebalance_CondensedNearestNeighbour', {'rebalance__n_neighbors': 1})}, 'score': 0.8293362717137672, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'entropy', 'max_depth': 3, 'max_features': 3, 'max_leaf_nodes': 5, 'min_samples_split': 5, 'n_estimators': 50}, 'config_hash': {'algorithm': '735caa9785596076014572a24050cde8dc338973', 'config': '0da4498002d6f452c59bb61756abb3ded841e786', 'pipeline': '51a53ea6ef5a2521ee65f76eb2da220ab7086513'}, 'duration': 0.6934049129486084, 'iteration': 7, 'loss': 0.06125875032408601, 'max_history_score': 0.9456356408262035, 'max_history_score_std': 0.040053650785990214, 'max_history_step': 'joint', 'pipeline': {'features': ('features_NoneType', {}), 'normalizer': ('normalizer_NoneType', {}), 'rebalance': ('rebalance_NearMiss', {'rebalance__n_neighbors': 3})}, 'score': 0.938741249675914, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': 4, 'max_features': 2, 'max_leaf_nodes': None, 'min_samples_split': 3, 'n_estimators': 75}, 'config_hash': {'algorithm': 'e71a1fe9515b6805f07914a61f2e7594be9e9afe', 'config': '344e4756fb1bec455d6af51d3727e33b0d27725f', 'pipeline': '248dad1d8b30a17a5de1d0bbdfe3e2acb7a1962b'}, 'duration': 1.3036692142486572, 'iteration': 8, 'loss': 0.06483125918243893, 'max_history_score': 0.9456356408262035, 'max_history_score_std': 0.040053650785990214, 'max_history_step': 'joint', 'pipeline': {'features': ('features_PCA', {'features__n_components': 2}), 'normalizer': ('normalizer_StandardScaler', {'normalizer__with_mean': False, 'normalizer__with_std': True}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 7})}, 'score': 0.9351687408175611, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'entropy', 'max_depth': 2, 'max_features': 2, 'max_leaf_nodes': 2, 'min_samples_split': 3, 'n_estimators': 10}, 'config_hash': {'algorithm': '0a507823f2ad8605ed5950e1fe61df0560f11a00', 'config': '4a538fdcf8e07f90e92a421c0d5c479d651629c7', 'pipeline': '5240329df25c9a533d025c1a401d49835a501b41'}, 'duration': 1.3821029663085938, 'iteration': 9, 'loss': 0.07006416904329793, 'max_history_score': 0.9456356408262035, 'max_history_score_std': 0.040053650785990214, 'max_history_step': 'joint', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 4, 'features__selectkbest__k': 2}), 'normalizer': ('normalizer_PowerTransformer', {}), 'rebalance': ('rebalance_NearMiss', {'rebalance__n_neighbors': 1})}, 'score': 0.9299358309567021, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'gini', 'max_depth': 1, 'max_features': 3, 'max_leaf_nodes': 5, 'min_samples_split': 3, 'n_estimators': 10}, 'config_hash': {'algorithm': 'd32739750d351948f8ff34a87c7d55b0c5e0d90f', 'config': 'c1609e71f1ce8486335adc70bb69a955580ba2c8', 'pipeline': 'f48b42ec5cf999279659966160a16353b75bdaa3'}, 'duration': 0.9055681228637695, 'iteration': 10, 'loss': 0.07532840722495904, 'max_history_score': 0.9456356408262035, 'max_history_score_std': 0.040053650785990214, 'max_history_step': 'joint', 'pipeline': {'features': ('features_PCA', {'features__n_components': 4}), 'normalizer': ('normalizer_PowerTransformer', {}), 'rebalance': ('rebalance_NearMiss', {'rebalance__n_neighbors': 1})}, 'score': 0.924671592775041, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': 3, 'max_features': 1, 'max_leaf_nodes': 5, 'min_samples_split': 3, 'n_estimators': 25}, 'config_hash': {'algorithm': 'f69bac35e71cbec1bfc1fb5942328a3390e7c252', 'config': 'abe36f188644e53e56ed3224236fa157107ed3b2', 'pipeline': 'aaf976c7c663a31fa039582d42f9e07101556a7c'}, 'duration': 0.764197826385498, 'iteration': 11, 'loss': 0.06818446979517778, 'max_history_score': 0.9456356408262035, 'max_history_score_std': 0.040053650785990214, 'max_history_step': 'joint', 'pipeline': {'features': ('features_NoneType', {}), 'normalizer': ('normalizer_PowerTransformer', {}), 'rebalance': ('rebalance_NoneType', {})}, 'score': 0.9318155302048222, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'entropy', 'max_depth': None, 'max_features': None, 'max_leaf_nodes': None, 'min_samples_split': 5, 'n_estimators': 25}, 'config_hash': {'algorithm': 'a0a27aec00db5ddf71eab96663f9bd61c845f5e3', 'config': '76aa002c3c9d4d9722466c60daf5119c18a41d2a', 'pipeline': '1ce34b7894ef342571d974bb19e8ec821a512c6b'}, 'duration': 1.1636500358581543, 'iteration': 12, 'loss': 0.12833700630887557, 'max_history_score': 0.9456356408262035, 'max_history_score_std': 0.040053650785990214, 'max_history_step': 'joint', 'pipeline': {'features': ('features_PCA', {'features__n_components': 1}), 'normalizer': ('normalizer_PowerTransformer', {}), 'rebalance': ('rebalance_NoneType', {})}, 'score': 0.8716629936911244, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'gini', 'max_depth': 1, 'max_features': 2, 'max_leaf_nodes': 2, 'min_samples_split': 2, 'n_estimators': 100}, 'config_hash': {'algorithm': '985c99dff1da9b2c87e4211c5335a9159aa9dbcb', 'config': 'f56a7a9e43a0a699e992dc1262e550b8b7c88538', 'pipeline': '5c934f6d9a8ad1f9afe762986a9cf2074fc95d79'}, 'duration': 2.235443115234375, 'iteration': 13, 'loss': 0.11414635727249167, 'max_history_score': 0.9456356408262035, 'max_history_score_std': 0.040053650785990214, 'max_history_step': 'joint', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 1, 'features__selectkbest__k': 1}), 'normalizer': ('normalizer_RobustScaler', {'normalizer__quantile_range': (...), 'normalizer__with_centering': False, 'normalizer__with_scaling': True}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 6})}, 'score': 0.8858536427275083, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'gini', 'max_depth': 1, 'max_features': 1, 'max_leaf_nodes': None, 'min_samples_split': 5, 'n_estimators': 10}, 'config_hash': {'algorithm': '7d74a39aac2579264a402aef2b6fa7943c19f3d3', 'config': '53f44c0ad925c5c08c25d4fadf5e9ee9d7c181cd', 'pipeline': '6eff5ef31d7d1d534db31913bb67529c8a24c42e'}, 'duration': 2.7847659587860107, 'iteration': 14, 'loss': 0.14061986863711007, 'max_history_score': 0.9456356408262035, 'max_history_score_std': 0.040053650785990214, 'max_history_step': 'joint', 'pipeline': {'features': ('features_PCA', {'features__n_components': 1}), 'normalizer': ('normalizer_RobustScaler', {'normalizer__quantile_range': (...), 'normalizer__with_centering': True, 'normalizer__with_scaling': True}), 'rebalance': ('rebalance_CondensedNearestNeighbour', {'rebalance__n_neighbors': 3})}, 'score': 0.8593801313628899, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'entropy', 'max_depth': 3, 'max_features': None, 'max_leaf_nodes': 5, 'min_samples_split': 2, 'n_estimators': 100}, 'config_hash': {'algorithm': 'c62d7c671832e4414b6b2d7c36cba5ddc83a0ed0', 'config': '5faee50671eaa0ac586722bff234e36a857e662d', 'pipeline': '8b29a55de2add78c49114b9bbe5e800e5524c59d'}, 'duration': 2.3916029930114746, 'iteration': 15, 'loss': 0.08770093336790252, 'max_history_score': 0.9456356408262035, 'max_history_score_std': 0.040053650785990214, 'max_history_step': 'joint', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 3, 'features__selectkbest__k': 4}), 'normalizer': ('normalizer_RobustScaler', {'normalizer__quantile_range': (...), 'normalizer__with_centering': True, 'normalizer__with_scaling': True}), 'rebalance': ('rebalance_NoneType', {})}, 'score': 0.9122990666320975, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': None, 'max_features': 1, 'max_leaf_nodes': 5, 'min_samples_split': 5, 'n_estimators': 10}, 'config_hash': {'algorithm': '290772bfb9b8ed15c48a72829e822fb0a07481d6', 'config': '9a04f25d8eb3db5b2f831abd341a6d384c73a957', 'pipeline': '1ce34b7894ef342571d974bb19e8ec821a512c6b'}, 'duration': 1.4364500045776367, 'iteration': 16, 'loss': 0.08948880822746508, 'max_history_score': 0.9456356408262035, 'max_history_score_std': 0.040053650785990214, 'max_history_step': 'joint', 'pipeline': {'features': ('features_PCA', {'features__n_components': 1}), 'normalizer': ('normalizer_PowerTransformer', {}), 'rebalance': ('rebalance_NoneType', {})}, 'score': 0.9105111917725349, ...}], 'history_hash': ['51144ca42f9ea5ab2d8d58606e3b3e4d89c6d7b3', '9e54ffcb6a727de032a0a2cd45c5cc37cc150756', 'e5241eee9ddf3f4ee29a4711f5bcc92a4d24cd09', '18ee4d3d1627472ec190326308d8755371a6dc62', '2af4f82b045c0c48ecb89d42728d1039fbff8878', '17b2a1e5814f3e933137158708a5b6e9b2475495', 'fa020a592ec5ac234f9f91aac28abc2cd1ec9d33', '0da4498002d6f452c59bb61756abb3ded841e786', '344e4756fb1bec455d6af51d3727e33b0d27725f', '4a538fdcf8e07f90e92a421c0d5c479d651629c7', 'c1609e71f1ce8486335adc70bb69a955580ba2c8', 'abe36f188644e53e56ed3224236fa157107ed3b2', '76aa002c3c9d4d9722466c60daf5119c18a41d2a', 'f56a7a9e43a0a699e992dc1262e550b8b7c88538', '53f44c0ad925c5c08c25d4fadf5e9ee9d7c181cd', '5faee50671eaa0ac586722bff234e36a857e662d', '9a04f25d8eb3db5b2f831abd341a6d384c73a957'], 'history_index': {'0da4498002d6f452c59bb61756abb3ded841e786': 7, '17b2a1e5814f3e933137158708a5b6e9b2475495': 5, '18ee4d3d1627472ec190326308d8755371a6dc62': 3, '2af4f82b045c0c48ecb89d42728d1039fbff8878': 4, '344e4756fb1bec455d6af51d3727e33b0d27725f': 8, '4a538fdcf8e07f90e92a421c0d5c479d651629c7': 9, '51144ca42f9ea5ab2d8d58606e3b3e4d89c6d7b3': 0, '53f44c0ad925c5c08c25d4fadf5e9ee9d7c181cd': 14, '5faee50671eaa0ac586722bff234e36a857e662d': 15, '76aa002c3c9d4d9722466c60daf5119c18a41d2a': 12, ...}, 'iteration': 16, 'max_history_score': 0.9456356408262035, 'max_history_score_std': 0.040053650785990214, 'max_history_step': 'joint'}
        config = {'algorithm': 'RandomForest', 'seed': 42, 'time': 300}
    114 
    115 
    116 def get_baseline_score(algorithm, X, y, seed):
    117     pipeline, _ = pipeline_conf_to_full_pipeline(

...........................................................................
/home/aquemy/dev/dp_hyperparameters/extension/experiment/objective.py in objective(pipeline_config={'features': ('features_SelectKBest', {'features__k': 2}), 'normalizer': ('normalizer_PowerTransformer', {}), 'rebalance': ('rebalance_NearMiss', {'rebalance__n_neighbors': 1})}, algo_config={'bootstrap': True, 'criterion': 'gini', 'max_depth': 2, 'max_features': 3, 'max_leaf_nodes': 3, 'min_samples_split': 3, 'n_estimators': 100}, algorithm='RandomForest', X=array([[1.799e+01, 1.038e+01, 1.228e+02, ..., 2...., ..., 0.000e+00, 2.871e-01,
        7.039e-02]]), y=array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,... 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1]), context={'baseline_score': 0.9545944602886527, 'baseline_score_std': 0.03716322883281839, 'best_config': {'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': None, 'max_features': 2, 'max_leaf_nodes': 3, 'min_samples_split': 2, 'n_estimators': 100}, 'config_hash': {'algorithm': '1b32258c630f07e01ab481ab925ab80aa757e482', 'config': '9e54ffcb6a727de032a0a2cd45c5cc37cc150756', 'pipeline': '37e72d4a97f5e784c9d3133e6379b91bfc3be803'}, 'duration': 1.3065669536590576, 'iteration': 1, 'loss': 0.05436435917379645, 'max_history_score': 0.9456356408262035, 'max_history_score_std': 0.040053650785990214, 'max_history_step': 'joint', 'pipeline': {'features': ('features_NoneType', {}), 'normalizer': ('normalizer_StandardScaler', {'normalizer__with_mean': True, 'normalizer__with_std': True}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 6})}, 'score': 0.9456356408262035, ...}, 'history': [{'algorithm': {'bootstrap': True, 'criterion': 'entropy', 'max_depth': 4, 'max_features': 3, 'max_leaf_nodes': 3, 'min_samples_split': 2, 'n_estimators': 10}, 'config_hash': {'algorithm': '42527c4120073c2a488d1b8df28732f486d1578c', 'config': '51144ca42f9ea5ab2d8d58606e3b3e4d89c6d7b3', 'pipeline': '52f07bda29f9d3a95fabb87e591d0b2581ca8209'}, 'duration': 0.26703310012817383, 'iteration': 0, 'loss': 0.06655431682654922, 'max_history_score': 0.9334456831734508, 'max_history_score_std': 0.03819399139659311, 'max_history_step': 'joint', 'pipeline': {'features': ('features_NoneType', {}), 'normalizer': ('normalizer_RobustScaler', {'normalizer__quantile_range': (...), 'normalizer__with_centering': False, 'normalizer__with_scaling': False}), 'rebalance': ('rebalance_NearMiss', {'rebalance__n_neighbors': 1})}, 'score': 0.9334456831734508, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': None, 'max_features': 2, 'max_leaf_nodes': 3, 'min_samples_split': 2, 'n_estimators': 100}, 'config_hash': {'algorithm': '1b32258c630f07e01ab481ab925ab80aa757e482', 'config': '9e54ffcb6a727de032a0a2cd45c5cc37cc150756', 'pipeline': '37e72d4a97f5e784c9d3133e6379b91bfc3be803'}, 'duration': 1.3065669536590576, 'iteration': 1, 'loss': 0.05436435917379645, 'max_history_score': 0.9456356408262035, 'max_history_score_std': 0.040053650785990214, 'max_history_step': 'joint', 'pipeline': {'features': ('features_NoneType', {}), 'normalizer': ('normalizer_StandardScaler', {'normalizer__with_mean': True, 'normalizer__with_std': True}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 6})}, 'score': 0.9456356408262035, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'entropy', 'max_depth': 1, 'max_features': 1, 'max_leaf_nodes': 2, 'min_samples_split': 3, 'n_estimators': 25}, 'config_hash': {'algorithm': '68ab9059aa7ec74e0da87c81734b9664243b3eb4', 'config': 'e5241eee9ddf3f4ee29a4711f5bcc92a4d24cd09', 'pipeline': '62463de065924498cdcd2f2f1f7e68535cdb33a5'}, 'duration': 0.6592490673065186, 'iteration': 2, 'loss': 0.07695856019358727, 'max_history_score': 0.9456356408262035, 'max_history_score_std': 0.040053650785990214, 'max_history_step': 'joint', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 1, 'features__selectkbest__k': 2}), 'normalizer': ('normalizer_NoneType', {}), 'rebalance': ('rebalance_NoneType', {})}, 'score': 0.9230414398064127, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': 3, 'max_features': 2, 'max_leaf_nodes': 2, 'min_samples_split': 2, 'n_estimators': 25}, 'config_hash': {'algorithm': 'e3f1f7d7783557a38f40f0476369091edd87092b', 'config': '18ee4d3d1627472ec190326308d8755371a6dc62', 'pipeline': 'c6d1263e344ed8c71b2e6e4ba8e0db2fb6c777c0'}, 'duration': 0.879349946975708, 'iteration': 3, 'loss': 0.07535973554576114, 'max_history_score': 0.9456356408262035, 'max_history_score_std': 0.040053650785990214, 'max_history_step': 'joint', 'pipeline': {'features': ('features_NoneType', {}), 'normalizer': ('normalizer_RobustScaler', {'normalizer__quantile_range': (...), 'normalizer__with_centering': True, 'normalizer__with_scaling': True}), 'rebalance': ('rebalance_NearMiss', {'rebalance__n_neighbors': 2})}, 'score': 0.9246402644542389, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'gini', 'max_depth': 4, 'max_features': 2, 'max_leaf_nodes': 5, 'min_samples_split': 2, 'n_estimators': 50}, 'config_hash': {'algorithm': '47581af7253940f9647ad16d37347d34baf13e5f', 'config': '2af4f82b045c0c48ecb89d42728d1039fbff8878', 'pipeline': '2928b22ed834303cb7bac6e6608531eaddd7df67'}, 'duration': 4.372632026672363, 'iteration': 4, 'loss': 0.09121294615849984, 'max_history_score': 0.9456356408262035, 'max_history_score_std': 0.040053650785990214, 'max_history_step': 'joint', 'pipeline': {'features': ('features_NoneType', {}), 'normalizer': ('normalizer_MinMaxScaler', {}), 'rebalance': ('rebalance_CondensedNearestNeighbour', {'rebalance__n_neighbors': 2})}, 'score': 0.9087870538415002, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'entropy', 'max_depth': 2, 'max_features': 2, 'max_leaf_nodes': None, 'min_samples_split': 2, 'n_estimators': 10}, 'config_hash': {'algorithm': '0a85f98ca2d06103287f153633d88f7a0535e7e8', 'config': '17b2a1e5814f3e933137158708a5b6e9b2475495', 'pipeline': '95defa3bdd8357f11f872d3c280d50a6d8ee398d'}, 'duration': 2.625814914703369, 'iteration': 5, 'loss': 0.15471329185031535, 'max_history_score': 0.9456356408262035, 'max_history_score_std': 0.040053650785990214, 'max_history_step': 'joint', 'pipeline': {'features': ('features_SelectKBest', {'features__k': 2}), 'normalizer': ('normalizer_StandardScaler', {'normalizer__with_mean': False, 'normalizer__with_std': False}), 'rebalance': ('rebalance_CondensedNearestNeighbour', {'rebalance__n_neighbors': 1})}, 'score': 0.8452867081496847, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': 3, 'max_features': None, 'max_leaf_nodes': None, 'min_samples_split': 5, 'n_estimators': 75}, 'config_hash': {'algorithm': 'd7466a2c1d5cb3fa95029d73dc030f4c3c45a159', 'config': 'fa020a592ec5ac234f9f91aac28abc2cd1ec9d33', 'pipeline': '71e0d26f923d42cfe0e2fa748931ef2afe72ed86'}, 'duration': 3.62078595161438, 'iteration': 6, 'loss': 0.17066372828623277, 'max_history_score': 0.9456356408262035, 'max_history_score_std': 0.040053650785990214, 'max_history_step': 'joint', 'pipeline': {'features': ('features_SelectKBest', {'features__k': 1}), 'normalizer': ('normalizer_RobustScaler', {'normalizer__quantile_range': (...), 'normalizer__with_centering': True, 'normalizer__with_scaling': True}), 'rebalance': ('rebalance_CondensedNearestNeighbour', {'rebalance__n_neighbors': 1})}, 'score': 0.8293362717137672, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'entropy', 'max_depth': 3, 'max_features': 3, 'max_leaf_nodes': 5, 'min_samples_split': 5, 'n_estimators': 50}, 'config_hash': {'algorithm': '735caa9785596076014572a24050cde8dc338973', 'config': '0da4498002d6f452c59bb61756abb3ded841e786', 'pipeline': '51a53ea6ef5a2521ee65f76eb2da220ab7086513'}, 'duration': 0.6934049129486084, 'iteration': 7, 'loss': 0.06125875032408601, 'max_history_score': 0.9456356408262035, 'max_history_score_std': 0.040053650785990214, 'max_history_step': 'joint', 'pipeline': {'features': ('features_NoneType', {}), 'normalizer': ('normalizer_NoneType', {}), 'rebalance': ('rebalance_NearMiss', {'rebalance__n_neighbors': 3})}, 'score': 0.938741249675914, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': 4, 'max_features': 2, 'max_leaf_nodes': None, 'min_samples_split': 3, 'n_estimators': 75}, 'config_hash': {'algorithm': 'e71a1fe9515b6805f07914a61f2e7594be9e9afe', 'config': '344e4756fb1bec455d6af51d3727e33b0d27725f', 'pipeline': '248dad1d8b30a17a5de1d0bbdfe3e2acb7a1962b'}, 'duration': 1.3036692142486572, 'iteration': 8, 'loss': 0.06483125918243893, 'max_history_score': 0.9456356408262035, 'max_history_score_std': 0.040053650785990214, 'max_history_step': 'joint', 'pipeline': {'features': ('features_PCA', {'features__n_components': 2}), 'normalizer': ('normalizer_StandardScaler', {'normalizer__with_mean': False, 'normalizer__with_std': True}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 7})}, 'score': 0.9351687408175611, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'entropy', 'max_depth': 2, 'max_features': 2, 'max_leaf_nodes': 2, 'min_samples_split': 3, 'n_estimators': 10}, 'config_hash': {'algorithm': '0a507823f2ad8605ed5950e1fe61df0560f11a00', 'config': '4a538fdcf8e07f90e92a421c0d5c479d651629c7', 'pipeline': '5240329df25c9a533d025c1a401d49835a501b41'}, 'duration': 1.3821029663085938, 'iteration': 9, 'loss': 0.07006416904329793, 'max_history_score': 0.9456356408262035, 'max_history_score_std': 0.040053650785990214, 'max_history_step': 'joint', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 4, 'features__selectkbest__k': 2}), 'normalizer': ('normalizer_PowerTransformer', {}), 'rebalance': ('rebalance_NearMiss', {'rebalance__n_neighbors': 1})}, 'score': 0.9299358309567021, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'gini', 'max_depth': 1, 'max_features': 3, 'max_leaf_nodes': 5, 'min_samples_split': 3, 'n_estimators': 10}, 'config_hash': {'algorithm': 'd32739750d351948f8ff34a87c7d55b0c5e0d90f', 'config': 'c1609e71f1ce8486335adc70bb69a955580ba2c8', 'pipeline': 'f48b42ec5cf999279659966160a16353b75bdaa3'}, 'duration': 0.9055681228637695, 'iteration': 10, 'loss': 0.07532840722495904, 'max_history_score': 0.9456356408262035, 'max_history_score_std': 0.040053650785990214, 'max_history_step': 'joint', 'pipeline': {'features': ('features_PCA', {'features__n_components': 4}), 'normalizer': ('normalizer_PowerTransformer', {}), 'rebalance': ('rebalance_NearMiss', {'rebalance__n_neighbors': 1})}, 'score': 0.924671592775041, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': 3, 'max_features': 1, 'max_leaf_nodes': 5, 'min_samples_split': 3, 'n_estimators': 25}, 'config_hash': {'algorithm': 'f69bac35e71cbec1bfc1fb5942328a3390e7c252', 'config': 'abe36f188644e53e56ed3224236fa157107ed3b2', 'pipeline': 'aaf976c7c663a31fa039582d42f9e07101556a7c'}, 'duration': 0.764197826385498, 'iteration': 11, 'loss': 0.06818446979517778, 'max_history_score': 0.9456356408262035, 'max_history_score_std': 0.040053650785990214, 'max_history_step': 'joint', 'pipeline': {'features': ('features_NoneType', {}), 'normalizer': ('normalizer_PowerTransformer', {}), 'rebalance': ('rebalance_NoneType', {})}, 'score': 0.9318155302048222, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'entropy', 'max_depth': None, 'max_features': None, 'max_leaf_nodes': None, 'min_samples_split': 5, 'n_estimators': 25}, 'config_hash': {'algorithm': 'a0a27aec00db5ddf71eab96663f9bd61c845f5e3', 'config': '76aa002c3c9d4d9722466c60daf5119c18a41d2a', 'pipeline': '1ce34b7894ef342571d974bb19e8ec821a512c6b'}, 'duration': 1.1636500358581543, 'iteration': 12, 'loss': 0.12833700630887557, 'max_history_score': 0.9456356408262035, 'max_history_score_std': 0.040053650785990214, 'max_history_step': 'joint', 'pipeline': {'features': ('features_PCA', {'features__n_components': 1}), 'normalizer': ('normalizer_PowerTransformer', {}), 'rebalance': ('rebalance_NoneType', {})}, 'score': 0.8716629936911244, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'gini', 'max_depth': 1, 'max_features': 2, 'max_leaf_nodes': 2, 'min_samples_split': 2, 'n_estimators': 100}, 'config_hash': {'algorithm': '985c99dff1da9b2c87e4211c5335a9159aa9dbcb', 'config': 'f56a7a9e43a0a699e992dc1262e550b8b7c88538', 'pipeline': '5c934f6d9a8ad1f9afe762986a9cf2074fc95d79'}, 'duration': 2.235443115234375, 'iteration': 13, 'loss': 0.11414635727249167, 'max_history_score': 0.9456356408262035, 'max_history_score_std': 0.040053650785990214, 'max_history_step': 'joint', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 1, 'features__selectkbest__k': 1}), 'normalizer': ('normalizer_RobustScaler', {'normalizer__quantile_range': (...), 'normalizer__with_centering': False, 'normalizer__with_scaling': True}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 6})}, 'score': 0.8858536427275083, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'gini', 'max_depth': 1, 'max_features': 1, 'max_leaf_nodes': None, 'min_samples_split': 5, 'n_estimators': 10}, 'config_hash': {'algorithm': '7d74a39aac2579264a402aef2b6fa7943c19f3d3', 'config': '53f44c0ad925c5c08c25d4fadf5e9ee9d7c181cd', 'pipeline': '6eff5ef31d7d1d534db31913bb67529c8a24c42e'}, 'duration': 2.7847659587860107, 'iteration': 14, 'loss': 0.14061986863711007, 'max_history_score': 0.9456356408262035, 'max_history_score_std': 0.040053650785990214, 'max_history_step': 'joint', 'pipeline': {'features': ('features_PCA', {'features__n_components': 1}), 'normalizer': ('normalizer_RobustScaler', {'normalizer__quantile_range': (...), 'normalizer__with_centering': True, 'normalizer__with_scaling': True}), 'rebalance': ('rebalance_CondensedNearestNeighbour', {'rebalance__n_neighbors': 3})}, 'score': 0.8593801313628899, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'entropy', 'max_depth': 3, 'max_features': None, 'max_leaf_nodes': 5, 'min_samples_split': 2, 'n_estimators': 100}, 'config_hash': {'algorithm': 'c62d7c671832e4414b6b2d7c36cba5ddc83a0ed0', 'config': '5faee50671eaa0ac586722bff234e36a857e662d', 'pipeline': '8b29a55de2add78c49114b9bbe5e800e5524c59d'}, 'duration': 2.3916029930114746, 'iteration': 15, 'loss': 0.08770093336790252, 'max_history_score': 0.9456356408262035, 'max_history_score_std': 0.040053650785990214, 'max_history_step': 'joint', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 3, 'features__selectkbest__k': 4}), 'normalizer': ('normalizer_RobustScaler', {'normalizer__quantile_range': (...), 'normalizer__with_centering': True, 'normalizer__with_scaling': True}), 'rebalance': ('rebalance_NoneType', {})}, 'score': 0.9122990666320975, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': None, 'max_features': 1, 'max_leaf_nodes': 5, 'min_samples_split': 5, 'n_estimators': 10}, 'config_hash': {'algorithm': '290772bfb9b8ed15c48a72829e822fb0a07481d6', 'config': '9a04f25d8eb3db5b2f831abd341a6d384c73a957', 'pipeline': '1ce34b7894ef342571d974bb19e8ec821a512c6b'}, 'duration': 1.4364500045776367, 'iteration': 16, 'loss': 0.08948880822746508, 'max_history_score': 0.9456356408262035, 'max_history_score_std': 0.040053650785990214, 'max_history_step': 'joint', 'pipeline': {'features': ('features_PCA', {'features__n_components': 1}), 'normalizer': ('normalizer_PowerTransformer', {}), 'rebalance': ('rebalance_NoneType', {})}, 'score': 0.9105111917725349, ...}], 'history_hash': ['51144ca42f9ea5ab2d8d58606e3b3e4d89c6d7b3', '9e54ffcb6a727de032a0a2cd45c5cc37cc150756', 'e5241eee9ddf3f4ee29a4711f5bcc92a4d24cd09', '18ee4d3d1627472ec190326308d8755371a6dc62', '2af4f82b045c0c48ecb89d42728d1039fbff8878', '17b2a1e5814f3e933137158708a5b6e9b2475495', 'fa020a592ec5ac234f9f91aac28abc2cd1ec9d33', '0da4498002d6f452c59bb61756abb3ded841e786', '344e4756fb1bec455d6af51d3727e33b0d27725f', '4a538fdcf8e07f90e92a421c0d5c479d651629c7', 'c1609e71f1ce8486335adc70bb69a955580ba2c8', 'abe36f188644e53e56ed3224236fa157107ed3b2', '76aa002c3c9d4d9722466c60daf5119c18a41d2a', 'f56a7a9e43a0a699e992dc1262e550b8b7c88538', '53f44c0ad925c5c08c25d4fadf5e9ee9d7c181cd', '5faee50671eaa0ac586722bff234e36a857e662d', '9a04f25d8eb3db5b2f831abd341a6d384c73a957'], 'history_index': {'0da4498002d6f452c59bb61756abb3ded841e786': 7, '17b2a1e5814f3e933137158708a5b6e9b2475495': 5, '18ee4d3d1627472ec190326308d8755371a6dc62': 3, '2af4f82b045c0c48ecb89d42728d1039fbff8878': 4, '344e4756fb1bec455d6af51d3727e33b0d27725f': 8, '4a538fdcf8e07f90e92a421c0d5c479d651629c7': 9, '51144ca42f9ea5ab2d8d58606e3b3e4d89c6d7b3': 0, '53f44c0ad925c5c08c25d4fadf5e9ee9d7c181cd': 14, '5faee50671eaa0ac586722bff234e36a857e662d': 15, '76aa002c3c9d4d9722466c60daf5119c18a41d2a': 12, ...}, 'iteration': 16, 'max_history_score': 0.9456356408262035, 'max_history_score_std': 0.040053650785990214, 'max_history_step': 'joint'}, config={'algorithm': 'RandomForest', 'seed': 42, 'time': 300}, step='joint')
     45                 y,
     46                 cv=10,
     47                 n_jobs=-1,
     48                 return_estimator=False,
     49                 return_train_score=False,
---> 50                 verbose=0)
     51         score = np.mean(scores['test_score'])
     52         std = np.std(scores['test_score'])
     53         status = STATUS_OK
     54     except Exception as e:

...........................................................................
/home/aquemy/.local/lib/python2.7/site-packages/sklearn/model_selection/_validation.py in cross_validate(estimator=Pipeline(memory=None,
     steps=[('rebalance', ... random_state=42, verbose=0, warm_start=False))]), X=array([[1.799e+01, 1.038e+01, 1.228e+02, ..., 2...., ..., 0.000e+00, 2.871e-01,
        7.039e-02]]), y=array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,... 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1]), groups=None, scoring=None, cv=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1, verbose=0, fit_params=None, pre_dispatch='2*n_jobs', return_train_score=False, return_estimator=False, error_score='raise-deprecating')
    235         delayed(_fit_and_score)(
    236             clone(estimator), X, y, scorers, train, test, verbose, None,
    237             fit_params, return_train_score=return_train_score,
    238             return_times=True, return_estimator=return_estimator,
    239             error_score=error_score)
--> 240         for train, test in cv.split(X, y, groups))
        cv.split = <bound method StratifiedKFold.split of Stratifie...d(n_splits=10, random_state=None, shuffle=False)>
        X = array([[1.799e+01, 1.038e+01, 1.228e+02, ..., 2...., ..., 0.000e+00, 2.871e-01,
        7.039e-02]])
        y = array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,... 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1])
        groups = None
    241 
    242     zipped_scores = list(zip(*scores))
    243     if return_train_score:
    244         train_scores = zipped_scores.pop(0)

...........................................................................
/home/aquemy/.local/lib/python2.7/site-packages/sklearn/externals/joblib/parallel.py in __call__(self=Parallel(n_jobs=-1), iterable=<generator object <genexpr>>)
    925                 # No need to wait for async callbacks to trigger to
    926                 # consumption.
    927                 self._iterating = False
    928 
    929             with self._backend.retrieval_context():
--> 930                 self.retrieve()
        self.retrieve = <bound method Parallel.retrieve of Parallel(n_jobs=-1)>
    931             # Make sure that we get a last message telling us we are done
    932             elapsed_time = time.time() - self._start_time
    933             self._print('Done %3i out of %3i | elapsed: %s finished',
    934                         (len(self._output), len(self._output),

---------------------------------------------------------------------------
Joblib worker traceback:
---------------------------------------------------------------------------
ValueError                                         Mon Jun 17 13:31:58 2019
PID: 25855                                  Python 2.7.15+: /usr/bin/python
...........................................................................
/home/aquemy/.local/lib/python2.7/site-packages/sklearn/externals/joblib/parallel.py in __call__(self=<sklearn.externals.joblib.parallel.BatchedCalls object>)
    220     def __call__(self):
    221         # Set the default nested backend to self._backend but do not set the
    222         # change the default number of processes to -1
    223         with parallel_backend(self._backend, n_jobs=self._n_jobs):
    224             return [func(*args, **kwargs)
--> 225                     for func, args, kwargs in self.items]
        func = <function _fit_and_score>
        args = (Pipeline(memory=None,
     steps=[('rebalance', ... random_state=42, verbose=0, warm_start=False))]), array([[1.799e+01, 1.038e+01, 1.228e+02, ..., 2...., ..., 0.000e+00, 2.871e-01,
        7.039e-02]]), array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,... 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1]), {'score': <function _passthrough_scorer>}, array([ 25,  26,  27,  28,  29,  30,  31,  32,  ..., 561, 562, 563, 564,
       565, 566, 567, 568]), array([  0,   1,   2,   3,   4,   5,   6,   7,  ...,  89,  90,
        92,  93,  96,  97,  98, 101]), 0, None, None)
        kwargs = {'error_score': 'raise-deprecating', 'return_estimator': False, 'return_times': True, 'return_train_score': False}
        self.items = [(<function _fit_and_score>, (Pipeline(memory=None,
     steps=[('rebalance', ... random_state=42, verbose=0, warm_start=False))]), array([[1.799e+01, 1.038e+01, 1.228e+02, ..., 2...., ..., 0.000e+00, 2.871e-01,
        7.039e-02]]), array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,... 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1]), {'score': <function _passthrough_scorer>}, array([ 25,  26,  27,  28,  29,  30,  31,  32,  ..., 561, 562, 563, 564,
       565, 566, 567, 568]), array([  0,   1,   2,   3,   4,   5,   6,   7,  ...,  89,  90,
        92,  93,  96,  97,  98, 101]), 0, None, None), {'error_score': 'raise-deprecating', 'return_estimator': False, 'return_times': True, 'return_train_score': False})]
    226 
    227     def __len__(self):
    228         return self._size
    229 

...........................................................................
/home/aquemy/.local/lib/python2.7/site-packages/sklearn/model_selection/_validation.py in _fit_and_score(estimator=Pipeline(memory=None,
     steps=[('rebalance', ... random_state=42, verbose=0, warm_start=False))]), X=array([[1.799e+01, 1.038e+01, 1.228e+02, ..., 2...., ..., 0.000e+00, 2.871e-01,
        7.039e-02]]), y=array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,... 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1]), scorer={'score': <function _passthrough_scorer>}, train=array([ 25,  26,  27,  28,  29,  30,  31,  32,  ..., 561, 562, 563, 564,
       565, 566, 567, 568]), test=array([  0,   1,   2,   3,   4,   5,   6,   7,  ...,  89,  90,
        92,  93,  96,  97,  98, 101]), verbose=0, parameters=None, fit_params={}, return_train_score=False, return_parameters=False, return_n_test_samples=False, return_times=True, return_estimator=False, error_score='raise-deprecating')
    523 
    524     try:
    525         if y_train is None:
    526             estimator.fit(X_train, **fit_params)
    527         else:
--> 528             estimator.fit(X_train, y_train, **fit_params)
        estimator.fit = <bound method Pipeline.fit of Pipeline(memory=No...random_state=42, verbose=0, warm_start=False))])>
        X_train = array([[1.714e+01, 1.640e+01, 1.160e+02, ..., 2...., ..., 0.000e+00, 2.871e-01,
        7.039e-02]])
        y_train = array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...1, 1, 1, 1, 1, 1, 1, 0, 0,
       0, 0, 0, 0, 1])
        fit_params = {}
    529 
    530     except Exception as e:
    531         # Note fit time as time until error
    532         fit_time = time.time() - start_time

...........................................................................
/usr/local/lib/python2.7/dist-packages/imblearn/pipeline.py in fit(self=Pipeline(memory=None,
     steps=[('rebalance', ... random_state=42, verbose=0, warm_start=False))]), X=array([[1.714e+01, 1.640e+01, 1.160e+02, ..., 2...., ..., 0.000e+00, 2.871e-01,
        7.039e-02]]), y=array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...1, 1, 1, 1, 1, 1, 1, 0, 0,
       0, 0, 0, 0, 1]), **fit_params={})
    234             This estimator
    235 
    236         """
    237         Xt, yt, fit_params = self._fit(X, y, **fit_params)
    238         if self._final_estimator is not None:
--> 239             self._final_estimator.fit(Xt, yt, **fit_params)
        self._final_estimator.fit = <bound method RandomForestClassifier.fit of Rand...e, random_state=42, verbose=0, warm_start=False)>
        Xt = array([[ 1.69225277,  1.16091407],
       [ 0.91...-1.6352888 ],
       [-0.93991228, -0.48389628]])
        yt = array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...1, 1, 1, 1, 1, 1, 1, 1,
       1, 1, 1, 1, 1, 1])
        fit_params = {}
    240         return self
    241 
    242     def fit_transform(self, X, y=None, **fit_params):
    243         """Fit the model and transform with the final estimator

...........................................................................
/home/aquemy/.local/lib/python2.7/site-packages/sklearn/ensemble/forest.py in fit(self=RandomForestClassifier(bootstrap=True, class_wei...se, random_state=42, verbose=0, warm_start=False), X=array([[ 1.6922528 ,  1.1609141 ],
       [ 0.91...      [-0.93991226, -0.4838963 ]], dtype=float32), y=array([[0.],
       [0.],
       [0.],
       [0...    [1.],
       [1.],
       [1.],
       [1.]]), sample_weight=None)
    328             trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,
    329                              **_joblib_parallel_args(prefer='threads'))(
    330                 delayed(_parallel_build_trees)(
    331                     t, self, X, y, sample_weight, i, len(trees),
    332                     verbose=self.verbose, class_weight=self.class_weight)
--> 333                 for i, t in enumerate(trees))
        i = 99
    334 
    335             # Collect newly grown trees
    336             self.estimators_.extend(trees)
    337 

...........................................................................
/home/aquemy/.local/lib/python2.7/site-packages/sklearn/externals/joblib/parallel.py in __call__(self=Parallel(n_jobs=1), iterable=<generator object <genexpr>>)
    912             # self._original_iterator is None, then this means either
    913             # that pre_dispatch == "all", n_jobs == 1 or that the first batch
    914             # was very quick and its callback already dispatched all the
    915             # remaining jobs.
    916             self._iterating = False
--> 917             if self.dispatch_one_batch(iterator):
        self.dispatch_one_batch = <bound method Parallel.dispatch_one_batch of Parallel(n_jobs=1)>
        iterator = <generator object <genexpr>>
    918                 self._iterating = self._original_iterator is not None
    919 
    920             while self.dispatch_one_batch(iterator):
    921                 pass

...........................................................................
/home/aquemy/.local/lib/python2.7/site-packages/sklearn/externals/joblib/parallel.py in dispatch_one_batch(self=Parallel(n_jobs=1), iterator=<generator object <genexpr>>)
    754                                  self._pickle_cache)
    755             if len(tasks) == 0:
    756                 # No more tasks available in the iterator: tell caller to stop.
    757                 return False
    758             else:
--> 759                 self._dispatch(tasks)
        self._dispatch = <bound method Parallel._dispatch of Parallel(n_jobs=1)>
        tasks = <sklearn.externals.joblib.parallel.BatchedCalls object>
    760                 return True
    761 
    762     def _print(self, msg, msg_args):
    763         """Display the message on stout or stderr depending on verbosity"""

...........................................................................
/home/aquemy/.local/lib/python2.7/site-packages/sklearn/externals/joblib/parallel.py in _dispatch(self=Parallel(n_jobs=1), batch=<sklearn.externals.joblib.parallel.BatchedCalls object>)
    711 
    712         dispatch_timestamp = time.time()
    713         cb = BatchCompletionCallBack(dispatch_timestamp, len(batch), self)
    714         with self._lock:
    715             job_idx = len(self._jobs)
--> 716             job = self._backend.apply_async(batch, callback=cb)
        job = undefined
        self._backend.apply_async = <bound method SequentialBackend.apply_async of <...lib._parallel_backends.SequentialBackend object>>
        batch = <sklearn.externals.joblib.parallel.BatchedCalls object>
        cb = <sklearn.externals.joblib.parallel.BatchCompletionCallBack object>
    717             # A job can complete so quickly than its callback is
    718             # called before we get here, causing self._jobs to
    719             # grow. To ensure correct results ordering, .insert is
    720             # used (rather than .append) in the following line

...........................................................................
/home/aquemy/.local/lib/python2.7/site-packages/sklearn/externals/joblib/_parallel_backends.py in apply_async(self=<sklearn.externals.joblib._parallel_backends.SequentialBackend object>, func=<sklearn.externals.joblib.parallel.BatchedCalls object>, callback=<sklearn.externals.joblib.parallel.BatchCompletionCallBack object>)
    177             raise ValueError('n_jobs == 0 in Parallel has no meaning')
    178         return 1
    179 
    180     def apply_async(self, func, callback=None):
    181         """Schedule a func to be run"""
--> 182         result = ImmediateResult(func)
        result = undefined
        func = <sklearn.externals.joblib.parallel.BatchedCalls object>
    183         if callback:
    184             callback(result)
    185         return result
    186 

...........................................................................
/home/aquemy/.local/lib/python2.7/site-packages/sklearn/externals/joblib/_parallel_backends.py in __init__(self=<sklearn.externals.joblib._parallel_backends.ImmediateResult object>, batch=<sklearn.externals.joblib.parallel.BatchedCalls object>)
    544 
    545 class ImmediateResult(object):
    546     def __init__(self, batch):
    547         # Don't delay the application, to avoid keeping the input
    548         # arguments in memory
--> 549         self.results = batch()
        self.results = undefined
        batch = <sklearn.externals.joblib.parallel.BatchedCalls object>
    550 
    551     def get(self):
    552         return self.results
    553 

...........................................................................
/home/aquemy/.local/lib/python2.7/site-packages/sklearn/externals/joblib/parallel.py in __call__(self=<sklearn.externals.joblib.parallel.BatchedCalls object>)
    220     def __call__(self):
    221         # Set the default nested backend to self._backend but do not set the
    222         # change the default number of processes to -1
    223         with parallel_backend(self._backend, n_jobs=self._n_jobs):
    224             return [func(*args, **kwargs)
--> 225                     for func, args, kwargs in self.items]
        func = <function _parallel_build_trees>
        args = (DecisionTreeClassifier(class_weight=None, criter...=False, random_state=1608637542, splitter='best'), RandomForestClassifier(bootstrap=True, class_wei...se, random_state=42, verbose=0, warm_start=False), array([[ 1.6922528 ,  1.1609141 ],
       [ 0.91...      [-0.93991226, -0.4838963 ]], dtype=float32), array([[0.],
       [0.],
       [0.],
       [0...    [1.],
       [1.],
       [1.],
       [1.]]), None, 0, 100)
        kwargs = {'class_weight': None, 'verbose': 0}
        self.items = [(<function _parallel_build_trees>, (DecisionTreeClassifier(class_weight=None, criter...=False, random_state=1608637542, splitter='best'), RandomForestClassifier(bootstrap=True, class_wei...se, random_state=42, verbose=0, warm_start=False), array([[ 1.6922528 ,  1.1609141 ],
       [ 0.91...      [-0.93991226, -0.4838963 ]], dtype=float32), array([[0.],
       [0.],
       [0.],
       [0...    [1.],
       [1.],
       [1.],
       [1.]]), None, 0, 100), {'class_weight': None, 'verbose': 0})]
    226 
    227     def __len__(self):
    228         return self._size
    229 

...........................................................................
/home/aquemy/.local/lib/python2.7/site-packages/sklearn/ensemble/forest.py in _parallel_build_trees(tree=DecisionTreeClassifier(class_weight=None, criter...=False, random_state=1608637542, splitter='best'), forest=RandomForestClassifier(bootstrap=True, class_wei...se, random_state=42, verbose=0, warm_start=False), X=array([[ 1.6922528 ,  1.1609141 ],
       [ 0.91...      [-0.93991226, -0.4838963 ]], dtype=float32), y=array([[0.],
       [0.],
       [0.],
       [0...    [1.],
       [1.],
       [1.],
       [1.]]), sample_weight=None, tree_idx=0, n_trees=100, verbose=0, class_weight=None)
    114                 simplefilter('ignore', DeprecationWarning)
    115                 curr_sample_weight *= compute_sample_weight('auto', y, indices)
    116         elif class_weight == 'balanced_subsample':
    117             curr_sample_weight *= compute_sample_weight('balanced', y, indices)
    118 
--> 119         tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)
        tree.fit = <bound method DecisionTreeClassifier.fit of Deci...False, random_state=1608637542, splitter='best')>
        X = array([[ 1.6922528 ,  1.1609141 ],
       [ 0.91...      [-0.93991226, -0.4838963 ]], dtype=float32)
        y = array([[0.],
       [0.],
       [0.],
       [0...    [1.],
       [1.],
       [1.],
       [1.]])
        sample_weight = None
        curr_sample_weight = array([4., 5., 1., 1., 2., 1., 1., 1., 2., 1., 0..., 3., 2., 2., 1.,
       0., 3., 0., 0., 2., 2.])
    120     else:
    121         tree.fit(X, y, sample_weight=sample_weight, check_input=False)
    122 
    123     return tree

...........................................................................
/home/aquemy/.local/lib/python2.7/site-packages/sklearn/tree/tree.py in fit(self=DecisionTreeClassifier(class_weight=None, criter...=False, random_state=1608637542, splitter='best'), X=array([[ 1.6922528 ,  1.1609141 ],
       [ 0.91...      [-0.93991226, -0.4838963 ]], dtype=float32), y=array([[0.],
       [0.],
       [0.],
       [0...    [1.],
       [1.],
       [1.],
       [1.]]), sample_weight=array([4., 5., 1., 1., 2., 1., 1., 1., 2., 1., 0..., 3., 2., 2., 1.,
       0., 3., 0., 0., 2., 2.]), check_input=False, X_idx_sorted=None)
    796 
    797         super(DecisionTreeClassifier, self).fit(
    798             X, y,
    799             sample_weight=sample_weight,
    800             check_input=check_input,
--> 801             X_idx_sorted=X_idx_sorted)
        X_idx_sorted = None
    802         return self
    803 
    804     def predict_proba(self, X, check_input=True):
    805         """Predict class probabilities of the input samples X.

...........................................................................
/home/aquemy/.local/lib/python2.7/site-packages/sklearn/tree/tree.py in fit(self=DecisionTreeClassifier(class_weight=None, criter...=False, random_state=1608637542, splitter='best'), X=array([[ 1.6922528 ,  1.1609141 ],
       [ 0.91...      [-0.93991226, -0.4838963 ]], dtype=float32), y=array([[0.],
       [0.],
       [0.],
       [0...    [1.],
       [1.],
       [1.],
       [1.]]), sample_weight=array([4., 5., 1., 1., 2., 1., 1., 1., 2., 1., 0..., 3., 2., 2., 1.,
       0., 3., 0., 0., 2., 2.]), check_input=False, X_idx_sorted=None)
    237         if not 0 <= self.min_weight_fraction_leaf <= 0.5:
    238             raise ValueError("min_weight_fraction_leaf must in [0, 0.5]")
    239         if max_depth <= 0:
    240             raise ValueError("max_depth must be greater than zero. ")
    241         if not (0 < max_features <= self.n_features_):
--> 242             raise ValueError("max_features must be in (0, n_features]")
    243         if not isinstance(max_leaf_nodes, (numbers.Integral, np.integer)):
    244             raise ValueError("max_leaf_nodes must be integral number but was "
    245                              "%r" % max_leaf_nodes)
    246         if -1 < max_leaf_nodes < 2:

ValueError: max_features must be in (0, n_features]
___________________________________________________________________________
Best score: 0.945635640826 (0.040053650786) [J] | Score: 0.0 (0.0) [J]
Best score: 0.950776726299 (0.0283281089257) [J] | Score: 0.950776726299 (0.0283281089257) [J]
JoblibValueError
___________________________________________________________________________
...........................................................................
/home/aquemy/dev/dp_hyperparameters/extension/main.py in <module>()
     27 
     28     serializer.serialize_results(scenario, policy)
     29 
     30 if __name__ == "__main__":
     31     args = cli.parse_args()
---> 32     main(args)

...........................................................................
/home/aquemy/dev/dp_hyperparameters/extension/main.py in main(args=Namespace(customize=[(['control', 'seed'], '42')...='./scenarios/rf_breast_joint.yaml', verbosity=0))
     21         test_size=0.4, 
     22         random_state=scenario['control']['seed']
     23     )
     24 
     25     policy = policies.initiate(scenario['setup']['policy'], config)
---> 26     policy.run(X,y)
        policy.run = <bound method Joint.run of <experiment.policies.joint.Joint object>>
        X = array([[1.799e+01, 1.038e+01, 1.228e+02, ..., 2...., ..., 0.000e+00, 2.871e-01,
        7.039e-02]])
        y = array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,... 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1])
     27 
     28     serializer.serialize_results(scenario, policy)
     29 
     30 if __name__ == "__main__":

...........................................................................
/home/aquemy/dev/dp_hyperparameters/extension/experiment/policies/joint.py in run(self=<experiment.policies.joint.Joint object>, X=array([[1.799e+01, 1.038e+01, 1.228e+02, ..., 2...., ..., 0.000e+00, 2.871e-01,
        7.039e-02]]), y=array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,... 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1]))
     32             algo=tpe.suggest, 
     33             max_evals=None,
     34             max_time=self.config['time'],     
     35             trials=trials,
     36             show_progressbar=False,
---> 37             verbose=0
     38         )
     39 
     40         best_config = self.context['best_config']
     41         super(Joint, self).display_step_results(best_config)

...........................................................................
/home/aquemy/dev/dp_hyperparameters/extension/hyperopt/fmin.py in fmin(fn=<functools.partial object>, space={'algorithm': {'bootstrap': <hyperopt.pyll.base.Apply object>, 'criterion': <hyperopt.pyll.base.Apply object>, 'max_depth': <hyperopt.pyll.base.Apply object>, 'max_features': <hyperopt.pyll.base.Apply object>, 'max_leaf_nodes': <hyperopt.pyll.base.Apply object>, 'min_samples_split': <hyperopt.pyll.base.Apply object>, 'n_estimators': <hyperopt.pyll.base.Apply object>}, 'pipeline': {'features': <hyperopt.pyll.base.Apply object>, 'normalizer': <hyperopt.pyll.base.Apply object>, 'rebalance': <hyperopt.pyll.base.Apply object>}}, algo=<function suggest>, max_evals=9223372036854775807, max_time=300, trials=<hyperopt.base.Trials object>, rstate=<mtrand.RandomState object>, allow_trials_fmin=True, pass_expr_memo_ctrl=None, catch_eval_exceptions=False, verbose=0, return_argmin=True, points_to_evaluate=None, max_queue_len=1, show_progressbar=False)
    406             pass_expr_memo_ctrl=pass_expr_memo_ctrl,
    407             verbose=verbose,
    408             catch_eval_exceptions=catch_eval_exceptions,
    409             return_argmin=return_argmin,
    410             show_progressbar=show_progressbar,
--> 411             max_time=max_time
        max_time = 300
    412         )
    413 
    414     if trials is None:
    415         if points_to_evaluate is None:

...........................................................................
/home/aquemy/dev/dp_hyperparameters/extension/hyperopt/base.py in fmin(self=<hyperopt.base.Trials object>, fn=<functools.partial object>, space={'algorithm': {'bootstrap': <hyperopt.pyll.base.Apply object>, 'criterion': <hyperopt.pyll.base.Apply object>, 'max_depth': <hyperopt.pyll.base.Apply object>, 'max_features': <hyperopt.pyll.base.Apply object>, 'max_leaf_nodes': <hyperopt.pyll.base.Apply object>, 'min_samples_split': <hyperopt.pyll.base.Apply object>, 'n_estimators': <hyperopt.pyll.base.Apply object>}, 'pipeline': {'features': <hyperopt.pyll.base.Apply object>, 'normalizer': <hyperopt.pyll.base.Apply object>, 'rebalance': <hyperopt.pyll.base.Apply object>}}, algo=<function suggest>, max_evals=9223372036854775807, max_time=300, rstate=<mtrand.RandomState object>, verbose=0, pass_expr_memo_ctrl=None, catch_eval_exceptions=False, return_argmin=True, show_progressbar=False)
    636             verbose=verbose,
    637             allow_trials_fmin=False,  # -- prevent recursion
    638             pass_expr_memo_ctrl=pass_expr_memo_ctrl,
    639             catch_eval_exceptions=catch_eval_exceptions,
    640             return_argmin=return_argmin,
--> 641             show_progressbar=show_progressbar)
        show_progressbar = False
    642 
    643 
    644 def trials_from_docs(docs, validate=True, **kwargs):
    645     """Construct a Trials base class instance from a list of trials documents

...........................................................................
/home/aquemy/dev/dp_hyperparameters/extension/hyperopt/fmin.py in fmin(fn=<functools.partial object>, space={'algorithm': {'bootstrap': <hyperopt.pyll.base.Apply object>, 'criterion': <hyperopt.pyll.base.Apply object>, 'max_depth': <hyperopt.pyll.base.Apply object>, 'max_features': <hyperopt.pyll.base.Apply object>, 'max_leaf_nodes': <hyperopt.pyll.base.Apply object>, 'min_samples_split': <hyperopt.pyll.base.Apply object>, 'n_estimators': <hyperopt.pyll.base.Apply object>}, 'pipeline': {'features': <hyperopt.pyll.base.Apply object>, 'normalizer': <hyperopt.pyll.base.Apply object>, 'rebalance': <hyperopt.pyll.base.Apply object>}}, algo=<function suggest>, max_evals=9223372036854775807, max_time=300, trials=<hyperopt.base.Trials object>, rstate=<mtrand.RandomState object>, allow_trials_fmin=False, pass_expr_memo_ctrl=None, catch_eval_exceptions=False, verbose=0, return_argmin=True, points_to_evaluate=None, max_queue_len=1, show_progressbar=False)
    426                     verbose=verbose,
    427                     max_queue_len=max_queue_len,
    428                     show_progressbar=show_progressbar,
    429                     max_time=max_time)
    430     rval.catch_eval_exceptions = catch_eval_exceptions
--> 431     rval.exhaust()
        rval.exhaust = <bound method FMinIter.exhaust of <hyperopt.fmin.FMinIter object>>
    432     if return_argmin:
    433         return trials.argmin
    434     elif len(trials) > 0:
    435         # Only if there are some succesfull trail runs, return the best point in the evaluation space

...........................................................................
/home/aquemy/dev/dp_hyperparameters/extension/hyperopt/fmin.py in exhaust(self=<hyperopt.fmin.FMinIter object>)
    273             raise StopIteration()
    274         return self.trials
    275 
    276     def exhaust(self):
    277         n_done = len(self.trials)
--> 278         self.run(self.max_evals - n_done, block_until_done=self.asynchronous)
        self.run = <bound method FMinIter.run of <hyperopt.fmin.FMinIter object>>
        self.max_evals = 9223372036854775807
        n_done = 0
        self.asynchronous = False
    279         self.trials.refresh()
    280         return self
    281 
    282 

...........................................................................
/home/aquemy/dev/dp_hyperparameters/extension/hyperopt/fmin.py in run(self=<hyperopt.fmin.FMinIter object>, N=9223372036854775807, block_until_done=False)
    232                     if self.asynchronous:
    233                         # -- wait for workers to fill in the trials
    234                         time.sleep(self.poll_interval_secs)
    235                     else:
    236                         # -- loop over trials and do the jobs directly
--> 237                         self.serial_evaluate()
        self.serial_evaluate = <bound method FMinIter.serial_evaluate of <hyperopt.fmin.FMinIter object>>
    238                     try:
    239                         res = [d['result']['loss'] for d in
    240                                          self.trials.trials if
    241                                          d['result']['status'] == 'ok']

...........................................................................
/home/aquemy/dev/dp_hyperparameters/extension/hyperopt/fmin.py in serial_evaluate(self=<hyperopt.fmin.FMinIter object>, N=-1)
    138                 trial['book_time'] = now
    139                 trial['refresh_time'] = now
    140                 spec = base.spec_from_misc(trial['misc'])
    141                 ctrl = base.Ctrl(self.trials, current_trial=trial)
    142                 try:
--> 143                     result = self.domain.evaluate(spec, ctrl)
        result = undefined
        self.domain.evaluate = <bound method Domain.evaluate of <hyperopt.base.Domain object>>
        spec = {'bootstrap': 1, 'criterion': 0, 'features': 1, 'features_PCA_features__n_components': 1, 'max_depth': 0, 'max_features': 2, 'max_leaf_nodes': 3, 'min_samples_split': 0, 'n_estimators': 2, 'normalizer': 4, ...}
        ctrl = <hyperopt.base.Ctrl object>
    144                 except Exception as e:
    145                     logger.info('job exception: %s' % str(e))
    146                     trial['state'] = base.JOB_STATE_ERROR
    147                     trial['misc']['error'] = (str(type(e)), str(e))

...........................................................................
/home/aquemy/dev/dp_hyperparameters/extension/hyperopt/base.py in evaluate(self=<hyperopt.base.Domain object>, config={'bootstrap': 1, 'criterion': 0, 'features': 1, 'features_PCA_features__n_components': 1, 'max_depth': 0, 'max_features': 2, 'max_leaf_nodes': 3, 'min_samples_split': 0, 'n_estimators': 2, 'normalizer': 4, ...}, ctrl=<hyperopt.base.Ctrl object>, attach_attachments=True)
    841             #    or the normal Python part (self.fn)
    842             pyll_rval = pyll.rec_eval(
    843                 self.expr,
    844                 memo=memo,
    845                 print_node_on_error=self.rec_eval_print_node_on_error)
--> 846             rval = self.fn(pyll_rval)
        rval = undefined
        self.fn = <functools.partial object>
        pyll_rval = {'algorithm': {'bootstrap': False, 'criterion': 'gini', 'max_depth': 1, 'max_features': 3, 'max_leaf_nodes': None, 'min_samples_split': 2, 'n_estimators': 50}, 'pipeline': {'features': ('features_PCA', {'features__n_components': 2}), 'normalizer': ('normalizer_RobustScaler', {'normalizer__quantile_range': (5.0, 95.0), 'normalizer__with_centering': False, 'normalizer__with_scaling': True}), 'rebalance': ('rebalance_NearMiss', {'rebalance__n_neighbors': 2})}}
    847 
    848         if isinstance(rval, (float, int, np.number)):
    849             dict_rval = {'loss': float(rval), 'status': STATUS_OK}
    850         else:

...........................................................................
/home/aquemy/dev/dp_hyperparameters/extension/experiment/objective.py in objective_joint(wconfig={'algorithm': {'bootstrap': False, 'criterion': 'gini', 'max_depth': 1, 'max_features': 3, 'max_leaf_nodes': None, 'min_samples_split': 2, 'n_estimators': 50}, 'pipeline': {'features': ('features_PCA', {'features__n_components': 2}), 'normalizer': ('normalizer_RobustScaler', {'normalizer__quantile_range': (5.0, 95.0), 'normalizer__with_centering': False, 'normalizer__with_scaling': True}), 'rebalance': ('rebalance_NearMiss', {'rebalance__n_neighbors': 2})}}, algorithm='RandomForest', X=array([[1.799e+01, 1.038e+01, 1.228e+02, ..., 2...., ..., 0.000e+00, 2.871e-01,
        7.039e-02]]), y=array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,... 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1]), context={'baseline_score': 0.9545944602886527, 'baseline_score_std': 0.03716322883281839, 'best_config': {'algorithm': {'bootstrap': False, 'criterion': 'entropy', 'max_depth': None, 'max_features': 3, 'max_leaf_nodes': None, 'min_samples_split': 5, 'n_estimators': 10}, 'config_hash': {'algorithm': 'def83e48be05ef92a37e1a90585820f2f67ff42b', 'config': '95902552cb76e9798f0fa58782bd72bd1cc272d7', 'pipeline': '1775187bf23f94f4fd0cc1e5c1ef665210edded5'}, 'duration': 2.0033559799194336, 'iteration': 18, 'loss': 0.04922327370149515, 'max_history_score': 0.9507767262985048, 'max_history_score_std': 0.028328108925705902, 'max_history_step': 'joint', 'pipeline': {'features': ('features_PCA', {'features__n_components': 4}), 'normalizer': ('normalizer_StandardScaler', {'normalizer__with_mean': True, 'normalizer__with_std': True}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 5})}, 'score': 0.9507767262985048, ...}, 'history': [{'algorithm': {'bootstrap': True, 'criterion': 'entropy', 'max_depth': 4, 'max_features': 3, 'max_leaf_nodes': 3, 'min_samples_split': 2, 'n_estimators': 10}, 'config_hash': {'algorithm': '42527c4120073c2a488d1b8df28732f486d1578c', 'config': '51144ca42f9ea5ab2d8d58606e3b3e4d89c6d7b3', 'pipeline': '52f07bda29f9d3a95fabb87e591d0b2581ca8209'}, 'duration': 0.26703310012817383, 'iteration': 0, 'loss': 0.06655431682654922, 'max_history_score': 0.9334456831734508, 'max_history_score_std': 0.03819399139659311, 'max_history_step': 'joint', 'pipeline': {'features': ('features_NoneType', {}), 'normalizer': ('normalizer_RobustScaler', {'normalizer__quantile_range': (...), 'normalizer__with_centering': False, 'normalizer__with_scaling': False}), 'rebalance': ('rebalance_NearMiss', {'rebalance__n_neighbors': 1})}, 'score': 0.9334456831734508, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': None, 'max_features': 2, 'max_leaf_nodes': 3, 'min_samples_split': 2, 'n_estimators': 100}, 'config_hash': {'algorithm': '1b32258c630f07e01ab481ab925ab80aa757e482', 'config': '9e54ffcb6a727de032a0a2cd45c5cc37cc150756', 'pipeline': '37e72d4a97f5e784c9d3133e6379b91bfc3be803'}, 'duration': 1.3065669536590576, 'iteration': 1, 'loss': 0.05436435917379645, 'max_history_score': 0.9456356408262035, 'max_history_score_std': 0.040053650785990214, 'max_history_step': 'joint', 'pipeline': {'features': ('features_NoneType', {}), 'normalizer': ('normalizer_StandardScaler', {'normalizer__with_mean': True, 'normalizer__with_std': True}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 6})}, 'score': 0.9456356408262035, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'entropy', 'max_depth': 1, 'max_features': 1, 'max_leaf_nodes': 2, 'min_samples_split': 3, 'n_estimators': 25}, 'config_hash': {'algorithm': '68ab9059aa7ec74e0da87c81734b9664243b3eb4', 'config': 'e5241eee9ddf3f4ee29a4711f5bcc92a4d24cd09', 'pipeline': '62463de065924498cdcd2f2f1f7e68535cdb33a5'}, 'duration': 0.6592490673065186, 'iteration': 2, 'loss': 0.07695856019358727, 'max_history_score': 0.9456356408262035, 'max_history_score_std': 0.040053650785990214, 'max_history_step': 'joint', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 1, 'features__selectkbest__k': 2}), 'normalizer': ('normalizer_NoneType', {}), 'rebalance': ('rebalance_NoneType', {})}, 'score': 0.9230414398064127, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': 3, 'max_features': 2, 'max_leaf_nodes': 2, 'min_samples_split': 2, 'n_estimators': 25}, 'config_hash': {'algorithm': 'e3f1f7d7783557a38f40f0476369091edd87092b', 'config': '18ee4d3d1627472ec190326308d8755371a6dc62', 'pipeline': 'c6d1263e344ed8c71b2e6e4ba8e0db2fb6c777c0'}, 'duration': 0.879349946975708, 'iteration': 3, 'loss': 0.07535973554576114, 'max_history_score': 0.9456356408262035, 'max_history_score_std': 0.040053650785990214, 'max_history_step': 'joint', 'pipeline': {'features': ('features_NoneType', {}), 'normalizer': ('normalizer_RobustScaler', {'normalizer__quantile_range': (...), 'normalizer__with_centering': True, 'normalizer__with_scaling': True}), 'rebalance': ('rebalance_NearMiss', {'rebalance__n_neighbors': 2})}, 'score': 0.9246402644542389, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'gini', 'max_depth': 4, 'max_features': 2, 'max_leaf_nodes': 5, 'min_samples_split': 2, 'n_estimators': 50}, 'config_hash': {'algorithm': '47581af7253940f9647ad16d37347d34baf13e5f', 'config': '2af4f82b045c0c48ecb89d42728d1039fbff8878', 'pipeline': '2928b22ed834303cb7bac6e6608531eaddd7df67'}, 'duration': 4.372632026672363, 'iteration': 4, 'loss': 0.09121294615849984, 'max_history_score': 0.9456356408262035, 'max_history_score_std': 0.040053650785990214, 'max_history_step': 'joint', 'pipeline': {'features': ('features_NoneType', {}), 'normalizer': ('normalizer_MinMaxScaler', {}), 'rebalance': ('rebalance_CondensedNearestNeighbour', {'rebalance__n_neighbors': 2})}, 'score': 0.9087870538415002, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'entropy', 'max_depth': 2, 'max_features': 2, 'max_leaf_nodes': None, 'min_samples_split': 2, 'n_estimators': 10}, 'config_hash': {'algorithm': '0a85f98ca2d06103287f153633d88f7a0535e7e8', 'config': '17b2a1e5814f3e933137158708a5b6e9b2475495', 'pipeline': '95defa3bdd8357f11f872d3c280d50a6d8ee398d'}, 'duration': 2.625814914703369, 'iteration': 5, 'loss': 0.15471329185031535, 'max_history_score': 0.9456356408262035, 'max_history_score_std': 0.040053650785990214, 'max_history_step': 'joint', 'pipeline': {'features': ('features_SelectKBest', {'features__k': 2}), 'normalizer': ('normalizer_StandardScaler', {'normalizer__with_mean': False, 'normalizer__with_std': False}), 'rebalance': ('rebalance_CondensedNearestNeighbour', {'rebalance__n_neighbors': 1})}, 'score': 0.8452867081496847, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': 3, 'max_features': None, 'max_leaf_nodes': None, 'min_samples_split': 5, 'n_estimators': 75}, 'config_hash': {'algorithm': 'd7466a2c1d5cb3fa95029d73dc030f4c3c45a159', 'config': 'fa020a592ec5ac234f9f91aac28abc2cd1ec9d33', 'pipeline': '71e0d26f923d42cfe0e2fa748931ef2afe72ed86'}, 'duration': 3.62078595161438, 'iteration': 6, 'loss': 0.17066372828623277, 'max_history_score': 0.9456356408262035, 'max_history_score_std': 0.040053650785990214, 'max_history_step': 'joint', 'pipeline': {'features': ('features_SelectKBest', {'features__k': 1}), 'normalizer': ('normalizer_RobustScaler', {'normalizer__quantile_range': (...), 'normalizer__with_centering': True, 'normalizer__with_scaling': True}), 'rebalance': ('rebalance_CondensedNearestNeighbour', {'rebalance__n_neighbors': 1})}, 'score': 0.8293362717137672, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'entropy', 'max_depth': 3, 'max_features': 3, 'max_leaf_nodes': 5, 'min_samples_split': 5, 'n_estimators': 50}, 'config_hash': {'algorithm': '735caa9785596076014572a24050cde8dc338973', 'config': '0da4498002d6f452c59bb61756abb3ded841e786', 'pipeline': '51a53ea6ef5a2521ee65f76eb2da220ab7086513'}, 'duration': 0.6934049129486084, 'iteration': 7, 'loss': 0.06125875032408601, 'max_history_score': 0.9456356408262035, 'max_history_score_std': 0.040053650785990214, 'max_history_step': 'joint', 'pipeline': {'features': ('features_NoneType', {}), 'normalizer': ('normalizer_NoneType', {}), 'rebalance': ('rebalance_NearMiss', {'rebalance__n_neighbors': 3})}, 'score': 0.938741249675914, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': 4, 'max_features': 2, 'max_leaf_nodes': None, 'min_samples_split': 3, 'n_estimators': 75}, 'config_hash': {'algorithm': 'e71a1fe9515b6805f07914a61f2e7594be9e9afe', 'config': '344e4756fb1bec455d6af51d3727e33b0d27725f', 'pipeline': '248dad1d8b30a17a5de1d0bbdfe3e2acb7a1962b'}, 'duration': 1.3036692142486572, 'iteration': 8, 'loss': 0.06483125918243893, 'max_history_score': 0.9456356408262035, 'max_history_score_std': 0.040053650785990214, 'max_history_step': 'joint', 'pipeline': {'features': ('features_PCA', {'features__n_components': 2}), 'normalizer': ('normalizer_StandardScaler', {'normalizer__with_mean': False, 'normalizer__with_std': True}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 7})}, 'score': 0.9351687408175611, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'entropy', 'max_depth': 2, 'max_features': 2, 'max_leaf_nodes': 2, 'min_samples_split': 3, 'n_estimators': 10}, 'config_hash': {'algorithm': '0a507823f2ad8605ed5950e1fe61df0560f11a00', 'config': '4a538fdcf8e07f90e92a421c0d5c479d651629c7', 'pipeline': '5240329df25c9a533d025c1a401d49835a501b41'}, 'duration': 1.3821029663085938, 'iteration': 9, 'loss': 0.07006416904329793, 'max_history_score': 0.9456356408262035, 'max_history_score_std': 0.040053650785990214, 'max_history_step': 'joint', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 4, 'features__selectkbest__k': 2}), 'normalizer': ('normalizer_PowerTransformer', {}), 'rebalance': ('rebalance_NearMiss', {'rebalance__n_neighbors': 1})}, 'score': 0.9299358309567021, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'gini', 'max_depth': 1, 'max_features': 3, 'max_leaf_nodes': 5, 'min_samples_split': 3, 'n_estimators': 10}, 'config_hash': {'algorithm': 'd32739750d351948f8ff34a87c7d55b0c5e0d90f', 'config': 'c1609e71f1ce8486335adc70bb69a955580ba2c8', 'pipeline': 'f48b42ec5cf999279659966160a16353b75bdaa3'}, 'duration': 0.9055681228637695, 'iteration': 10, 'loss': 0.07532840722495904, 'max_history_score': 0.9456356408262035, 'max_history_score_std': 0.040053650785990214, 'max_history_step': 'joint', 'pipeline': {'features': ('features_PCA', {'features__n_components': 4}), 'normalizer': ('normalizer_PowerTransformer', {}), 'rebalance': ('rebalance_NearMiss', {'rebalance__n_neighbors': 1})}, 'score': 0.924671592775041, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': 3, 'max_features': 1, 'max_leaf_nodes': 5, 'min_samples_split': 3, 'n_estimators': 25}, 'config_hash': {'algorithm': 'f69bac35e71cbec1bfc1fb5942328a3390e7c252', 'config': 'abe36f188644e53e56ed3224236fa157107ed3b2', 'pipeline': 'aaf976c7c663a31fa039582d42f9e07101556a7c'}, 'duration': 0.764197826385498, 'iteration': 11, 'loss': 0.06818446979517778, 'max_history_score': 0.9456356408262035, 'max_history_score_std': 0.040053650785990214, 'max_history_step': 'joint', 'pipeline': {'features': ('features_NoneType', {}), 'normalizer': ('normalizer_PowerTransformer', {}), 'rebalance': ('rebalance_NoneType', {})}, 'score': 0.9318155302048222, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'entropy', 'max_depth': None, 'max_features': None, 'max_leaf_nodes': None, 'min_samples_split': 5, 'n_estimators': 25}, 'config_hash': {'algorithm': 'a0a27aec00db5ddf71eab96663f9bd61c845f5e3', 'config': '76aa002c3c9d4d9722466c60daf5119c18a41d2a', 'pipeline': '1ce34b7894ef342571d974bb19e8ec821a512c6b'}, 'duration': 1.1636500358581543, 'iteration': 12, 'loss': 0.12833700630887557, 'max_history_score': 0.9456356408262035, 'max_history_score_std': 0.040053650785990214, 'max_history_step': 'joint', 'pipeline': {'features': ('features_PCA', {'features__n_components': 1}), 'normalizer': ('normalizer_PowerTransformer', {}), 'rebalance': ('rebalance_NoneType', {})}, 'score': 0.8716629936911244, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'gini', 'max_depth': 1, 'max_features': 2, 'max_leaf_nodes': 2, 'min_samples_split': 2, 'n_estimators': 100}, 'config_hash': {'algorithm': '985c99dff1da9b2c87e4211c5335a9159aa9dbcb', 'config': 'f56a7a9e43a0a699e992dc1262e550b8b7c88538', 'pipeline': '5c934f6d9a8ad1f9afe762986a9cf2074fc95d79'}, 'duration': 2.235443115234375, 'iteration': 13, 'loss': 0.11414635727249167, 'max_history_score': 0.9456356408262035, 'max_history_score_std': 0.040053650785990214, 'max_history_step': 'joint', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 1, 'features__selectkbest__k': 1}), 'normalizer': ('normalizer_RobustScaler', {'normalizer__quantile_range': (...), 'normalizer__with_centering': False, 'normalizer__with_scaling': True}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 6})}, 'score': 0.8858536427275083, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'gini', 'max_depth': 1, 'max_features': 1, 'max_leaf_nodes': None, 'min_samples_split': 5, 'n_estimators': 10}, 'config_hash': {'algorithm': '7d74a39aac2579264a402aef2b6fa7943c19f3d3', 'config': '53f44c0ad925c5c08c25d4fadf5e9ee9d7c181cd', 'pipeline': '6eff5ef31d7d1d534db31913bb67529c8a24c42e'}, 'duration': 2.7847659587860107, 'iteration': 14, 'loss': 0.14061986863711007, 'max_history_score': 0.9456356408262035, 'max_history_score_std': 0.040053650785990214, 'max_history_step': 'joint', 'pipeline': {'features': ('features_PCA', {'features__n_components': 1}), 'normalizer': ('normalizer_RobustScaler', {'normalizer__quantile_range': (...), 'normalizer__with_centering': True, 'normalizer__with_scaling': True}), 'rebalance': ('rebalance_CondensedNearestNeighbour', {'rebalance__n_neighbors': 3})}, 'score': 0.8593801313628899, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'entropy', 'max_depth': 3, 'max_features': None, 'max_leaf_nodes': 5, 'min_samples_split': 2, 'n_estimators': 100}, 'config_hash': {'algorithm': 'c62d7c671832e4414b6b2d7c36cba5ddc83a0ed0', 'config': '5faee50671eaa0ac586722bff234e36a857e662d', 'pipeline': '8b29a55de2add78c49114b9bbe5e800e5524c59d'}, 'duration': 2.3916029930114746, 'iteration': 15, 'loss': 0.08770093336790252, 'max_history_score': 0.9456356408262035, 'max_history_score_std': 0.040053650785990214, 'max_history_step': 'joint', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 3, 'features__selectkbest__k': 4}), 'normalizer': ('normalizer_RobustScaler', {'normalizer__quantile_range': (...), 'normalizer__with_centering': True, 'normalizer__with_scaling': True}), 'rebalance': ('rebalance_NoneType', {})}, 'score': 0.9122990666320975, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': None, 'max_features': 1, 'max_leaf_nodes': 5, 'min_samples_split': 5, 'n_estimators': 10}, 'config_hash': {'algorithm': '290772bfb9b8ed15c48a72829e822fb0a07481d6', 'config': '9a04f25d8eb3db5b2f831abd341a6d384c73a957', 'pipeline': '1ce34b7894ef342571d974bb19e8ec821a512c6b'}, 'duration': 1.4364500045776367, 'iteration': 16, 'loss': 0.08948880822746508, 'max_history_score': 0.9456356408262035, 'max_history_score_std': 0.040053650785990214, 'max_history_step': 'joint', 'pipeline': {'features': ('features_PCA', {'features__n_components': 1}), 'normalizer': ('normalizer_PowerTransformer', {}), 'rebalance': ('rebalance_NoneType', {})}, 'score': 0.9105111917725349, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': 2, 'max_features': 3, 'max_leaf_nodes': 3, 'min_samples_split': 3, 'n_estimators': 100}, 'config_hash': {'algorithm': '7dab6d47f897c2961d3402eff844aff16a7d142a', 'config': '4dbfa2688b239be9f372d3e80223960ba9a1fbdd', 'pipeline': 'cdef51702798fa49f11c11d80baf3ab43d5358fc'}, 'duration': 0.9830451011657715, 'iteration': 17, 'loss': 1.0, 'max_history_score': 0.9456356408262035, 'max_history_score_std': 0.040053650785990214, 'max_history_step': 'joint', 'pipeline': {'features': ('features_SelectKBest', {'features__k': 2}), 'normalizer': ('normalizer_PowerTransformer', {}), 'rebalance': ('rebalance_NearMiss', {'rebalance__n_neighbors': 1})}, 'score': 0.0, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'entropy', 'max_depth': None, 'max_features': 3, 'max_leaf_nodes': None, 'min_samples_split': 5, 'n_estimators': 10}, 'config_hash': {'algorithm': 'def83e48be05ef92a37e1a90585820f2f67ff42b', 'config': '95902552cb76e9798f0fa58782bd72bd1cc272d7', 'pipeline': '1775187bf23f94f4fd0cc1e5c1ef665210edded5'}, 'duration': 2.0033559799194336, 'iteration': 18, 'loss': 0.04922327370149515, 'max_history_score': 0.9507767262985048, 'max_history_score_std': 0.028328108925705902, 'max_history_step': 'joint', 'pipeline': {'features': ('features_PCA', {'features__n_components': 4}), 'normalizer': ('normalizer_StandardScaler', {'normalizer__with_mean': True, 'normalizer__with_std': True}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 5})}, 'score': 0.9507767262985048, ...}], 'history_hash': ['51144ca42f9ea5ab2d8d58606e3b3e4d89c6d7b3', '9e54ffcb6a727de032a0a2cd45c5cc37cc150756', 'e5241eee9ddf3f4ee29a4711f5bcc92a4d24cd09', '18ee4d3d1627472ec190326308d8755371a6dc62', '2af4f82b045c0c48ecb89d42728d1039fbff8878', '17b2a1e5814f3e933137158708a5b6e9b2475495', 'fa020a592ec5ac234f9f91aac28abc2cd1ec9d33', '0da4498002d6f452c59bb61756abb3ded841e786', '344e4756fb1bec455d6af51d3727e33b0d27725f', '4a538fdcf8e07f90e92a421c0d5c479d651629c7', 'c1609e71f1ce8486335adc70bb69a955580ba2c8', 'abe36f188644e53e56ed3224236fa157107ed3b2', '76aa002c3c9d4d9722466c60daf5119c18a41d2a', 'f56a7a9e43a0a699e992dc1262e550b8b7c88538', '53f44c0ad925c5c08c25d4fadf5e9ee9d7c181cd', '5faee50671eaa0ac586722bff234e36a857e662d', '9a04f25d8eb3db5b2f831abd341a6d384c73a957', '4dbfa2688b239be9f372d3e80223960ba9a1fbdd', '95902552cb76e9798f0fa58782bd72bd1cc272d7'], 'history_index': {'0da4498002d6f452c59bb61756abb3ded841e786': 7, '17b2a1e5814f3e933137158708a5b6e9b2475495': 5, '18ee4d3d1627472ec190326308d8755371a6dc62': 3, '2af4f82b045c0c48ecb89d42728d1039fbff8878': 4, '344e4756fb1bec455d6af51d3727e33b0d27725f': 8, '4a538fdcf8e07f90e92a421c0d5c479d651629c7': 9, '4dbfa2688b239be9f372d3e80223960ba9a1fbdd': 17, '51144ca42f9ea5ab2d8d58606e3b3e4d89c6d7b3': 0, '53f44c0ad925c5c08c25d4fadf5e9ee9d7c181cd': 14, '5faee50671eaa0ac586722bff234e36a857e662d': 15, ...}, 'iteration': 18, 'max_history_score': 0.9507767262985048, 'max_history_score_std': 0.028328108925705902, 'max_history_step': 'joint'}, config={'algorithm': 'RandomForest', 'seed': 42, 'time': 300})
    108 
    109 def objective_algo(algo_config, current_pipeline_config, algorithm, X, y, context, config):
    110     return objective(current_pipeline_config, algo_config, algorithm, X, y, context, config, step='algorithm')
    111 
    112 def objective_joint(wconfig, algorithm, X, y, context, config):
--> 113     return objective(wconfig['pipeline'], wconfig['algorithm'], algorithm, X, y, context, config, step='joint')
        wconfig = {'algorithm': {'bootstrap': False, 'criterion': 'gini', 'max_depth': 1, 'max_features': 3, 'max_leaf_nodes': None, 'min_samples_split': 2, 'n_estimators': 50}, 'pipeline': {'features': ('features_PCA', {'features__n_components': 2}), 'normalizer': ('normalizer_RobustScaler', {'normalizer__quantile_range': (5.0, 95.0), 'normalizer__with_centering': False, 'normalizer__with_scaling': True}), 'rebalance': ('rebalance_NearMiss', {'rebalance__n_neighbors': 2})}}
        algorithm = 'RandomForest'
        X = array([[1.799e+01, 1.038e+01, 1.228e+02, ..., 2...., ..., 0.000e+00, 2.871e-01,
        7.039e-02]])
        y = array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,... 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1])
        context = {'baseline_score': 0.9545944602886527, 'baseline_score_std': 0.03716322883281839, 'best_config': {'algorithm': {'bootstrap': False, 'criterion': 'entropy', 'max_depth': None, 'max_features': 3, 'max_leaf_nodes': None, 'min_samples_split': 5, 'n_estimators': 10}, 'config_hash': {'algorithm': 'def83e48be05ef92a37e1a90585820f2f67ff42b', 'config': '95902552cb76e9798f0fa58782bd72bd1cc272d7', 'pipeline': '1775187bf23f94f4fd0cc1e5c1ef665210edded5'}, 'duration': 2.0033559799194336, 'iteration': 18, 'loss': 0.04922327370149515, 'max_history_score': 0.9507767262985048, 'max_history_score_std': 0.028328108925705902, 'max_history_step': 'joint', 'pipeline': {'features': ('features_PCA', {'features__n_components': 4}), 'normalizer': ('normalizer_StandardScaler', {'normalizer__with_mean': True, 'normalizer__with_std': True}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 5})}, 'score': 0.9507767262985048, ...}, 'history': [{'algorithm': {'bootstrap': True, 'criterion': 'entropy', 'max_depth': 4, 'max_features': 3, 'max_leaf_nodes': 3, 'min_samples_split': 2, 'n_estimators': 10}, 'config_hash': {'algorithm': '42527c4120073c2a488d1b8df28732f486d1578c', 'config': '51144ca42f9ea5ab2d8d58606e3b3e4d89c6d7b3', 'pipeline': '52f07bda29f9d3a95fabb87e591d0b2581ca8209'}, 'duration': 0.26703310012817383, 'iteration': 0, 'loss': 0.06655431682654922, 'max_history_score': 0.9334456831734508, 'max_history_score_std': 0.03819399139659311, 'max_history_step': 'joint', 'pipeline': {'features': ('features_NoneType', {}), 'normalizer': ('normalizer_RobustScaler', {'normalizer__quantile_range': (...), 'normalizer__with_centering': False, 'normalizer__with_scaling': False}), 'rebalance': ('rebalance_NearMiss', {'rebalance__n_neighbors': 1})}, 'score': 0.9334456831734508, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': None, 'max_features': 2, 'max_leaf_nodes': 3, 'min_samples_split': 2, 'n_estimators': 100}, 'config_hash': {'algorithm': '1b32258c630f07e01ab481ab925ab80aa757e482', 'config': '9e54ffcb6a727de032a0a2cd45c5cc37cc150756', 'pipeline': '37e72d4a97f5e784c9d3133e6379b91bfc3be803'}, 'duration': 1.3065669536590576, 'iteration': 1, 'loss': 0.05436435917379645, 'max_history_score': 0.9456356408262035, 'max_history_score_std': 0.040053650785990214, 'max_history_step': 'joint', 'pipeline': {'features': ('features_NoneType', {}), 'normalizer': ('normalizer_StandardScaler', {'normalizer__with_mean': True, 'normalizer__with_std': True}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 6})}, 'score': 0.9456356408262035, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'entropy', 'max_depth': 1, 'max_features': 1, 'max_leaf_nodes': 2, 'min_samples_split': 3, 'n_estimators': 25}, 'config_hash': {'algorithm': '68ab9059aa7ec74e0da87c81734b9664243b3eb4', 'config': 'e5241eee9ddf3f4ee29a4711f5bcc92a4d24cd09', 'pipeline': '62463de065924498cdcd2f2f1f7e68535cdb33a5'}, 'duration': 0.6592490673065186, 'iteration': 2, 'loss': 0.07695856019358727, 'max_history_score': 0.9456356408262035, 'max_history_score_std': 0.040053650785990214, 'max_history_step': 'joint', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 1, 'features__selectkbest__k': 2}), 'normalizer': ('normalizer_NoneType', {}), 'rebalance': ('rebalance_NoneType', {})}, 'score': 0.9230414398064127, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': 3, 'max_features': 2, 'max_leaf_nodes': 2, 'min_samples_split': 2, 'n_estimators': 25}, 'config_hash': {'algorithm': 'e3f1f7d7783557a38f40f0476369091edd87092b', 'config': '18ee4d3d1627472ec190326308d8755371a6dc62', 'pipeline': 'c6d1263e344ed8c71b2e6e4ba8e0db2fb6c777c0'}, 'duration': 0.879349946975708, 'iteration': 3, 'loss': 0.07535973554576114, 'max_history_score': 0.9456356408262035, 'max_history_score_std': 0.040053650785990214, 'max_history_step': 'joint', 'pipeline': {'features': ('features_NoneType', {}), 'normalizer': ('normalizer_RobustScaler', {'normalizer__quantile_range': (...), 'normalizer__with_centering': True, 'normalizer__with_scaling': True}), 'rebalance': ('rebalance_NearMiss', {'rebalance__n_neighbors': 2})}, 'score': 0.9246402644542389, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'gini', 'max_depth': 4, 'max_features': 2, 'max_leaf_nodes': 5, 'min_samples_split': 2, 'n_estimators': 50}, 'config_hash': {'algorithm': '47581af7253940f9647ad16d37347d34baf13e5f', 'config': '2af4f82b045c0c48ecb89d42728d1039fbff8878', 'pipeline': '2928b22ed834303cb7bac6e6608531eaddd7df67'}, 'duration': 4.372632026672363, 'iteration': 4, 'loss': 0.09121294615849984, 'max_history_score': 0.9456356408262035, 'max_history_score_std': 0.040053650785990214, 'max_history_step': 'joint', 'pipeline': {'features': ('features_NoneType', {}), 'normalizer': ('normalizer_MinMaxScaler', {}), 'rebalance': ('rebalance_CondensedNearestNeighbour', {'rebalance__n_neighbors': 2})}, 'score': 0.9087870538415002, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'entropy', 'max_depth': 2, 'max_features': 2, 'max_leaf_nodes': None, 'min_samples_split': 2, 'n_estimators': 10}, 'config_hash': {'algorithm': '0a85f98ca2d06103287f153633d88f7a0535e7e8', 'config': '17b2a1e5814f3e933137158708a5b6e9b2475495', 'pipeline': '95defa3bdd8357f11f872d3c280d50a6d8ee398d'}, 'duration': 2.625814914703369, 'iteration': 5, 'loss': 0.15471329185031535, 'max_history_score': 0.9456356408262035, 'max_history_score_std': 0.040053650785990214, 'max_history_step': 'joint', 'pipeline': {'features': ('features_SelectKBest', {'features__k': 2}), 'normalizer': ('normalizer_StandardScaler', {'normalizer__with_mean': False, 'normalizer__with_std': False}), 'rebalance': ('rebalance_CondensedNearestNeighbour', {'rebalance__n_neighbors': 1})}, 'score': 0.8452867081496847, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': 3, 'max_features': None, 'max_leaf_nodes': None, 'min_samples_split': 5, 'n_estimators': 75}, 'config_hash': {'algorithm': 'd7466a2c1d5cb3fa95029d73dc030f4c3c45a159', 'config': 'fa020a592ec5ac234f9f91aac28abc2cd1ec9d33', 'pipeline': '71e0d26f923d42cfe0e2fa748931ef2afe72ed86'}, 'duration': 3.62078595161438, 'iteration': 6, 'loss': 0.17066372828623277, 'max_history_score': 0.9456356408262035, 'max_history_score_std': 0.040053650785990214, 'max_history_step': 'joint', 'pipeline': {'features': ('features_SelectKBest', {'features__k': 1}), 'normalizer': ('normalizer_RobustScaler', {'normalizer__quantile_range': (...), 'normalizer__with_centering': True, 'normalizer__with_scaling': True}), 'rebalance': ('rebalance_CondensedNearestNeighbour', {'rebalance__n_neighbors': 1})}, 'score': 0.8293362717137672, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'entropy', 'max_depth': 3, 'max_features': 3, 'max_leaf_nodes': 5, 'min_samples_split': 5, 'n_estimators': 50}, 'config_hash': {'algorithm': '735caa9785596076014572a24050cde8dc338973', 'config': '0da4498002d6f452c59bb61756abb3ded841e786', 'pipeline': '51a53ea6ef5a2521ee65f76eb2da220ab7086513'}, 'duration': 0.6934049129486084, 'iteration': 7, 'loss': 0.06125875032408601, 'max_history_score': 0.9456356408262035, 'max_history_score_std': 0.040053650785990214, 'max_history_step': 'joint', 'pipeline': {'features': ('features_NoneType', {}), 'normalizer': ('normalizer_NoneType', {}), 'rebalance': ('rebalance_NearMiss', {'rebalance__n_neighbors': 3})}, 'score': 0.938741249675914, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': 4, 'max_features': 2, 'max_leaf_nodes': None, 'min_samples_split': 3, 'n_estimators': 75}, 'config_hash': {'algorithm': 'e71a1fe9515b6805f07914a61f2e7594be9e9afe', 'config': '344e4756fb1bec455d6af51d3727e33b0d27725f', 'pipeline': '248dad1d8b30a17a5de1d0bbdfe3e2acb7a1962b'}, 'duration': 1.3036692142486572, 'iteration': 8, 'loss': 0.06483125918243893, 'max_history_score': 0.9456356408262035, 'max_history_score_std': 0.040053650785990214, 'max_history_step': 'joint', 'pipeline': {'features': ('features_PCA', {'features__n_components': 2}), 'normalizer': ('normalizer_StandardScaler', {'normalizer__with_mean': False, 'normalizer__with_std': True}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 7})}, 'score': 0.9351687408175611, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'entropy', 'max_depth': 2, 'max_features': 2, 'max_leaf_nodes': 2, 'min_samples_split': 3, 'n_estimators': 10}, 'config_hash': {'algorithm': '0a507823f2ad8605ed5950e1fe61df0560f11a00', 'config': '4a538fdcf8e07f90e92a421c0d5c479d651629c7', 'pipeline': '5240329df25c9a533d025c1a401d49835a501b41'}, 'duration': 1.3821029663085938, 'iteration': 9, 'loss': 0.07006416904329793, 'max_history_score': 0.9456356408262035, 'max_history_score_std': 0.040053650785990214, 'max_history_step': 'joint', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 4, 'features__selectkbest__k': 2}), 'normalizer': ('normalizer_PowerTransformer', {}), 'rebalance': ('rebalance_NearMiss', {'rebalance__n_neighbors': 1})}, 'score': 0.9299358309567021, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'gini', 'max_depth': 1, 'max_features': 3, 'max_leaf_nodes': 5, 'min_samples_split': 3, 'n_estimators': 10}, 'config_hash': {'algorithm': 'd32739750d351948f8ff34a87c7d55b0c5e0d90f', 'config': 'c1609e71f1ce8486335adc70bb69a955580ba2c8', 'pipeline': 'f48b42ec5cf999279659966160a16353b75bdaa3'}, 'duration': 0.9055681228637695, 'iteration': 10, 'loss': 0.07532840722495904, 'max_history_score': 0.9456356408262035, 'max_history_score_std': 0.040053650785990214, 'max_history_step': 'joint', 'pipeline': {'features': ('features_PCA', {'features__n_components': 4}), 'normalizer': ('normalizer_PowerTransformer', {}), 'rebalance': ('rebalance_NearMiss', {'rebalance__n_neighbors': 1})}, 'score': 0.924671592775041, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': 3, 'max_features': 1, 'max_leaf_nodes': 5, 'min_samples_split': 3, 'n_estimators': 25}, 'config_hash': {'algorithm': 'f69bac35e71cbec1bfc1fb5942328a3390e7c252', 'config': 'abe36f188644e53e56ed3224236fa157107ed3b2', 'pipeline': 'aaf976c7c663a31fa039582d42f9e07101556a7c'}, 'duration': 0.764197826385498, 'iteration': 11, 'loss': 0.06818446979517778, 'max_history_score': 0.9456356408262035, 'max_history_score_std': 0.040053650785990214, 'max_history_step': 'joint', 'pipeline': {'features': ('features_NoneType', {}), 'normalizer': ('normalizer_PowerTransformer', {}), 'rebalance': ('rebalance_NoneType', {})}, 'score': 0.9318155302048222, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'entropy', 'max_depth': None, 'max_features': None, 'max_leaf_nodes': None, 'min_samples_split': 5, 'n_estimators': 25}, 'config_hash': {'algorithm': 'a0a27aec00db5ddf71eab96663f9bd61c845f5e3', 'config': '76aa002c3c9d4d9722466c60daf5119c18a41d2a', 'pipeline': '1ce34b7894ef342571d974bb19e8ec821a512c6b'}, 'duration': 1.1636500358581543, 'iteration': 12, 'loss': 0.12833700630887557, 'max_history_score': 0.9456356408262035, 'max_history_score_std': 0.040053650785990214, 'max_history_step': 'joint', 'pipeline': {'features': ('features_PCA', {'features__n_components': 1}), 'normalizer': ('normalizer_PowerTransformer', {}), 'rebalance': ('rebalance_NoneType', {})}, 'score': 0.8716629936911244, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'gini', 'max_depth': 1, 'max_features': 2, 'max_leaf_nodes': 2, 'min_samples_split': 2, 'n_estimators': 100}, 'config_hash': {'algorithm': '985c99dff1da9b2c87e4211c5335a9159aa9dbcb', 'config': 'f56a7a9e43a0a699e992dc1262e550b8b7c88538', 'pipeline': '5c934f6d9a8ad1f9afe762986a9cf2074fc95d79'}, 'duration': 2.235443115234375, 'iteration': 13, 'loss': 0.11414635727249167, 'max_history_score': 0.9456356408262035, 'max_history_score_std': 0.040053650785990214, 'max_history_step': 'joint', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 1, 'features__selectkbest__k': 1}), 'normalizer': ('normalizer_RobustScaler', {'normalizer__quantile_range': (...), 'normalizer__with_centering': False, 'normalizer__with_scaling': True}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 6})}, 'score': 0.8858536427275083, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'gini', 'max_depth': 1, 'max_features': 1, 'max_leaf_nodes': None, 'min_samples_split': 5, 'n_estimators': 10}, 'config_hash': {'algorithm': '7d74a39aac2579264a402aef2b6fa7943c19f3d3', 'config': '53f44c0ad925c5c08c25d4fadf5e9ee9d7c181cd', 'pipeline': '6eff5ef31d7d1d534db31913bb67529c8a24c42e'}, 'duration': 2.7847659587860107, 'iteration': 14, 'loss': 0.14061986863711007, 'max_history_score': 0.9456356408262035, 'max_history_score_std': 0.040053650785990214, 'max_history_step': 'joint', 'pipeline': {'features': ('features_PCA', {'features__n_components': 1}), 'normalizer': ('normalizer_RobustScaler', {'normalizer__quantile_range': (...), 'normalizer__with_centering': True, 'normalizer__with_scaling': True}), 'rebalance': ('rebalance_CondensedNearestNeighbour', {'rebalance__n_neighbors': 3})}, 'score': 0.8593801313628899, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'entropy', 'max_depth': 3, 'max_features': None, 'max_leaf_nodes': 5, 'min_samples_split': 2, 'n_estimators': 100}, 'config_hash': {'algorithm': 'c62d7c671832e4414b6b2d7c36cba5ddc83a0ed0', 'config': '5faee50671eaa0ac586722bff234e36a857e662d', 'pipeline': '8b29a55de2add78c49114b9bbe5e800e5524c59d'}, 'duration': 2.3916029930114746, 'iteration': 15, 'loss': 0.08770093336790252, 'max_history_score': 0.9456356408262035, 'max_history_score_std': 0.040053650785990214, 'max_history_step': 'joint', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 3, 'features__selectkbest__k': 4}), 'normalizer': ('normalizer_RobustScaler', {'normalizer__quantile_range': (...), 'normalizer__with_centering': True, 'normalizer__with_scaling': True}), 'rebalance': ('rebalance_NoneType', {})}, 'score': 0.9122990666320975, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': None, 'max_features': 1, 'max_leaf_nodes': 5, 'min_samples_split': 5, 'n_estimators': 10}, 'config_hash': {'algorithm': '290772bfb9b8ed15c48a72829e822fb0a07481d6', 'config': '9a04f25d8eb3db5b2f831abd341a6d384c73a957', 'pipeline': '1ce34b7894ef342571d974bb19e8ec821a512c6b'}, 'duration': 1.4364500045776367, 'iteration': 16, 'loss': 0.08948880822746508, 'max_history_score': 0.9456356408262035, 'max_history_score_std': 0.040053650785990214, 'max_history_step': 'joint', 'pipeline': {'features': ('features_PCA', {'features__n_components': 1}), 'normalizer': ('normalizer_PowerTransformer', {}), 'rebalance': ('rebalance_NoneType', {})}, 'score': 0.9105111917725349, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': 2, 'max_features': 3, 'max_leaf_nodes': 3, 'min_samples_split': 3, 'n_estimators': 100}, 'config_hash': {'algorithm': '7dab6d47f897c2961d3402eff844aff16a7d142a', 'config': '4dbfa2688b239be9f372d3e80223960ba9a1fbdd', 'pipeline': 'cdef51702798fa49f11c11d80baf3ab43d5358fc'}, 'duration': 0.9830451011657715, 'iteration': 17, 'loss': 1.0, 'max_history_score': 0.9456356408262035, 'max_history_score_std': 0.040053650785990214, 'max_history_step': 'joint', 'pipeline': {'features': ('features_SelectKBest', {'features__k': 2}), 'normalizer': ('normalizer_PowerTransformer', {}), 'rebalance': ('rebalance_NearMiss', {'rebalance__n_neighbors': 1})}, 'score': 0.0, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'entropy', 'max_depth': None, 'max_features': 3, 'max_leaf_nodes': None, 'min_samples_split': 5, 'n_estimators': 10}, 'config_hash': {'algorithm': 'def83e48be05ef92a37e1a90585820f2f67ff42b', 'config': '95902552cb76e9798f0fa58782bd72bd1cc272d7', 'pipeline': '1775187bf23f94f4fd0cc1e5c1ef665210edded5'}, 'duration': 2.0033559799194336, 'iteration': 18, 'loss': 0.04922327370149515, 'max_history_score': 0.9507767262985048, 'max_history_score_std': 0.028328108925705902, 'max_history_step': 'joint', 'pipeline': {'features': ('features_PCA', {'features__n_components': 4}), 'normalizer': ('normalizer_StandardScaler', {'normalizer__with_mean': True, 'normalizer__with_std': True}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 5})}, 'score': 0.9507767262985048, ...}], 'history_hash': ['51144ca42f9ea5ab2d8d58606e3b3e4d89c6d7b3', '9e54ffcb6a727de032a0a2cd45c5cc37cc150756', 'e5241eee9ddf3f4ee29a4711f5bcc92a4d24cd09', '18ee4d3d1627472ec190326308d8755371a6dc62', '2af4f82b045c0c48ecb89d42728d1039fbff8878', '17b2a1e5814f3e933137158708a5b6e9b2475495', 'fa020a592ec5ac234f9f91aac28abc2cd1ec9d33', '0da4498002d6f452c59bb61756abb3ded841e786', '344e4756fb1bec455d6af51d3727e33b0d27725f', '4a538fdcf8e07f90e92a421c0d5c479d651629c7', 'c1609e71f1ce8486335adc70bb69a955580ba2c8', 'abe36f188644e53e56ed3224236fa157107ed3b2', '76aa002c3c9d4d9722466c60daf5119c18a41d2a', 'f56a7a9e43a0a699e992dc1262e550b8b7c88538', '53f44c0ad925c5c08c25d4fadf5e9ee9d7c181cd', '5faee50671eaa0ac586722bff234e36a857e662d', '9a04f25d8eb3db5b2f831abd341a6d384c73a957', '4dbfa2688b239be9f372d3e80223960ba9a1fbdd', '95902552cb76e9798f0fa58782bd72bd1cc272d7'], 'history_index': {'0da4498002d6f452c59bb61756abb3ded841e786': 7, '17b2a1e5814f3e933137158708a5b6e9b2475495': 5, '18ee4d3d1627472ec190326308d8755371a6dc62': 3, '2af4f82b045c0c48ecb89d42728d1039fbff8878': 4, '344e4756fb1bec455d6af51d3727e33b0d27725f': 8, '4a538fdcf8e07f90e92a421c0d5c479d651629c7': 9, '4dbfa2688b239be9f372d3e80223960ba9a1fbdd': 17, '51144ca42f9ea5ab2d8d58606e3b3e4d89c6d7b3': 0, '53f44c0ad925c5c08c25d4fadf5e9ee9d7c181cd': 14, '5faee50671eaa0ac586722bff234e36a857e662d': 15, ...}, 'iteration': 18, 'max_history_score': 0.9507767262985048, 'max_history_score_std': 0.028328108925705902, 'max_history_step': 'joint'}
        config = {'algorithm': 'RandomForest', 'seed': 42, 'time': 300}
    114 
    115 
    116 def get_baseline_score(algorithm, X, y, seed):
    117     pipeline, _ = pipeline_conf_to_full_pipeline(

...........................................................................
/home/aquemy/dev/dp_hyperparameters/extension/experiment/objective.py in objective(pipeline_config={'features': ('features_PCA', {'features__n_components': 2}), 'normalizer': ('normalizer_RobustScaler', {'normalizer__quantile_range': (5.0, 95.0), 'normalizer__with_centering': False, 'normalizer__with_scaling': True}), 'rebalance': ('rebalance_NearMiss', {'rebalance__n_neighbors': 2})}, algo_config={'bootstrap': False, 'criterion': 'gini', 'max_depth': 1, 'max_features': 3, 'max_leaf_nodes': None, 'min_samples_split': 2, 'n_estimators': 50}, algorithm='RandomForest', X=array([[1.799e+01, 1.038e+01, 1.228e+02, ..., 2...., ..., 0.000e+00, 2.871e-01,
        7.039e-02]]), y=array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,... 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1]), context={'baseline_score': 0.9545944602886527, 'baseline_score_std': 0.03716322883281839, 'best_config': {'algorithm': {'bootstrap': False, 'criterion': 'entropy', 'max_depth': None, 'max_features': 3, 'max_leaf_nodes': None, 'min_samples_split': 5, 'n_estimators': 10}, 'config_hash': {'algorithm': 'def83e48be05ef92a37e1a90585820f2f67ff42b', 'config': '95902552cb76e9798f0fa58782bd72bd1cc272d7', 'pipeline': '1775187bf23f94f4fd0cc1e5c1ef665210edded5'}, 'duration': 2.0033559799194336, 'iteration': 18, 'loss': 0.04922327370149515, 'max_history_score': 0.9507767262985048, 'max_history_score_std': 0.028328108925705902, 'max_history_step': 'joint', 'pipeline': {'features': ('features_PCA', {'features__n_components': 4}), 'normalizer': ('normalizer_StandardScaler', {'normalizer__with_mean': True, 'normalizer__with_std': True}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 5})}, 'score': 0.9507767262985048, ...}, 'history': [{'algorithm': {'bootstrap': True, 'criterion': 'entropy', 'max_depth': 4, 'max_features': 3, 'max_leaf_nodes': 3, 'min_samples_split': 2, 'n_estimators': 10}, 'config_hash': {'algorithm': '42527c4120073c2a488d1b8df28732f486d1578c', 'config': '51144ca42f9ea5ab2d8d58606e3b3e4d89c6d7b3', 'pipeline': '52f07bda29f9d3a95fabb87e591d0b2581ca8209'}, 'duration': 0.26703310012817383, 'iteration': 0, 'loss': 0.06655431682654922, 'max_history_score': 0.9334456831734508, 'max_history_score_std': 0.03819399139659311, 'max_history_step': 'joint', 'pipeline': {'features': ('features_NoneType', {}), 'normalizer': ('normalizer_RobustScaler', {'normalizer__quantile_range': (...), 'normalizer__with_centering': False, 'normalizer__with_scaling': False}), 'rebalance': ('rebalance_NearMiss', {'rebalance__n_neighbors': 1})}, 'score': 0.9334456831734508, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': None, 'max_features': 2, 'max_leaf_nodes': 3, 'min_samples_split': 2, 'n_estimators': 100}, 'config_hash': {'algorithm': '1b32258c630f07e01ab481ab925ab80aa757e482', 'config': '9e54ffcb6a727de032a0a2cd45c5cc37cc150756', 'pipeline': '37e72d4a97f5e784c9d3133e6379b91bfc3be803'}, 'duration': 1.3065669536590576, 'iteration': 1, 'loss': 0.05436435917379645, 'max_history_score': 0.9456356408262035, 'max_history_score_std': 0.040053650785990214, 'max_history_step': 'joint', 'pipeline': {'features': ('features_NoneType', {}), 'normalizer': ('normalizer_StandardScaler', {'normalizer__with_mean': True, 'normalizer__with_std': True}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 6})}, 'score': 0.9456356408262035, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'entropy', 'max_depth': 1, 'max_features': 1, 'max_leaf_nodes': 2, 'min_samples_split': 3, 'n_estimators': 25}, 'config_hash': {'algorithm': '68ab9059aa7ec74e0da87c81734b9664243b3eb4', 'config': 'e5241eee9ddf3f4ee29a4711f5bcc92a4d24cd09', 'pipeline': '62463de065924498cdcd2f2f1f7e68535cdb33a5'}, 'duration': 0.6592490673065186, 'iteration': 2, 'loss': 0.07695856019358727, 'max_history_score': 0.9456356408262035, 'max_history_score_std': 0.040053650785990214, 'max_history_step': 'joint', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 1, 'features__selectkbest__k': 2}), 'normalizer': ('normalizer_NoneType', {}), 'rebalance': ('rebalance_NoneType', {})}, 'score': 0.9230414398064127, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': 3, 'max_features': 2, 'max_leaf_nodes': 2, 'min_samples_split': 2, 'n_estimators': 25}, 'config_hash': {'algorithm': 'e3f1f7d7783557a38f40f0476369091edd87092b', 'config': '18ee4d3d1627472ec190326308d8755371a6dc62', 'pipeline': 'c6d1263e344ed8c71b2e6e4ba8e0db2fb6c777c0'}, 'duration': 0.879349946975708, 'iteration': 3, 'loss': 0.07535973554576114, 'max_history_score': 0.9456356408262035, 'max_history_score_std': 0.040053650785990214, 'max_history_step': 'joint', 'pipeline': {'features': ('features_NoneType', {}), 'normalizer': ('normalizer_RobustScaler', {'normalizer__quantile_range': (...), 'normalizer__with_centering': True, 'normalizer__with_scaling': True}), 'rebalance': ('rebalance_NearMiss', {'rebalance__n_neighbors': 2})}, 'score': 0.9246402644542389, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'gini', 'max_depth': 4, 'max_features': 2, 'max_leaf_nodes': 5, 'min_samples_split': 2, 'n_estimators': 50}, 'config_hash': {'algorithm': '47581af7253940f9647ad16d37347d34baf13e5f', 'config': '2af4f82b045c0c48ecb89d42728d1039fbff8878', 'pipeline': '2928b22ed834303cb7bac6e6608531eaddd7df67'}, 'duration': 4.372632026672363, 'iteration': 4, 'loss': 0.09121294615849984, 'max_history_score': 0.9456356408262035, 'max_history_score_std': 0.040053650785990214, 'max_history_step': 'joint', 'pipeline': {'features': ('features_NoneType', {}), 'normalizer': ('normalizer_MinMaxScaler', {}), 'rebalance': ('rebalance_CondensedNearestNeighbour', {'rebalance__n_neighbors': 2})}, 'score': 0.9087870538415002, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'entropy', 'max_depth': 2, 'max_features': 2, 'max_leaf_nodes': None, 'min_samples_split': 2, 'n_estimators': 10}, 'config_hash': {'algorithm': '0a85f98ca2d06103287f153633d88f7a0535e7e8', 'config': '17b2a1e5814f3e933137158708a5b6e9b2475495', 'pipeline': '95defa3bdd8357f11f872d3c280d50a6d8ee398d'}, 'duration': 2.625814914703369, 'iteration': 5, 'loss': 0.15471329185031535, 'max_history_score': 0.9456356408262035, 'max_history_score_std': 0.040053650785990214, 'max_history_step': 'joint', 'pipeline': {'features': ('features_SelectKBest', {'features__k': 2}), 'normalizer': ('normalizer_StandardScaler', {'normalizer__with_mean': False, 'normalizer__with_std': False}), 'rebalance': ('rebalance_CondensedNearestNeighbour', {'rebalance__n_neighbors': 1})}, 'score': 0.8452867081496847, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': 3, 'max_features': None, 'max_leaf_nodes': None, 'min_samples_split': 5, 'n_estimators': 75}, 'config_hash': {'algorithm': 'd7466a2c1d5cb3fa95029d73dc030f4c3c45a159', 'config': 'fa020a592ec5ac234f9f91aac28abc2cd1ec9d33', 'pipeline': '71e0d26f923d42cfe0e2fa748931ef2afe72ed86'}, 'duration': 3.62078595161438, 'iteration': 6, 'loss': 0.17066372828623277, 'max_history_score': 0.9456356408262035, 'max_history_score_std': 0.040053650785990214, 'max_history_step': 'joint', 'pipeline': {'features': ('features_SelectKBest', {'features__k': 1}), 'normalizer': ('normalizer_RobustScaler', {'normalizer__quantile_range': (...), 'normalizer__with_centering': True, 'normalizer__with_scaling': True}), 'rebalance': ('rebalance_CondensedNearestNeighbour', {'rebalance__n_neighbors': 1})}, 'score': 0.8293362717137672, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'entropy', 'max_depth': 3, 'max_features': 3, 'max_leaf_nodes': 5, 'min_samples_split': 5, 'n_estimators': 50}, 'config_hash': {'algorithm': '735caa9785596076014572a24050cde8dc338973', 'config': '0da4498002d6f452c59bb61756abb3ded841e786', 'pipeline': '51a53ea6ef5a2521ee65f76eb2da220ab7086513'}, 'duration': 0.6934049129486084, 'iteration': 7, 'loss': 0.06125875032408601, 'max_history_score': 0.9456356408262035, 'max_history_score_std': 0.040053650785990214, 'max_history_step': 'joint', 'pipeline': {'features': ('features_NoneType', {}), 'normalizer': ('normalizer_NoneType', {}), 'rebalance': ('rebalance_NearMiss', {'rebalance__n_neighbors': 3})}, 'score': 0.938741249675914, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': 4, 'max_features': 2, 'max_leaf_nodes': None, 'min_samples_split': 3, 'n_estimators': 75}, 'config_hash': {'algorithm': 'e71a1fe9515b6805f07914a61f2e7594be9e9afe', 'config': '344e4756fb1bec455d6af51d3727e33b0d27725f', 'pipeline': '248dad1d8b30a17a5de1d0bbdfe3e2acb7a1962b'}, 'duration': 1.3036692142486572, 'iteration': 8, 'loss': 0.06483125918243893, 'max_history_score': 0.9456356408262035, 'max_history_score_std': 0.040053650785990214, 'max_history_step': 'joint', 'pipeline': {'features': ('features_PCA', {'features__n_components': 2}), 'normalizer': ('normalizer_StandardScaler', {'normalizer__with_mean': False, 'normalizer__with_std': True}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 7})}, 'score': 0.9351687408175611, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'entropy', 'max_depth': 2, 'max_features': 2, 'max_leaf_nodes': 2, 'min_samples_split': 3, 'n_estimators': 10}, 'config_hash': {'algorithm': '0a507823f2ad8605ed5950e1fe61df0560f11a00', 'config': '4a538fdcf8e07f90e92a421c0d5c479d651629c7', 'pipeline': '5240329df25c9a533d025c1a401d49835a501b41'}, 'duration': 1.3821029663085938, 'iteration': 9, 'loss': 0.07006416904329793, 'max_history_score': 0.9456356408262035, 'max_history_score_std': 0.040053650785990214, 'max_history_step': 'joint', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 4, 'features__selectkbest__k': 2}), 'normalizer': ('normalizer_PowerTransformer', {}), 'rebalance': ('rebalance_NearMiss', {'rebalance__n_neighbors': 1})}, 'score': 0.9299358309567021, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'gini', 'max_depth': 1, 'max_features': 3, 'max_leaf_nodes': 5, 'min_samples_split': 3, 'n_estimators': 10}, 'config_hash': {'algorithm': 'd32739750d351948f8ff34a87c7d55b0c5e0d90f', 'config': 'c1609e71f1ce8486335adc70bb69a955580ba2c8', 'pipeline': 'f48b42ec5cf999279659966160a16353b75bdaa3'}, 'duration': 0.9055681228637695, 'iteration': 10, 'loss': 0.07532840722495904, 'max_history_score': 0.9456356408262035, 'max_history_score_std': 0.040053650785990214, 'max_history_step': 'joint', 'pipeline': {'features': ('features_PCA', {'features__n_components': 4}), 'normalizer': ('normalizer_PowerTransformer', {}), 'rebalance': ('rebalance_NearMiss', {'rebalance__n_neighbors': 1})}, 'score': 0.924671592775041, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': 3, 'max_features': 1, 'max_leaf_nodes': 5, 'min_samples_split': 3, 'n_estimators': 25}, 'config_hash': {'algorithm': 'f69bac35e71cbec1bfc1fb5942328a3390e7c252', 'config': 'abe36f188644e53e56ed3224236fa157107ed3b2', 'pipeline': 'aaf976c7c663a31fa039582d42f9e07101556a7c'}, 'duration': 0.764197826385498, 'iteration': 11, 'loss': 0.06818446979517778, 'max_history_score': 0.9456356408262035, 'max_history_score_std': 0.040053650785990214, 'max_history_step': 'joint', 'pipeline': {'features': ('features_NoneType', {}), 'normalizer': ('normalizer_PowerTransformer', {}), 'rebalance': ('rebalance_NoneType', {})}, 'score': 0.9318155302048222, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'entropy', 'max_depth': None, 'max_features': None, 'max_leaf_nodes': None, 'min_samples_split': 5, 'n_estimators': 25}, 'config_hash': {'algorithm': 'a0a27aec00db5ddf71eab96663f9bd61c845f5e3', 'config': '76aa002c3c9d4d9722466c60daf5119c18a41d2a', 'pipeline': '1ce34b7894ef342571d974bb19e8ec821a512c6b'}, 'duration': 1.1636500358581543, 'iteration': 12, 'loss': 0.12833700630887557, 'max_history_score': 0.9456356408262035, 'max_history_score_std': 0.040053650785990214, 'max_history_step': 'joint', 'pipeline': {'features': ('features_PCA', {'features__n_components': 1}), 'normalizer': ('normalizer_PowerTransformer', {}), 'rebalance': ('rebalance_NoneType', {})}, 'score': 0.8716629936911244, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'gini', 'max_depth': 1, 'max_features': 2, 'max_leaf_nodes': 2, 'min_samples_split': 2, 'n_estimators': 100}, 'config_hash': {'algorithm': '985c99dff1da9b2c87e4211c5335a9159aa9dbcb', 'config': 'f56a7a9e43a0a699e992dc1262e550b8b7c88538', 'pipeline': '5c934f6d9a8ad1f9afe762986a9cf2074fc95d79'}, 'duration': 2.235443115234375, 'iteration': 13, 'loss': 0.11414635727249167, 'max_history_score': 0.9456356408262035, 'max_history_score_std': 0.040053650785990214, 'max_history_step': 'joint', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 1, 'features__selectkbest__k': 1}), 'normalizer': ('normalizer_RobustScaler', {'normalizer__quantile_range': (...), 'normalizer__with_centering': False, 'normalizer__with_scaling': True}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 6})}, 'score': 0.8858536427275083, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'gini', 'max_depth': 1, 'max_features': 1, 'max_leaf_nodes': None, 'min_samples_split': 5, 'n_estimators': 10}, 'config_hash': {'algorithm': '7d74a39aac2579264a402aef2b6fa7943c19f3d3', 'config': '53f44c0ad925c5c08c25d4fadf5e9ee9d7c181cd', 'pipeline': '6eff5ef31d7d1d534db31913bb67529c8a24c42e'}, 'duration': 2.7847659587860107, 'iteration': 14, 'loss': 0.14061986863711007, 'max_history_score': 0.9456356408262035, 'max_history_score_std': 0.040053650785990214, 'max_history_step': 'joint', 'pipeline': {'features': ('features_PCA', {'features__n_components': 1}), 'normalizer': ('normalizer_RobustScaler', {'normalizer__quantile_range': (...), 'normalizer__with_centering': True, 'normalizer__with_scaling': True}), 'rebalance': ('rebalance_CondensedNearestNeighbour', {'rebalance__n_neighbors': 3})}, 'score': 0.8593801313628899, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'entropy', 'max_depth': 3, 'max_features': None, 'max_leaf_nodes': 5, 'min_samples_split': 2, 'n_estimators': 100}, 'config_hash': {'algorithm': 'c62d7c671832e4414b6b2d7c36cba5ddc83a0ed0', 'config': '5faee50671eaa0ac586722bff234e36a857e662d', 'pipeline': '8b29a55de2add78c49114b9bbe5e800e5524c59d'}, 'duration': 2.3916029930114746, 'iteration': 15, 'loss': 0.08770093336790252, 'max_history_score': 0.9456356408262035, 'max_history_score_std': 0.040053650785990214, 'max_history_step': 'joint', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 3, 'features__selectkbest__k': 4}), 'normalizer': ('normalizer_RobustScaler', {'normalizer__quantile_range': (...), 'normalizer__with_centering': True, 'normalizer__with_scaling': True}), 'rebalance': ('rebalance_NoneType', {})}, 'score': 0.9122990666320975, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': None, 'max_features': 1, 'max_leaf_nodes': 5, 'min_samples_split': 5, 'n_estimators': 10}, 'config_hash': {'algorithm': '290772bfb9b8ed15c48a72829e822fb0a07481d6', 'config': '9a04f25d8eb3db5b2f831abd341a6d384c73a957', 'pipeline': '1ce34b7894ef342571d974bb19e8ec821a512c6b'}, 'duration': 1.4364500045776367, 'iteration': 16, 'loss': 0.08948880822746508, 'max_history_score': 0.9456356408262035, 'max_history_score_std': 0.040053650785990214, 'max_history_step': 'joint', 'pipeline': {'features': ('features_PCA', {'features__n_components': 1}), 'normalizer': ('normalizer_PowerTransformer', {}), 'rebalance': ('rebalance_NoneType', {})}, 'score': 0.9105111917725349, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': 2, 'max_features': 3, 'max_leaf_nodes': 3, 'min_samples_split': 3, 'n_estimators': 100}, 'config_hash': {'algorithm': '7dab6d47f897c2961d3402eff844aff16a7d142a', 'config': '4dbfa2688b239be9f372d3e80223960ba9a1fbdd', 'pipeline': 'cdef51702798fa49f11c11d80baf3ab43d5358fc'}, 'duration': 0.9830451011657715, 'iteration': 17, 'loss': 1.0, 'max_history_score': 0.9456356408262035, 'max_history_score_std': 0.040053650785990214, 'max_history_step': 'joint', 'pipeline': {'features': ('features_SelectKBest', {'features__k': 2}), 'normalizer': ('normalizer_PowerTransformer', {}), 'rebalance': ('rebalance_NearMiss', {'rebalance__n_neighbors': 1})}, 'score': 0.0, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'entropy', 'max_depth': None, 'max_features': 3, 'max_leaf_nodes': None, 'min_samples_split': 5, 'n_estimators': 10}, 'config_hash': {'algorithm': 'def83e48be05ef92a37e1a90585820f2f67ff42b', 'config': '95902552cb76e9798f0fa58782bd72bd1cc272d7', 'pipeline': '1775187bf23f94f4fd0cc1e5c1ef665210edded5'}, 'duration': 2.0033559799194336, 'iteration': 18, 'loss': 0.04922327370149515, 'max_history_score': 0.9507767262985048, 'max_history_score_std': 0.028328108925705902, 'max_history_step': 'joint', 'pipeline': {'features': ('features_PCA', {'features__n_components': 4}), 'normalizer': ('normalizer_StandardScaler', {'normalizer__with_mean': True, 'normalizer__with_std': True}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 5})}, 'score': 0.9507767262985048, ...}], 'history_hash': ['51144ca42f9ea5ab2d8d58606e3b3e4d89c6d7b3', '9e54ffcb6a727de032a0a2cd45c5cc37cc150756', 'e5241eee9ddf3f4ee29a4711f5bcc92a4d24cd09', '18ee4d3d1627472ec190326308d8755371a6dc62', '2af4f82b045c0c48ecb89d42728d1039fbff8878', '17b2a1e5814f3e933137158708a5b6e9b2475495', 'fa020a592ec5ac234f9f91aac28abc2cd1ec9d33', '0da4498002d6f452c59bb61756abb3ded841e786', '344e4756fb1bec455d6af51d3727e33b0d27725f', '4a538fdcf8e07f90e92a421c0d5c479d651629c7', 'c1609e71f1ce8486335adc70bb69a955580ba2c8', 'abe36f188644e53e56ed3224236fa157107ed3b2', '76aa002c3c9d4d9722466c60daf5119c18a41d2a', 'f56a7a9e43a0a699e992dc1262e550b8b7c88538', '53f44c0ad925c5c08c25d4fadf5e9ee9d7c181cd', '5faee50671eaa0ac586722bff234e36a857e662d', '9a04f25d8eb3db5b2f831abd341a6d384c73a957', '4dbfa2688b239be9f372d3e80223960ba9a1fbdd', '95902552cb76e9798f0fa58782bd72bd1cc272d7'], 'history_index': {'0da4498002d6f452c59bb61756abb3ded841e786': 7, '17b2a1e5814f3e933137158708a5b6e9b2475495': 5, '18ee4d3d1627472ec190326308d8755371a6dc62': 3, '2af4f82b045c0c48ecb89d42728d1039fbff8878': 4, '344e4756fb1bec455d6af51d3727e33b0d27725f': 8, '4a538fdcf8e07f90e92a421c0d5c479d651629c7': 9, '4dbfa2688b239be9f372d3e80223960ba9a1fbdd': 17, '51144ca42f9ea5ab2d8d58606e3b3e4d89c6d7b3': 0, '53f44c0ad925c5c08c25d4fadf5e9ee9d7c181cd': 14, '5faee50671eaa0ac586722bff234e36a857e662d': 15, ...}, 'iteration': 18, 'max_history_score': 0.9507767262985048, 'max_history_score_std': 0.028328108925705902, 'max_history_step': 'joint'}, config={'algorithm': 'RandomForest', 'seed': 42, 'time': 300}, step='joint')
     45                 y,
     46                 cv=10,
     47                 n_jobs=-1,
     48                 return_estimator=False,
     49                 return_train_score=False,
---> 50                 verbose=0)
     51         score = np.mean(scores['test_score'])
     52         std = np.std(scores['test_score'])
     53         status = STATUS_OK
     54     except Exception as e:

...........................................................................
/home/aquemy/.local/lib/python2.7/site-packages/sklearn/model_selection/_validation.py in cross_validate(estimator=Pipeline(memory=None,
     steps=[('rebalance', ... random_state=42, verbose=0, warm_start=False))]), X=array([[1.799e+01, 1.038e+01, 1.228e+02, ..., 2...., ..., 0.000e+00, 2.871e-01,
        7.039e-02]]), y=array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,... 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1]), groups=None, scoring=None, cv=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1, verbose=0, fit_params=None, pre_dispatch='2*n_jobs', return_train_score=False, return_estimator=False, error_score='raise-deprecating')
    235         delayed(_fit_and_score)(
    236             clone(estimator), X, y, scorers, train, test, verbose, None,
    237             fit_params, return_train_score=return_train_score,
    238             return_times=True, return_estimator=return_estimator,
    239             error_score=error_score)
--> 240         for train, test in cv.split(X, y, groups))
        cv.split = <bound method StratifiedKFold.split of Stratifie...d(n_splits=10, random_state=None, shuffle=False)>
        X = array([[1.799e+01, 1.038e+01, 1.228e+02, ..., 2...., ..., 0.000e+00, 2.871e-01,
        7.039e-02]])
        y = array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,... 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1])
        groups = None
    241 
    242     zipped_scores = list(zip(*scores))
    243     if return_train_score:
    244         train_scores = zipped_scores.pop(0)

...........................................................................
/home/aquemy/.local/lib/python2.7/site-packages/sklearn/externals/joblib/parallel.py in __call__(self=Parallel(n_jobs=-1), iterable=<generator object <genexpr>>)
    925                 # No need to wait for async callbacks to trigger to
    926                 # consumption.
    927                 self._iterating = False
    928 
    929             with self._backend.retrieval_context():
--> 930                 self.retrieve()
        self.retrieve = <bound method Parallel.retrieve of Parallel(n_jobs=-1)>
    931             # Make sure that we get a last message telling us we are done
    932             elapsed_time = time.time() - self._start_time
    933             self._print('Done %3i out of %3i | elapsed: %s finished',
    934                         (len(self._output), len(self._output),

---------------------------------------------------------------------------
Joblib worker traceback:
---------------------------------------------------------------------------
ValueError                                         Mon Jun 17 13:32:01 2019
PID: 25932                                  Python 2.7.15+: /usr/bin/python
...........................................................................
/home/aquemy/.local/lib/python2.7/site-packages/sklearn/externals/joblib/parallel.py in __call__(self=<sklearn.externals.joblib.parallel.BatchedCalls object>)
    220     def __call__(self):
    221         # Set the default nested backend to self._backend but do not set the
    222         # change the default number of processes to -1
    223         with parallel_backend(self._backend, n_jobs=self._n_jobs):
    224             return [func(*args, **kwargs)
--> 225                     for func, args, kwargs in self.items]
        func = <function _fit_and_score>
        args = (Pipeline(memory=None,
     steps=[('rebalance', ... random_state=42, verbose=0, warm_start=False))]), array([[1.799e+01, 1.038e+01, 1.228e+02, ..., 2...., ..., 0.000e+00, 2.871e-01,
        7.039e-02]]), array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,... 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1]), {'score': <function _passthrough_scorer>}, array([ 25,  26,  27,  28,  29,  30,  31,  32,  ..., 561, 562, 563, 564,
       565, 566, 567, 568]), array([  0,   1,   2,   3,   4,   5,   6,   7,  ...,  89,  90,
        92,  93,  96,  97,  98, 101]), 0, None, None)
        kwargs = {'error_score': 'raise-deprecating', 'return_estimator': False, 'return_times': True, 'return_train_score': False}
        self.items = [(<function _fit_and_score>, (Pipeline(memory=None,
     steps=[('rebalance', ... random_state=42, verbose=0, warm_start=False))]), array([[1.799e+01, 1.038e+01, 1.228e+02, ..., 2...., ..., 0.000e+00, 2.871e-01,
        7.039e-02]]), array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,... 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1]), {'score': <function _passthrough_scorer>}, array([ 25,  26,  27,  28,  29,  30,  31,  32,  ..., 561, 562, 563, 564,
       565, 566, 567, 568]), array([  0,   1,   2,   3,   4,   5,   6,   7,  ...,  89,  90,
        92,  93,  96,  97,  98, 101]), 0, None, None), {'error_score': 'raise-deprecating', 'return_estimator': False, 'return_times': True, 'return_train_score': False})]
    226 
    227     def __len__(self):
    228         return self._size
    229 

...........................................................................
/home/aquemy/.local/lib/python2.7/site-packages/sklearn/model_selection/_validation.py in _fit_and_score(estimator=Pipeline(memory=None,
     steps=[('rebalance', ... random_state=42, verbose=0, warm_start=False))]), X=array([[1.799e+01, 1.038e+01, 1.228e+02, ..., 2...., ..., 0.000e+00, 2.871e-01,
        7.039e-02]]), y=array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,... 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1]), scorer={'score': <function _passthrough_scorer>}, train=array([ 25,  26,  27,  28,  29,  30,  31,  32,  ..., 561, 562, 563, 564,
       565, 566, 567, 568]), test=array([  0,   1,   2,   3,   4,   5,   6,   7,  ...,  89,  90,
        92,  93,  96,  97,  98, 101]), verbose=0, parameters=None, fit_params={}, return_train_score=False, return_parameters=False, return_n_test_samples=False, return_times=True, return_estimator=False, error_score='raise-deprecating')
    523 
    524     try:
    525         if y_train is None:
    526             estimator.fit(X_train, **fit_params)
    527         else:
--> 528             estimator.fit(X_train, y_train, **fit_params)
        estimator.fit = <bound method Pipeline.fit of Pipeline(memory=No...random_state=42, verbose=0, warm_start=False))])>
        X_train = array([[1.714e+01, 1.640e+01, 1.160e+02, ..., 2...., ..., 0.000e+00, 2.871e-01,
        7.039e-02]])
        y_train = array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...1, 1, 1, 1, 1, 1, 1, 0, 0,
       0, 0, 0, 0, 1])
        fit_params = {}
    529 
    530     except Exception as e:
    531         # Note fit time as time until error
    532         fit_time = time.time() - start_time

...........................................................................
/usr/local/lib/python2.7/dist-packages/imblearn/pipeline.py in fit(self=Pipeline(memory=None,
     steps=[('rebalance', ... random_state=42, verbose=0, warm_start=False))]), X=array([[1.714e+01, 1.640e+01, 1.160e+02, ..., 2...., ..., 0.000e+00, 2.871e-01,
        7.039e-02]]), y=array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...1, 1, 1, 1, 1, 1, 1, 0, 0,
       0, 0, 0, 0, 1]), **fit_params={})
    234             This estimator
    235 
    236         """
    237         Xt, yt, fit_params = self._fit(X, y, **fit_params)
    238         if self._final_estimator is not None:
--> 239             self._final_estimator.fit(Xt, yt, **fit_params)
        self._final_estimator.fit = <bound method RandomForestClassifier.fit of Rand...e, random_state=42, verbose=0, warm_start=False)>
        Xt = array([[ 2.13413448e+00,  8.27142119e-01],
     ...-01],
       [-9.29323445e-01, -2.11968134e-01]])
        yt = array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...1, 1, 1, 1, 1, 1, 1, 1,
       1, 1, 1, 1, 1, 1])
        fit_params = {}
    240         return self
    241 
    242     def fit_transform(self, X, y=None, **fit_params):
    243         """Fit the model and transform with the final estimator

...........................................................................
/home/aquemy/.local/lib/python2.7/site-packages/sklearn/ensemble/forest.py in fit(self=RandomForestClassifier(bootstrap=False, class_we...se, random_state=42, verbose=0, warm_start=False), X=array([[ 2.13413453e+00,  8.27142119e-01],
     ...9.29323435e-01, -2.11968139e-01]], dtype=float32), y=array([[0.],
       [0.],
       [0.],
       [0...    [1.],
       [1.],
       [1.],
       [1.]]), sample_weight=None)
    328             trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,
    329                              **_joblib_parallel_args(prefer='threads'))(
    330                 delayed(_parallel_build_trees)(
    331                     t, self, X, y, sample_weight, i, len(trees),
    332                     verbose=self.verbose, class_weight=self.class_weight)
--> 333                 for i, t in enumerate(trees))
        i = 49
    334 
    335             # Collect newly grown trees
    336             self.estimators_.extend(trees)
    337 

...........................................................................
/home/aquemy/.local/lib/python2.7/site-packages/sklearn/externals/joblib/parallel.py in __call__(self=Parallel(n_jobs=1), iterable=<generator object <genexpr>>)
    912             # self._original_iterator is None, then this means either
    913             # that pre_dispatch == "all", n_jobs == 1 or that the first batch
    914             # was very quick and its callback already dispatched all the
    915             # remaining jobs.
    916             self._iterating = False
--> 917             if self.dispatch_one_batch(iterator):
        self.dispatch_one_batch = <bound method Parallel.dispatch_one_batch of Parallel(n_jobs=1)>
        iterator = <generator object <genexpr>>
    918                 self._iterating = self._original_iterator is not None
    919 
    920             while self.dispatch_one_batch(iterator):
    921                 pass

...........................................................................
/home/aquemy/.local/lib/python2.7/site-packages/sklearn/externals/joblib/parallel.py in dispatch_one_batch(self=Parallel(n_jobs=1), iterator=<generator object <genexpr>>)
    754                                  self._pickle_cache)
    755             if len(tasks) == 0:
    756                 # No more tasks available in the iterator: tell caller to stop.
    757                 return False
    758             else:
--> 759                 self._dispatch(tasks)
        self._dispatch = <bound method Parallel._dispatch of Parallel(n_jobs=1)>
        tasks = <sklearn.externals.joblib.parallel.BatchedCalls object>
    760                 return True
    761 
    762     def _print(self, msg, msg_args):
    763         """Display the message on stout or stderr depending on verbosity"""

...........................................................................
/home/aquemy/.local/lib/python2.7/site-packages/sklearn/externals/joblib/parallel.py in _dispatch(self=Parallel(n_jobs=1), batch=<sklearn.externals.joblib.parallel.BatchedCalls object>)
    711 
    712         dispatch_timestamp = time.time()
    713         cb = BatchCompletionCallBack(dispatch_timestamp, len(batch), self)
    714         with self._lock:
    715             job_idx = len(self._jobs)
--> 716             job = self._backend.apply_async(batch, callback=cb)
        job = undefined
        self._backend.apply_async = <bound method SequentialBackend.apply_async of <...lib._parallel_backends.SequentialBackend object>>
        batch = <sklearn.externals.joblib.parallel.BatchedCalls object>
        cb = <sklearn.externals.joblib.parallel.BatchCompletionCallBack object>
    717             # A job can complete so quickly than its callback is
    718             # called before we get here, causing self._jobs to
    719             # grow. To ensure correct results ordering, .insert is
    720             # used (rather than .append) in the following line

...........................................................................
/home/aquemy/.local/lib/python2.7/site-packages/sklearn/externals/joblib/_parallel_backends.py in apply_async(self=<sklearn.externals.joblib._parallel_backends.SequentialBackend object>, func=<sklearn.externals.joblib.parallel.BatchedCalls object>, callback=<sklearn.externals.joblib.parallel.BatchCompletionCallBack object>)
    177             raise ValueError('n_jobs == 0 in Parallel has no meaning')
    178         return 1
    179 
    180     def apply_async(self, func, callback=None):
    181         """Schedule a func to be run"""
--> 182         result = ImmediateResult(func)
        result = undefined
        func = <sklearn.externals.joblib.parallel.BatchedCalls object>
    183         if callback:
    184             callback(result)
    185         return result
    186 

...........................................................................
/home/aquemy/.local/lib/python2.7/site-packages/sklearn/externals/joblib/_parallel_backends.py in __init__(self=<sklearn.externals.joblib._parallel_backends.ImmediateResult object>, batch=<sklearn.externals.joblib.parallel.BatchedCalls object>)
    544 
    545 class ImmediateResult(object):
    546     def __init__(self, batch):
    547         # Don't delay the application, to avoid keeping the input
    548         # arguments in memory
--> 549         self.results = batch()
        self.results = undefined
        batch = <sklearn.externals.joblib.parallel.BatchedCalls object>
    550 
    551     def get(self):
    552         return self.results
    553 

...........................................................................
/home/aquemy/.local/lib/python2.7/site-packages/sklearn/externals/joblib/parallel.py in __call__(self=<sklearn.externals.joblib.parallel.BatchedCalls object>)
    220     def __call__(self):
    221         # Set the default nested backend to self._backend but do not set the
    222         # change the default number of processes to -1
    223         with parallel_backend(self._backend, n_jobs=self._n_jobs):
    224             return [func(*args, **kwargs)
--> 225                     for func, args, kwargs in self.items]
        func = <function _parallel_build_trees>
        args = (DecisionTreeClassifier(class_weight=None, criter...=False, random_state=1608637542, splitter='best'), RandomForestClassifier(bootstrap=False, class_we...se, random_state=42, verbose=0, warm_start=False), array([[ 2.13413453e+00,  8.27142119e-01],
     ...9.29323435e-01, -2.11968139e-01]], dtype=float32), array([[0.],
       [0.],
       [0.],
       [0...    [1.],
       [1.],
       [1.],
       [1.]]), None, 0, 50)
        kwargs = {'class_weight': None, 'verbose': 0}
        self.items = [(<function _parallel_build_trees>, (DecisionTreeClassifier(class_weight=None, criter...=False, random_state=1608637542, splitter='best'), RandomForestClassifier(bootstrap=False, class_we...se, random_state=42, verbose=0, warm_start=False), array([[ 2.13413453e+00,  8.27142119e-01],
     ...9.29323435e-01, -2.11968139e-01]], dtype=float32), array([[0.],
       [0.],
       [0.],
       [0...    [1.],
       [1.],
       [1.],
       [1.]]), None, 0, 50), {'class_weight': None, 'verbose': 0})]
    226 
    227     def __len__(self):
    228         return self._size
    229 

...........................................................................
/home/aquemy/.local/lib/python2.7/site-packages/sklearn/ensemble/forest.py in _parallel_build_trees(tree=DecisionTreeClassifier(class_weight=None, criter...=False, random_state=1608637542, splitter='best'), forest=RandomForestClassifier(bootstrap=False, class_we...se, random_state=42, verbose=0, warm_start=False), X=array([[ 2.13413453e+00,  8.27142119e-01],
     ...9.29323435e-01, -2.11968139e-01]], dtype=float32), y=array([[0.],
       [0.],
       [0.],
       [0...    [1.],
       [1.],
       [1.],
       [1.]]), sample_weight=None, tree_idx=0, n_trees=50, verbose=0, class_weight=None)
    116         elif class_weight == 'balanced_subsample':
    117             curr_sample_weight *= compute_sample_weight('balanced', y, indices)
    118 
    119         tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)
    120     else:
--> 121         tree.fit(X, y, sample_weight=sample_weight, check_input=False)
        tree.fit = <bound method DecisionTreeClassifier.fit of Deci...False, random_state=1608637542, splitter='best')>
        X = array([[ 2.13413453e+00,  8.27142119e-01],
     ...9.29323435e-01, -2.11968139e-01]], dtype=float32)
        y = array([[0.],
       [0.],
       [0.],
       [0...    [1.],
       [1.],
       [1.],
       [1.]])
        sample_weight = None
    122 
    123     return tree
    124 
    125 

...........................................................................
/home/aquemy/.local/lib/python2.7/site-packages/sklearn/tree/tree.py in fit(self=DecisionTreeClassifier(class_weight=None, criter...=False, random_state=1608637542, splitter='best'), X=array([[ 2.13413453e+00,  8.27142119e-01],
     ...9.29323435e-01, -2.11968139e-01]], dtype=float32), y=array([[0.],
       [0.],
       [0.],
       [0...    [1.],
       [1.],
       [1.],
       [1.]]), sample_weight=None, check_input=False, X_idx_sorted=None)
    796 
    797         super(DecisionTreeClassifier, self).fit(
    798             X, y,
    799             sample_weight=sample_weight,
    800             check_input=check_input,
--> 801             X_idx_sorted=X_idx_sorted)
        X_idx_sorted = None
    802         return self
    803 
    804     def predict_proba(self, X, check_input=True):
    805         """Predict class probabilities of the input samples X.

...........................................................................
/home/aquemy/.local/lib/python2.7/site-packages/sklearn/tree/tree.py in fit(self=DecisionTreeClassifier(class_weight=None, criter...=False, random_state=1608637542, splitter='best'), X=array([[ 2.13413453e+00,  8.27142119e-01],
     ...9.29323435e-01, -2.11968139e-01]], dtype=float32), y=array([[0.],
       [0.],
       [0.],
       [0...    [1.],
       [1.],
       [1.],
       [1.]]), sample_weight=None, check_input=False, X_idx_sorted=None)
    237         if not 0 <= self.min_weight_fraction_leaf <= 0.5:
    238             raise ValueError("min_weight_fraction_leaf must in [0, 0.5]")
    239         if max_depth <= 0:
    240             raise ValueError("max_depth must be greater than zero. ")
    241         if not (0 < max_features <= self.n_features_):
--> 242             raise ValueError("max_features must be in (0, n_features]")
    243         if not isinstance(max_leaf_nodes, (numbers.Integral, np.integer)):
    244             raise ValueError("max_leaf_nodes must be integral number but was "
    245                              "%r" % max_leaf_nodes)
    246         if -1 < max_leaf_nodes < 2:

ValueError: max_features must be in (0, n_features]
___________________________________________________________________________
Best score: 0.950776726299 (0.0283281089257) [J] | Score: 0.0 (0.0) [J]
Best score: 0.950776726299 (0.0283281089257) [J] | Score: 0.944126479993 (0.0450191479878) [J]
Best score: 0.950776726299 (0.0283281089257) [J] | Score: 0.910572768127 (0.0279428714174) [J]
Best score: 0.950776726299 (0.0283281089257) [J] | Score: 0.943912583182 (0.0370270424099) [J]
Best score: 0.950776726299 (0.0283281089257) [J] | Score: 0.927996715928 (0.0318467712377) [J]
Best score: 0.950776726299 (0.0283281089257) [J] | Score: 0.937017111745 (0.0472378976396) [J]
Best score: 0.950776726299 (0.0283281089257) [J] | Score: 0.936925287356 (0.0269377224941) [J]
Best score: 0.95250086423 (0.0222529506572) [J] | Score: 0.95250086423 (0.0222529506572) [J]
Best score: 0.95250086423 (0.0222529506572) [J] | Score: 0.948899187624 (0.0320811562332) [J]
Best score: 0.95250086423 (0.0222529506572) [J] | Score: 0.94015534526 (0.0298718162003) [J]
Best score: 0.95250086423 (0.0222529506572) [J] | Score: 0.942096620863 (0.0173376291459) [J]
Best score: 0.95250086423 (0.0222529506572) [J] | Score: 0.901612868378 (0.0501109273963) [J]
Best score: 0.95250086423 (0.0222529506572) [J] | Score: 0.910419367384 (0.0237442672258) [J]
Best score: 0.95250086423 (0.0222529506572) [J] | Score: 0.919128640567 (0.03963968117) [J]
Best score: 0.95250086423 (0.0222529506572) [J] | Score: 0.915653357532 (0.0318952378346) [J]
Best score: 0.95250086423 (0.0222529506572) [J] | Score: 0.456147912886 (0.0861640706846) [J]
Best score: 0.95250086423 (0.0222529506572) [J] | Score: 0.926458387348 (0.0324331124049) [J]
Best score: 0.95250086423 (0.0222529506572) [J] | Score: 0.908509420102 (0.0224096977869) [J]
Best score: 0.95250086423 (0.0222529506572) [J] | Score: 0.894811381903 (0.0389722677736) [J]
Best score: 0.95250086423 (0.0222529506572) [J] | Score: 0.88387887823 (0.0573347278252) [J]
Best score: 0.95250086423 (0.0222529506572) [J] | Score: 0.909004191513 (0.0432066953673) [J]
Best score: 0.95250086423 (0.0222529506572) [J] | Score: 0.891272361939 (0.0437412596655) [J]
Best score: 0.95250086423 (0.0222529506572) [J] | Score: 0.942188445251 (0.0267143180183) [J]
Best score: 0.95250086423 (0.0222529506572) [J] | Score: 0.905186457523 (0.0402074039491) [J]
Best score: 0.95250086423 (0.0222529506572) [J] | Score: 0.933045977011 (0.0295437415522) [J]
Best score: 0.95250086423 (0.0222529506572) [J] | Score: 0.921038587849 (0.0219965338159) [J]
Best score: 0.95250086423 (0.0222529506572) [J] | Score: 0.940434059286 (0.0257584890261) [J]
Best score: 0.95250086423 (0.0222529506572) [J] | Score: 0.910390199637 (0.0252464380852) [J]
Best score: 0.95250086423 (0.0222529506572) [J] | Score: 0.940401650678 (0.0345288425578) [J]
Best score: 0.95250086423 (0.0222529506572) [J] | Score: 0.88963896811 (0.0571000888994) [J]
Best score: 0.95250086423 (0.0222529506572) [J] | Score: 0.864766441967 (0.0500581711006) [J]
Best score: 0.95250086423 (0.0222529506572) [J] | Score: 0.905464091263 (0.0427917858766) [J]
Best score: 0.95250086423 (0.0222529506572) [J] | Score: 0.929968239564 (0.0296341839288) [J]
Best score: 0.95250086423 (0.0222529506572) [J] | Score: 0.943941750929 (0.0324426130904) [J]
Best score: 0.95250086423 (0.0222529506572) [J] | Score: 0.896289214415 (0.029698400072) [J]
Best score: 0.95250086423 (0.0222529506572) [J] | Score: 0.922918287097 (0.0265835376962) [J]
Best score: 0.95250086423 (0.0222529506572) [J] | Score: 0.882311381903 (0.0437660524972) [J]
Best score: 0.95250086423 (0.0222529506572) [J] | Score: 0.904753262467 (0.0596667621202) [J]
Best score: 0.95250086423 (0.0222529506572) [J] | Score: 0.944004407571 (0.0391783210826) [J]
Best score: 0.95250086423 (0.0222529506572) [J] | Score: 0.940434059286 (0.0298813387356) [J]
Best score: 0.95250086423 (0.0222529506572) [J] | Score: 0.929844006568 (0.0288074111814) [J]
JoblibValueError
___________________________________________________________________________
...........................................................................
/home/aquemy/dev/dp_hyperparameters/extension/main.py in <module>()
     27 
     28     serializer.serialize_results(scenario, policy)
     29 
     30 if __name__ == "__main__":
     31     args = cli.parse_args()
---> 32     main(args)

...........................................................................
/home/aquemy/dev/dp_hyperparameters/extension/main.py in main(args=Namespace(customize=[(['control', 'seed'], '42')...='./scenarios/rf_breast_joint.yaml', verbosity=0))
     21         test_size=0.4, 
     22         random_state=scenario['control']['seed']
     23     )
     24 
     25     policy = policies.initiate(scenario['setup']['policy'], config)
---> 26     policy.run(X,y)
        policy.run = <bound method Joint.run of <experiment.policies.joint.Joint object>>
        X = array([[1.799e+01, 1.038e+01, 1.228e+02, ..., 2...., ..., 0.000e+00, 2.871e-01,
        7.039e-02]])
        y = array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,... 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1])
     27 
     28     serializer.serialize_results(scenario, policy)
     29 
     30 if __name__ == "__main__":

...........................................................................
/home/aquemy/dev/dp_hyperparameters/extension/experiment/policies/joint.py in run(self=<experiment.policies.joint.Joint object>, X=array([[1.799e+01, 1.038e+01, 1.228e+02, ..., 2...., ..., 0.000e+00, 2.871e-01,
        7.039e-02]]), y=array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,... 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1]))
     32             algo=tpe.suggest, 
     33             max_evals=None,
     34             max_time=self.config['time'],     
     35             trials=trials,
     36             show_progressbar=False,
---> 37             verbose=0
     38         )
     39 
     40         best_config = self.context['best_config']
     41         super(Joint, self).display_step_results(best_config)

...........................................................................
/home/aquemy/dev/dp_hyperparameters/extension/hyperopt/fmin.py in fmin(fn=<functools.partial object>, space={'algorithm': {'bootstrap': <hyperopt.pyll.base.Apply object>, 'criterion': <hyperopt.pyll.base.Apply object>, 'max_depth': <hyperopt.pyll.base.Apply object>, 'max_features': <hyperopt.pyll.base.Apply object>, 'max_leaf_nodes': <hyperopt.pyll.base.Apply object>, 'min_samples_split': <hyperopt.pyll.base.Apply object>, 'n_estimators': <hyperopt.pyll.base.Apply object>}, 'pipeline': {'features': <hyperopt.pyll.base.Apply object>, 'normalizer': <hyperopt.pyll.base.Apply object>, 'rebalance': <hyperopt.pyll.base.Apply object>}}, algo=<function suggest>, max_evals=9223372036854775807, max_time=300, trials=<hyperopt.base.Trials object>, rstate=<mtrand.RandomState object>, allow_trials_fmin=True, pass_expr_memo_ctrl=None, catch_eval_exceptions=False, verbose=0, return_argmin=True, points_to_evaluate=None, max_queue_len=1, show_progressbar=False)
    406             pass_expr_memo_ctrl=pass_expr_memo_ctrl,
    407             verbose=verbose,
    408             catch_eval_exceptions=catch_eval_exceptions,
    409             return_argmin=return_argmin,
    410             show_progressbar=show_progressbar,
--> 411             max_time=max_time
        max_time = 300
    412         )
    413 
    414     if trials is None:
    415         if points_to_evaluate is None:

...........................................................................
/home/aquemy/dev/dp_hyperparameters/extension/hyperopt/base.py in fmin(self=<hyperopt.base.Trials object>, fn=<functools.partial object>, space={'algorithm': {'bootstrap': <hyperopt.pyll.base.Apply object>, 'criterion': <hyperopt.pyll.base.Apply object>, 'max_depth': <hyperopt.pyll.base.Apply object>, 'max_features': <hyperopt.pyll.base.Apply object>, 'max_leaf_nodes': <hyperopt.pyll.base.Apply object>, 'min_samples_split': <hyperopt.pyll.base.Apply object>, 'n_estimators': <hyperopt.pyll.base.Apply object>}, 'pipeline': {'features': <hyperopt.pyll.base.Apply object>, 'normalizer': <hyperopt.pyll.base.Apply object>, 'rebalance': <hyperopt.pyll.base.Apply object>}}, algo=<function suggest>, max_evals=9223372036854775807, max_time=300, rstate=<mtrand.RandomState object>, verbose=0, pass_expr_memo_ctrl=None, catch_eval_exceptions=False, return_argmin=True, show_progressbar=False)
    636             verbose=verbose,
    637             allow_trials_fmin=False,  # -- prevent recursion
    638             pass_expr_memo_ctrl=pass_expr_memo_ctrl,
    639             catch_eval_exceptions=catch_eval_exceptions,
    640             return_argmin=return_argmin,
--> 641             show_progressbar=show_progressbar)
        show_progressbar = False
    642 
    643 
    644 def trials_from_docs(docs, validate=True, **kwargs):
    645     """Construct a Trials base class instance from a list of trials documents

...........................................................................
/home/aquemy/dev/dp_hyperparameters/extension/hyperopt/fmin.py in fmin(fn=<functools.partial object>, space={'algorithm': {'bootstrap': <hyperopt.pyll.base.Apply object>, 'criterion': <hyperopt.pyll.base.Apply object>, 'max_depth': <hyperopt.pyll.base.Apply object>, 'max_features': <hyperopt.pyll.base.Apply object>, 'max_leaf_nodes': <hyperopt.pyll.base.Apply object>, 'min_samples_split': <hyperopt.pyll.base.Apply object>, 'n_estimators': <hyperopt.pyll.base.Apply object>}, 'pipeline': {'features': <hyperopt.pyll.base.Apply object>, 'normalizer': <hyperopt.pyll.base.Apply object>, 'rebalance': <hyperopt.pyll.base.Apply object>}}, algo=<function suggest>, max_evals=9223372036854775807, max_time=300, trials=<hyperopt.base.Trials object>, rstate=<mtrand.RandomState object>, allow_trials_fmin=False, pass_expr_memo_ctrl=None, catch_eval_exceptions=False, verbose=0, return_argmin=True, points_to_evaluate=None, max_queue_len=1, show_progressbar=False)
    426                     verbose=verbose,
    427                     max_queue_len=max_queue_len,
    428                     show_progressbar=show_progressbar,
    429                     max_time=max_time)
    430     rval.catch_eval_exceptions = catch_eval_exceptions
--> 431     rval.exhaust()
        rval.exhaust = <bound method FMinIter.exhaust of <hyperopt.fmin.FMinIter object>>
    432     if return_argmin:
    433         return trials.argmin
    434     elif len(trials) > 0:
    435         # Only if there are some succesfull trail runs, return the best point in the evaluation space

...........................................................................
/home/aquemy/dev/dp_hyperparameters/extension/hyperopt/fmin.py in exhaust(self=<hyperopt.fmin.FMinIter object>)
    273             raise StopIteration()
    274         return self.trials
    275 
    276     def exhaust(self):
    277         n_done = len(self.trials)
--> 278         self.run(self.max_evals - n_done, block_until_done=self.asynchronous)
        self.run = <bound method FMinIter.run of <hyperopt.fmin.FMinIter object>>
        self.max_evals = 9223372036854775807
        n_done = 0
        self.asynchronous = False
    279         self.trials.refresh()
    280         return self
    281 
    282 

...........................................................................
/home/aquemy/dev/dp_hyperparameters/extension/hyperopt/fmin.py in run(self=<hyperopt.fmin.FMinIter object>, N=9223372036854775807, block_until_done=False)
    232                     if self.asynchronous:
    233                         # -- wait for workers to fill in the trials
    234                         time.sleep(self.poll_interval_secs)
    235                     else:
    236                         # -- loop over trials and do the jobs directly
--> 237                         self.serial_evaluate()
        self.serial_evaluate = <bound method FMinIter.serial_evaluate of <hyperopt.fmin.FMinIter object>>
    238                     try:
    239                         res = [d['result']['loss'] for d in
    240                                          self.trials.trials if
    241                                          d['result']['status'] == 'ok']

...........................................................................
/home/aquemy/dev/dp_hyperparameters/extension/hyperopt/fmin.py in serial_evaluate(self=<hyperopt.fmin.FMinIter object>, N=-1)
    138                 trial['book_time'] = now
    139                 trial['refresh_time'] = now
    140                 spec = base.spec_from_misc(trial['misc'])
    141                 ctrl = base.Ctrl(self.trials, current_trial=trial)
    142                 try:
--> 143                     result = self.domain.evaluate(spec, ctrl)
        result = undefined
        self.domain.evaluate = <bound method Domain.evaluate of <hyperopt.base.Domain object>>
        spec = {'bootstrap': 0, 'criterion': 1, 'features': 2, 'features_SelectKBest_features__k': 0, 'max_depth': 4, 'max_features': 1, 'max_leaf_nodes': 3, 'min_samples_split': 1, 'n_estimators': 0, 'normalizer': 1, ...}
        ctrl = <hyperopt.base.Ctrl object>
    144                 except Exception as e:
    145                     logger.info('job exception: %s' % str(e))
    146                     trial['state'] = base.JOB_STATE_ERROR
    147                     trial['misc']['error'] = (str(type(e)), str(e))

...........................................................................
/home/aquemy/dev/dp_hyperparameters/extension/hyperopt/base.py in evaluate(self=<hyperopt.base.Domain object>, config={'bootstrap': 0, 'criterion': 1, 'features': 2, 'features_SelectKBest_features__k': 0, 'max_depth': 4, 'max_features': 1, 'max_leaf_nodes': 3, 'min_samples_split': 1, 'n_estimators': 0, 'normalizer': 1, ...}, ctrl=<hyperopt.base.Ctrl object>, attach_attachments=True)
    841             #    or the normal Python part (self.fn)
    842             pyll_rval = pyll.rec_eval(
    843                 self.expr,
    844                 memo=memo,
    845                 print_node_on_error=self.rec_eval_print_node_on_error)
--> 846             rval = self.fn(pyll_rval)
        rval = undefined
        self.fn = <functools.partial object>
        pyll_rval = {'algorithm': {'bootstrap': True, 'criterion': 'entropy', 'max_depth': None, 'max_features': 2, 'max_leaf_nodes': None, 'min_samples_split': 3, 'n_estimators': 10}, 'pipeline': {'features': ('features_SelectKBest', {'features__k': 1}), 'normalizer': ('normalizer_StandardScaler', {'normalizer__with_mean': False, 'normalizer__with_std': False}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 7})}}
    847 
    848         if isinstance(rval, (float, int, np.number)):
    849             dict_rval = {'loss': float(rval), 'status': STATUS_OK}
    850         else:

...........................................................................
/home/aquemy/dev/dp_hyperparameters/extension/experiment/objective.py in objective_joint(wconfig={'algorithm': {'bootstrap': True, 'criterion': 'entropy', 'max_depth': None, 'max_features': 2, 'max_leaf_nodes': None, 'min_samples_split': 3, 'n_estimators': 10}, 'pipeline': {'features': ('features_SelectKBest', {'features__k': 1}), 'normalizer': ('normalizer_StandardScaler', {'normalizer__with_mean': False, 'normalizer__with_std': False}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 7})}}, algorithm='RandomForest', X=array([[1.799e+01, 1.038e+01, 1.228e+02, ..., 2...., ..., 0.000e+00, 2.871e-01,
        7.039e-02]]), y=array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,... 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1]), context={'baseline_score': 0.9545944602886527, 'baseline_score_std': 0.03716322883281839, 'best_config': {'algorithm': {'bootstrap': False, 'criterion': 'entropy', 'max_depth': None, 'max_features': 2, 'max_leaf_nodes': None, 'min_samples_split': 5, 'n_estimators': 10}, 'config_hash': {'algorithm': 'e7a772c2bc361aa61cf7eeb364a26dca2c9b89d6', 'config': 'afb67da069b544b0505b1e8c150edc7498ad37b4', 'pipeline': 'a43db4b4fc4c38610b7b5e484840d2e583089ff4'}, 'duration': 1.0073001384735107, 'iteration': 26, 'loss': 0.04749913577046061, 'max_history_score': 0.9525008642295394, 'max_history_score_std': 0.02225295065716913, 'max_history_step': 'joint', 'pipeline': {'features': ('features_PCA', {'features__n_components': 4}), 'normalizer': ('normalizer_StandardScaler', {'normalizer__with_mean': True, 'normalizer__with_std': False}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 7})}, 'score': 0.9525008642295394, ...}, 'history': [{'algorithm': {'bootstrap': True, 'criterion': 'entropy', 'max_depth': 4, 'max_features': 3, 'max_leaf_nodes': 3, 'min_samples_split': 2, 'n_estimators': 10}, 'config_hash': {'algorithm': '42527c4120073c2a488d1b8df28732f486d1578c', 'config': '51144ca42f9ea5ab2d8d58606e3b3e4d89c6d7b3', 'pipeline': '52f07bda29f9d3a95fabb87e591d0b2581ca8209'}, 'duration': 0.26703310012817383, 'iteration': 0, 'loss': 0.06655431682654922, 'max_history_score': 0.9334456831734508, 'max_history_score_std': 0.03819399139659311, 'max_history_step': 'joint', 'pipeline': {'features': ('features_NoneType', {}), 'normalizer': ('normalizer_RobustScaler', {'normalizer__quantile_range': (...), 'normalizer__with_centering': False, 'normalizer__with_scaling': False}), 'rebalance': ('rebalance_NearMiss', {'rebalance__n_neighbors': 1})}, 'score': 0.9334456831734508, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': None, 'max_features': 2, 'max_leaf_nodes': 3, 'min_samples_split': 2, 'n_estimators': 100}, 'config_hash': {'algorithm': '1b32258c630f07e01ab481ab925ab80aa757e482', 'config': '9e54ffcb6a727de032a0a2cd45c5cc37cc150756', 'pipeline': '37e72d4a97f5e784c9d3133e6379b91bfc3be803'}, 'duration': 1.3065669536590576, 'iteration': 1, 'loss': 0.05436435917379645, 'max_history_score': 0.9456356408262035, 'max_history_score_std': 0.040053650785990214, 'max_history_step': 'joint', 'pipeline': {'features': ('features_NoneType', {}), 'normalizer': ('normalizer_StandardScaler', {'normalizer__with_mean': True, 'normalizer__with_std': True}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 6})}, 'score': 0.9456356408262035, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'entropy', 'max_depth': 1, 'max_features': 1, 'max_leaf_nodes': 2, 'min_samples_split': 3, 'n_estimators': 25}, 'config_hash': {'algorithm': '68ab9059aa7ec74e0da87c81734b9664243b3eb4', 'config': 'e5241eee9ddf3f4ee29a4711f5bcc92a4d24cd09', 'pipeline': '62463de065924498cdcd2f2f1f7e68535cdb33a5'}, 'duration': 0.6592490673065186, 'iteration': 2, 'loss': 0.07695856019358727, 'max_history_score': 0.9456356408262035, 'max_history_score_std': 0.040053650785990214, 'max_history_step': 'joint', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 1, 'features__selectkbest__k': 2}), 'normalizer': ('normalizer_NoneType', {}), 'rebalance': ('rebalance_NoneType', {})}, 'score': 0.9230414398064127, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': 3, 'max_features': 2, 'max_leaf_nodes': 2, 'min_samples_split': 2, 'n_estimators': 25}, 'config_hash': {'algorithm': 'e3f1f7d7783557a38f40f0476369091edd87092b', 'config': '18ee4d3d1627472ec190326308d8755371a6dc62', 'pipeline': 'c6d1263e344ed8c71b2e6e4ba8e0db2fb6c777c0'}, 'duration': 0.879349946975708, 'iteration': 3, 'loss': 0.07535973554576114, 'max_history_score': 0.9456356408262035, 'max_history_score_std': 0.040053650785990214, 'max_history_step': 'joint', 'pipeline': {'features': ('features_NoneType', {}), 'normalizer': ('normalizer_RobustScaler', {'normalizer__quantile_range': (...), 'normalizer__with_centering': True, 'normalizer__with_scaling': True}), 'rebalance': ('rebalance_NearMiss', {'rebalance__n_neighbors': 2})}, 'score': 0.9246402644542389, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'gini', 'max_depth': 4, 'max_features': 2, 'max_leaf_nodes': 5, 'min_samples_split': 2, 'n_estimators': 50}, 'config_hash': {'algorithm': '47581af7253940f9647ad16d37347d34baf13e5f', 'config': '2af4f82b045c0c48ecb89d42728d1039fbff8878', 'pipeline': '2928b22ed834303cb7bac6e6608531eaddd7df67'}, 'duration': 4.372632026672363, 'iteration': 4, 'loss': 0.09121294615849984, 'max_history_score': 0.9456356408262035, 'max_history_score_std': 0.040053650785990214, 'max_history_step': 'joint', 'pipeline': {'features': ('features_NoneType', {}), 'normalizer': ('normalizer_MinMaxScaler', {}), 'rebalance': ('rebalance_CondensedNearestNeighbour', {'rebalance__n_neighbors': 2})}, 'score': 0.9087870538415002, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'entropy', 'max_depth': 2, 'max_features': 2, 'max_leaf_nodes': None, 'min_samples_split': 2, 'n_estimators': 10}, 'config_hash': {'algorithm': '0a85f98ca2d06103287f153633d88f7a0535e7e8', 'config': '17b2a1e5814f3e933137158708a5b6e9b2475495', 'pipeline': '95defa3bdd8357f11f872d3c280d50a6d8ee398d'}, 'duration': 2.625814914703369, 'iteration': 5, 'loss': 0.15471329185031535, 'max_history_score': 0.9456356408262035, 'max_history_score_std': 0.040053650785990214, 'max_history_step': 'joint', 'pipeline': {'features': ('features_SelectKBest', {'features__k': 2}), 'normalizer': ('normalizer_StandardScaler', {'normalizer__with_mean': False, 'normalizer__with_std': False}), 'rebalance': ('rebalance_CondensedNearestNeighbour', {'rebalance__n_neighbors': 1})}, 'score': 0.8452867081496847, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': 3, 'max_features': None, 'max_leaf_nodes': None, 'min_samples_split': 5, 'n_estimators': 75}, 'config_hash': {'algorithm': 'd7466a2c1d5cb3fa95029d73dc030f4c3c45a159', 'config': 'fa020a592ec5ac234f9f91aac28abc2cd1ec9d33', 'pipeline': '71e0d26f923d42cfe0e2fa748931ef2afe72ed86'}, 'duration': 3.62078595161438, 'iteration': 6, 'loss': 0.17066372828623277, 'max_history_score': 0.9456356408262035, 'max_history_score_std': 0.040053650785990214, 'max_history_step': 'joint', 'pipeline': {'features': ('features_SelectKBest', {'features__k': 1}), 'normalizer': ('normalizer_RobustScaler', {'normalizer__quantile_range': (...), 'normalizer__with_centering': True, 'normalizer__with_scaling': True}), 'rebalance': ('rebalance_CondensedNearestNeighbour', {'rebalance__n_neighbors': 1})}, 'score': 0.8293362717137672, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'entropy', 'max_depth': 3, 'max_features': 3, 'max_leaf_nodes': 5, 'min_samples_split': 5, 'n_estimators': 50}, 'config_hash': {'algorithm': '735caa9785596076014572a24050cde8dc338973', 'config': '0da4498002d6f452c59bb61756abb3ded841e786', 'pipeline': '51a53ea6ef5a2521ee65f76eb2da220ab7086513'}, 'duration': 0.6934049129486084, 'iteration': 7, 'loss': 0.06125875032408601, 'max_history_score': 0.9456356408262035, 'max_history_score_std': 0.040053650785990214, 'max_history_step': 'joint', 'pipeline': {'features': ('features_NoneType', {}), 'normalizer': ('normalizer_NoneType', {}), 'rebalance': ('rebalance_NearMiss', {'rebalance__n_neighbors': 3})}, 'score': 0.938741249675914, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': 4, 'max_features': 2, 'max_leaf_nodes': None, 'min_samples_split': 3, 'n_estimators': 75}, 'config_hash': {'algorithm': 'e71a1fe9515b6805f07914a61f2e7594be9e9afe', 'config': '344e4756fb1bec455d6af51d3727e33b0d27725f', 'pipeline': '248dad1d8b30a17a5de1d0bbdfe3e2acb7a1962b'}, 'duration': 1.3036692142486572, 'iteration': 8, 'loss': 0.06483125918243893, 'max_history_score': 0.9456356408262035, 'max_history_score_std': 0.040053650785990214, 'max_history_step': 'joint', 'pipeline': {'features': ('features_PCA', {'features__n_components': 2}), 'normalizer': ('normalizer_StandardScaler', {'normalizer__with_mean': False, 'normalizer__with_std': True}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 7})}, 'score': 0.9351687408175611, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'entropy', 'max_depth': 2, 'max_features': 2, 'max_leaf_nodes': 2, 'min_samples_split': 3, 'n_estimators': 10}, 'config_hash': {'algorithm': '0a507823f2ad8605ed5950e1fe61df0560f11a00', 'config': '4a538fdcf8e07f90e92a421c0d5c479d651629c7', 'pipeline': '5240329df25c9a533d025c1a401d49835a501b41'}, 'duration': 1.3821029663085938, 'iteration': 9, 'loss': 0.07006416904329793, 'max_history_score': 0.9456356408262035, 'max_history_score_std': 0.040053650785990214, 'max_history_step': 'joint', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 4, 'features__selectkbest__k': 2}), 'normalizer': ('normalizer_PowerTransformer', {}), 'rebalance': ('rebalance_NearMiss', {'rebalance__n_neighbors': 1})}, 'score': 0.9299358309567021, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'gini', 'max_depth': 1, 'max_features': 3, 'max_leaf_nodes': 5, 'min_samples_split': 3, 'n_estimators': 10}, 'config_hash': {'algorithm': 'd32739750d351948f8ff34a87c7d55b0c5e0d90f', 'config': 'c1609e71f1ce8486335adc70bb69a955580ba2c8', 'pipeline': 'f48b42ec5cf999279659966160a16353b75bdaa3'}, 'duration': 0.9055681228637695, 'iteration': 10, 'loss': 0.07532840722495904, 'max_history_score': 0.9456356408262035, 'max_history_score_std': 0.040053650785990214, 'max_history_step': 'joint', 'pipeline': {'features': ('features_PCA', {'features__n_components': 4}), 'normalizer': ('normalizer_PowerTransformer', {}), 'rebalance': ('rebalance_NearMiss', {'rebalance__n_neighbors': 1})}, 'score': 0.924671592775041, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': 3, 'max_features': 1, 'max_leaf_nodes': 5, 'min_samples_split': 3, 'n_estimators': 25}, 'config_hash': {'algorithm': 'f69bac35e71cbec1bfc1fb5942328a3390e7c252', 'config': 'abe36f188644e53e56ed3224236fa157107ed3b2', 'pipeline': 'aaf976c7c663a31fa039582d42f9e07101556a7c'}, 'duration': 0.764197826385498, 'iteration': 11, 'loss': 0.06818446979517778, 'max_history_score': 0.9456356408262035, 'max_history_score_std': 0.040053650785990214, 'max_history_step': 'joint', 'pipeline': {'features': ('features_NoneType', {}), 'normalizer': ('normalizer_PowerTransformer', {}), 'rebalance': ('rebalance_NoneType', {})}, 'score': 0.9318155302048222, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'entropy', 'max_depth': None, 'max_features': None, 'max_leaf_nodes': None, 'min_samples_split': 5, 'n_estimators': 25}, 'config_hash': {'algorithm': 'a0a27aec00db5ddf71eab96663f9bd61c845f5e3', 'config': '76aa002c3c9d4d9722466c60daf5119c18a41d2a', 'pipeline': '1ce34b7894ef342571d974bb19e8ec821a512c6b'}, 'duration': 1.1636500358581543, 'iteration': 12, 'loss': 0.12833700630887557, 'max_history_score': 0.9456356408262035, 'max_history_score_std': 0.040053650785990214, 'max_history_step': 'joint', 'pipeline': {'features': ('features_PCA', {'features__n_components': 1}), 'normalizer': ('normalizer_PowerTransformer', {}), 'rebalance': ('rebalance_NoneType', {})}, 'score': 0.8716629936911244, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'gini', 'max_depth': 1, 'max_features': 2, 'max_leaf_nodes': 2, 'min_samples_split': 2, 'n_estimators': 100}, 'config_hash': {'algorithm': '985c99dff1da9b2c87e4211c5335a9159aa9dbcb', 'config': 'f56a7a9e43a0a699e992dc1262e550b8b7c88538', 'pipeline': '5c934f6d9a8ad1f9afe762986a9cf2074fc95d79'}, 'duration': 2.235443115234375, 'iteration': 13, 'loss': 0.11414635727249167, 'max_history_score': 0.9456356408262035, 'max_history_score_std': 0.040053650785990214, 'max_history_step': 'joint', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 1, 'features__selectkbest__k': 1}), 'normalizer': ('normalizer_RobustScaler', {'normalizer__quantile_range': (...), 'normalizer__with_centering': False, 'normalizer__with_scaling': True}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 6})}, 'score': 0.8858536427275083, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'gini', 'max_depth': 1, 'max_features': 1, 'max_leaf_nodes': None, 'min_samples_split': 5, 'n_estimators': 10}, 'config_hash': {'algorithm': '7d74a39aac2579264a402aef2b6fa7943c19f3d3', 'config': '53f44c0ad925c5c08c25d4fadf5e9ee9d7c181cd', 'pipeline': '6eff5ef31d7d1d534db31913bb67529c8a24c42e'}, 'duration': 2.7847659587860107, 'iteration': 14, 'loss': 0.14061986863711007, 'max_history_score': 0.9456356408262035, 'max_history_score_std': 0.040053650785990214, 'max_history_step': 'joint', 'pipeline': {'features': ('features_PCA', {'features__n_components': 1}), 'normalizer': ('normalizer_RobustScaler', {'normalizer__quantile_range': (...), 'normalizer__with_centering': True, 'normalizer__with_scaling': True}), 'rebalance': ('rebalance_CondensedNearestNeighbour', {'rebalance__n_neighbors': 3})}, 'score': 0.8593801313628899, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'entropy', 'max_depth': 3, 'max_features': None, 'max_leaf_nodes': 5, 'min_samples_split': 2, 'n_estimators': 100}, 'config_hash': {'algorithm': 'c62d7c671832e4414b6b2d7c36cba5ddc83a0ed0', 'config': '5faee50671eaa0ac586722bff234e36a857e662d', 'pipeline': '8b29a55de2add78c49114b9bbe5e800e5524c59d'}, 'duration': 2.3916029930114746, 'iteration': 15, 'loss': 0.08770093336790252, 'max_history_score': 0.9456356408262035, 'max_history_score_std': 0.040053650785990214, 'max_history_step': 'joint', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 3, 'features__selectkbest__k': 4}), 'normalizer': ('normalizer_RobustScaler', {'normalizer__quantile_range': (...), 'normalizer__with_centering': True, 'normalizer__with_scaling': True}), 'rebalance': ('rebalance_NoneType', {})}, 'score': 0.9122990666320975, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': None, 'max_features': 1, 'max_leaf_nodes': 5, 'min_samples_split': 5, 'n_estimators': 10}, 'config_hash': {'algorithm': '290772bfb9b8ed15c48a72829e822fb0a07481d6', 'config': '9a04f25d8eb3db5b2f831abd341a6d384c73a957', 'pipeline': '1ce34b7894ef342571d974bb19e8ec821a512c6b'}, 'duration': 1.4364500045776367, 'iteration': 16, 'loss': 0.08948880822746508, 'max_history_score': 0.9456356408262035, 'max_history_score_std': 0.040053650785990214, 'max_history_step': 'joint', 'pipeline': {'features': ('features_PCA', {'features__n_components': 1}), 'normalizer': ('normalizer_PowerTransformer', {}), 'rebalance': ('rebalance_NoneType', {})}, 'score': 0.9105111917725349, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': 2, 'max_features': 3, 'max_leaf_nodes': 3, 'min_samples_split': 3, 'n_estimators': 100}, 'config_hash': {'algorithm': '7dab6d47f897c2961d3402eff844aff16a7d142a', 'config': '4dbfa2688b239be9f372d3e80223960ba9a1fbdd', 'pipeline': 'cdef51702798fa49f11c11d80baf3ab43d5358fc'}, 'duration': 0.9830451011657715, 'iteration': 17, 'loss': 1.0, 'max_history_score': 0.9456356408262035, 'max_history_score_std': 0.040053650785990214, 'max_history_step': 'joint', 'pipeline': {'features': ('features_SelectKBest', {'features__k': 2}), 'normalizer': ('normalizer_PowerTransformer', {}), 'rebalance': ('rebalance_NearMiss', {'rebalance__n_neighbors': 1})}, 'score': 0.0, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'entropy', 'max_depth': None, 'max_features': 3, 'max_leaf_nodes': None, 'min_samples_split': 5, 'n_estimators': 10}, 'config_hash': {'algorithm': 'def83e48be05ef92a37e1a90585820f2f67ff42b', 'config': '95902552cb76e9798f0fa58782bd72bd1cc272d7', 'pipeline': '1775187bf23f94f4fd0cc1e5c1ef665210edded5'}, 'duration': 2.0033559799194336, 'iteration': 18, 'loss': 0.04922327370149515, 'max_history_score': 0.9507767262985048, 'max_history_score_std': 0.028328108925705902, 'max_history_step': 'joint', 'pipeline': {'features': ('features_PCA', {'features__n_components': 4}), 'normalizer': ('normalizer_StandardScaler', {'normalizer__with_mean': True, 'normalizer__with_std': True}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 5})}, 'score': 0.9507767262985048, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'gini', 'max_depth': 1, 'max_features': 3, 'max_leaf_nodes': None, 'min_samples_split': 2, 'n_estimators': 50}, 'config_hash': {'algorithm': '4e9e3275f817df75115d9d7e3366980fc1b4cf13', 'config': '7770b19007b40bf13005d52eb81f87bc401f15b4', 'pipeline': 'c4dd111513ea35f97dd3aec3e8e7f6268ce035da'}, 'duration': 0.9069631099700928, 'iteration': 19, 'loss': 1.0, 'max_history_score': 0.9507767262985048, 'max_history_score_std': 0.028328108925705902, 'max_history_step': 'joint', 'pipeline': {'features': ('features_PCA', {'features__n_components': 2}), 'normalizer': ('normalizer_RobustScaler', {'normalizer__quantile_range': (...), 'normalizer__with_centering': False, 'normalizer__with_scaling': True}), 'rebalance': ('rebalance_NearMiss', {'rebalance__n_neighbors': 2})}, 'score': 0.0, ...}, ...], 'history_hash': ['51144ca42f9ea5ab2d8d58606e3b3e4d89c6d7b3', '9e54ffcb6a727de032a0a2cd45c5cc37cc150756', 'e5241eee9ddf3f4ee29a4711f5bcc92a4d24cd09', '18ee4d3d1627472ec190326308d8755371a6dc62', '2af4f82b045c0c48ecb89d42728d1039fbff8878', '17b2a1e5814f3e933137158708a5b6e9b2475495', 'fa020a592ec5ac234f9f91aac28abc2cd1ec9d33', '0da4498002d6f452c59bb61756abb3ded841e786', '344e4756fb1bec455d6af51d3727e33b0d27725f', '4a538fdcf8e07f90e92a421c0d5c479d651629c7', 'c1609e71f1ce8486335adc70bb69a955580ba2c8', 'abe36f188644e53e56ed3224236fa157107ed3b2', '76aa002c3c9d4d9722466c60daf5119c18a41d2a', 'f56a7a9e43a0a699e992dc1262e550b8b7c88538', '53f44c0ad925c5c08c25d4fadf5e9ee9d7c181cd', '5faee50671eaa0ac586722bff234e36a857e662d', '9a04f25d8eb3db5b2f831abd341a6d384c73a957', '4dbfa2688b239be9f372d3e80223960ba9a1fbdd', '95902552cb76e9798f0fa58782bd72bd1cc272d7', '7770b19007b40bf13005d52eb81f87bc401f15b4', ...], 'history_index': {'0da4498002d6f452c59bb61756abb3ded841e786': 7, '127553d555ed39231b8da3a1ce42d3902e30919b': 59, '17b2a1e5814f3e933137158708a5b6e9b2475495': 5, '18ee4d3d1627472ec190326308d8755371a6dc62': 3, '1b2267555a9226d7eb4df3c63dd12506da370f4d': 56, '2af4f82b045c0c48ecb89d42728d1039fbff8878': 4, '2d054540972225f4f17fb36d63106b7bb5c406fe': 36, '306511091d7e5d6431b5e5a6320802c4c04cde44': 33, '312e05571f41c77895a9ad8c57db6947f3fdfe03': 58, '344e4756fb1bec455d6af51d3727e33b0d27725f': 8, ...}, 'iteration': 59, 'max_history_score': 0.9525008642295394, 'max_history_score_std': 0.02225295065716913, 'max_history_step': 'joint'}, config={'algorithm': 'RandomForest', 'seed': 42, 'time': 300})
    108 
    109 def objective_algo(algo_config, current_pipeline_config, algorithm, X, y, context, config):
    110     return objective(current_pipeline_config, algo_config, algorithm, X, y, context, config, step='algorithm')
    111 
    112 def objective_joint(wconfig, algorithm, X, y, context, config):
--> 113     return objective(wconfig['pipeline'], wconfig['algorithm'], algorithm, X, y, context, config, step='joint')
        wconfig = {'algorithm': {'bootstrap': True, 'criterion': 'entropy', 'max_depth': None, 'max_features': 2, 'max_leaf_nodes': None, 'min_samples_split': 3, 'n_estimators': 10}, 'pipeline': {'features': ('features_SelectKBest', {'features__k': 1}), 'normalizer': ('normalizer_StandardScaler', {'normalizer__with_mean': False, 'normalizer__with_std': False}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 7})}}
        algorithm = 'RandomForest'
        X = array([[1.799e+01, 1.038e+01, 1.228e+02, ..., 2...., ..., 0.000e+00, 2.871e-01,
        7.039e-02]])
        y = array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,... 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1])
        context = {'baseline_score': 0.9545944602886527, 'baseline_score_std': 0.03716322883281839, 'best_config': {'algorithm': {'bootstrap': False, 'criterion': 'entropy', 'max_depth': None, 'max_features': 2, 'max_leaf_nodes': None, 'min_samples_split': 5, 'n_estimators': 10}, 'config_hash': {'algorithm': 'e7a772c2bc361aa61cf7eeb364a26dca2c9b89d6', 'config': 'afb67da069b544b0505b1e8c150edc7498ad37b4', 'pipeline': 'a43db4b4fc4c38610b7b5e484840d2e583089ff4'}, 'duration': 1.0073001384735107, 'iteration': 26, 'loss': 0.04749913577046061, 'max_history_score': 0.9525008642295394, 'max_history_score_std': 0.02225295065716913, 'max_history_step': 'joint', 'pipeline': {'features': ('features_PCA', {'features__n_components': 4}), 'normalizer': ('normalizer_StandardScaler', {'normalizer__with_mean': True, 'normalizer__with_std': False}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 7})}, 'score': 0.9525008642295394, ...}, 'history': [{'algorithm': {'bootstrap': True, 'criterion': 'entropy', 'max_depth': 4, 'max_features': 3, 'max_leaf_nodes': 3, 'min_samples_split': 2, 'n_estimators': 10}, 'config_hash': {'algorithm': '42527c4120073c2a488d1b8df28732f486d1578c', 'config': '51144ca42f9ea5ab2d8d58606e3b3e4d89c6d7b3', 'pipeline': '52f07bda29f9d3a95fabb87e591d0b2581ca8209'}, 'duration': 0.26703310012817383, 'iteration': 0, 'loss': 0.06655431682654922, 'max_history_score': 0.9334456831734508, 'max_history_score_std': 0.03819399139659311, 'max_history_step': 'joint', 'pipeline': {'features': ('features_NoneType', {}), 'normalizer': ('normalizer_RobustScaler', {'normalizer__quantile_range': (...), 'normalizer__with_centering': False, 'normalizer__with_scaling': False}), 'rebalance': ('rebalance_NearMiss', {'rebalance__n_neighbors': 1})}, 'score': 0.9334456831734508, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': None, 'max_features': 2, 'max_leaf_nodes': 3, 'min_samples_split': 2, 'n_estimators': 100}, 'config_hash': {'algorithm': '1b32258c630f07e01ab481ab925ab80aa757e482', 'config': '9e54ffcb6a727de032a0a2cd45c5cc37cc150756', 'pipeline': '37e72d4a97f5e784c9d3133e6379b91bfc3be803'}, 'duration': 1.3065669536590576, 'iteration': 1, 'loss': 0.05436435917379645, 'max_history_score': 0.9456356408262035, 'max_history_score_std': 0.040053650785990214, 'max_history_step': 'joint', 'pipeline': {'features': ('features_NoneType', {}), 'normalizer': ('normalizer_StandardScaler', {'normalizer__with_mean': True, 'normalizer__with_std': True}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 6})}, 'score': 0.9456356408262035, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'entropy', 'max_depth': 1, 'max_features': 1, 'max_leaf_nodes': 2, 'min_samples_split': 3, 'n_estimators': 25}, 'config_hash': {'algorithm': '68ab9059aa7ec74e0da87c81734b9664243b3eb4', 'config': 'e5241eee9ddf3f4ee29a4711f5bcc92a4d24cd09', 'pipeline': '62463de065924498cdcd2f2f1f7e68535cdb33a5'}, 'duration': 0.6592490673065186, 'iteration': 2, 'loss': 0.07695856019358727, 'max_history_score': 0.9456356408262035, 'max_history_score_std': 0.040053650785990214, 'max_history_step': 'joint', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 1, 'features__selectkbest__k': 2}), 'normalizer': ('normalizer_NoneType', {}), 'rebalance': ('rebalance_NoneType', {})}, 'score': 0.9230414398064127, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': 3, 'max_features': 2, 'max_leaf_nodes': 2, 'min_samples_split': 2, 'n_estimators': 25}, 'config_hash': {'algorithm': 'e3f1f7d7783557a38f40f0476369091edd87092b', 'config': '18ee4d3d1627472ec190326308d8755371a6dc62', 'pipeline': 'c6d1263e344ed8c71b2e6e4ba8e0db2fb6c777c0'}, 'duration': 0.879349946975708, 'iteration': 3, 'loss': 0.07535973554576114, 'max_history_score': 0.9456356408262035, 'max_history_score_std': 0.040053650785990214, 'max_history_step': 'joint', 'pipeline': {'features': ('features_NoneType', {}), 'normalizer': ('normalizer_RobustScaler', {'normalizer__quantile_range': (...), 'normalizer__with_centering': True, 'normalizer__with_scaling': True}), 'rebalance': ('rebalance_NearMiss', {'rebalance__n_neighbors': 2})}, 'score': 0.9246402644542389, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'gini', 'max_depth': 4, 'max_features': 2, 'max_leaf_nodes': 5, 'min_samples_split': 2, 'n_estimators': 50}, 'config_hash': {'algorithm': '47581af7253940f9647ad16d37347d34baf13e5f', 'config': '2af4f82b045c0c48ecb89d42728d1039fbff8878', 'pipeline': '2928b22ed834303cb7bac6e6608531eaddd7df67'}, 'duration': 4.372632026672363, 'iteration': 4, 'loss': 0.09121294615849984, 'max_history_score': 0.9456356408262035, 'max_history_score_std': 0.040053650785990214, 'max_history_step': 'joint', 'pipeline': {'features': ('features_NoneType', {}), 'normalizer': ('normalizer_MinMaxScaler', {}), 'rebalance': ('rebalance_CondensedNearestNeighbour', {'rebalance__n_neighbors': 2})}, 'score': 0.9087870538415002, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'entropy', 'max_depth': 2, 'max_features': 2, 'max_leaf_nodes': None, 'min_samples_split': 2, 'n_estimators': 10}, 'config_hash': {'algorithm': '0a85f98ca2d06103287f153633d88f7a0535e7e8', 'config': '17b2a1e5814f3e933137158708a5b6e9b2475495', 'pipeline': '95defa3bdd8357f11f872d3c280d50a6d8ee398d'}, 'duration': 2.625814914703369, 'iteration': 5, 'loss': 0.15471329185031535, 'max_history_score': 0.9456356408262035, 'max_history_score_std': 0.040053650785990214, 'max_history_step': 'joint', 'pipeline': {'features': ('features_SelectKBest', {'features__k': 2}), 'normalizer': ('normalizer_StandardScaler', {'normalizer__with_mean': False, 'normalizer__with_std': False}), 'rebalance': ('rebalance_CondensedNearestNeighbour', {'rebalance__n_neighbors': 1})}, 'score': 0.8452867081496847, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': 3, 'max_features': None, 'max_leaf_nodes': None, 'min_samples_split': 5, 'n_estimators': 75}, 'config_hash': {'algorithm': 'd7466a2c1d5cb3fa95029d73dc030f4c3c45a159', 'config': 'fa020a592ec5ac234f9f91aac28abc2cd1ec9d33', 'pipeline': '71e0d26f923d42cfe0e2fa748931ef2afe72ed86'}, 'duration': 3.62078595161438, 'iteration': 6, 'loss': 0.17066372828623277, 'max_history_score': 0.9456356408262035, 'max_history_score_std': 0.040053650785990214, 'max_history_step': 'joint', 'pipeline': {'features': ('features_SelectKBest', {'features__k': 1}), 'normalizer': ('normalizer_RobustScaler', {'normalizer__quantile_range': (...), 'normalizer__with_centering': True, 'normalizer__with_scaling': True}), 'rebalance': ('rebalance_CondensedNearestNeighbour', {'rebalance__n_neighbors': 1})}, 'score': 0.8293362717137672, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'entropy', 'max_depth': 3, 'max_features': 3, 'max_leaf_nodes': 5, 'min_samples_split': 5, 'n_estimators': 50}, 'config_hash': {'algorithm': '735caa9785596076014572a24050cde8dc338973', 'config': '0da4498002d6f452c59bb61756abb3ded841e786', 'pipeline': '51a53ea6ef5a2521ee65f76eb2da220ab7086513'}, 'duration': 0.6934049129486084, 'iteration': 7, 'loss': 0.06125875032408601, 'max_history_score': 0.9456356408262035, 'max_history_score_std': 0.040053650785990214, 'max_history_step': 'joint', 'pipeline': {'features': ('features_NoneType', {}), 'normalizer': ('normalizer_NoneType', {}), 'rebalance': ('rebalance_NearMiss', {'rebalance__n_neighbors': 3})}, 'score': 0.938741249675914, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': 4, 'max_features': 2, 'max_leaf_nodes': None, 'min_samples_split': 3, 'n_estimators': 75}, 'config_hash': {'algorithm': 'e71a1fe9515b6805f07914a61f2e7594be9e9afe', 'config': '344e4756fb1bec455d6af51d3727e33b0d27725f', 'pipeline': '248dad1d8b30a17a5de1d0bbdfe3e2acb7a1962b'}, 'duration': 1.3036692142486572, 'iteration': 8, 'loss': 0.06483125918243893, 'max_history_score': 0.9456356408262035, 'max_history_score_std': 0.040053650785990214, 'max_history_step': 'joint', 'pipeline': {'features': ('features_PCA', {'features__n_components': 2}), 'normalizer': ('normalizer_StandardScaler', {'normalizer__with_mean': False, 'normalizer__with_std': True}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 7})}, 'score': 0.9351687408175611, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'entropy', 'max_depth': 2, 'max_features': 2, 'max_leaf_nodes': 2, 'min_samples_split': 3, 'n_estimators': 10}, 'config_hash': {'algorithm': '0a507823f2ad8605ed5950e1fe61df0560f11a00', 'config': '4a538fdcf8e07f90e92a421c0d5c479d651629c7', 'pipeline': '5240329df25c9a533d025c1a401d49835a501b41'}, 'duration': 1.3821029663085938, 'iteration': 9, 'loss': 0.07006416904329793, 'max_history_score': 0.9456356408262035, 'max_history_score_std': 0.040053650785990214, 'max_history_step': 'joint', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 4, 'features__selectkbest__k': 2}), 'normalizer': ('normalizer_PowerTransformer', {}), 'rebalance': ('rebalance_NearMiss', {'rebalance__n_neighbors': 1})}, 'score': 0.9299358309567021, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'gini', 'max_depth': 1, 'max_features': 3, 'max_leaf_nodes': 5, 'min_samples_split': 3, 'n_estimators': 10}, 'config_hash': {'algorithm': 'd32739750d351948f8ff34a87c7d55b0c5e0d90f', 'config': 'c1609e71f1ce8486335adc70bb69a955580ba2c8', 'pipeline': 'f48b42ec5cf999279659966160a16353b75bdaa3'}, 'duration': 0.9055681228637695, 'iteration': 10, 'loss': 0.07532840722495904, 'max_history_score': 0.9456356408262035, 'max_history_score_std': 0.040053650785990214, 'max_history_step': 'joint', 'pipeline': {'features': ('features_PCA', {'features__n_components': 4}), 'normalizer': ('normalizer_PowerTransformer', {}), 'rebalance': ('rebalance_NearMiss', {'rebalance__n_neighbors': 1})}, 'score': 0.924671592775041, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': 3, 'max_features': 1, 'max_leaf_nodes': 5, 'min_samples_split': 3, 'n_estimators': 25}, 'config_hash': {'algorithm': 'f69bac35e71cbec1bfc1fb5942328a3390e7c252', 'config': 'abe36f188644e53e56ed3224236fa157107ed3b2', 'pipeline': 'aaf976c7c663a31fa039582d42f9e07101556a7c'}, 'duration': 0.764197826385498, 'iteration': 11, 'loss': 0.06818446979517778, 'max_history_score': 0.9456356408262035, 'max_history_score_std': 0.040053650785990214, 'max_history_step': 'joint', 'pipeline': {'features': ('features_NoneType', {}), 'normalizer': ('normalizer_PowerTransformer', {}), 'rebalance': ('rebalance_NoneType', {})}, 'score': 0.9318155302048222, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'entropy', 'max_depth': None, 'max_features': None, 'max_leaf_nodes': None, 'min_samples_split': 5, 'n_estimators': 25}, 'config_hash': {'algorithm': 'a0a27aec00db5ddf71eab96663f9bd61c845f5e3', 'config': '76aa002c3c9d4d9722466c60daf5119c18a41d2a', 'pipeline': '1ce34b7894ef342571d974bb19e8ec821a512c6b'}, 'duration': 1.1636500358581543, 'iteration': 12, 'loss': 0.12833700630887557, 'max_history_score': 0.9456356408262035, 'max_history_score_std': 0.040053650785990214, 'max_history_step': 'joint', 'pipeline': {'features': ('features_PCA', {'features__n_components': 1}), 'normalizer': ('normalizer_PowerTransformer', {}), 'rebalance': ('rebalance_NoneType', {})}, 'score': 0.8716629936911244, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'gini', 'max_depth': 1, 'max_features': 2, 'max_leaf_nodes': 2, 'min_samples_split': 2, 'n_estimators': 100}, 'config_hash': {'algorithm': '985c99dff1da9b2c87e4211c5335a9159aa9dbcb', 'config': 'f56a7a9e43a0a699e992dc1262e550b8b7c88538', 'pipeline': '5c934f6d9a8ad1f9afe762986a9cf2074fc95d79'}, 'duration': 2.235443115234375, 'iteration': 13, 'loss': 0.11414635727249167, 'max_history_score': 0.9456356408262035, 'max_history_score_std': 0.040053650785990214, 'max_history_step': 'joint', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 1, 'features__selectkbest__k': 1}), 'normalizer': ('normalizer_RobustScaler', {'normalizer__quantile_range': (...), 'normalizer__with_centering': False, 'normalizer__with_scaling': True}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 6})}, 'score': 0.8858536427275083, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'gini', 'max_depth': 1, 'max_features': 1, 'max_leaf_nodes': None, 'min_samples_split': 5, 'n_estimators': 10}, 'config_hash': {'algorithm': '7d74a39aac2579264a402aef2b6fa7943c19f3d3', 'config': '53f44c0ad925c5c08c25d4fadf5e9ee9d7c181cd', 'pipeline': '6eff5ef31d7d1d534db31913bb67529c8a24c42e'}, 'duration': 2.7847659587860107, 'iteration': 14, 'loss': 0.14061986863711007, 'max_history_score': 0.9456356408262035, 'max_history_score_std': 0.040053650785990214, 'max_history_step': 'joint', 'pipeline': {'features': ('features_PCA', {'features__n_components': 1}), 'normalizer': ('normalizer_RobustScaler', {'normalizer__quantile_range': (...), 'normalizer__with_centering': True, 'normalizer__with_scaling': True}), 'rebalance': ('rebalance_CondensedNearestNeighbour', {'rebalance__n_neighbors': 3})}, 'score': 0.8593801313628899, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'entropy', 'max_depth': 3, 'max_features': None, 'max_leaf_nodes': 5, 'min_samples_split': 2, 'n_estimators': 100}, 'config_hash': {'algorithm': 'c62d7c671832e4414b6b2d7c36cba5ddc83a0ed0', 'config': '5faee50671eaa0ac586722bff234e36a857e662d', 'pipeline': '8b29a55de2add78c49114b9bbe5e800e5524c59d'}, 'duration': 2.3916029930114746, 'iteration': 15, 'loss': 0.08770093336790252, 'max_history_score': 0.9456356408262035, 'max_history_score_std': 0.040053650785990214, 'max_history_step': 'joint', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 3, 'features__selectkbest__k': 4}), 'normalizer': ('normalizer_RobustScaler', {'normalizer__quantile_range': (...), 'normalizer__with_centering': True, 'normalizer__with_scaling': True}), 'rebalance': ('rebalance_NoneType', {})}, 'score': 0.9122990666320975, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': None, 'max_features': 1, 'max_leaf_nodes': 5, 'min_samples_split': 5, 'n_estimators': 10}, 'config_hash': {'algorithm': '290772bfb9b8ed15c48a72829e822fb0a07481d6', 'config': '9a04f25d8eb3db5b2f831abd341a6d384c73a957', 'pipeline': '1ce34b7894ef342571d974bb19e8ec821a512c6b'}, 'duration': 1.4364500045776367, 'iteration': 16, 'loss': 0.08948880822746508, 'max_history_score': 0.9456356408262035, 'max_history_score_std': 0.040053650785990214, 'max_history_step': 'joint', 'pipeline': {'features': ('features_PCA', {'features__n_components': 1}), 'normalizer': ('normalizer_PowerTransformer', {}), 'rebalance': ('rebalance_NoneType', {})}, 'score': 0.9105111917725349, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': 2, 'max_features': 3, 'max_leaf_nodes': 3, 'min_samples_split': 3, 'n_estimators': 100}, 'config_hash': {'algorithm': '7dab6d47f897c2961d3402eff844aff16a7d142a', 'config': '4dbfa2688b239be9f372d3e80223960ba9a1fbdd', 'pipeline': 'cdef51702798fa49f11c11d80baf3ab43d5358fc'}, 'duration': 0.9830451011657715, 'iteration': 17, 'loss': 1.0, 'max_history_score': 0.9456356408262035, 'max_history_score_std': 0.040053650785990214, 'max_history_step': 'joint', 'pipeline': {'features': ('features_SelectKBest', {'features__k': 2}), 'normalizer': ('normalizer_PowerTransformer', {}), 'rebalance': ('rebalance_NearMiss', {'rebalance__n_neighbors': 1})}, 'score': 0.0, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'entropy', 'max_depth': None, 'max_features': 3, 'max_leaf_nodes': None, 'min_samples_split': 5, 'n_estimators': 10}, 'config_hash': {'algorithm': 'def83e48be05ef92a37e1a90585820f2f67ff42b', 'config': '95902552cb76e9798f0fa58782bd72bd1cc272d7', 'pipeline': '1775187bf23f94f4fd0cc1e5c1ef665210edded5'}, 'duration': 2.0033559799194336, 'iteration': 18, 'loss': 0.04922327370149515, 'max_history_score': 0.9507767262985048, 'max_history_score_std': 0.028328108925705902, 'max_history_step': 'joint', 'pipeline': {'features': ('features_PCA', {'features__n_components': 4}), 'normalizer': ('normalizer_StandardScaler', {'normalizer__with_mean': True, 'normalizer__with_std': True}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 5})}, 'score': 0.9507767262985048, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'gini', 'max_depth': 1, 'max_features': 3, 'max_leaf_nodes': None, 'min_samples_split': 2, 'n_estimators': 50}, 'config_hash': {'algorithm': '4e9e3275f817df75115d9d7e3366980fc1b4cf13', 'config': '7770b19007b40bf13005d52eb81f87bc401f15b4', 'pipeline': 'c4dd111513ea35f97dd3aec3e8e7f6268ce035da'}, 'duration': 0.9069631099700928, 'iteration': 19, 'loss': 1.0, 'max_history_score': 0.9507767262985048, 'max_history_score_std': 0.028328108925705902, 'max_history_step': 'joint', 'pipeline': {'features': ('features_PCA', {'features__n_components': 2}), 'normalizer': ('normalizer_RobustScaler', {'normalizer__quantile_range': (...), 'normalizer__with_centering': False, 'normalizer__with_scaling': True}), 'rebalance': ('rebalance_NearMiss', {'rebalance__n_neighbors': 2})}, 'score': 0.0, ...}, ...], 'history_hash': ['51144ca42f9ea5ab2d8d58606e3b3e4d89c6d7b3', '9e54ffcb6a727de032a0a2cd45c5cc37cc150756', 'e5241eee9ddf3f4ee29a4711f5bcc92a4d24cd09', '18ee4d3d1627472ec190326308d8755371a6dc62', '2af4f82b045c0c48ecb89d42728d1039fbff8878', '17b2a1e5814f3e933137158708a5b6e9b2475495', 'fa020a592ec5ac234f9f91aac28abc2cd1ec9d33', '0da4498002d6f452c59bb61756abb3ded841e786', '344e4756fb1bec455d6af51d3727e33b0d27725f', '4a538fdcf8e07f90e92a421c0d5c479d651629c7', 'c1609e71f1ce8486335adc70bb69a955580ba2c8', 'abe36f188644e53e56ed3224236fa157107ed3b2', '76aa002c3c9d4d9722466c60daf5119c18a41d2a', 'f56a7a9e43a0a699e992dc1262e550b8b7c88538', '53f44c0ad925c5c08c25d4fadf5e9ee9d7c181cd', '5faee50671eaa0ac586722bff234e36a857e662d', '9a04f25d8eb3db5b2f831abd341a6d384c73a957', '4dbfa2688b239be9f372d3e80223960ba9a1fbdd', '95902552cb76e9798f0fa58782bd72bd1cc272d7', '7770b19007b40bf13005d52eb81f87bc401f15b4', ...], 'history_index': {'0da4498002d6f452c59bb61756abb3ded841e786': 7, '127553d555ed39231b8da3a1ce42d3902e30919b': 59, '17b2a1e5814f3e933137158708a5b6e9b2475495': 5, '18ee4d3d1627472ec190326308d8755371a6dc62': 3, '1b2267555a9226d7eb4df3c63dd12506da370f4d': 56, '2af4f82b045c0c48ecb89d42728d1039fbff8878': 4, '2d054540972225f4f17fb36d63106b7bb5c406fe': 36, '306511091d7e5d6431b5e5a6320802c4c04cde44': 33, '312e05571f41c77895a9ad8c57db6947f3fdfe03': 58, '344e4756fb1bec455d6af51d3727e33b0d27725f': 8, ...}, 'iteration': 59, 'max_history_score': 0.9525008642295394, 'max_history_score_std': 0.02225295065716913, 'max_history_step': 'joint'}
        config = {'algorithm': 'RandomForest', 'seed': 42, 'time': 300}
    114 
    115 
    116 def get_baseline_score(algorithm, X, y, seed):
    117     pipeline, _ = pipeline_conf_to_full_pipeline(

...........................................................................
/home/aquemy/dev/dp_hyperparameters/extension/experiment/objective.py in objective(pipeline_config={'features': ('features_SelectKBest', {'features__k': 1}), 'normalizer': ('normalizer_StandardScaler', {'normalizer__with_mean': False, 'normalizer__with_std': False}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 7})}, algo_config={'bootstrap': True, 'criterion': 'entropy', 'max_depth': None, 'max_features': 2, 'max_leaf_nodes': None, 'min_samples_split': 3, 'n_estimators': 10}, algorithm='RandomForest', X=array([[1.799e+01, 1.038e+01, 1.228e+02, ..., 2...., ..., 0.000e+00, 2.871e-01,
        7.039e-02]]), y=array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,... 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1]), context={'baseline_score': 0.9545944602886527, 'baseline_score_std': 0.03716322883281839, 'best_config': {'algorithm': {'bootstrap': False, 'criterion': 'entropy', 'max_depth': None, 'max_features': 2, 'max_leaf_nodes': None, 'min_samples_split': 5, 'n_estimators': 10}, 'config_hash': {'algorithm': 'e7a772c2bc361aa61cf7eeb364a26dca2c9b89d6', 'config': 'afb67da069b544b0505b1e8c150edc7498ad37b4', 'pipeline': 'a43db4b4fc4c38610b7b5e484840d2e583089ff4'}, 'duration': 1.0073001384735107, 'iteration': 26, 'loss': 0.04749913577046061, 'max_history_score': 0.9525008642295394, 'max_history_score_std': 0.02225295065716913, 'max_history_step': 'joint', 'pipeline': {'features': ('features_PCA', {'features__n_components': 4}), 'normalizer': ('normalizer_StandardScaler', {'normalizer__with_mean': True, 'normalizer__with_std': False}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 7})}, 'score': 0.9525008642295394, ...}, 'history': [{'algorithm': {'bootstrap': True, 'criterion': 'entropy', 'max_depth': 4, 'max_features': 3, 'max_leaf_nodes': 3, 'min_samples_split': 2, 'n_estimators': 10}, 'config_hash': {'algorithm': '42527c4120073c2a488d1b8df28732f486d1578c', 'config': '51144ca42f9ea5ab2d8d58606e3b3e4d89c6d7b3', 'pipeline': '52f07bda29f9d3a95fabb87e591d0b2581ca8209'}, 'duration': 0.26703310012817383, 'iteration': 0, 'loss': 0.06655431682654922, 'max_history_score': 0.9334456831734508, 'max_history_score_std': 0.03819399139659311, 'max_history_step': 'joint', 'pipeline': {'features': ('features_NoneType', {}), 'normalizer': ('normalizer_RobustScaler', {'normalizer__quantile_range': (...), 'normalizer__with_centering': False, 'normalizer__with_scaling': False}), 'rebalance': ('rebalance_NearMiss', {'rebalance__n_neighbors': 1})}, 'score': 0.9334456831734508, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': None, 'max_features': 2, 'max_leaf_nodes': 3, 'min_samples_split': 2, 'n_estimators': 100}, 'config_hash': {'algorithm': '1b32258c630f07e01ab481ab925ab80aa757e482', 'config': '9e54ffcb6a727de032a0a2cd45c5cc37cc150756', 'pipeline': '37e72d4a97f5e784c9d3133e6379b91bfc3be803'}, 'duration': 1.3065669536590576, 'iteration': 1, 'loss': 0.05436435917379645, 'max_history_score': 0.9456356408262035, 'max_history_score_std': 0.040053650785990214, 'max_history_step': 'joint', 'pipeline': {'features': ('features_NoneType', {}), 'normalizer': ('normalizer_StandardScaler', {'normalizer__with_mean': True, 'normalizer__with_std': True}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 6})}, 'score': 0.9456356408262035, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'entropy', 'max_depth': 1, 'max_features': 1, 'max_leaf_nodes': 2, 'min_samples_split': 3, 'n_estimators': 25}, 'config_hash': {'algorithm': '68ab9059aa7ec74e0da87c81734b9664243b3eb4', 'config': 'e5241eee9ddf3f4ee29a4711f5bcc92a4d24cd09', 'pipeline': '62463de065924498cdcd2f2f1f7e68535cdb33a5'}, 'duration': 0.6592490673065186, 'iteration': 2, 'loss': 0.07695856019358727, 'max_history_score': 0.9456356408262035, 'max_history_score_std': 0.040053650785990214, 'max_history_step': 'joint', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 1, 'features__selectkbest__k': 2}), 'normalizer': ('normalizer_NoneType', {}), 'rebalance': ('rebalance_NoneType', {})}, 'score': 0.9230414398064127, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': 3, 'max_features': 2, 'max_leaf_nodes': 2, 'min_samples_split': 2, 'n_estimators': 25}, 'config_hash': {'algorithm': 'e3f1f7d7783557a38f40f0476369091edd87092b', 'config': '18ee4d3d1627472ec190326308d8755371a6dc62', 'pipeline': 'c6d1263e344ed8c71b2e6e4ba8e0db2fb6c777c0'}, 'duration': 0.879349946975708, 'iteration': 3, 'loss': 0.07535973554576114, 'max_history_score': 0.9456356408262035, 'max_history_score_std': 0.040053650785990214, 'max_history_step': 'joint', 'pipeline': {'features': ('features_NoneType', {}), 'normalizer': ('normalizer_RobustScaler', {'normalizer__quantile_range': (...), 'normalizer__with_centering': True, 'normalizer__with_scaling': True}), 'rebalance': ('rebalance_NearMiss', {'rebalance__n_neighbors': 2})}, 'score': 0.9246402644542389, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'gini', 'max_depth': 4, 'max_features': 2, 'max_leaf_nodes': 5, 'min_samples_split': 2, 'n_estimators': 50}, 'config_hash': {'algorithm': '47581af7253940f9647ad16d37347d34baf13e5f', 'config': '2af4f82b045c0c48ecb89d42728d1039fbff8878', 'pipeline': '2928b22ed834303cb7bac6e6608531eaddd7df67'}, 'duration': 4.372632026672363, 'iteration': 4, 'loss': 0.09121294615849984, 'max_history_score': 0.9456356408262035, 'max_history_score_std': 0.040053650785990214, 'max_history_step': 'joint', 'pipeline': {'features': ('features_NoneType', {}), 'normalizer': ('normalizer_MinMaxScaler', {}), 'rebalance': ('rebalance_CondensedNearestNeighbour', {'rebalance__n_neighbors': 2})}, 'score': 0.9087870538415002, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'entropy', 'max_depth': 2, 'max_features': 2, 'max_leaf_nodes': None, 'min_samples_split': 2, 'n_estimators': 10}, 'config_hash': {'algorithm': '0a85f98ca2d06103287f153633d88f7a0535e7e8', 'config': '17b2a1e5814f3e933137158708a5b6e9b2475495', 'pipeline': '95defa3bdd8357f11f872d3c280d50a6d8ee398d'}, 'duration': 2.625814914703369, 'iteration': 5, 'loss': 0.15471329185031535, 'max_history_score': 0.9456356408262035, 'max_history_score_std': 0.040053650785990214, 'max_history_step': 'joint', 'pipeline': {'features': ('features_SelectKBest', {'features__k': 2}), 'normalizer': ('normalizer_StandardScaler', {'normalizer__with_mean': False, 'normalizer__with_std': False}), 'rebalance': ('rebalance_CondensedNearestNeighbour', {'rebalance__n_neighbors': 1})}, 'score': 0.8452867081496847, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': 3, 'max_features': None, 'max_leaf_nodes': None, 'min_samples_split': 5, 'n_estimators': 75}, 'config_hash': {'algorithm': 'd7466a2c1d5cb3fa95029d73dc030f4c3c45a159', 'config': 'fa020a592ec5ac234f9f91aac28abc2cd1ec9d33', 'pipeline': '71e0d26f923d42cfe0e2fa748931ef2afe72ed86'}, 'duration': 3.62078595161438, 'iteration': 6, 'loss': 0.17066372828623277, 'max_history_score': 0.9456356408262035, 'max_history_score_std': 0.040053650785990214, 'max_history_step': 'joint', 'pipeline': {'features': ('features_SelectKBest', {'features__k': 1}), 'normalizer': ('normalizer_RobustScaler', {'normalizer__quantile_range': (...), 'normalizer__with_centering': True, 'normalizer__with_scaling': True}), 'rebalance': ('rebalance_CondensedNearestNeighbour', {'rebalance__n_neighbors': 1})}, 'score': 0.8293362717137672, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'entropy', 'max_depth': 3, 'max_features': 3, 'max_leaf_nodes': 5, 'min_samples_split': 5, 'n_estimators': 50}, 'config_hash': {'algorithm': '735caa9785596076014572a24050cde8dc338973', 'config': '0da4498002d6f452c59bb61756abb3ded841e786', 'pipeline': '51a53ea6ef5a2521ee65f76eb2da220ab7086513'}, 'duration': 0.6934049129486084, 'iteration': 7, 'loss': 0.06125875032408601, 'max_history_score': 0.9456356408262035, 'max_history_score_std': 0.040053650785990214, 'max_history_step': 'joint', 'pipeline': {'features': ('features_NoneType', {}), 'normalizer': ('normalizer_NoneType', {}), 'rebalance': ('rebalance_NearMiss', {'rebalance__n_neighbors': 3})}, 'score': 0.938741249675914, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': 4, 'max_features': 2, 'max_leaf_nodes': None, 'min_samples_split': 3, 'n_estimators': 75}, 'config_hash': {'algorithm': 'e71a1fe9515b6805f07914a61f2e7594be9e9afe', 'config': '344e4756fb1bec455d6af51d3727e33b0d27725f', 'pipeline': '248dad1d8b30a17a5de1d0bbdfe3e2acb7a1962b'}, 'duration': 1.3036692142486572, 'iteration': 8, 'loss': 0.06483125918243893, 'max_history_score': 0.9456356408262035, 'max_history_score_std': 0.040053650785990214, 'max_history_step': 'joint', 'pipeline': {'features': ('features_PCA', {'features__n_components': 2}), 'normalizer': ('normalizer_StandardScaler', {'normalizer__with_mean': False, 'normalizer__with_std': True}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 7})}, 'score': 0.9351687408175611, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'entropy', 'max_depth': 2, 'max_features': 2, 'max_leaf_nodes': 2, 'min_samples_split': 3, 'n_estimators': 10}, 'config_hash': {'algorithm': '0a507823f2ad8605ed5950e1fe61df0560f11a00', 'config': '4a538fdcf8e07f90e92a421c0d5c479d651629c7', 'pipeline': '5240329df25c9a533d025c1a401d49835a501b41'}, 'duration': 1.3821029663085938, 'iteration': 9, 'loss': 0.07006416904329793, 'max_history_score': 0.9456356408262035, 'max_history_score_std': 0.040053650785990214, 'max_history_step': 'joint', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 4, 'features__selectkbest__k': 2}), 'normalizer': ('normalizer_PowerTransformer', {}), 'rebalance': ('rebalance_NearMiss', {'rebalance__n_neighbors': 1})}, 'score': 0.9299358309567021, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'gini', 'max_depth': 1, 'max_features': 3, 'max_leaf_nodes': 5, 'min_samples_split': 3, 'n_estimators': 10}, 'config_hash': {'algorithm': 'd32739750d351948f8ff34a87c7d55b0c5e0d90f', 'config': 'c1609e71f1ce8486335adc70bb69a955580ba2c8', 'pipeline': 'f48b42ec5cf999279659966160a16353b75bdaa3'}, 'duration': 0.9055681228637695, 'iteration': 10, 'loss': 0.07532840722495904, 'max_history_score': 0.9456356408262035, 'max_history_score_std': 0.040053650785990214, 'max_history_step': 'joint', 'pipeline': {'features': ('features_PCA', {'features__n_components': 4}), 'normalizer': ('normalizer_PowerTransformer', {}), 'rebalance': ('rebalance_NearMiss', {'rebalance__n_neighbors': 1})}, 'score': 0.924671592775041, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': 3, 'max_features': 1, 'max_leaf_nodes': 5, 'min_samples_split': 3, 'n_estimators': 25}, 'config_hash': {'algorithm': 'f69bac35e71cbec1bfc1fb5942328a3390e7c252', 'config': 'abe36f188644e53e56ed3224236fa157107ed3b2', 'pipeline': 'aaf976c7c663a31fa039582d42f9e07101556a7c'}, 'duration': 0.764197826385498, 'iteration': 11, 'loss': 0.06818446979517778, 'max_history_score': 0.9456356408262035, 'max_history_score_std': 0.040053650785990214, 'max_history_step': 'joint', 'pipeline': {'features': ('features_NoneType', {}), 'normalizer': ('normalizer_PowerTransformer', {}), 'rebalance': ('rebalance_NoneType', {})}, 'score': 0.9318155302048222, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'entropy', 'max_depth': None, 'max_features': None, 'max_leaf_nodes': None, 'min_samples_split': 5, 'n_estimators': 25}, 'config_hash': {'algorithm': 'a0a27aec00db5ddf71eab96663f9bd61c845f5e3', 'config': '76aa002c3c9d4d9722466c60daf5119c18a41d2a', 'pipeline': '1ce34b7894ef342571d974bb19e8ec821a512c6b'}, 'duration': 1.1636500358581543, 'iteration': 12, 'loss': 0.12833700630887557, 'max_history_score': 0.9456356408262035, 'max_history_score_std': 0.040053650785990214, 'max_history_step': 'joint', 'pipeline': {'features': ('features_PCA', {'features__n_components': 1}), 'normalizer': ('normalizer_PowerTransformer', {}), 'rebalance': ('rebalance_NoneType', {})}, 'score': 0.8716629936911244, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'gini', 'max_depth': 1, 'max_features': 2, 'max_leaf_nodes': 2, 'min_samples_split': 2, 'n_estimators': 100}, 'config_hash': {'algorithm': '985c99dff1da9b2c87e4211c5335a9159aa9dbcb', 'config': 'f56a7a9e43a0a699e992dc1262e550b8b7c88538', 'pipeline': '5c934f6d9a8ad1f9afe762986a9cf2074fc95d79'}, 'duration': 2.235443115234375, 'iteration': 13, 'loss': 0.11414635727249167, 'max_history_score': 0.9456356408262035, 'max_history_score_std': 0.040053650785990214, 'max_history_step': 'joint', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 1, 'features__selectkbest__k': 1}), 'normalizer': ('normalizer_RobustScaler', {'normalizer__quantile_range': (...), 'normalizer__with_centering': False, 'normalizer__with_scaling': True}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 6})}, 'score': 0.8858536427275083, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'gini', 'max_depth': 1, 'max_features': 1, 'max_leaf_nodes': None, 'min_samples_split': 5, 'n_estimators': 10}, 'config_hash': {'algorithm': '7d74a39aac2579264a402aef2b6fa7943c19f3d3', 'config': '53f44c0ad925c5c08c25d4fadf5e9ee9d7c181cd', 'pipeline': '6eff5ef31d7d1d534db31913bb67529c8a24c42e'}, 'duration': 2.7847659587860107, 'iteration': 14, 'loss': 0.14061986863711007, 'max_history_score': 0.9456356408262035, 'max_history_score_std': 0.040053650785990214, 'max_history_step': 'joint', 'pipeline': {'features': ('features_PCA', {'features__n_components': 1}), 'normalizer': ('normalizer_RobustScaler', {'normalizer__quantile_range': (...), 'normalizer__with_centering': True, 'normalizer__with_scaling': True}), 'rebalance': ('rebalance_CondensedNearestNeighbour', {'rebalance__n_neighbors': 3})}, 'score': 0.8593801313628899, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'entropy', 'max_depth': 3, 'max_features': None, 'max_leaf_nodes': 5, 'min_samples_split': 2, 'n_estimators': 100}, 'config_hash': {'algorithm': 'c62d7c671832e4414b6b2d7c36cba5ddc83a0ed0', 'config': '5faee50671eaa0ac586722bff234e36a857e662d', 'pipeline': '8b29a55de2add78c49114b9bbe5e800e5524c59d'}, 'duration': 2.3916029930114746, 'iteration': 15, 'loss': 0.08770093336790252, 'max_history_score': 0.9456356408262035, 'max_history_score_std': 0.040053650785990214, 'max_history_step': 'joint', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 3, 'features__selectkbest__k': 4}), 'normalizer': ('normalizer_RobustScaler', {'normalizer__quantile_range': (...), 'normalizer__with_centering': True, 'normalizer__with_scaling': True}), 'rebalance': ('rebalance_NoneType', {})}, 'score': 0.9122990666320975, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': None, 'max_features': 1, 'max_leaf_nodes': 5, 'min_samples_split': 5, 'n_estimators': 10}, 'config_hash': {'algorithm': '290772bfb9b8ed15c48a72829e822fb0a07481d6', 'config': '9a04f25d8eb3db5b2f831abd341a6d384c73a957', 'pipeline': '1ce34b7894ef342571d974bb19e8ec821a512c6b'}, 'duration': 1.4364500045776367, 'iteration': 16, 'loss': 0.08948880822746508, 'max_history_score': 0.9456356408262035, 'max_history_score_std': 0.040053650785990214, 'max_history_step': 'joint', 'pipeline': {'features': ('features_PCA', {'features__n_components': 1}), 'normalizer': ('normalizer_PowerTransformer', {}), 'rebalance': ('rebalance_NoneType', {})}, 'score': 0.9105111917725349, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': 2, 'max_features': 3, 'max_leaf_nodes': 3, 'min_samples_split': 3, 'n_estimators': 100}, 'config_hash': {'algorithm': '7dab6d47f897c2961d3402eff844aff16a7d142a', 'config': '4dbfa2688b239be9f372d3e80223960ba9a1fbdd', 'pipeline': 'cdef51702798fa49f11c11d80baf3ab43d5358fc'}, 'duration': 0.9830451011657715, 'iteration': 17, 'loss': 1.0, 'max_history_score': 0.9456356408262035, 'max_history_score_std': 0.040053650785990214, 'max_history_step': 'joint', 'pipeline': {'features': ('features_SelectKBest', {'features__k': 2}), 'normalizer': ('normalizer_PowerTransformer', {}), 'rebalance': ('rebalance_NearMiss', {'rebalance__n_neighbors': 1})}, 'score': 0.0, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'entropy', 'max_depth': None, 'max_features': 3, 'max_leaf_nodes': None, 'min_samples_split': 5, 'n_estimators': 10}, 'config_hash': {'algorithm': 'def83e48be05ef92a37e1a90585820f2f67ff42b', 'config': '95902552cb76e9798f0fa58782bd72bd1cc272d7', 'pipeline': '1775187bf23f94f4fd0cc1e5c1ef665210edded5'}, 'duration': 2.0033559799194336, 'iteration': 18, 'loss': 0.04922327370149515, 'max_history_score': 0.9507767262985048, 'max_history_score_std': 0.028328108925705902, 'max_history_step': 'joint', 'pipeline': {'features': ('features_PCA', {'features__n_components': 4}), 'normalizer': ('normalizer_StandardScaler', {'normalizer__with_mean': True, 'normalizer__with_std': True}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 5})}, 'score': 0.9507767262985048, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'gini', 'max_depth': 1, 'max_features': 3, 'max_leaf_nodes': None, 'min_samples_split': 2, 'n_estimators': 50}, 'config_hash': {'algorithm': '4e9e3275f817df75115d9d7e3366980fc1b4cf13', 'config': '7770b19007b40bf13005d52eb81f87bc401f15b4', 'pipeline': 'c4dd111513ea35f97dd3aec3e8e7f6268ce035da'}, 'duration': 0.9069631099700928, 'iteration': 19, 'loss': 1.0, 'max_history_score': 0.9507767262985048, 'max_history_score_std': 0.028328108925705902, 'max_history_step': 'joint', 'pipeline': {'features': ('features_PCA', {'features__n_components': 2}), 'normalizer': ('normalizer_RobustScaler', {'normalizer__quantile_range': (...), 'normalizer__with_centering': False, 'normalizer__with_scaling': True}), 'rebalance': ('rebalance_NearMiss', {'rebalance__n_neighbors': 2})}, 'score': 0.0, ...}, ...], 'history_hash': ['51144ca42f9ea5ab2d8d58606e3b3e4d89c6d7b3', '9e54ffcb6a727de032a0a2cd45c5cc37cc150756', 'e5241eee9ddf3f4ee29a4711f5bcc92a4d24cd09', '18ee4d3d1627472ec190326308d8755371a6dc62', '2af4f82b045c0c48ecb89d42728d1039fbff8878', '17b2a1e5814f3e933137158708a5b6e9b2475495', 'fa020a592ec5ac234f9f91aac28abc2cd1ec9d33', '0da4498002d6f452c59bb61756abb3ded841e786', '344e4756fb1bec455d6af51d3727e33b0d27725f', '4a538fdcf8e07f90e92a421c0d5c479d651629c7', 'c1609e71f1ce8486335adc70bb69a955580ba2c8', 'abe36f188644e53e56ed3224236fa157107ed3b2', '76aa002c3c9d4d9722466c60daf5119c18a41d2a', 'f56a7a9e43a0a699e992dc1262e550b8b7c88538', '53f44c0ad925c5c08c25d4fadf5e9ee9d7c181cd', '5faee50671eaa0ac586722bff234e36a857e662d', '9a04f25d8eb3db5b2f831abd341a6d384c73a957', '4dbfa2688b239be9f372d3e80223960ba9a1fbdd', '95902552cb76e9798f0fa58782bd72bd1cc272d7', '7770b19007b40bf13005d52eb81f87bc401f15b4', ...], 'history_index': {'0da4498002d6f452c59bb61756abb3ded841e786': 7, '127553d555ed39231b8da3a1ce42d3902e30919b': 59, '17b2a1e5814f3e933137158708a5b6e9b2475495': 5, '18ee4d3d1627472ec190326308d8755371a6dc62': 3, '1b2267555a9226d7eb4df3c63dd12506da370f4d': 56, '2af4f82b045c0c48ecb89d42728d1039fbff8878': 4, '2d054540972225f4f17fb36d63106b7bb5c406fe': 36, '306511091d7e5d6431b5e5a6320802c4c04cde44': 33, '312e05571f41c77895a9ad8c57db6947f3fdfe03': 58, '344e4756fb1bec455d6af51d3727e33b0d27725f': 8, ...}, 'iteration': 59, 'max_history_score': 0.9525008642295394, 'max_history_score_std': 0.02225295065716913, 'max_history_step': 'joint'}, config={'algorithm': 'RandomForest', 'seed': 42, 'time': 300}, step='joint')
     45                 y,
     46                 cv=10,
     47                 n_jobs=-1,
     48                 return_estimator=False,
     49                 return_train_score=False,
---> 50                 verbose=0)
     51         score = np.mean(scores['test_score'])
     52         std = np.std(scores['test_score'])
     53         status = STATUS_OK
     54     except Exception as e:

...........................................................................
/home/aquemy/.local/lib/python2.7/site-packages/sklearn/model_selection/_validation.py in cross_validate(estimator=Pipeline(memory=None,
     steps=[('rebalance', ... random_state=42, verbose=0, warm_start=False))]), X=array([[1.799e+01, 1.038e+01, 1.228e+02, ..., 2...., ..., 0.000e+00, 2.871e-01,
        7.039e-02]]), y=array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,... 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1]), groups=None, scoring=None, cv=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1, verbose=0, fit_params=None, pre_dispatch='2*n_jobs', return_train_score=False, return_estimator=False, error_score='raise-deprecating')
    235         delayed(_fit_and_score)(
    236             clone(estimator), X, y, scorers, train, test, verbose, None,
    237             fit_params, return_train_score=return_train_score,
    238             return_times=True, return_estimator=return_estimator,
    239             error_score=error_score)
--> 240         for train, test in cv.split(X, y, groups))
        cv.split = <bound method StratifiedKFold.split of Stratifie...d(n_splits=10, random_state=None, shuffle=False)>
        X = array([[1.799e+01, 1.038e+01, 1.228e+02, ..., 2...., ..., 0.000e+00, 2.871e-01,
        7.039e-02]])
        y = array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,... 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1])
        groups = None
    241 
    242     zipped_scores = list(zip(*scores))
    243     if return_train_score:
    244         train_scores = zipped_scores.pop(0)

...........................................................................
/home/aquemy/.local/lib/python2.7/site-packages/sklearn/externals/joblib/parallel.py in __call__(self=Parallel(n_jobs=-1), iterable=<generator object <genexpr>>)
    925                 # No need to wait for async callbacks to trigger to
    926                 # consumption.
    927                 self._iterating = False
    928 
    929             with self._backend.retrieval_context():
--> 930                 self.retrieve()
        self.retrieve = <bound method Parallel.retrieve of Parallel(n_jobs=-1)>
    931             # Make sure that we get a last message telling us we are done
    932             elapsed_time = time.time() - self._start_time
    933             self._print('Done %3i out of %3i | elapsed: %s finished',
    934                         (len(self._output), len(self._output),

---------------------------------------------------------------------------
Joblib worker traceback:
---------------------------------------------------------------------------
ValueError                                         Mon Jun 17 13:33:01 2019
PID: 25990                                  Python 2.7.15+: /usr/bin/python
...........................................................................
/home/aquemy/.local/lib/python2.7/site-packages/sklearn/externals/joblib/parallel.py in __call__(self=<sklearn.externals.joblib.parallel.BatchedCalls object>)
    220     def __call__(self):
    221         # Set the default nested backend to self._backend but do not set the
    222         # change the default number of processes to -1
    223         with parallel_backend(self._backend, n_jobs=self._n_jobs):
    224             return [func(*args, **kwargs)
--> 225                     for func, args, kwargs in self.items]
        func = <function _fit_and_score>
        args = (Pipeline(memory=None,
     steps=[('rebalance', ... random_state=42, verbose=0, warm_start=False))]), array([[1.799e+01, 1.038e+01, 1.228e+02, ..., 2...., ..., 0.000e+00, 2.871e-01,
        7.039e-02]]), array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,... 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1]), {'score': <function _passthrough_scorer>}, array([ 25,  26,  27,  28,  29,  30,  31,  32,  ..., 561, 562, 563, 564,
       565, 566, 567, 568]), array([  0,   1,   2,   3,   4,   5,   6,   7,  ...,  89,  90,
        92,  93,  96,  97,  98, 101]), 0, None, None)
        kwargs = {'error_score': 'raise-deprecating', 'return_estimator': False, 'return_times': True, 'return_train_score': False}
        self.items = [(<function _fit_and_score>, (Pipeline(memory=None,
     steps=[('rebalance', ... random_state=42, verbose=0, warm_start=False))]), array([[1.799e+01, 1.038e+01, 1.228e+02, ..., 2...., ..., 0.000e+00, 2.871e-01,
        7.039e-02]]), array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,... 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1]), {'score': <function _passthrough_scorer>}, array([ 25,  26,  27,  28,  29,  30,  31,  32,  ..., 561, 562, 563, 564,
       565, 566, 567, 568]), array([  0,   1,   2,   3,   4,   5,   6,   7,  ...,  89,  90,
        92,  93,  96,  97,  98, 101]), 0, None, None), {'error_score': 'raise-deprecating', 'return_estimator': False, 'return_times': True, 'return_train_score': False})]
    226 
    227     def __len__(self):
    228         return self._size
    229 

...........................................................................
/home/aquemy/.local/lib/python2.7/site-packages/sklearn/model_selection/_validation.py in _fit_and_score(estimator=Pipeline(memory=None,
     steps=[('rebalance', ... random_state=42, verbose=0, warm_start=False))]), X=array([[1.799e+01, 1.038e+01, 1.228e+02, ..., 2...., ..., 0.000e+00, 2.871e-01,
        7.039e-02]]), y=array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,... 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1]), scorer={'score': <function _passthrough_scorer>}, train=array([ 25,  26,  27,  28,  29,  30,  31,  32,  ..., 561, 562, 563, 564,
       565, 566, 567, 568]), test=array([  0,   1,   2,   3,   4,   5,   6,   7,  ...,  89,  90,
        92,  93,  96,  97,  98, 101]), verbose=0, parameters=None, fit_params={}, return_train_score=False, return_parameters=False, return_n_test_samples=False, return_times=True, return_estimator=False, error_score='raise-deprecating')
    523 
    524     try:
    525         if y_train is None:
    526             estimator.fit(X_train, **fit_params)
    527         else:
--> 528             estimator.fit(X_train, y_train, **fit_params)
        estimator.fit = <bound method Pipeline.fit of Pipeline(memory=No...random_state=42, verbose=0, warm_start=False))])>
        X_train = array([[1.714e+01, 1.640e+01, 1.160e+02, ..., 2...., ..., 0.000e+00, 2.871e-01,
        7.039e-02]])
        y_train = array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...1, 1, 1, 1, 1, 1, 1, 0, 0,
       0, 0, 0, 0, 1])
        fit_params = {}
    529 
    530     except Exception as e:
    531         # Note fit time as time until error
    532         fit_time = time.time() - start_time

...........................................................................
/usr/local/lib/python2.7/dist-packages/imblearn/pipeline.py in fit(self=Pipeline(memory=None,
     steps=[('rebalance', ... random_state=42, verbose=0, warm_start=False))]), X=array([[1.714e+01, 1.640e+01, 1.160e+02, ..., 2...., ..., 0.000e+00, 2.871e-01,
        7.039e-02]]), y=array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...1, 1, 1, 1, 1, 1, 1, 0, 0,
       0, 0, 0, 0, 1]), **fit_params={})
    234             This estimator
    235 
    236         """
    237         Xt, yt, fit_params = self._fit(X, y, **fit_params)
    238         if self._final_estimator is not None:
--> 239             self._final_estimator.fit(Xt, yt, **fit_params)
        self._final_estimator.fit = <bound method RandomForestClassifier.fit of Rand...e, random_state=42, verbose=0, warm_start=False)>
        Xt = array([[0.255     ],
       [0.2701    ],
      ...1042],
       [0.17680096],
       [0.17522434]])
        yt = array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
       0, 0, 0, 0])
        fit_params = {}
    240         return self
    241 
    242     def fit_transform(self, X, y=None, **fit_params):
    243         """Fit the model and transform with the final estimator

...........................................................................
/home/aquemy/.local/lib/python2.7/site-packages/sklearn/ensemble/forest.py in fit(self=RandomForestClassifier(bootstrap=True, class_wei...se, random_state=42, verbose=0, warm_start=False), X=array([[0.255     ],
       [0.2701    ],
      ...0.17680097],
       [0.17522435]], dtype=float32), y=array([[0.],
       [0.],
       [0.],
       [0...    [0.],
       [0.],
       [0.],
       [0.]]), sample_weight=None)
    328             trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,
    329                              **_joblib_parallel_args(prefer='threads'))(
    330                 delayed(_parallel_build_trees)(
    331                     t, self, X, y, sample_weight, i, len(trees),
    332                     verbose=self.verbose, class_weight=self.class_weight)
--> 333                 for i, t in enumerate(trees))
        i = 9
    334 
    335             # Collect newly grown trees
    336             self.estimators_.extend(trees)
    337 

...........................................................................
/home/aquemy/.local/lib/python2.7/site-packages/sklearn/externals/joblib/parallel.py in __call__(self=Parallel(n_jobs=1), iterable=<generator object <genexpr>>)
    912             # self._original_iterator is None, then this means either
    913             # that pre_dispatch == "all", n_jobs == 1 or that the first batch
    914             # was very quick and its callback already dispatched all the
    915             # remaining jobs.
    916             self._iterating = False
--> 917             if self.dispatch_one_batch(iterator):
        self.dispatch_one_batch = <bound method Parallel.dispatch_one_batch of Parallel(n_jobs=1)>
        iterator = <generator object <genexpr>>
    918                 self._iterating = self._original_iterator is not None
    919 
    920             while self.dispatch_one_batch(iterator):
    921                 pass

...........................................................................
/home/aquemy/.local/lib/python2.7/site-packages/sklearn/externals/joblib/parallel.py in dispatch_one_batch(self=Parallel(n_jobs=1), iterator=<generator object <genexpr>>)
    754                                  self._pickle_cache)
    755             if len(tasks) == 0:
    756                 # No more tasks available in the iterator: tell caller to stop.
    757                 return False
    758             else:
--> 759                 self._dispatch(tasks)
        self._dispatch = <bound method Parallel._dispatch of Parallel(n_jobs=1)>
        tasks = <sklearn.externals.joblib.parallel.BatchedCalls object>
    760                 return True
    761 
    762     def _print(self, msg, msg_args):
    763         """Display the message on stout or stderr depending on verbosity"""

...........................................................................
/home/aquemy/.local/lib/python2.7/site-packages/sklearn/externals/joblib/parallel.py in _dispatch(self=Parallel(n_jobs=1), batch=<sklearn.externals.joblib.parallel.BatchedCalls object>)
    711 
    712         dispatch_timestamp = time.time()
    713         cb = BatchCompletionCallBack(dispatch_timestamp, len(batch), self)
    714         with self._lock:
    715             job_idx = len(self._jobs)
--> 716             job = self._backend.apply_async(batch, callback=cb)
        job = undefined
        self._backend.apply_async = <bound method SequentialBackend.apply_async of <...lib._parallel_backends.SequentialBackend object>>
        batch = <sklearn.externals.joblib.parallel.BatchedCalls object>
        cb = <sklearn.externals.joblib.parallel.BatchCompletionCallBack object>
    717             # A job can complete so quickly than its callback is
    718             # called before we get here, causing self._jobs to
    719             # grow. To ensure correct results ordering, .insert is
    720             # used (rather than .append) in the following line

...........................................................................
/home/aquemy/.local/lib/python2.7/site-packages/sklearn/externals/joblib/_parallel_backends.py in apply_async(self=<sklearn.externals.joblib._parallel_backends.SequentialBackend object>, func=<sklearn.externals.joblib.parallel.BatchedCalls object>, callback=<sklearn.externals.joblib.parallel.BatchCompletionCallBack object>)
    177             raise ValueError('n_jobs == 0 in Parallel has no meaning')
    178         return 1
    179 
    180     def apply_async(self, func, callback=None):
    181         """Schedule a func to be run"""
--> 182         result = ImmediateResult(func)
        result = undefined
        func = <sklearn.externals.joblib.parallel.BatchedCalls object>
    183         if callback:
    184             callback(result)
    185         return result
    186 

...........................................................................
/home/aquemy/.local/lib/python2.7/site-packages/sklearn/externals/joblib/_parallel_backends.py in __init__(self=<sklearn.externals.joblib._parallel_backends.ImmediateResult object>, batch=<sklearn.externals.joblib.parallel.BatchedCalls object>)
    544 
    545 class ImmediateResult(object):
    546     def __init__(self, batch):
    547         # Don't delay the application, to avoid keeping the input
    548         # arguments in memory
--> 549         self.results = batch()
        self.results = undefined
        batch = <sklearn.externals.joblib.parallel.BatchedCalls object>
    550 
    551     def get(self):
    552         return self.results
    553 

...........................................................................
/home/aquemy/.local/lib/python2.7/site-packages/sklearn/externals/joblib/parallel.py in __call__(self=<sklearn.externals.joblib.parallel.BatchedCalls object>)
    220     def __call__(self):
    221         # Set the default nested backend to self._backend but do not set the
    222         # change the default number of processes to -1
    223         with parallel_backend(self._backend, n_jobs=self._n_jobs):
    224             return [func(*args, **kwargs)
--> 225                     for func, args, kwargs in self.items]
        func = <function _parallel_build_trees>
        args = (DecisionTreeClassifier(class_weight=None, criter...=False, random_state=1608637542, splitter='best'), RandomForestClassifier(bootstrap=True, class_wei...se, random_state=42, verbose=0, warm_start=False), array([[0.255     ],
       [0.2701    ],
      ...0.17680097],
       [0.17522435]], dtype=float32), array([[0.],
       [0.],
       [0.],
       [0...    [0.],
       [0.],
       [0.],
       [0.]]), None, 0, 10)
        kwargs = {'class_weight': None, 'verbose': 0}
        self.items = [(<function _parallel_build_trees>, (DecisionTreeClassifier(class_weight=None, criter...=False, random_state=1608637542, splitter='best'), RandomForestClassifier(bootstrap=True, class_wei...se, random_state=42, verbose=0, warm_start=False), array([[0.255     ],
       [0.2701    ],
      ...0.17680097],
       [0.17522435]], dtype=float32), array([[0.],
       [0.],
       [0.],
       [0...    [0.],
       [0.],
       [0.],
       [0.]]), None, 0, 10), {'class_weight': None, 'verbose': 0})]
    226 
    227     def __len__(self):
    228         return self._size
    229 

...........................................................................
/home/aquemy/.local/lib/python2.7/site-packages/sklearn/ensemble/forest.py in _parallel_build_trees(tree=DecisionTreeClassifier(class_weight=None, criter...=False, random_state=1608637542, splitter='best'), forest=RandomForestClassifier(bootstrap=True, class_wei...se, random_state=42, verbose=0, warm_start=False), X=array([[0.255     ],
       [0.2701    ],
      ...0.17680097],
       [0.17522435]], dtype=float32), y=array([[0.],
       [0.],
       [0.],
       [0...    [0.],
       [0.],
       [0.],
       [0.]]), sample_weight=None, tree_idx=0, n_trees=10, verbose=0, class_weight=None)
    114                 simplefilter('ignore', DeprecationWarning)
    115                 curr_sample_weight *= compute_sample_weight('auto', y, indices)
    116         elif class_weight == 'balanced_subsample':
    117             curr_sample_weight *= compute_sample_weight('balanced', y, indices)
    118 
--> 119         tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)
        tree.fit = <bound method DecisionTreeClassifier.fit of Deci...False, random_state=1608637542, splitter='best')>
        X = array([[0.255     ],
       [0.2701    ],
      ...0.17680097],
       [0.17522435]], dtype=float32)
        y = array([[0.],
       [0.],
       [0.],
       [0...    [0.],
       [0.],
       [0.],
       [0.]])
        sample_weight = None
        curr_sample_weight = array([1., 2., 0., 0., 0., 1., 1., 2., 3., 0., 1... 0., 2., 2., 0., 3., 0., 2., 0., 1., 0., 1., 1.])
    120     else:
    121         tree.fit(X, y, sample_weight=sample_weight, check_input=False)
    122 
    123     return tree

...........................................................................
/home/aquemy/.local/lib/python2.7/site-packages/sklearn/tree/tree.py in fit(self=DecisionTreeClassifier(class_weight=None, criter...=False, random_state=1608637542, splitter='best'), X=array([[0.255     ],
       [0.2701    ],
      ...0.17680097],
       [0.17522435]], dtype=float32), y=array([[0.],
       [0.],
       [0.],
       [0...    [0.],
       [0.],
       [0.],
       [0.]]), sample_weight=array([1., 2., 0., 0., 0., 1., 1., 2., 3., 0., 1... 0., 2., 2., 0., 3., 0., 2., 0., 1., 0., 1., 1.]), check_input=False, X_idx_sorted=None)
    796 
    797         super(DecisionTreeClassifier, self).fit(
    798             X, y,
    799             sample_weight=sample_weight,
    800             check_input=check_input,
--> 801             X_idx_sorted=X_idx_sorted)
        X_idx_sorted = None
    802         return self
    803 
    804     def predict_proba(self, X, check_input=True):
    805         """Predict class probabilities of the input samples X.

...........................................................................
/home/aquemy/.local/lib/python2.7/site-packages/sklearn/tree/tree.py in fit(self=DecisionTreeClassifier(class_weight=None, criter...=False, random_state=1608637542, splitter='best'), X=array([[0.255     ],
       [0.2701    ],
      ...0.17680097],
       [0.17522435]], dtype=float32), y=array([[0.],
       [0.],
       [0.],
       [0...    [0.],
       [0.],
       [0.],
       [0.]]), sample_weight=array([1., 2., 0., 0., 0., 1., 1., 2., 3., 0., 1... 0., 2., 2., 0., 3., 0., 2., 0., 1., 0., 1., 1.]), check_input=False, X_idx_sorted=None)
    237         if not 0 <= self.min_weight_fraction_leaf <= 0.5:
    238             raise ValueError("min_weight_fraction_leaf must in [0, 0.5]")
    239         if max_depth <= 0:
    240             raise ValueError("max_depth must be greater than zero. ")
    241         if not (0 < max_features <= self.n_features_):
--> 242             raise ValueError("max_features must be in (0, n_features]")
    243         if not isinstance(max_leaf_nodes, (numbers.Integral, np.integer)):
    244             raise ValueError("max_leaf_nodes must be integral number but was "
    245                              "%r" % max_leaf_nodes)
    246         if -1 < max_leaf_nodes < 2:

ValueError: max_features must be in (0, n_features]
___________________________________________________________________________
Best score: 0.95250086423 (0.0222529506572) [J] | Score: 0.0 (0.0) [J]
Best score: 0.95250086423 (0.0222529506572) [J] | Score: 0.907218477228 (0.0412078086563) [J]
Best score: 0.95250086423 (0.0222529506572) [J] | Score: 0.919192377495 (0.028600863808) [J]
Best score: 0.95250086423 (0.0222529506572) [J] | Score: 0.83120948924 (0.0663565196674) [J]
JoblibValueError
___________________________________________________________________________
...........................................................................
/home/aquemy/dev/dp_hyperparameters/extension/main.py in <module>()
     27 
     28     serializer.serialize_results(scenario, policy)
     29 
     30 if __name__ == "__main__":
     31     args = cli.parse_args()
---> 32     main(args)

...........................................................................
/home/aquemy/dev/dp_hyperparameters/extension/main.py in main(args=Namespace(customize=[(['control', 'seed'], '42')...='./scenarios/rf_breast_joint.yaml', verbosity=0))
     21         test_size=0.4, 
     22         random_state=scenario['control']['seed']
     23     )
     24 
     25     policy = policies.initiate(scenario['setup']['policy'], config)
---> 26     policy.run(X,y)
        policy.run = <bound method Joint.run of <experiment.policies.joint.Joint object>>
        X = array([[1.799e+01, 1.038e+01, 1.228e+02, ..., 2...., ..., 0.000e+00, 2.871e-01,
        7.039e-02]])
        y = array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,... 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1])
     27 
     28     serializer.serialize_results(scenario, policy)
     29 
     30 if __name__ == "__main__":

...........................................................................
/home/aquemy/dev/dp_hyperparameters/extension/experiment/policies/joint.py in run(self=<experiment.policies.joint.Joint object>, X=array([[1.799e+01, 1.038e+01, 1.228e+02, ..., 2...., ..., 0.000e+00, 2.871e-01,
        7.039e-02]]), y=array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,... 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1]))
     32             algo=tpe.suggest, 
     33             max_evals=None,
     34             max_time=self.config['time'],     
     35             trials=trials,
     36             show_progressbar=False,
---> 37             verbose=0
     38         )
     39 
     40         best_config = self.context['best_config']
     41         super(Joint, self).display_step_results(best_config)

...........................................................................
/home/aquemy/dev/dp_hyperparameters/extension/hyperopt/fmin.py in fmin(fn=<functools.partial object>, space={'algorithm': {'bootstrap': <hyperopt.pyll.base.Apply object>, 'criterion': <hyperopt.pyll.base.Apply object>, 'max_depth': <hyperopt.pyll.base.Apply object>, 'max_features': <hyperopt.pyll.base.Apply object>, 'max_leaf_nodes': <hyperopt.pyll.base.Apply object>, 'min_samples_split': <hyperopt.pyll.base.Apply object>, 'n_estimators': <hyperopt.pyll.base.Apply object>}, 'pipeline': {'features': <hyperopt.pyll.base.Apply object>, 'normalizer': <hyperopt.pyll.base.Apply object>, 'rebalance': <hyperopt.pyll.base.Apply object>}}, algo=<function suggest>, max_evals=9223372036854775807, max_time=300, trials=<hyperopt.base.Trials object>, rstate=<mtrand.RandomState object>, allow_trials_fmin=True, pass_expr_memo_ctrl=None, catch_eval_exceptions=False, verbose=0, return_argmin=True, points_to_evaluate=None, max_queue_len=1, show_progressbar=False)
    406             pass_expr_memo_ctrl=pass_expr_memo_ctrl,
    407             verbose=verbose,
    408             catch_eval_exceptions=catch_eval_exceptions,
    409             return_argmin=return_argmin,
    410             show_progressbar=show_progressbar,
--> 411             max_time=max_time
        max_time = 300
    412         )
    413 
    414     if trials is None:
    415         if points_to_evaluate is None:

...........................................................................
/home/aquemy/dev/dp_hyperparameters/extension/hyperopt/base.py in fmin(self=<hyperopt.base.Trials object>, fn=<functools.partial object>, space={'algorithm': {'bootstrap': <hyperopt.pyll.base.Apply object>, 'criterion': <hyperopt.pyll.base.Apply object>, 'max_depth': <hyperopt.pyll.base.Apply object>, 'max_features': <hyperopt.pyll.base.Apply object>, 'max_leaf_nodes': <hyperopt.pyll.base.Apply object>, 'min_samples_split': <hyperopt.pyll.base.Apply object>, 'n_estimators': <hyperopt.pyll.base.Apply object>}, 'pipeline': {'features': <hyperopt.pyll.base.Apply object>, 'normalizer': <hyperopt.pyll.base.Apply object>, 'rebalance': <hyperopt.pyll.base.Apply object>}}, algo=<function suggest>, max_evals=9223372036854775807, max_time=300, rstate=<mtrand.RandomState object>, verbose=0, pass_expr_memo_ctrl=None, catch_eval_exceptions=False, return_argmin=True, show_progressbar=False)
    636             verbose=verbose,
    637             allow_trials_fmin=False,  # -- prevent recursion
    638             pass_expr_memo_ctrl=pass_expr_memo_ctrl,
    639             catch_eval_exceptions=catch_eval_exceptions,
    640             return_argmin=return_argmin,
--> 641             show_progressbar=show_progressbar)
        show_progressbar = False
    642 
    643 
    644 def trials_from_docs(docs, validate=True, **kwargs):
    645     """Construct a Trials base class instance from a list of trials documents

...........................................................................
/home/aquemy/dev/dp_hyperparameters/extension/hyperopt/fmin.py in fmin(fn=<functools.partial object>, space={'algorithm': {'bootstrap': <hyperopt.pyll.base.Apply object>, 'criterion': <hyperopt.pyll.base.Apply object>, 'max_depth': <hyperopt.pyll.base.Apply object>, 'max_features': <hyperopt.pyll.base.Apply object>, 'max_leaf_nodes': <hyperopt.pyll.base.Apply object>, 'min_samples_split': <hyperopt.pyll.base.Apply object>, 'n_estimators': <hyperopt.pyll.base.Apply object>}, 'pipeline': {'features': <hyperopt.pyll.base.Apply object>, 'normalizer': <hyperopt.pyll.base.Apply object>, 'rebalance': <hyperopt.pyll.base.Apply object>}}, algo=<function suggest>, max_evals=9223372036854775807, max_time=300, trials=<hyperopt.base.Trials object>, rstate=<mtrand.RandomState object>, allow_trials_fmin=False, pass_expr_memo_ctrl=None, catch_eval_exceptions=False, verbose=0, return_argmin=True, points_to_evaluate=None, max_queue_len=1, show_progressbar=False)
    426                     verbose=verbose,
    427                     max_queue_len=max_queue_len,
    428                     show_progressbar=show_progressbar,
    429                     max_time=max_time)
    430     rval.catch_eval_exceptions = catch_eval_exceptions
--> 431     rval.exhaust()
        rval.exhaust = <bound method FMinIter.exhaust of <hyperopt.fmin.FMinIter object>>
    432     if return_argmin:
    433         return trials.argmin
    434     elif len(trials) > 0:
    435         # Only if there are some succesfull trail runs, return the best point in the evaluation space

...........................................................................
/home/aquemy/dev/dp_hyperparameters/extension/hyperopt/fmin.py in exhaust(self=<hyperopt.fmin.FMinIter object>)
    273             raise StopIteration()
    274         return self.trials
    275 
    276     def exhaust(self):
    277         n_done = len(self.trials)
--> 278         self.run(self.max_evals - n_done, block_until_done=self.asynchronous)
        self.run = <bound method FMinIter.run of <hyperopt.fmin.FMinIter object>>
        self.max_evals = 9223372036854775807
        n_done = 0
        self.asynchronous = False
    279         self.trials.refresh()
    280         return self
    281 
    282 

...........................................................................
/home/aquemy/dev/dp_hyperparameters/extension/hyperopt/fmin.py in run(self=<hyperopt.fmin.FMinIter object>, N=9223372036854775807, block_until_done=False)
    232                     if self.asynchronous:
    233                         # -- wait for workers to fill in the trials
    234                         time.sleep(self.poll_interval_secs)
    235                     else:
    236                         # -- loop over trials and do the jobs directly
--> 237                         self.serial_evaluate()
        self.serial_evaluate = <bound method FMinIter.serial_evaluate of <hyperopt.fmin.FMinIter object>>
    238                     try:
    239                         res = [d['result']['loss'] for d in
    240                                          self.trials.trials if
    241                                          d['result']['status'] == 'ok']

...........................................................................
/home/aquemy/dev/dp_hyperparameters/extension/hyperopt/fmin.py in serial_evaluate(self=<hyperopt.fmin.FMinIter object>, N=-1)
    138                 trial['book_time'] = now
    139                 trial['refresh_time'] = now
    140                 spec = base.spec_from_misc(trial['misc'])
    141                 ctrl = base.Ctrl(self.trials, current_trial=trial)
    142                 try:
--> 143                     result = self.domain.evaluate(spec, ctrl)
        result = undefined
        self.domain.evaluate = <bound method Domain.evaluate of <hyperopt.base.Domain object>>
        spec = {'bootstrap': 1, 'criterion': 1, 'features': 1, 'features_PCA_features__n_components': 0, 'max_depth': 4, 'max_features': 2, 'max_leaf_nodes': 3, 'min_samples_split': 2, 'n_estimators': 0, 'normalizer': 1, ...}
        ctrl = <hyperopt.base.Ctrl object>
    144                 except Exception as e:
    145                     logger.info('job exception: %s' % str(e))
    146                     trial['state'] = base.JOB_STATE_ERROR
    147                     trial['misc']['error'] = (str(type(e)), str(e))

...........................................................................
/home/aquemy/dev/dp_hyperparameters/extension/hyperopt/base.py in evaluate(self=<hyperopt.base.Domain object>, config={'bootstrap': 1, 'criterion': 1, 'features': 1, 'features_PCA_features__n_components': 0, 'max_depth': 4, 'max_features': 2, 'max_leaf_nodes': 3, 'min_samples_split': 2, 'n_estimators': 0, 'normalizer': 1, ...}, ctrl=<hyperopt.base.Ctrl object>, attach_attachments=True)
    841             #    or the normal Python part (self.fn)
    842             pyll_rval = pyll.rec_eval(
    843                 self.expr,
    844                 memo=memo,
    845                 print_node_on_error=self.rec_eval_print_node_on_error)
--> 846             rval = self.fn(pyll_rval)
        rval = undefined
        self.fn = <functools.partial object>
        pyll_rval = {'algorithm': {'bootstrap': False, 'criterion': 'entropy', 'max_depth': None, 'max_features': 3, 'max_leaf_nodes': None, 'min_samples_split': 5, 'n_estimators': 10}, 'pipeline': {'features': ('features_PCA', {'features__n_components': 1}), 'normalizer': ('normalizer_StandardScaler', {'normalizer__with_mean': False, 'normalizer__with_std': True}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 5})}}
    847 
    848         if isinstance(rval, (float, int, np.number)):
    849             dict_rval = {'loss': float(rval), 'status': STATUS_OK}
    850         else:

...........................................................................
/home/aquemy/dev/dp_hyperparameters/extension/experiment/objective.py in objective_joint(wconfig={'algorithm': {'bootstrap': False, 'criterion': 'entropy', 'max_depth': None, 'max_features': 3, 'max_leaf_nodes': None, 'min_samples_split': 5, 'n_estimators': 10}, 'pipeline': {'features': ('features_PCA', {'features__n_components': 1}), 'normalizer': ('normalizer_StandardScaler', {'normalizer__with_mean': False, 'normalizer__with_std': True}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 5})}}, algorithm='RandomForest', X=array([[1.799e+01, 1.038e+01, 1.228e+02, ..., 2...., ..., 0.000e+00, 2.871e-01,
        7.039e-02]]), y=array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,... 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1]), context={'baseline_score': 0.9545944602886527, 'baseline_score_std': 0.03716322883281839, 'best_config': {'algorithm': {'bootstrap': False, 'criterion': 'entropy', 'max_depth': None, 'max_features': 2, 'max_leaf_nodes': None, 'min_samples_split': 5, 'n_estimators': 10}, 'config_hash': {'algorithm': 'e7a772c2bc361aa61cf7eeb364a26dca2c9b89d6', 'config': 'afb67da069b544b0505b1e8c150edc7498ad37b4', 'pipeline': 'a43db4b4fc4c38610b7b5e484840d2e583089ff4'}, 'duration': 1.0073001384735107, 'iteration': 26, 'loss': 0.04749913577046061, 'max_history_score': 0.9525008642295394, 'max_history_score_std': 0.02225295065716913, 'max_history_step': 'joint', 'pipeline': {'features': ('features_PCA', {'features__n_components': 4}), 'normalizer': ('normalizer_StandardScaler', {'normalizer__with_mean': True, 'normalizer__with_std': False}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 7})}, 'score': 0.9525008642295394, ...}, 'history': [{'algorithm': {'bootstrap': True, 'criterion': 'entropy', 'max_depth': 4, 'max_features': 3, 'max_leaf_nodes': 3, 'min_samples_split': 2, 'n_estimators': 10}, 'config_hash': {'algorithm': '42527c4120073c2a488d1b8df28732f486d1578c', 'config': '51144ca42f9ea5ab2d8d58606e3b3e4d89c6d7b3', 'pipeline': '52f07bda29f9d3a95fabb87e591d0b2581ca8209'}, 'duration': 0.26703310012817383, 'iteration': 0, 'loss': 0.06655431682654922, 'max_history_score': 0.9334456831734508, 'max_history_score_std': 0.03819399139659311, 'max_history_step': 'joint', 'pipeline': {'features': ('features_NoneType', {}), 'normalizer': ('normalizer_RobustScaler', {'normalizer__quantile_range': (...), 'normalizer__with_centering': False, 'normalizer__with_scaling': False}), 'rebalance': ('rebalance_NearMiss', {'rebalance__n_neighbors': 1})}, 'score': 0.9334456831734508, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': None, 'max_features': 2, 'max_leaf_nodes': 3, 'min_samples_split': 2, 'n_estimators': 100}, 'config_hash': {'algorithm': '1b32258c630f07e01ab481ab925ab80aa757e482', 'config': '9e54ffcb6a727de032a0a2cd45c5cc37cc150756', 'pipeline': '37e72d4a97f5e784c9d3133e6379b91bfc3be803'}, 'duration': 1.3065669536590576, 'iteration': 1, 'loss': 0.05436435917379645, 'max_history_score': 0.9456356408262035, 'max_history_score_std': 0.040053650785990214, 'max_history_step': 'joint', 'pipeline': {'features': ('features_NoneType', {}), 'normalizer': ('normalizer_StandardScaler', {'normalizer__with_mean': True, 'normalizer__with_std': True}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 6})}, 'score': 0.9456356408262035, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'entropy', 'max_depth': 1, 'max_features': 1, 'max_leaf_nodes': 2, 'min_samples_split': 3, 'n_estimators': 25}, 'config_hash': {'algorithm': '68ab9059aa7ec74e0da87c81734b9664243b3eb4', 'config': 'e5241eee9ddf3f4ee29a4711f5bcc92a4d24cd09', 'pipeline': '62463de065924498cdcd2f2f1f7e68535cdb33a5'}, 'duration': 0.6592490673065186, 'iteration': 2, 'loss': 0.07695856019358727, 'max_history_score': 0.9456356408262035, 'max_history_score_std': 0.040053650785990214, 'max_history_step': 'joint', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 1, 'features__selectkbest__k': 2}), 'normalizer': ('normalizer_NoneType', {}), 'rebalance': ('rebalance_NoneType', {})}, 'score': 0.9230414398064127, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': 3, 'max_features': 2, 'max_leaf_nodes': 2, 'min_samples_split': 2, 'n_estimators': 25}, 'config_hash': {'algorithm': 'e3f1f7d7783557a38f40f0476369091edd87092b', 'config': '18ee4d3d1627472ec190326308d8755371a6dc62', 'pipeline': 'c6d1263e344ed8c71b2e6e4ba8e0db2fb6c777c0'}, 'duration': 0.879349946975708, 'iteration': 3, 'loss': 0.07535973554576114, 'max_history_score': 0.9456356408262035, 'max_history_score_std': 0.040053650785990214, 'max_history_step': 'joint', 'pipeline': {'features': ('features_NoneType', {}), 'normalizer': ('normalizer_RobustScaler', {'normalizer__quantile_range': (...), 'normalizer__with_centering': True, 'normalizer__with_scaling': True}), 'rebalance': ('rebalance_NearMiss', {'rebalance__n_neighbors': 2})}, 'score': 0.9246402644542389, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'gini', 'max_depth': 4, 'max_features': 2, 'max_leaf_nodes': 5, 'min_samples_split': 2, 'n_estimators': 50}, 'config_hash': {'algorithm': '47581af7253940f9647ad16d37347d34baf13e5f', 'config': '2af4f82b045c0c48ecb89d42728d1039fbff8878', 'pipeline': '2928b22ed834303cb7bac6e6608531eaddd7df67'}, 'duration': 4.372632026672363, 'iteration': 4, 'loss': 0.09121294615849984, 'max_history_score': 0.9456356408262035, 'max_history_score_std': 0.040053650785990214, 'max_history_step': 'joint', 'pipeline': {'features': ('features_NoneType', {}), 'normalizer': ('normalizer_MinMaxScaler', {}), 'rebalance': ('rebalance_CondensedNearestNeighbour', {'rebalance__n_neighbors': 2})}, 'score': 0.9087870538415002, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'entropy', 'max_depth': 2, 'max_features': 2, 'max_leaf_nodes': None, 'min_samples_split': 2, 'n_estimators': 10}, 'config_hash': {'algorithm': '0a85f98ca2d06103287f153633d88f7a0535e7e8', 'config': '17b2a1e5814f3e933137158708a5b6e9b2475495', 'pipeline': '95defa3bdd8357f11f872d3c280d50a6d8ee398d'}, 'duration': 2.625814914703369, 'iteration': 5, 'loss': 0.15471329185031535, 'max_history_score': 0.9456356408262035, 'max_history_score_std': 0.040053650785990214, 'max_history_step': 'joint', 'pipeline': {'features': ('features_SelectKBest', {'features__k': 2}), 'normalizer': ('normalizer_StandardScaler', {'normalizer__with_mean': False, 'normalizer__with_std': False}), 'rebalance': ('rebalance_CondensedNearestNeighbour', {'rebalance__n_neighbors': 1})}, 'score': 0.8452867081496847, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': 3, 'max_features': None, 'max_leaf_nodes': None, 'min_samples_split': 5, 'n_estimators': 75}, 'config_hash': {'algorithm': 'd7466a2c1d5cb3fa95029d73dc030f4c3c45a159', 'config': 'fa020a592ec5ac234f9f91aac28abc2cd1ec9d33', 'pipeline': '71e0d26f923d42cfe0e2fa748931ef2afe72ed86'}, 'duration': 3.62078595161438, 'iteration': 6, 'loss': 0.17066372828623277, 'max_history_score': 0.9456356408262035, 'max_history_score_std': 0.040053650785990214, 'max_history_step': 'joint', 'pipeline': {'features': ('features_SelectKBest', {'features__k': 1}), 'normalizer': ('normalizer_RobustScaler', {'normalizer__quantile_range': (...), 'normalizer__with_centering': True, 'normalizer__with_scaling': True}), 'rebalance': ('rebalance_CondensedNearestNeighbour', {'rebalance__n_neighbors': 1})}, 'score': 0.8293362717137672, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'entropy', 'max_depth': 3, 'max_features': 3, 'max_leaf_nodes': 5, 'min_samples_split': 5, 'n_estimators': 50}, 'config_hash': {'algorithm': '735caa9785596076014572a24050cde8dc338973', 'config': '0da4498002d6f452c59bb61756abb3ded841e786', 'pipeline': '51a53ea6ef5a2521ee65f76eb2da220ab7086513'}, 'duration': 0.6934049129486084, 'iteration': 7, 'loss': 0.06125875032408601, 'max_history_score': 0.9456356408262035, 'max_history_score_std': 0.040053650785990214, 'max_history_step': 'joint', 'pipeline': {'features': ('features_NoneType', {}), 'normalizer': ('normalizer_NoneType', {}), 'rebalance': ('rebalance_NearMiss', {'rebalance__n_neighbors': 3})}, 'score': 0.938741249675914, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': 4, 'max_features': 2, 'max_leaf_nodes': None, 'min_samples_split': 3, 'n_estimators': 75}, 'config_hash': {'algorithm': 'e71a1fe9515b6805f07914a61f2e7594be9e9afe', 'config': '344e4756fb1bec455d6af51d3727e33b0d27725f', 'pipeline': '248dad1d8b30a17a5de1d0bbdfe3e2acb7a1962b'}, 'duration': 1.3036692142486572, 'iteration': 8, 'loss': 0.06483125918243893, 'max_history_score': 0.9456356408262035, 'max_history_score_std': 0.040053650785990214, 'max_history_step': 'joint', 'pipeline': {'features': ('features_PCA', {'features__n_components': 2}), 'normalizer': ('normalizer_StandardScaler', {'normalizer__with_mean': False, 'normalizer__with_std': True}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 7})}, 'score': 0.9351687408175611, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'entropy', 'max_depth': 2, 'max_features': 2, 'max_leaf_nodes': 2, 'min_samples_split': 3, 'n_estimators': 10}, 'config_hash': {'algorithm': '0a507823f2ad8605ed5950e1fe61df0560f11a00', 'config': '4a538fdcf8e07f90e92a421c0d5c479d651629c7', 'pipeline': '5240329df25c9a533d025c1a401d49835a501b41'}, 'duration': 1.3821029663085938, 'iteration': 9, 'loss': 0.07006416904329793, 'max_history_score': 0.9456356408262035, 'max_history_score_std': 0.040053650785990214, 'max_history_step': 'joint', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 4, 'features__selectkbest__k': 2}), 'normalizer': ('normalizer_PowerTransformer', {}), 'rebalance': ('rebalance_NearMiss', {'rebalance__n_neighbors': 1})}, 'score': 0.9299358309567021, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'gini', 'max_depth': 1, 'max_features': 3, 'max_leaf_nodes': 5, 'min_samples_split': 3, 'n_estimators': 10}, 'config_hash': {'algorithm': 'd32739750d351948f8ff34a87c7d55b0c5e0d90f', 'config': 'c1609e71f1ce8486335adc70bb69a955580ba2c8', 'pipeline': 'f48b42ec5cf999279659966160a16353b75bdaa3'}, 'duration': 0.9055681228637695, 'iteration': 10, 'loss': 0.07532840722495904, 'max_history_score': 0.9456356408262035, 'max_history_score_std': 0.040053650785990214, 'max_history_step': 'joint', 'pipeline': {'features': ('features_PCA', {'features__n_components': 4}), 'normalizer': ('normalizer_PowerTransformer', {}), 'rebalance': ('rebalance_NearMiss', {'rebalance__n_neighbors': 1})}, 'score': 0.924671592775041, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': 3, 'max_features': 1, 'max_leaf_nodes': 5, 'min_samples_split': 3, 'n_estimators': 25}, 'config_hash': {'algorithm': 'f69bac35e71cbec1bfc1fb5942328a3390e7c252', 'config': 'abe36f188644e53e56ed3224236fa157107ed3b2', 'pipeline': 'aaf976c7c663a31fa039582d42f9e07101556a7c'}, 'duration': 0.764197826385498, 'iteration': 11, 'loss': 0.06818446979517778, 'max_history_score': 0.9456356408262035, 'max_history_score_std': 0.040053650785990214, 'max_history_step': 'joint', 'pipeline': {'features': ('features_NoneType', {}), 'normalizer': ('normalizer_PowerTransformer', {}), 'rebalance': ('rebalance_NoneType', {})}, 'score': 0.9318155302048222, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'entropy', 'max_depth': None, 'max_features': None, 'max_leaf_nodes': None, 'min_samples_split': 5, 'n_estimators': 25}, 'config_hash': {'algorithm': 'a0a27aec00db5ddf71eab96663f9bd61c845f5e3', 'config': '76aa002c3c9d4d9722466c60daf5119c18a41d2a', 'pipeline': '1ce34b7894ef342571d974bb19e8ec821a512c6b'}, 'duration': 1.1636500358581543, 'iteration': 12, 'loss': 0.12833700630887557, 'max_history_score': 0.9456356408262035, 'max_history_score_std': 0.040053650785990214, 'max_history_step': 'joint', 'pipeline': {'features': ('features_PCA', {'features__n_components': 1}), 'normalizer': ('normalizer_PowerTransformer', {}), 'rebalance': ('rebalance_NoneType', {})}, 'score': 0.8716629936911244, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'gini', 'max_depth': 1, 'max_features': 2, 'max_leaf_nodes': 2, 'min_samples_split': 2, 'n_estimators': 100}, 'config_hash': {'algorithm': '985c99dff1da9b2c87e4211c5335a9159aa9dbcb', 'config': 'f56a7a9e43a0a699e992dc1262e550b8b7c88538', 'pipeline': '5c934f6d9a8ad1f9afe762986a9cf2074fc95d79'}, 'duration': 2.235443115234375, 'iteration': 13, 'loss': 0.11414635727249167, 'max_history_score': 0.9456356408262035, 'max_history_score_std': 0.040053650785990214, 'max_history_step': 'joint', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 1, 'features__selectkbest__k': 1}), 'normalizer': ('normalizer_RobustScaler', {'normalizer__quantile_range': (...), 'normalizer__with_centering': False, 'normalizer__with_scaling': True}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 6})}, 'score': 0.8858536427275083, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'gini', 'max_depth': 1, 'max_features': 1, 'max_leaf_nodes': None, 'min_samples_split': 5, 'n_estimators': 10}, 'config_hash': {'algorithm': '7d74a39aac2579264a402aef2b6fa7943c19f3d3', 'config': '53f44c0ad925c5c08c25d4fadf5e9ee9d7c181cd', 'pipeline': '6eff5ef31d7d1d534db31913bb67529c8a24c42e'}, 'duration': 2.7847659587860107, 'iteration': 14, 'loss': 0.14061986863711007, 'max_history_score': 0.9456356408262035, 'max_history_score_std': 0.040053650785990214, 'max_history_step': 'joint', 'pipeline': {'features': ('features_PCA', {'features__n_components': 1}), 'normalizer': ('normalizer_RobustScaler', {'normalizer__quantile_range': (...), 'normalizer__with_centering': True, 'normalizer__with_scaling': True}), 'rebalance': ('rebalance_CondensedNearestNeighbour', {'rebalance__n_neighbors': 3})}, 'score': 0.8593801313628899, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'entropy', 'max_depth': 3, 'max_features': None, 'max_leaf_nodes': 5, 'min_samples_split': 2, 'n_estimators': 100}, 'config_hash': {'algorithm': 'c62d7c671832e4414b6b2d7c36cba5ddc83a0ed0', 'config': '5faee50671eaa0ac586722bff234e36a857e662d', 'pipeline': '8b29a55de2add78c49114b9bbe5e800e5524c59d'}, 'duration': 2.3916029930114746, 'iteration': 15, 'loss': 0.08770093336790252, 'max_history_score': 0.9456356408262035, 'max_history_score_std': 0.040053650785990214, 'max_history_step': 'joint', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 3, 'features__selectkbest__k': 4}), 'normalizer': ('normalizer_RobustScaler', {'normalizer__quantile_range': (...), 'normalizer__with_centering': True, 'normalizer__with_scaling': True}), 'rebalance': ('rebalance_NoneType', {})}, 'score': 0.9122990666320975, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': None, 'max_features': 1, 'max_leaf_nodes': 5, 'min_samples_split': 5, 'n_estimators': 10}, 'config_hash': {'algorithm': '290772bfb9b8ed15c48a72829e822fb0a07481d6', 'config': '9a04f25d8eb3db5b2f831abd341a6d384c73a957', 'pipeline': '1ce34b7894ef342571d974bb19e8ec821a512c6b'}, 'duration': 1.4364500045776367, 'iteration': 16, 'loss': 0.08948880822746508, 'max_history_score': 0.9456356408262035, 'max_history_score_std': 0.040053650785990214, 'max_history_step': 'joint', 'pipeline': {'features': ('features_PCA', {'features__n_components': 1}), 'normalizer': ('normalizer_PowerTransformer', {}), 'rebalance': ('rebalance_NoneType', {})}, 'score': 0.9105111917725349, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': 2, 'max_features': 3, 'max_leaf_nodes': 3, 'min_samples_split': 3, 'n_estimators': 100}, 'config_hash': {'algorithm': '7dab6d47f897c2961d3402eff844aff16a7d142a', 'config': '4dbfa2688b239be9f372d3e80223960ba9a1fbdd', 'pipeline': 'cdef51702798fa49f11c11d80baf3ab43d5358fc'}, 'duration': 0.9830451011657715, 'iteration': 17, 'loss': 1.0, 'max_history_score': 0.9456356408262035, 'max_history_score_std': 0.040053650785990214, 'max_history_step': 'joint', 'pipeline': {'features': ('features_SelectKBest', {'features__k': 2}), 'normalizer': ('normalizer_PowerTransformer', {}), 'rebalance': ('rebalance_NearMiss', {'rebalance__n_neighbors': 1})}, 'score': 0.0, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'entropy', 'max_depth': None, 'max_features': 3, 'max_leaf_nodes': None, 'min_samples_split': 5, 'n_estimators': 10}, 'config_hash': {'algorithm': 'def83e48be05ef92a37e1a90585820f2f67ff42b', 'config': '95902552cb76e9798f0fa58782bd72bd1cc272d7', 'pipeline': '1775187bf23f94f4fd0cc1e5c1ef665210edded5'}, 'duration': 2.0033559799194336, 'iteration': 18, 'loss': 0.04922327370149515, 'max_history_score': 0.9507767262985048, 'max_history_score_std': 0.028328108925705902, 'max_history_step': 'joint', 'pipeline': {'features': ('features_PCA', {'features__n_components': 4}), 'normalizer': ('normalizer_StandardScaler', {'normalizer__with_mean': True, 'normalizer__with_std': True}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 5})}, 'score': 0.9507767262985048, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'gini', 'max_depth': 1, 'max_features': 3, 'max_leaf_nodes': None, 'min_samples_split': 2, 'n_estimators': 50}, 'config_hash': {'algorithm': '4e9e3275f817df75115d9d7e3366980fc1b4cf13', 'config': '7770b19007b40bf13005d52eb81f87bc401f15b4', 'pipeline': 'c4dd111513ea35f97dd3aec3e8e7f6268ce035da'}, 'duration': 0.9069631099700928, 'iteration': 19, 'loss': 1.0, 'max_history_score': 0.9507767262985048, 'max_history_score_std': 0.028328108925705902, 'max_history_step': 'joint', 'pipeline': {'features': ('features_PCA', {'features__n_components': 2}), 'normalizer': ('normalizer_RobustScaler', {'normalizer__quantile_range': (...), 'normalizer__with_centering': False, 'normalizer__with_scaling': True}), 'rebalance': ('rebalance_NearMiss', {'rebalance__n_neighbors': 2})}, 'score': 0.0, ...}, ...], 'history_hash': ['51144ca42f9ea5ab2d8d58606e3b3e4d89c6d7b3', '9e54ffcb6a727de032a0a2cd45c5cc37cc150756', 'e5241eee9ddf3f4ee29a4711f5bcc92a4d24cd09', '18ee4d3d1627472ec190326308d8755371a6dc62', '2af4f82b045c0c48ecb89d42728d1039fbff8878', '17b2a1e5814f3e933137158708a5b6e9b2475495', 'fa020a592ec5ac234f9f91aac28abc2cd1ec9d33', '0da4498002d6f452c59bb61756abb3ded841e786', '344e4756fb1bec455d6af51d3727e33b0d27725f', '4a538fdcf8e07f90e92a421c0d5c479d651629c7', 'c1609e71f1ce8486335adc70bb69a955580ba2c8', 'abe36f188644e53e56ed3224236fa157107ed3b2', '76aa002c3c9d4d9722466c60daf5119c18a41d2a', 'f56a7a9e43a0a699e992dc1262e550b8b7c88538', '53f44c0ad925c5c08c25d4fadf5e9ee9d7c181cd', '5faee50671eaa0ac586722bff234e36a857e662d', '9a04f25d8eb3db5b2f831abd341a6d384c73a957', '4dbfa2688b239be9f372d3e80223960ba9a1fbdd', '95902552cb76e9798f0fa58782bd72bd1cc272d7', '7770b19007b40bf13005d52eb81f87bc401f15b4', ...], 'history_index': {'0da4498002d6f452c59bb61756abb3ded841e786': 7, '0f77a69b0a8d34861caf915a51dc588ff8d4efac': 61, '127553d555ed39231b8da3a1ce42d3902e30919b': 59, '17b2a1e5814f3e933137158708a5b6e9b2475495': 5, '18ee4d3d1627472ec190326308d8755371a6dc62': 3, '1b2267555a9226d7eb4df3c63dd12506da370f4d': 56, '2af4f82b045c0c48ecb89d42728d1039fbff8878': 4, '2d054540972225f4f17fb36d63106b7bb5c406fe': 36, '306511091d7e5d6431b5e5a6320802c4c04cde44': 33, '312e05571f41c77895a9ad8c57db6947f3fdfe03': 58, ...}, 'iteration': 63, 'max_history_score': 0.9525008642295394, 'max_history_score_std': 0.02225295065716913, 'max_history_step': 'joint'}, config={'algorithm': 'RandomForest', 'seed': 42, 'time': 300})
    108 
    109 def objective_algo(algo_config, current_pipeline_config, algorithm, X, y, context, config):
    110     return objective(current_pipeline_config, algo_config, algorithm, X, y, context, config, step='algorithm')
    111 
    112 def objective_joint(wconfig, algorithm, X, y, context, config):
--> 113     return objective(wconfig['pipeline'], wconfig['algorithm'], algorithm, X, y, context, config, step='joint')
        wconfig = {'algorithm': {'bootstrap': False, 'criterion': 'entropy', 'max_depth': None, 'max_features': 3, 'max_leaf_nodes': None, 'min_samples_split': 5, 'n_estimators': 10}, 'pipeline': {'features': ('features_PCA', {'features__n_components': 1}), 'normalizer': ('normalizer_StandardScaler', {'normalizer__with_mean': False, 'normalizer__with_std': True}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 5})}}
        algorithm = 'RandomForest'
        X = array([[1.799e+01, 1.038e+01, 1.228e+02, ..., 2...., ..., 0.000e+00, 2.871e-01,
        7.039e-02]])
        y = array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,... 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1])
        context = {'baseline_score': 0.9545944602886527, 'baseline_score_std': 0.03716322883281839, 'best_config': {'algorithm': {'bootstrap': False, 'criterion': 'entropy', 'max_depth': None, 'max_features': 2, 'max_leaf_nodes': None, 'min_samples_split': 5, 'n_estimators': 10}, 'config_hash': {'algorithm': 'e7a772c2bc361aa61cf7eeb364a26dca2c9b89d6', 'config': 'afb67da069b544b0505b1e8c150edc7498ad37b4', 'pipeline': 'a43db4b4fc4c38610b7b5e484840d2e583089ff4'}, 'duration': 1.0073001384735107, 'iteration': 26, 'loss': 0.04749913577046061, 'max_history_score': 0.9525008642295394, 'max_history_score_std': 0.02225295065716913, 'max_history_step': 'joint', 'pipeline': {'features': ('features_PCA', {'features__n_components': 4}), 'normalizer': ('normalizer_StandardScaler', {'normalizer__with_mean': True, 'normalizer__with_std': False}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 7})}, 'score': 0.9525008642295394, ...}, 'history': [{'algorithm': {'bootstrap': True, 'criterion': 'entropy', 'max_depth': 4, 'max_features': 3, 'max_leaf_nodes': 3, 'min_samples_split': 2, 'n_estimators': 10}, 'config_hash': {'algorithm': '42527c4120073c2a488d1b8df28732f486d1578c', 'config': '51144ca42f9ea5ab2d8d58606e3b3e4d89c6d7b3', 'pipeline': '52f07bda29f9d3a95fabb87e591d0b2581ca8209'}, 'duration': 0.26703310012817383, 'iteration': 0, 'loss': 0.06655431682654922, 'max_history_score': 0.9334456831734508, 'max_history_score_std': 0.03819399139659311, 'max_history_step': 'joint', 'pipeline': {'features': ('features_NoneType', {}), 'normalizer': ('normalizer_RobustScaler', {'normalizer__quantile_range': (...), 'normalizer__with_centering': False, 'normalizer__with_scaling': False}), 'rebalance': ('rebalance_NearMiss', {'rebalance__n_neighbors': 1})}, 'score': 0.9334456831734508, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': None, 'max_features': 2, 'max_leaf_nodes': 3, 'min_samples_split': 2, 'n_estimators': 100}, 'config_hash': {'algorithm': '1b32258c630f07e01ab481ab925ab80aa757e482', 'config': '9e54ffcb6a727de032a0a2cd45c5cc37cc150756', 'pipeline': '37e72d4a97f5e784c9d3133e6379b91bfc3be803'}, 'duration': 1.3065669536590576, 'iteration': 1, 'loss': 0.05436435917379645, 'max_history_score': 0.9456356408262035, 'max_history_score_std': 0.040053650785990214, 'max_history_step': 'joint', 'pipeline': {'features': ('features_NoneType', {}), 'normalizer': ('normalizer_StandardScaler', {'normalizer__with_mean': True, 'normalizer__with_std': True}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 6})}, 'score': 0.9456356408262035, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'entropy', 'max_depth': 1, 'max_features': 1, 'max_leaf_nodes': 2, 'min_samples_split': 3, 'n_estimators': 25}, 'config_hash': {'algorithm': '68ab9059aa7ec74e0da87c81734b9664243b3eb4', 'config': 'e5241eee9ddf3f4ee29a4711f5bcc92a4d24cd09', 'pipeline': '62463de065924498cdcd2f2f1f7e68535cdb33a5'}, 'duration': 0.6592490673065186, 'iteration': 2, 'loss': 0.07695856019358727, 'max_history_score': 0.9456356408262035, 'max_history_score_std': 0.040053650785990214, 'max_history_step': 'joint', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 1, 'features__selectkbest__k': 2}), 'normalizer': ('normalizer_NoneType', {}), 'rebalance': ('rebalance_NoneType', {})}, 'score': 0.9230414398064127, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': 3, 'max_features': 2, 'max_leaf_nodes': 2, 'min_samples_split': 2, 'n_estimators': 25}, 'config_hash': {'algorithm': 'e3f1f7d7783557a38f40f0476369091edd87092b', 'config': '18ee4d3d1627472ec190326308d8755371a6dc62', 'pipeline': 'c6d1263e344ed8c71b2e6e4ba8e0db2fb6c777c0'}, 'duration': 0.879349946975708, 'iteration': 3, 'loss': 0.07535973554576114, 'max_history_score': 0.9456356408262035, 'max_history_score_std': 0.040053650785990214, 'max_history_step': 'joint', 'pipeline': {'features': ('features_NoneType', {}), 'normalizer': ('normalizer_RobustScaler', {'normalizer__quantile_range': (...), 'normalizer__with_centering': True, 'normalizer__with_scaling': True}), 'rebalance': ('rebalance_NearMiss', {'rebalance__n_neighbors': 2})}, 'score': 0.9246402644542389, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'gini', 'max_depth': 4, 'max_features': 2, 'max_leaf_nodes': 5, 'min_samples_split': 2, 'n_estimators': 50}, 'config_hash': {'algorithm': '47581af7253940f9647ad16d37347d34baf13e5f', 'config': '2af4f82b045c0c48ecb89d42728d1039fbff8878', 'pipeline': '2928b22ed834303cb7bac6e6608531eaddd7df67'}, 'duration': 4.372632026672363, 'iteration': 4, 'loss': 0.09121294615849984, 'max_history_score': 0.9456356408262035, 'max_history_score_std': 0.040053650785990214, 'max_history_step': 'joint', 'pipeline': {'features': ('features_NoneType', {}), 'normalizer': ('normalizer_MinMaxScaler', {}), 'rebalance': ('rebalance_CondensedNearestNeighbour', {'rebalance__n_neighbors': 2})}, 'score': 0.9087870538415002, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'entropy', 'max_depth': 2, 'max_features': 2, 'max_leaf_nodes': None, 'min_samples_split': 2, 'n_estimators': 10}, 'config_hash': {'algorithm': '0a85f98ca2d06103287f153633d88f7a0535e7e8', 'config': '17b2a1e5814f3e933137158708a5b6e9b2475495', 'pipeline': '95defa3bdd8357f11f872d3c280d50a6d8ee398d'}, 'duration': 2.625814914703369, 'iteration': 5, 'loss': 0.15471329185031535, 'max_history_score': 0.9456356408262035, 'max_history_score_std': 0.040053650785990214, 'max_history_step': 'joint', 'pipeline': {'features': ('features_SelectKBest', {'features__k': 2}), 'normalizer': ('normalizer_StandardScaler', {'normalizer__with_mean': False, 'normalizer__with_std': False}), 'rebalance': ('rebalance_CondensedNearestNeighbour', {'rebalance__n_neighbors': 1})}, 'score': 0.8452867081496847, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': 3, 'max_features': None, 'max_leaf_nodes': None, 'min_samples_split': 5, 'n_estimators': 75}, 'config_hash': {'algorithm': 'd7466a2c1d5cb3fa95029d73dc030f4c3c45a159', 'config': 'fa020a592ec5ac234f9f91aac28abc2cd1ec9d33', 'pipeline': '71e0d26f923d42cfe0e2fa748931ef2afe72ed86'}, 'duration': 3.62078595161438, 'iteration': 6, 'loss': 0.17066372828623277, 'max_history_score': 0.9456356408262035, 'max_history_score_std': 0.040053650785990214, 'max_history_step': 'joint', 'pipeline': {'features': ('features_SelectKBest', {'features__k': 1}), 'normalizer': ('normalizer_RobustScaler', {'normalizer__quantile_range': (...), 'normalizer__with_centering': True, 'normalizer__with_scaling': True}), 'rebalance': ('rebalance_CondensedNearestNeighbour', {'rebalance__n_neighbors': 1})}, 'score': 0.8293362717137672, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'entropy', 'max_depth': 3, 'max_features': 3, 'max_leaf_nodes': 5, 'min_samples_split': 5, 'n_estimators': 50}, 'config_hash': {'algorithm': '735caa9785596076014572a24050cde8dc338973', 'config': '0da4498002d6f452c59bb61756abb3ded841e786', 'pipeline': '51a53ea6ef5a2521ee65f76eb2da220ab7086513'}, 'duration': 0.6934049129486084, 'iteration': 7, 'loss': 0.06125875032408601, 'max_history_score': 0.9456356408262035, 'max_history_score_std': 0.040053650785990214, 'max_history_step': 'joint', 'pipeline': {'features': ('features_NoneType', {}), 'normalizer': ('normalizer_NoneType', {}), 'rebalance': ('rebalance_NearMiss', {'rebalance__n_neighbors': 3})}, 'score': 0.938741249675914, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': 4, 'max_features': 2, 'max_leaf_nodes': None, 'min_samples_split': 3, 'n_estimators': 75}, 'config_hash': {'algorithm': 'e71a1fe9515b6805f07914a61f2e7594be9e9afe', 'config': '344e4756fb1bec455d6af51d3727e33b0d27725f', 'pipeline': '248dad1d8b30a17a5de1d0bbdfe3e2acb7a1962b'}, 'duration': 1.3036692142486572, 'iteration': 8, 'loss': 0.06483125918243893, 'max_history_score': 0.9456356408262035, 'max_history_score_std': 0.040053650785990214, 'max_history_step': 'joint', 'pipeline': {'features': ('features_PCA', {'features__n_components': 2}), 'normalizer': ('normalizer_StandardScaler', {'normalizer__with_mean': False, 'normalizer__with_std': True}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 7})}, 'score': 0.9351687408175611, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'entropy', 'max_depth': 2, 'max_features': 2, 'max_leaf_nodes': 2, 'min_samples_split': 3, 'n_estimators': 10}, 'config_hash': {'algorithm': '0a507823f2ad8605ed5950e1fe61df0560f11a00', 'config': '4a538fdcf8e07f90e92a421c0d5c479d651629c7', 'pipeline': '5240329df25c9a533d025c1a401d49835a501b41'}, 'duration': 1.3821029663085938, 'iteration': 9, 'loss': 0.07006416904329793, 'max_history_score': 0.9456356408262035, 'max_history_score_std': 0.040053650785990214, 'max_history_step': 'joint', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 4, 'features__selectkbest__k': 2}), 'normalizer': ('normalizer_PowerTransformer', {}), 'rebalance': ('rebalance_NearMiss', {'rebalance__n_neighbors': 1})}, 'score': 0.9299358309567021, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'gini', 'max_depth': 1, 'max_features': 3, 'max_leaf_nodes': 5, 'min_samples_split': 3, 'n_estimators': 10}, 'config_hash': {'algorithm': 'd32739750d351948f8ff34a87c7d55b0c5e0d90f', 'config': 'c1609e71f1ce8486335adc70bb69a955580ba2c8', 'pipeline': 'f48b42ec5cf999279659966160a16353b75bdaa3'}, 'duration': 0.9055681228637695, 'iteration': 10, 'loss': 0.07532840722495904, 'max_history_score': 0.9456356408262035, 'max_history_score_std': 0.040053650785990214, 'max_history_step': 'joint', 'pipeline': {'features': ('features_PCA', {'features__n_components': 4}), 'normalizer': ('normalizer_PowerTransformer', {}), 'rebalance': ('rebalance_NearMiss', {'rebalance__n_neighbors': 1})}, 'score': 0.924671592775041, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': 3, 'max_features': 1, 'max_leaf_nodes': 5, 'min_samples_split': 3, 'n_estimators': 25}, 'config_hash': {'algorithm': 'f69bac35e71cbec1bfc1fb5942328a3390e7c252', 'config': 'abe36f188644e53e56ed3224236fa157107ed3b2', 'pipeline': 'aaf976c7c663a31fa039582d42f9e07101556a7c'}, 'duration': 0.764197826385498, 'iteration': 11, 'loss': 0.06818446979517778, 'max_history_score': 0.9456356408262035, 'max_history_score_std': 0.040053650785990214, 'max_history_step': 'joint', 'pipeline': {'features': ('features_NoneType', {}), 'normalizer': ('normalizer_PowerTransformer', {}), 'rebalance': ('rebalance_NoneType', {})}, 'score': 0.9318155302048222, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'entropy', 'max_depth': None, 'max_features': None, 'max_leaf_nodes': None, 'min_samples_split': 5, 'n_estimators': 25}, 'config_hash': {'algorithm': 'a0a27aec00db5ddf71eab96663f9bd61c845f5e3', 'config': '76aa002c3c9d4d9722466c60daf5119c18a41d2a', 'pipeline': '1ce34b7894ef342571d974bb19e8ec821a512c6b'}, 'duration': 1.1636500358581543, 'iteration': 12, 'loss': 0.12833700630887557, 'max_history_score': 0.9456356408262035, 'max_history_score_std': 0.040053650785990214, 'max_history_step': 'joint', 'pipeline': {'features': ('features_PCA', {'features__n_components': 1}), 'normalizer': ('normalizer_PowerTransformer', {}), 'rebalance': ('rebalance_NoneType', {})}, 'score': 0.8716629936911244, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'gini', 'max_depth': 1, 'max_features': 2, 'max_leaf_nodes': 2, 'min_samples_split': 2, 'n_estimators': 100}, 'config_hash': {'algorithm': '985c99dff1da9b2c87e4211c5335a9159aa9dbcb', 'config': 'f56a7a9e43a0a699e992dc1262e550b8b7c88538', 'pipeline': '5c934f6d9a8ad1f9afe762986a9cf2074fc95d79'}, 'duration': 2.235443115234375, 'iteration': 13, 'loss': 0.11414635727249167, 'max_history_score': 0.9456356408262035, 'max_history_score_std': 0.040053650785990214, 'max_history_step': 'joint', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 1, 'features__selectkbest__k': 1}), 'normalizer': ('normalizer_RobustScaler', {'normalizer__quantile_range': (...), 'normalizer__with_centering': False, 'normalizer__with_scaling': True}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 6})}, 'score': 0.8858536427275083, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'gini', 'max_depth': 1, 'max_features': 1, 'max_leaf_nodes': None, 'min_samples_split': 5, 'n_estimators': 10}, 'config_hash': {'algorithm': '7d74a39aac2579264a402aef2b6fa7943c19f3d3', 'config': '53f44c0ad925c5c08c25d4fadf5e9ee9d7c181cd', 'pipeline': '6eff5ef31d7d1d534db31913bb67529c8a24c42e'}, 'duration': 2.7847659587860107, 'iteration': 14, 'loss': 0.14061986863711007, 'max_history_score': 0.9456356408262035, 'max_history_score_std': 0.040053650785990214, 'max_history_step': 'joint', 'pipeline': {'features': ('features_PCA', {'features__n_components': 1}), 'normalizer': ('normalizer_RobustScaler', {'normalizer__quantile_range': (...), 'normalizer__with_centering': True, 'normalizer__with_scaling': True}), 'rebalance': ('rebalance_CondensedNearestNeighbour', {'rebalance__n_neighbors': 3})}, 'score': 0.8593801313628899, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'entropy', 'max_depth': 3, 'max_features': None, 'max_leaf_nodes': 5, 'min_samples_split': 2, 'n_estimators': 100}, 'config_hash': {'algorithm': 'c62d7c671832e4414b6b2d7c36cba5ddc83a0ed0', 'config': '5faee50671eaa0ac586722bff234e36a857e662d', 'pipeline': '8b29a55de2add78c49114b9bbe5e800e5524c59d'}, 'duration': 2.3916029930114746, 'iteration': 15, 'loss': 0.08770093336790252, 'max_history_score': 0.9456356408262035, 'max_history_score_std': 0.040053650785990214, 'max_history_step': 'joint', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 3, 'features__selectkbest__k': 4}), 'normalizer': ('normalizer_RobustScaler', {'normalizer__quantile_range': (...), 'normalizer__with_centering': True, 'normalizer__with_scaling': True}), 'rebalance': ('rebalance_NoneType', {})}, 'score': 0.9122990666320975, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': None, 'max_features': 1, 'max_leaf_nodes': 5, 'min_samples_split': 5, 'n_estimators': 10}, 'config_hash': {'algorithm': '290772bfb9b8ed15c48a72829e822fb0a07481d6', 'config': '9a04f25d8eb3db5b2f831abd341a6d384c73a957', 'pipeline': '1ce34b7894ef342571d974bb19e8ec821a512c6b'}, 'duration': 1.4364500045776367, 'iteration': 16, 'loss': 0.08948880822746508, 'max_history_score': 0.9456356408262035, 'max_history_score_std': 0.040053650785990214, 'max_history_step': 'joint', 'pipeline': {'features': ('features_PCA', {'features__n_components': 1}), 'normalizer': ('normalizer_PowerTransformer', {}), 'rebalance': ('rebalance_NoneType', {})}, 'score': 0.9105111917725349, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': 2, 'max_features': 3, 'max_leaf_nodes': 3, 'min_samples_split': 3, 'n_estimators': 100}, 'config_hash': {'algorithm': '7dab6d47f897c2961d3402eff844aff16a7d142a', 'config': '4dbfa2688b239be9f372d3e80223960ba9a1fbdd', 'pipeline': 'cdef51702798fa49f11c11d80baf3ab43d5358fc'}, 'duration': 0.9830451011657715, 'iteration': 17, 'loss': 1.0, 'max_history_score': 0.9456356408262035, 'max_history_score_std': 0.040053650785990214, 'max_history_step': 'joint', 'pipeline': {'features': ('features_SelectKBest', {'features__k': 2}), 'normalizer': ('normalizer_PowerTransformer', {}), 'rebalance': ('rebalance_NearMiss', {'rebalance__n_neighbors': 1})}, 'score': 0.0, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'entropy', 'max_depth': None, 'max_features': 3, 'max_leaf_nodes': None, 'min_samples_split': 5, 'n_estimators': 10}, 'config_hash': {'algorithm': 'def83e48be05ef92a37e1a90585820f2f67ff42b', 'config': '95902552cb76e9798f0fa58782bd72bd1cc272d7', 'pipeline': '1775187bf23f94f4fd0cc1e5c1ef665210edded5'}, 'duration': 2.0033559799194336, 'iteration': 18, 'loss': 0.04922327370149515, 'max_history_score': 0.9507767262985048, 'max_history_score_std': 0.028328108925705902, 'max_history_step': 'joint', 'pipeline': {'features': ('features_PCA', {'features__n_components': 4}), 'normalizer': ('normalizer_StandardScaler', {'normalizer__with_mean': True, 'normalizer__with_std': True}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 5})}, 'score': 0.9507767262985048, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'gini', 'max_depth': 1, 'max_features': 3, 'max_leaf_nodes': None, 'min_samples_split': 2, 'n_estimators': 50}, 'config_hash': {'algorithm': '4e9e3275f817df75115d9d7e3366980fc1b4cf13', 'config': '7770b19007b40bf13005d52eb81f87bc401f15b4', 'pipeline': 'c4dd111513ea35f97dd3aec3e8e7f6268ce035da'}, 'duration': 0.9069631099700928, 'iteration': 19, 'loss': 1.0, 'max_history_score': 0.9507767262985048, 'max_history_score_std': 0.028328108925705902, 'max_history_step': 'joint', 'pipeline': {'features': ('features_PCA', {'features__n_components': 2}), 'normalizer': ('normalizer_RobustScaler', {'normalizer__quantile_range': (...), 'normalizer__with_centering': False, 'normalizer__with_scaling': True}), 'rebalance': ('rebalance_NearMiss', {'rebalance__n_neighbors': 2})}, 'score': 0.0, ...}, ...], 'history_hash': ['51144ca42f9ea5ab2d8d58606e3b3e4d89c6d7b3', '9e54ffcb6a727de032a0a2cd45c5cc37cc150756', 'e5241eee9ddf3f4ee29a4711f5bcc92a4d24cd09', '18ee4d3d1627472ec190326308d8755371a6dc62', '2af4f82b045c0c48ecb89d42728d1039fbff8878', '17b2a1e5814f3e933137158708a5b6e9b2475495', 'fa020a592ec5ac234f9f91aac28abc2cd1ec9d33', '0da4498002d6f452c59bb61756abb3ded841e786', '344e4756fb1bec455d6af51d3727e33b0d27725f', '4a538fdcf8e07f90e92a421c0d5c479d651629c7', 'c1609e71f1ce8486335adc70bb69a955580ba2c8', 'abe36f188644e53e56ed3224236fa157107ed3b2', '76aa002c3c9d4d9722466c60daf5119c18a41d2a', 'f56a7a9e43a0a699e992dc1262e550b8b7c88538', '53f44c0ad925c5c08c25d4fadf5e9ee9d7c181cd', '5faee50671eaa0ac586722bff234e36a857e662d', '9a04f25d8eb3db5b2f831abd341a6d384c73a957', '4dbfa2688b239be9f372d3e80223960ba9a1fbdd', '95902552cb76e9798f0fa58782bd72bd1cc272d7', '7770b19007b40bf13005d52eb81f87bc401f15b4', ...], 'history_index': {'0da4498002d6f452c59bb61756abb3ded841e786': 7, '0f77a69b0a8d34861caf915a51dc588ff8d4efac': 61, '127553d555ed39231b8da3a1ce42d3902e30919b': 59, '17b2a1e5814f3e933137158708a5b6e9b2475495': 5, '18ee4d3d1627472ec190326308d8755371a6dc62': 3, '1b2267555a9226d7eb4df3c63dd12506da370f4d': 56, '2af4f82b045c0c48ecb89d42728d1039fbff8878': 4, '2d054540972225f4f17fb36d63106b7bb5c406fe': 36, '306511091d7e5d6431b5e5a6320802c4c04cde44': 33, '312e05571f41c77895a9ad8c57db6947f3fdfe03': 58, ...}, 'iteration': 63, 'max_history_score': 0.9525008642295394, 'max_history_score_std': 0.02225295065716913, 'max_history_step': 'joint'}
        config = {'algorithm': 'RandomForest', 'seed': 42, 'time': 300}
    114 
    115 
    116 def get_baseline_score(algorithm, X, y, seed):
    117     pipeline, _ = pipeline_conf_to_full_pipeline(

...........................................................................
/home/aquemy/dev/dp_hyperparameters/extension/experiment/objective.py in objective(pipeline_config={'features': ('features_PCA', {'features__n_components': 1}), 'normalizer': ('normalizer_StandardScaler', {'normalizer__with_mean': False, 'normalizer__with_std': True}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 5})}, algo_config={'bootstrap': False, 'criterion': 'entropy', 'max_depth': None, 'max_features': 3, 'max_leaf_nodes': None, 'min_samples_split': 5, 'n_estimators': 10}, algorithm='RandomForest', X=array([[1.799e+01, 1.038e+01, 1.228e+02, ..., 2...., ..., 0.000e+00, 2.871e-01,
        7.039e-02]]), y=array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,... 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1]), context={'baseline_score': 0.9545944602886527, 'baseline_score_std': 0.03716322883281839, 'best_config': {'algorithm': {'bootstrap': False, 'criterion': 'entropy', 'max_depth': None, 'max_features': 2, 'max_leaf_nodes': None, 'min_samples_split': 5, 'n_estimators': 10}, 'config_hash': {'algorithm': 'e7a772c2bc361aa61cf7eeb364a26dca2c9b89d6', 'config': 'afb67da069b544b0505b1e8c150edc7498ad37b4', 'pipeline': 'a43db4b4fc4c38610b7b5e484840d2e583089ff4'}, 'duration': 1.0073001384735107, 'iteration': 26, 'loss': 0.04749913577046061, 'max_history_score': 0.9525008642295394, 'max_history_score_std': 0.02225295065716913, 'max_history_step': 'joint', 'pipeline': {'features': ('features_PCA', {'features__n_components': 4}), 'normalizer': ('normalizer_StandardScaler', {'normalizer__with_mean': True, 'normalizer__with_std': False}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 7})}, 'score': 0.9525008642295394, ...}, 'history': [{'algorithm': {'bootstrap': True, 'criterion': 'entropy', 'max_depth': 4, 'max_features': 3, 'max_leaf_nodes': 3, 'min_samples_split': 2, 'n_estimators': 10}, 'config_hash': {'algorithm': '42527c4120073c2a488d1b8df28732f486d1578c', 'config': '51144ca42f9ea5ab2d8d58606e3b3e4d89c6d7b3', 'pipeline': '52f07bda29f9d3a95fabb87e591d0b2581ca8209'}, 'duration': 0.26703310012817383, 'iteration': 0, 'loss': 0.06655431682654922, 'max_history_score': 0.9334456831734508, 'max_history_score_std': 0.03819399139659311, 'max_history_step': 'joint', 'pipeline': {'features': ('features_NoneType', {}), 'normalizer': ('normalizer_RobustScaler', {'normalizer__quantile_range': (...), 'normalizer__with_centering': False, 'normalizer__with_scaling': False}), 'rebalance': ('rebalance_NearMiss', {'rebalance__n_neighbors': 1})}, 'score': 0.9334456831734508, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': None, 'max_features': 2, 'max_leaf_nodes': 3, 'min_samples_split': 2, 'n_estimators': 100}, 'config_hash': {'algorithm': '1b32258c630f07e01ab481ab925ab80aa757e482', 'config': '9e54ffcb6a727de032a0a2cd45c5cc37cc150756', 'pipeline': '37e72d4a97f5e784c9d3133e6379b91bfc3be803'}, 'duration': 1.3065669536590576, 'iteration': 1, 'loss': 0.05436435917379645, 'max_history_score': 0.9456356408262035, 'max_history_score_std': 0.040053650785990214, 'max_history_step': 'joint', 'pipeline': {'features': ('features_NoneType', {}), 'normalizer': ('normalizer_StandardScaler', {'normalizer__with_mean': True, 'normalizer__with_std': True}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 6})}, 'score': 0.9456356408262035, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'entropy', 'max_depth': 1, 'max_features': 1, 'max_leaf_nodes': 2, 'min_samples_split': 3, 'n_estimators': 25}, 'config_hash': {'algorithm': '68ab9059aa7ec74e0da87c81734b9664243b3eb4', 'config': 'e5241eee9ddf3f4ee29a4711f5bcc92a4d24cd09', 'pipeline': '62463de065924498cdcd2f2f1f7e68535cdb33a5'}, 'duration': 0.6592490673065186, 'iteration': 2, 'loss': 0.07695856019358727, 'max_history_score': 0.9456356408262035, 'max_history_score_std': 0.040053650785990214, 'max_history_step': 'joint', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 1, 'features__selectkbest__k': 2}), 'normalizer': ('normalizer_NoneType', {}), 'rebalance': ('rebalance_NoneType', {})}, 'score': 0.9230414398064127, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': 3, 'max_features': 2, 'max_leaf_nodes': 2, 'min_samples_split': 2, 'n_estimators': 25}, 'config_hash': {'algorithm': 'e3f1f7d7783557a38f40f0476369091edd87092b', 'config': '18ee4d3d1627472ec190326308d8755371a6dc62', 'pipeline': 'c6d1263e344ed8c71b2e6e4ba8e0db2fb6c777c0'}, 'duration': 0.879349946975708, 'iteration': 3, 'loss': 0.07535973554576114, 'max_history_score': 0.9456356408262035, 'max_history_score_std': 0.040053650785990214, 'max_history_step': 'joint', 'pipeline': {'features': ('features_NoneType', {}), 'normalizer': ('normalizer_RobustScaler', {'normalizer__quantile_range': (...), 'normalizer__with_centering': True, 'normalizer__with_scaling': True}), 'rebalance': ('rebalance_NearMiss', {'rebalance__n_neighbors': 2})}, 'score': 0.9246402644542389, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'gini', 'max_depth': 4, 'max_features': 2, 'max_leaf_nodes': 5, 'min_samples_split': 2, 'n_estimators': 50}, 'config_hash': {'algorithm': '47581af7253940f9647ad16d37347d34baf13e5f', 'config': '2af4f82b045c0c48ecb89d42728d1039fbff8878', 'pipeline': '2928b22ed834303cb7bac6e6608531eaddd7df67'}, 'duration': 4.372632026672363, 'iteration': 4, 'loss': 0.09121294615849984, 'max_history_score': 0.9456356408262035, 'max_history_score_std': 0.040053650785990214, 'max_history_step': 'joint', 'pipeline': {'features': ('features_NoneType', {}), 'normalizer': ('normalizer_MinMaxScaler', {}), 'rebalance': ('rebalance_CondensedNearestNeighbour', {'rebalance__n_neighbors': 2})}, 'score': 0.9087870538415002, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'entropy', 'max_depth': 2, 'max_features': 2, 'max_leaf_nodes': None, 'min_samples_split': 2, 'n_estimators': 10}, 'config_hash': {'algorithm': '0a85f98ca2d06103287f153633d88f7a0535e7e8', 'config': '17b2a1e5814f3e933137158708a5b6e9b2475495', 'pipeline': '95defa3bdd8357f11f872d3c280d50a6d8ee398d'}, 'duration': 2.625814914703369, 'iteration': 5, 'loss': 0.15471329185031535, 'max_history_score': 0.9456356408262035, 'max_history_score_std': 0.040053650785990214, 'max_history_step': 'joint', 'pipeline': {'features': ('features_SelectKBest', {'features__k': 2}), 'normalizer': ('normalizer_StandardScaler', {'normalizer__with_mean': False, 'normalizer__with_std': False}), 'rebalance': ('rebalance_CondensedNearestNeighbour', {'rebalance__n_neighbors': 1})}, 'score': 0.8452867081496847, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': 3, 'max_features': None, 'max_leaf_nodes': None, 'min_samples_split': 5, 'n_estimators': 75}, 'config_hash': {'algorithm': 'd7466a2c1d5cb3fa95029d73dc030f4c3c45a159', 'config': 'fa020a592ec5ac234f9f91aac28abc2cd1ec9d33', 'pipeline': '71e0d26f923d42cfe0e2fa748931ef2afe72ed86'}, 'duration': 3.62078595161438, 'iteration': 6, 'loss': 0.17066372828623277, 'max_history_score': 0.9456356408262035, 'max_history_score_std': 0.040053650785990214, 'max_history_step': 'joint', 'pipeline': {'features': ('features_SelectKBest', {'features__k': 1}), 'normalizer': ('normalizer_RobustScaler', {'normalizer__quantile_range': (...), 'normalizer__with_centering': True, 'normalizer__with_scaling': True}), 'rebalance': ('rebalance_CondensedNearestNeighbour', {'rebalance__n_neighbors': 1})}, 'score': 0.8293362717137672, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'entropy', 'max_depth': 3, 'max_features': 3, 'max_leaf_nodes': 5, 'min_samples_split': 5, 'n_estimators': 50}, 'config_hash': {'algorithm': '735caa9785596076014572a24050cde8dc338973', 'config': '0da4498002d6f452c59bb61756abb3ded841e786', 'pipeline': '51a53ea6ef5a2521ee65f76eb2da220ab7086513'}, 'duration': 0.6934049129486084, 'iteration': 7, 'loss': 0.06125875032408601, 'max_history_score': 0.9456356408262035, 'max_history_score_std': 0.040053650785990214, 'max_history_step': 'joint', 'pipeline': {'features': ('features_NoneType', {}), 'normalizer': ('normalizer_NoneType', {}), 'rebalance': ('rebalance_NearMiss', {'rebalance__n_neighbors': 3})}, 'score': 0.938741249675914, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': 4, 'max_features': 2, 'max_leaf_nodes': None, 'min_samples_split': 3, 'n_estimators': 75}, 'config_hash': {'algorithm': 'e71a1fe9515b6805f07914a61f2e7594be9e9afe', 'config': '344e4756fb1bec455d6af51d3727e33b0d27725f', 'pipeline': '248dad1d8b30a17a5de1d0bbdfe3e2acb7a1962b'}, 'duration': 1.3036692142486572, 'iteration': 8, 'loss': 0.06483125918243893, 'max_history_score': 0.9456356408262035, 'max_history_score_std': 0.040053650785990214, 'max_history_step': 'joint', 'pipeline': {'features': ('features_PCA', {'features__n_components': 2}), 'normalizer': ('normalizer_StandardScaler', {'normalizer__with_mean': False, 'normalizer__with_std': True}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 7})}, 'score': 0.9351687408175611, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'entropy', 'max_depth': 2, 'max_features': 2, 'max_leaf_nodes': 2, 'min_samples_split': 3, 'n_estimators': 10}, 'config_hash': {'algorithm': '0a507823f2ad8605ed5950e1fe61df0560f11a00', 'config': '4a538fdcf8e07f90e92a421c0d5c479d651629c7', 'pipeline': '5240329df25c9a533d025c1a401d49835a501b41'}, 'duration': 1.3821029663085938, 'iteration': 9, 'loss': 0.07006416904329793, 'max_history_score': 0.9456356408262035, 'max_history_score_std': 0.040053650785990214, 'max_history_step': 'joint', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 4, 'features__selectkbest__k': 2}), 'normalizer': ('normalizer_PowerTransformer', {}), 'rebalance': ('rebalance_NearMiss', {'rebalance__n_neighbors': 1})}, 'score': 0.9299358309567021, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'gini', 'max_depth': 1, 'max_features': 3, 'max_leaf_nodes': 5, 'min_samples_split': 3, 'n_estimators': 10}, 'config_hash': {'algorithm': 'd32739750d351948f8ff34a87c7d55b0c5e0d90f', 'config': 'c1609e71f1ce8486335adc70bb69a955580ba2c8', 'pipeline': 'f48b42ec5cf999279659966160a16353b75bdaa3'}, 'duration': 0.9055681228637695, 'iteration': 10, 'loss': 0.07532840722495904, 'max_history_score': 0.9456356408262035, 'max_history_score_std': 0.040053650785990214, 'max_history_step': 'joint', 'pipeline': {'features': ('features_PCA', {'features__n_components': 4}), 'normalizer': ('normalizer_PowerTransformer', {}), 'rebalance': ('rebalance_NearMiss', {'rebalance__n_neighbors': 1})}, 'score': 0.924671592775041, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': 3, 'max_features': 1, 'max_leaf_nodes': 5, 'min_samples_split': 3, 'n_estimators': 25}, 'config_hash': {'algorithm': 'f69bac35e71cbec1bfc1fb5942328a3390e7c252', 'config': 'abe36f188644e53e56ed3224236fa157107ed3b2', 'pipeline': 'aaf976c7c663a31fa039582d42f9e07101556a7c'}, 'duration': 0.764197826385498, 'iteration': 11, 'loss': 0.06818446979517778, 'max_history_score': 0.9456356408262035, 'max_history_score_std': 0.040053650785990214, 'max_history_step': 'joint', 'pipeline': {'features': ('features_NoneType', {}), 'normalizer': ('normalizer_PowerTransformer', {}), 'rebalance': ('rebalance_NoneType', {})}, 'score': 0.9318155302048222, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'entropy', 'max_depth': None, 'max_features': None, 'max_leaf_nodes': None, 'min_samples_split': 5, 'n_estimators': 25}, 'config_hash': {'algorithm': 'a0a27aec00db5ddf71eab96663f9bd61c845f5e3', 'config': '76aa002c3c9d4d9722466c60daf5119c18a41d2a', 'pipeline': '1ce34b7894ef342571d974bb19e8ec821a512c6b'}, 'duration': 1.1636500358581543, 'iteration': 12, 'loss': 0.12833700630887557, 'max_history_score': 0.9456356408262035, 'max_history_score_std': 0.040053650785990214, 'max_history_step': 'joint', 'pipeline': {'features': ('features_PCA', {'features__n_components': 1}), 'normalizer': ('normalizer_PowerTransformer', {}), 'rebalance': ('rebalance_NoneType', {})}, 'score': 0.8716629936911244, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'gini', 'max_depth': 1, 'max_features': 2, 'max_leaf_nodes': 2, 'min_samples_split': 2, 'n_estimators': 100}, 'config_hash': {'algorithm': '985c99dff1da9b2c87e4211c5335a9159aa9dbcb', 'config': 'f56a7a9e43a0a699e992dc1262e550b8b7c88538', 'pipeline': '5c934f6d9a8ad1f9afe762986a9cf2074fc95d79'}, 'duration': 2.235443115234375, 'iteration': 13, 'loss': 0.11414635727249167, 'max_history_score': 0.9456356408262035, 'max_history_score_std': 0.040053650785990214, 'max_history_step': 'joint', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 1, 'features__selectkbest__k': 1}), 'normalizer': ('normalizer_RobustScaler', {'normalizer__quantile_range': (...), 'normalizer__with_centering': False, 'normalizer__with_scaling': True}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 6})}, 'score': 0.8858536427275083, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'gini', 'max_depth': 1, 'max_features': 1, 'max_leaf_nodes': None, 'min_samples_split': 5, 'n_estimators': 10}, 'config_hash': {'algorithm': '7d74a39aac2579264a402aef2b6fa7943c19f3d3', 'config': '53f44c0ad925c5c08c25d4fadf5e9ee9d7c181cd', 'pipeline': '6eff5ef31d7d1d534db31913bb67529c8a24c42e'}, 'duration': 2.7847659587860107, 'iteration': 14, 'loss': 0.14061986863711007, 'max_history_score': 0.9456356408262035, 'max_history_score_std': 0.040053650785990214, 'max_history_step': 'joint', 'pipeline': {'features': ('features_PCA', {'features__n_components': 1}), 'normalizer': ('normalizer_RobustScaler', {'normalizer__quantile_range': (...), 'normalizer__with_centering': True, 'normalizer__with_scaling': True}), 'rebalance': ('rebalance_CondensedNearestNeighbour', {'rebalance__n_neighbors': 3})}, 'score': 0.8593801313628899, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'entropy', 'max_depth': 3, 'max_features': None, 'max_leaf_nodes': 5, 'min_samples_split': 2, 'n_estimators': 100}, 'config_hash': {'algorithm': 'c62d7c671832e4414b6b2d7c36cba5ddc83a0ed0', 'config': '5faee50671eaa0ac586722bff234e36a857e662d', 'pipeline': '8b29a55de2add78c49114b9bbe5e800e5524c59d'}, 'duration': 2.3916029930114746, 'iteration': 15, 'loss': 0.08770093336790252, 'max_history_score': 0.9456356408262035, 'max_history_score_std': 0.040053650785990214, 'max_history_step': 'joint', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 3, 'features__selectkbest__k': 4}), 'normalizer': ('normalizer_RobustScaler', {'normalizer__quantile_range': (...), 'normalizer__with_centering': True, 'normalizer__with_scaling': True}), 'rebalance': ('rebalance_NoneType', {})}, 'score': 0.9122990666320975, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': None, 'max_features': 1, 'max_leaf_nodes': 5, 'min_samples_split': 5, 'n_estimators': 10}, 'config_hash': {'algorithm': '290772bfb9b8ed15c48a72829e822fb0a07481d6', 'config': '9a04f25d8eb3db5b2f831abd341a6d384c73a957', 'pipeline': '1ce34b7894ef342571d974bb19e8ec821a512c6b'}, 'duration': 1.4364500045776367, 'iteration': 16, 'loss': 0.08948880822746508, 'max_history_score': 0.9456356408262035, 'max_history_score_std': 0.040053650785990214, 'max_history_step': 'joint', 'pipeline': {'features': ('features_PCA', {'features__n_components': 1}), 'normalizer': ('normalizer_PowerTransformer', {}), 'rebalance': ('rebalance_NoneType', {})}, 'score': 0.9105111917725349, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': 2, 'max_features': 3, 'max_leaf_nodes': 3, 'min_samples_split': 3, 'n_estimators': 100}, 'config_hash': {'algorithm': '7dab6d47f897c2961d3402eff844aff16a7d142a', 'config': '4dbfa2688b239be9f372d3e80223960ba9a1fbdd', 'pipeline': 'cdef51702798fa49f11c11d80baf3ab43d5358fc'}, 'duration': 0.9830451011657715, 'iteration': 17, 'loss': 1.0, 'max_history_score': 0.9456356408262035, 'max_history_score_std': 0.040053650785990214, 'max_history_step': 'joint', 'pipeline': {'features': ('features_SelectKBest', {'features__k': 2}), 'normalizer': ('normalizer_PowerTransformer', {}), 'rebalance': ('rebalance_NearMiss', {'rebalance__n_neighbors': 1})}, 'score': 0.0, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'entropy', 'max_depth': None, 'max_features': 3, 'max_leaf_nodes': None, 'min_samples_split': 5, 'n_estimators': 10}, 'config_hash': {'algorithm': 'def83e48be05ef92a37e1a90585820f2f67ff42b', 'config': '95902552cb76e9798f0fa58782bd72bd1cc272d7', 'pipeline': '1775187bf23f94f4fd0cc1e5c1ef665210edded5'}, 'duration': 2.0033559799194336, 'iteration': 18, 'loss': 0.04922327370149515, 'max_history_score': 0.9507767262985048, 'max_history_score_std': 0.028328108925705902, 'max_history_step': 'joint', 'pipeline': {'features': ('features_PCA', {'features__n_components': 4}), 'normalizer': ('normalizer_StandardScaler', {'normalizer__with_mean': True, 'normalizer__with_std': True}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 5})}, 'score': 0.9507767262985048, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'gini', 'max_depth': 1, 'max_features': 3, 'max_leaf_nodes': None, 'min_samples_split': 2, 'n_estimators': 50}, 'config_hash': {'algorithm': '4e9e3275f817df75115d9d7e3366980fc1b4cf13', 'config': '7770b19007b40bf13005d52eb81f87bc401f15b4', 'pipeline': 'c4dd111513ea35f97dd3aec3e8e7f6268ce035da'}, 'duration': 0.9069631099700928, 'iteration': 19, 'loss': 1.0, 'max_history_score': 0.9507767262985048, 'max_history_score_std': 0.028328108925705902, 'max_history_step': 'joint', 'pipeline': {'features': ('features_PCA', {'features__n_components': 2}), 'normalizer': ('normalizer_RobustScaler', {'normalizer__quantile_range': (...), 'normalizer__with_centering': False, 'normalizer__with_scaling': True}), 'rebalance': ('rebalance_NearMiss', {'rebalance__n_neighbors': 2})}, 'score': 0.0, ...}, ...], 'history_hash': ['51144ca42f9ea5ab2d8d58606e3b3e4d89c6d7b3', '9e54ffcb6a727de032a0a2cd45c5cc37cc150756', 'e5241eee9ddf3f4ee29a4711f5bcc92a4d24cd09', '18ee4d3d1627472ec190326308d8755371a6dc62', '2af4f82b045c0c48ecb89d42728d1039fbff8878', '17b2a1e5814f3e933137158708a5b6e9b2475495', 'fa020a592ec5ac234f9f91aac28abc2cd1ec9d33', '0da4498002d6f452c59bb61756abb3ded841e786', '344e4756fb1bec455d6af51d3727e33b0d27725f', '4a538fdcf8e07f90e92a421c0d5c479d651629c7', 'c1609e71f1ce8486335adc70bb69a955580ba2c8', 'abe36f188644e53e56ed3224236fa157107ed3b2', '76aa002c3c9d4d9722466c60daf5119c18a41d2a', 'f56a7a9e43a0a699e992dc1262e550b8b7c88538', '53f44c0ad925c5c08c25d4fadf5e9ee9d7c181cd', '5faee50671eaa0ac586722bff234e36a857e662d', '9a04f25d8eb3db5b2f831abd341a6d384c73a957', '4dbfa2688b239be9f372d3e80223960ba9a1fbdd', '95902552cb76e9798f0fa58782bd72bd1cc272d7', '7770b19007b40bf13005d52eb81f87bc401f15b4', ...], 'history_index': {'0da4498002d6f452c59bb61756abb3ded841e786': 7, '0f77a69b0a8d34861caf915a51dc588ff8d4efac': 61, '127553d555ed39231b8da3a1ce42d3902e30919b': 59, '17b2a1e5814f3e933137158708a5b6e9b2475495': 5, '18ee4d3d1627472ec190326308d8755371a6dc62': 3, '1b2267555a9226d7eb4df3c63dd12506da370f4d': 56, '2af4f82b045c0c48ecb89d42728d1039fbff8878': 4, '2d054540972225f4f17fb36d63106b7bb5c406fe': 36, '306511091d7e5d6431b5e5a6320802c4c04cde44': 33, '312e05571f41c77895a9ad8c57db6947f3fdfe03': 58, ...}, 'iteration': 63, 'max_history_score': 0.9525008642295394, 'max_history_score_std': 0.02225295065716913, 'max_history_step': 'joint'}, config={'algorithm': 'RandomForest', 'seed': 42, 'time': 300}, step='joint')
     45                 y,
     46                 cv=10,
     47                 n_jobs=-1,
     48                 return_estimator=False,
     49                 return_train_score=False,
---> 50                 verbose=0)
     51         score = np.mean(scores['test_score'])
     52         std = np.std(scores['test_score'])
     53         status = STATUS_OK
     54     except Exception as e:

...........................................................................
/home/aquemy/.local/lib/python2.7/site-packages/sklearn/model_selection/_validation.py in cross_validate(estimator=Pipeline(memory=None,
     steps=[('rebalance', ...e=42,
            verbose=0, warm_start=False))]), X=array([[1.799e+01, 1.038e+01, 1.228e+02, ..., 2...., ..., 0.000e+00, 2.871e-01,
        7.039e-02]]), y=array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,... 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1]), groups=None, scoring=None, cv=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1, verbose=0, fit_params=None, pre_dispatch='2*n_jobs', return_train_score=False, return_estimator=False, error_score='raise-deprecating')
    235         delayed(_fit_and_score)(
    236             clone(estimator), X, y, scorers, train, test, verbose, None,
    237             fit_params, return_train_score=return_train_score,
    238             return_times=True, return_estimator=return_estimator,
    239             error_score=error_score)
--> 240         for train, test in cv.split(X, y, groups))
        cv.split = <bound method StratifiedKFold.split of Stratifie...d(n_splits=10, random_state=None, shuffle=False)>
        X = array([[1.799e+01, 1.038e+01, 1.228e+02, ..., 2...., ..., 0.000e+00, 2.871e-01,
        7.039e-02]])
        y = array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,... 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1])
        groups = None
    241 
    242     zipped_scores = list(zip(*scores))
    243     if return_train_score:
    244         train_scores = zipped_scores.pop(0)

...........................................................................
/home/aquemy/.local/lib/python2.7/site-packages/sklearn/externals/joblib/parallel.py in __call__(self=Parallel(n_jobs=-1), iterable=<generator object <genexpr>>)
    925                 # No need to wait for async callbacks to trigger to
    926                 # consumption.
    927                 self._iterating = False
    928 
    929             with self._backend.retrieval_context():
--> 930                 self.retrieve()
        self.retrieve = <bound method Parallel.retrieve of Parallel(n_jobs=-1)>
    931             # Make sure that we get a last message telling us we are done
    932             elapsed_time = time.time() - self._start_time
    933             self._print('Done %3i out of %3i | elapsed: %s finished',
    934                         (len(self._output), len(self._output),

---------------------------------------------------------------------------
Joblib worker traceback:
---------------------------------------------------------------------------
ValueError                                         Mon Jun 17 13:33:08 2019
PID: 26061                                  Python 2.7.15+: /usr/bin/python
...........................................................................
/home/aquemy/.local/lib/python2.7/site-packages/sklearn/externals/joblib/parallel.py in __call__(self=<sklearn.externals.joblib.parallel.BatchedCalls object>)
    220     def __call__(self):
    221         # Set the default nested backend to self._backend but do not set the
    222         # change the default number of processes to -1
    223         with parallel_backend(self._backend, n_jobs=self._n_jobs):
    224             return [func(*args, **kwargs)
--> 225                     for func, args, kwargs in self.items]
        func = <function _fit_and_score>
        args = (Pipeline(memory=None,
     steps=[('rebalance', ...e=42,
            verbose=0, warm_start=False))]), array([[1.799e+01, 1.038e+01, 1.228e+02, ..., 2...., ..., 0.000e+00, 2.871e-01,
        7.039e-02]]), array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,... 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1]), {'score': <function _passthrough_scorer>}, array([ 25,  26,  27,  28,  29,  30,  31,  32,  ..., 561, 562, 563, 564,
       565, 566, 567, 568]), array([  0,   1,   2,   3,   4,   5,   6,   7,  ...,  89,  90,
        92,  93,  96,  97,  98, 101]), 0, None, None)
        kwargs = {'error_score': 'raise-deprecating', 'return_estimator': False, 'return_times': True, 'return_train_score': False}
        self.items = [(<function _fit_and_score>, (Pipeline(memory=None,
     steps=[('rebalance', ...e=42,
            verbose=0, warm_start=False))]), array([[1.799e+01, 1.038e+01, 1.228e+02, ..., 2...., ..., 0.000e+00, 2.871e-01,
        7.039e-02]]), array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,... 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1]), {'score': <function _passthrough_scorer>}, array([ 25,  26,  27,  28,  29,  30,  31,  32,  ..., 561, 562, 563, 564,
       565, 566, 567, 568]), array([  0,   1,   2,   3,   4,   5,   6,   7,  ...,  89,  90,
        92,  93,  96,  97,  98, 101]), 0, None, None), {'error_score': 'raise-deprecating', 'return_estimator': False, 'return_times': True, 'return_train_score': False})]
    226 
    227     def __len__(self):
    228         return self._size
    229 

...........................................................................
/home/aquemy/.local/lib/python2.7/site-packages/sklearn/model_selection/_validation.py in _fit_and_score(estimator=Pipeline(memory=None,
     steps=[('rebalance', ...e=42,
            verbose=0, warm_start=False))]), X=array([[1.799e+01, 1.038e+01, 1.228e+02, ..., 2...., ..., 0.000e+00, 2.871e-01,
        7.039e-02]]), y=array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,... 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1]), scorer={'score': <function _passthrough_scorer>}, train=array([ 25,  26,  27,  28,  29,  30,  31,  32,  ..., 561, 562, 563, 564,
       565, 566, 567, 568]), test=array([  0,   1,   2,   3,   4,   5,   6,   7,  ...,  89,  90,
        92,  93,  96,  97,  98, 101]), verbose=0, parameters=None, fit_params={}, return_train_score=False, return_parameters=False, return_n_test_samples=False, return_times=True, return_estimator=False, error_score='raise-deprecating')
    523 
    524     try:
    525         if y_train is None:
    526             estimator.fit(X_train, **fit_params)
    527         else:
--> 528             estimator.fit(X_train, y_train, **fit_params)
        estimator.fit = <bound method Pipeline.fit of Pipeline(memory=No...=42,
            verbose=0, warm_start=False))])>
        X_train = array([[1.714e+01, 1.640e+01, 1.160e+02, ..., 2...., ..., 0.000e+00, 2.871e-01,
        7.039e-02]])
        y_train = array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...1, 1, 1, 1, 1, 1, 1, 0, 0,
       0, 0, 0, 0, 1])
        fit_params = {}
    529 
    530     except Exception as e:
    531         # Note fit time as time until error
    532         fit_time = time.time() - start_time

...........................................................................
/usr/local/lib/python2.7/dist-packages/imblearn/pipeline.py in fit(self=Pipeline(memory=None,
     steps=[('rebalance', ...e=42,
            verbose=0, warm_start=False))]), X=array([[1.714e+01, 1.640e+01, 1.160e+02, ..., 2...., ..., 0.000e+00, 2.871e-01,
        7.039e-02]]), y=array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...1, 1, 1, 1, 1, 1, 1, 0, 0,
       0, 0, 0, 0, 1]), **fit_params={})
    234             This estimator
    235 
    236         """
    237         Xt, yt, fit_params = self._fit(X, y, **fit_params)
    238         if self._final_estimator is not None:
--> 239             self._final_estimator.fit(Xt, yt, **fit_params)
        self._final_estimator.fit = <bound method RandomForestClassifier.fit of Rand...ate=42,
            verbose=0, warm_start=False)>
        Xt = array([[ 6.35049026e+00],
       [ 2.84657438e+0...    [ 2.39181984e+00],
       [-4.30785311e-01]])
        yt = array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
       0, 0, 0, 0])
        fit_params = {}
    240         return self
    241 
    242     def fit_transform(self, X, y=None, **fit_params):
    243         """Fit the model and transform with the final estimator

...........................................................................
/home/aquemy/.local/lib/python2.7/site-packages/sklearn/ensemble/forest.py in fit(self=RandomForestClassifier(bootstrap=False, class_we...tate=42,
            verbose=0, warm_start=False), X=array([[ 6.3504901e+00],
       [ 2.8465743e+00]...00e+00],
       [-4.3078530e-01]], dtype=float32), y=array([[0.],
       [0.],
       [0.],
       [0...    [0.],
       [0.],
       [0.],
       [0.]]), sample_weight=None)
    328             trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,
    329                              **_joblib_parallel_args(prefer='threads'))(
    330                 delayed(_parallel_build_trees)(
    331                     t, self, X, y, sample_weight, i, len(trees),
    332                     verbose=self.verbose, class_weight=self.class_weight)
--> 333                 for i, t in enumerate(trees))
        i = 9
    334 
    335             # Collect newly grown trees
    336             self.estimators_.extend(trees)
    337 

...........................................................................
/home/aquemy/.local/lib/python2.7/site-packages/sklearn/externals/joblib/parallel.py in __call__(self=Parallel(n_jobs=1), iterable=<generator object <genexpr>>)
    912             # self._original_iterator is None, then this means either
    913             # that pre_dispatch == "all", n_jobs == 1 or that the first batch
    914             # was very quick and its callback already dispatched all the
    915             # remaining jobs.
    916             self._iterating = False
--> 917             if self.dispatch_one_batch(iterator):
        self.dispatch_one_batch = <bound method Parallel.dispatch_one_batch of Parallel(n_jobs=1)>
        iterator = <generator object <genexpr>>
    918                 self._iterating = self._original_iterator is not None
    919 
    920             while self.dispatch_one_batch(iterator):
    921                 pass

...........................................................................
/home/aquemy/.local/lib/python2.7/site-packages/sklearn/externals/joblib/parallel.py in dispatch_one_batch(self=Parallel(n_jobs=1), iterator=<generator object <genexpr>>)
    754                                  self._pickle_cache)
    755             if len(tasks) == 0:
    756                 # No more tasks available in the iterator: tell caller to stop.
    757                 return False
    758             else:
--> 759                 self._dispatch(tasks)
        self._dispatch = <bound method Parallel._dispatch of Parallel(n_jobs=1)>
        tasks = <sklearn.externals.joblib.parallel.BatchedCalls object>
    760                 return True
    761 
    762     def _print(self, msg, msg_args):
    763         """Display the message on stout or stderr depending on verbosity"""

...........................................................................
/home/aquemy/.local/lib/python2.7/site-packages/sklearn/externals/joblib/parallel.py in _dispatch(self=Parallel(n_jobs=1), batch=<sklearn.externals.joblib.parallel.BatchedCalls object>)
    711 
    712         dispatch_timestamp = time.time()
    713         cb = BatchCompletionCallBack(dispatch_timestamp, len(batch), self)
    714         with self._lock:
    715             job_idx = len(self._jobs)
--> 716             job = self._backend.apply_async(batch, callback=cb)
        job = undefined
        self._backend.apply_async = <bound method SequentialBackend.apply_async of <...lib._parallel_backends.SequentialBackend object>>
        batch = <sklearn.externals.joblib.parallel.BatchedCalls object>
        cb = <sklearn.externals.joblib.parallel.BatchCompletionCallBack object>
    717             # A job can complete so quickly than its callback is
    718             # called before we get here, causing self._jobs to
    719             # grow. To ensure correct results ordering, .insert is
    720             # used (rather than .append) in the following line

...........................................................................
/home/aquemy/.local/lib/python2.7/site-packages/sklearn/externals/joblib/_parallel_backends.py in apply_async(self=<sklearn.externals.joblib._parallel_backends.SequentialBackend object>, func=<sklearn.externals.joblib.parallel.BatchedCalls object>, callback=<sklearn.externals.joblib.parallel.BatchCompletionCallBack object>)
    177             raise ValueError('n_jobs == 0 in Parallel has no meaning')
    178         return 1
    179 
    180     def apply_async(self, func, callback=None):
    181         """Schedule a func to be run"""
--> 182         result = ImmediateResult(func)
        result = undefined
        func = <sklearn.externals.joblib.parallel.BatchedCalls object>
    183         if callback:
    184             callback(result)
    185         return result
    186 

...........................................................................
/home/aquemy/.local/lib/python2.7/site-packages/sklearn/externals/joblib/_parallel_backends.py in __init__(self=<sklearn.externals.joblib._parallel_backends.ImmediateResult object>, batch=<sklearn.externals.joblib.parallel.BatchedCalls object>)
    544 
    545 class ImmediateResult(object):
    546     def __init__(self, batch):
    547         # Don't delay the application, to avoid keeping the input
    548         # arguments in memory
--> 549         self.results = batch()
        self.results = undefined
        batch = <sklearn.externals.joblib.parallel.BatchedCalls object>
    550 
    551     def get(self):
    552         return self.results
    553 

...........................................................................
/home/aquemy/.local/lib/python2.7/site-packages/sklearn/externals/joblib/parallel.py in __call__(self=<sklearn.externals.joblib.parallel.BatchedCalls object>)
    220     def __call__(self):
    221         # Set the default nested backend to self._backend but do not set the
    222         # change the default number of processes to -1
    223         with parallel_backend(self._backend, n_jobs=self._n_jobs):
    224             return [func(*args, **kwargs)
--> 225                     for func, args, kwargs in self.items]
        func = <function _parallel_build_trees>
        args = (DecisionTreeClassifier(class_weight=None, criter...=False, random_state=1608637542, splitter='best'), RandomForestClassifier(bootstrap=False, class_we...tate=42,
            verbose=0, warm_start=False), array([[ 6.3504901e+00],
       [ 2.8465743e+00]...00e+00],
       [-4.3078530e-01]], dtype=float32), array([[0.],
       [0.],
       [0.],
       [0...    [0.],
       [0.],
       [0.],
       [0.]]), None, 0, 10)
        kwargs = {'class_weight': None, 'verbose': 0}
        self.items = [(<function _parallel_build_trees>, (DecisionTreeClassifier(class_weight=None, criter...=False, random_state=1608637542, splitter='best'), RandomForestClassifier(bootstrap=False, class_we...tate=42,
            verbose=0, warm_start=False), array([[ 6.3504901e+00],
       [ 2.8465743e+00]...00e+00],
       [-4.3078530e-01]], dtype=float32), array([[0.],
       [0.],
       [0.],
       [0...    [0.],
       [0.],
       [0.],
       [0.]]), None, 0, 10), {'class_weight': None, 'verbose': 0})]
    226 
    227     def __len__(self):
    228         return self._size
    229 

...........................................................................
/home/aquemy/.local/lib/python2.7/site-packages/sklearn/ensemble/forest.py in _parallel_build_trees(tree=DecisionTreeClassifier(class_weight=None, criter...=False, random_state=1608637542, splitter='best'), forest=RandomForestClassifier(bootstrap=False, class_we...tate=42,
            verbose=0, warm_start=False), X=array([[ 6.3504901e+00],
       [ 2.8465743e+00]...00e+00],
       [-4.3078530e-01]], dtype=float32), y=array([[0.],
       [0.],
       [0.],
       [0...    [0.],
       [0.],
       [0.],
       [0.]]), sample_weight=None, tree_idx=0, n_trees=10, verbose=0, class_weight=None)
    116         elif class_weight == 'balanced_subsample':
    117             curr_sample_weight *= compute_sample_weight('balanced', y, indices)
    118 
    119         tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)
    120     else:
--> 121         tree.fit(X, y, sample_weight=sample_weight, check_input=False)
        tree.fit = <bound method DecisionTreeClassifier.fit of Deci...False, random_state=1608637542, splitter='best')>
        X = array([[ 6.3504901e+00],
       [ 2.8465743e+00]...00e+00],
       [-4.3078530e-01]], dtype=float32)
        y = array([[0.],
       [0.],
       [0.],
       [0...    [0.],
       [0.],
       [0.],
       [0.]])
        sample_weight = None
    122 
    123     return tree
    124 
    125 

...........................................................................
/home/aquemy/.local/lib/python2.7/site-packages/sklearn/tree/tree.py in fit(self=DecisionTreeClassifier(class_weight=None, criter...=False, random_state=1608637542, splitter='best'), X=array([[ 6.3504901e+00],
       [ 2.8465743e+00]...00e+00],
       [-4.3078530e-01]], dtype=float32), y=array([[0.],
       [0.],
       [0.],
       [0...    [0.],
       [0.],
       [0.],
       [0.]]), sample_weight=None, check_input=False, X_idx_sorted=None)
    796 
    797         super(DecisionTreeClassifier, self).fit(
    798             X, y,
    799             sample_weight=sample_weight,
    800             check_input=check_input,
--> 801             X_idx_sorted=X_idx_sorted)
        X_idx_sorted = None
    802         return self
    803 
    804     def predict_proba(self, X, check_input=True):
    805         """Predict class probabilities of the input samples X.

...........................................................................
/home/aquemy/.local/lib/python2.7/site-packages/sklearn/tree/tree.py in fit(self=DecisionTreeClassifier(class_weight=None, criter...=False, random_state=1608637542, splitter='best'), X=array([[ 6.3504901e+00],
       [ 2.8465743e+00]...00e+00],
       [-4.3078530e-01]], dtype=float32), y=array([[0.],
       [0.],
       [0.],
       [0...    [0.],
       [0.],
       [0.],
       [0.]]), sample_weight=None, check_input=False, X_idx_sorted=None)
    237         if not 0 <= self.min_weight_fraction_leaf <= 0.5:
    238             raise ValueError("min_weight_fraction_leaf must in [0, 0.5]")
    239         if max_depth <= 0:
    240             raise ValueError("max_depth must be greater than zero. ")
    241         if not (0 < max_features <= self.n_features_):
--> 242             raise ValueError("max_features must be in (0, n_features]")
    243         if not isinstance(max_leaf_nodes, (numbers.Integral, np.integer)):
    244             raise ValueError("max_leaf_nodes must be integral number but was "
    245                              "%r" % max_leaf_nodes)
    246         if -1 < max_leaf_nodes < 2:

ValueError: max_features must be in (0, n_features]
___________________________________________________________________________
Best score: 0.95250086423 (0.0222529506572) [J] | Score: 0.0 (0.0) [J]
JoblibValueError
___________________________________________________________________________
...........................................................................
/home/aquemy/dev/dp_hyperparameters/extension/main.py in <module>()
     27 
     28     serializer.serialize_results(scenario, policy)
     29 
     30 if __name__ == "__main__":
     31     args = cli.parse_args()
---> 32     main(args)

...........................................................................
/home/aquemy/dev/dp_hyperparameters/extension/main.py in main(args=Namespace(customize=[(['control', 'seed'], '42')...='./scenarios/rf_breast_joint.yaml', verbosity=0))
     21         test_size=0.4, 
     22         random_state=scenario['control']['seed']
     23     )
     24 
     25     policy = policies.initiate(scenario['setup']['policy'], config)
---> 26     policy.run(X,y)
        policy.run = <bound method Joint.run of <experiment.policies.joint.Joint object>>
        X = array([[1.799e+01, 1.038e+01, 1.228e+02, ..., 2...., ..., 0.000e+00, 2.871e-01,
        7.039e-02]])
        y = array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,... 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1])
     27 
     28     serializer.serialize_results(scenario, policy)
     29 
     30 if __name__ == "__main__":

...........................................................................
/home/aquemy/dev/dp_hyperparameters/extension/experiment/policies/joint.py in run(self=<experiment.policies.joint.Joint object>, X=array([[1.799e+01, 1.038e+01, 1.228e+02, ..., 2...., ..., 0.000e+00, 2.871e-01,
        7.039e-02]]), y=array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,... 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1]))
     32             algo=tpe.suggest, 
     33             max_evals=None,
     34             max_time=self.config['time'],     
     35             trials=trials,
     36             show_progressbar=False,
---> 37             verbose=0
     38         )
     39 
     40         best_config = self.context['best_config']
     41         super(Joint, self).display_step_results(best_config)

...........................................................................
/home/aquemy/dev/dp_hyperparameters/extension/hyperopt/fmin.py in fmin(fn=<functools.partial object>, space={'algorithm': {'bootstrap': <hyperopt.pyll.base.Apply object>, 'criterion': <hyperopt.pyll.base.Apply object>, 'max_depth': <hyperopt.pyll.base.Apply object>, 'max_features': <hyperopt.pyll.base.Apply object>, 'max_leaf_nodes': <hyperopt.pyll.base.Apply object>, 'min_samples_split': <hyperopt.pyll.base.Apply object>, 'n_estimators': <hyperopt.pyll.base.Apply object>}, 'pipeline': {'features': <hyperopt.pyll.base.Apply object>, 'normalizer': <hyperopt.pyll.base.Apply object>, 'rebalance': <hyperopt.pyll.base.Apply object>}}, algo=<function suggest>, max_evals=9223372036854775807, max_time=300, trials=<hyperopt.base.Trials object>, rstate=<mtrand.RandomState object>, allow_trials_fmin=True, pass_expr_memo_ctrl=None, catch_eval_exceptions=False, verbose=0, return_argmin=True, points_to_evaluate=None, max_queue_len=1, show_progressbar=False)
    406             pass_expr_memo_ctrl=pass_expr_memo_ctrl,
    407             verbose=verbose,
    408             catch_eval_exceptions=catch_eval_exceptions,
    409             return_argmin=return_argmin,
    410             show_progressbar=show_progressbar,
--> 411             max_time=max_time
        max_time = 300
    412         )
    413 
    414     if trials is None:
    415         if points_to_evaluate is None:

...........................................................................
/home/aquemy/dev/dp_hyperparameters/extension/hyperopt/base.py in fmin(self=<hyperopt.base.Trials object>, fn=<functools.partial object>, space={'algorithm': {'bootstrap': <hyperopt.pyll.base.Apply object>, 'criterion': <hyperopt.pyll.base.Apply object>, 'max_depth': <hyperopt.pyll.base.Apply object>, 'max_features': <hyperopt.pyll.base.Apply object>, 'max_leaf_nodes': <hyperopt.pyll.base.Apply object>, 'min_samples_split': <hyperopt.pyll.base.Apply object>, 'n_estimators': <hyperopt.pyll.base.Apply object>}, 'pipeline': {'features': <hyperopt.pyll.base.Apply object>, 'normalizer': <hyperopt.pyll.base.Apply object>, 'rebalance': <hyperopt.pyll.base.Apply object>}}, algo=<function suggest>, max_evals=9223372036854775807, max_time=300, rstate=<mtrand.RandomState object>, verbose=0, pass_expr_memo_ctrl=None, catch_eval_exceptions=False, return_argmin=True, show_progressbar=False)
    636             verbose=verbose,
    637             allow_trials_fmin=False,  # -- prevent recursion
    638             pass_expr_memo_ctrl=pass_expr_memo_ctrl,
    639             catch_eval_exceptions=catch_eval_exceptions,
    640             return_argmin=return_argmin,
--> 641             show_progressbar=show_progressbar)
        show_progressbar = False
    642 
    643 
    644 def trials_from_docs(docs, validate=True, **kwargs):
    645     """Construct a Trials base class instance from a list of trials documents

...........................................................................
/home/aquemy/dev/dp_hyperparameters/extension/hyperopt/fmin.py in fmin(fn=<functools.partial object>, space={'algorithm': {'bootstrap': <hyperopt.pyll.base.Apply object>, 'criterion': <hyperopt.pyll.base.Apply object>, 'max_depth': <hyperopt.pyll.base.Apply object>, 'max_features': <hyperopt.pyll.base.Apply object>, 'max_leaf_nodes': <hyperopt.pyll.base.Apply object>, 'min_samples_split': <hyperopt.pyll.base.Apply object>, 'n_estimators': <hyperopt.pyll.base.Apply object>}, 'pipeline': {'features': <hyperopt.pyll.base.Apply object>, 'normalizer': <hyperopt.pyll.base.Apply object>, 'rebalance': <hyperopt.pyll.base.Apply object>}}, algo=<function suggest>, max_evals=9223372036854775807, max_time=300, trials=<hyperopt.base.Trials object>, rstate=<mtrand.RandomState object>, allow_trials_fmin=False, pass_expr_memo_ctrl=None, catch_eval_exceptions=False, verbose=0, return_argmin=True, points_to_evaluate=None, max_queue_len=1, show_progressbar=False)
    426                     verbose=verbose,
    427                     max_queue_len=max_queue_len,
    428                     show_progressbar=show_progressbar,
    429                     max_time=max_time)
    430     rval.catch_eval_exceptions = catch_eval_exceptions
--> 431     rval.exhaust()
        rval.exhaust = <bound method FMinIter.exhaust of <hyperopt.fmin.FMinIter object>>
    432     if return_argmin:
    433         return trials.argmin
    434     elif len(trials) > 0:
    435         # Only if there are some succesfull trail runs, return the best point in the evaluation space

...........................................................................
/home/aquemy/dev/dp_hyperparameters/extension/hyperopt/fmin.py in exhaust(self=<hyperopt.fmin.FMinIter object>)
    273             raise StopIteration()
    274         return self.trials
    275 
    276     def exhaust(self):
    277         n_done = len(self.trials)
--> 278         self.run(self.max_evals - n_done, block_until_done=self.asynchronous)
        self.run = <bound method FMinIter.run of <hyperopt.fmin.FMinIter object>>
        self.max_evals = 9223372036854775807
        n_done = 0
        self.asynchronous = False
    279         self.trials.refresh()
    280         return self
    281 
    282 

...........................................................................
/home/aquemy/dev/dp_hyperparameters/extension/hyperopt/fmin.py in run(self=<hyperopt.fmin.FMinIter object>, N=9223372036854775807, block_until_done=False)
    232                     if self.asynchronous:
    233                         # -- wait for workers to fill in the trials
    234                         time.sleep(self.poll_interval_secs)
    235                     else:
    236                         # -- loop over trials and do the jobs directly
--> 237                         self.serial_evaluate()
        self.serial_evaluate = <bound method FMinIter.serial_evaluate of <hyperopt.fmin.FMinIter object>>
    238                     try:
    239                         res = [d['result']['loss'] for d in
    240                                          self.trials.trials if
    241                                          d['result']['status'] == 'ok']

...........................................................................
/home/aquemy/dev/dp_hyperparameters/extension/hyperopt/fmin.py in serial_evaluate(self=<hyperopt.fmin.FMinIter object>, N=-1)
    138                 trial['book_time'] = now
    139                 trial['refresh_time'] = now
    140                 spec = base.spec_from_misc(trial['misc'])
    141                 ctrl = base.Ctrl(self.trials, current_trial=trial)
    142                 try:
--> 143                     result = self.domain.evaluate(spec, ctrl)
        result = undefined
        self.domain.evaluate = <bound method Domain.evaluate of <hyperopt.base.Domain object>>
        spec = {'bootstrap': 1, 'criterion': 1, 'features': 1, 'features_PCA_features__n_components': 1, 'max_depth': 4, 'max_features': 2, 'max_leaf_nodes': 3, 'min_samples_split': 2, 'n_estimators': 4, 'normalizer': 0, ...}
        ctrl = <hyperopt.base.Ctrl object>
    144                 except Exception as e:
    145                     logger.info('job exception: %s' % str(e))
    146                     trial['state'] = base.JOB_STATE_ERROR
    147                     trial['misc']['error'] = (str(type(e)), str(e))

...........................................................................
/home/aquemy/dev/dp_hyperparameters/extension/hyperopt/base.py in evaluate(self=<hyperopt.base.Domain object>, config={'bootstrap': 1, 'criterion': 1, 'features': 1, 'features_PCA_features__n_components': 1, 'max_depth': 4, 'max_features': 2, 'max_leaf_nodes': 3, 'min_samples_split': 2, 'n_estimators': 4, 'normalizer': 0, ...}, ctrl=<hyperopt.base.Ctrl object>, attach_attachments=True)
    841             #    or the normal Python part (self.fn)
    842             pyll_rval = pyll.rec_eval(
    843                 self.expr,
    844                 memo=memo,
    845                 print_node_on_error=self.rec_eval_print_node_on_error)
--> 846             rval = self.fn(pyll_rval)
        rval = undefined
        self.fn = <functools.partial object>
        pyll_rval = {'algorithm': {'bootstrap': False, 'criterion': 'entropy', 'max_depth': None, 'max_features': 3, 'max_leaf_nodes': None, 'min_samples_split': 5, 'n_estimators': 100}, 'pipeline': {'features': ('features_PCA', {'features__n_components': 2}), 'normalizer': ('normalizer_NoneType', {}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 6})}}
    847 
    848         if isinstance(rval, (float, int, np.number)):
    849             dict_rval = {'loss': float(rval), 'status': STATUS_OK}
    850         else:

...........................................................................
/home/aquemy/dev/dp_hyperparameters/extension/experiment/objective.py in objective_joint(wconfig={'algorithm': {'bootstrap': False, 'criterion': 'entropy', 'max_depth': None, 'max_features': 3, 'max_leaf_nodes': None, 'min_samples_split': 5, 'n_estimators': 100}, 'pipeline': {'features': ('features_PCA', {'features__n_components': 2}), 'normalizer': ('normalizer_NoneType', {}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 6})}}, algorithm='RandomForest', X=array([[1.799e+01, 1.038e+01, 1.228e+02, ..., 2...., ..., 0.000e+00, 2.871e-01,
        7.039e-02]]), y=array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,... 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1]), context={'baseline_score': 0.9545944602886527, 'baseline_score_std': 0.03716322883281839, 'best_config': {'algorithm': {'bootstrap': False, 'criterion': 'entropy', 'max_depth': None, 'max_features': 2, 'max_leaf_nodes': None, 'min_samples_split': 5, 'n_estimators': 10}, 'config_hash': {'algorithm': 'e7a772c2bc361aa61cf7eeb364a26dca2c9b89d6', 'config': 'afb67da069b544b0505b1e8c150edc7498ad37b4', 'pipeline': 'a43db4b4fc4c38610b7b5e484840d2e583089ff4'}, 'duration': 1.0073001384735107, 'iteration': 26, 'loss': 0.04749913577046061, 'max_history_score': 0.9525008642295394, 'max_history_score_std': 0.02225295065716913, 'max_history_step': 'joint', 'pipeline': {'features': ('features_PCA', {'features__n_components': 4}), 'normalizer': ('normalizer_StandardScaler', {'normalizer__with_mean': True, 'normalizer__with_std': False}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 7})}, 'score': 0.9525008642295394, ...}, 'history': [{'algorithm': {'bootstrap': True, 'criterion': 'entropy', 'max_depth': 4, 'max_features': 3, 'max_leaf_nodes': 3, 'min_samples_split': 2, 'n_estimators': 10}, 'config_hash': {'algorithm': '42527c4120073c2a488d1b8df28732f486d1578c', 'config': '51144ca42f9ea5ab2d8d58606e3b3e4d89c6d7b3', 'pipeline': '52f07bda29f9d3a95fabb87e591d0b2581ca8209'}, 'duration': 0.26703310012817383, 'iteration': 0, 'loss': 0.06655431682654922, 'max_history_score': 0.9334456831734508, 'max_history_score_std': 0.03819399139659311, 'max_history_step': 'joint', 'pipeline': {'features': ('features_NoneType', {}), 'normalizer': ('normalizer_RobustScaler', {'normalizer__quantile_range': (...), 'normalizer__with_centering': False, 'normalizer__with_scaling': False}), 'rebalance': ('rebalance_NearMiss', {'rebalance__n_neighbors': 1})}, 'score': 0.9334456831734508, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': None, 'max_features': 2, 'max_leaf_nodes': 3, 'min_samples_split': 2, 'n_estimators': 100}, 'config_hash': {'algorithm': '1b32258c630f07e01ab481ab925ab80aa757e482', 'config': '9e54ffcb6a727de032a0a2cd45c5cc37cc150756', 'pipeline': '37e72d4a97f5e784c9d3133e6379b91bfc3be803'}, 'duration': 1.3065669536590576, 'iteration': 1, 'loss': 0.05436435917379645, 'max_history_score': 0.9456356408262035, 'max_history_score_std': 0.040053650785990214, 'max_history_step': 'joint', 'pipeline': {'features': ('features_NoneType', {}), 'normalizer': ('normalizer_StandardScaler', {'normalizer__with_mean': True, 'normalizer__with_std': True}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 6})}, 'score': 0.9456356408262035, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'entropy', 'max_depth': 1, 'max_features': 1, 'max_leaf_nodes': 2, 'min_samples_split': 3, 'n_estimators': 25}, 'config_hash': {'algorithm': '68ab9059aa7ec74e0da87c81734b9664243b3eb4', 'config': 'e5241eee9ddf3f4ee29a4711f5bcc92a4d24cd09', 'pipeline': '62463de065924498cdcd2f2f1f7e68535cdb33a5'}, 'duration': 0.6592490673065186, 'iteration': 2, 'loss': 0.07695856019358727, 'max_history_score': 0.9456356408262035, 'max_history_score_std': 0.040053650785990214, 'max_history_step': 'joint', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 1, 'features__selectkbest__k': 2}), 'normalizer': ('normalizer_NoneType', {}), 'rebalance': ('rebalance_NoneType', {})}, 'score': 0.9230414398064127, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': 3, 'max_features': 2, 'max_leaf_nodes': 2, 'min_samples_split': 2, 'n_estimators': 25}, 'config_hash': {'algorithm': 'e3f1f7d7783557a38f40f0476369091edd87092b', 'config': '18ee4d3d1627472ec190326308d8755371a6dc62', 'pipeline': 'c6d1263e344ed8c71b2e6e4ba8e0db2fb6c777c0'}, 'duration': 0.879349946975708, 'iteration': 3, 'loss': 0.07535973554576114, 'max_history_score': 0.9456356408262035, 'max_history_score_std': 0.040053650785990214, 'max_history_step': 'joint', 'pipeline': {'features': ('features_NoneType', {}), 'normalizer': ('normalizer_RobustScaler', {'normalizer__quantile_range': (...), 'normalizer__with_centering': True, 'normalizer__with_scaling': True}), 'rebalance': ('rebalance_NearMiss', {'rebalance__n_neighbors': 2})}, 'score': 0.9246402644542389, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'gini', 'max_depth': 4, 'max_features': 2, 'max_leaf_nodes': 5, 'min_samples_split': 2, 'n_estimators': 50}, 'config_hash': {'algorithm': '47581af7253940f9647ad16d37347d34baf13e5f', 'config': '2af4f82b045c0c48ecb89d42728d1039fbff8878', 'pipeline': '2928b22ed834303cb7bac6e6608531eaddd7df67'}, 'duration': 4.372632026672363, 'iteration': 4, 'loss': 0.09121294615849984, 'max_history_score': 0.9456356408262035, 'max_history_score_std': 0.040053650785990214, 'max_history_step': 'joint', 'pipeline': {'features': ('features_NoneType', {}), 'normalizer': ('normalizer_MinMaxScaler', {}), 'rebalance': ('rebalance_CondensedNearestNeighbour', {'rebalance__n_neighbors': 2})}, 'score': 0.9087870538415002, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'entropy', 'max_depth': 2, 'max_features': 2, 'max_leaf_nodes': None, 'min_samples_split': 2, 'n_estimators': 10}, 'config_hash': {'algorithm': '0a85f98ca2d06103287f153633d88f7a0535e7e8', 'config': '17b2a1e5814f3e933137158708a5b6e9b2475495', 'pipeline': '95defa3bdd8357f11f872d3c280d50a6d8ee398d'}, 'duration': 2.625814914703369, 'iteration': 5, 'loss': 0.15471329185031535, 'max_history_score': 0.9456356408262035, 'max_history_score_std': 0.040053650785990214, 'max_history_step': 'joint', 'pipeline': {'features': ('features_SelectKBest', {'features__k': 2}), 'normalizer': ('normalizer_StandardScaler', {'normalizer__with_mean': False, 'normalizer__with_std': False}), 'rebalance': ('rebalance_CondensedNearestNeighbour', {'rebalance__n_neighbors': 1})}, 'score': 0.8452867081496847, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': 3, 'max_features': None, 'max_leaf_nodes': None, 'min_samples_split': 5, 'n_estimators': 75}, 'config_hash': {'algorithm': 'd7466a2c1d5cb3fa95029d73dc030f4c3c45a159', 'config': 'fa020a592ec5ac234f9f91aac28abc2cd1ec9d33', 'pipeline': '71e0d26f923d42cfe0e2fa748931ef2afe72ed86'}, 'duration': 3.62078595161438, 'iteration': 6, 'loss': 0.17066372828623277, 'max_history_score': 0.9456356408262035, 'max_history_score_std': 0.040053650785990214, 'max_history_step': 'joint', 'pipeline': {'features': ('features_SelectKBest', {'features__k': 1}), 'normalizer': ('normalizer_RobustScaler', {'normalizer__quantile_range': (...), 'normalizer__with_centering': True, 'normalizer__with_scaling': True}), 'rebalance': ('rebalance_CondensedNearestNeighbour', {'rebalance__n_neighbors': 1})}, 'score': 0.8293362717137672, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'entropy', 'max_depth': 3, 'max_features': 3, 'max_leaf_nodes': 5, 'min_samples_split': 5, 'n_estimators': 50}, 'config_hash': {'algorithm': '735caa9785596076014572a24050cde8dc338973', 'config': '0da4498002d6f452c59bb61756abb3ded841e786', 'pipeline': '51a53ea6ef5a2521ee65f76eb2da220ab7086513'}, 'duration': 0.6934049129486084, 'iteration': 7, 'loss': 0.06125875032408601, 'max_history_score': 0.9456356408262035, 'max_history_score_std': 0.040053650785990214, 'max_history_step': 'joint', 'pipeline': {'features': ('features_NoneType', {}), 'normalizer': ('normalizer_NoneType', {}), 'rebalance': ('rebalance_NearMiss', {'rebalance__n_neighbors': 3})}, 'score': 0.938741249675914, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': 4, 'max_features': 2, 'max_leaf_nodes': None, 'min_samples_split': 3, 'n_estimators': 75}, 'config_hash': {'algorithm': 'e71a1fe9515b6805f07914a61f2e7594be9e9afe', 'config': '344e4756fb1bec455d6af51d3727e33b0d27725f', 'pipeline': '248dad1d8b30a17a5de1d0bbdfe3e2acb7a1962b'}, 'duration': 1.3036692142486572, 'iteration': 8, 'loss': 0.06483125918243893, 'max_history_score': 0.9456356408262035, 'max_history_score_std': 0.040053650785990214, 'max_history_step': 'joint', 'pipeline': {'features': ('features_PCA', {'features__n_components': 2}), 'normalizer': ('normalizer_StandardScaler', {'normalizer__with_mean': False, 'normalizer__with_std': True}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 7})}, 'score': 0.9351687408175611, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'entropy', 'max_depth': 2, 'max_features': 2, 'max_leaf_nodes': 2, 'min_samples_split': 3, 'n_estimators': 10}, 'config_hash': {'algorithm': '0a507823f2ad8605ed5950e1fe61df0560f11a00', 'config': '4a538fdcf8e07f90e92a421c0d5c479d651629c7', 'pipeline': '5240329df25c9a533d025c1a401d49835a501b41'}, 'duration': 1.3821029663085938, 'iteration': 9, 'loss': 0.07006416904329793, 'max_history_score': 0.9456356408262035, 'max_history_score_std': 0.040053650785990214, 'max_history_step': 'joint', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 4, 'features__selectkbest__k': 2}), 'normalizer': ('normalizer_PowerTransformer', {}), 'rebalance': ('rebalance_NearMiss', {'rebalance__n_neighbors': 1})}, 'score': 0.9299358309567021, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'gini', 'max_depth': 1, 'max_features': 3, 'max_leaf_nodes': 5, 'min_samples_split': 3, 'n_estimators': 10}, 'config_hash': {'algorithm': 'd32739750d351948f8ff34a87c7d55b0c5e0d90f', 'config': 'c1609e71f1ce8486335adc70bb69a955580ba2c8', 'pipeline': 'f48b42ec5cf999279659966160a16353b75bdaa3'}, 'duration': 0.9055681228637695, 'iteration': 10, 'loss': 0.07532840722495904, 'max_history_score': 0.9456356408262035, 'max_history_score_std': 0.040053650785990214, 'max_history_step': 'joint', 'pipeline': {'features': ('features_PCA', {'features__n_components': 4}), 'normalizer': ('normalizer_PowerTransformer', {}), 'rebalance': ('rebalance_NearMiss', {'rebalance__n_neighbors': 1})}, 'score': 0.924671592775041, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': 3, 'max_features': 1, 'max_leaf_nodes': 5, 'min_samples_split': 3, 'n_estimators': 25}, 'config_hash': {'algorithm': 'f69bac35e71cbec1bfc1fb5942328a3390e7c252', 'config': 'abe36f188644e53e56ed3224236fa157107ed3b2', 'pipeline': 'aaf976c7c663a31fa039582d42f9e07101556a7c'}, 'duration': 0.764197826385498, 'iteration': 11, 'loss': 0.06818446979517778, 'max_history_score': 0.9456356408262035, 'max_history_score_std': 0.040053650785990214, 'max_history_step': 'joint', 'pipeline': {'features': ('features_NoneType', {}), 'normalizer': ('normalizer_PowerTransformer', {}), 'rebalance': ('rebalance_NoneType', {})}, 'score': 0.9318155302048222, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'entropy', 'max_depth': None, 'max_features': None, 'max_leaf_nodes': None, 'min_samples_split': 5, 'n_estimators': 25}, 'config_hash': {'algorithm': 'a0a27aec00db5ddf71eab96663f9bd61c845f5e3', 'config': '76aa002c3c9d4d9722466c60daf5119c18a41d2a', 'pipeline': '1ce34b7894ef342571d974bb19e8ec821a512c6b'}, 'duration': 1.1636500358581543, 'iteration': 12, 'loss': 0.12833700630887557, 'max_history_score': 0.9456356408262035, 'max_history_score_std': 0.040053650785990214, 'max_history_step': 'joint', 'pipeline': {'features': ('features_PCA', {'features__n_components': 1}), 'normalizer': ('normalizer_PowerTransformer', {}), 'rebalance': ('rebalance_NoneType', {})}, 'score': 0.8716629936911244, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'gini', 'max_depth': 1, 'max_features': 2, 'max_leaf_nodes': 2, 'min_samples_split': 2, 'n_estimators': 100}, 'config_hash': {'algorithm': '985c99dff1da9b2c87e4211c5335a9159aa9dbcb', 'config': 'f56a7a9e43a0a699e992dc1262e550b8b7c88538', 'pipeline': '5c934f6d9a8ad1f9afe762986a9cf2074fc95d79'}, 'duration': 2.235443115234375, 'iteration': 13, 'loss': 0.11414635727249167, 'max_history_score': 0.9456356408262035, 'max_history_score_std': 0.040053650785990214, 'max_history_step': 'joint', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 1, 'features__selectkbest__k': 1}), 'normalizer': ('normalizer_RobustScaler', {'normalizer__quantile_range': (...), 'normalizer__with_centering': False, 'normalizer__with_scaling': True}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 6})}, 'score': 0.8858536427275083, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'gini', 'max_depth': 1, 'max_features': 1, 'max_leaf_nodes': None, 'min_samples_split': 5, 'n_estimators': 10}, 'config_hash': {'algorithm': '7d74a39aac2579264a402aef2b6fa7943c19f3d3', 'config': '53f44c0ad925c5c08c25d4fadf5e9ee9d7c181cd', 'pipeline': '6eff5ef31d7d1d534db31913bb67529c8a24c42e'}, 'duration': 2.7847659587860107, 'iteration': 14, 'loss': 0.14061986863711007, 'max_history_score': 0.9456356408262035, 'max_history_score_std': 0.040053650785990214, 'max_history_step': 'joint', 'pipeline': {'features': ('features_PCA', {'features__n_components': 1}), 'normalizer': ('normalizer_RobustScaler', {'normalizer__quantile_range': (...), 'normalizer__with_centering': True, 'normalizer__with_scaling': True}), 'rebalance': ('rebalance_CondensedNearestNeighbour', {'rebalance__n_neighbors': 3})}, 'score': 0.8593801313628899, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'entropy', 'max_depth': 3, 'max_features': None, 'max_leaf_nodes': 5, 'min_samples_split': 2, 'n_estimators': 100}, 'config_hash': {'algorithm': 'c62d7c671832e4414b6b2d7c36cba5ddc83a0ed0', 'config': '5faee50671eaa0ac586722bff234e36a857e662d', 'pipeline': '8b29a55de2add78c49114b9bbe5e800e5524c59d'}, 'duration': 2.3916029930114746, 'iteration': 15, 'loss': 0.08770093336790252, 'max_history_score': 0.9456356408262035, 'max_history_score_std': 0.040053650785990214, 'max_history_step': 'joint', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 3, 'features__selectkbest__k': 4}), 'normalizer': ('normalizer_RobustScaler', {'normalizer__quantile_range': (...), 'normalizer__with_centering': True, 'normalizer__with_scaling': True}), 'rebalance': ('rebalance_NoneType', {})}, 'score': 0.9122990666320975, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': None, 'max_features': 1, 'max_leaf_nodes': 5, 'min_samples_split': 5, 'n_estimators': 10}, 'config_hash': {'algorithm': '290772bfb9b8ed15c48a72829e822fb0a07481d6', 'config': '9a04f25d8eb3db5b2f831abd341a6d384c73a957', 'pipeline': '1ce34b7894ef342571d974bb19e8ec821a512c6b'}, 'duration': 1.4364500045776367, 'iteration': 16, 'loss': 0.08948880822746508, 'max_history_score': 0.9456356408262035, 'max_history_score_std': 0.040053650785990214, 'max_history_step': 'joint', 'pipeline': {'features': ('features_PCA', {'features__n_components': 1}), 'normalizer': ('normalizer_PowerTransformer', {}), 'rebalance': ('rebalance_NoneType', {})}, 'score': 0.9105111917725349, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': 2, 'max_features': 3, 'max_leaf_nodes': 3, 'min_samples_split': 3, 'n_estimators': 100}, 'config_hash': {'algorithm': '7dab6d47f897c2961d3402eff844aff16a7d142a', 'config': '4dbfa2688b239be9f372d3e80223960ba9a1fbdd', 'pipeline': 'cdef51702798fa49f11c11d80baf3ab43d5358fc'}, 'duration': 0.9830451011657715, 'iteration': 17, 'loss': 1.0, 'max_history_score': 0.9456356408262035, 'max_history_score_std': 0.040053650785990214, 'max_history_step': 'joint', 'pipeline': {'features': ('features_SelectKBest', {'features__k': 2}), 'normalizer': ('normalizer_PowerTransformer', {}), 'rebalance': ('rebalance_NearMiss', {'rebalance__n_neighbors': 1})}, 'score': 0.0, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'entropy', 'max_depth': None, 'max_features': 3, 'max_leaf_nodes': None, 'min_samples_split': 5, 'n_estimators': 10}, 'config_hash': {'algorithm': 'def83e48be05ef92a37e1a90585820f2f67ff42b', 'config': '95902552cb76e9798f0fa58782bd72bd1cc272d7', 'pipeline': '1775187bf23f94f4fd0cc1e5c1ef665210edded5'}, 'duration': 2.0033559799194336, 'iteration': 18, 'loss': 0.04922327370149515, 'max_history_score': 0.9507767262985048, 'max_history_score_std': 0.028328108925705902, 'max_history_step': 'joint', 'pipeline': {'features': ('features_PCA', {'features__n_components': 4}), 'normalizer': ('normalizer_StandardScaler', {'normalizer__with_mean': True, 'normalizer__with_std': True}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 5})}, 'score': 0.9507767262985048, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'gini', 'max_depth': 1, 'max_features': 3, 'max_leaf_nodes': None, 'min_samples_split': 2, 'n_estimators': 50}, 'config_hash': {'algorithm': '4e9e3275f817df75115d9d7e3366980fc1b4cf13', 'config': '7770b19007b40bf13005d52eb81f87bc401f15b4', 'pipeline': 'c4dd111513ea35f97dd3aec3e8e7f6268ce035da'}, 'duration': 0.9069631099700928, 'iteration': 19, 'loss': 1.0, 'max_history_score': 0.9507767262985048, 'max_history_score_std': 0.028328108925705902, 'max_history_step': 'joint', 'pipeline': {'features': ('features_PCA', {'features__n_components': 2}), 'normalizer': ('normalizer_RobustScaler', {'normalizer__quantile_range': (...), 'normalizer__with_centering': False, 'normalizer__with_scaling': True}), 'rebalance': ('rebalance_NearMiss', {'rebalance__n_neighbors': 2})}, 'score': 0.0, ...}, ...], 'history_hash': ['51144ca42f9ea5ab2d8d58606e3b3e4d89c6d7b3', '9e54ffcb6a727de032a0a2cd45c5cc37cc150756', 'e5241eee9ddf3f4ee29a4711f5bcc92a4d24cd09', '18ee4d3d1627472ec190326308d8755371a6dc62', '2af4f82b045c0c48ecb89d42728d1039fbff8878', '17b2a1e5814f3e933137158708a5b6e9b2475495', 'fa020a592ec5ac234f9f91aac28abc2cd1ec9d33', '0da4498002d6f452c59bb61756abb3ded841e786', '344e4756fb1bec455d6af51d3727e33b0d27725f', '4a538fdcf8e07f90e92a421c0d5c479d651629c7', 'c1609e71f1ce8486335adc70bb69a955580ba2c8', 'abe36f188644e53e56ed3224236fa157107ed3b2', '76aa002c3c9d4d9722466c60daf5119c18a41d2a', 'f56a7a9e43a0a699e992dc1262e550b8b7c88538', '53f44c0ad925c5c08c25d4fadf5e9ee9d7c181cd', '5faee50671eaa0ac586722bff234e36a857e662d', '9a04f25d8eb3db5b2f831abd341a6d384c73a957', '4dbfa2688b239be9f372d3e80223960ba9a1fbdd', '95902552cb76e9798f0fa58782bd72bd1cc272d7', '7770b19007b40bf13005d52eb81f87bc401f15b4', ...], 'history_index': {'0da4498002d6f452c59bb61756abb3ded841e786': 7, '0f77a69b0a8d34861caf915a51dc588ff8d4efac': 61, '127553d555ed39231b8da3a1ce42d3902e30919b': 59, '17b2a1e5814f3e933137158708a5b6e9b2475495': 5, '18ee4d3d1627472ec190326308d8755371a6dc62': 3, '1b2267555a9226d7eb4df3c63dd12506da370f4d': 56, '2af4f82b045c0c48ecb89d42728d1039fbff8878': 4, '2d054540972225f4f17fb36d63106b7bb5c406fe': 36, '306511091d7e5d6431b5e5a6320802c4c04cde44': 33, '312e05571f41c77895a9ad8c57db6947f3fdfe03': 58, ...}, 'iteration': 64, 'max_history_score': 0.9525008642295394, 'max_history_score_std': 0.02225295065716913, 'max_history_step': 'joint'}, config={'algorithm': 'RandomForest', 'seed': 42, 'time': 300})
    108 
    109 def objective_algo(algo_config, current_pipeline_config, algorithm, X, y, context, config):
    110     return objective(current_pipeline_config, algo_config, algorithm, X, y, context, config, step='algorithm')
    111 
    112 def objective_joint(wconfig, algorithm, X, y, context, config):
--> 113     return objective(wconfig['pipeline'], wconfig['algorithm'], algorithm, X, y, context, config, step='joint')
        wconfig = {'algorithm': {'bootstrap': False, 'criterion': 'entropy', 'max_depth': None, 'max_features': 3, 'max_leaf_nodes': None, 'min_samples_split': 5, 'n_estimators': 100}, 'pipeline': {'features': ('features_PCA', {'features__n_components': 2}), 'normalizer': ('normalizer_NoneType', {}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 6})}}
        algorithm = 'RandomForest'
        X = array([[1.799e+01, 1.038e+01, 1.228e+02, ..., 2...., ..., 0.000e+00, 2.871e-01,
        7.039e-02]])
        y = array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,... 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1])
        context = {'baseline_score': 0.9545944602886527, 'baseline_score_std': 0.03716322883281839, 'best_config': {'algorithm': {'bootstrap': False, 'criterion': 'entropy', 'max_depth': None, 'max_features': 2, 'max_leaf_nodes': None, 'min_samples_split': 5, 'n_estimators': 10}, 'config_hash': {'algorithm': 'e7a772c2bc361aa61cf7eeb364a26dca2c9b89d6', 'config': 'afb67da069b544b0505b1e8c150edc7498ad37b4', 'pipeline': 'a43db4b4fc4c38610b7b5e484840d2e583089ff4'}, 'duration': 1.0073001384735107, 'iteration': 26, 'loss': 0.04749913577046061, 'max_history_score': 0.9525008642295394, 'max_history_score_std': 0.02225295065716913, 'max_history_step': 'joint', 'pipeline': {'features': ('features_PCA', {'features__n_components': 4}), 'normalizer': ('normalizer_StandardScaler', {'normalizer__with_mean': True, 'normalizer__with_std': False}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 7})}, 'score': 0.9525008642295394, ...}, 'history': [{'algorithm': {'bootstrap': True, 'criterion': 'entropy', 'max_depth': 4, 'max_features': 3, 'max_leaf_nodes': 3, 'min_samples_split': 2, 'n_estimators': 10}, 'config_hash': {'algorithm': '42527c4120073c2a488d1b8df28732f486d1578c', 'config': '51144ca42f9ea5ab2d8d58606e3b3e4d89c6d7b3', 'pipeline': '52f07bda29f9d3a95fabb87e591d0b2581ca8209'}, 'duration': 0.26703310012817383, 'iteration': 0, 'loss': 0.06655431682654922, 'max_history_score': 0.9334456831734508, 'max_history_score_std': 0.03819399139659311, 'max_history_step': 'joint', 'pipeline': {'features': ('features_NoneType', {}), 'normalizer': ('normalizer_RobustScaler', {'normalizer__quantile_range': (...), 'normalizer__with_centering': False, 'normalizer__with_scaling': False}), 'rebalance': ('rebalance_NearMiss', {'rebalance__n_neighbors': 1})}, 'score': 0.9334456831734508, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': None, 'max_features': 2, 'max_leaf_nodes': 3, 'min_samples_split': 2, 'n_estimators': 100}, 'config_hash': {'algorithm': '1b32258c630f07e01ab481ab925ab80aa757e482', 'config': '9e54ffcb6a727de032a0a2cd45c5cc37cc150756', 'pipeline': '37e72d4a97f5e784c9d3133e6379b91bfc3be803'}, 'duration': 1.3065669536590576, 'iteration': 1, 'loss': 0.05436435917379645, 'max_history_score': 0.9456356408262035, 'max_history_score_std': 0.040053650785990214, 'max_history_step': 'joint', 'pipeline': {'features': ('features_NoneType', {}), 'normalizer': ('normalizer_StandardScaler', {'normalizer__with_mean': True, 'normalizer__with_std': True}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 6})}, 'score': 0.9456356408262035, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'entropy', 'max_depth': 1, 'max_features': 1, 'max_leaf_nodes': 2, 'min_samples_split': 3, 'n_estimators': 25}, 'config_hash': {'algorithm': '68ab9059aa7ec74e0da87c81734b9664243b3eb4', 'config': 'e5241eee9ddf3f4ee29a4711f5bcc92a4d24cd09', 'pipeline': '62463de065924498cdcd2f2f1f7e68535cdb33a5'}, 'duration': 0.6592490673065186, 'iteration': 2, 'loss': 0.07695856019358727, 'max_history_score': 0.9456356408262035, 'max_history_score_std': 0.040053650785990214, 'max_history_step': 'joint', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 1, 'features__selectkbest__k': 2}), 'normalizer': ('normalizer_NoneType', {}), 'rebalance': ('rebalance_NoneType', {})}, 'score': 0.9230414398064127, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': 3, 'max_features': 2, 'max_leaf_nodes': 2, 'min_samples_split': 2, 'n_estimators': 25}, 'config_hash': {'algorithm': 'e3f1f7d7783557a38f40f0476369091edd87092b', 'config': '18ee4d3d1627472ec190326308d8755371a6dc62', 'pipeline': 'c6d1263e344ed8c71b2e6e4ba8e0db2fb6c777c0'}, 'duration': 0.879349946975708, 'iteration': 3, 'loss': 0.07535973554576114, 'max_history_score': 0.9456356408262035, 'max_history_score_std': 0.040053650785990214, 'max_history_step': 'joint', 'pipeline': {'features': ('features_NoneType', {}), 'normalizer': ('normalizer_RobustScaler', {'normalizer__quantile_range': (...), 'normalizer__with_centering': True, 'normalizer__with_scaling': True}), 'rebalance': ('rebalance_NearMiss', {'rebalance__n_neighbors': 2})}, 'score': 0.9246402644542389, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'gini', 'max_depth': 4, 'max_features': 2, 'max_leaf_nodes': 5, 'min_samples_split': 2, 'n_estimators': 50}, 'config_hash': {'algorithm': '47581af7253940f9647ad16d37347d34baf13e5f', 'config': '2af4f82b045c0c48ecb89d42728d1039fbff8878', 'pipeline': '2928b22ed834303cb7bac6e6608531eaddd7df67'}, 'duration': 4.372632026672363, 'iteration': 4, 'loss': 0.09121294615849984, 'max_history_score': 0.9456356408262035, 'max_history_score_std': 0.040053650785990214, 'max_history_step': 'joint', 'pipeline': {'features': ('features_NoneType', {}), 'normalizer': ('normalizer_MinMaxScaler', {}), 'rebalance': ('rebalance_CondensedNearestNeighbour', {'rebalance__n_neighbors': 2})}, 'score': 0.9087870538415002, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'entropy', 'max_depth': 2, 'max_features': 2, 'max_leaf_nodes': None, 'min_samples_split': 2, 'n_estimators': 10}, 'config_hash': {'algorithm': '0a85f98ca2d06103287f153633d88f7a0535e7e8', 'config': '17b2a1e5814f3e933137158708a5b6e9b2475495', 'pipeline': '95defa3bdd8357f11f872d3c280d50a6d8ee398d'}, 'duration': 2.625814914703369, 'iteration': 5, 'loss': 0.15471329185031535, 'max_history_score': 0.9456356408262035, 'max_history_score_std': 0.040053650785990214, 'max_history_step': 'joint', 'pipeline': {'features': ('features_SelectKBest', {'features__k': 2}), 'normalizer': ('normalizer_StandardScaler', {'normalizer__with_mean': False, 'normalizer__with_std': False}), 'rebalance': ('rebalance_CondensedNearestNeighbour', {'rebalance__n_neighbors': 1})}, 'score': 0.8452867081496847, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': 3, 'max_features': None, 'max_leaf_nodes': None, 'min_samples_split': 5, 'n_estimators': 75}, 'config_hash': {'algorithm': 'd7466a2c1d5cb3fa95029d73dc030f4c3c45a159', 'config': 'fa020a592ec5ac234f9f91aac28abc2cd1ec9d33', 'pipeline': '71e0d26f923d42cfe0e2fa748931ef2afe72ed86'}, 'duration': 3.62078595161438, 'iteration': 6, 'loss': 0.17066372828623277, 'max_history_score': 0.9456356408262035, 'max_history_score_std': 0.040053650785990214, 'max_history_step': 'joint', 'pipeline': {'features': ('features_SelectKBest', {'features__k': 1}), 'normalizer': ('normalizer_RobustScaler', {'normalizer__quantile_range': (...), 'normalizer__with_centering': True, 'normalizer__with_scaling': True}), 'rebalance': ('rebalance_CondensedNearestNeighbour', {'rebalance__n_neighbors': 1})}, 'score': 0.8293362717137672, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'entropy', 'max_depth': 3, 'max_features': 3, 'max_leaf_nodes': 5, 'min_samples_split': 5, 'n_estimators': 50}, 'config_hash': {'algorithm': '735caa9785596076014572a24050cde8dc338973', 'config': '0da4498002d6f452c59bb61756abb3ded841e786', 'pipeline': '51a53ea6ef5a2521ee65f76eb2da220ab7086513'}, 'duration': 0.6934049129486084, 'iteration': 7, 'loss': 0.06125875032408601, 'max_history_score': 0.9456356408262035, 'max_history_score_std': 0.040053650785990214, 'max_history_step': 'joint', 'pipeline': {'features': ('features_NoneType', {}), 'normalizer': ('normalizer_NoneType', {}), 'rebalance': ('rebalance_NearMiss', {'rebalance__n_neighbors': 3})}, 'score': 0.938741249675914, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': 4, 'max_features': 2, 'max_leaf_nodes': None, 'min_samples_split': 3, 'n_estimators': 75}, 'config_hash': {'algorithm': 'e71a1fe9515b6805f07914a61f2e7594be9e9afe', 'config': '344e4756fb1bec455d6af51d3727e33b0d27725f', 'pipeline': '248dad1d8b30a17a5de1d0bbdfe3e2acb7a1962b'}, 'duration': 1.3036692142486572, 'iteration': 8, 'loss': 0.06483125918243893, 'max_history_score': 0.9456356408262035, 'max_history_score_std': 0.040053650785990214, 'max_history_step': 'joint', 'pipeline': {'features': ('features_PCA', {'features__n_components': 2}), 'normalizer': ('normalizer_StandardScaler', {'normalizer__with_mean': False, 'normalizer__with_std': True}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 7})}, 'score': 0.9351687408175611, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'entropy', 'max_depth': 2, 'max_features': 2, 'max_leaf_nodes': 2, 'min_samples_split': 3, 'n_estimators': 10}, 'config_hash': {'algorithm': '0a507823f2ad8605ed5950e1fe61df0560f11a00', 'config': '4a538fdcf8e07f90e92a421c0d5c479d651629c7', 'pipeline': '5240329df25c9a533d025c1a401d49835a501b41'}, 'duration': 1.3821029663085938, 'iteration': 9, 'loss': 0.07006416904329793, 'max_history_score': 0.9456356408262035, 'max_history_score_std': 0.040053650785990214, 'max_history_step': 'joint', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 4, 'features__selectkbest__k': 2}), 'normalizer': ('normalizer_PowerTransformer', {}), 'rebalance': ('rebalance_NearMiss', {'rebalance__n_neighbors': 1})}, 'score': 0.9299358309567021, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'gini', 'max_depth': 1, 'max_features': 3, 'max_leaf_nodes': 5, 'min_samples_split': 3, 'n_estimators': 10}, 'config_hash': {'algorithm': 'd32739750d351948f8ff34a87c7d55b0c5e0d90f', 'config': 'c1609e71f1ce8486335adc70bb69a955580ba2c8', 'pipeline': 'f48b42ec5cf999279659966160a16353b75bdaa3'}, 'duration': 0.9055681228637695, 'iteration': 10, 'loss': 0.07532840722495904, 'max_history_score': 0.9456356408262035, 'max_history_score_std': 0.040053650785990214, 'max_history_step': 'joint', 'pipeline': {'features': ('features_PCA', {'features__n_components': 4}), 'normalizer': ('normalizer_PowerTransformer', {}), 'rebalance': ('rebalance_NearMiss', {'rebalance__n_neighbors': 1})}, 'score': 0.924671592775041, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': 3, 'max_features': 1, 'max_leaf_nodes': 5, 'min_samples_split': 3, 'n_estimators': 25}, 'config_hash': {'algorithm': 'f69bac35e71cbec1bfc1fb5942328a3390e7c252', 'config': 'abe36f188644e53e56ed3224236fa157107ed3b2', 'pipeline': 'aaf976c7c663a31fa039582d42f9e07101556a7c'}, 'duration': 0.764197826385498, 'iteration': 11, 'loss': 0.06818446979517778, 'max_history_score': 0.9456356408262035, 'max_history_score_std': 0.040053650785990214, 'max_history_step': 'joint', 'pipeline': {'features': ('features_NoneType', {}), 'normalizer': ('normalizer_PowerTransformer', {}), 'rebalance': ('rebalance_NoneType', {})}, 'score': 0.9318155302048222, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'entropy', 'max_depth': None, 'max_features': None, 'max_leaf_nodes': None, 'min_samples_split': 5, 'n_estimators': 25}, 'config_hash': {'algorithm': 'a0a27aec00db5ddf71eab96663f9bd61c845f5e3', 'config': '76aa002c3c9d4d9722466c60daf5119c18a41d2a', 'pipeline': '1ce34b7894ef342571d974bb19e8ec821a512c6b'}, 'duration': 1.1636500358581543, 'iteration': 12, 'loss': 0.12833700630887557, 'max_history_score': 0.9456356408262035, 'max_history_score_std': 0.040053650785990214, 'max_history_step': 'joint', 'pipeline': {'features': ('features_PCA', {'features__n_components': 1}), 'normalizer': ('normalizer_PowerTransformer', {}), 'rebalance': ('rebalance_NoneType', {})}, 'score': 0.8716629936911244, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'gini', 'max_depth': 1, 'max_features': 2, 'max_leaf_nodes': 2, 'min_samples_split': 2, 'n_estimators': 100}, 'config_hash': {'algorithm': '985c99dff1da9b2c87e4211c5335a9159aa9dbcb', 'config': 'f56a7a9e43a0a699e992dc1262e550b8b7c88538', 'pipeline': '5c934f6d9a8ad1f9afe762986a9cf2074fc95d79'}, 'duration': 2.235443115234375, 'iteration': 13, 'loss': 0.11414635727249167, 'max_history_score': 0.9456356408262035, 'max_history_score_std': 0.040053650785990214, 'max_history_step': 'joint', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 1, 'features__selectkbest__k': 1}), 'normalizer': ('normalizer_RobustScaler', {'normalizer__quantile_range': (...), 'normalizer__with_centering': False, 'normalizer__with_scaling': True}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 6})}, 'score': 0.8858536427275083, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'gini', 'max_depth': 1, 'max_features': 1, 'max_leaf_nodes': None, 'min_samples_split': 5, 'n_estimators': 10}, 'config_hash': {'algorithm': '7d74a39aac2579264a402aef2b6fa7943c19f3d3', 'config': '53f44c0ad925c5c08c25d4fadf5e9ee9d7c181cd', 'pipeline': '6eff5ef31d7d1d534db31913bb67529c8a24c42e'}, 'duration': 2.7847659587860107, 'iteration': 14, 'loss': 0.14061986863711007, 'max_history_score': 0.9456356408262035, 'max_history_score_std': 0.040053650785990214, 'max_history_step': 'joint', 'pipeline': {'features': ('features_PCA', {'features__n_components': 1}), 'normalizer': ('normalizer_RobustScaler', {'normalizer__quantile_range': (...), 'normalizer__with_centering': True, 'normalizer__with_scaling': True}), 'rebalance': ('rebalance_CondensedNearestNeighbour', {'rebalance__n_neighbors': 3})}, 'score': 0.8593801313628899, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'entropy', 'max_depth': 3, 'max_features': None, 'max_leaf_nodes': 5, 'min_samples_split': 2, 'n_estimators': 100}, 'config_hash': {'algorithm': 'c62d7c671832e4414b6b2d7c36cba5ddc83a0ed0', 'config': '5faee50671eaa0ac586722bff234e36a857e662d', 'pipeline': '8b29a55de2add78c49114b9bbe5e800e5524c59d'}, 'duration': 2.3916029930114746, 'iteration': 15, 'loss': 0.08770093336790252, 'max_history_score': 0.9456356408262035, 'max_history_score_std': 0.040053650785990214, 'max_history_step': 'joint', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 3, 'features__selectkbest__k': 4}), 'normalizer': ('normalizer_RobustScaler', {'normalizer__quantile_range': (...), 'normalizer__with_centering': True, 'normalizer__with_scaling': True}), 'rebalance': ('rebalance_NoneType', {})}, 'score': 0.9122990666320975, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': None, 'max_features': 1, 'max_leaf_nodes': 5, 'min_samples_split': 5, 'n_estimators': 10}, 'config_hash': {'algorithm': '290772bfb9b8ed15c48a72829e822fb0a07481d6', 'config': '9a04f25d8eb3db5b2f831abd341a6d384c73a957', 'pipeline': '1ce34b7894ef342571d974bb19e8ec821a512c6b'}, 'duration': 1.4364500045776367, 'iteration': 16, 'loss': 0.08948880822746508, 'max_history_score': 0.9456356408262035, 'max_history_score_std': 0.040053650785990214, 'max_history_step': 'joint', 'pipeline': {'features': ('features_PCA', {'features__n_components': 1}), 'normalizer': ('normalizer_PowerTransformer', {}), 'rebalance': ('rebalance_NoneType', {})}, 'score': 0.9105111917725349, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': 2, 'max_features': 3, 'max_leaf_nodes': 3, 'min_samples_split': 3, 'n_estimators': 100}, 'config_hash': {'algorithm': '7dab6d47f897c2961d3402eff844aff16a7d142a', 'config': '4dbfa2688b239be9f372d3e80223960ba9a1fbdd', 'pipeline': 'cdef51702798fa49f11c11d80baf3ab43d5358fc'}, 'duration': 0.9830451011657715, 'iteration': 17, 'loss': 1.0, 'max_history_score': 0.9456356408262035, 'max_history_score_std': 0.040053650785990214, 'max_history_step': 'joint', 'pipeline': {'features': ('features_SelectKBest', {'features__k': 2}), 'normalizer': ('normalizer_PowerTransformer', {}), 'rebalance': ('rebalance_NearMiss', {'rebalance__n_neighbors': 1})}, 'score': 0.0, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'entropy', 'max_depth': None, 'max_features': 3, 'max_leaf_nodes': None, 'min_samples_split': 5, 'n_estimators': 10}, 'config_hash': {'algorithm': 'def83e48be05ef92a37e1a90585820f2f67ff42b', 'config': '95902552cb76e9798f0fa58782bd72bd1cc272d7', 'pipeline': '1775187bf23f94f4fd0cc1e5c1ef665210edded5'}, 'duration': 2.0033559799194336, 'iteration': 18, 'loss': 0.04922327370149515, 'max_history_score': 0.9507767262985048, 'max_history_score_std': 0.028328108925705902, 'max_history_step': 'joint', 'pipeline': {'features': ('features_PCA', {'features__n_components': 4}), 'normalizer': ('normalizer_StandardScaler', {'normalizer__with_mean': True, 'normalizer__with_std': True}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 5})}, 'score': 0.9507767262985048, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'gini', 'max_depth': 1, 'max_features': 3, 'max_leaf_nodes': None, 'min_samples_split': 2, 'n_estimators': 50}, 'config_hash': {'algorithm': '4e9e3275f817df75115d9d7e3366980fc1b4cf13', 'config': '7770b19007b40bf13005d52eb81f87bc401f15b4', 'pipeline': 'c4dd111513ea35f97dd3aec3e8e7f6268ce035da'}, 'duration': 0.9069631099700928, 'iteration': 19, 'loss': 1.0, 'max_history_score': 0.9507767262985048, 'max_history_score_std': 0.028328108925705902, 'max_history_step': 'joint', 'pipeline': {'features': ('features_PCA', {'features__n_components': 2}), 'normalizer': ('normalizer_RobustScaler', {'normalizer__quantile_range': (...), 'normalizer__with_centering': False, 'normalizer__with_scaling': True}), 'rebalance': ('rebalance_NearMiss', {'rebalance__n_neighbors': 2})}, 'score': 0.0, ...}, ...], 'history_hash': ['51144ca42f9ea5ab2d8d58606e3b3e4d89c6d7b3', '9e54ffcb6a727de032a0a2cd45c5cc37cc150756', 'e5241eee9ddf3f4ee29a4711f5bcc92a4d24cd09', '18ee4d3d1627472ec190326308d8755371a6dc62', '2af4f82b045c0c48ecb89d42728d1039fbff8878', '17b2a1e5814f3e933137158708a5b6e9b2475495', 'fa020a592ec5ac234f9f91aac28abc2cd1ec9d33', '0da4498002d6f452c59bb61756abb3ded841e786', '344e4756fb1bec455d6af51d3727e33b0d27725f', '4a538fdcf8e07f90e92a421c0d5c479d651629c7', 'c1609e71f1ce8486335adc70bb69a955580ba2c8', 'abe36f188644e53e56ed3224236fa157107ed3b2', '76aa002c3c9d4d9722466c60daf5119c18a41d2a', 'f56a7a9e43a0a699e992dc1262e550b8b7c88538', '53f44c0ad925c5c08c25d4fadf5e9ee9d7c181cd', '5faee50671eaa0ac586722bff234e36a857e662d', '9a04f25d8eb3db5b2f831abd341a6d384c73a957', '4dbfa2688b239be9f372d3e80223960ba9a1fbdd', '95902552cb76e9798f0fa58782bd72bd1cc272d7', '7770b19007b40bf13005d52eb81f87bc401f15b4', ...], 'history_index': {'0da4498002d6f452c59bb61756abb3ded841e786': 7, '0f77a69b0a8d34861caf915a51dc588ff8d4efac': 61, '127553d555ed39231b8da3a1ce42d3902e30919b': 59, '17b2a1e5814f3e933137158708a5b6e9b2475495': 5, '18ee4d3d1627472ec190326308d8755371a6dc62': 3, '1b2267555a9226d7eb4df3c63dd12506da370f4d': 56, '2af4f82b045c0c48ecb89d42728d1039fbff8878': 4, '2d054540972225f4f17fb36d63106b7bb5c406fe': 36, '306511091d7e5d6431b5e5a6320802c4c04cde44': 33, '312e05571f41c77895a9ad8c57db6947f3fdfe03': 58, ...}, 'iteration': 64, 'max_history_score': 0.9525008642295394, 'max_history_score_std': 0.02225295065716913, 'max_history_step': 'joint'}
        config = {'algorithm': 'RandomForest', 'seed': 42, 'time': 300}
    114 
    115 
    116 def get_baseline_score(algorithm, X, y, seed):
    117     pipeline, _ = pipeline_conf_to_full_pipeline(

...........................................................................
/home/aquemy/dev/dp_hyperparameters/extension/experiment/objective.py in objective(pipeline_config={'features': ('features_PCA', {'features__n_components': 2}), 'normalizer': ('normalizer_NoneType', {}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 6})}, algo_config={'bootstrap': False, 'criterion': 'entropy', 'max_depth': None, 'max_features': 3, 'max_leaf_nodes': None, 'min_samples_split': 5, 'n_estimators': 100}, algorithm='RandomForest', X=array([[1.799e+01, 1.038e+01, 1.228e+02, ..., 2...., ..., 0.000e+00, 2.871e-01,
        7.039e-02]]), y=array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,... 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1]), context={'baseline_score': 0.9545944602886527, 'baseline_score_std': 0.03716322883281839, 'best_config': {'algorithm': {'bootstrap': False, 'criterion': 'entropy', 'max_depth': None, 'max_features': 2, 'max_leaf_nodes': None, 'min_samples_split': 5, 'n_estimators': 10}, 'config_hash': {'algorithm': 'e7a772c2bc361aa61cf7eeb364a26dca2c9b89d6', 'config': 'afb67da069b544b0505b1e8c150edc7498ad37b4', 'pipeline': 'a43db4b4fc4c38610b7b5e484840d2e583089ff4'}, 'duration': 1.0073001384735107, 'iteration': 26, 'loss': 0.04749913577046061, 'max_history_score': 0.9525008642295394, 'max_history_score_std': 0.02225295065716913, 'max_history_step': 'joint', 'pipeline': {'features': ('features_PCA', {'features__n_components': 4}), 'normalizer': ('normalizer_StandardScaler', {'normalizer__with_mean': True, 'normalizer__with_std': False}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 7})}, 'score': 0.9525008642295394, ...}, 'history': [{'algorithm': {'bootstrap': True, 'criterion': 'entropy', 'max_depth': 4, 'max_features': 3, 'max_leaf_nodes': 3, 'min_samples_split': 2, 'n_estimators': 10}, 'config_hash': {'algorithm': '42527c4120073c2a488d1b8df28732f486d1578c', 'config': '51144ca42f9ea5ab2d8d58606e3b3e4d89c6d7b3', 'pipeline': '52f07bda29f9d3a95fabb87e591d0b2581ca8209'}, 'duration': 0.26703310012817383, 'iteration': 0, 'loss': 0.06655431682654922, 'max_history_score': 0.9334456831734508, 'max_history_score_std': 0.03819399139659311, 'max_history_step': 'joint', 'pipeline': {'features': ('features_NoneType', {}), 'normalizer': ('normalizer_RobustScaler', {'normalizer__quantile_range': (...), 'normalizer__with_centering': False, 'normalizer__with_scaling': False}), 'rebalance': ('rebalance_NearMiss', {'rebalance__n_neighbors': 1})}, 'score': 0.9334456831734508, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': None, 'max_features': 2, 'max_leaf_nodes': 3, 'min_samples_split': 2, 'n_estimators': 100}, 'config_hash': {'algorithm': '1b32258c630f07e01ab481ab925ab80aa757e482', 'config': '9e54ffcb6a727de032a0a2cd45c5cc37cc150756', 'pipeline': '37e72d4a97f5e784c9d3133e6379b91bfc3be803'}, 'duration': 1.3065669536590576, 'iteration': 1, 'loss': 0.05436435917379645, 'max_history_score': 0.9456356408262035, 'max_history_score_std': 0.040053650785990214, 'max_history_step': 'joint', 'pipeline': {'features': ('features_NoneType', {}), 'normalizer': ('normalizer_StandardScaler', {'normalizer__with_mean': True, 'normalizer__with_std': True}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 6})}, 'score': 0.9456356408262035, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'entropy', 'max_depth': 1, 'max_features': 1, 'max_leaf_nodes': 2, 'min_samples_split': 3, 'n_estimators': 25}, 'config_hash': {'algorithm': '68ab9059aa7ec74e0da87c81734b9664243b3eb4', 'config': 'e5241eee9ddf3f4ee29a4711f5bcc92a4d24cd09', 'pipeline': '62463de065924498cdcd2f2f1f7e68535cdb33a5'}, 'duration': 0.6592490673065186, 'iteration': 2, 'loss': 0.07695856019358727, 'max_history_score': 0.9456356408262035, 'max_history_score_std': 0.040053650785990214, 'max_history_step': 'joint', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 1, 'features__selectkbest__k': 2}), 'normalizer': ('normalizer_NoneType', {}), 'rebalance': ('rebalance_NoneType', {})}, 'score': 0.9230414398064127, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': 3, 'max_features': 2, 'max_leaf_nodes': 2, 'min_samples_split': 2, 'n_estimators': 25}, 'config_hash': {'algorithm': 'e3f1f7d7783557a38f40f0476369091edd87092b', 'config': '18ee4d3d1627472ec190326308d8755371a6dc62', 'pipeline': 'c6d1263e344ed8c71b2e6e4ba8e0db2fb6c777c0'}, 'duration': 0.879349946975708, 'iteration': 3, 'loss': 0.07535973554576114, 'max_history_score': 0.9456356408262035, 'max_history_score_std': 0.040053650785990214, 'max_history_step': 'joint', 'pipeline': {'features': ('features_NoneType', {}), 'normalizer': ('normalizer_RobustScaler', {'normalizer__quantile_range': (...), 'normalizer__with_centering': True, 'normalizer__with_scaling': True}), 'rebalance': ('rebalance_NearMiss', {'rebalance__n_neighbors': 2})}, 'score': 0.9246402644542389, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'gini', 'max_depth': 4, 'max_features': 2, 'max_leaf_nodes': 5, 'min_samples_split': 2, 'n_estimators': 50}, 'config_hash': {'algorithm': '47581af7253940f9647ad16d37347d34baf13e5f', 'config': '2af4f82b045c0c48ecb89d42728d1039fbff8878', 'pipeline': '2928b22ed834303cb7bac6e6608531eaddd7df67'}, 'duration': 4.372632026672363, 'iteration': 4, 'loss': 0.09121294615849984, 'max_history_score': 0.9456356408262035, 'max_history_score_std': 0.040053650785990214, 'max_history_step': 'joint', 'pipeline': {'features': ('features_NoneType', {}), 'normalizer': ('normalizer_MinMaxScaler', {}), 'rebalance': ('rebalance_CondensedNearestNeighbour', {'rebalance__n_neighbors': 2})}, 'score': 0.9087870538415002, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'entropy', 'max_depth': 2, 'max_features': 2, 'max_leaf_nodes': None, 'min_samples_split': 2, 'n_estimators': 10}, 'config_hash': {'algorithm': '0a85f98ca2d06103287f153633d88f7a0535e7e8', 'config': '17b2a1e5814f3e933137158708a5b6e9b2475495', 'pipeline': '95defa3bdd8357f11f872d3c280d50a6d8ee398d'}, 'duration': 2.625814914703369, 'iteration': 5, 'loss': 0.15471329185031535, 'max_history_score': 0.9456356408262035, 'max_history_score_std': 0.040053650785990214, 'max_history_step': 'joint', 'pipeline': {'features': ('features_SelectKBest', {'features__k': 2}), 'normalizer': ('normalizer_StandardScaler', {'normalizer__with_mean': False, 'normalizer__with_std': False}), 'rebalance': ('rebalance_CondensedNearestNeighbour', {'rebalance__n_neighbors': 1})}, 'score': 0.8452867081496847, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': 3, 'max_features': None, 'max_leaf_nodes': None, 'min_samples_split': 5, 'n_estimators': 75}, 'config_hash': {'algorithm': 'd7466a2c1d5cb3fa95029d73dc030f4c3c45a159', 'config': 'fa020a592ec5ac234f9f91aac28abc2cd1ec9d33', 'pipeline': '71e0d26f923d42cfe0e2fa748931ef2afe72ed86'}, 'duration': 3.62078595161438, 'iteration': 6, 'loss': 0.17066372828623277, 'max_history_score': 0.9456356408262035, 'max_history_score_std': 0.040053650785990214, 'max_history_step': 'joint', 'pipeline': {'features': ('features_SelectKBest', {'features__k': 1}), 'normalizer': ('normalizer_RobustScaler', {'normalizer__quantile_range': (...), 'normalizer__with_centering': True, 'normalizer__with_scaling': True}), 'rebalance': ('rebalance_CondensedNearestNeighbour', {'rebalance__n_neighbors': 1})}, 'score': 0.8293362717137672, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'entropy', 'max_depth': 3, 'max_features': 3, 'max_leaf_nodes': 5, 'min_samples_split': 5, 'n_estimators': 50}, 'config_hash': {'algorithm': '735caa9785596076014572a24050cde8dc338973', 'config': '0da4498002d6f452c59bb61756abb3ded841e786', 'pipeline': '51a53ea6ef5a2521ee65f76eb2da220ab7086513'}, 'duration': 0.6934049129486084, 'iteration': 7, 'loss': 0.06125875032408601, 'max_history_score': 0.9456356408262035, 'max_history_score_std': 0.040053650785990214, 'max_history_step': 'joint', 'pipeline': {'features': ('features_NoneType', {}), 'normalizer': ('normalizer_NoneType', {}), 'rebalance': ('rebalance_NearMiss', {'rebalance__n_neighbors': 3})}, 'score': 0.938741249675914, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': 4, 'max_features': 2, 'max_leaf_nodes': None, 'min_samples_split': 3, 'n_estimators': 75}, 'config_hash': {'algorithm': 'e71a1fe9515b6805f07914a61f2e7594be9e9afe', 'config': '344e4756fb1bec455d6af51d3727e33b0d27725f', 'pipeline': '248dad1d8b30a17a5de1d0bbdfe3e2acb7a1962b'}, 'duration': 1.3036692142486572, 'iteration': 8, 'loss': 0.06483125918243893, 'max_history_score': 0.9456356408262035, 'max_history_score_std': 0.040053650785990214, 'max_history_step': 'joint', 'pipeline': {'features': ('features_PCA', {'features__n_components': 2}), 'normalizer': ('normalizer_StandardScaler', {'normalizer__with_mean': False, 'normalizer__with_std': True}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 7})}, 'score': 0.9351687408175611, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'entropy', 'max_depth': 2, 'max_features': 2, 'max_leaf_nodes': 2, 'min_samples_split': 3, 'n_estimators': 10}, 'config_hash': {'algorithm': '0a507823f2ad8605ed5950e1fe61df0560f11a00', 'config': '4a538fdcf8e07f90e92a421c0d5c479d651629c7', 'pipeline': '5240329df25c9a533d025c1a401d49835a501b41'}, 'duration': 1.3821029663085938, 'iteration': 9, 'loss': 0.07006416904329793, 'max_history_score': 0.9456356408262035, 'max_history_score_std': 0.040053650785990214, 'max_history_step': 'joint', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 4, 'features__selectkbest__k': 2}), 'normalizer': ('normalizer_PowerTransformer', {}), 'rebalance': ('rebalance_NearMiss', {'rebalance__n_neighbors': 1})}, 'score': 0.9299358309567021, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'gini', 'max_depth': 1, 'max_features': 3, 'max_leaf_nodes': 5, 'min_samples_split': 3, 'n_estimators': 10}, 'config_hash': {'algorithm': 'd32739750d351948f8ff34a87c7d55b0c5e0d90f', 'config': 'c1609e71f1ce8486335adc70bb69a955580ba2c8', 'pipeline': 'f48b42ec5cf999279659966160a16353b75bdaa3'}, 'duration': 0.9055681228637695, 'iteration': 10, 'loss': 0.07532840722495904, 'max_history_score': 0.9456356408262035, 'max_history_score_std': 0.040053650785990214, 'max_history_step': 'joint', 'pipeline': {'features': ('features_PCA', {'features__n_components': 4}), 'normalizer': ('normalizer_PowerTransformer', {}), 'rebalance': ('rebalance_NearMiss', {'rebalance__n_neighbors': 1})}, 'score': 0.924671592775041, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': 3, 'max_features': 1, 'max_leaf_nodes': 5, 'min_samples_split': 3, 'n_estimators': 25}, 'config_hash': {'algorithm': 'f69bac35e71cbec1bfc1fb5942328a3390e7c252', 'config': 'abe36f188644e53e56ed3224236fa157107ed3b2', 'pipeline': 'aaf976c7c663a31fa039582d42f9e07101556a7c'}, 'duration': 0.764197826385498, 'iteration': 11, 'loss': 0.06818446979517778, 'max_history_score': 0.9456356408262035, 'max_history_score_std': 0.040053650785990214, 'max_history_step': 'joint', 'pipeline': {'features': ('features_NoneType', {}), 'normalizer': ('normalizer_PowerTransformer', {}), 'rebalance': ('rebalance_NoneType', {})}, 'score': 0.9318155302048222, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'entropy', 'max_depth': None, 'max_features': None, 'max_leaf_nodes': None, 'min_samples_split': 5, 'n_estimators': 25}, 'config_hash': {'algorithm': 'a0a27aec00db5ddf71eab96663f9bd61c845f5e3', 'config': '76aa002c3c9d4d9722466c60daf5119c18a41d2a', 'pipeline': '1ce34b7894ef342571d974bb19e8ec821a512c6b'}, 'duration': 1.1636500358581543, 'iteration': 12, 'loss': 0.12833700630887557, 'max_history_score': 0.9456356408262035, 'max_history_score_std': 0.040053650785990214, 'max_history_step': 'joint', 'pipeline': {'features': ('features_PCA', {'features__n_components': 1}), 'normalizer': ('normalizer_PowerTransformer', {}), 'rebalance': ('rebalance_NoneType', {})}, 'score': 0.8716629936911244, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'gini', 'max_depth': 1, 'max_features': 2, 'max_leaf_nodes': 2, 'min_samples_split': 2, 'n_estimators': 100}, 'config_hash': {'algorithm': '985c99dff1da9b2c87e4211c5335a9159aa9dbcb', 'config': 'f56a7a9e43a0a699e992dc1262e550b8b7c88538', 'pipeline': '5c934f6d9a8ad1f9afe762986a9cf2074fc95d79'}, 'duration': 2.235443115234375, 'iteration': 13, 'loss': 0.11414635727249167, 'max_history_score': 0.9456356408262035, 'max_history_score_std': 0.040053650785990214, 'max_history_step': 'joint', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 1, 'features__selectkbest__k': 1}), 'normalizer': ('normalizer_RobustScaler', {'normalizer__quantile_range': (...), 'normalizer__with_centering': False, 'normalizer__with_scaling': True}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 6})}, 'score': 0.8858536427275083, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'gini', 'max_depth': 1, 'max_features': 1, 'max_leaf_nodes': None, 'min_samples_split': 5, 'n_estimators': 10}, 'config_hash': {'algorithm': '7d74a39aac2579264a402aef2b6fa7943c19f3d3', 'config': '53f44c0ad925c5c08c25d4fadf5e9ee9d7c181cd', 'pipeline': '6eff5ef31d7d1d534db31913bb67529c8a24c42e'}, 'duration': 2.7847659587860107, 'iteration': 14, 'loss': 0.14061986863711007, 'max_history_score': 0.9456356408262035, 'max_history_score_std': 0.040053650785990214, 'max_history_step': 'joint', 'pipeline': {'features': ('features_PCA', {'features__n_components': 1}), 'normalizer': ('normalizer_RobustScaler', {'normalizer__quantile_range': (...), 'normalizer__with_centering': True, 'normalizer__with_scaling': True}), 'rebalance': ('rebalance_CondensedNearestNeighbour', {'rebalance__n_neighbors': 3})}, 'score': 0.8593801313628899, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'entropy', 'max_depth': 3, 'max_features': None, 'max_leaf_nodes': 5, 'min_samples_split': 2, 'n_estimators': 100}, 'config_hash': {'algorithm': 'c62d7c671832e4414b6b2d7c36cba5ddc83a0ed0', 'config': '5faee50671eaa0ac586722bff234e36a857e662d', 'pipeline': '8b29a55de2add78c49114b9bbe5e800e5524c59d'}, 'duration': 2.3916029930114746, 'iteration': 15, 'loss': 0.08770093336790252, 'max_history_score': 0.9456356408262035, 'max_history_score_std': 0.040053650785990214, 'max_history_step': 'joint', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 3, 'features__selectkbest__k': 4}), 'normalizer': ('normalizer_RobustScaler', {'normalizer__quantile_range': (...), 'normalizer__with_centering': True, 'normalizer__with_scaling': True}), 'rebalance': ('rebalance_NoneType', {})}, 'score': 0.9122990666320975, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': None, 'max_features': 1, 'max_leaf_nodes': 5, 'min_samples_split': 5, 'n_estimators': 10}, 'config_hash': {'algorithm': '290772bfb9b8ed15c48a72829e822fb0a07481d6', 'config': '9a04f25d8eb3db5b2f831abd341a6d384c73a957', 'pipeline': '1ce34b7894ef342571d974bb19e8ec821a512c6b'}, 'duration': 1.4364500045776367, 'iteration': 16, 'loss': 0.08948880822746508, 'max_history_score': 0.9456356408262035, 'max_history_score_std': 0.040053650785990214, 'max_history_step': 'joint', 'pipeline': {'features': ('features_PCA', {'features__n_components': 1}), 'normalizer': ('normalizer_PowerTransformer', {}), 'rebalance': ('rebalance_NoneType', {})}, 'score': 0.9105111917725349, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': 2, 'max_features': 3, 'max_leaf_nodes': 3, 'min_samples_split': 3, 'n_estimators': 100}, 'config_hash': {'algorithm': '7dab6d47f897c2961d3402eff844aff16a7d142a', 'config': '4dbfa2688b239be9f372d3e80223960ba9a1fbdd', 'pipeline': 'cdef51702798fa49f11c11d80baf3ab43d5358fc'}, 'duration': 0.9830451011657715, 'iteration': 17, 'loss': 1.0, 'max_history_score': 0.9456356408262035, 'max_history_score_std': 0.040053650785990214, 'max_history_step': 'joint', 'pipeline': {'features': ('features_SelectKBest', {'features__k': 2}), 'normalizer': ('normalizer_PowerTransformer', {}), 'rebalance': ('rebalance_NearMiss', {'rebalance__n_neighbors': 1})}, 'score': 0.0, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'entropy', 'max_depth': None, 'max_features': 3, 'max_leaf_nodes': None, 'min_samples_split': 5, 'n_estimators': 10}, 'config_hash': {'algorithm': 'def83e48be05ef92a37e1a90585820f2f67ff42b', 'config': '95902552cb76e9798f0fa58782bd72bd1cc272d7', 'pipeline': '1775187bf23f94f4fd0cc1e5c1ef665210edded5'}, 'duration': 2.0033559799194336, 'iteration': 18, 'loss': 0.04922327370149515, 'max_history_score': 0.9507767262985048, 'max_history_score_std': 0.028328108925705902, 'max_history_step': 'joint', 'pipeline': {'features': ('features_PCA', {'features__n_components': 4}), 'normalizer': ('normalizer_StandardScaler', {'normalizer__with_mean': True, 'normalizer__with_std': True}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 5})}, 'score': 0.9507767262985048, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'gini', 'max_depth': 1, 'max_features': 3, 'max_leaf_nodes': None, 'min_samples_split': 2, 'n_estimators': 50}, 'config_hash': {'algorithm': '4e9e3275f817df75115d9d7e3366980fc1b4cf13', 'config': '7770b19007b40bf13005d52eb81f87bc401f15b4', 'pipeline': 'c4dd111513ea35f97dd3aec3e8e7f6268ce035da'}, 'duration': 0.9069631099700928, 'iteration': 19, 'loss': 1.0, 'max_history_score': 0.9507767262985048, 'max_history_score_std': 0.028328108925705902, 'max_history_step': 'joint', 'pipeline': {'features': ('features_PCA', {'features__n_components': 2}), 'normalizer': ('normalizer_RobustScaler', {'normalizer__quantile_range': (...), 'normalizer__with_centering': False, 'normalizer__with_scaling': True}), 'rebalance': ('rebalance_NearMiss', {'rebalance__n_neighbors': 2})}, 'score': 0.0, ...}, ...], 'history_hash': ['51144ca42f9ea5ab2d8d58606e3b3e4d89c6d7b3', '9e54ffcb6a727de032a0a2cd45c5cc37cc150756', 'e5241eee9ddf3f4ee29a4711f5bcc92a4d24cd09', '18ee4d3d1627472ec190326308d8755371a6dc62', '2af4f82b045c0c48ecb89d42728d1039fbff8878', '17b2a1e5814f3e933137158708a5b6e9b2475495', 'fa020a592ec5ac234f9f91aac28abc2cd1ec9d33', '0da4498002d6f452c59bb61756abb3ded841e786', '344e4756fb1bec455d6af51d3727e33b0d27725f', '4a538fdcf8e07f90e92a421c0d5c479d651629c7', 'c1609e71f1ce8486335adc70bb69a955580ba2c8', 'abe36f188644e53e56ed3224236fa157107ed3b2', '76aa002c3c9d4d9722466c60daf5119c18a41d2a', 'f56a7a9e43a0a699e992dc1262e550b8b7c88538', '53f44c0ad925c5c08c25d4fadf5e9ee9d7c181cd', '5faee50671eaa0ac586722bff234e36a857e662d', '9a04f25d8eb3db5b2f831abd341a6d384c73a957', '4dbfa2688b239be9f372d3e80223960ba9a1fbdd', '95902552cb76e9798f0fa58782bd72bd1cc272d7', '7770b19007b40bf13005d52eb81f87bc401f15b4', ...], 'history_index': {'0da4498002d6f452c59bb61756abb3ded841e786': 7, '0f77a69b0a8d34861caf915a51dc588ff8d4efac': 61, '127553d555ed39231b8da3a1ce42d3902e30919b': 59, '17b2a1e5814f3e933137158708a5b6e9b2475495': 5, '18ee4d3d1627472ec190326308d8755371a6dc62': 3, '1b2267555a9226d7eb4df3c63dd12506da370f4d': 56, '2af4f82b045c0c48ecb89d42728d1039fbff8878': 4, '2d054540972225f4f17fb36d63106b7bb5c406fe': 36, '306511091d7e5d6431b5e5a6320802c4c04cde44': 33, '312e05571f41c77895a9ad8c57db6947f3fdfe03': 58, ...}, 'iteration': 64, 'max_history_score': 0.9525008642295394, 'max_history_score_std': 0.02225295065716913, 'max_history_step': 'joint'}, config={'algorithm': 'RandomForest', 'seed': 42, 'time': 300}, step='joint')
     45                 y,
     46                 cv=10,
     47                 n_jobs=-1,
     48                 return_estimator=False,
     49                 return_train_score=False,
---> 50                 verbose=0)
     51         score = np.mean(scores['test_score'])
     52         std = np.std(scores['test_score'])
     53         status = STATUS_OK
     54     except Exception as e:

...........................................................................
/home/aquemy/.local/lib/python2.7/site-packages/sklearn/model_selection/_validation.py in cross_validate(estimator=Pipeline(memory=None,
     steps=[('rebalance', ... random_state=42, verbose=0, warm_start=False))]), X=array([[1.799e+01, 1.038e+01, 1.228e+02, ..., 2...., ..., 0.000e+00, 2.871e-01,
        7.039e-02]]), y=array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,... 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1]), groups=None, scoring=None, cv=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1, verbose=0, fit_params=None, pre_dispatch='2*n_jobs', return_train_score=False, return_estimator=False, error_score='raise-deprecating')
    235         delayed(_fit_and_score)(
    236             clone(estimator), X, y, scorers, train, test, verbose, None,
    237             fit_params, return_train_score=return_train_score,
    238             return_times=True, return_estimator=return_estimator,
    239             error_score=error_score)
--> 240         for train, test in cv.split(X, y, groups))
        cv.split = <bound method StratifiedKFold.split of Stratifie...d(n_splits=10, random_state=None, shuffle=False)>
        X = array([[1.799e+01, 1.038e+01, 1.228e+02, ..., 2...., ..., 0.000e+00, 2.871e-01,
        7.039e-02]])
        y = array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,... 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1])
        groups = None
    241 
    242     zipped_scores = list(zip(*scores))
    243     if return_train_score:
    244         train_scores = zipped_scores.pop(0)

...........................................................................
/home/aquemy/.local/lib/python2.7/site-packages/sklearn/externals/joblib/parallel.py in __call__(self=Parallel(n_jobs=-1), iterable=<generator object <genexpr>>)
    925                 # No need to wait for async callbacks to trigger to
    926                 # consumption.
    927                 self._iterating = False
    928 
    929             with self._backend.retrieval_context():
--> 930                 self.retrieve()
        self.retrieve = <bound method Parallel.retrieve of Parallel(n_jobs=-1)>
    931             # Make sure that we get a last message telling us we are done
    932             elapsed_time = time.time() - self._start_time
    933             self._print('Done %3i out of %3i | elapsed: %s finished',
    934                         (len(self._output), len(self._output),

---------------------------------------------------------------------------
Joblib worker traceback:
---------------------------------------------------------------------------
ValueError                                         Mon Jun 17 13:33:10 2019
PID: 26119                                  Python 2.7.15+: /usr/bin/python
...........................................................................
/home/aquemy/.local/lib/python2.7/site-packages/sklearn/externals/joblib/parallel.py in __call__(self=<sklearn.externals.joblib.parallel.BatchedCalls object>)
    220     def __call__(self):
    221         # Set the default nested backend to self._backend but do not set the
    222         # change the default number of processes to -1
    223         with parallel_backend(self._backend, n_jobs=self._n_jobs):
    224             return [func(*args, **kwargs)
--> 225                     for func, args, kwargs in self.items]
        func = <function _fit_and_score>
        args = (Pipeline(memory=None,
     steps=[('rebalance', ... random_state=42, verbose=0, warm_start=False))]), array([[1.799e+01, 1.038e+01, 1.228e+02, ..., 2...., ..., 0.000e+00, 2.871e-01,
        7.039e-02]]), array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,... 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1]), {'score': <function _passthrough_scorer>}, array([ 25,  26,  27,  28,  29,  30,  31,  32,  ..., 561, 562, 563, 564,
       565, 566, 567, 568]), array([  0,   1,   2,   3,   4,   5,   6,   7,  ...,  89,  90,
        92,  93,  96,  97,  98, 101]), 0, None, None)
        kwargs = {'error_score': 'raise-deprecating', 'return_estimator': False, 'return_times': True, 'return_train_score': False}
        self.items = [(<function _fit_and_score>, (Pipeline(memory=None,
     steps=[('rebalance', ... random_state=42, verbose=0, warm_start=False))]), array([[1.799e+01, 1.038e+01, 1.228e+02, ..., 2...., ..., 0.000e+00, 2.871e-01,
        7.039e-02]]), array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,... 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1]), {'score': <function _passthrough_scorer>}, array([ 25,  26,  27,  28,  29,  30,  31,  32,  ..., 561, 562, 563, 564,
       565, 566, 567, 568]), array([  0,   1,   2,   3,   4,   5,   6,   7,  ...,  89,  90,
        92,  93,  96,  97,  98, 101]), 0, None, None), {'error_score': 'raise-deprecating', 'return_estimator': False, 'return_times': True, 'return_train_score': False})]
    226 
    227     def __len__(self):
    228         return self._size
    229 

...........................................................................
/home/aquemy/.local/lib/python2.7/site-packages/sklearn/model_selection/_validation.py in _fit_and_score(estimator=Pipeline(memory=None,
     steps=[('rebalance', ... random_state=42, verbose=0, warm_start=False))]), X=array([[1.799e+01, 1.038e+01, 1.228e+02, ..., 2...., ..., 0.000e+00, 2.871e-01,
        7.039e-02]]), y=array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,... 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1]), scorer={'score': <function _passthrough_scorer>}, train=array([ 25,  26,  27,  28,  29,  30,  31,  32,  ..., 561, 562, 563, 564,
       565, 566, 567, 568]), test=array([  0,   1,   2,   3,   4,   5,   6,   7,  ...,  89,  90,
        92,  93,  96,  97,  98, 101]), verbose=0, parameters=None, fit_params={}, return_train_score=False, return_parameters=False, return_n_test_samples=False, return_times=True, return_estimator=False, error_score='raise-deprecating')
    523 
    524     try:
    525         if y_train is None:
    526             estimator.fit(X_train, **fit_params)
    527         else:
--> 528             estimator.fit(X_train, y_train, **fit_params)
        estimator.fit = <bound method Pipeline.fit of Pipeline(memory=No...random_state=42, verbose=0, warm_start=False))])>
        X_train = array([[1.714e+01, 1.640e+01, 1.160e+02, ..., 2...., ..., 0.000e+00, 2.871e-01,
        7.039e-02]])
        y_train = array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...1, 1, 1, 1, 1, 1, 1, 0, 0,
       0, 0, 0, 0, 1])
        fit_params = {}
    529 
    530     except Exception as e:
    531         # Note fit time as time until error
    532         fit_time = time.time() - start_time

...........................................................................
/usr/local/lib/python2.7/dist-packages/imblearn/pipeline.py in fit(self=Pipeline(memory=None,
     steps=[('rebalance', ... random_state=42, verbose=0, warm_start=False))]), X=array([[1.714e+01, 1.640e+01, 1.160e+02, ..., 2...., ..., 0.000e+00, 2.871e-01,
        7.039e-02]]), y=array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...1, 1, 1, 1, 1, 1, 1, 0, 0,
       0, 0, 0, 0, 1]), **fit_params={})
    234             This estimator
    235 
    236         """
    237         Xt, yt, fit_params = self._fit(X, y, **fit_params)
    238         if self._final_estimator is not None:
--> 239             self._final_estimator.fit(Xt, yt, **fit_params)
        self._final_estimator.fit = <bound method RandomForestClassifier.fit of Rand...   random_state=42, verbose=0, warm_start=False)>
        Xt = array([[ 487.66284525,  -83.70203307],
       [-...97679  ],
       [ 598.74780188,  175.64694042]])
        yt = array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
       0, 0, 0, 0])
        fit_params = {}
    240         return self
    241 
    242     def fit_transform(self, X, y=None, **fit_params):
    243         """Fit the model and transform with the final estimator

...........................................................................
/home/aquemy/.local/lib/python2.7/site-packages/sklearn/ensemble/forest.py in fit(self=RandomForestClassifier(bootstrap=False, class_we...    random_state=42, verbose=0, warm_start=False), X=array([[ 487.66284 ,  -83.702034],
       [-138....      [ 598.7478  ,  175.64694 ]], dtype=float32), y=array([[0.],
       [0.],
       [0.],
       [0...    [0.],
       [0.],
       [0.],
       [0.]]), sample_weight=None)
    328             trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,
    329                              **_joblib_parallel_args(prefer='threads'))(
    330                 delayed(_parallel_build_trees)(
    331                     t, self, X, y, sample_weight, i, len(trees),
    332                     verbose=self.verbose, class_weight=self.class_weight)
--> 333                 for i, t in enumerate(trees))
        i = 99
    334 
    335             # Collect newly grown trees
    336             self.estimators_.extend(trees)
    337 

...........................................................................
/home/aquemy/.local/lib/python2.7/site-packages/sklearn/externals/joblib/parallel.py in __call__(self=Parallel(n_jobs=1), iterable=<generator object <genexpr>>)
    912             # self._original_iterator is None, then this means either
    913             # that pre_dispatch == "all", n_jobs == 1 or that the first batch
    914             # was very quick and its callback already dispatched all the
    915             # remaining jobs.
    916             self._iterating = False
--> 917             if self.dispatch_one_batch(iterator):
        self.dispatch_one_batch = <bound method Parallel.dispatch_one_batch of Parallel(n_jobs=1)>
        iterator = <generator object <genexpr>>
    918                 self._iterating = self._original_iterator is not None
    919 
    920             while self.dispatch_one_batch(iterator):
    921                 pass

...........................................................................
/home/aquemy/.local/lib/python2.7/site-packages/sklearn/externals/joblib/parallel.py in dispatch_one_batch(self=Parallel(n_jobs=1), iterator=<generator object <genexpr>>)
    754                                  self._pickle_cache)
    755             if len(tasks) == 0:
    756                 # No more tasks available in the iterator: tell caller to stop.
    757                 return False
    758             else:
--> 759                 self._dispatch(tasks)
        self._dispatch = <bound method Parallel._dispatch of Parallel(n_jobs=1)>
        tasks = <sklearn.externals.joblib.parallel.BatchedCalls object>
    760                 return True
    761 
    762     def _print(self, msg, msg_args):
    763         """Display the message on stout or stderr depending on verbosity"""

...........................................................................
/home/aquemy/.local/lib/python2.7/site-packages/sklearn/externals/joblib/parallel.py in _dispatch(self=Parallel(n_jobs=1), batch=<sklearn.externals.joblib.parallel.BatchedCalls object>)
    711 
    712         dispatch_timestamp = time.time()
    713         cb = BatchCompletionCallBack(dispatch_timestamp, len(batch), self)
    714         with self._lock:
    715             job_idx = len(self._jobs)
--> 716             job = self._backend.apply_async(batch, callback=cb)
        job = undefined
        self._backend.apply_async = <bound method SequentialBackend.apply_async of <...lib._parallel_backends.SequentialBackend object>>
        batch = <sklearn.externals.joblib.parallel.BatchedCalls object>
        cb = <sklearn.externals.joblib.parallel.BatchCompletionCallBack object>
    717             # A job can complete so quickly than its callback is
    718             # called before we get here, causing self._jobs to
    719             # grow. To ensure correct results ordering, .insert is
    720             # used (rather than .append) in the following line

...........................................................................
/home/aquemy/.local/lib/python2.7/site-packages/sklearn/externals/joblib/_parallel_backends.py in apply_async(self=<sklearn.externals.joblib._parallel_backends.SequentialBackend object>, func=<sklearn.externals.joblib.parallel.BatchedCalls object>, callback=<sklearn.externals.joblib.parallel.BatchCompletionCallBack object>)
    177             raise ValueError('n_jobs == 0 in Parallel has no meaning')
    178         return 1
    179 
    180     def apply_async(self, func, callback=None):
    181         """Schedule a func to be run"""
--> 182         result = ImmediateResult(func)
        result = undefined
        func = <sklearn.externals.joblib.parallel.BatchedCalls object>
    183         if callback:
    184             callback(result)
    185         return result
    186 

...........................................................................
/home/aquemy/.local/lib/python2.7/site-packages/sklearn/externals/joblib/_parallel_backends.py in __init__(self=<sklearn.externals.joblib._parallel_backends.ImmediateResult object>, batch=<sklearn.externals.joblib.parallel.BatchedCalls object>)
    544 
    545 class ImmediateResult(object):
    546     def __init__(self, batch):
    547         # Don't delay the application, to avoid keeping the input
    548         # arguments in memory
--> 549         self.results = batch()
        self.results = undefined
        batch = <sklearn.externals.joblib.parallel.BatchedCalls object>
    550 
    551     def get(self):
    552         return self.results
    553 

...........................................................................
/home/aquemy/.local/lib/python2.7/site-packages/sklearn/externals/joblib/parallel.py in __call__(self=<sklearn.externals.joblib.parallel.BatchedCalls object>)
    220     def __call__(self):
    221         # Set the default nested backend to self._backend but do not set the
    222         # change the default number of processes to -1
    223         with parallel_backend(self._backend, n_jobs=self._n_jobs):
    224             return [func(*args, **kwargs)
--> 225                     for func, args, kwargs in self.items]
        func = <function _parallel_build_trees>
        args = (DecisionTreeClassifier(class_weight=None, criter...=False, random_state=1608637542, splitter='best'), RandomForestClassifier(bootstrap=False, class_we...    random_state=42, verbose=0, warm_start=False), array([[ 487.66284 ,  -83.702034],
       [-138....      [ 598.7478  ,  175.64694 ]], dtype=float32), array([[0.],
       [0.],
       [0.],
       [0...    [0.],
       [0.],
       [0.],
       [0.]]), None, 0, 100)
        kwargs = {'class_weight': None, 'verbose': 0}
        self.items = [(<function _parallel_build_trees>, (DecisionTreeClassifier(class_weight=None, criter...=False, random_state=1608637542, splitter='best'), RandomForestClassifier(bootstrap=False, class_we...    random_state=42, verbose=0, warm_start=False), array([[ 487.66284 ,  -83.702034],
       [-138....      [ 598.7478  ,  175.64694 ]], dtype=float32), array([[0.],
       [0.],
       [0.],
       [0...    [0.],
       [0.],
       [0.],
       [0.]]), None, 0, 100), {'class_weight': None, 'verbose': 0})]
    226 
    227     def __len__(self):
    228         return self._size
    229 

...........................................................................
/home/aquemy/.local/lib/python2.7/site-packages/sklearn/ensemble/forest.py in _parallel_build_trees(tree=DecisionTreeClassifier(class_weight=None, criter...=False, random_state=1608637542, splitter='best'), forest=RandomForestClassifier(bootstrap=False, class_we...    random_state=42, verbose=0, warm_start=False), X=array([[ 487.66284 ,  -83.702034],
       [-138....      [ 598.7478  ,  175.64694 ]], dtype=float32), y=array([[0.],
       [0.],
       [0.],
       [0...    [0.],
       [0.],
       [0.],
       [0.]]), sample_weight=None, tree_idx=0, n_trees=100, verbose=0, class_weight=None)
    116         elif class_weight == 'balanced_subsample':
    117             curr_sample_weight *= compute_sample_weight('balanced', y, indices)
    118 
    119         tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)
    120     else:
--> 121         tree.fit(X, y, sample_weight=sample_weight, check_input=False)
        tree.fit = <bound method DecisionTreeClassifier.fit of Deci...False, random_state=1608637542, splitter='best')>
        X = array([[ 487.66284 ,  -83.702034],
       [-138....      [ 598.7478  ,  175.64694 ]], dtype=float32)
        y = array([[0.],
       [0.],
       [0.],
       [0...    [0.],
       [0.],
       [0.],
       [0.]])
        sample_weight = None
    122 
    123     return tree
    124 
    125 

...........................................................................
/home/aquemy/.local/lib/python2.7/site-packages/sklearn/tree/tree.py in fit(self=DecisionTreeClassifier(class_weight=None, criter...=False, random_state=1608637542, splitter='best'), X=array([[ 487.66284 ,  -83.702034],
       [-138....      [ 598.7478  ,  175.64694 ]], dtype=float32), y=array([[0.],
       [0.],
       [0.],
       [0...    [0.],
       [0.],
       [0.],
       [0.]]), sample_weight=None, check_input=False, X_idx_sorted=None)
    796 
    797         super(DecisionTreeClassifier, self).fit(
    798             X, y,
    799             sample_weight=sample_weight,
    800             check_input=check_input,
--> 801             X_idx_sorted=X_idx_sorted)
        X_idx_sorted = None
    802         return self
    803 
    804     def predict_proba(self, X, check_input=True):
    805         """Predict class probabilities of the input samples X.

...........................................................................
/home/aquemy/.local/lib/python2.7/site-packages/sklearn/tree/tree.py in fit(self=DecisionTreeClassifier(class_weight=None, criter...=False, random_state=1608637542, splitter='best'), X=array([[ 487.66284 ,  -83.702034],
       [-138....      [ 598.7478  ,  175.64694 ]], dtype=float32), y=array([[0.],
       [0.],
       [0.],
       [0...    [0.],
       [0.],
       [0.],
       [0.]]), sample_weight=None, check_input=False, X_idx_sorted=None)
    237         if not 0 <= self.min_weight_fraction_leaf <= 0.5:
    238             raise ValueError("min_weight_fraction_leaf must in [0, 0.5]")
    239         if max_depth <= 0:
    240             raise ValueError("max_depth must be greater than zero. ")
    241         if not (0 < max_features <= self.n_features_):
--> 242             raise ValueError("max_features must be in (0, n_features]")
    243         if not isinstance(max_leaf_nodes, (numbers.Integral, np.integer)):
    244             raise ValueError("max_leaf_nodes must be integral number but was "
    245                              "%r" % max_leaf_nodes)
    246         if -1 < max_leaf_nodes < 2:

ValueError: max_features must be in (0, n_features]
___________________________________________________________________________
Best score: 0.95250086423 (0.0222529506572) [J] | Score: 0.0 (0.0) [J]
Best score: 0.95250086423 (0.0222529506572) [J] | Score: 0.922704390286 (0.0384634412332) [J]
Best score: 0.95250086423 (0.0222529506572) [J] | Score: 0.931691297209 (0.0246453244791) [J]
Best score: 0.95250086423 (0.0222529506572) [J] | Score: 0.93997277677 (0.0310083219298) [J]
Best score: 0.95250086423 (0.0222529506572) [J] | Score: 0.894754126696 (0.0306550099616) [J]
JoblibValueError
___________________________________________________________________________
...........................................................................
/home/aquemy/dev/dp_hyperparameters/extension/main.py in <module>()
     27 
     28     serializer.serialize_results(scenario, policy)
     29 
     30 if __name__ == "__main__":
     31     args = cli.parse_args()
---> 32     main(args)

...........................................................................
/home/aquemy/dev/dp_hyperparameters/extension/main.py in main(args=Namespace(customize=[(['control', 'seed'], '42')...='./scenarios/rf_breast_joint.yaml', verbosity=0))
     21         test_size=0.4, 
     22         random_state=scenario['control']['seed']
     23     )
     24 
     25     policy = policies.initiate(scenario['setup']['policy'], config)
---> 26     policy.run(X,y)
        policy.run = <bound method Joint.run of <experiment.policies.joint.Joint object>>
        X = array([[1.799e+01, 1.038e+01, 1.228e+02, ..., 2...., ..., 0.000e+00, 2.871e-01,
        7.039e-02]])
        y = array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,... 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1])
     27 
     28     serializer.serialize_results(scenario, policy)
     29 
     30 if __name__ == "__main__":

...........................................................................
/home/aquemy/dev/dp_hyperparameters/extension/experiment/policies/joint.py in run(self=<experiment.policies.joint.Joint object>, X=array([[1.799e+01, 1.038e+01, 1.228e+02, ..., 2...., ..., 0.000e+00, 2.871e-01,
        7.039e-02]]), y=array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,... 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1]))
     32             algo=tpe.suggest, 
     33             max_evals=None,
     34             max_time=self.config['time'],     
     35             trials=trials,
     36             show_progressbar=False,
---> 37             verbose=0
     38         )
     39 
     40         best_config = self.context['best_config']
     41         super(Joint, self).display_step_results(best_config)

...........................................................................
/home/aquemy/dev/dp_hyperparameters/extension/hyperopt/fmin.py in fmin(fn=<functools.partial object>, space={'algorithm': {'bootstrap': <hyperopt.pyll.base.Apply object>, 'criterion': <hyperopt.pyll.base.Apply object>, 'max_depth': <hyperopt.pyll.base.Apply object>, 'max_features': <hyperopt.pyll.base.Apply object>, 'max_leaf_nodes': <hyperopt.pyll.base.Apply object>, 'min_samples_split': <hyperopt.pyll.base.Apply object>, 'n_estimators': <hyperopt.pyll.base.Apply object>}, 'pipeline': {'features': <hyperopt.pyll.base.Apply object>, 'normalizer': <hyperopt.pyll.base.Apply object>, 'rebalance': <hyperopt.pyll.base.Apply object>}}, algo=<function suggest>, max_evals=9223372036854775807, max_time=300, trials=<hyperopt.base.Trials object>, rstate=<mtrand.RandomState object>, allow_trials_fmin=True, pass_expr_memo_ctrl=None, catch_eval_exceptions=False, verbose=0, return_argmin=True, points_to_evaluate=None, max_queue_len=1, show_progressbar=False)
    406             pass_expr_memo_ctrl=pass_expr_memo_ctrl,
    407             verbose=verbose,
    408             catch_eval_exceptions=catch_eval_exceptions,
    409             return_argmin=return_argmin,
    410             show_progressbar=show_progressbar,
--> 411             max_time=max_time
        max_time = 300
    412         )
    413 
    414     if trials is None:
    415         if points_to_evaluate is None:

...........................................................................
/home/aquemy/dev/dp_hyperparameters/extension/hyperopt/base.py in fmin(self=<hyperopt.base.Trials object>, fn=<functools.partial object>, space={'algorithm': {'bootstrap': <hyperopt.pyll.base.Apply object>, 'criterion': <hyperopt.pyll.base.Apply object>, 'max_depth': <hyperopt.pyll.base.Apply object>, 'max_features': <hyperopt.pyll.base.Apply object>, 'max_leaf_nodes': <hyperopt.pyll.base.Apply object>, 'min_samples_split': <hyperopt.pyll.base.Apply object>, 'n_estimators': <hyperopt.pyll.base.Apply object>}, 'pipeline': {'features': <hyperopt.pyll.base.Apply object>, 'normalizer': <hyperopt.pyll.base.Apply object>, 'rebalance': <hyperopt.pyll.base.Apply object>}}, algo=<function suggest>, max_evals=9223372036854775807, max_time=300, rstate=<mtrand.RandomState object>, verbose=0, pass_expr_memo_ctrl=None, catch_eval_exceptions=False, return_argmin=True, show_progressbar=False)
    636             verbose=verbose,
    637             allow_trials_fmin=False,  # -- prevent recursion
    638             pass_expr_memo_ctrl=pass_expr_memo_ctrl,
    639             catch_eval_exceptions=catch_eval_exceptions,
    640             return_argmin=return_argmin,
--> 641             show_progressbar=show_progressbar)
        show_progressbar = False
    642 
    643 
    644 def trials_from_docs(docs, validate=True, **kwargs):
    645     """Construct a Trials base class instance from a list of trials documents

...........................................................................
/home/aquemy/dev/dp_hyperparameters/extension/hyperopt/fmin.py in fmin(fn=<functools.partial object>, space={'algorithm': {'bootstrap': <hyperopt.pyll.base.Apply object>, 'criterion': <hyperopt.pyll.base.Apply object>, 'max_depth': <hyperopt.pyll.base.Apply object>, 'max_features': <hyperopt.pyll.base.Apply object>, 'max_leaf_nodes': <hyperopt.pyll.base.Apply object>, 'min_samples_split': <hyperopt.pyll.base.Apply object>, 'n_estimators': <hyperopt.pyll.base.Apply object>}, 'pipeline': {'features': <hyperopt.pyll.base.Apply object>, 'normalizer': <hyperopt.pyll.base.Apply object>, 'rebalance': <hyperopt.pyll.base.Apply object>}}, algo=<function suggest>, max_evals=9223372036854775807, max_time=300, trials=<hyperopt.base.Trials object>, rstate=<mtrand.RandomState object>, allow_trials_fmin=False, pass_expr_memo_ctrl=None, catch_eval_exceptions=False, verbose=0, return_argmin=True, points_to_evaluate=None, max_queue_len=1, show_progressbar=False)
    426                     verbose=verbose,
    427                     max_queue_len=max_queue_len,
    428                     show_progressbar=show_progressbar,
    429                     max_time=max_time)
    430     rval.catch_eval_exceptions = catch_eval_exceptions
--> 431     rval.exhaust()
        rval.exhaust = <bound method FMinIter.exhaust of <hyperopt.fmin.FMinIter object>>
    432     if return_argmin:
    433         return trials.argmin
    434     elif len(trials) > 0:
    435         # Only if there are some succesfull trail runs, return the best point in the evaluation space

...........................................................................
/home/aquemy/dev/dp_hyperparameters/extension/hyperopt/fmin.py in exhaust(self=<hyperopt.fmin.FMinIter object>)
    273             raise StopIteration()
    274         return self.trials
    275 
    276     def exhaust(self):
    277         n_done = len(self.trials)
--> 278         self.run(self.max_evals - n_done, block_until_done=self.asynchronous)
        self.run = <bound method FMinIter.run of <hyperopt.fmin.FMinIter object>>
        self.max_evals = 9223372036854775807
        n_done = 0
        self.asynchronous = False
    279         self.trials.refresh()
    280         return self
    281 
    282 

...........................................................................
/home/aquemy/dev/dp_hyperparameters/extension/hyperopt/fmin.py in run(self=<hyperopt.fmin.FMinIter object>, N=9223372036854775807, block_until_done=False)
    232                     if self.asynchronous:
    233                         # -- wait for workers to fill in the trials
    234                         time.sleep(self.poll_interval_secs)
    235                     else:
    236                         # -- loop over trials and do the jobs directly
--> 237                         self.serial_evaluate()
        self.serial_evaluate = <bound method FMinIter.serial_evaluate of <hyperopt.fmin.FMinIter object>>
    238                     try:
    239                         res = [d['result']['loss'] for d in
    240                                          self.trials.trials if
    241                                          d['result']['status'] == 'ok']

...........................................................................
/home/aquemy/dev/dp_hyperparameters/extension/hyperopt/fmin.py in serial_evaluate(self=<hyperopt.fmin.FMinIter object>, N=-1)
    138                 trial['book_time'] = now
    139                 trial['refresh_time'] = now
    140                 spec = base.spec_from_misc(trial['misc'])
    141                 ctrl = base.Ctrl(self.trials, current_trial=trial)
    142                 try:
--> 143                     result = self.domain.evaluate(spec, ctrl)
        result = undefined
        self.domain.evaluate = <bound method Domain.evaluate of <hyperopt.base.Domain object>>
        spec = {'bootstrap': 1, 'criterion': 1, 'features': 1, 'features_PCA_features__n_components': 0, 'max_depth': 4, 'max_features': 2, 'max_leaf_nodes': 0, 'min_samples_split': 2, 'n_estimators': 0, 'normalizer': 2, ...}
        ctrl = <hyperopt.base.Ctrl object>
    144                 except Exception as e:
    145                     logger.info('job exception: %s' % str(e))
    146                     trial['state'] = base.JOB_STATE_ERROR
    147                     trial['misc']['error'] = (str(type(e)), str(e))

...........................................................................
/home/aquemy/dev/dp_hyperparameters/extension/hyperopt/base.py in evaluate(self=<hyperopt.base.Domain object>, config={'bootstrap': 1, 'criterion': 1, 'features': 1, 'features_PCA_features__n_components': 0, 'max_depth': 4, 'max_features': 2, 'max_leaf_nodes': 0, 'min_samples_split': 2, 'n_estimators': 0, 'normalizer': 2, ...}, ctrl=<hyperopt.base.Ctrl object>, attach_attachments=True)
    841             #    or the normal Python part (self.fn)
    842             pyll_rval = pyll.rec_eval(
    843                 self.expr,
    844                 memo=memo,
    845                 print_node_on_error=self.rec_eval_print_node_on_error)
--> 846             rval = self.fn(pyll_rval)
        rval = undefined
        self.fn = <functools.partial object>
        pyll_rval = {'algorithm': {'bootstrap': False, 'criterion': 'entropy', 'max_depth': None, 'max_features': 3, 'max_leaf_nodes': 2, 'min_samples_split': 5, 'n_estimators': 10}, 'pipeline': {'features': ('features_PCA', {'features__n_components': 1}), 'normalizer': ('normalizer_PowerTransformer', {}), 'rebalance': ('rebalance_CondensedNearestNeighbour', {'rebalance__n_neighbors': 2})}}
    847 
    848         if isinstance(rval, (float, int, np.number)):
    849             dict_rval = {'loss': float(rval), 'status': STATUS_OK}
    850         else:

...........................................................................
/home/aquemy/dev/dp_hyperparameters/extension/experiment/objective.py in objective_joint(wconfig={'algorithm': {'bootstrap': False, 'criterion': 'entropy', 'max_depth': None, 'max_features': 3, 'max_leaf_nodes': 2, 'min_samples_split': 5, 'n_estimators': 10}, 'pipeline': {'features': ('features_PCA', {'features__n_components': 1}), 'normalizer': ('normalizer_PowerTransformer', {}), 'rebalance': ('rebalance_CondensedNearestNeighbour', {'rebalance__n_neighbors': 2})}}, algorithm='RandomForest', X=array([[1.799e+01, 1.038e+01, 1.228e+02, ..., 2...., ..., 0.000e+00, 2.871e-01,
        7.039e-02]]), y=array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,... 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1]), context={'baseline_score': 0.9545944602886527, 'baseline_score_std': 0.03716322883281839, 'best_config': {'algorithm': {'bootstrap': False, 'criterion': 'entropy', 'max_depth': None, 'max_features': 2, 'max_leaf_nodes': None, 'min_samples_split': 5, 'n_estimators': 10}, 'config_hash': {'algorithm': 'e7a772c2bc361aa61cf7eeb364a26dca2c9b89d6', 'config': 'afb67da069b544b0505b1e8c150edc7498ad37b4', 'pipeline': 'a43db4b4fc4c38610b7b5e484840d2e583089ff4'}, 'duration': 1.0073001384735107, 'iteration': 26, 'loss': 0.04749913577046061, 'max_history_score': 0.9525008642295394, 'max_history_score_std': 0.02225295065716913, 'max_history_step': 'joint', 'pipeline': {'features': ('features_PCA', {'features__n_components': 4}), 'normalizer': ('normalizer_StandardScaler', {'normalizer__with_mean': True, 'normalizer__with_std': False}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 7})}, 'score': 0.9525008642295394, ...}, 'history': [{'algorithm': {'bootstrap': True, 'criterion': 'entropy', 'max_depth': 4, 'max_features': 3, 'max_leaf_nodes': 3, 'min_samples_split': 2, 'n_estimators': 10}, 'config_hash': {'algorithm': '42527c4120073c2a488d1b8df28732f486d1578c', 'config': '51144ca42f9ea5ab2d8d58606e3b3e4d89c6d7b3', 'pipeline': '52f07bda29f9d3a95fabb87e591d0b2581ca8209'}, 'duration': 0.26703310012817383, 'iteration': 0, 'loss': 0.06655431682654922, 'max_history_score': 0.9334456831734508, 'max_history_score_std': 0.03819399139659311, 'max_history_step': 'joint', 'pipeline': {'features': ('features_NoneType', {}), 'normalizer': ('normalizer_RobustScaler', {'normalizer__quantile_range': (...), 'normalizer__with_centering': False, 'normalizer__with_scaling': False}), 'rebalance': ('rebalance_NearMiss', {'rebalance__n_neighbors': 1})}, 'score': 0.9334456831734508, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': None, 'max_features': 2, 'max_leaf_nodes': 3, 'min_samples_split': 2, 'n_estimators': 100}, 'config_hash': {'algorithm': '1b32258c630f07e01ab481ab925ab80aa757e482', 'config': '9e54ffcb6a727de032a0a2cd45c5cc37cc150756', 'pipeline': '37e72d4a97f5e784c9d3133e6379b91bfc3be803'}, 'duration': 1.3065669536590576, 'iteration': 1, 'loss': 0.05436435917379645, 'max_history_score': 0.9456356408262035, 'max_history_score_std': 0.040053650785990214, 'max_history_step': 'joint', 'pipeline': {'features': ('features_NoneType', {}), 'normalizer': ('normalizer_StandardScaler', {'normalizer__with_mean': True, 'normalizer__with_std': True}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 6})}, 'score': 0.9456356408262035, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'entropy', 'max_depth': 1, 'max_features': 1, 'max_leaf_nodes': 2, 'min_samples_split': 3, 'n_estimators': 25}, 'config_hash': {'algorithm': '68ab9059aa7ec74e0da87c81734b9664243b3eb4', 'config': 'e5241eee9ddf3f4ee29a4711f5bcc92a4d24cd09', 'pipeline': '62463de065924498cdcd2f2f1f7e68535cdb33a5'}, 'duration': 0.6592490673065186, 'iteration': 2, 'loss': 0.07695856019358727, 'max_history_score': 0.9456356408262035, 'max_history_score_std': 0.040053650785990214, 'max_history_step': 'joint', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 1, 'features__selectkbest__k': 2}), 'normalizer': ('normalizer_NoneType', {}), 'rebalance': ('rebalance_NoneType', {})}, 'score': 0.9230414398064127, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': 3, 'max_features': 2, 'max_leaf_nodes': 2, 'min_samples_split': 2, 'n_estimators': 25}, 'config_hash': {'algorithm': 'e3f1f7d7783557a38f40f0476369091edd87092b', 'config': '18ee4d3d1627472ec190326308d8755371a6dc62', 'pipeline': 'c6d1263e344ed8c71b2e6e4ba8e0db2fb6c777c0'}, 'duration': 0.879349946975708, 'iteration': 3, 'loss': 0.07535973554576114, 'max_history_score': 0.9456356408262035, 'max_history_score_std': 0.040053650785990214, 'max_history_step': 'joint', 'pipeline': {'features': ('features_NoneType', {}), 'normalizer': ('normalizer_RobustScaler', {'normalizer__quantile_range': (...), 'normalizer__with_centering': True, 'normalizer__with_scaling': True}), 'rebalance': ('rebalance_NearMiss', {'rebalance__n_neighbors': 2})}, 'score': 0.9246402644542389, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'gini', 'max_depth': 4, 'max_features': 2, 'max_leaf_nodes': 5, 'min_samples_split': 2, 'n_estimators': 50}, 'config_hash': {'algorithm': '47581af7253940f9647ad16d37347d34baf13e5f', 'config': '2af4f82b045c0c48ecb89d42728d1039fbff8878', 'pipeline': '2928b22ed834303cb7bac6e6608531eaddd7df67'}, 'duration': 4.372632026672363, 'iteration': 4, 'loss': 0.09121294615849984, 'max_history_score': 0.9456356408262035, 'max_history_score_std': 0.040053650785990214, 'max_history_step': 'joint', 'pipeline': {'features': ('features_NoneType', {}), 'normalizer': ('normalizer_MinMaxScaler', {}), 'rebalance': ('rebalance_CondensedNearestNeighbour', {'rebalance__n_neighbors': 2})}, 'score': 0.9087870538415002, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'entropy', 'max_depth': 2, 'max_features': 2, 'max_leaf_nodes': None, 'min_samples_split': 2, 'n_estimators': 10}, 'config_hash': {'algorithm': '0a85f98ca2d06103287f153633d88f7a0535e7e8', 'config': '17b2a1e5814f3e933137158708a5b6e9b2475495', 'pipeline': '95defa3bdd8357f11f872d3c280d50a6d8ee398d'}, 'duration': 2.625814914703369, 'iteration': 5, 'loss': 0.15471329185031535, 'max_history_score': 0.9456356408262035, 'max_history_score_std': 0.040053650785990214, 'max_history_step': 'joint', 'pipeline': {'features': ('features_SelectKBest', {'features__k': 2}), 'normalizer': ('normalizer_StandardScaler', {'normalizer__with_mean': False, 'normalizer__with_std': False}), 'rebalance': ('rebalance_CondensedNearestNeighbour', {'rebalance__n_neighbors': 1})}, 'score': 0.8452867081496847, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': 3, 'max_features': None, 'max_leaf_nodes': None, 'min_samples_split': 5, 'n_estimators': 75}, 'config_hash': {'algorithm': 'd7466a2c1d5cb3fa95029d73dc030f4c3c45a159', 'config': 'fa020a592ec5ac234f9f91aac28abc2cd1ec9d33', 'pipeline': '71e0d26f923d42cfe0e2fa748931ef2afe72ed86'}, 'duration': 3.62078595161438, 'iteration': 6, 'loss': 0.17066372828623277, 'max_history_score': 0.9456356408262035, 'max_history_score_std': 0.040053650785990214, 'max_history_step': 'joint', 'pipeline': {'features': ('features_SelectKBest', {'features__k': 1}), 'normalizer': ('normalizer_RobustScaler', {'normalizer__quantile_range': (...), 'normalizer__with_centering': True, 'normalizer__with_scaling': True}), 'rebalance': ('rebalance_CondensedNearestNeighbour', {'rebalance__n_neighbors': 1})}, 'score': 0.8293362717137672, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'entropy', 'max_depth': 3, 'max_features': 3, 'max_leaf_nodes': 5, 'min_samples_split': 5, 'n_estimators': 50}, 'config_hash': {'algorithm': '735caa9785596076014572a24050cde8dc338973', 'config': '0da4498002d6f452c59bb61756abb3ded841e786', 'pipeline': '51a53ea6ef5a2521ee65f76eb2da220ab7086513'}, 'duration': 0.6934049129486084, 'iteration': 7, 'loss': 0.06125875032408601, 'max_history_score': 0.9456356408262035, 'max_history_score_std': 0.040053650785990214, 'max_history_step': 'joint', 'pipeline': {'features': ('features_NoneType', {}), 'normalizer': ('normalizer_NoneType', {}), 'rebalance': ('rebalance_NearMiss', {'rebalance__n_neighbors': 3})}, 'score': 0.938741249675914, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': 4, 'max_features': 2, 'max_leaf_nodes': None, 'min_samples_split': 3, 'n_estimators': 75}, 'config_hash': {'algorithm': 'e71a1fe9515b6805f07914a61f2e7594be9e9afe', 'config': '344e4756fb1bec455d6af51d3727e33b0d27725f', 'pipeline': '248dad1d8b30a17a5de1d0bbdfe3e2acb7a1962b'}, 'duration': 1.3036692142486572, 'iteration': 8, 'loss': 0.06483125918243893, 'max_history_score': 0.9456356408262035, 'max_history_score_std': 0.040053650785990214, 'max_history_step': 'joint', 'pipeline': {'features': ('features_PCA', {'features__n_components': 2}), 'normalizer': ('normalizer_StandardScaler', {'normalizer__with_mean': False, 'normalizer__with_std': True}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 7})}, 'score': 0.9351687408175611, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'entropy', 'max_depth': 2, 'max_features': 2, 'max_leaf_nodes': 2, 'min_samples_split': 3, 'n_estimators': 10}, 'config_hash': {'algorithm': '0a507823f2ad8605ed5950e1fe61df0560f11a00', 'config': '4a538fdcf8e07f90e92a421c0d5c479d651629c7', 'pipeline': '5240329df25c9a533d025c1a401d49835a501b41'}, 'duration': 1.3821029663085938, 'iteration': 9, 'loss': 0.07006416904329793, 'max_history_score': 0.9456356408262035, 'max_history_score_std': 0.040053650785990214, 'max_history_step': 'joint', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 4, 'features__selectkbest__k': 2}), 'normalizer': ('normalizer_PowerTransformer', {}), 'rebalance': ('rebalance_NearMiss', {'rebalance__n_neighbors': 1})}, 'score': 0.9299358309567021, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'gini', 'max_depth': 1, 'max_features': 3, 'max_leaf_nodes': 5, 'min_samples_split': 3, 'n_estimators': 10}, 'config_hash': {'algorithm': 'd32739750d351948f8ff34a87c7d55b0c5e0d90f', 'config': 'c1609e71f1ce8486335adc70bb69a955580ba2c8', 'pipeline': 'f48b42ec5cf999279659966160a16353b75bdaa3'}, 'duration': 0.9055681228637695, 'iteration': 10, 'loss': 0.07532840722495904, 'max_history_score': 0.9456356408262035, 'max_history_score_std': 0.040053650785990214, 'max_history_step': 'joint', 'pipeline': {'features': ('features_PCA', {'features__n_components': 4}), 'normalizer': ('normalizer_PowerTransformer', {}), 'rebalance': ('rebalance_NearMiss', {'rebalance__n_neighbors': 1})}, 'score': 0.924671592775041, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': 3, 'max_features': 1, 'max_leaf_nodes': 5, 'min_samples_split': 3, 'n_estimators': 25}, 'config_hash': {'algorithm': 'f69bac35e71cbec1bfc1fb5942328a3390e7c252', 'config': 'abe36f188644e53e56ed3224236fa157107ed3b2', 'pipeline': 'aaf976c7c663a31fa039582d42f9e07101556a7c'}, 'duration': 0.764197826385498, 'iteration': 11, 'loss': 0.06818446979517778, 'max_history_score': 0.9456356408262035, 'max_history_score_std': 0.040053650785990214, 'max_history_step': 'joint', 'pipeline': {'features': ('features_NoneType', {}), 'normalizer': ('normalizer_PowerTransformer', {}), 'rebalance': ('rebalance_NoneType', {})}, 'score': 0.9318155302048222, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'entropy', 'max_depth': None, 'max_features': None, 'max_leaf_nodes': None, 'min_samples_split': 5, 'n_estimators': 25}, 'config_hash': {'algorithm': 'a0a27aec00db5ddf71eab96663f9bd61c845f5e3', 'config': '76aa002c3c9d4d9722466c60daf5119c18a41d2a', 'pipeline': '1ce34b7894ef342571d974bb19e8ec821a512c6b'}, 'duration': 1.1636500358581543, 'iteration': 12, 'loss': 0.12833700630887557, 'max_history_score': 0.9456356408262035, 'max_history_score_std': 0.040053650785990214, 'max_history_step': 'joint', 'pipeline': {'features': ('features_PCA', {'features__n_components': 1}), 'normalizer': ('normalizer_PowerTransformer', {}), 'rebalance': ('rebalance_NoneType', {})}, 'score': 0.8716629936911244, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'gini', 'max_depth': 1, 'max_features': 2, 'max_leaf_nodes': 2, 'min_samples_split': 2, 'n_estimators': 100}, 'config_hash': {'algorithm': '985c99dff1da9b2c87e4211c5335a9159aa9dbcb', 'config': 'f56a7a9e43a0a699e992dc1262e550b8b7c88538', 'pipeline': '5c934f6d9a8ad1f9afe762986a9cf2074fc95d79'}, 'duration': 2.235443115234375, 'iteration': 13, 'loss': 0.11414635727249167, 'max_history_score': 0.9456356408262035, 'max_history_score_std': 0.040053650785990214, 'max_history_step': 'joint', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 1, 'features__selectkbest__k': 1}), 'normalizer': ('normalizer_RobustScaler', {'normalizer__quantile_range': (...), 'normalizer__with_centering': False, 'normalizer__with_scaling': True}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 6})}, 'score': 0.8858536427275083, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'gini', 'max_depth': 1, 'max_features': 1, 'max_leaf_nodes': None, 'min_samples_split': 5, 'n_estimators': 10}, 'config_hash': {'algorithm': '7d74a39aac2579264a402aef2b6fa7943c19f3d3', 'config': '53f44c0ad925c5c08c25d4fadf5e9ee9d7c181cd', 'pipeline': '6eff5ef31d7d1d534db31913bb67529c8a24c42e'}, 'duration': 2.7847659587860107, 'iteration': 14, 'loss': 0.14061986863711007, 'max_history_score': 0.9456356408262035, 'max_history_score_std': 0.040053650785990214, 'max_history_step': 'joint', 'pipeline': {'features': ('features_PCA', {'features__n_components': 1}), 'normalizer': ('normalizer_RobustScaler', {'normalizer__quantile_range': (...), 'normalizer__with_centering': True, 'normalizer__with_scaling': True}), 'rebalance': ('rebalance_CondensedNearestNeighbour', {'rebalance__n_neighbors': 3})}, 'score': 0.8593801313628899, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'entropy', 'max_depth': 3, 'max_features': None, 'max_leaf_nodes': 5, 'min_samples_split': 2, 'n_estimators': 100}, 'config_hash': {'algorithm': 'c62d7c671832e4414b6b2d7c36cba5ddc83a0ed0', 'config': '5faee50671eaa0ac586722bff234e36a857e662d', 'pipeline': '8b29a55de2add78c49114b9bbe5e800e5524c59d'}, 'duration': 2.3916029930114746, 'iteration': 15, 'loss': 0.08770093336790252, 'max_history_score': 0.9456356408262035, 'max_history_score_std': 0.040053650785990214, 'max_history_step': 'joint', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 3, 'features__selectkbest__k': 4}), 'normalizer': ('normalizer_RobustScaler', {'normalizer__quantile_range': (...), 'normalizer__with_centering': True, 'normalizer__with_scaling': True}), 'rebalance': ('rebalance_NoneType', {})}, 'score': 0.9122990666320975, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': None, 'max_features': 1, 'max_leaf_nodes': 5, 'min_samples_split': 5, 'n_estimators': 10}, 'config_hash': {'algorithm': '290772bfb9b8ed15c48a72829e822fb0a07481d6', 'config': '9a04f25d8eb3db5b2f831abd341a6d384c73a957', 'pipeline': '1ce34b7894ef342571d974bb19e8ec821a512c6b'}, 'duration': 1.4364500045776367, 'iteration': 16, 'loss': 0.08948880822746508, 'max_history_score': 0.9456356408262035, 'max_history_score_std': 0.040053650785990214, 'max_history_step': 'joint', 'pipeline': {'features': ('features_PCA', {'features__n_components': 1}), 'normalizer': ('normalizer_PowerTransformer', {}), 'rebalance': ('rebalance_NoneType', {})}, 'score': 0.9105111917725349, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': 2, 'max_features': 3, 'max_leaf_nodes': 3, 'min_samples_split': 3, 'n_estimators': 100}, 'config_hash': {'algorithm': '7dab6d47f897c2961d3402eff844aff16a7d142a', 'config': '4dbfa2688b239be9f372d3e80223960ba9a1fbdd', 'pipeline': 'cdef51702798fa49f11c11d80baf3ab43d5358fc'}, 'duration': 0.9830451011657715, 'iteration': 17, 'loss': 1.0, 'max_history_score': 0.9456356408262035, 'max_history_score_std': 0.040053650785990214, 'max_history_step': 'joint', 'pipeline': {'features': ('features_SelectKBest', {'features__k': 2}), 'normalizer': ('normalizer_PowerTransformer', {}), 'rebalance': ('rebalance_NearMiss', {'rebalance__n_neighbors': 1})}, 'score': 0.0, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'entropy', 'max_depth': None, 'max_features': 3, 'max_leaf_nodes': None, 'min_samples_split': 5, 'n_estimators': 10}, 'config_hash': {'algorithm': 'def83e48be05ef92a37e1a90585820f2f67ff42b', 'config': '95902552cb76e9798f0fa58782bd72bd1cc272d7', 'pipeline': '1775187bf23f94f4fd0cc1e5c1ef665210edded5'}, 'duration': 2.0033559799194336, 'iteration': 18, 'loss': 0.04922327370149515, 'max_history_score': 0.9507767262985048, 'max_history_score_std': 0.028328108925705902, 'max_history_step': 'joint', 'pipeline': {'features': ('features_PCA', {'features__n_components': 4}), 'normalizer': ('normalizer_StandardScaler', {'normalizer__with_mean': True, 'normalizer__with_std': True}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 5})}, 'score': 0.9507767262985048, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'gini', 'max_depth': 1, 'max_features': 3, 'max_leaf_nodes': None, 'min_samples_split': 2, 'n_estimators': 50}, 'config_hash': {'algorithm': '4e9e3275f817df75115d9d7e3366980fc1b4cf13', 'config': '7770b19007b40bf13005d52eb81f87bc401f15b4', 'pipeline': 'c4dd111513ea35f97dd3aec3e8e7f6268ce035da'}, 'duration': 0.9069631099700928, 'iteration': 19, 'loss': 1.0, 'max_history_score': 0.9507767262985048, 'max_history_score_std': 0.028328108925705902, 'max_history_step': 'joint', 'pipeline': {'features': ('features_PCA', {'features__n_components': 2}), 'normalizer': ('normalizer_RobustScaler', {'normalizer__quantile_range': (...), 'normalizer__with_centering': False, 'normalizer__with_scaling': True}), 'rebalance': ('rebalance_NearMiss', {'rebalance__n_neighbors': 2})}, 'score': 0.0, ...}, ...], 'history_hash': ['51144ca42f9ea5ab2d8d58606e3b3e4d89c6d7b3', '9e54ffcb6a727de032a0a2cd45c5cc37cc150756', 'e5241eee9ddf3f4ee29a4711f5bcc92a4d24cd09', '18ee4d3d1627472ec190326308d8755371a6dc62', '2af4f82b045c0c48ecb89d42728d1039fbff8878', '17b2a1e5814f3e933137158708a5b6e9b2475495', 'fa020a592ec5ac234f9f91aac28abc2cd1ec9d33', '0da4498002d6f452c59bb61756abb3ded841e786', '344e4756fb1bec455d6af51d3727e33b0d27725f', '4a538fdcf8e07f90e92a421c0d5c479d651629c7', 'c1609e71f1ce8486335adc70bb69a955580ba2c8', 'abe36f188644e53e56ed3224236fa157107ed3b2', '76aa002c3c9d4d9722466c60daf5119c18a41d2a', 'f56a7a9e43a0a699e992dc1262e550b8b7c88538', '53f44c0ad925c5c08c25d4fadf5e9ee9d7c181cd', '5faee50671eaa0ac586722bff234e36a857e662d', '9a04f25d8eb3db5b2f831abd341a6d384c73a957', '4dbfa2688b239be9f372d3e80223960ba9a1fbdd', '95902552cb76e9798f0fa58782bd72bd1cc272d7', '7770b19007b40bf13005d52eb81f87bc401f15b4', ...], 'history_index': {'0da4498002d6f452c59bb61756abb3ded841e786': 7, '0f77a69b0a8d34861caf915a51dc588ff8d4efac': 61, '127553d555ed39231b8da3a1ce42d3902e30919b': 59, '17b2a1e5814f3e933137158708a5b6e9b2475495': 5, '18ee4d3d1627472ec190326308d8755371a6dc62': 3, '1b2267555a9226d7eb4df3c63dd12506da370f4d': 56, '28b2db1bf9b505aa8e490d811b55f6655178ede7': 67, '2af4f82b045c0c48ecb89d42728d1039fbff8878': 4, '2d054540972225f4f17fb36d63106b7bb5c406fe': 36, '306511091d7e5d6431b5e5a6320802c4c04cde44': 33, ...}, 'iteration': 69, 'max_history_score': 0.9525008642295394, 'max_history_score_std': 0.02225295065716913, 'max_history_step': 'joint'}, config={'algorithm': 'RandomForest', 'seed': 42, 'time': 300})
    108 
    109 def objective_algo(algo_config, current_pipeline_config, algorithm, X, y, context, config):
    110     return objective(current_pipeline_config, algo_config, algorithm, X, y, context, config, step='algorithm')
    111 
    112 def objective_joint(wconfig, algorithm, X, y, context, config):
--> 113     return objective(wconfig['pipeline'], wconfig['algorithm'], algorithm, X, y, context, config, step='joint')
        wconfig = {'algorithm': {'bootstrap': False, 'criterion': 'entropy', 'max_depth': None, 'max_features': 3, 'max_leaf_nodes': 2, 'min_samples_split': 5, 'n_estimators': 10}, 'pipeline': {'features': ('features_PCA', {'features__n_components': 1}), 'normalizer': ('normalizer_PowerTransformer', {}), 'rebalance': ('rebalance_CondensedNearestNeighbour', {'rebalance__n_neighbors': 2})}}
        algorithm = 'RandomForest'
        X = array([[1.799e+01, 1.038e+01, 1.228e+02, ..., 2...., ..., 0.000e+00, 2.871e-01,
        7.039e-02]])
        y = array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,... 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1])
        context = {'baseline_score': 0.9545944602886527, 'baseline_score_std': 0.03716322883281839, 'best_config': {'algorithm': {'bootstrap': False, 'criterion': 'entropy', 'max_depth': None, 'max_features': 2, 'max_leaf_nodes': None, 'min_samples_split': 5, 'n_estimators': 10}, 'config_hash': {'algorithm': 'e7a772c2bc361aa61cf7eeb364a26dca2c9b89d6', 'config': 'afb67da069b544b0505b1e8c150edc7498ad37b4', 'pipeline': 'a43db4b4fc4c38610b7b5e484840d2e583089ff4'}, 'duration': 1.0073001384735107, 'iteration': 26, 'loss': 0.04749913577046061, 'max_history_score': 0.9525008642295394, 'max_history_score_std': 0.02225295065716913, 'max_history_step': 'joint', 'pipeline': {'features': ('features_PCA', {'features__n_components': 4}), 'normalizer': ('normalizer_StandardScaler', {'normalizer__with_mean': True, 'normalizer__with_std': False}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 7})}, 'score': 0.9525008642295394, ...}, 'history': [{'algorithm': {'bootstrap': True, 'criterion': 'entropy', 'max_depth': 4, 'max_features': 3, 'max_leaf_nodes': 3, 'min_samples_split': 2, 'n_estimators': 10}, 'config_hash': {'algorithm': '42527c4120073c2a488d1b8df28732f486d1578c', 'config': '51144ca42f9ea5ab2d8d58606e3b3e4d89c6d7b3', 'pipeline': '52f07bda29f9d3a95fabb87e591d0b2581ca8209'}, 'duration': 0.26703310012817383, 'iteration': 0, 'loss': 0.06655431682654922, 'max_history_score': 0.9334456831734508, 'max_history_score_std': 0.03819399139659311, 'max_history_step': 'joint', 'pipeline': {'features': ('features_NoneType', {}), 'normalizer': ('normalizer_RobustScaler', {'normalizer__quantile_range': (...), 'normalizer__with_centering': False, 'normalizer__with_scaling': False}), 'rebalance': ('rebalance_NearMiss', {'rebalance__n_neighbors': 1})}, 'score': 0.9334456831734508, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': None, 'max_features': 2, 'max_leaf_nodes': 3, 'min_samples_split': 2, 'n_estimators': 100}, 'config_hash': {'algorithm': '1b32258c630f07e01ab481ab925ab80aa757e482', 'config': '9e54ffcb6a727de032a0a2cd45c5cc37cc150756', 'pipeline': '37e72d4a97f5e784c9d3133e6379b91bfc3be803'}, 'duration': 1.3065669536590576, 'iteration': 1, 'loss': 0.05436435917379645, 'max_history_score': 0.9456356408262035, 'max_history_score_std': 0.040053650785990214, 'max_history_step': 'joint', 'pipeline': {'features': ('features_NoneType', {}), 'normalizer': ('normalizer_StandardScaler', {'normalizer__with_mean': True, 'normalizer__with_std': True}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 6})}, 'score': 0.9456356408262035, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'entropy', 'max_depth': 1, 'max_features': 1, 'max_leaf_nodes': 2, 'min_samples_split': 3, 'n_estimators': 25}, 'config_hash': {'algorithm': '68ab9059aa7ec74e0da87c81734b9664243b3eb4', 'config': 'e5241eee9ddf3f4ee29a4711f5bcc92a4d24cd09', 'pipeline': '62463de065924498cdcd2f2f1f7e68535cdb33a5'}, 'duration': 0.6592490673065186, 'iteration': 2, 'loss': 0.07695856019358727, 'max_history_score': 0.9456356408262035, 'max_history_score_std': 0.040053650785990214, 'max_history_step': 'joint', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 1, 'features__selectkbest__k': 2}), 'normalizer': ('normalizer_NoneType', {}), 'rebalance': ('rebalance_NoneType', {})}, 'score': 0.9230414398064127, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': 3, 'max_features': 2, 'max_leaf_nodes': 2, 'min_samples_split': 2, 'n_estimators': 25}, 'config_hash': {'algorithm': 'e3f1f7d7783557a38f40f0476369091edd87092b', 'config': '18ee4d3d1627472ec190326308d8755371a6dc62', 'pipeline': 'c6d1263e344ed8c71b2e6e4ba8e0db2fb6c777c0'}, 'duration': 0.879349946975708, 'iteration': 3, 'loss': 0.07535973554576114, 'max_history_score': 0.9456356408262035, 'max_history_score_std': 0.040053650785990214, 'max_history_step': 'joint', 'pipeline': {'features': ('features_NoneType', {}), 'normalizer': ('normalizer_RobustScaler', {'normalizer__quantile_range': (...), 'normalizer__with_centering': True, 'normalizer__with_scaling': True}), 'rebalance': ('rebalance_NearMiss', {'rebalance__n_neighbors': 2})}, 'score': 0.9246402644542389, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'gini', 'max_depth': 4, 'max_features': 2, 'max_leaf_nodes': 5, 'min_samples_split': 2, 'n_estimators': 50}, 'config_hash': {'algorithm': '47581af7253940f9647ad16d37347d34baf13e5f', 'config': '2af4f82b045c0c48ecb89d42728d1039fbff8878', 'pipeline': '2928b22ed834303cb7bac6e6608531eaddd7df67'}, 'duration': 4.372632026672363, 'iteration': 4, 'loss': 0.09121294615849984, 'max_history_score': 0.9456356408262035, 'max_history_score_std': 0.040053650785990214, 'max_history_step': 'joint', 'pipeline': {'features': ('features_NoneType', {}), 'normalizer': ('normalizer_MinMaxScaler', {}), 'rebalance': ('rebalance_CondensedNearestNeighbour', {'rebalance__n_neighbors': 2})}, 'score': 0.9087870538415002, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'entropy', 'max_depth': 2, 'max_features': 2, 'max_leaf_nodes': None, 'min_samples_split': 2, 'n_estimators': 10}, 'config_hash': {'algorithm': '0a85f98ca2d06103287f153633d88f7a0535e7e8', 'config': '17b2a1e5814f3e933137158708a5b6e9b2475495', 'pipeline': '95defa3bdd8357f11f872d3c280d50a6d8ee398d'}, 'duration': 2.625814914703369, 'iteration': 5, 'loss': 0.15471329185031535, 'max_history_score': 0.9456356408262035, 'max_history_score_std': 0.040053650785990214, 'max_history_step': 'joint', 'pipeline': {'features': ('features_SelectKBest', {'features__k': 2}), 'normalizer': ('normalizer_StandardScaler', {'normalizer__with_mean': False, 'normalizer__with_std': False}), 'rebalance': ('rebalance_CondensedNearestNeighbour', {'rebalance__n_neighbors': 1})}, 'score': 0.8452867081496847, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': 3, 'max_features': None, 'max_leaf_nodes': None, 'min_samples_split': 5, 'n_estimators': 75}, 'config_hash': {'algorithm': 'd7466a2c1d5cb3fa95029d73dc030f4c3c45a159', 'config': 'fa020a592ec5ac234f9f91aac28abc2cd1ec9d33', 'pipeline': '71e0d26f923d42cfe0e2fa748931ef2afe72ed86'}, 'duration': 3.62078595161438, 'iteration': 6, 'loss': 0.17066372828623277, 'max_history_score': 0.9456356408262035, 'max_history_score_std': 0.040053650785990214, 'max_history_step': 'joint', 'pipeline': {'features': ('features_SelectKBest', {'features__k': 1}), 'normalizer': ('normalizer_RobustScaler', {'normalizer__quantile_range': (...), 'normalizer__with_centering': True, 'normalizer__with_scaling': True}), 'rebalance': ('rebalance_CondensedNearestNeighbour', {'rebalance__n_neighbors': 1})}, 'score': 0.8293362717137672, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'entropy', 'max_depth': 3, 'max_features': 3, 'max_leaf_nodes': 5, 'min_samples_split': 5, 'n_estimators': 50}, 'config_hash': {'algorithm': '735caa9785596076014572a24050cde8dc338973', 'config': '0da4498002d6f452c59bb61756abb3ded841e786', 'pipeline': '51a53ea6ef5a2521ee65f76eb2da220ab7086513'}, 'duration': 0.6934049129486084, 'iteration': 7, 'loss': 0.06125875032408601, 'max_history_score': 0.9456356408262035, 'max_history_score_std': 0.040053650785990214, 'max_history_step': 'joint', 'pipeline': {'features': ('features_NoneType', {}), 'normalizer': ('normalizer_NoneType', {}), 'rebalance': ('rebalance_NearMiss', {'rebalance__n_neighbors': 3})}, 'score': 0.938741249675914, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': 4, 'max_features': 2, 'max_leaf_nodes': None, 'min_samples_split': 3, 'n_estimators': 75}, 'config_hash': {'algorithm': 'e71a1fe9515b6805f07914a61f2e7594be9e9afe', 'config': '344e4756fb1bec455d6af51d3727e33b0d27725f', 'pipeline': '248dad1d8b30a17a5de1d0bbdfe3e2acb7a1962b'}, 'duration': 1.3036692142486572, 'iteration': 8, 'loss': 0.06483125918243893, 'max_history_score': 0.9456356408262035, 'max_history_score_std': 0.040053650785990214, 'max_history_step': 'joint', 'pipeline': {'features': ('features_PCA', {'features__n_components': 2}), 'normalizer': ('normalizer_StandardScaler', {'normalizer__with_mean': False, 'normalizer__with_std': True}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 7})}, 'score': 0.9351687408175611, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'entropy', 'max_depth': 2, 'max_features': 2, 'max_leaf_nodes': 2, 'min_samples_split': 3, 'n_estimators': 10}, 'config_hash': {'algorithm': '0a507823f2ad8605ed5950e1fe61df0560f11a00', 'config': '4a538fdcf8e07f90e92a421c0d5c479d651629c7', 'pipeline': '5240329df25c9a533d025c1a401d49835a501b41'}, 'duration': 1.3821029663085938, 'iteration': 9, 'loss': 0.07006416904329793, 'max_history_score': 0.9456356408262035, 'max_history_score_std': 0.040053650785990214, 'max_history_step': 'joint', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 4, 'features__selectkbest__k': 2}), 'normalizer': ('normalizer_PowerTransformer', {}), 'rebalance': ('rebalance_NearMiss', {'rebalance__n_neighbors': 1})}, 'score': 0.9299358309567021, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'gini', 'max_depth': 1, 'max_features': 3, 'max_leaf_nodes': 5, 'min_samples_split': 3, 'n_estimators': 10}, 'config_hash': {'algorithm': 'd32739750d351948f8ff34a87c7d55b0c5e0d90f', 'config': 'c1609e71f1ce8486335adc70bb69a955580ba2c8', 'pipeline': 'f48b42ec5cf999279659966160a16353b75bdaa3'}, 'duration': 0.9055681228637695, 'iteration': 10, 'loss': 0.07532840722495904, 'max_history_score': 0.9456356408262035, 'max_history_score_std': 0.040053650785990214, 'max_history_step': 'joint', 'pipeline': {'features': ('features_PCA', {'features__n_components': 4}), 'normalizer': ('normalizer_PowerTransformer', {}), 'rebalance': ('rebalance_NearMiss', {'rebalance__n_neighbors': 1})}, 'score': 0.924671592775041, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': 3, 'max_features': 1, 'max_leaf_nodes': 5, 'min_samples_split': 3, 'n_estimators': 25}, 'config_hash': {'algorithm': 'f69bac35e71cbec1bfc1fb5942328a3390e7c252', 'config': 'abe36f188644e53e56ed3224236fa157107ed3b2', 'pipeline': 'aaf976c7c663a31fa039582d42f9e07101556a7c'}, 'duration': 0.764197826385498, 'iteration': 11, 'loss': 0.06818446979517778, 'max_history_score': 0.9456356408262035, 'max_history_score_std': 0.040053650785990214, 'max_history_step': 'joint', 'pipeline': {'features': ('features_NoneType', {}), 'normalizer': ('normalizer_PowerTransformer', {}), 'rebalance': ('rebalance_NoneType', {})}, 'score': 0.9318155302048222, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'entropy', 'max_depth': None, 'max_features': None, 'max_leaf_nodes': None, 'min_samples_split': 5, 'n_estimators': 25}, 'config_hash': {'algorithm': 'a0a27aec00db5ddf71eab96663f9bd61c845f5e3', 'config': '76aa002c3c9d4d9722466c60daf5119c18a41d2a', 'pipeline': '1ce34b7894ef342571d974bb19e8ec821a512c6b'}, 'duration': 1.1636500358581543, 'iteration': 12, 'loss': 0.12833700630887557, 'max_history_score': 0.9456356408262035, 'max_history_score_std': 0.040053650785990214, 'max_history_step': 'joint', 'pipeline': {'features': ('features_PCA', {'features__n_components': 1}), 'normalizer': ('normalizer_PowerTransformer', {}), 'rebalance': ('rebalance_NoneType', {})}, 'score': 0.8716629936911244, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'gini', 'max_depth': 1, 'max_features': 2, 'max_leaf_nodes': 2, 'min_samples_split': 2, 'n_estimators': 100}, 'config_hash': {'algorithm': '985c99dff1da9b2c87e4211c5335a9159aa9dbcb', 'config': 'f56a7a9e43a0a699e992dc1262e550b8b7c88538', 'pipeline': '5c934f6d9a8ad1f9afe762986a9cf2074fc95d79'}, 'duration': 2.235443115234375, 'iteration': 13, 'loss': 0.11414635727249167, 'max_history_score': 0.9456356408262035, 'max_history_score_std': 0.040053650785990214, 'max_history_step': 'joint', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 1, 'features__selectkbest__k': 1}), 'normalizer': ('normalizer_RobustScaler', {'normalizer__quantile_range': (...), 'normalizer__with_centering': False, 'normalizer__with_scaling': True}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 6})}, 'score': 0.8858536427275083, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'gini', 'max_depth': 1, 'max_features': 1, 'max_leaf_nodes': None, 'min_samples_split': 5, 'n_estimators': 10}, 'config_hash': {'algorithm': '7d74a39aac2579264a402aef2b6fa7943c19f3d3', 'config': '53f44c0ad925c5c08c25d4fadf5e9ee9d7c181cd', 'pipeline': '6eff5ef31d7d1d534db31913bb67529c8a24c42e'}, 'duration': 2.7847659587860107, 'iteration': 14, 'loss': 0.14061986863711007, 'max_history_score': 0.9456356408262035, 'max_history_score_std': 0.040053650785990214, 'max_history_step': 'joint', 'pipeline': {'features': ('features_PCA', {'features__n_components': 1}), 'normalizer': ('normalizer_RobustScaler', {'normalizer__quantile_range': (...), 'normalizer__with_centering': True, 'normalizer__with_scaling': True}), 'rebalance': ('rebalance_CondensedNearestNeighbour', {'rebalance__n_neighbors': 3})}, 'score': 0.8593801313628899, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'entropy', 'max_depth': 3, 'max_features': None, 'max_leaf_nodes': 5, 'min_samples_split': 2, 'n_estimators': 100}, 'config_hash': {'algorithm': 'c62d7c671832e4414b6b2d7c36cba5ddc83a0ed0', 'config': '5faee50671eaa0ac586722bff234e36a857e662d', 'pipeline': '8b29a55de2add78c49114b9bbe5e800e5524c59d'}, 'duration': 2.3916029930114746, 'iteration': 15, 'loss': 0.08770093336790252, 'max_history_score': 0.9456356408262035, 'max_history_score_std': 0.040053650785990214, 'max_history_step': 'joint', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 3, 'features__selectkbest__k': 4}), 'normalizer': ('normalizer_RobustScaler', {'normalizer__quantile_range': (...), 'normalizer__with_centering': True, 'normalizer__with_scaling': True}), 'rebalance': ('rebalance_NoneType', {})}, 'score': 0.9122990666320975, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': None, 'max_features': 1, 'max_leaf_nodes': 5, 'min_samples_split': 5, 'n_estimators': 10}, 'config_hash': {'algorithm': '290772bfb9b8ed15c48a72829e822fb0a07481d6', 'config': '9a04f25d8eb3db5b2f831abd341a6d384c73a957', 'pipeline': '1ce34b7894ef342571d974bb19e8ec821a512c6b'}, 'duration': 1.4364500045776367, 'iteration': 16, 'loss': 0.08948880822746508, 'max_history_score': 0.9456356408262035, 'max_history_score_std': 0.040053650785990214, 'max_history_step': 'joint', 'pipeline': {'features': ('features_PCA', {'features__n_components': 1}), 'normalizer': ('normalizer_PowerTransformer', {}), 'rebalance': ('rebalance_NoneType', {})}, 'score': 0.9105111917725349, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': 2, 'max_features': 3, 'max_leaf_nodes': 3, 'min_samples_split': 3, 'n_estimators': 100}, 'config_hash': {'algorithm': '7dab6d47f897c2961d3402eff844aff16a7d142a', 'config': '4dbfa2688b239be9f372d3e80223960ba9a1fbdd', 'pipeline': 'cdef51702798fa49f11c11d80baf3ab43d5358fc'}, 'duration': 0.9830451011657715, 'iteration': 17, 'loss': 1.0, 'max_history_score': 0.9456356408262035, 'max_history_score_std': 0.040053650785990214, 'max_history_step': 'joint', 'pipeline': {'features': ('features_SelectKBest', {'features__k': 2}), 'normalizer': ('normalizer_PowerTransformer', {}), 'rebalance': ('rebalance_NearMiss', {'rebalance__n_neighbors': 1})}, 'score': 0.0, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'entropy', 'max_depth': None, 'max_features': 3, 'max_leaf_nodes': None, 'min_samples_split': 5, 'n_estimators': 10}, 'config_hash': {'algorithm': 'def83e48be05ef92a37e1a90585820f2f67ff42b', 'config': '95902552cb76e9798f0fa58782bd72bd1cc272d7', 'pipeline': '1775187bf23f94f4fd0cc1e5c1ef665210edded5'}, 'duration': 2.0033559799194336, 'iteration': 18, 'loss': 0.04922327370149515, 'max_history_score': 0.9507767262985048, 'max_history_score_std': 0.028328108925705902, 'max_history_step': 'joint', 'pipeline': {'features': ('features_PCA', {'features__n_components': 4}), 'normalizer': ('normalizer_StandardScaler', {'normalizer__with_mean': True, 'normalizer__with_std': True}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 5})}, 'score': 0.9507767262985048, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'gini', 'max_depth': 1, 'max_features': 3, 'max_leaf_nodes': None, 'min_samples_split': 2, 'n_estimators': 50}, 'config_hash': {'algorithm': '4e9e3275f817df75115d9d7e3366980fc1b4cf13', 'config': '7770b19007b40bf13005d52eb81f87bc401f15b4', 'pipeline': 'c4dd111513ea35f97dd3aec3e8e7f6268ce035da'}, 'duration': 0.9069631099700928, 'iteration': 19, 'loss': 1.0, 'max_history_score': 0.9507767262985048, 'max_history_score_std': 0.028328108925705902, 'max_history_step': 'joint', 'pipeline': {'features': ('features_PCA', {'features__n_components': 2}), 'normalizer': ('normalizer_RobustScaler', {'normalizer__quantile_range': (...), 'normalizer__with_centering': False, 'normalizer__with_scaling': True}), 'rebalance': ('rebalance_NearMiss', {'rebalance__n_neighbors': 2})}, 'score': 0.0, ...}, ...], 'history_hash': ['51144ca42f9ea5ab2d8d58606e3b3e4d89c6d7b3', '9e54ffcb6a727de032a0a2cd45c5cc37cc150756', 'e5241eee9ddf3f4ee29a4711f5bcc92a4d24cd09', '18ee4d3d1627472ec190326308d8755371a6dc62', '2af4f82b045c0c48ecb89d42728d1039fbff8878', '17b2a1e5814f3e933137158708a5b6e9b2475495', 'fa020a592ec5ac234f9f91aac28abc2cd1ec9d33', '0da4498002d6f452c59bb61756abb3ded841e786', '344e4756fb1bec455d6af51d3727e33b0d27725f', '4a538fdcf8e07f90e92a421c0d5c479d651629c7', 'c1609e71f1ce8486335adc70bb69a955580ba2c8', 'abe36f188644e53e56ed3224236fa157107ed3b2', '76aa002c3c9d4d9722466c60daf5119c18a41d2a', 'f56a7a9e43a0a699e992dc1262e550b8b7c88538', '53f44c0ad925c5c08c25d4fadf5e9ee9d7c181cd', '5faee50671eaa0ac586722bff234e36a857e662d', '9a04f25d8eb3db5b2f831abd341a6d384c73a957', '4dbfa2688b239be9f372d3e80223960ba9a1fbdd', '95902552cb76e9798f0fa58782bd72bd1cc272d7', '7770b19007b40bf13005d52eb81f87bc401f15b4', ...], 'history_index': {'0da4498002d6f452c59bb61756abb3ded841e786': 7, '0f77a69b0a8d34861caf915a51dc588ff8d4efac': 61, '127553d555ed39231b8da3a1ce42d3902e30919b': 59, '17b2a1e5814f3e933137158708a5b6e9b2475495': 5, '18ee4d3d1627472ec190326308d8755371a6dc62': 3, '1b2267555a9226d7eb4df3c63dd12506da370f4d': 56, '28b2db1bf9b505aa8e490d811b55f6655178ede7': 67, '2af4f82b045c0c48ecb89d42728d1039fbff8878': 4, '2d054540972225f4f17fb36d63106b7bb5c406fe': 36, '306511091d7e5d6431b5e5a6320802c4c04cde44': 33, ...}, 'iteration': 69, 'max_history_score': 0.9525008642295394, 'max_history_score_std': 0.02225295065716913, 'max_history_step': 'joint'}
        config = {'algorithm': 'RandomForest', 'seed': 42, 'time': 300}
    114 
    115 
    116 def get_baseline_score(algorithm, X, y, seed):
    117     pipeline, _ = pipeline_conf_to_full_pipeline(

...........................................................................
/home/aquemy/dev/dp_hyperparameters/extension/experiment/objective.py in objective(pipeline_config={'features': ('features_PCA', {'features__n_components': 1}), 'normalizer': ('normalizer_PowerTransformer', {}), 'rebalance': ('rebalance_CondensedNearestNeighbour', {'rebalance__n_neighbors': 2})}, algo_config={'bootstrap': False, 'criterion': 'entropy', 'max_depth': None, 'max_features': 3, 'max_leaf_nodes': 2, 'min_samples_split': 5, 'n_estimators': 10}, algorithm='RandomForest', X=array([[1.799e+01, 1.038e+01, 1.228e+02, ..., 2...., ..., 0.000e+00, 2.871e-01,
        7.039e-02]]), y=array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,... 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1]), context={'baseline_score': 0.9545944602886527, 'baseline_score_std': 0.03716322883281839, 'best_config': {'algorithm': {'bootstrap': False, 'criterion': 'entropy', 'max_depth': None, 'max_features': 2, 'max_leaf_nodes': None, 'min_samples_split': 5, 'n_estimators': 10}, 'config_hash': {'algorithm': 'e7a772c2bc361aa61cf7eeb364a26dca2c9b89d6', 'config': 'afb67da069b544b0505b1e8c150edc7498ad37b4', 'pipeline': 'a43db4b4fc4c38610b7b5e484840d2e583089ff4'}, 'duration': 1.0073001384735107, 'iteration': 26, 'loss': 0.04749913577046061, 'max_history_score': 0.9525008642295394, 'max_history_score_std': 0.02225295065716913, 'max_history_step': 'joint', 'pipeline': {'features': ('features_PCA', {'features__n_components': 4}), 'normalizer': ('normalizer_StandardScaler', {'normalizer__with_mean': True, 'normalizer__with_std': False}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 7})}, 'score': 0.9525008642295394, ...}, 'history': [{'algorithm': {'bootstrap': True, 'criterion': 'entropy', 'max_depth': 4, 'max_features': 3, 'max_leaf_nodes': 3, 'min_samples_split': 2, 'n_estimators': 10}, 'config_hash': {'algorithm': '42527c4120073c2a488d1b8df28732f486d1578c', 'config': '51144ca42f9ea5ab2d8d58606e3b3e4d89c6d7b3', 'pipeline': '52f07bda29f9d3a95fabb87e591d0b2581ca8209'}, 'duration': 0.26703310012817383, 'iteration': 0, 'loss': 0.06655431682654922, 'max_history_score': 0.9334456831734508, 'max_history_score_std': 0.03819399139659311, 'max_history_step': 'joint', 'pipeline': {'features': ('features_NoneType', {}), 'normalizer': ('normalizer_RobustScaler', {'normalizer__quantile_range': (...), 'normalizer__with_centering': False, 'normalizer__with_scaling': False}), 'rebalance': ('rebalance_NearMiss', {'rebalance__n_neighbors': 1})}, 'score': 0.9334456831734508, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': None, 'max_features': 2, 'max_leaf_nodes': 3, 'min_samples_split': 2, 'n_estimators': 100}, 'config_hash': {'algorithm': '1b32258c630f07e01ab481ab925ab80aa757e482', 'config': '9e54ffcb6a727de032a0a2cd45c5cc37cc150756', 'pipeline': '37e72d4a97f5e784c9d3133e6379b91bfc3be803'}, 'duration': 1.3065669536590576, 'iteration': 1, 'loss': 0.05436435917379645, 'max_history_score': 0.9456356408262035, 'max_history_score_std': 0.040053650785990214, 'max_history_step': 'joint', 'pipeline': {'features': ('features_NoneType', {}), 'normalizer': ('normalizer_StandardScaler', {'normalizer__with_mean': True, 'normalizer__with_std': True}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 6})}, 'score': 0.9456356408262035, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'entropy', 'max_depth': 1, 'max_features': 1, 'max_leaf_nodes': 2, 'min_samples_split': 3, 'n_estimators': 25}, 'config_hash': {'algorithm': '68ab9059aa7ec74e0da87c81734b9664243b3eb4', 'config': 'e5241eee9ddf3f4ee29a4711f5bcc92a4d24cd09', 'pipeline': '62463de065924498cdcd2f2f1f7e68535cdb33a5'}, 'duration': 0.6592490673065186, 'iteration': 2, 'loss': 0.07695856019358727, 'max_history_score': 0.9456356408262035, 'max_history_score_std': 0.040053650785990214, 'max_history_step': 'joint', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 1, 'features__selectkbest__k': 2}), 'normalizer': ('normalizer_NoneType', {}), 'rebalance': ('rebalance_NoneType', {})}, 'score': 0.9230414398064127, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': 3, 'max_features': 2, 'max_leaf_nodes': 2, 'min_samples_split': 2, 'n_estimators': 25}, 'config_hash': {'algorithm': 'e3f1f7d7783557a38f40f0476369091edd87092b', 'config': '18ee4d3d1627472ec190326308d8755371a6dc62', 'pipeline': 'c6d1263e344ed8c71b2e6e4ba8e0db2fb6c777c0'}, 'duration': 0.879349946975708, 'iteration': 3, 'loss': 0.07535973554576114, 'max_history_score': 0.9456356408262035, 'max_history_score_std': 0.040053650785990214, 'max_history_step': 'joint', 'pipeline': {'features': ('features_NoneType', {}), 'normalizer': ('normalizer_RobustScaler', {'normalizer__quantile_range': (...), 'normalizer__with_centering': True, 'normalizer__with_scaling': True}), 'rebalance': ('rebalance_NearMiss', {'rebalance__n_neighbors': 2})}, 'score': 0.9246402644542389, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'gini', 'max_depth': 4, 'max_features': 2, 'max_leaf_nodes': 5, 'min_samples_split': 2, 'n_estimators': 50}, 'config_hash': {'algorithm': '47581af7253940f9647ad16d37347d34baf13e5f', 'config': '2af4f82b045c0c48ecb89d42728d1039fbff8878', 'pipeline': '2928b22ed834303cb7bac6e6608531eaddd7df67'}, 'duration': 4.372632026672363, 'iteration': 4, 'loss': 0.09121294615849984, 'max_history_score': 0.9456356408262035, 'max_history_score_std': 0.040053650785990214, 'max_history_step': 'joint', 'pipeline': {'features': ('features_NoneType', {}), 'normalizer': ('normalizer_MinMaxScaler', {}), 'rebalance': ('rebalance_CondensedNearestNeighbour', {'rebalance__n_neighbors': 2})}, 'score': 0.9087870538415002, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'entropy', 'max_depth': 2, 'max_features': 2, 'max_leaf_nodes': None, 'min_samples_split': 2, 'n_estimators': 10}, 'config_hash': {'algorithm': '0a85f98ca2d06103287f153633d88f7a0535e7e8', 'config': '17b2a1e5814f3e933137158708a5b6e9b2475495', 'pipeline': '95defa3bdd8357f11f872d3c280d50a6d8ee398d'}, 'duration': 2.625814914703369, 'iteration': 5, 'loss': 0.15471329185031535, 'max_history_score': 0.9456356408262035, 'max_history_score_std': 0.040053650785990214, 'max_history_step': 'joint', 'pipeline': {'features': ('features_SelectKBest', {'features__k': 2}), 'normalizer': ('normalizer_StandardScaler', {'normalizer__with_mean': False, 'normalizer__with_std': False}), 'rebalance': ('rebalance_CondensedNearestNeighbour', {'rebalance__n_neighbors': 1})}, 'score': 0.8452867081496847, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': 3, 'max_features': None, 'max_leaf_nodes': None, 'min_samples_split': 5, 'n_estimators': 75}, 'config_hash': {'algorithm': 'd7466a2c1d5cb3fa95029d73dc030f4c3c45a159', 'config': 'fa020a592ec5ac234f9f91aac28abc2cd1ec9d33', 'pipeline': '71e0d26f923d42cfe0e2fa748931ef2afe72ed86'}, 'duration': 3.62078595161438, 'iteration': 6, 'loss': 0.17066372828623277, 'max_history_score': 0.9456356408262035, 'max_history_score_std': 0.040053650785990214, 'max_history_step': 'joint', 'pipeline': {'features': ('features_SelectKBest', {'features__k': 1}), 'normalizer': ('normalizer_RobustScaler', {'normalizer__quantile_range': (...), 'normalizer__with_centering': True, 'normalizer__with_scaling': True}), 'rebalance': ('rebalance_CondensedNearestNeighbour', {'rebalance__n_neighbors': 1})}, 'score': 0.8293362717137672, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'entropy', 'max_depth': 3, 'max_features': 3, 'max_leaf_nodes': 5, 'min_samples_split': 5, 'n_estimators': 50}, 'config_hash': {'algorithm': '735caa9785596076014572a24050cde8dc338973', 'config': '0da4498002d6f452c59bb61756abb3ded841e786', 'pipeline': '51a53ea6ef5a2521ee65f76eb2da220ab7086513'}, 'duration': 0.6934049129486084, 'iteration': 7, 'loss': 0.06125875032408601, 'max_history_score': 0.9456356408262035, 'max_history_score_std': 0.040053650785990214, 'max_history_step': 'joint', 'pipeline': {'features': ('features_NoneType', {}), 'normalizer': ('normalizer_NoneType', {}), 'rebalance': ('rebalance_NearMiss', {'rebalance__n_neighbors': 3})}, 'score': 0.938741249675914, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': 4, 'max_features': 2, 'max_leaf_nodes': None, 'min_samples_split': 3, 'n_estimators': 75}, 'config_hash': {'algorithm': 'e71a1fe9515b6805f07914a61f2e7594be9e9afe', 'config': '344e4756fb1bec455d6af51d3727e33b0d27725f', 'pipeline': '248dad1d8b30a17a5de1d0bbdfe3e2acb7a1962b'}, 'duration': 1.3036692142486572, 'iteration': 8, 'loss': 0.06483125918243893, 'max_history_score': 0.9456356408262035, 'max_history_score_std': 0.040053650785990214, 'max_history_step': 'joint', 'pipeline': {'features': ('features_PCA', {'features__n_components': 2}), 'normalizer': ('normalizer_StandardScaler', {'normalizer__with_mean': False, 'normalizer__with_std': True}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 7})}, 'score': 0.9351687408175611, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'entropy', 'max_depth': 2, 'max_features': 2, 'max_leaf_nodes': 2, 'min_samples_split': 3, 'n_estimators': 10}, 'config_hash': {'algorithm': '0a507823f2ad8605ed5950e1fe61df0560f11a00', 'config': '4a538fdcf8e07f90e92a421c0d5c479d651629c7', 'pipeline': '5240329df25c9a533d025c1a401d49835a501b41'}, 'duration': 1.3821029663085938, 'iteration': 9, 'loss': 0.07006416904329793, 'max_history_score': 0.9456356408262035, 'max_history_score_std': 0.040053650785990214, 'max_history_step': 'joint', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 4, 'features__selectkbest__k': 2}), 'normalizer': ('normalizer_PowerTransformer', {}), 'rebalance': ('rebalance_NearMiss', {'rebalance__n_neighbors': 1})}, 'score': 0.9299358309567021, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'gini', 'max_depth': 1, 'max_features': 3, 'max_leaf_nodes': 5, 'min_samples_split': 3, 'n_estimators': 10}, 'config_hash': {'algorithm': 'd32739750d351948f8ff34a87c7d55b0c5e0d90f', 'config': 'c1609e71f1ce8486335adc70bb69a955580ba2c8', 'pipeline': 'f48b42ec5cf999279659966160a16353b75bdaa3'}, 'duration': 0.9055681228637695, 'iteration': 10, 'loss': 0.07532840722495904, 'max_history_score': 0.9456356408262035, 'max_history_score_std': 0.040053650785990214, 'max_history_step': 'joint', 'pipeline': {'features': ('features_PCA', {'features__n_components': 4}), 'normalizer': ('normalizer_PowerTransformer', {}), 'rebalance': ('rebalance_NearMiss', {'rebalance__n_neighbors': 1})}, 'score': 0.924671592775041, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': 3, 'max_features': 1, 'max_leaf_nodes': 5, 'min_samples_split': 3, 'n_estimators': 25}, 'config_hash': {'algorithm': 'f69bac35e71cbec1bfc1fb5942328a3390e7c252', 'config': 'abe36f188644e53e56ed3224236fa157107ed3b2', 'pipeline': 'aaf976c7c663a31fa039582d42f9e07101556a7c'}, 'duration': 0.764197826385498, 'iteration': 11, 'loss': 0.06818446979517778, 'max_history_score': 0.9456356408262035, 'max_history_score_std': 0.040053650785990214, 'max_history_step': 'joint', 'pipeline': {'features': ('features_NoneType', {}), 'normalizer': ('normalizer_PowerTransformer', {}), 'rebalance': ('rebalance_NoneType', {})}, 'score': 0.9318155302048222, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'entropy', 'max_depth': None, 'max_features': None, 'max_leaf_nodes': None, 'min_samples_split': 5, 'n_estimators': 25}, 'config_hash': {'algorithm': 'a0a27aec00db5ddf71eab96663f9bd61c845f5e3', 'config': '76aa002c3c9d4d9722466c60daf5119c18a41d2a', 'pipeline': '1ce34b7894ef342571d974bb19e8ec821a512c6b'}, 'duration': 1.1636500358581543, 'iteration': 12, 'loss': 0.12833700630887557, 'max_history_score': 0.9456356408262035, 'max_history_score_std': 0.040053650785990214, 'max_history_step': 'joint', 'pipeline': {'features': ('features_PCA', {'features__n_components': 1}), 'normalizer': ('normalizer_PowerTransformer', {}), 'rebalance': ('rebalance_NoneType', {})}, 'score': 0.8716629936911244, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'gini', 'max_depth': 1, 'max_features': 2, 'max_leaf_nodes': 2, 'min_samples_split': 2, 'n_estimators': 100}, 'config_hash': {'algorithm': '985c99dff1da9b2c87e4211c5335a9159aa9dbcb', 'config': 'f56a7a9e43a0a699e992dc1262e550b8b7c88538', 'pipeline': '5c934f6d9a8ad1f9afe762986a9cf2074fc95d79'}, 'duration': 2.235443115234375, 'iteration': 13, 'loss': 0.11414635727249167, 'max_history_score': 0.9456356408262035, 'max_history_score_std': 0.040053650785990214, 'max_history_step': 'joint', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 1, 'features__selectkbest__k': 1}), 'normalizer': ('normalizer_RobustScaler', {'normalizer__quantile_range': (...), 'normalizer__with_centering': False, 'normalizer__with_scaling': True}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 6})}, 'score': 0.8858536427275083, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'gini', 'max_depth': 1, 'max_features': 1, 'max_leaf_nodes': None, 'min_samples_split': 5, 'n_estimators': 10}, 'config_hash': {'algorithm': '7d74a39aac2579264a402aef2b6fa7943c19f3d3', 'config': '53f44c0ad925c5c08c25d4fadf5e9ee9d7c181cd', 'pipeline': '6eff5ef31d7d1d534db31913bb67529c8a24c42e'}, 'duration': 2.7847659587860107, 'iteration': 14, 'loss': 0.14061986863711007, 'max_history_score': 0.9456356408262035, 'max_history_score_std': 0.040053650785990214, 'max_history_step': 'joint', 'pipeline': {'features': ('features_PCA', {'features__n_components': 1}), 'normalizer': ('normalizer_RobustScaler', {'normalizer__quantile_range': (...), 'normalizer__with_centering': True, 'normalizer__with_scaling': True}), 'rebalance': ('rebalance_CondensedNearestNeighbour', {'rebalance__n_neighbors': 3})}, 'score': 0.8593801313628899, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'entropy', 'max_depth': 3, 'max_features': None, 'max_leaf_nodes': 5, 'min_samples_split': 2, 'n_estimators': 100}, 'config_hash': {'algorithm': 'c62d7c671832e4414b6b2d7c36cba5ddc83a0ed0', 'config': '5faee50671eaa0ac586722bff234e36a857e662d', 'pipeline': '8b29a55de2add78c49114b9bbe5e800e5524c59d'}, 'duration': 2.3916029930114746, 'iteration': 15, 'loss': 0.08770093336790252, 'max_history_score': 0.9456356408262035, 'max_history_score_std': 0.040053650785990214, 'max_history_step': 'joint', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 3, 'features__selectkbest__k': 4}), 'normalizer': ('normalizer_RobustScaler', {'normalizer__quantile_range': (...), 'normalizer__with_centering': True, 'normalizer__with_scaling': True}), 'rebalance': ('rebalance_NoneType', {})}, 'score': 0.9122990666320975, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': None, 'max_features': 1, 'max_leaf_nodes': 5, 'min_samples_split': 5, 'n_estimators': 10}, 'config_hash': {'algorithm': '290772bfb9b8ed15c48a72829e822fb0a07481d6', 'config': '9a04f25d8eb3db5b2f831abd341a6d384c73a957', 'pipeline': '1ce34b7894ef342571d974bb19e8ec821a512c6b'}, 'duration': 1.4364500045776367, 'iteration': 16, 'loss': 0.08948880822746508, 'max_history_score': 0.9456356408262035, 'max_history_score_std': 0.040053650785990214, 'max_history_step': 'joint', 'pipeline': {'features': ('features_PCA', {'features__n_components': 1}), 'normalizer': ('normalizer_PowerTransformer', {}), 'rebalance': ('rebalance_NoneType', {})}, 'score': 0.9105111917725349, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': 2, 'max_features': 3, 'max_leaf_nodes': 3, 'min_samples_split': 3, 'n_estimators': 100}, 'config_hash': {'algorithm': '7dab6d47f897c2961d3402eff844aff16a7d142a', 'config': '4dbfa2688b239be9f372d3e80223960ba9a1fbdd', 'pipeline': 'cdef51702798fa49f11c11d80baf3ab43d5358fc'}, 'duration': 0.9830451011657715, 'iteration': 17, 'loss': 1.0, 'max_history_score': 0.9456356408262035, 'max_history_score_std': 0.040053650785990214, 'max_history_step': 'joint', 'pipeline': {'features': ('features_SelectKBest', {'features__k': 2}), 'normalizer': ('normalizer_PowerTransformer', {}), 'rebalance': ('rebalance_NearMiss', {'rebalance__n_neighbors': 1})}, 'score': 0.0, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'entropy', 'max_depth': None, 'max_features': 3, 'max_leaf_nodes': None, 'min_samples_split': 5, 'n_estimators': 10}, 'config_hash': {'algorithm': 'def83e48be05ef92a37e1a90585820f2f67ff42b', 'config': '95902552cb76e9798f0fa58782bd72bd1cc272d7', 'pipeline': '1775187bf23f94f4fd0cc1e5c1ef665210edded5'}, 'duration': 2.0033559799194336, 'iteration': 18, 'loss': 0.04922327370149515, 'max_history_score': 0.9507767262985048, 'max_history_score_std': 0.028328108925705902, 'max_history_step': 'joint', 'pipeline': {'features': ('features_PCA', {'features__n_components': 4}), 'normalizer': ('normalizer_StandardScaler', {'normalizer__with_mean': True, 'normalizer__with_std': True}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 5})}, 'score': 0.9507767262985048, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'gini', 'max_depth': 1, 'max_features': 3, 'max_leaf_nodes': None, 'min_samples_split': 2, 'n_estimators': 50}, 'config_hash': {'algorithm': '4e9e3275f817df75115d9d7e3366980fc1b4cf13', 'config': '7770b19007b40bf13005d52eb81f87bc401f15b4', 'pipeline': 'c4dd111513ea35f97dd3aec3e8e7f6268ce035da'}, 'duration': 0.9069631099700928, 'iteration': 19, 'loss': 1.0, 'max_history_score': 0.9507767262985048, 'max_history_score_std': 0.028328108925705902, 'max_history_step': 'joint', 'pipeline': {'features': ('features_PCA', {'features__n_components': 2}), 'normalizer': ('normalizer_RobustScaler', {'normalizer__quantile_range': (...), 'normalizer__with_centering': False, 'normalizer__with_scaling': True}), 'rebalance': ('rebalance_NearMiss', {'rebalance__n_neighbors': 2})}, 'score': 0.0, ...}, ...], 'history_hash': ['51144ca42f9ea5ab2d8d58606e3b3e4d89c6d7b3', '9e54ffcb6a727de032a0a2cd45c5cc37cc150756', 'e5241eee9ddf3f4ee29a4711f5bcc92a4d24cd09', '18ee4d3d1627472ec190326308d8755371a6dc62', '2af4f82b045c0c48ecb89d42728d1039fbff8878', '17b2a1e5814f3e933137158708a5b6e9b2475495', 'fa020a592ec5ac234f9f91aac28abc2cd1ec9d33', '0da4498002d6f452c59bb61756abb3ded841e786', '344e4756fb1bec455d6af51d3727e33b0d27725f', '4a538fdcf8e07f90e92a421c0d5c479d651629c7', 'c1609e71f1ce8486335adc70bb69a955580ba2c8', 'abe36f188644e53e56ed3224236fa157107ed3b2', '76aa002c3c9d4d9722466c60daf5119c18a41d2a', 'f56a7a9e43a0a699e992dc1262e550b8b7c88538', '53f44c0ad925c5c08c25d4fadf5e9ee9d7c181cd', '5faee50671eaa0ac586722bff234e36a857e662d', '9a04f25d8eb3db5b2f831abd341a6d384c73a957', '4dbfa2688b239be9f372d3e80223960ba9a1fbdd', '95902552cb76e9798f0fa58782bd72bd1cc272d7', '7770b19007b40bf13005d52eb81f87bc401f15b4', ...], 'history_index': {'0da4498002d6f452c59bb61756abb3ded841e786': 7, '0f77a69b0a8d34861caf915a51dc588ff8d4efac': 61, '127553d555ed39231b8da3a1ce42d3902e30919b': 59, '17b2a1e5814f3e933137158708a5b6e9b2475495': 5, '18ee4d3d1627472ec190326308d8755371a6dc62': 3, '1b2267555a9226d7eb4df3c63dd12506da370f4d': 56, '28b2db1bf9b505aa8e490d811b55f6655178ede7': 67, '2af4f82b045c0c48ecb89d42728d1039fbff8878': 4, '2d054540972225f4f17fb36d63106b7bb5c406fe': 36, '306511091d7e5d6431b5e5a6320802c4c04cde44': 33, ...}, 'iteration': 69, 'max_history_score': 0.9525008642295394, 'max_history_score_std': 0.02225295065716913, 'max_history_step': 'joint'}, config={'algorithm': 'RandomForest', 'seed': 42, 'time': 300}, step='joint')
     45                 y,
     46                 cv=10,
     47                 n_jobs=-1,
     48                 return_estimator=False,
     49                 return_train_score=False,
---> 50                 verbose=0)
     51         score = np.mean(scores['test_score'])
     52         std = np.std(scores['test_score'])
     53         status = STATUS_OK
     54     except Exception as e:

...........................................................................
/home/aquemy/.local/lib/python2.7/site-packages/sklearn/model_selection/_validation.py in cross_validate(estimator=Pipeline(memory=None,
     steps=[('rebalance', ...e=42,
            verbose=0, warm_start=False))]), X=array([[1.799e+01, 1.038e+01, 1.228e+02, ..., 2...., ..., 0.000e+00, 2.871e-01,
        7.039e-02]]), y=array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,... 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1]), groups=None, scoring=None, cv=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1, verbose=0, fit_params=None, pre_dispatch='2*n_jobs', return_train_score=False, return_estimator=False, error_score='raise-deprecating')
    235         delayed(_fit_and_score)(
    236             clone(estimator), X, y, scorers, train, test, verbose, None,
    237             fit_params, return_train_score=return_train_score,
    238             return_times=True, return_estimator=return_estimator,
    239             error_score=error_score)
--> 240         for train, test in cv.split(X, y, groups))
        cv.split = <bound method StratifiedKFold.split of Stratifie...d(n_splits=10, random_state=None, shuffle=False)>
        X = array([[1.799e+01, 1.038e+01, 1.228e+02, ..., 2...., ..., 0.000e+00, 2.871e-01,
        7.039e-02]])
        y = array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,... 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1])
        groups = None
    241 
    242     zipped_scores = list(zip(*scores))
    243     if return_train_score:
    244         train_scores = zipped_scores.pop(0)

...........................................................................
/home/aquemy/.local/lib/python2.7/site-packages/sklearn/externals/joblib/parallel.py in __call__(self=Parallel(n_jobs=-1), iterable=<generator object <genexpr>>)
    925                 # No need to wait for async callbacks to trigger to
    926                 # consumption.
    927                 self._iterating = False
    928 
    929             with self._backend.retrieval_context():
--> 930                 self.retrieve()
        self.retrieve = <bound method Parallel.retrieve of Parallel(n_jobs=-1)>
    931             # Make sure that we get a last message telling us we are done
    932             elapsed_time = time.time() - self._start_time
    933             self._print('Done %3i out of %3i | elapsed: %s finished',
    934                         (len(self._output), len(self._output),

---------------------------------------------------------------------------
Joblib worker traceback:
---------------------------------------------------------------------------
ValueError                                         Mon Jun 17 13:33:17 2019
PID: 26165                                  Python 2.7.15+: /usr/bin/python
...........................................................................
/home/aquemy/.local/lib/python2.7/site-packages/sklearn/externals/joblib/parallel.py in __call__(self=<sklearn.externals.joblib.parallel.BatchedCalls object>)
    220     def __call__(self):
    221         # Set the default nested backend to self._backend but do not set the
    222         # change the default number of processes to -1
    223         with parallel_backend(self._backend, n_jobs=self._n_jobs):
    224             return [func(*args, **kwargs)
--> 225                     for func, args, kwargs in self.items]
        func = <function _fit_and_score>
        args = (Pipeline(memory=None,
     steps=[('rebalance', ...e=42,
            verbose=0, warm_start=False))]), array([[1.799e+01, 1.038e+01, 1.228e+02, ..., 2...., ..., 0.000e+00, 2.871e-01,
        7.039e-02]]), array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,... 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1]), {'score': <function _passthrough_scorer>}, array([ 25,  26,  27,  28,  29,  30,  31,  32,  ..., 561, 562, 563, 564,
       565, 566, 567, 568]), array([  0,   1,   2,   3,   4,   5,   6,   7,  ...,  89,  90,
        92,  93,  96,  97,  98, 101]), 0, None, None)
        kwargs = {'error_score': 'raise-deprecating', 'return_estimator': False, 'return_times': True, 'return_train_score': False}
        self.items = [(<function _fit_and_score>, (Pipeline(memory=None,
     steps=[('rebalance', ...e=42,
            verbose=0, warm_start=False))]), array([[1.799e+01, 1.038e+01, 1.228e+02, ..., 2...., ..., 0.000e+00, 2.871e-01,
        7.039e-02]]), array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,... 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1]), {'score': <function _passthrough_scorer>}, array([ 25,  26,  27,  28,  29,  30,  31,  32,  ..., 561, 562, 563, 564,
       565, 566, 567, 568]), array([  0,   1,   2,   3,   4,   5,   6,   7,  ...,  89,  90,
        92,  93,  96,  97,  98, 101]), 0, None, None), {'error_score': 'raise-deprecating', 'return_estimator': False, 'return_times': True, 'return_train_score': False})]
    226 
    227     def __len__(self):
    228         return self._size
    229 

...........................................................................
/home/aquemy/.local/lib/python2.7/site-packages/sklearn/model_selection/_validation.py in _fit_and_score(estimator=Pipeline(memory=None,
     steps=[('rebalance', ...e=42,
            verbose=0, warm_start=False))]), X=array([[1.799e+01, 1.038e+01, 1.228e+02, ..., 2...., ..., 0.000e+00, 2.871e-01,
        7.039e-02]]), y=array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,... 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1]), scorer={'score': <function _passthrough_scorer>}, train=array([ 25,  26,  27,  28,  29,  30,  31,  32,  ..., 561, 562, 563, 564,
       565, 566, 567, 568]), test=array([  0,   1,   2,   3,   4,   5,   6,   7,  ...,  89,  90,
        92,  93,  96,  97,  98, 101]), verbose=0, parameters=None, fit_params={}, return_train_score=False, return_parameters=False, return_n_test_samples=False, return_times=True, return_estimator=False, error_score='raise-deprecating')
    523 
    524     try:
    525         if y_train is None:
    526             estimator.fit(X_train, **fit_params)
    527         else:
--> 528             estimator.fit(X_train, y_train, **fit_params)
        estimator.fit = <bound method Pipeline.fit of Pipeline(memory=No...=42,
            verbose=0, warm_start=False))])>
        X_train = array([[1.714e+01, 1.640e+01, 1.160e+02, ..., 2...., ..., 0.000e+00, 2.871e-01,
        7.039e-02]])
        y_train = array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...1, 1, 1, 1, 1, 1, 1, 0, 0,
       0, 0, 0, 0, 1])
        fit_params = {}
    529 
    530     except Exception as e:
    531         # Note fit time as time until error
    532         fit_time = time.time() - start_time

...........................................................................
/usr/local/lib/python2.7/dist-packages/imblearn/pipeline.py in fit(self=Pipeline(memory=None,
     steps=[('rebalance', ...e=42,
            verbose=0, warm_start=False))]), X=array([[1.714e+01, 1.640e+01, 1.160e+02, ..., 2...., ..., 0.000e+00, 2.871e-01,
        7.039e-02]]), y=array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...1, 1, 1, 1, 1, 1, 1, 0, 0,
       0, 0, 0, 0, 1]), **fit_params={})
    234             This estimator
    235 
    236         """
    237         Xt, yt, fit_params = self._fit(X, y, **fit_params)
    238         if self._final_estimator is not None:
--> 239             self._final_estimator.fit(Xt, yt, **fit_params)
        self._final_estimator.fit = <bound method RandomForestClassifier.fit of Rand...ate=42,
            verbose=0, warm_start=False)>
        Xt = array([[-5.08269440e+00],
       [-1.17826173e+0...    [ 6.62089607e-01],
       [ 5.33674972e+00]])
        yt = array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...1, 1,
       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])
        fit_params = {}
    240         return self
    241 
    242     def fit_transform(self, X, y=None, **fit_params):
    243         """Fit the model and transform with the final estimator

...........................................................................
/home/aquemy/.local/lib/python2.7/site-packages/sklearn/ensemble/forest.py in fit(self=RandomForestClassifier(bootstrap=False, class_we...tate=42,
            verbose=0, warm_start=False), X=array([[-5.0826945e+00],
       [-1.1782618e+00]...59e-01],
       [ 5.3367496e+00]], dtype=float32), y=array([[0.],
       [0.],
       [0.],
       [0...    [1.],
       [1.],
       [1.],
       [1.]]), sample_weight=None)
    328             trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,
    329                              **_joblib_parallel_args(prefer='threads'))(
    330                 delayed(_parallel_build_trees)(
    331                     t, self, X, y, sample_weight, i, len(trees),
    332                     verbose=self.verbose, class_weight=self.class_weight)
--> 333                 for i, t in enumerate(trees))
        i = 9
    334 
    335             # Collect newly grown trees
    336             self.estimators_.extend(trees)
    337 

...........................................................................
/home/aquemy/.local/lib/python2.7/site-packages/sklearn/externals/joblib/parallel.py in __call__(self=Parallel(n_jobs=1), iterable=<generator object <genexpr>>)
    912             # self._original_iterator is None, then this means either
    913             # that pre_dispatch == "all", n_jobs == 1 or that the first batch
    914             # was very quick and its callback already dispatched all the
    915             # remaining jobs.
    916             self._iterating = False
--> 917             if self.dispatch_one_batch(iterator):
        self.dispatch_one_batch = <bound method Parallel.dispatch_one_batch of Parallel(n_jobs=1)>
        iterator = <generator object <genexpr>>
    918                 self._iterating = self._original_iterator is not None
    919 
    920             while self.dispatch_one_batch(iterator):
    921                 pass

...........................................................................
/home/aquemy/.local/lib/python2.7/site-packages/sklearn/externals/joblib/parallel.py in dispatch_one_batch(self=Parallel(n_jobs=1), iterator=<generator object <genexpr>>)
    754                                  self._pickle_cache)
    755             if len(tasks) == 0:
    756                 # No more tasks available in the iterator: tell caller to stop.
    757                 return False
    758             else:
--> 759                 self._dispatch(tasks)
        self._dispatch = <bound method Parallel._dispatch of Parallel(n_jobs=1)>
        tasks = <sklearn.externals.joblib.parallel.BatchedCalls object>
    760                 return True
    761 
    762     def _print(self, msg, msg_args):
    763         """Display the message on stout or stderr depending on verbosity"""

...........................................................................
/home/aquemy/.local/lib/python2.7/site-packages/sklearn/externals/joblib/parallel.py in _dispatch(self=Parallel(n_jobs=1), batch=<sklearn.externals.joblib.parallel.BatchedCalls object>)
    711 
    712         dispatch_timestamp = time.time()
    713         cb = BatchCompletionCallBack(dispatch_timestamp, len(batch), self)
    714         with self._lock:
    715             job_idx = len(self._jobs)
--> 716             job = self._backend.apply_async(batch, callback=cb)
        job = undefined
        self._backend.apply_async = <bound method SequentialBackend.apply_async of <...lib._parallel_backends.SequentialBackend object>>
        batch = <sklearn.externals.joblib.parallel.BatchedCalls object>
        cb = <sklearn.externals.joblib.parallel.BatchCompletionCallBack object>
    717             # A job can complete so quickly than its callback is
    718             # called before we get here, causing self._jobs to
    719             # grow. To ensure correct results ordering, .insert is
    720             # used (rather than .append) in the following line

...........................................................................
/home/aquemy/.local/lib/python2.7/site-packages/sklearn/externals/joblib/_parallel_backends.py in apply_async(self=<sklearn.externals.joblib._parallel_backends.SequentialBackend object>, func=<sklearn.externals.joblib.parallel.BatchedCalls object>, callback=<sklearn.externals.joblib.parallel.BatchCompletionCallBack object>)
    177             raise ValueError('n_jobs == 0 in Parallel has no meaning')
    178         return 1
    179 
    180     def apply_async(self, func, callback=None):
    181         """Schedule a func to be run"""
--> 182         result = ImmediateResult(func)
        result = undefined
        func = <sklearn.externals.joblib.parallel.BatchedCalls object>
    183         if callback:
    184             callback(result)
    185         return result
    186 

...........................................................................
/home/aquemy/.local/lib/python2.7/site-packages/sklearn/externals/joblib/_parallel_backends.py in __init__(self=<sklearn.externals.joblib._parallel_backends.ImmediateResult object>, batch=<sklearn.externals.joblib.parallel.BatchedCalls object>)
    544 
    545 class ImmediateResult(object):
    546     def __init__(self, batch):
    547         # Don't delay the application, to avoid keeping the input
    548         # arguments in memory
--> 549         self.results = batch()
        self.results = undefined
        batch = <sklearn.externals.joblib.parallel.BatchedCalls object>
    550 
    551     def get(self):
    552         return self.results
    553 

...........................................................................
/home/aquemy/.local/lib/python2.7/site-packages/sklearn/externals/joblib/parallel.py in __call__(self=<sklearn.externals.joblib.parallel.BatchedCalls object>)
    220     def __call__(self):
    221         # Set the default nested backend to self._backend but do not set the
    222         # change the default number of processes to -1
    223         with parallel_backend(self._backend, n_jobs=self._n_jobs):
    224             return [func(*args, **kwargs)
--> 225                     for func, args, kwargs in self.items]
        func = <function _parallel_build_trees>
        args = (DecisionTreeClassifier(class_weight=None, criter...=False, random_state=1608637542, splitter='best'), RandomForestClassifier(bootstrap=False, class_we...tate=42,
            verbose=0, warm_start=False), array([[-5.0826945e+00],
       [-1.1782618e+00]...59e-01],
       [ 5.3367496e+00]], dtype=float32), array([[0.],
       [0.],
       [0.],
       [0...    [1.],
       [1.],
       [1.],
       [1.]]), None, 0, 10)
        kwargs = {'class_weight': None, 'verbose': 0}
        self.items = [(<function _parallel_build_trees>, (DecisionTreeClassifier(class_weight=None, criter...=False, random_state=1608637542, splitter='best'), RandomForestClassifier(bootstrap=False, class_we...tate=42,
            verbose=0, warm_start=False), array([[-5.0826945e+00],
       [-1.1782618e+00]...59e-01],
       [ 5.3367496e+00]], dtype=float32), array([[0.],
       [0.],
       [0.],
       [0...    [1.],
       [1.],
       [1.],
       [1.]]), None, 0, 10), {'class_weight': None, 'verbose': 0})]
    226 
    227     def __len__(self):
    228         return self._size
    229 

...........................................................................
/home/aquemy/.local/lib/python2.7/site-packages/sklearn/ensemble/forest.py in _parallel_build_trees(tree=DecisionTreeClassifier(class_weight=None, criter...=False, random_state=1608637542, splitter='best'), forest=RandomForestClassifier(bootstrap=False, class_we...tate=42,
            verbose=0, warm_start=False), X=array([[-5.0826945e+00],
       [-1.1782618e+00]...59e-01],
       [ 5.3367496e+00]], dtype=float32), y=array([[0.],
       [0.],
       [0.],
       [0...    [1.],
       [1.],
       [1.],
       [1.]]), sample_weight=None, tree_idx=0, n_trees=10, verbose=0, class_weight=None)
    116         elif class_weight == 'balanced_subsample':
    117             curr_sample_weight *= compute_sample_weight('balanced', y, indices)
    118 
    119         tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)
    120     else:
--> 121         tree.fit(X, y, sample_weight=sample_weight, check_input=False)
        tree.fit = <bound method DecisionTreeClassifier.fit of Deci...False, random_state=1608637542, splitter='best')>
        X = array([[-5.0826945e+00],
       [-1.1782618e+00]...59e-01],
       [ 5.3367496e+00]], dtype=float32)
        y = array([[0.],
       [0.],
       [0.],
       [0...    [1.],
       [1.],
       [1.],
       [1.]])
        sample_weight = None
    122 
    123     return tree
    124 
    125 

...........................................................................
/home/aquemy/.local/lib/python2.7/site-packages/sklearn/tree/tree.py in fit(self=DecisionTreeClassifier(class_weight=None, criter...=False, random_state=1608637542, splitter='best'), X=array([[-5.0826945e+00],
       [-1.1782618e+00]...59e-01],
       [ 5.3367496e+00]], dtype=float32), y=array([[0.],
       [0.],
       [0.],
       [0...    [1.],
       [1.],
       [1.],
       [1.]]), sample_weight=None, check_input=False, X_idx_sorted=None)
    796 
    797         super(DecisionTreeClassifier, self).fit(
    798             X, y,
    799             sample_weight=sample_weight,
    800             check_input=check_input,
--> 801             X_idx_sorted=X_idx_sorted)
        X_idx_sorted = None
    802         return self
    803 
    804     def predict_proba(self, X, check_input=True):
    805         """Predict class probabilities of the input samples X.

...........................................................................
/home/aquemy/.local/lib/python2.7/site-packages/sklearn/tree/tree.py in fit(self=DecisionTreeClassifier(class_weight=None, criter...=False, random_state=1608637542, splitter='best'), X=array([[-5.0826945e+00],
       [-1.1782618e+00]...59e-01],
       [ 5.3367496e+00]], dtype=float32), y=array([[0.],
       [0.],
       [0.],
       [0...    [1.],
       [1.],
       [1.],
       [1.]]), sample_weight=None, check_input=False, X_idx_sorted=None)
    237         if not 0 <= self.min_weight_fraction_leaf <= 0.5:
    238             raise ValueError("min_weight_fraction_leaf must in [0, 0.5]")
    239         if max_depth <= 0:
    240             raise ValueError("max_depth must be greater than zero. ")
    241         if not (0 < max_features <= self.n_features_):
--> 242             raise ValueError("max_features must be in (0, n_features]")
    243         if not isinstance(max_leaf_nodes, (numbers.Integral, np.integer)):
    244             raise ValueError("max_leaf_nodes must be integral number but was "
    245                              "%r" % max_leaf_nodes)
    246         if -1 < max_leaf_nodes < 2:

ValueError: max_features must be in (0, n_features]
___________________________________________________________________________
Best score: 0.95250086423 (0.0222529506572) [J] | Score: 0.0 (0.0) [J]
Best score: 0.95250086423 (0.0222529506572) [J] | Score: 0.908663901132 (0.029891746426) [J]
Best score: 0.95250086423 (0.0222529506572) [J] | Score: 0.884161913404 (0.0319805818913) [J]
Best score: 0.95250086423 (0.0222529506572) [J] | Score: 0.919315530205 (0.0356069023039) [J]
Best score: 0.95250086423 (0.0222529506572) [J] | Score: 0.907063996197 (0.0306786455093) [J]
Best score: 0.95250086423 (0.0222529506572) [J] | Score: 0.933199377755 (0.026115755391) [J]
Best score: 0.95250086423 (0.0222529506572) [J] | Score: 0.93159947282 (0.0222284548242) [J]
Best score: 0.95250086423 (0.0222529506572) [J] | Score: 0.471538760695 (0.200824500269) [J]
Best score: 0.95250086423 (0.0222529506572) [J] | Score: 0.906971091522 (0.0242938238381) [J]
Best score: 0.95250086423 (0.0222529506572) [J] | Score: 0.935291893527 (0.0461508121135) [J]
Best score: 0.95250086423 (0.0222529506572) [J] | Score: 0.935169821104 (0.0337606681103) [J]
Best score: 0.95250086423 (0.0222529506572) [J] | Score: 0.917313758534 (0.0305776218423) [J]
Best score: 0.95250086423 (0.0222529506572) [J] | Score: 0.8629213119 (0.0300277885153) [J]
Best score: 0.95250086423 (0.0222529506572) [J] | Score: 0.894351179673 (0.0463384983144) [J]
JoblibValueError
___________________________________________________________________________
...........................................................................
/home/aquemy/dev/dp_hyperparameters/extension/main.py in <module>()
     27 
     28     serializer.serialize_results(scenario, policy)
     29 
     30 if __name__ == "__main__":
     31     args = cli.parse_args()
---> 32     main(args)

...........................................................................
/home/aquemy/dev/dp_hyperparameters/extension/main.py in main(args=Namespace(customize=[(['control', 'seed'], '42')...='./scenarios/rf_breast_joint.yaml', verbosity=0))
     21         test_size=0.4, 
     22         random_state=scenario['control']['seed']
     23     )
     24 
     25     policy = policies.initiate(scenario['setup']['policy'], config)
---> 26     policy.run(X,y)
        policy.run = <bound method Joint.run of <experiment.policies.joint.Joint object>>
        X = array([[1.799e+01, 1.038e+01, 1.228e+02, ..., 2...., ..., 0.000e+00, 2.871e-01,
        7.039e-02]])
        y = array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,... 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1])
     27 
     28     serializer.serialize_results(scenario, policy)
     29 
     30 if __name__ == "__main__":

...........................................................................
/home/aquemy/dev/dp_hyperparameters/extension/experiment/policies/joint.py in run(self=<experiment.policies.joint.Joint object>, X=array([[1.799e+01, 1.038e+01, 1.228e+02, ..., 2...., ..., 0.000e+00, 2.871e-01,
        7.039e-02]]), y=array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,... 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1]))
     32             algo=tpe.suggest, 
     33             max_evals=None,
     34             max_time=self.config['time'],     
     35             trials=trials,
     36             show_progressbar=False,
---> 37             verbose=0
     38         )
     39 
     40         best_config = self.context['best_config']
     41         super(Joint, self).display_step_results(best_config)

...........................................................................
/home/aquemy/dev/dp_hyperparameters/extension/hyperopt/fmin.py in fmin(fn=<functools.partial object>, space={'algorithm': {'bootstrap': <hyperopt.pyll.base.Apply object>, 'criterion': <hyperopt.pyll.base.Apply object>, 'max_depth': <hyperopt.pyll.base.Apply object>, 'max_features': <hyperopt.pyll.base.Apply object>, 'max_leaf_nodes': <hyperopt.pyll.base.Apply object>, 'min_samples_split': <hyperopt.pyll.base.Apply object>, 'n_estimators': <hyperopt.pyll.base.Apply object>}, 'pipeline': {'features': <hyperopt.pyll.base.Apply object>, 'normalizer': <hyperopt.pyll.base.Apply object>, 'rebalance': <hyperopt.pyll.base.Apply object>}}, algo=<function suggest>, max_evals=9223372036854775807, max_time=300, trials=<hyperopt.base.Trials object>, rstate=<mtrand.RandomState object>, allow_trials_fmin=True, pass_expr_memo_ctrl=None, catch_eval_exceptions=False, verbose=0, return_argmin=True, points_to_evaluate=None, max_queue_len=1, show_progressbar=False)
    406             pass_expr_memo_ctrl=pass_expr_memo_ctrl,
    407             verbose=verbose,
    408             catch_eval_exceptions=catch_eval_exceptions,
    409             return_argmin=return_argmin,
    410             show_progressbar=show_progressbar,
--> 411             max_time=max_time
        max_time = 300
    412         )
    413 
    414     if trials is None:
    415         if points_to_evaluate is None:

...........................................................................
/home/aquemy/dev/dp_hyperparameters/extension/hyperopt/base.py in fmin(self=<hyperopt.base.Trials object>, fn=<functools.partial object>, space={'algorithm': {'bootstrap': <hyperopt.pyll.base.Apply object>, 'criterion': <hyperopt.pyll.base.Apply object>, 'max_depth': <hyperopt.pyll.base.Apply object>, 'max_features': <hyperopt.pyll.base.Apply object>, 'max_leaf_nodes': <hyperopt.pyll.base.Apply object>, 'min_samples_split': <hyperopt.pyll.base.Apply object>, 'n_estimators': <hyperopt.pyll.base.Apply object>}, 'pipeline': {'features': <hyperopt.pyll.base.Apply object>, 'normalizer': <hyperopt.pyll.base.Apply object>, 'rebalance': <hyperopt.pyll.base.Apply object>}}, algo=<function suggest>, max_evals=9223372036854775807, max_time=300, rstate=<mtrand.RandomState object>, verbose=0, pass_expr_memo_ctrl=None, catch_eval_exceptions=False, return_argmin=True, show_progressbar=False)
    636             verbose=verbose,
    637             allow_trials_fmin=False,  # -- prevent recursion
    638             pass_expr_memo_ctrl=pass_expr_memo_ctrl,
    639             catch_eval_exceptions=catch_eval_exceptions,
    640             return_argmin=return_argmin,
--> 641             show_progressbar=show_progressbar)
        show_progressbar = False
    642 
    643 
    644 def trials_from_docs(docs, validate=True, **kwargs):
    645     """Construct a Trials base class instance from a list of trials documents

...........................................................................
/home/aquemy/dev/dp_hyperparameters/extension/hyperopt/fmin.py in fmin(fn=<functools.partial object>, space={'algorithm': {'bootstrap': <hyperopt.pyll.base.Apply object>, 'criterion': <hyperopt.pyll.base.Apply object>, 'max_depth': <hyperopt.pyll.base.Apply object>, 'max_features': <hyperopt.pyll.base.Apply object>, 'max_leaf_nodes': <hyperopt.pyll.base.Apply object>, 'min_samples_split': <hyperopt.pyll.base.Apply object>, 'n_estimators': <hyperopt.pyll.base.Apply object>}, 'pipeline': {'features': <hyperopt.pyll.base.Apply object>, 'normalizer': <hyperopt.pyll.base.Apply object>, 'rebalance': <hyperopt.pyll.base.Apply object>}}, algo=<function suggest>, max_evals=9223372036854775807, max_time=300, trials=<hyperopt.base.Trials object>, rstate=<mtrand.RandomState object>, allow_trials_fmin=False, pass_expr_memo_ctrl=None, catch_eval_exceptions=False, verbose=0, return_argmin=True, points_to_evaluate=None, max_queue_len=1, show_progressbar=False)
    426                     verbose=verbose,
    427                     max_queue_len=max_queue_len,
    428                     show_progressbar=show_progressbar,
    429                     max_time=max_time)
    430     rval.catch_eval_exceptions = catch_eval_exceptions
--> 431     rval.exhaust()
        rval.exhaust = <bound method FMinIter.exhaust of <hyperopt.fmin.FMinIter object>>
    432     if return_argmin:
    433         return trials.argmin
    434     elif len(trials) > 0:
    435         # Only if there are some succesfull trail runs, return the best point in the evaluation space

...........................................................................
/home/aquemy/dev/dp_hyperparameters/extension/hyperopt/fmin.py in exhaust(self=<hyperopt.fmin.FMinIter object>)
    273             raise StopIteration()
    274         return self.trials
    275 
    276     def exhaust(self):
    277         n_done = len(self.trials)
--> 278         self.run(self.max_evals - n_done, block_until_done=self.asynchronous)
        self.run = <bound method FMinIter.run of <hyperopt.fmin.FMinIter object>>
        self.max_evals = 9223372036854775807
        n_done = 0
        self.asynchronous = False
    279         self.trials.refresh()
    280         return self
    281 
    282 

...........................................................................
/home/aquemy/dev/dp_hyperparameters/extension/hyperopt/fmin.py in run(self=<hyperopt.fmin.FMinIter object>, N=9223372036854775807, block_until_done=False)
    232                     if self.asynchronous:
    233                         # -- wait for workers to fill in the trials
    234                         time.sleep(self.poll_interval_secs)
    235                     else:
    236                         # -- loop over trials and do the jobs directly
--> 237                         self.serial_evaluate()
        self.serial_evaluate = <bound method FMinIter.serial_evaluate of <hyperopt.fmin.FMinIter object>>
    238                     try:
    239                         res = [d['result']['loss'] for d in
    240                                          self.trials.trials if
    241                                          d['result']['status'] == 'ok']

...........................................................................
/home/aquemy/dev/dp_hyperparameters/extension/hyperopt/fmin.py in serial_evaluate(self=<hyperopt.fmin.FMinIter object>, N=-1)
    138                 trial['book_time'] = now
    139                 trial['refresh_time'] = now
    140                 spec = base.spec_from_misc(trial['misc'])
    141                 ctrl = base.Ctrl(self.trials, current_trial=trial)
    142                 try:
--> 143                     result = self.domain.evaluate(spec, ctrl)
        result = undefined
        self.domain.evaluate = <bound method Domain.evaluate of <hyperopt.base.Domain object>>
        spec = {'bootstrap': 0, 'criterion': 1, 'features': 1, 'features_PCA_features__n_components': 0, 'max_depth': 2, 'max_features': 2, 'max_leaf_nodes': 3, 'min_samples_split': 2, 'n_estimators': 0, 'normalizer': 2, ...}
        ctrl = <hyperopt.base.Ctrl object>
    144                 except Exception as e:
    145                     logger.info('job exception: %s' % str(e))
    146                     trial['state'] = base.JOB_STATE_ERROR
    147                     trial['misc']['error'] = (str(type(e)), str(e))

...........................................................................
/home/aquemy/dev/dp_hyperparameters/extension/hyperopt/base.py in evaluate(self=<hyperopt.base.Domain object>, config={'bootstrap': 0, 'criterion': 1, 'features': 1, 'features_PCA_features__n_components': 0, 'max_depth': 2, 'max_features': 2, 'max_leaf_nodes': 3, 'min_samples_split': 2, 'n_estimators': 0, 'normalizer': 2, ...}, ctrl=<hyperopt.base.Ctrl object>, attach_attachments=True)
    841             #    or the normal Python part (self.fn)
    842             pyll_rval = pyll.rec_eval(
    843                 self.expr,
    844                 memo=memo,
    845                 print_node_on_error=self.rec_eval_print_node_on_error)
--> 846             rval = self.fn(pyll_rval)
        rval = undefined
        self.fn = <functools.partial object>
        pyll_rval = {'algorithm': {'bootstrap': True, 'criterion': 'entropy', 'max_depth': 3, 'max_features': 3, 'max_leaf_nodes': None, 'min_samples_split': 5, 'n_estimators': 10}, 'pipeline': {'features': ('features_PCA', {'features__n_components': 1}), 'normalizer': ('normalizer_PowerTransformer', {}), 'rebalance': ('rebalance_NoneType', {})}}
    847 
    848         if isinstance(rval, (float, int, np.number)):
    849             dict_rval = {'loss': float(rval), 'status': STATUS_OK}
    850         else:

...........................................................................
/home/aquemy/dev/dp_hyperparameters/extension/experiment/objective.py in objective_joint(wconfig={'algorithm': {'bootstrap': True, 'criterion': 'entropy', 'max_depth': 3, 'max_features': 3, 'max_leaf_nodes': None, 'min_samples_split': 5, 'n_estimators': 10}, 'pipeline': {'features': ('features_PCA', {'features__n_components': 1}), 'normalizer': ('normalizer_PowerTransformer', {}), 'rebalance': ('rebalance_NoneType', {})}}, algorithm='RandomForest', X=array([[1.799e+01, 1.038e+01, 1.228e+02, ..., 2...., ..., 0.000e+00, 2.871e-01,
        7.039e-02]]), y=array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,... 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1]), context={'baseline_score': 0.9545944602886527, 'baseline_score_std': 0.03716322883281839, 'best_config': {'algorithm': {'bootstrap': False, 'criterion': 'entropy', 'max_depth': None, 'max_features': 2, 'max_leaf_nodes': None, 'min_samples_split': 5, 'n_estimators': 10}, 'config_hash': {'algorithm': 'e7a772c2bc361aa61cf7eeb364a26dca2c9b89d6', 'config': 'afb67da069b544b0505b1e8c150edc7498ad37b4', 'pipeline': 'a43db4b4fc4c38610b7b5e484840d2e583089ff4'}, 'duration': 1.0073001384735107, 'iteration': 26, 'loss': 0.04749913577046061, 'max_history_score': 0.9525008642295394, 'max_history_score_std': 0.02225295065716913, 'max_history_step': 'joint', 'pipeline': {'features': ('features_PCA', {'features__n_components': 4}), 'normalizer': ('normalizer_StandardScaler', {'normalizer__with_mean': True, 'normalizer__with_std': False}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 7})}, 'score': 0.9525008642295394, ...}, 'history': [{'algorithm': {'bootstrap': True, 'criterion': 'entropy', 'max_depth': 4, 'max_features': 3, 'max_leaf_nodes': 3, 'min_samples_split': 2, 'n_estimators': 10}, 'config_hash': {'algorithm': '42527c4120073c2a488d1b8df28732f486d1578c', 'config': '51144ca42f9ea5ab2d8d58606e3b3e4d89c6d7b3', 'pipeline': '52f07bda29f9d3a95fabb87e591d0b2581ca8209'}, 'duration': 0.26703310012817383, 'iteration': 0, 'loss': 0.06655431682654922, 'max_history_score': 0.9334456831734508, 'max_history_score_std': 0.03819399139659311, 'max_history_step': 'joint', 'pipeline': {'features': ('features_NoneType', {}), 'normalizer': ('normalizer_RobustScaler', {'normalizer__quantile_range': (...), 'normalizer__with_centering': False, 'normalizer__with_scaling': False}), 'rebalance': ('rebalance_NearMiss', {'rebalance__n_neighbors': 1})}, 'score': 0.9334456831734508, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': None, 'max_features': 2, 'max_leaf_nodes': 3, 'min_samples_split': 2, 'n_estimators': 100}, 'config_hash': {'algorithm': '1b32258c630f07e01ab481ab925ab80aa757e482', 'config': '9e54ffcb6a727de032a0a2cd45c5cc37cc150756', 'pipeline': '37e72d4a97f5e784c9d3133e6379b91bfc3be803'}, 'duration': 1.3065669536590576, 'iteration': 1, 'loss': 0.05436435917379645, 'max_history_score': 0.9456356408262035, 'max_history_score_std': 0.040053650785990214, 'max_history_step': 'joint', 'pipeline': {'features': ('features_NoneType', {}), 'normalizer': ('normalizer_StandardScaler', {'normalizer__with_mean': True, 'normalizer__with_std': True}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 6})}, 'score': 0.9456356408262035, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'entropy', 'max_depth': 1, 'max_features': 1, 'max_leaf_nodes': 2, 'min_samples_split': 3, 'n_estimators': 25}, 'config_hash': {'algorithm': '68ab9059aa7ec74e0da87c81734b9664243b3eb4', 'config': 'e5241eee9ddf3f4ee29a4711f5bcc92a4d24cd09', 'pipeline': '62463de065924498cdcd2f2f1f7e68535cdb33a5'}, 'duration': 0.6592490673065186, 'iteration': 2, 'loss': 0.07695856019358727, 'max_history_score': 0.9456356408262035, 'max_history_score_std': 0.040053650785990214, 'max_history_step': 'joint', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 1, 'features__selectkbest__k': 2}), 'normalizer': ('normalizer_NoneType', {}), 'rebalance': ('rebalance_NoneType', {})}, 'score': 0.9230414398064127, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': 3, 'max_features': 2, 'max_leaf_nodes': 2, 'min_samples_split': 2, 'n_estimators': 25}, 'config_hash': {'algorithm': 'e3f1f7d7783557a38f40f0476369091edd87092b', 'config': '18ee4d3d1627472ec190326308d8755371a6dc62', 'pipeline': 'c6d1263e344ed8c71b2e6e4ba8e0db2fb6c777c0'}, 'duration': 0.879349946975708, 'iteration': 3, 'loss': 0.07535973554576114, 'max_history_score': 0.9456356408262035, 'max_history_score_std': 0.040053650785990214, 'max_history_step': 'joint', 'pipeline': {'features': ('features_NoneType', {}), 'normalizer': ('normalizer_RobustScaler', {'normalizer__quantile_range': (...), 'normalizer__with_centering': True, 'normalizer__with_scaling': True}), 'rebalance': ('rebalance_NearMiss', {'rebalance__n_neighbors': 2})}, 'score': 0.9246402644542389, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'gini', 'max_depth': 4, 'max_features': 2, 'max_leaf_nodes': 5, 'min_samples_split': 2, 'n_estimators': 50}, 'config_hash': {'algorithm': '47581af7253940f9647ad16d37347d34baf13e5f', 'config': '2af4f82b045c0c48ecb89d42728d1039fbff8878', 'pipeline': '2928b22ed834303cb7bac6e6608531eaddd7df67'}, 'duration': 4.372632026672363, 'iteration': 4, 'loss': 0.09121294615849984, 'max_history_score': 0.9456356408262035, 'max_history_score_std': 0.040053650785990214, 'max_history_step': 'joint', 'pipeline': {'features': ('features_NoneType', {}), 'normalizer': ('normalizer_MinMaxScaler', {}), 'rebalance': ('rebalance_CondensedNearestNeighbour', {'rebalance__n_neighbors': 2})}, 'score': 0.9087870538415002, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'entropy', 'max_depth': 2, 'max_features': 2, 'max_leaf_nodes': None, 'min_samples_split': 2, 'n_estimators': 10}, 'config_hash': {'algorithm': '0a85f98ca2d06103287f153633d88f7a0535e7e8', 'config': '17b2a1e5814f3e933137158708a5b6e9b2475495', 'pipeline': '95defa3bdd8357f11f872d3c280d50a6d8ee398d'}, 'duration': 2.625814914703369, 'iteration': 5, 'loss': 0.15471329185031535, 'max_history_score': 0.9456356408262035, 'max_history_score_std': 0.040053650785990214, 'max_history_step': 'joint', 'pipeline': {'features': ('features_SelectKBest', {'features__k': 2}), 'normalizer': ('normalizer_StandardScaler', {'normalizer__with_mean': False, 'normalizer__with_std': False}), 'rebalance': ('rebalance_CondensedNearestNeighbour', {'rebalance__n_neighbors': 1})}, 'score': 0.8452867081496847, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': 3, 'max_features': None, 'max_leaf_nodes': None, 'min_samples_split': 5, 'n_estimators': 75}, 'config_hash': {'algorithm': 'd7466a2c1d5cb3fa95029d73dc030f4c3c45a159', 'config': 'fa020a592ec5ac234f9f91aac28abc2cd1ec9d33', 'pipeline': '71e0d26f923d42cfe0e2fa748931ef2afe72ed86'}, 'duration': 3.62078595161438, 'iteration': 6, 'loss': 0.17066372828623277, 'max_history_score': 0.9456356408262035, 'max_history_score_std': 0.040053650785990214, 'max_history_step': 'joint', 'pipeline': {'features': ('features_SelectKBest', {'features__k': 1}), 'normalizer': ('normalizer_RobustScaler', {'normalizer__quantile_range': (...), 'normalizer__with_centering': True, 'normalizer__with_scaling': True}), 'rebalance': ('rebalance_CondensedNearestNeighbour', {'rebalance__n_neighbors': 1})}, 'score': 0.8293362717137672, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'entropy', 'max_depth': 3, 'max_features': 3, 'max_leaf_nodes': 5, 'min_samples_split': 5, 'n_estimators': 50}, 'config_hash': {'algorithm': '735caa9785596076014572a24050cde8dc338973', 'config': '0da4498002d6f452c59bb61756abb3ded841e786', 'pipeline': '51a53ea6ef5a2521ee65f76eb2da220ab7086513'}, 'duration': 0.6934049129486084, 'iteration': 7, 'loss': 0.06125875032408601, 'max_history_score': 0.9456356408262035, 'max_history_score_std': 0.040053650785990214, 'max_history_step': 'joint', 'pipeline': {'features': ('features_NoneType', {}), 'normalizer': ('normalizer_NoneType', {}), 'rebalance': ('rebalance_NearMiss', {'rebalance__n_neighbors': 3})}, 'score': 0.938741249675914, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': 4, 'max_features': 2, 'max_leaf_nodes': None, 'min_samples_split': 3, 'n_estimators': 75}, 'config_hash': {'algorithm': 'e71a1fe9515b6805f07914a61f2e7594be9e9afe', 'config': '344e4756fb1bec455d6af51d3727e33b0d27725f', 'pipeline': '248dad1d8b30a17a5de1d0bbdfe3e2acb7a1962b'}, 'duration': 1.3036692142486572, 'iteration': 8, 'loss': 0.06483125918243893, 'max_history_score': 0.9456356408262035, 'max_history_score_std': 0.040053650785990214, 'max_history_step': 'joint', 'pipeline': {'features': ('features_PCA', {'features__n_components': 2}), 'normalizer': ('normalizer_StandardScaler', {'normalizer__with_mean': False, 'normalizer__with_std': True}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 7})}, 'score': 0.9351687408175611, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'entropy', 'max_depth': 2, 'max_features': 2, 'max_leaf_nodes': 2, 'min_samples_split': 3, 'n_estimators': 10}, 'config_hash': {'algorithm': '0a507823f2ad8605ed5950e1fe61df0560f11a00', 'config': '4a538fdcf8e07f90e92a421c0d5c479d651629c7', 'pipeline': '5240329df25c9a533d025c1a401d49835a501b41'}, 'duration': 1.3821029663085938, 'iteration': 9, 'loss': 0.07006416904329793, 'max_history_score': 0.9456356408262035, 'max_history_score_std': 0.040053650785990214, 'max_history_step': 'joint', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 4, 'features__selectkbest__k': 2}), 'normalizer': ('normalizer_PowerTransformer', {}), 'rebalance': ('rebalance_NearMiss', {'rebalance__n_neighbors': 1})}, 'score': 0.9299358309567021, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'gini', 'max_depth': 1, 'max_features': 3, 'max_leaf_nodes': 5, 'min_samples_split': 3, 'n_estimators': 10}, 'config_hash': {'algorithm': 'd32739750d351948f8ff34a87c7d55b0c5e0d90f', 'config': 'c1609e71f1ce8486335adc70bb69a955580ba2c8', 'pipeline': 'f48b42ec5cf999279659966160a16353b75bdaa3'}, 'duration': 0.9055681228637695, 'iteration': 10, 'loss': 0.07532840722495904, 'max_history_score': 0.9456356408262035, 'max_history_score_std': 0.040053650785990214, 'max_history_step': 'joint', 'pipeline': {'features': ('features_PCA', {'features__n_components': 4}), 'normalizer': ('normalizer_PowerTransformer', {}), 'rebalance': ('rebalance_NearMiss', {'rebalance__n_neighbors': 1})}, 'score': 0.924671592775041, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': 3, 'max_features': 1, 'max_leaf_nodes': 5, 'min_samples_split': 3, 'n_estimators': 25}, 'config_hash': {'algorithm': 'f69bac35e71cbec1bfc1fb5942328a3390e7c252', 'config': 'abe36f188644e53e56ed3224236fa157107ed3b2', 'pipeline': 'aaf976c7c663a31fa039582d42f9e07101556a7c'}, 'duration': 0.764197826385498, 'iteration': 11, 'loss': 0.06818446979517778, 'max_history_score': 0.9456356408262035, 'max_history_score_std': 0.040053650785990214, 'max_history_step': 'joint', 'pipeline': {'features': ('features_NoneType', {}), 'normalizer': ('normalizer_PowerTransformer', {}), 'rebalance': ('rebalance_NoneType', {})}, 'score': 0.9318155302048222, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'entropy', 'max_depth': None, 'max_features': None, 'max_leaf_nodes': None, 'min_samples_split': 5, 'n_estimators': 25}, 'config_hash': {'algorithm': 'a0a27aec00db5ddf71eab96663f9bd61c845f5e3', 'config': '76aa002c3c9d4d9722466c60daf5119c18a41d2a', 'pipeline': '1ce34b7894ef342571d974bb19e8ec821a512c6b'}, 'duration': 1.1636500358581543, 'iteration': 12, 'loss': 0.12833700630887557, 'max_history_score': 0.9456356408262035, 'max_history_score_std': 0.040053650785990214, 'max_history_step': 'joint', 'pipeline': {'features': ('features_PCA', {'features__n_components': 1}), 'normalizer': ('normalizer_PowerTransformer', {}), 'rebalance': ('rebalance_NoneType', {})}, 'score': 0.8716629936911244, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'gini', 'max_depth': 1, 'max_features': 2, 'max_leaf_nodes': 2, 'min_samples_split': 2, 'n_estimators': 100}, 'config_hash': {'algorithm': '985c99dff1da9b2c87e4211c5335a9159aa9dbcb', 'config': 'f56a7a9e43a0a699e992dc1262e550b8b7c88538', 'pipeline': '5c934f6d9a8ad1f9afe762986a9cf2074fc95d79'}, 'duration': 2.235443115234375, 'iteration': 13, 'loss': 0.11414635727249167, 'max_history_score': 0.9456356408262035, 'max_history_score_std': 0.040053650785990214, 'max_history_step': 'joint', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 1, 'features__selectkbest__k': 1}), 'normalizer': ('normalizer_RobustScaler', {'normalizer__quantile_range': (...), 'normalizer__with_centering': False, 'normalizer__with_scaling': True}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 6})}, 'score': 0.8858536427275083, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'gini', 'max_depth': 1, 'max_features': 1, 'max_leaf_nodes': None, 'min_samples_split': 5, 'n_estimators': 10}, 'config_hash': {'algorithm': '7d74a39aac2579264a402aef2b6fa7943c19f3d3', 'config': '53f44c0ad925c5c08c25d4fadf5e9ee9d7c181cd', 'pipeline': '6eff5ef31d7d1d534db31913bb67529c8a24c42e'}, 'duration': 2.7847659587860107, 'iteration': 14, 'loss': 0.14061986863711007, 'max_history_score': 0.9456356408262035, 'max_history_score_std': 0.040053650785990214, 'max_history_step': 'joint', 'pipeline': {'features': ('features_PCA', {'features__n_components': 1}), 'normalizer': ('normalizer_RobustScaler', {'normalizer__quantile_range': (...), 'normalizer__with_centering': True, 'normalizer__with_scaling': True}), 'rebalance': ('rebalance_CondensedNearestNeighbour', {'rebalance__n_neighbors': 3})}, 'score': 0.8593801313628899, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'entropy', 'max_depth': 3, 'max_features': None, 'max_leaf_nodes': 5, 'min_samples_split': 2, 'n_estimators': 100}, 'config_hash': {'algorithm': 'c62d7c671832e4414b6b2d7c36cba5ddc83a0ed0', 'config': '5faee50671eaa0ac586722bff234e36a857e662d', 'pipeline': '8b29a55de2add78c49114b9bbe5e800e5524c59d'}, 'duration': 2.3916029930114746, 'iteration': 15, 'loss': 0.08770093336790252, 'max_history_score': 0.9456356408262035, 'max_history_score_std': 0.040053650785990214, 'max_history_step': 'joint', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 3, 'features__selectkbest__k': 4}), 'normalizer': ('normalizer_RobustScaler', {'normalizer__quantile_range': (...), 'normalizer__with_centering': True, 'normalizer__with_scaling': True}), 'rebalance': ('rebalance_NoneType', {})}, 'score': 0.9122990666320975, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': None, 'max_features': 1, 'max_leaf_nodes': 5, 'min_samples_split': 5, 'n_estimators': 10}, 'config_hash': {'algorithm': '290772bfb9b8ed15c48a72829e822fb0a07481d6', 'config': '9a04f25d8eb3db5b2f831abd341a6d384c73a957', 'pipeline': '1ce34b7894ef342571d974bb19e8ec821a512c6b'}, 'duration': 1.4364500045776367, 'iteration': 16, 'loss': 0.08948880822746508, 'max_history_score': 0.9456356408262035, 'max_history_score_std': 0.040053650785990214, 'max_history_step': 'joint', 'pipeline': {'features': ('features_PCA', {'features__n_components': 1}), 'normalizer': ('normalizer_PowerTransformer', {}), 'rebalance': ('rebalance_NoneType', {})}, 'score': 0.9105111917725349, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': 2, 'max_features': 3, 'max_leaf_nodes': 3, 'min_samples_split': 3, 'n_estimators': 100}, 'config_hash': {'algorithm': '7dab6d47f897c2961d3402eff844aff16a7d142a', 'config': '4dbfa2688b239be9f372d3e80223960ba9a1fbdd', 'pipeline': 'cdef51702798fa49f11c11d80baf3ab43d5358fc'}, 'duration': 0.9830451011657715, 'iteration': 17, 'loss': 1.0, 'max_history_score': 0.9456356408262035, 'max_history_score_std': 0.040053650785990214, 'max_history_step': 'joint', 'pipeline': {'features': ('features_SelectKBest', {'features__k': 2}), 'normalizer': ('normalizer_PowerTransformer', {}), 'rebalance': ('rebalance_NearMiss', {'rebalance__n_neighbors': 1})}, 'score': 0.0, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'entropy', 'max_depth': None, 'max_features': 3, 'max_leaf_nodes': None, 'min_samples_split': 5, 'n_estimators': 10}, 'config_hash': {'algorithm': 'def83e48be05ef92a37e1a90585820f2f67ff42b', 'config': '95902552cb76e9798f0fa58782bd72bd1cc272d7', 'pipeline': '1775187bf23f94f4fd0cc1e5c1ef665210edded5'}, 'duration': 2.0033559799194336, 'iteration': 18, 'loss': 0.04922327370149515, 'max_history_score': 0.9507767262985048, 'max_history_score_std': 0.028328108925705902, 'max_history_step': 'joint', 'pipeline': {'features': ('features_PCA', {'features__n_components': 4}), 'normalizer': ('normalizer_StandardScaler', {'normalizer__with_mean': True, 'normalizer__with_std': True}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 5})}, 'score': 0.9507767262985048, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'gini', 'max_depth': 1, 'max_features': 3, 'max_leaf_nodes': None, 'min_samples_split': 2, 'n_estimators': 50}, 'config_hash': {'algorithm': '4e9e3275f817df75115d9d7e3366980fc1b4cf13', 'config': '7770b19007b40bf13005d52eb81f87bc401f15b4', 'pipeline': 'c4dd111513ea35f97dd3aec3e8e7f6268ce035da'}, 'duration': 0.9069631099700928, 'iteration': 19, 'loss': 1.0, 'max_history_score': 0.9507767262985048, 'max_history_score_std': 0.028328108925705902, 'max_history_step': 'joint', 'pipeline': {'features': ('features_PCA', {'features__n_components': 2}), 'normalizer': ('normalizer_RobustScaler', {'normalizer__quantile_range': (...), 'normalizer__with_centering': False, 'normalizer__with_scaling': True}), 'rebalance': ('rebalance_NearMiss', {'rebalance__n_neighbors': 2})}, 'score': 0.0, ...}, ...], 'history_hash': ['51144ca42f9ea5ab2d8d58606e3b3e4d89c6d7b3', '9e54ffcb6a727de032a0a2cd45c5cc37cc150756', 'e5241eee9ddf3f4ee29a4711f5bcc92a4d24cd09', '18ee4d3d1627472ec190326308d8755371a6dc62', '2af4f82b045c0c48ecb89d42728d1039fbff8878', '17b2a1e5814f3e933137158708a5b6e9b2475495', 'fa020a592ec5ac234f9f91aac28abc2cd1ec9d33', '0da4498002d6f452c59bb61756abb3ded841e786', '344e4756fb1bec455d6af51d3727e33b0d27725f', '4a538fdcf8e07f90e92a421c0d5c479d651629c7', 'c1609e71f1ce8486335adc70bb69a955580ba2c8', 'abe36f188644e53e56ed3224236fa157107ed3b2', '76aa002c3c9d4d9722466c60daf5119c18a41d2a', 'f56a7a9e43a0a699e992dc1262e550b8b7c88538', '53f44c0ad925c5c08c25d4fadf5e9ee9d7c181cd', '5faee50671eaa0ac586722bff234e36a857e662d', '9a04f25d8eb3db5b2f831abd341a6d384c73a957', '4dbfa2688b239be9f372d3e80223960ba9a1fbdd', '95902552cb76e9798f0fa58782bd72bd1cc272d7', '7770b19007b40bf13005d52eb81f87bc401f15b4', ...], 'history_index': {'0da4498002d6f452c59bb61756abb3ded841e786': 7, '0f77a69b0a8d34861caf915a51dc588ff8d4efac': 61, '127553d555ed39231b8da3a1ce42d3902e30919b': 59, '17b2a1e5814f3e933137158708a5b6e9b2475495': 5, '18ee4d3d1627472ec190326308d8755371a6dc62': 3, '1b2267555a9226d7eb4df3c63dd12506da370f4d': 56, '28b2db1bf9b505aa8e490d811b55f6655178ede7': 67, '2af4f82b045c0c48ecb89d42728d1039fbff8878': 4, '2d054540972225f4f17fb36d63106b7bb5c406fe': 36, '306511091d7e5d6431b5e5a6320802c4c04cde44': 33, ...}, 'iteration': 83, 'max_history_score': 0.9525008642295394, 'max_history_score_std': 0.02225295065716913, 'max_history_step': 'joint'}, config={'algorithm': 'RandomForest', 'seed': 42, 'time': 300})
    108 
    109 def objective_algo(algo_config, current_pipeline_config, algorithm, X, y, context, config):
    110     return objective(current_pipeline_config, algo_config, algorithm, X, y, context, config, step='algorithm')
    111 
    112 def objective_joint(wconfig, algorithm, X, y, context, config):
--> 113     return objective(wconfig['pipeline'], wconfig['algorithm'], algorithm, X, y, context, config, step='joint')
        wconfig = {'algorithm': {'bootstrap': True, 'criterion': 'entropy', 'max_depth': 3, 'max_features': 3, 'max_leaf_nodes': None, 'min_samples_split': 5, 'n_estimators': 10}, 'pipeline': {'features': ('features_PCA', {'features__n_components': 1}), 'normalizer': ('normalizer_PowerTransformer', {}), 'rebalance': ('rebalance_NoneType', {})}}
        algorithm = 'RandomForest'
        X = array([[1.799e+01, 1.038e+01, 1.228e+02, ..., 2...., ..., 0.000e+00, 2.871e-01,
        7.039e-02]])
        y = array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,... 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1])
        context = {'baseline_score': 0.9545944602886527, 'baseline_score_std': 0.03716322883281839, 'best_config': {'algorithm': {'bootstrap': False, 'criterion': 'entropy', 'max_depth': None, 'max_features': 2, 'max_leaf_nodes': None, 'min_samples_split': 5, 'n_estimators': 10}, 'config_hash': {'algorithm': 'e7a772c2bc361aa61cf7eeb364a26dca2c9b89d6', 'config': 'afb67da069b544b0505b1e8c150edc7498ad37b4', 'pipeline': 'a43db4b4fc4c38610b7b5e484840d2e583089ff4'}, 'duration': 1.0073001384735107, 'iteration': 26, 'loss': 0.04749913577046061, 'max_history_score': 0.9525008642295394, 'max_history_score_std': 0.02225295065716913, 'max_history_step': 'joint', 'pipeline': {'features': ('features_PCA', {'features__n_components': 4}), 'normalizer': ('normalizer_StandardScaler', {'normalizer__with_mean': True, 'normalizer__with_std': False}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 7})}, 'score': 0.9525008642295394, ...}, 'history': [{'algorithm': {'bootstrap': True, 'criterion': 'entropy', 'max_depth': 4, 'max_features': 3, 'max_leaf_nodes': 3, 'min_samples_split': 2, 'n_estimators': 10}, 'config_hash': {'algorithm': '42527c4120073c2a488d1b8df28732f486d1578c', 'config': '51144ca42f9ea5ab2d8d58606e3b3e4d89c6d7b3', 'pipeline': '52f07bda29f9d3a95fabb87e591d0b2581ca8209'}, 'duration': 0.26703310012817383, 'iteration': 0, 'loss': 0.06655431682654922, 'max_history_score': 0.9334456831734508, 'max_history_score_std': 0.03819399139659311, 'max_history_step': 'joint', 'pipeline': {'features': ('features_NoneType', {}), 'normalizer': ('normalizer_RobustScaler', {'normalizer__quantile_range': (...), 'normalizer__with_centering': False, 'normalizer__with_scaling': False}), 'rebalance': ('rebalance_NearMiss', {'rebalance__n_neighbors': 1})}, 'score': 0.9334456831734508, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': None, 'max_features': 2, 'max_leaf_nodes': 3, 'min_samples_split': 2, 'n_estimators': 100}, 'config_hash': {'algorithm': '1b32258c630f07e01ab481ab925ab80aa757e482', 'config': '9e54ffcb6a727de032a0a2cd45c5cc37cc150756', 'pipeline': '37e72d4a97f5e784c9d3133e6379b91bfc3be803'}, 'duration': 1.3065669536590576, 'iteration': 1, 'loss': 0.05436435917379645, 'max_history_score': 0.9456356408262035, 'max_history_score_std': 0.040053650785990214, 'max_history_step': 'joint', 'pipeline': {'features': ('features_NoneType', {}), 'normalizer': ('normalizer_StandardScaler', {'normalizer__with_mean': True, 'normalizer__with_std': True}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 6})}, 'score': 0.9456356408262035, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'entropy', 'max_depth': 1, 'max_features': 1, 'max_leaf_nodes': 2, 'min_samples_split': 3, 'n_estimators': 25}, 'config_hash': {'algorithm': '68ab9059aa7ec74e0da87c81734b9664243b3eb4', 'config': 'e5241eee9ddf3f4ee29a4711f5bcc92a4d24cd09', 'pipeline': '62463de065924498cdcd2f2f1f7e68535cdb33a5'}, 'duration': 0.6592490673065186, 'iteration': 2, 'loss': 0.07695856019358727, 'max_history_score': 0.9456356408262035, 'max_history_score_std': 0.040053650785990214, 'max_history_step': 'joint', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 1, 'features__selectkbest__k': 2}), 'normalizer': ('normalizer_NoneType', {}), 'rebalance': ('rebalance_NoneType', {})}, 'score': 0.9230414398064127, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': 3, 'max_features': 2, 'max_leaf_nodes': 2, 'min_samples_split': 2, 'n_estimators': 25}, 'config_hash': {'algorithm': 'e3f1f7d7783557a38f40f0476369091edd87092b', 'config': '18ee4d3d1627472ec190326308d8755371a6dc62', 'pipeline': 'c6d1263e344ed8c71b2e6e4ba8e0db2fb6c777c0'}, 'duration': 0.879349946975708, 'iteration': 3, 'loss': 0.07535973554576114, 'max_history_score': 0.9456356408262035, 'max_history_score_std': 0.040053650785990214, 'max_history_step': 'joint', 'pipeline': {'features': ('features_NoneType', {}), 'normalizer': ('normalizer_RobustScaler', {'normalizer__quantile_range': (...), 'normalizer__with_centering': True, 'normalizer__with_scaling': True}), 'rebalance': ('rebalance_NearMiss', {'rebalance__n_neighbors': 2})}, 'score': 0.9246402644542389, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'gini', 'max_depth': 4, 'max_features': 2, 'max_leaf_nodes': 5, 'min_samples_split': 2, 'n_estimators': 50}, 'config_hash': {'algorithm': '47581af7253940f9647ad16d37347d34baf13e5f', 'config': '2af4f82b045c0c48ecb89d42728d1039fbff8878', 'pipeline': '2928b22ed834303cb7bac6e6608531eaddd7df67'}, 'duration': 4.372632026672363, 'iteration': 4, 'loss': 0.09121294615849984, 'max_history_score': 0.9456356408262035, 'max_history_score_std': 0.040053650785990214, 'max_history_step': 'joint', 'pipeline': {'features': ('features_NoneType', {}), 'normalizer': ('normalizer_MinMaxScaler', {}), 'rebalance': ('rebalance_CondensedNearestNeighbour', {'rebalance__n_neighbors': 2})}, 'score': 0.9087870538415002, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'entropy', 'max_depth': 2, 'max_features': 2, 'max_leaf_nodes': None, 'min_samples_split': 2, 'n_estimators': 10}, 'config_hash': {'algorithm': '0a85f98ca2d06103287f153633d88f7a0535e7e8', 'config': '17b2a1e5814f3e933137158708a5b6e9b2475495', 'pipeline': '95defa3bdd8357f11f872d3c280d50a6d8ee398d'}, 'duration': 2.625814914703369, 'iteration': 5, 'loss': 0.15471329185031535, 'max_history_score': 0.9456356408262035, 'max_history_score_std': 0.040053650785990214, 'max_history_step': 'joint', 'pipeline': {'features': ('features_SelectKBest', {'features__k': 2}), 'normalizer': ('normalizer_StandardScaler', {'normalizer__with_mean': False, 'normalizer__with_std': False}), 'rebalance': ('rebalance_CondensedNearestNeighbour', {'rebalance__n_neighbors': 1})}, 'score': 0.8452867081496847, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': 3, 'max_features': None, 'max_leaf_nodes': None, 'min_samples_split': 5, 'n_estimators': 75}, 'config_hash': {'algorithm': 'd7466a2c1d5cb3fa95029d73dc030f4c3c45a159', 'config': 'fa020a592ec5ac234f9f91aac28abc2cd1ec9d33', 'pipeline': '71e0d26f923d42cfe0e2fa748931ef2afe72ed86'}, 'duration': 3.62078595161438, 'iteration': 6, 'loss': 0.17066372828623277, 'max_history_score': 0.9456356408262035, 'max_history_score_std': 0.040053650785990214, 'max_history_step': 'joint', 'pipeline': {'features': ('features_SelectKBest', {'features__k': 1}), 'normalizer': ('normalizer_RobustScaler', {'normalizer__quantile_range': (...), 'normalizer__with_centering': True, 'normalizer__with_scaling': True}), 'rebalance': ('rebalance_CondensedNearestNeighbour', {'rebalance__n_neighbors': 1})}, 'score': 0.8293362717137672, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'entropy', 'max_depth': 3, 'max_features': 3, 'max_leaf_nodes': 5, 'min_samples_split': 5, 'n_estimators': 50}, 'config_hash': {'algorithm': '735caa9785596076014572a24050cde8dc338973', 'config': '0da4498002d6f452c59bb61756abb3ded841e786', 'pipeline': '51a53ea6ef5a2521ee65f76eb2da220ab7086513'}, 'duration': 0.6934049129486084, 'iteration': 7, 'loss': 0.06125875032408601, 'max_history_score': 0.9456356408262035, 'max_history_score_std': 0.040053650785990214, 'max_history_step': 'joint', 'pipeline': {'features': ('features_NoneType', {}), 'normalizer': ('normalizer_NoneType', {}), 'rebalance': ('rebalance_NearMiss', {'rebalance__n_neighbors': 3})}, 'score': 0.938741249675914, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': 4, 'max_features': 2, 'max_leaf_nodes': None, 'min_samples_split': 3, 'n_estimators': 75}, 'config_hash': {'algorithm': 'e71a1fe9515b6805f07914a61f2e7594be9e9afe', 'config': '344e4756fb1bec455d6af51d3727e33b0d27725f', 'pipeline': '248dad1d8b30a17a5de1d0bbdfe3e2acb7a1962b'}, 'duration': 1.3036692142486572, 'iteration': 8, 'loss': 0.06483125918243893, 'max_history_score': 0.9456356408262035, 'max_history_score_std': 0.040053650785990214, 'max_history_step': 'joint', 'pipeline': {'features': ('features_PCA', {'features__n_components': 2}), 'normalizer': ('normalizer_StandardScaler', {'normalizer__with_mean': False, 'normalizer__with_std': True}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 7})}, 'score': 0.9351687408175611, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'entropy', 'max_depth': 2, 'max_features': 2, 'max_leaf_nodes': 2, 'min_samples_split': 3, 'n_estimators': 10}, 'config_hash': {'algorithm': '0a507823f2ad8605ed5950e1fe61df0560f11a00', 'config': '4a538fdcf8e07f90e92a421c0d5c479d651629c7', 'pipeline': '5240329df25c9a533d025c1a401d49835a501b41'}, 'duration': 1.3821029663085938, 'iteration': 9, 'loss': 0.07006416904329793, 'max_history_score': 0.9456356408262035, 'max_history_score_std': 0.040053650785990214, 'max_history_step': 'joint', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 4, 'features__selectkbest__k': 2}), 'normalizer': ('normalizer_PowerTransformer', {}), 'rebalance': ('rebalance_NearMiss', {'rebalance__n_neighbors': 1})}, 'score': 0.9299358309567021, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'gini', 'max_depth': 1, 'max_features': 3, 'max_leaf_nodes': 5, 'min_samples_split': 3, 'n_estimators': 10}, 'config_hash': {'algorithm': 'd32739750d351948f8ff34a87c7d55b0c5e0d90f', 'config': 'c1609e71f1ce8486335adc70bb69a955580ba2c8', 'pipeline': 'f48b42ec5cf999279659966160a16353b75bdaa3'}, 'duration': 0.9055681228637695, 'iteration': 10, 'loss': 0.07532840722495904, 'max_history_score': 0.9456356408262035, 'max_history_score_std': 0.040053650785990214, 'max_history_step': 'joint', 'pipeline': {'features': ('features_PCA', {'features__n_components': 4}), 'normalizer': ('normalizer_PowerTransformer', {}), 'rebalance': ('rebalance_NearMiss', {'rebalance__n_neighbors': 1})}, 'score': 0.924671592775041, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': 3, 'max_features': 1, 'max_leaf_nodes': 5, 'min_samples_split': 3, 'n_estimators': 25}, 'config_hash': {'algorithm': 'f69bac35e71cbec1bfc1fb5942328a3390e7c252', 'config': 'abe36f188644e53e56ed3224236fa157107ed3b2', 'pipeline': 'aaf976c7c663a31fa039582d42f9e07101556a7c'}, 'duration': 0.764197826385498, 'iteration': 11, 'loss': 0.06818446979517778, 'max_history_score': 0.9456356408262035, 'max_history_score_std': 0.040053650785990214, 'max_history_step': 'joint', 'pipeline': {'features': ('features_NoneType', {}), 'normalizer': ('normalizer_PowerTransformer', {}), 'rebalance': ('rebalance_NoneType', {})}, 'score': 0.9318155302048222, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'entropy', 'max_depth': None, 'max_features': None, 'max_leaf_nodes': None, 'min_samples_split': 5, 'n_estimators': 25}, 'config_hash': {'algorithm': 'a0a27aec00db5ddf71eab96663f9bd61c845f5e3', 'config': '76aa002c3c9d4d9722466c60daf5119c18a41d2a', 'pipeline': '1ce34b7894ef342571d974bb19e8ec821a512c6b'}, 'duration': 1.1636500358581543, 'iteration': 12, 'loss': 0.12833700630887557, 'max_history_score': 0.9456356408262035, 'max_history_score_std': 0.040053650785990214, 'max_history_step': 'joint', 'pipeline': {'features': ('features_PCA', {'features__n_components': 1}), 'normalizer': ('normalizer_PowerTransformer', {}), 'rebalance': ('rebalance_NoneType', {})}, 'score': 0.8716629936911244, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'gini', 'max_depth': 1, 'max_features': 2, 'max_leaf_nodes': 2, 'min_samples_split': 2, 'n_estimators': 100}, 'config_hash': {'algorithm': '985c99dff1da9b2c87e4211c5335a9159aa9dbcb', 'config': 'f56a7a9e43a0a699e992dc1262e550b8b7c88538', 'pipeline': '5c934f6d9a8ad1f9afe762986a9cf2074fc95d79'}, 'duration': 2.235443115234375, 'iteration': 13, 'loss': 0.11414635727249167, 'max_history_score': 0.9456356408262035, 'max_history_score_std': 0.040053650785990214, 'max_history_step': 'joint', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 1, 'features__selectkbest__k': 1}), 'normalizer': ('normalizer_RobustScaler', {'normalizer__quantile_range': (...), 'normalizer__with_centering': False, 'normalizer__with_scaling': True}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 6})}, 'score': 0.8858536427275083, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'gini', 'max_depth': 1, 'max_features': 1, 'max_leaf_nodes': None, 'min_samples_split': 5, 'n_estimators': 10}, 'config_hash': {'algorithm': '7d74a39aac2579264a402aef2b6fa7943c19f3d3', 'config': '53f44c0ad925c5c08c25d4fadf5e9ee9d7c181cd', 'pipeline': '6eff5ef31d7d1d534db31913bb67529c8a24c42e'}, 'duration': 2.7847659587860107, 'iteration': 14, 'loss': 0.14061986863711007, 'max_history_score': 0.9456356408262035, 'max_history_score_std': 0.040053650785990214, 'max_history_step': 'joint', 'pipeline': {'features': ('features_PCA', {'features__n_components': 1}), 'normalizer': ('normalizer_RobustScaler', {'normalizer__quantile_range': (...), 'normalizer__with_centering': True, 'normalizer__with_scaling': True}), 'rebalance': ('rebalance_CondensedNearestNeighbour', {'rebalance__n_neighbors': 3})}, 'score': 0.8593801313628899, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'entropy', 'max_depth': 3, 'max_features': None, 'max_leaf_nodes': 5, 'min_samples_split': 2, 'n_estimators': 100}, 'config_hash': {'algorithm': 'c62d7c671832e4414b6b2d7c36cba5ddc83a0ed0', 'config': '5faee50671eaa0ac586722bff234e36a857e662d', 'pipeline': '8b29a55de2add78c49114b9bbe5e800e5524c59d'}, 'duration': 2.3916029930114746, 'iteration': 15, 'loss': 0.08770093336790252, 'max_history_score': 0.9456356408262035, 'max_history_score_std': 0.040053650785990214, 'max_history_step': 'joint', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 3, 'features__selectkbest__k': 4}), 'normalizer': ('normalizer_RobustScaler', {'normalizer__quantile_range': (...), 'normalizer__with_centering': True, 'normalizer__with_scaling': True}), 'rebalance': ('rebalance_NoneType', {})}, 'score': 0.9122990666320975, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': None, 'max_features': 1, 'max_leaf_nodes': 5, 'min_samples_split': 5, 'n_estimators': 10}, 'config_hash': {'algorithm': '290772bfb9b8ed15c48a72829e822fb0a07481d6', 'config': '9a04f25d8eb3db5b2f831abd341a6d384c73a957', 'pipeline': '1ce34b7894ef342571d974bb19e8ec821a512c6b'}, 'duration': 1.4364500045776367, 'iteration': 16, 'loss': 0.08948880822746508, 'max_history_score': 0.9456356408262035, 'max_history_score_std': 0.040053650785990214, 'max_history_step': 'joint', 'pipeline': {'features': ('features_PCA', {'features__n_components': 1}), 'normalizer': ('normalizer_PowerTransformer', {}), 'rebalance': ('rebalance_NoneType', {})}, 'score': 0.9105111917725349, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': 2, 'max_features': 3, 'max_leaf_nodes': 3, 'min_samples_split': 3, 'n_estimators': 100}, 'config_hash': {'algorithm': '7dab6d47f897c2961d3402eff844aff16a7d142a', 'config': '4dbfa2688b239be9f372d3e80223960ba9a1fbdd', 'pipeline': 'cdef51702798fa49f11c11d80baf3ab43d5358fc'}, 'duration': 0.9830451011657715, 'iteration': 17, 'loss': 1.0, 'max_history_score': 0.9456356408262035, 'max_history_score_std': 0.040053650785990214, 'max_history_step': 'joint', 'pipeline': {'features': ('features_SelectKBest', {'features__k': 2}), 'normalizer': ('normalizer_PowerTransformer', {}), 'rebalance': ('rebalance_NearMiss', {'rebalance__n_neighbors': 1})}, 'score': 0.0, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'entropy', 'max_depth': None, 'max_features': 3, 'max_leaf_nodes': None, 'min_samples_split': 5, 'n_estimators': 10}, 'config_hash': {'algorithm': 'def83e48be05ef92a37e1a90585820f2f67ff42b', 'config': '95902552cb76e9798f0fa58782bd72bd1cc272d7', 'pipeline': '1775187bf23f94f4fd0cc1e5c1ef665210edded5'}, 'duration': 2.0033559799194336, 'iteration': 18, 'loss': 0.04922327370149515, 'max_history_score': 0.9507767262985048, 'max_history_score_std': 0.028328108925705902, 'max_history_step': 'joint', 'pipeline': {'features': ('features_PCA', {'features__n_components': 4}), 'normalizer': ('normalizer_StandardScaler', {'normalizer__with_mean': True, 'normalizer__with_std': True}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 5})}, 'score': 0.9507767262985048, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'gini', 'max_depth': 1, 'max_features': 3, 'max_leaf_nodes': None, 'min_samples_split': 2, 'n_estimators': 50}, 'config_hash': {'algorithm': '4e9e3275f817df75115d9d7e3366980fc1b4cf13', 'config': '7770b19007b40bf13005d52eb81f87bc401f15b4', 'pipeline': 'c4dd111513ea35f97dd3aec3e8e7f6268ce035da'}, 'duration': 0.9069631099700928, 'iteration': 19, 'loss': 1.0, 'max_history_score': 0.9507767262985048, 'max_history_score_std': 0.028328108925705902, 'max_history_step': 'joint', 'pipeline': {'features': ('features_PCA', {'features__n_components': 2}), 'normalizer': ('normalizer_RobustScaler', {'normalizer__quantile_range': (...), 'normalizer__with_centering': False, 'normalizer__with_scaling': True}), 'rebalance': ('rebalance_NearMiss', {'rebalance__n_neighbors': 2})}, 'score': 0.0, ...}, ...], 'history_hash': ['51144ca42f9ea5ab2d8d58606e3b3e4d89c6d7b3', '9e54ffcb6a727de032a0a2cd45c5cc37cc150756', 'e5241eee9ddf3f4ee29a4711f5bcc92a4d24cd09', '18ee4d3d1627472ec190326308d8755371a6dc62', '2af4f82b045c0c48ecb89d42728d1039fbff8878', '17b2a1e5814f3e933137158708a5b6e9b2475495', 'fa020a592ec5ac234f9f91aac28abc2cd1ec9d33', '0da4498002d6f452c59bb61756abb3ded841e786', '344e4756fb1bec455d6af51d3727e33b0d27725f', '4a538fdcf8e07f90e92a421c0d5c479d651629c7', 'c1609e71f1ce8486335adc70bb69a955580ba2c8', 'abe36f188644e53e56ed3224236fa157107ed3b2', '76aa002c3c9d4d9722466c60daf5119c18a41d2a', 'f56a7a9e43a0a699e992dc1262e550b8b7c88538', '53f44c0ad925c5c08c25d4fadf5e9ee9d7c181cd', '5faee50671eaa0ac586722bff234e36a857e662d', '9a04f25d8eb3db5b2f831abd341a6d384c73a957', '4dbfa2688b239be9f372d3e80223960ba9a1fbdd', '95902552cb76e9798f0fa58782bd72bd1cc272d7', '7770b19007b40bf13005d52eb81f87bc401f15b4', ...], 'history_index': {'0da4498002d6f452c59bb61756abb3ded841e786': 7, '0f77a69b0a8d34861caf915a51dc588ff8d4efac': 61, '127553d555ed39231b8da3a1ce42d3902e30919b': 59, '17b2a1e5814f3e933137158708a5b6e9b2475495': 5, '18ee4d3d1627472ec190326308d8755371a6dc62': 3, '1b2267555a9226d7eb4df3c63dd12506da370f4d': 56, '28b2db1bf9b505aa8e490d811b55f6655178ede7': 67, '2af4f82b045c0c48ecb89d42728d1039fbff8878': 4, '2d054540972225f4f17fb36d63106b7bb5c406fe': 36, '306511091d7e5d6431b5e5a6320802c4c04cde44': 33, ...}, 'iteration': 83, 'max_history_score': 0.9525008642295394, 'max_history_score_std': 0.02225295065716913, 'max_history_step': 'joint'}
        config = {'algorithm': 'RandomForest', 'seed': 42, 'time': 300}
    114 
    115 
    116 def get_baseline_score(algorithm, X, y, seed):
    117     pipeline, _ = pipeline_conf_to_full_pipeline(

...........................................................................
/home/aquemy/dev/dp_hyperparameters/extension/experiment/objective.py in objective(pipeline_config={'features': ('features_PCA', {'features__n_components': 1}), 'normalizer': ('normalizer_PowerTransformer', {}), 'rebalance': ('rebalance_NoneType', {})}, algo_config={'bootstrap': True, 'criterion': 'entropy', 'max_depth': 3, 'max_features': 3, 'max_leaf_nodes': None, 'min_samples_split': 5, 'n_estimators': 10}, algorithm='RandomForest', X=array([[1.799e+01, 1.038e+01, 1.228e+02, ..., 2...., ..., 0.000e+00, 2.871e-01,
        7.039e-02]]), y=array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,... 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1]), context={'baseline_score': 0.9545944602886527, 'baseline_score_std': 0.03716322883281839, 'best_config': {'algorithm': {'bootstrap': False, 'criterion': 'entropy', 'max_depth': None, 'max_features': 2, 'max_leaf_nodes': None, 'min_samples_split': 5, 'n_estimators': 10}, 'config_hash': {'algorithm': 'e7a772c2bc361aa61cf7eeb364a26dca2c9b89d6', 'config': 'afb67da069b544b0505b1e8c150edc7498ad37b4', 'pipeline': 'a43db4b4fc4c38610b7b5e484840d2e583089ff4'}, 'duration': 1.0073001384735107, 'iteration': 26, 'loss': 0.04749913577046061, 'max_history_score': 0.9525008642295394, 'max_history_score_std': 0.02225295065716913, 'max_history_step': 'joint', 'pipeline': {'features': ('features_PCA', {'features__n_components': 4}), 'normalizer': ('normalizer_StandardScaler', {'normalizer__with_mean': True, 'normalizer__with_std': False}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 7})}, 'score': 0.9525008642295394, ...}, 'history': [{'algorithm': {'bootstrap': True, 'criterion': 'entropy', 'max_depth': 4, 'max_features': 3, 'max_leaf_nodes': 3, 'min_samples_split': 2, 'n_estimators': 10}, 'config_hash': {'algorithm': '42527c4120073c2a488d1b8df28732f486d1578c', 'config': '51144ca42f9ea5ab2d8d58606e3b3e4d89c6d7b3', 'pipeline': '52f07bda29f9d3a95fabb87e591d0b2581ca8209'}, 'duration': 0.26703310012817383, 'iteration': 0, 'loss': 0.06655431682654922, 'max_history_score': 0.9334456831734508, 'max_history_score_std': 0.03819399139659311, 'max_history_step': 'joint', 'pipeline': {'features': ('features_NoneType', {}), 'normalizer': ('normalizer_RobustScaler', {'normalizer__quantile_range': (...), 'normalizer__with_centering': False, 'normalizer__with_scaling': False}), 'rebalance': ('rebalance_NearMiss', {'rebalance__n_neighbors': 1})}, 'score': 0.9334456831734508, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': None, 'max_features': 2, 'max_leaf_nodes': 3, 'min_samples_split': 2, 'n_estimators': 100}, 'config_hash': {'algorithm': '1b32258c630f07e01ab481ab925ab80aa757e482', 'config': '9e54ffcb6a727de032a0a2cd45c5cc37cc150756', 'pipeline': '37e72d4a97f5e784c9d3133e6379b91bfc3be803'}, 'duration': 1.3065669536590576, 'iteration': 1, 'loss': 0.05436435917379645, 'max_history_score': 0.9456356408262035, 'max_history_score_std': 0.040053650785990214, 'max_history_step': 'joint', 'pipeline': {'features': ('features_NoneType', {}), 'normalizer': ('normalizer_StandardScaler', {'normalizer__with_mean': True, 'normalizer__with_std': True}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 6})}, 'score': 0.9456356408262035, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'entropy', 'max_depth': 1, 'max_features': 1, 'max_leaf_nodes': 2, 'min_samples_split': 3, 'n_estimators': 25}, 'config_hash': {'algorithm': '68ab9059aa7ec74e0da87c81734b9664243b3eb4', 'config': 'e5241eee9ddf3f4ee29a4711f5bcc92a4d24cd09', 'pipeline': '62463de065924498cdcd2f2f1f7e68535cdb33a5'}, 'duration': 0.6592490673065186, 'iteration': 2, 'loss': 0.07695856019358727, 'max_history_score': 0.9456356408262035, 'max_history_score_std': 0.040053650785990214, 'max_history_step': 'joint', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 1, 'features__selectkbest__k': 2}), 'normalizer': ('normalizer_NoneType', {}), 'rebalance': ('rebalance_NoneType', {})}, 'score': 0.9230414398064127, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': 3, 'max_features': 2, 'max_leaf_nodes': 2, 'min_samples_split': 2, 'n_estimators': 25}, 'config_hash': {'algorithm': 'e3f1f7d7783557a38f40f0476369091edd87092b', 'config': '18ee4d3d1627472ec190326308d8755371a6dc62', 'pipeline': 'c6d1263e344ed8c71b2e6e4ba8e0db2fb6c777c0'}, 'duration': 0.879349946975708, 'iteration': 3, 'loss': 0.07535973554576114, 'max_history_score': 0.9456356408262035, 'max_history_score_std': 0.040053650785990214, 'max_history_step': 'joint', 'pipeline': {'features': ('features_NoneType', {}), 'normalizer': ('normalizer_RobustScaler', {'normalizer__quantile_range': (...), 'normalizer__with_centering': True, 'normalizer__with_scaling': True}), 'rebalance': ('rebalance_NearMiss', {'rebalance__n_neighbors': 2})}, 'score': 0.9246402644542389, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'gini', 'max_depth': 4, 'max_features': 2, 'max_leaf_nodes': 5, 'min_samples_split': 2, 'n_estimators': 50}, 'config_hash': {'algorithm': '47581af7253940f9647ad16d37347d34baf13e5f', 'config': '2af4f82b045c0c48ecb89d42728d1039fbff8878', 'pipeline': '2928b22ed834303cb7bac6e6608531eaddd7df67'}, 'duration': 4.372632026672363, 'iteration': 4, 'loss': 0.09121294615849984, 'max_history_score': 0.9456356408262035, 'max_history_score_std': 0.040053650785990214, 'max_history_step': 'joint', 'pipeline': {'features': ('features_NoneType', {}), 'normalizer': ('normalizer_MinMaxScaler', {}), 'rebalance': ('rebalance_CondensedNearestNeighbour', {'rebalance__n_neighbors': 2})}, 'score': 0.9087870538415002, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'entropy', 'max_depth': 2, 'max_features': 2, 'max_leaf_nodes': None, 'min_samples_split': 2, 'n_estimators': 10}, 'config_hash': {'algorithm': '0a85f98ca2d06103287f153633d88f7a0535e7e8', 'config': '17b2a1e5814f3e933137158708a5b6e9b2475495', 'pipeline': '95defa3bdd8357f11f872d3c280d50a6d8ee398d'}, 'duration': 2.625814914703369, 'iteration': 5, 'loss': 0.15471329185031535, 'max_history_score': 0.9456356408262035, 'max_history_score_std': 0.040053650785990214, 'max_history_step': 'joint', 'pipeline': {'features': ('features_SelectKBest', {'features__k': 2}), 'normalizer': ('normalizer_StandardScaler', {'normalizer__with_mean': False, 'normalizer__with_std': False}), 'rebalance': ('rebalance_CondensedNearestNeighbour', {'rebalance__n_neighbors': 1})}, 'score': 0.8452867081496847, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': 3, 'max_features': None, 'max_leaf_nodes': None, 'min_samples_split': 5, 'n_estimators': 75}, 'config_hash': {'algorithm': 'd7466a2c1d5cb3fa95029d73dc030f4c3c45a159', 'config': 'fa020a592ec5ac234f9f91aac28abc2cd1ec9d33', 'pipeline': '71e0d26f923d42cfe0e2fa748931ef2afe72ed86'}, 'duration': 3.62078595161438, 'iteration': 6, 'loss': 0.17066372828623277, 'max_history_score': 0.9456356408262035, 'max_history_score_std': 0.040053650785990214, 'max_history_step': 'joint', 'pipeline': {'features': ('features_SelectKBest', {'features__k': 1}), 'normalizer': ('normalizer_RobustScaler', {'normalizer__quantile_range': (...), 'normalizer__with_centering': True, 'normalizer__with_scaling': True}), 'rebalance': ('rebalance_CondensedNearestNeighbour', {'rebalance__n_neighbors': 1})}, 'score': 0.8293362717137672, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'entropy', 'max_depth': 3, 'max_features': 3, 'max_leaf_nodes': 5, 'min_samples_split': 5, 'n_estimators': 50}, 'config_hash': {'algorithm': '735caa9785596076014572a24050cde8dc338973', 'config': '0da4498002d6f452c59bb61756abb3ded841e786', 'pipeline': '51a53ea6ef5a2521ee65f76eb2da220ab7086513'}, 'duration': 0.6934049129486084, 'iteration': 7, 'loss': 0.06125875032408601, 'max_history_score': 0.9456356408262035, 'max_history_score_std': 0.040053650785990214, 'max_history_step': 'joint', 'pipeline': {'features': ('features_NoneType', {}), 'normalizer': ('normalizer_NoneType', {}), 'rebalance': ('rebalance_NearMiss', {'rebalance__n_neighbors': 3})}, 'score': 0.938741249675914, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': 4, 'max_features': 2, 'max_leaf_nodes': None, 'min_samples_split': 3, 'n_estimators': 75}, 'config_hash': {'algorithm': 'e71a1fe9515b6805f07914a61f2e7594be9e9afe', 'config': '344e4756fb1bec455d6af51d3727e33b0d27725f', 'pipeline': '248dad1d8b30a17a5de1d0bbdfe3e2acb7a1962b'}, 'duration': 1.3036692142486572, 'iteration': 8, 'loss': 0.06483125918243893, 'max_history_score': 0.9456356408262035, 'max_history_score_std': 0.040053650785990214, 'max_history_step': 'joint', 'pipeline': {'features': ('features_PCA', {'features__n_components': 2}), 'normalizer': ('normalizer_StandardScaler', {'normalizer__with_mean': False, 'normalizer__with_std': True}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 7})}, 'score': 0.9351687408175611, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'entropy', 'max_depth': 2, 'max_features': 2, 'max_leaf_nodes': 2, 'min_samples_split': 3, 'n_estimators': 10}, 'config_hash': {'algorithm': '0a507823f2ad8605ed5950e1fe61df0560f11a00', 'config': '4a538fdcf8e07f90e92a421c0d5c479d651629c7', 'pipeline': '5240329df25c9a533d025c1a401d49835a501b41'}, 'duration': 1.3821029663085938, 'iteration': 9, 'loss': 0.07006416904329793, 'max_history_score': 0.9456356408262035, 'max_history_score_std': 0.040053650785990214, 'max_history_step': 'joint', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 4, 'features__selectkbest__k': 2}), 'normalizer': ('normalizer_PowerTransformer', {}), 'rebalance': ('rebalance_NearMiss', {'rebalance__n_neighbors': 1})}, 'score': 0.9299358309567021, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'gini', 'max_depth': 1, 'max_features': 3, 'max_leaf_nodes': 5, 'min_samples_split': 3, 'n_estimators': 10}, 'config_hash': {'algorithm': 'd32739750d351948f8ff34a87c7d55b0c5e0d90f', 'config': 'c1609e71f1ce8486335adc70bb69a955580ba2c8', 'pipeline': 'f48b42ec5cf999279659966160a16353b75bdaa3'}, 'duration': 0.9055681228637695, 'iteration': 10, 'loss': 0.07532840722495904, 'max_history_score': 0.9456356408262035, 'max_history_score_std': 0.040053650785990214, 'max_history_step': 'joint', 'pipeline': {'features': ('features_PCA', {'features__n_components': 4}), 'normalizer': ('normalizer_PowerTransformer', {}), 'rebalance': ('rebalance_NearMiss', {'rebalance__n_neighbors': 1})}, 'score': 0.924671592775041, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': 3, 'max_features': 1, 'max_leaf_nodes': 5, 'min_samples_split': 3, 'n_estimators': 25}, 'config_hash': {'algorithm': 'f69bac35e71cbec1bfc1fb5942328a3390e7c252', 'config': 'abe36f188644e53e56ed3224236fa157107ed3b2', 'pipeline': 'aaf976c7c663a31fa039582d42f9e07101556a7c'}, 'duration': 0.764197826385498, 'iteration': 11, 'loss': 0.06818446979517778, 'max_history_score': 0.9456356408262035, 'max_history_score_std': 0.040053650785990214, 'max_history_step': 'joint', 'pipeline': {'features': ('features_NoneType', {}), 'normalizer': ('normalizer_PowerTransformer', {}), 'rebalance': ('rebalance_NoneType', {})}, 'score': 0.9318155302048222, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'entropy', 'max_depth': None, 'max_features': None, 'max_leaf_nodes': None, 'min_samples_split': 5, 'n_estimators': 25}, 'config_hash': {'algorithm': 'a0a27aec00db5ddf71eab96663f9bd61c845f5e3', 'config': '76aa002c3c9d4d9722466c60daf5119c18a41d2a', 'pipeline': '1ce34b7894ef342571d974bb19e8ec821a512c6b'}, 'duration': 1.1636500358581543, 'iteration': 12, 'loss': 0.12833700630887557, 'max_history_score': 0.9456356408262035, 'max_history_score_std': 0.040053650785990214, 'max_history_step': 'joint', 'pipeline': {'features': ('features_PCA', {'features__n_components': 1}), 'normalizer': ('normalizer_PowerTransformer', {}), 'rebalance': ('rebalance_NoneType', {})}, 'score': 0.8716629936911244, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'gini', 'max_depth': 1, 'max_features': 2, 'max_leaf_nodes': 2, 'min_samples_split': 2, 'n_estimators': 100}, 'config_hash': {'algorithm': '985c99dff1da9b2c87e4211c5335a9159aa9dbcb', 'config': 'f56a7a9e43a0a699e992dc1262e550b8b7c88538', 'pipeline': '5c934f6d9a8ad1f9afe762986a9cf2074fc95d79'}, 'duration': 2.235443115234375, 'iteration': 13, 'loss': 0.11414635727249167, 'max_history_score': 0.9456356408262035, 'max_history_score_std': 0.040053650785990214, 'max_history_step': 'joint', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 1, 'features__selectkbest__k': 1}), 'normalizer': ('normalizer_RobustScaler', {'normalizer__quantile_range': (...), 'normalizer__with_centering': False, 'normalizer__with_scaling': True}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 6})}, 'score': 0.8858536427275083, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'gini', 'max_depth': 1, 'max_features': 1, 'max_leaf_nodes': None, 'min_samples_split': 5, 'n_estimators': 10}, 'config_hash': {'algorithm': '7d74a39aac2579264a402aef2b6fa7943c19f3d3', 'config': '53f44c0ad925c5c08c25d4fadf5e9ee9d7c181cd', 'pipeline': '6eff5ef31d7d1d534db31913bb67529c8a24c42e'}, 'duration': 2.7847659587860107, 'iteration': 14, 'loss': 0.14061986863711007, 'max_history_score': 0.9456356408262035, 'max_history_score_std': 0.040053650785990214, 'max_history_step': 'joint', 'pipeline': {'features': ('features_PCA', {'features__n_components': 1}), 'normalizer': ('normalizer_RobustScaler', {'normalizer__quantile_range': (...), 'normalizer__with_centering': True, 'normalizer__with_scaling': True}), 'rebalance': ('rebalance_CondensedNearestNeighbour', {'rebalance__n_neighbors': 3})}, 'score': 0.8593801313628899, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'entropy', 'max_depth': 3, 'max_features': None, 'max_leaf_nodes': 5, 'min_samples_split': 2, 'n_estimators': 100}, 'config_hash': {'algorithm': 'c62d7c671832e4414b6b2d7c36cba5ddc83a0ed0', 'config': '5faee50671eaa0ac586722bff234e36a857e662d', 'pipeline': '8b29a55de2add78c49114b9bbe5e800e5524c59d'}, 'duration': 2.3916029930114746, 'iteration': 15, 'loss': 0.08770093336790252, 'max_history_score': 0.9456356408262035, 'max_history_score_std': 0.040053650785990214, 'max_history_step': 'joint', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 3, 'features__selectkbest__k': 4}), 'normalizer': ('normalizer_RobustScaler', {'normalizer__quantile_range': (...), 'normalizer__with_centering': True, 'normalizer__with_scaling': True}), 'rebalance': ('rebalance_NoneType', {})}, 'score': 0.9122990666320975, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': None, 'max_features': 1, 'max_leaf_nodes': 5, 'min_samples_split': 5, 'n_estimators': 10}, 'config_hash': {'algorithm': '290772bfb9b8ed15c48a72829e822fb0a07481d6', 'config': '9a04f25d8eb3db5b2f831abd341a6d384c73a957', 'pipeline': '1ce34b7894ef342571d974bb19e8ec821a512c6b'}, 'duration': 1.4364500045776367, 'iteration': 16, 'loss': 0.08948880822746508, 'max_history_score': 0.9456356408262035, 'max_history_score_std': 0.040053650785990214, 'max_history_step': 'joint', 'pipeline': {'features': ('features_PCA', {'features__n_components': 1}), 'normalizer': ('normalizer_PowerTransformer', {}), 'rebalance': ('rebalance_NoneType', {})}, 'score': 0.9105111917725349, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': 2, 'max_features': 3, 'max_leaf_nodes': 3, 'min_samples_split': 3, 'n_estimators': 100}, 'config_hash': {'algorithm': '7dab6d47f897c2961d3402eff844aff16a7d142a', 'config': '4dbfa2688b239be9f372d3e80223960ba9a1fbdd', 'pipeline': 'cdef51702798fa49f11c11d80baf3ab43d5358fc'}, 'duration': 0.9830451011657715, 'iteration': 17, 'loss': 1.0, 'max_history_score': 0.9456356408262035, 'max_history_score_std': 0.040053650785990214, 'max_history_step': 'joint', 'pipeline': {'features': ('features_SelectKBest', {'features__k': 2}), 'normalizer': ('normalizer_PowerTransformer', {}), 'rebalance': ('rebalance_NearMiss', {'rebalance__n_neighbors': 1})}, 'score': 0.0, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'entropy', 'max_depth': None, 'max_features': 3, 'max_leaf_nodes': None, 'min_samples_split': 5, 'n_estimators': 10}, 'config_hash': {'algorithm': 'def83e48be05ef92a37e1a90585820f2f67ff42b', 'config': '95902552cb76e9798f0fa58782bd72bd1cc272d7', 'pipeline': '1775187bf23f94f4fd0cc1e5c1ef665210edded5'}, 'duration': 2.0033559799194336, 'iteration': 18, 'loss': 0.04922327370149515, 'max_history_score': 0.9507767262985048, 'max_history_score_std': 0.028328108925705902, 'max_history_step': 'joint', 'pipeline': {'features': ('features_PCA', {'features__n_components': 4}), 'normalizer': ('normalizer_StandardScaler', {'normalizer__with_mean': True, 'normalizer__with_std': True}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 5})}, 'score': 0.9507767262985048, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'gini', 'max_depth': 1, 'max_features': 3, 'max_leaf_nodes': None, 'min_samples_split': 2, 'n_estimators': 50}, 'config_hash': {'algorithm': '4e9e3275f817df75115d9d7e3366980fc1b4cf13', 'config': '7770b19007b40bf13005d52eb81f87bc401f15b4', 'pipeline': 'c4dd111513ea35f97dd3aec3e8e7f6268ce035da'}, 'duration': 0.9069631099700928, 'iteration': 19, 'loss': 1.0, 'max_history_score': 0.9507767262985048, 'max_history_score_std': 0.028328108925705902, 'max_history_step': 'joint', 'pipeline': {'features': ('features_PCA', {'features__n_components': 2}), 'normalizer': ('normalizer_RobustScaler', {'normalizer__quantile_range': (...), 'normalizer__with_centering': False, 'normalizer__with_scaling': True}), 'rebalance': ('rebalance_NearMiss', {'rebalance__n_neighbors': 2})}, 'score': 0.0, ...}, ...], 'history_hash': ['51144ca42f9ea5ab2d8d58606e3b3e4d89c6d7b3', '9e54ffcb6a727de032a0a2cd45c5cc37cc150756', 'e5241eee9ddf3f4ee29a4711f5bcc92a4d24cd09', '18ee4d3d1627472ec190326308d8755371a6dc62', '2af4f82b045c0c48ecb89d42728d1039fbff8878', '17b2a1e5814f3e933137158708a5b6e9b2475495', 'fa020a592ec5ac234f9f91aac28abc2cd1ec9d33', '0da4498002d6f452c59bb61756abb3ded841e786', '344e4756fb1bec455d6af51d3727e33b0d27725f', '4a538fdcf8e07f90e92a421c0d5c479d651629c7', 'c1609e71f1ce8486335adc70bb69a955580ba2c8', 'abe36f188644e53e56ed3224236fa157107ed3b2', '76aa002c3c9d4d9722466c60daf5119c18a41d2a', 'f56a7a9e43a0a699e992dc1262e550b8b7c88538', '53f44c0ad925c5c08c25d4fadf5e9ee9d7c181cd', '5faee50671eaa0ac586722bff234e36a857e662d', '9a04f25d8eb3db5b2f831abd341a6d384c73a957', '4dbfa2688b239be9f372d3e80223960ba9a1fbdd', '95902552cb76e9798f0fa58782bd72bd1cc272d7', '7770b19007b40bf13005d52eb81f87bc401f15b4', ...], 'history_index': {'0da4498002d6f452c59bb61756abb3ded841e786': 7, '0f77a69b0a8d34861caf915a51dc588ff8d4efac': 61, '127553d555ed39231b8da3a1ce42d3902e30919b': 59, '17b2a1e5814f3e933137158708a5b6e9b2475495': 5, '18ee4d3d1627472ec190326308d8755371a6dc62': 3, '1b2267555a9226d7eb4df3c63dd12506da370f4d': 56, '28b2db1bf9b505aa8e490d811b55f6655178ede7': 67, '2af4f82b045c0c48ecb89d42728d1039fbff8878': 4, '2d054540972225f4f17fb36d63106b7bb5c406fe': 36, '306511091d7e5d6431b5e5a6320802c4c04cde44': 33, ...}, 'iteration': 83, 'max_history_score': 0.9525008642295394, 'max_history_score_std': 0.02225295065716913, 'max_history_step': 'joint'}, config={'algorithm': 'RandomForest', 'seed': 42, 'time': 300}, step='joint')
     45                 y,
     46                 cv=10,
     47                 n_jobs=-1,
     48                 return_estimator=False,
     49                 return_train_score=False,
---> 50                 verbose=0)
     51         score = np.mean(scores['test_score'])
     52         std = np.std(scores['test_score'])
     53         status = STATUS_OK
     54     except Exception as e:

...........................................................................
/home/aquemy/.local/lib/python2.7/site-packages/sklearn/model_selection/_validation.py in cross_validate(estimator=Pipeline(memory=None,
     steps=[('normalizer',... random_state=42, verbose=0, warm_start=False))]), X=array([[1.799e+01, 1.038e+01, 1.228e+02, ..., 2...., ..., 0.000e+00, 2.871e-01,
        7.039e-02]]), y=array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,... 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1]), groups=None, scoring=None, cv=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1, verbose=0, fit_params=None, pre_dispatch='2*n_jobs', return_train_score=False, return_estimator=False, error_score='raise-deprecating')
    235         delayed(_fit_and_score)(
    236             clone(estimator), X, y, scorers, train, test, verbose, None,
    237             fit_params, return_train_score=return_train_score,
    238             return_times=True, return_estimator=return_estimator,
    239             error_score=error_score)
--> 240         for train, test in cv.split(X, y, groups))
        cv.split = <bound method StratifiedKFold.split of Stratifie...d(n_splits=10, random_state=None, shuffle=False)>
        X = array([[1.799e+01, 1.038e+01, 1.228e+02, ..., 2...., ..., 0.000e+00, 2.871e-01,
        7.039e-02]])
        y = array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,... 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1])
        groups = None
    241 
    242     zipped_scores = list(zip(*scores))
    243     if return_train_score:
    244         train_scores = zipped_scores.pop(0)

...........................................................................
/home/aquemy/.local/lib/python2.7/site-packages/sklearn/externals/joblib/parallel.py in __call__(self=Parallel(n_jobs=-1), iterable=<generator object <genexpr>>)
    925                 # No need to wait for async callbacks to trigger to
    926                 # consumption.
    927                 self._iterating = False
    928 
    929             with self._backend.retrieval_context():
--> 930                 self.retrieve()
        self.retrieve = <bound method Parallel.retrieve of Parallel(n_jobs=-1)>
    931             # Make sure that we get a last message telling us we are done
    932             elapsed_time = time.time() - self._start_time
    933             self._print('Done %3i out of %3i | elapsed: %s finished',
    934                         (len(self._output), len(self._output),

---------------------------------------------------------------------------
Joblib worker traceback:
---------------------------------------------------------------------------
ValueError                                         Mon Jun 17 13:33:39 2019
PID: 26222                                  Python 2.7.15+: /usr/bin/python
...........................................................................
/home/aquemy/.local/lib/python2.7/site-packages/sklearn/externals/joblib/parallel.py in __call__(self=<sklearn.externals.joblib.parallel.BatchedCalls object>)
    220     def __call__(self):
    221         # Set the default nested backend to self._backend but do not set the
    222         # change the default number of processes to -1
    223         with parallel_backend(self._backend, n_jobs=self._n_jobs):
    224             return [func(*args, **kwargs)
--> 225                     for func, args, kwargs in self.items]
        func = <function _fit_and_score>
        args = (Pipeline(memory=None,
     steps=[('normalizer',... random_state=42, verbose=0, warm_start=False))]), array([[1.799e+01, 1.038e+01, 1.228e+02, ..., 2...., ..., 0.000e+00, 2.871e-01,
        7.039e-02]]), array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,... 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1]), {'score': <function _passthrough_scorer>}, array([ 25,  26,  27,  28,  29,  30,  31,  32,  ..., 561, 562, 563, 564,
       565, 566, 567, 568]), array([  0,   1,   2,   3,   4,   5,   6,   7,  ...,  89,  90,
        92,  93,  96,  97,  98, 101]), 0, None, None)
        kwargs = {'error_score': 'raise-deprecating', 'return_estimator': False, 'return_times': True, 'return_train_score': False}
        self.items = [(<function _fit_and_score>, (Pipeline(memory=None,
     steps=[('normalizer',... random_state=42, verbose=0, warm_start=False))]), array([[1.799e+01, 1.038e+01, 1.228e+02, ..., 2...., ..., 0.000e+00, 2.871e-01,
        7.039e-02]]), array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,... 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1]), {'score': <function _passthrough_scorer>}, array([ 25,  26,  27,  28,  29,  30,  31,  32,  ..., 561, 562, 563, 564,
       565, 566, 567, 568]), array([  0,   1,   2,   3,   4,   5,   6,   7,  ...,  89,  90,
        92,  93,  96,  97,  98, 101]), 0, None, None), {'error_score': 'raise-deprecating', 'return_estimator': False, 'return_times': True, 'return_train_score': False})]
    226 
    227     def __len__(self):
    228         return self._size
    229 

...........................................................................
/home/aquemy/.local/lib/python2.7/site-packages/sklearn/model_selection/_validation.py in _fit_and_score(estimator=Pipeline(memory=None,
     steps=[('normalizer',... random_state=42, verbose=0, warm_start=False))]), X=array([[1.799e+01, 1.038e+01, 1.228e+02, ..., 2...., ..., 0.000e+00, 2.871e-01,
        7.039e-02]]), y=array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,... 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1]), scorer={'score': <function _passthrough_scorer>}, train=array([ 25,  26,  27,  28,  29,  30,  31,  32,  ..., 561, 562, 563, 564,
       565, 566, 567, 568]), test=array([  0,   1,   2,   3,   4,   5,   6,   7,  ...,  89,  90,
        92,  93,  96,  97,  98, 101]), verbose=0, parameters=None, fit_params={}, return_train_score=False, return_parameters=False, return_n_test_samples=False, return_times=True, return_estimator=False, error_score='raise-deprecating')
    523 
    524     try:
    525         if y_train is None:
    526             estimator.fit(X_train, **fit_params)
    527         else:
--> 528             estimator.fit(X_train, y_train, **fit_params)
        estimator.fit = <bound method Pipeline.fit of Pipeline(memory=No...random_state=42, verbose=0, warm_start=False))])>
        X_train = array([[1.714e+01, 1.640e+01, 1.160e+02, ..., 2...., ..., 0.000e+00, 2.871e-01,
        7.039e-02]])
        y_train = array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...1, 1, 1, 1, 1, 1, 1, 0, 0,
       0, 0, 0, 0, 1])
        fit_params = {}
    529 
    530     except Exception as e:
    531         # Note fit time as time until error
    532         fit_time = time.time() - start_time

...........................................................................
/usr/local/lib/python2.7/dist-packages/imblearn/pipeline.py in fit(self=Pipeline(memory=None,
     steps=[('normalizer',... random_state=42, verbose=0, warm_start=False))]), X=array([[1.714e+01, 1.640e+01, 1.160e+02, ..., 2...., ..., 0.000e+00, 2.871e-01,
        7.039e-02]]), y=array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...1, 1, 1, 1, 1, 1, 1, 0, 0,
       0, 0, 0, 0, 1]), **fit_params={})
    234             This estimator
    235 
    236         """
    237         Xt, yt, fit_params = self._fit(X, y, **fit_params)
    238         if self._final_estimator is not None:
--> 239             self._final_estimator.fit(Xt, yt, **fit_params)
        self._final_estimator.fit = <bound method RandomForestClassifier.fit of Rand...e, random_state=42, verbose=0, warm_start=False)>
        Xt = array([[ 6.67385514e+00],
       [ 3.89202763e+0...    [ 8.67790599e+00],
       [-8.06808284e+00]])
        yt = array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...1, 1, 1, 1, 1, 1, 1, 0, 0,
       0, 0, 0, 0, 1])
        fit_params = {}
    240         return self
    241 
    242     def fit_transform(self, X, y=None, **fit_params):
    243         """Fit the model and transform with the final estimator

...........................................................................
/home/aquemy/.local/lib/python2.7/site-packages/sklearn/ensemble/forest.py in fit(self=RandomForestClassifier(bootstrap=True, class_wei...se, random_state=42, verbose=0, warm_start=False), X=array([[ 6.6738553e+00],
       [ 3.8920276e+00]...60e+00],
       [-8.0680828e+00]], dtype=float32), y=array([[0.],
       [0.],
       [0.],
       [0...    [0.],
       [0.],
       [0.],
       [1.]]), sample_weight=None)
    328             trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,
    329                              **_joblib_parallel_args(prefer='threads'))(
    330                 delayed(_parallel_build_trees)(
    331                     t, self, X, y, sample_weight, i, len(trees),
    332                     verbose=self.verbose, class_weight=self.class_weight)
--> 333                 for i, t in enumerate(trees))
        i = 9
    334 
    335             # Collect newly grown trees
    336             self.estimators_.extend(trees)
    337 

...........................................................................
/home/aquemy/.local/lib/python2.7/site-packages/sklearn/externals/joblib/parallel.py in __call__(self=Parallel(n_jobs=1), iterable=<generator object <genexpr>>)
    912             # self._original_iterator is None, then this means either
    913             # that pre_dispatch == "all", n_jobs == 1 or that the first batch
    914             # was very quick and its callback already dispatched all the
    915             # remaining jobs.
    916             self._iterating = False
--> 917             if self.dispatch_one_batch(iterator):
        self.dispatch_one_batch = <bound method Parallel.dispatch_one_batch of Parallel(n_jobs=1)>
        iterator = <generator object <genexpr>>
    918                 self._iterating = self._original_iterator is not None
    919 
    920             while self.dispatch_one_batch(iterator):
    921                 pass

...........................................................................
/home/aquemy/.local/lib/python2.7/site-packages/sklearn/externals/joblib/parallel.py in dispatch_one_batch(self=Parallel(n_jobs=1), iterator=<generator object <genexpr>>)
    754                                  self._pickle_cache)
    755             if len(tasks) == 0:
    756                 # No more tasks available in the iterator: tell caller to stop.
    757                 return False
    758             else:
--> 759                 self._dispatch(tasks)
        self._dispatch = <bound method Parallel._dispatch of Parallel(n_jobs=1)>
        tasks = <sklearn.externals.joblib.parallel.BatchedCalls object>
    760                 return True
    761 
    762     def _print(self, msg, msg_args):
    763         """Display the message on stout or stderr depending on verbosity"""

...........................................................................
/home/aquemy/.local/lib/python2.7/site-packages/sklearn/externals/joblib/parallel.py in _dispatch(self=Parallel(n_jobs=1), batch=<sklearn.externals.joblib.parallel.BatchedCalls object>)
    711 
    712         dispatch_timestamp = time.time()
    713         cb = BatchCompletionCallBack(dispatch_timestamp, len(batch), self)
    714         with self._lock:
    715             job_idx = len(self._jobs)
--> 716             job = self._backend.apply_async(batch, callback=cb)
        job = undefined
        self._backend.apply_async = <bound method SequentialBackend.apply_async of <...lib._parallel_backends.SequentialBackend object>>
        batch = <sklearn.externals.joblib.parallel.BatchedCalls object>
        cb = <sklearn.externals.joblib.parallel.BatchCompletionCallBack object>
    717             # A job can complete so quickly than its callback is
    718             # called before we get here, causing self._jobs to
    719             # grow. To ensure correct results ordering, .insert is
    720             # used (rather than .append) in the following line

...........................................................................
/home/aquemy/.local/lib/python2.7/site-packages/sklearn/externals/joblib/_parallel_backends.py in apply_async(self=<sklearn.externals.joblib._parallel_backends.SequentialBackend object>, func=<sklearn.externals.joblib.parallel.BatchedCalls object>, callback=<sklearn.externals.joblib.parallel.BatchCompletionCallBack object>)
    177             raise ValueError('n_jobs == 0 in Parallel has no meaning')
    178         return 1
    179 
    180     def apply_async(self, func, callback=None):
    181         """Schedule a func to be run"""
--> 182         result = ImmediateResult(func)
        result = undefined
        func = <sklearn.externals.joblib.parallel.BatchedCalls object>
    183         if callback:
    184             callback(result)
    185         return result
    186 

...........................................................................
/home/aquemy/.local/lib/python2.7/site-packages/sklearn/externals/joblib/_parallel_backends.py in __init__(self=<sklearn.externals.joblib._parallel_backends.ImmediateResult object>, batch=<sklearn.externals.joblib.parallel.BatchedCalls object>)
    544 
    545 class ImmediateResult(object):
    546     def __init__(self, batch):
    547         # Don't delay the application, to avoid keeping the input
    548         # arguments in memory
--> 549         self.results = batch()
        self.results = undefined
        batch = <sklearn.externals.joblib.parallel.BatchedCalls object>
    550 
    551     def get(self):
    552         return self.results
    553 

...........................................................................
/home/aquemy/.local/lib/python2.7/site-packages/sklearn/externals/joblib/parallel.py in __call__(self=<sklearn.externals.joblib.parallel.BatchedCalls object>)
    220     def __call__(self):
    221         # Set the default nested backend to self._backend but do not set the
    222         # change the default number of processes to -1
    223         with parallel_backend(self._backend, n_jobs=self._n_jobs):
    224             return [func(*args, **kwargs)
--> 225                     for func, args, kwargs in self.items]
        func = <function _parallel_build_trees>
        args = (DecisionTreeClassifier(class_weight=None, criter...=False, random_state=1608637542, splitter='best'), RandomForestClassifier(bootstrap=True, class_wei...se, random_state=42, verbose=0, warm_start=False), array([[ 6.6738553e+00],
       [ 3.8920276e+00]...60e+00],
       [-8.0680828e+00]], dtype=float32), array([[0.],
       [0.],
       [0.],
       [0...    [0.],
       [0.],
       [0.],
       [1.]]), None, 0, 10)
        kwargs = {'class_weight': None, 'verbose': 0}
        self.items = [(<function _parallel_build_trees>, (DecisionTreeClassifier(class_weight=None, criter...=False, random_state=1608637542, splitter='best'), RandomForestClassifier(bootstrap=True, class_wei...se, random_state=42, verbose=0, warm_start=False), array([[ 6.6738553e+00],
       [ 3.8920276e+00]...60e+00],
       [-8.0680828e+00]], dtype=float32), array([[0.],
       [0.],
       [0.],
       [0...    [0.],
       [0.],
       [0.],
       [1.]]), None, 0, 10), {'class_weight': None, 'verbose': 0})]
    226 
    227     def __len__(self):
    228         return self._size
    229 

...........................................................................
/home/aquemy/.local/lib/python2.7/site-packages/sklearn/ensemble/forest.py in _parallel_build_trees(tree=DecisionTreeClassifier(class_weight=None, criter...=False, random_state=1608637542, splitter='best'), forest=RandomForestClassifier(bootstrap=True, class_wei...se, random_state=42, verbose=0, warm_start=False), X=array([[ 6.6738553e+00],
       [ 3.8920276e+00]...60e+00],
       [-8.0680828e+00]], dtype=float32), y=array([[0.],
       [0.],
       [0.],
       [0...    [0.],
       [0.],
       [0.],
       [1.]]), sample_weight=None, tree_idx=0, n_trees=10, verbose=0, class_weight=None)
    114                 simplefilter('ignore', DeprecationWarning)
    115                 curr_sample_weight *= compute_sample_weight('auto', y, indices)
    116         elif class_weight == 'balanced_subsample':
    117             curr_sample_weight *= compute_sample_weight('balanced', y, indices)
    118 
--> 119         tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)
        tree.fit = <bound method DecisionTreeClassifier.fit of Deci...False, random_state=1608637542, splitter='best')>
        X = array([[ 6.6738553e+00],
       [ 3.8920276e+00]...60e+00],
       [-8.0680828e+00]], dtype=float32)
        y = array([[0.],
       [0.],
       [0.],
       [0...    [0.],
       [0.],
       [0.],
       [1.]])
        sample_weight = None
        curr_sample_weight = array([4., 5., 1., 1., 2., 1., 1., 1., 2., 1., 0..., 1., 1., 0., 0., 1., 0., 0., 0., 0.,
       2.])
    120     else:
    121         tree.fit(X, y, sample_weight=sample_weight, check_input=False)
    122 
    123     return tree

...........................................................................
/home/aquemy/.local/lib/python2.7/site-packages/sklearn/tree/tree.py in fit(self=DecisionTreeClassifier(class_weight=None, criter...=False, random_state=1608637542, splitter='best'), X=array([[ 6.6738553e+00],
       [ 3.8920276e+00]...60e+00],
       [-8.0680828e+00]], dtype=float32), y=array([[0.],
       [0.],
       [0.],
       [0...    [0.],
       [0.],
       [0.],
       [1.]]), sample_weight=array([4., 5., 1., 1., 2., 1., 1., 1., 2., 1., 0..., 1., 1., 0., 0., 1., 0., 0., 0., 0.,
       2.]), check_input=False, X_idx_sorted=None)
    796 
    797         super(DecisionTreeClassifier, self).fit(
    798             X, y,
    799             sample_weight=sample_weight,
    800             check_input=check_input,
--> 801             X_idx_sorted=X_idx_sorted)
        X_idx_sorted = None
    802         return self
    803 
    804     def predict_proba(self, X, check_input=True):
    805         """Predict class probabilities of the input samples X.

...........................................................................
/home/aquemy/.local/lib/python2.7/site-packages/sklearn/tree/tree.py in fit(self=DecisionTreeClassifier(class_weight=None, criter...=False, random_state=1608637542, splitter='best'), X=array([[ 6.6738553e+00],
       [ 3.8920276e+00]...60e+00],
       [-8.0680828e+00]], dtype=float32), y=array([[0.],
       [0.],
       [0.],
       [0...    [0.],
       [0.],
       [0.],
       [1.]]), sample_weight=array([4., 5., 1., 1., 2., 1., 1., 1., 2., 1., 0..., 1., 1., 0., 0., 1., 0., 0., 0., 0.,
       2.]), check_input=False, X_idx_sorted=None)
    237         if not 0 <= self.min_weight_fraction_leaf <= 0.5:
    238             raise ValueError("min_weight_fraction_leaf must in [0, 0.5]")
    239         if max_depth <= 0:
    240             raise ValueError("max_depth must be greater than zero. ")
    241         if not (0 < max_features <= self.n_features_):
--> 242             raise ValueError("max_features must be in (0, n_features]")
    243         if not isinstance(max_leaf_nodes, (numbers.Integral, np.integer)):
    244             raise ValueError("max_leaf_nodes must be integral number but was "
    245                              "%r" % max_leaf_nodes)
    246         if -1 < max_leaf_nodes < 2:

ValueError: max_features must be in (0, n_features]
___________________________________________________________________________
Best score: 0.95250086423 (0.0222529506572) [J] | Score: 0.0 (0.0) [J]
Best score: 0.95250086423 (0.0222529506572) [J] | Score: 0.898135424769 (0.0330139407047) [J]
Best score: 0.95250086423 (0.0222529506572) [J] | Score: 0.945636721113 (0.0262393230468) [J]
Best score: 0.95250086423 (0.0222529506572) [J] | Score: 0.912048440066 (0.0410165760831) [J]
Best score: 0.95250086423 (0.0222529506572) [J] | Score: 0.919161049175 (0.0359366353819) [J]
JoblibValueError
___________________________________________________________________________
...........................................................................
/home/aquemy/dev/dp_hyperparameters/extension/main.py in <module>()
     27 
     28     serializer.serialize_results(scenario, policy)
     29 
     30 if __name__ == "__main__":
     31     args = cli.parse_args()
---> 32     main(args)

...........................................................................
/home/aquemy/dev/dp_hyperparameters/extension/main.py in main(args=Namespace(customize=[(['control', 'seed'], '42')...='./scenarios/rf_breast_joint.yaml', verbosity=0))
     21         test_size=0.4, 
     22         random_state=scenario['control']['seed']
     23     )
     24 
     25     policy = policies.initiate(scenario['setup']['policy'], config)
---> 26     policy.run(X,y)
        policy.run = <bound method Joint.run of <experiment.policies.joint.Joint object>>
        X = array([[1.799e+01, 1.038e+01, 1.228e+02, ..., 2...., ..., 0.000e+00, 2.871e-01,
        7.039e-02]])
        y = array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,... 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1])
     27 
     28     serializer.serialize_results(scenario, policy)
     29 
     30 if __name__ == "__main__":

...........................................................................
/home/aquemy/dev/dp_hyperparameters/extension/experiment/policies/joint.py in run(self=<experiment.policies.joint.Joint object>, X=array([[1.799e+01, 1.038e+01, 1.228e+02, ..., 2...., ..., 0.000e+00, 2.871e-01,
        7.039e-02]]), y=array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,... 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1]))
     32             algo=tpe.suggest, 
     33             max_evals=None,
     34             max_time=self.config['time'],     
     35             trials=trials,
     36             show_progressbar=False,
---> 37             verbose=0
     38         )
     39 
     40         best_config = self.context['best_config']
     41         super(Joint, self).display_step_results(best_config)

...........................................................................
/home/aquemy/dev/dp_hyperparameters/extension/hyperopt/fmin.py in fmin(fn=<functools.partial object>, space={'algorithm': {'bootstrap': <hyperopt.pyll.base.Apply object>, 'criterion': <hyperopt.pyll.base.Apply object>, 'max_depth': <hyperopt.pyll.base.Apply object>, 'max_features': <hyperopt.pyll.base.Apply object>, 'max_leaf_nodes': <hyperopt.pyll.base.Apply object>, 'min_samples_split': <hyperopt.pyll.base.Apply object>, 'n_estimators': <hyperopt.pyll.base.Apply object>}, 'pipeline': {'features': <hyperopt.pyll.base.Apply object>, 'normalizer': <hyperopt.pyll.base.Apply object>, 'rebalance': <hyperopt.pyll.base.Apply object>}}, algo=<function suggest>, max_evals=9223372036854775807, max_time=300, trials=<hyperopt.base.Trials object>, rstate=<mtrand.RandomState object>, allow_trials_fmin=True, pass_expr_memo_ctrl=None, catch_eval_exceptions=False, verbose=0, return_argmin=True, points_to_evaluate=None, max_queue_len=1, show_progressbar=False)
    406             pass_expr_memo_ctrl=pass_expr_memo_ctrl,
    407             verbose=verbose,
    408             catch_eval_exceptions=catch_eval_exceptions,
    409             return_argmin=return_argmin,
    410             show_progressbar=show_progressbar,
--> 411             max_time=max_time
        max_time = 300
    412         )
    413 
    414     if trials is None:
    415         if points_to_evaluate is None:

...........................................................................
/home/aquemy/dev/dp_hyperparameters/extension/hyperopt/base.py in fmin(self=<hyperopt.base.Trials object>, fn=<functools.partial object>, space={'algorithm': {'bootstrap': <hyperopt.pyll.base.Apply object>, 'criterion': <hyperopt.pyll.base.Apply object>, 'max_depth': <hyperopt.pyll.base.Apply object>, 'max_features': <hyperopt.pyll.base.Apply object>, 'max_leaf_nodes': <hyperopt.pyll.base.Apply object>, 'min_samples_split': <hyperopt.pyll.base.Apply object>, 'n_estimators': <hyperopt.pyll.base.Apply object>}, 'pipeline': {'features': <hyperopt.pyll.base.Apply object>, 'normalizer': <hyperopt.pyll.base.Apply object>, 'rebalance': <hyperopt.pyll.base.Apply object>}}, algo=<function suggest>, max_evals=9223372036854775807, max_time=300, rstate=<mtrand.RandomState object>, verbose=0, pass_expr_memo_ctrl=None, catch_eval_exceptions=False, return_argmin=True, show_progressbar=False)
    636             verbose=verbose,
    637             allow_trials_fmin=False,  # -- prevent recursion
    638             pass_expr_memo_ctrl=pass_expr_memo_ctrl,
    639             catch_eval_exceptions=catch_eval_exceptions,
    640             return_argmin=return_argmin,
--> 641             show_progressbar=show_progressbar)
        show_progressbar = False
    642 
    643 
    644 def trials_from_docs(docs, validate=True, **kwargs):
    645     """Construct a Trials base class instance from a list of trials documents

...........................................................................
/home/aquemy/dev/dp_hyperparameters/extension/hyperopt/fmin.py in fmin(fn=<functools.partial object>, space={'algorithm': {'bootstrap': <hyperopt.pyll.base.Apply object>, 'criterion': <hyperopt.pyll.base.Apply object>, 'max_depth': <hyperopt.pyll.base.Apply object>, 'max_features': <hyperopt.pyll.base.Apply object>, 'max_leaf_nodes': <hyperopt.pyll.base.Apply object>, 'min_samples_split': <hyperopt.pyll.base.Apply object>, 'n_estimators': <hyperopt.pyll.base.Apply object>}, 'pipeline': {'features': <hyperopt.pyll.base.Apply object>, 'normalizer': <hyperopt.pyll.base.Apply object>, 'rebalance': <hyperopt.pyll.base.Apply object>}}, algo=<function suggest>, max_evals=9223372036854775807, max_time=300, trials=<hyperopt.base.Trials object>, rstate=<mtrand.RandomState object>, allow_trials_fmin=False, pass_expr_memo_ctrl=None, catch_eval_exceptions=False, verbose=0, return_argmin=True, points_to_evaluate=None, max_queue_len=1, show_progressbar=False)
    426                     verbose=verbose,
    427                     max_queue_len=max_queue_len,
    428                     show_progressbar=show_progressbar,
    429                     max_time=max_time)
    430     rval.catch_eval_exceptions = catch_eval_exceptions
--> 431     rval.exhaust()
        rval.exhaust = <bound method FMinIter.exhaust of <hyperopt.fmin.FMinIter object>>
    432     if return_argmin:
    433         return trials.argmin
    434     elif len(trials) > 0:
    435         # Only if there are some succesfull trail runs, return the best point in the evaluation space

...........................................................................
/home/aquemy/dev/dp_hyperparameters/extension/hyperopt/fmin.py in exhaust(self=<hyperopt.fmin.FMinIter object>)
    273             raise StopIteration()
    274         return self.trials
    275 
    276     def exhaust(self):
    277         n_done = len(self.trials)
--> 278         self.run(self.max_evals - n_done, block_until_done=self.asynchronous)
        self.run = <bound method FMinIter.run of <hyperopt.fmin.FMinIter object>>
        self.max_evals = 9223372036854775807
        n_done = 0
        self.asynchronous = False
    279         self.trials.refresh()
    280         return self
    281 
    282 

...........................................................................
/home/aquemy/dev/dp_hyperparameters/extension/hyperopt/fmin.py in run(self=<hyperopt.fmin.FMinIter object>, N=9223372036854775807, block_until_done=False)
    232                     if self.asynchronous:
    233                         # -- wait for workers to fill in the trials
    234                         time.sleep(self.poll_interval_secs)
    235                     else:
    236                         # -- loop over trials and do the jobs directly
--> 237                         self.serial_evaluate()
        self.serial_evaluate = <bound method FMinIter.serial_evaluate of <hyperopt.fmin.FMinIter object>>
    238                     try:
    239                         res = [d['result']['loss'] for d in
    240                                          self.trials.trials if
    241                                          d['result']['status'] == 'ok']

...........................................................................
/home/aquemy/dev/dp_hyperparameters/extension/hyperopt/fmin.py in serial_evaluate(self=<hyperopt.fmin.FMinIter object>, N=-1)
    138                 trial['book_time'] = now
    139                 trial['refresh_time'] = now
    140                 spec = base.spec_from_misc(trial['misc'])
    141                 ctrl = base.Ctrl(self.trials, current_trial=trial)
    142                 try:
--> 143                     result = self.domain.evaluate(spec, ctrl)
        result = undefined
        self.domain.evaluate = <bound method Domain.evaluate of <hyperopt.base.Domain object>>
        spec = {'bootstrap': 0, 'criterion': 1, 'features': 2, 'features_SelectKBest_features__k': 1, 'max_depth': 3, 'max_features': 2, 'max_leaf_nodes': 3, 'min_samples_split': 0, 'n_estimators': 0, 'normalizer': 1, ...}
        ctrl = <hyperopt.base.Ctrl object>
    144                 except Exception as e:
    145                     logger.info('job exception: %s' % str(e))
    146                     trial['state'] = base.JOB_STATE_ERROR
    147                     trial['misc']['error'] = (str(type(e)), str(e))

...........................................................................
/home/aquemy/dev/dp_hyperparameters/extension/hyperopt/base.py in evaluate(self=<hyperopt.base.Domain object>, config={'bootstrap': 0, 'criterion': 1, 'features': 2, 'features_SelectKBest_features__k': 1, 'max_depth': 3, 'max_features': 2, 'max_leaf_nodes': 3, 'min_samples_split': 0, 'n_estimators': 0, 'normalizer': 1, ...}, ctrl=<hyperopt.base.Ctrl object>, attach_attachments=True)
    841             #    or the normal Python part (self.fn)
    842             pyll_rval = pyll.rec_eval(
    843                 self.expr,
    844                 memo=memo,
    845                 print_node_on_error=self.rec_eval_print_node_on_error)
--> 846             rval = self.fn(pyll_rval)
        rval = undefined
        self.fn = <functools.partial object>
        pyll_rval = {'algorithm': {'bootstrap': True, 'criterion': 'entropy', 'max_depth': 4, 'max_features': 3, 'max_leaf_nodes': None, 'min_samples_split': 2, 'n_estimators': 10}, 'pipeline': {'features': ('features_SelectKBest', {'features__k': 2}), 'normalizer': ('normalizer_StandardScaler', {'normalizer__with_mean': True, 'normalizer__with_std': True}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 5})}}
    847 
    848         if isinstance(rval, (float, int, np.number)):
    849             dict_rval = {'loss': float(rval), 'status': STATUS_OK}
    850         else:

...........................................................................
/home/aquemy/dev/dp_hyperparameters/extension/experiment/objective.py in objective_joint(wconfig={'algorithm': {'bootstrap': True, 'criterion': 'entropy', 'max_depth': 4, 'max_features': 3, 'max_leaf_nodes': None, 'min_samples_split': 2, 'n_estimators': 10}, 'pipeline': {'features': ('features_SelectKBest', {'features__k': 2}), 'normalizer': ('normalizer_StandardScaler', {'normalizer__with_mean': True, 'normalizer__with_std': True}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 5})}}, algorithm='RandomForest', X=array([[1.799e+01, 1.038e+01, 1.228e+02, ..., 2...., ..., 0.000e+00, 2.871e-01,
        7.039e-02]]), y=array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,... 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1]), context={'baseline_score': 0.9545944602886527, 'baseline_score_std': 0.03716322883281839, 'best_config': {'algorithm': {'bootstrap': False, 'criterion': 'entropy', 'max_depth': None, 'max_features': 2, 'max_leaf_nodes': None, 'min_samples_split': 5, 'n_estimators': 10}, 'config_hash': {'algorithm': 'e7a772c2bc361aa61cf7eeb364a26dca2c9b89d6', 'config': 'afb67da069b544b0505b1e8c150edc7498ad37b4', 'pipeline': 'a43db4b4fc4c38610b7b5e484840d2e583089ff4'}, 'duration': 1.0073001384735107, 'iteration': 26, 'loss': 0.04749913577046061, 'max_history_score': 0.9525008642295394, 'max_history_score_std': 0.02225295065716913, 'max_history_step': 'joint', 'pipeline': {'features': ('features_PCA', {'features__n_components': 4}), 'normalizer': ('normalizer_StandardScaler', {'normalizer__with_mean': True, 'normalizer__with_std': False}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 7})}, 'score': 0.9525008642295394, ...}, 'history': [{'algorithm': {'bootstrap': True, 'criterion': 'entropy', 'max_depth': 4, 'max_features': 3, 'max_leaf_nodes': 3, 'min_samples_split': 2, 'n_estimators': 10}, 'config_hash': {'algorithm': '42527c4120073c2a488d1b8df28732f486d1578c', 'config': '51144ca42f9ea5ab2d8d58606e3b3e4d89c6d7b3', 'pipeline': '52f07bda29f9d3a95fabb87e591d0b2581ca8209'}, 'duration': 0.26703310012817383, 'iteration': 0, 'loss': 0.06655431682654922, 'max_history_score': 0.9334456831734508, 'max_history_score_std': 0.03819399139659311, 'max_history_step': 'joint', 'pipeline': {'features': ('features_NoneType', {}), 'normalizer': ('normalizer_RobustScaler', {'normalizer__quantile_range': (...), 'normalizer__with_centering': False, 'normalizer__with_scaling': False}), 'rebalance': ('rebalance_NearMiss', {'rebalance__n_neighbors': 1})}, 'score': 0.9334456831734508, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': None, 'max_features': 2, 'max_leaf_nodes': 3, 'min_samples_split': 2, 'n_estimators': 100}, 'config_hash': {'algorithm': '1b32258c630f07e01ab481ab925ab80aa757e482', 'config': '9e54ffcb6a727de032a0a2cd45c5cc37cc150756', 'pipeline': '37e72d4a97f5e784c9d3133e6379b91bfc3be803'}, 'duration': 1.3065669536590576, 'iteration': 1, 'loss': 0.05436435917379645, 'max_history_score': 0.9456356408262035, 'max_history_score_std': 0.040053650785990214, 'max_history_step': 'joint', 'pipeline': {'features': ('features_NoneType', {}), 'normalizer': ('normalizer_StandardScaler', {'normalizer__with_mean': True, 'normalizer__with_std': True}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 6})}, 'score': 0.9456356408262035, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'entropy', 'max_depth': 1, 'max_features': 1, 'max_leaf_nodes': 2, 'min_samples_split': 3, 'n_estimators': 25}, 'config_hash': {'algorithm': '68ab9059aa7ec74e0da87c81734b9664243b3eb4', 'config': 'e5241eee9ddf3f4ee29a4711f5bcc92a4d24cd09', 'pipeline': '62463de065924498cdcd2f2f1f7e68535cdb33a5'}, 'duration': 0.6592490673065186, 'iteration': 2, 'loss': 0.07695856019358727, 'max_history_score': 0.9456356408262035, 'max_history_score_std': 0.040053650785990214, 'max_history_step': 'joint', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 1, 'features__selectkbest__k': 2}), 'normalizer': ('normalizer_NoneType', {}), 'rebalance': ('rebalance_NoneType', {})}, 'score': 0.9230414398064127, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': 3, 'max_features': 2, 'max_leaf_nodes': 2, 'min_samples_split': 2, 'n_estimators': 25}, 'config_hash': {'algorithm': 'e3f1f7d7783557a38f40f0476369091edd87092b', 'config': '18ee4d3d1627472ec190326308d8755371a6dc62', 'pipeline': 'c6d1263e344ed8c71b2e6e4ba8e0db2fb6c777c0'}, 'duration': 0.879349946975708, 'iteration': 3, 'loss': 0.07535973554576114, 'max_history_score': 0.9456356408262035, 'max_history_score_std': 0.040053650785990214, 'max_history_step': 'joint', 'pipeline': {'features': ('features_NoneType', {}), 'normalizer': ('normalizer_RobustScaler', {'normalizer__quantile_range': (...), 'normalizer__with_centering': True, 'normalizer__with_scaling': True}), 'rebalance': ('rebalance_NearMiss', {'rebalance__n_neighbors': 2})}, 'score': 0.9246402644542389, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'gini', 'max_depth': 4, 'max_features': 2, 'max_leaf_nodes': 5, 'min_samples_split': 2, 'n_estimators': 50}, 'config_hash': {'algorithm': '47581af7253940f9647ad16d37347d34baf13e5f', 'config': '2af4f82b045c0c48ecb89d42728d1039fbff8878', 'pipeline': '2928b22ed834303cb7bac6e6608531eaddd7df67'}, 'duration': 4.372632026672363, 'iteration': 4, 'loss': 0.09121294615849984, 'max_history_score': 0.9456356408262035, 'max_history_score_std': 0.040053650785990214, 'max_history_step': 'joint', 'pipeline': {'features': ('features_NoneType', {}), 'normalizer': ('normalizer_MinMaxScaler', {}), 'rebalance': ('rebalance_CondensedNearestNeighbour', {'rebalance__n_neighbors': 2})}, 'score': 0.9087870538415002, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'entropy', 'max_depth': 2, 'max_features': 2, 'max_leaf_nodes': None, 'min_samples_split': 2, 'n_estimators': 10}, 'config_hash': {'algorithm': '0a85f98ca2d06103287f153633d88f7a0535e7e8', 'config': '17b2a1e5814f3e933137158708a5b6e9b2475495', 'pipeline': '95defa3bdd8357f11f872d3c280d50a6d8ee398d'}, 'duration': 2.625814914703369, 'iteration': 5, 'loss': 0.15471329185031535, 'max_history_score': 0.9456356408262035, 'max_history_score_std': 0.040053650785990214, 'max_history_step': 'joint', 'pipeline': {'features': ('features_SelectKBest', {'features__k': 2}), 'normalizer': ('normalizer_StandardScaler', {'normalizer__with_mean': False, 'normalizer__with_std': False}), 'rebalance': ('rebalance_CondensedNearestNeighbour', {'rebalance__n_neighbors': 1})}, 'score': 0.8452867081496847, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': 3, 'max_features': None, 'max_leaf_nodes': None, 'min_samples_split': 5, 'n_estimators': 75}, 'config_hash': {'algorithm': 'd7466a2c1d5cb3fa95029d73dc030f4c3c45a159', 'config': 'fa020a592ec5ac234f9f91aac28abc2cd1ec9d33', 'pipeline': '71e0d26f923d42cfe0e2fa748931ef2afe72ed86'}, 'duration': 3.62078595161438, 'iteration': 6, 'loss': 0.17066372828623277, 'max_history_score': 0.9456356408262035, 'max_history_score_std': 0.040053650785990214, 'max_history_step': 'joint', 'pipeline': {'features': ('features_SelectKBest', {'features__k': 1}), 'normalizer': ('normalizer_RobustScaler', {'normalizer__quantile_range': (...), 'normalizer__with_centering': True, 'normalizer__with_scaling': True}), 'rebalance': ('rebalance_CondensedNearestNeighbour', {'rebalance__n_neighbors': 1})}, 'score': 0.8293362717137672, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'entropy', 'max_depth': 3, 'max_features': 3, 'max_leaf_nodes': 5, 'min_samples_split': 5, 'n_estimators': 50}, 'config_hash': {'algorithm': '735caa9785596076014572a24050cde8dc338973', 'config': '0da4498002d6f452c59bb61756abb3ded841e786', 'pipeline': '51a53ea6ef5a2521ee65f76eb2da220ab7086513'}, 'duration': 0.6934049129486084, 'iteration': 7, 'loss': 0.06125875032408601, 'max_history_score': 0.9456356408262035, 'max_history_score_std': 0.040053650785990214, 'max_history_step': 'joint', 'pipeline': {'features': ('features_NoneType', {}), 'normalizer': ('normalizer_NoneType', {}), 'rebalance': ('rebalance_NearMiss', {'rebalance__n_neighbors': 3})}, 'score': 0.938741249675914, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': 4, 'max_features': 2, 'max_leaf_nodes': None, 'min_samples_split': 3, 'n_estimators': 75}, 'config_hash': {'algorithm': 'e71a1fe9515b6805f07914a61f2e7594be9e9afe', 'config': '344e4756fb1bec455d6af51d3727e33b0d27725f', 'pipeline': '248dad1d8b30a17a5de1d0bbdfe3e2acb7a1962b'}, 'duration': 1.3036692142486572, 'iteration': 8, 'loss': 0.06483125918243893, 'max_history_score': 0.9456356408262035, 'max_history_score_std': 0.040053650785990214, 'max_history_step': 'joint', 'pipeline': {'features': ('features_PCA', {'features__n_components': 2}), 'normalizer': ('normalizer_StandardScaler', {'normalizer__with_mean': False, 'normalizer__with_std': True}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 7})}, 'score': 0.9351687408175611, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'entropy', 'max_depth': 2, 'max_features': 2, 'max_leaf_nodes': 2, 'min_samples_split': 3, 'n_estimators': 10}, 'config_hash': {'algorithm': '0a507823f2ad8605ed5950e1fe61df0560f11a00', 'config': '4a538fdcf8e07f90e92a421c0d5c479d651629c7', 'pipeline': '5240329df25c9a533d025c1a401d49835a501b41'}, 'duration': 1.3821029663085938, 'iteration': 9, 'loss': 0.07006416904329793, 'max_history_score': 0.9456356408262035, 'max_history_score_std': 0.040053650785990214, 'max_history_step': 'joint', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 4, 'features__selectkbest__k': 2}), 'normalizer': ('normalizer_PowerTransformer', {}), 'rebalance': ('rebalance_NearMiss', {'rebalance__n_neighbors': 1})}, 'score': 0.9299358309567021, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'gini', 'max_depth': 1, 'max_features': 3, 'max_leaf_nodes': 5, 'min_samples_split': 3, 'n_estimators': 10}, 'config_hash': {'algorithm': 'd32739750d351948f8ff34a87c7d55b0c5e0d90f', 'config': 'c1609e71f1ce8486335adc70bb69a955580ba2c8', 'pipeline': 'f48b42ec5cf999279659966160a16353b75bdaa3'}, 'duration': 0.9055681228637695, 'iteration': 10, 'loss': 0.07532840722495904, 'max_history_score': 0.9456356408262035, 'max_history_score_std': 0.040053650785990214, 'max_history_step': 'joint', 'pipeline': {'features': ('features_PCA', {'features__n_components': 4}), 'normalizer': ('normalizer_PowerTransformer', {}), 'rebalance': ('rebalance_NearMiss', {'rebalance__n_neighbors': 1})}, 'score': 0.924671592775041, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': 3, 'max_features': 1, 'max_leaf_nodes': 5, 'min_samples_split': 3, 'n_estimators': 25}, 'config_hash': {'algorithm': 'f69bac35e71cbec1bfc1fb5942328a3390e7c252', 'config': 'abe36f188644e53e56ed3224236fa157107ed3b2', 'pipeline': 'aaf976c7c663a31fa039582d42f9e07101556a7c'}, 'duration': 0.764197826385498, 'iteration': 11, 'loss': 0.06818446979517778, 'max_history_score': 0.9456356408262035, 'max_history_score_std': 0.040053650785990214, 'max_history_step': 'joint', 'pipeline': {'features': ('features_NoneType', {}), 'normalizer': ('normalizer_PowerTransformer', {}), 'rebalance': ('rebalance_NoneType', {})}, 'score': 0.9318155302048222, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'entropy', 'max_depth': None, 'max_features': None, 'max_leaf_nodes': None, 'min_samples_split': 5, 'n_estimators': 25}, 'config_hash': {'algorithm': 'a0a27aec00db5ddf71eab96663f9bd61c845f5e3', 'config': '76aa002c3c9d4d9722466c60daf5119c18a41d2a', 'pipeline': '1ce34b7894ef342571d974bb19e8ec821a512c6b'}, 'duration': 1.1636500358581543, 'iteration': 12, 'loss': 0.12833700630887557, 'max_history_score': 0.9456356408262035, 'max_history_score_std': 0.040053650785990214, 'max_history_step': 'joint', 'pipeline': {'features': ('features_PCA', {'features__n_components': 1}), 'normalizer': ('normalizer_PowerTransformer', {}), 'rebalance': ('rebalance_NoneType', {})}, 'score': 0.8716629936911244, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'gini', 'max_depth': 1, 'max_features': 2, 'max_leaf_nodes': 2, 'min_samples_split': 2, 'n_estimators': 100}, 'config_hash': {'algorithm': '985c99dff1da9b2c87e4211c5335a9159aa9dbcb', 'config': 'f56a7a9e43a0a699e992dc1262e550b8b7c88538', 'pipeline': '5c934f6d9a8ad1f9afe762986a9cf2074fc95d79'}, 'duration': 2.235443115234375, 'iteration': 13, 'loss': 0.11414635727249167, 'max_history_score': 0.9456356408262035, 'max_history_score_std': 0.040053650785990214, 'max_history_step': 'joint', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 1, 'features__selectkbest__k': 1}), 'normalizer': ('normalizer_RobustScaler', {'normalizer__quantile_range': (...), 'normalizer__with_centering': False, 'normalizer__with_scaling': True}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 6})}, 'score': 0.8858536427275083, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'gini', 'max_depth': 1, 'max_features': 1, 'max_leaf_nodes': None, 'min_samples_split': 5, 'n_estimators': 10}, 'config_hash': {'algorithm': '7d74a39aac2579264a402aef2b6fa7943c19f3d3', 'config': '53f44c0ad925c5c08c25d4fadf5e9ee9d7c181cd', 'pipeline': '6eff5ef31d7d1d534db31913bb67529c8a24c42e'}, 'duration': 2.7847659587860107, 'iteration': 14, 'loss': 0.14061986863711007, 'max_history_score': 0.9456356408262035, 'max_history_score_std': 0.040053650785990214, 'max_history_step': 'joint', 'pipeline': {'features': ('features_PCA', {'features__n_components': 1}), 'normalizer': ('normalizer_RobustScaler', {'normalizer__quantile_range': (...), 'normalizer__with_centering': True, 'normalizer__with_scaling': True}), 'rebalance': ('rebalance_CondensedNearestNeighbour', {'rebalance__n_neighbors': 3})}, 'score': 0.8593801313628899, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'entropy', 'max_depth': 3, 'max_features': None, 'max_leaf_nodes': 5, 'min_samples_split': 2, 'n_estimators': 100}, 'config_hash': {'algorithm': 'c62d7c671832e4414b6b2d7c36cba5ddc83a0ed0', 'config': '5faee50671eaa0ac586722bff234e36a857e662d', 'pipeline': '8b29a55de2add78c49114b9bbe5e800e5524c59d'}, 'duration': 2.3916029930114746, 'iteration': 15, 'loss': 0.08770093336790252, 'max_history_score': 0.9456356408262035, 'max_history_score_std': 0.040053650785990214, 'max_history_step': 'joint', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 3, 'features__selectkbest__k': 4}), 'normalizer': ('normalizer_RobustScaler', {'normalizer__quantile_range': (...), 'normalizer__with_centering': True, 'normalizer__with_scaling': True}), 'rebalance': ('rebalance_NoneType', {})}, 'score': 0.9122990666320975, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': None, 'max_features': 1, 'max_leaf_nodes': 5, 'min_samples_split': 5, 'n_estimators': 10}, 'config_hash': {'algorithm': '290772bfb9b8ed15c48a72829e822fb0a07481d6', 'config': '9a04f25d8eb3db5b2f831abd341a6d384c73a957', 'pipeline': '1ce34b7894ef342571d974bb19e8ec821a512c6b'}, 'duration': 1.4364500045776367, 'iteration': 16, 'loss': 0.08948880822746508, 'max_history_score': 0.9456356408262035, 'max_history_score_std': 0.040053650785990214, 'max_history_step': 'joint', 'pipeline': {'features': ('features_PCA', {'features__n_components': 1}), 'normalizer': ('normalizer_PowerTransformer', {}), 'rebalance': ('rebalance_NoneType', {})}, 'score': 0.9105111917725349, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': 2, 'max_features': 3, 'max_leaf_nodes': 3, 'min_samples_split': 3, 'n_estimators': 100}, 'config_hash': {'algorithm': '7dab6d47f897c2961d3402eff844aff16a7d142a', 'config': '4dbfa2688b239be9f372d3e80223960ba9a1fbdd', 'pipeline': 'cdef51702798fa49f11c11d80baf3ab43d5358fc'}, 'duration': 0.9830451011657715, 'iteration': 17, 'loss': 1.0, 'max_history_score': 0.9456356408262035, 'max_history_score_std': 0.040053650785990214, 'max_history_step': 'joint', 'pipeline': {'features': ('features_SelectKBest', {'features__k': 2}), 'normalizer': ('normalizer_PowerTransformer', {}), 'rebalance': ('rebalance_NearMiss', {'rebalance__n_neighbors': 1})}, 'score': 0.0, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'entropy', 'max_depth': None, 'max_features': 3, 'max_leaf_nodes': None, 'min_samples_split': 5, 'n_estimators': 10}, 'config_hash': {'algorithm': 'def83e48be05ef92a37e1a90585820f2f67ff42b', 'config': '95902552cb76e9798f0fa58782bd72bd1cc272d7', 'pipeline': '1775187bf23f94f4fd0cc1e5c1ef665210edded5'}, 'duration': 2.0033559799194336, 'iteration': 18, 'loss': 0.04922327370149515, 'max_history_score': 0.9507767262985048, 'max_history_score_std': 0.028328108925705902, 'max_history_step': 'joint', 'pipeline': {'features': ('features_PCA', {'features__n_components': 4}), 'normalizer': ('normalizer_StandardScaler', {'normalizer__with_mean': True, 'normalizer__with_std': True}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 5})}, 'score': 0.9507767262985048, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'gini', 'max_depth': 1, 'max_features': 3, 'max_leaf_nodes': None, 'min_samples_split': 2, 'n_estimators': 50}, 'config_hash': {'algorithm': '4e9e3275f817df75115d9d7e3366980fc1b4cf13', 'config': '7770b19007b40bf13005d52eb81f87bc401f15b4', 'pipeline': 'c4dd111513ea35f97dd3aec3e8e7f6268ce035da'}, 'duration': 0.9069631099700928, 'iteration': 19, 'loss': 1.0, 'max_history_score': 0.9507767262985048, 'max_history_score_std': 0.028328108925705902, 'max_history_step': 'joint', 'pipeline': {'features': ('features_PCA', {'features__n_components': 2}), 'normalizer': ('normalizer_RobustScaler', {'normalizer__quantile_range': (...), 'normalizer__with_centering': False, 'normalizer__with_scaling': True}), 'rebalance': ('rebalance_NearMiss', {'rebalance__n_neighbors': 2})}, 'score': 0.0, ...}, ...], 'history_hash': ['51144ca42f9ea5ab2d8d58606e3b3e4d89c6d7b3', '9e54ffcb6a727de032a0a2cd45c5cc37cc150756', 'e5241eee9ddf3f4ee29a4711f5bcc92a4d24cd09', '18ee4d3d1627472ec190326308d8755371a6dc62', '2af4f82b045c0c48ecb89d42728d1039fbff8878', '17b2a1e5814f3e933137158708a5b6e9b2475495', 'fa020a592ec5ac234f9f91aac28abc2cd1ec9d33', '0da4498002d6f452c59bb61756abb3ded841e786', '344e4756fb1bec455d6af51d3727e33b0d27725f', '4a538fdcf8e07f90e92a421c0d5c479d651629c7', 'c1609e71f1ce8486335adc70bb69a955580ba2c8', 'abe36f188644e53e56ed3224236fa157107ed3b2', '76aa002c3c9d4d9722466c60daf5119c18a41d2a', 'f56a7a9e43a0a699e992dc1262e550b8b7c88538', '53f44c0ad925c5c08c25d4fadf5e9ee9d7c181cd', '5faee50671eaa0ac586722bff234e36a857e662d', '9a04f25d8eb3db5b2f831abd341a6d384c73a957', '4dbfa2688b239be9f372d3e80223960ba9a1fbdd', '95902552cb76e9798f0fa58782bd72bd1cc272d7', '7770b19007b40bf13005d52eb81f87bc401f15b4', ...], 'history_index': {'0da4498002d6f452c59bb61756abb3ded841e786': 7, '0f77a69b0a8d34861caf915a51dc588ff8d4efac': 61, '127553d555ed39231b8da3a1ce42d3902e30919b': 59, '17b2a1e5814f3e933137158708a5b6e9b2475495': 5, '18ee4d3d1627472ec190326308d8755371a6dc62': 3, '1b2267555a9226d7eb4df3c63dd12506da370f4d': 56, '28b2db1bf9b505aa8e490d811b55f6655178ede7': 67, '2af4f82b045c0c48ecb89d42728d1039fbff8878': 4, '2d054540972225f4f17fb36d63106b7bb5c406fe': 36, '306511091d7e5d6431b5e5a6320802c4c04cde44': 33, ...}, 'iteration': 88, 'max_history_score': 0.9525008642295394, 'max_history_score_std': 0.02225295065716913, 'max_history_step': 'joint'}, config={'algorithm': 'RandomForest', 'seed': 42, 'time': 300})
    108 
    109 def objective_algo(algo_config, current_pipeline_config, algorithm, X, y, context, config):
    110     return objective(current_pipeline_config, algo_config, algorithm, X, y, context, config, step='algorithm')
    111 
    112 def objective_joint(wconfig, algorithm, X, y, context, config):
--> 113     return objective(wconfig['pipeline'], wconfig['algorithm'], algorithm, X, y, context, config, step='joint')
        wconfig = {'algorithm': {'bootstrap': True, 'criterion': 'entropy', 'max_depth': 4, 'max_features': 3, 'max_leaf_nodes': None, 'min_samples_split': 2, 'n_estimators': 10}, 'pipeline': {'features': ('features_SelectKBest', {'features__k': 2}), 'normalizer': ('normalizer_StandardScaler', {'normalizer__with_mean': True, 'normalizer__with_std': True}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 5})}}
        algorithm = 'RandomForest'
        X = array([[1.799e+01, 1.038e+01, 1.228e+02, ..., 2...., ..., 0.000e+00, 2.871e-01,
        7.039e-02]])
        y = array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,... 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1])
        context = {'baseline_score': 0.9545944602886527, 'baseline_score_std': 0.03716322883281839, 'best_config': {'algorithm': {'bootstrap': False, 'criterion': 'entropy', 'max_depth': None, 'max_features': 2, 'max_leaf_nodes': None, 'min_samples_split': 5, 'n_estimators': 10}, 'config_hash': {'algorithm': 'e7a772c2bc361aa61cf7eeb364a26dca2c9b89d6', 'config': 'afb67da069b544b0505b1e8c150edc7498ad37b4', 'pipeline': 'a43db4b4fc4c38610b7b5e484840d2e583089ff4'}, 'duration': 1.0073001384735107, 'iteration': 26, 'loss': 0.04749913577046061, 'max_history_score': 0.9525008642295394, 'max_history_score_std': 0.02225295065716913, 'max_history_step': 'joint', 'pipeline': {'features': ('features_PCA', {'features__n_components': 4}), 'normalizer': ('normalizer_StandardScaler', {'normalizer__with_mean': True, 'normalizer__with_std': False}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 7})}, 'score': 0.9525008642295394, ...}, 'history': [{'algorithm': {'bootstrap': True, 'criterion': 'entropy', 'max_depth': 4, 'max_features': 3, 'max_leaf_nodes': 3, 'min_samples_split': 2, 'n_estimators': 10}, 'config_hash': {'algorithm': '42527c4120073c2a488d1b8df28732f486d1578c', 'config': '51144ca42f9ea5ab2d8d58606e3b3e4d89c6d7b3', 'pipeline': '52f07bda29f9d3a95fabb87e591d0b2581ca8209'}, 'duration': 0.26703310012817383, 'iteration': 0, 'loss': 0.06655431682654922, 'max_history_score': 0.9334456831734508, 'max_history_score_std': 0.03819399139659311, 'max_history_step': 'joint', 'pipeline': {'features': ('features_NoneType', {}), 'normalizer': ('normalizer_RobustScaler', {'normalizer__quantile_range': (...), 'normalizer__with_centering': False, 'normalizer__with_scaling': False}), 'rebalance': ('rebalance_NearMiss', {'rebalance__n_neighbors': 1})}, 'score': 0.9334456831734508, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': None, 'max_features': 2, 'max_leaf_nodes': 3, 'min_samples_split': 2, 'n_estimators': 100}, 'config_hash': {'algorithm': '1b32258c630f07e01ab481ab925ab80aa757e482', 'config': '9e54ffcb6a727de032a0a2cd45c5cc37cc150756', 'pipeline': '37e72d4a97f5e784c9d3133e6379b91bfc3be803'}, 'duration': 1.3065669536590576, 'iteration': 1, 'loss': 0.05436435917379645, 'max_history_score': 0.9456356408262035, 'max_history_score_std': 0.040053650785990214, 'max_history_step': 'joint', 'pipeline': {'features': ('features_NoneType', {}), 'normalizer': ('normalizer_StandardScaler', {'normalizer__with_mean': True, 'normalizer__with_std': True}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 6})}, 'score': 0.9456356408262035, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'entropy', 'max_depth': 1, 'max_features': 1, 'max_leaf_nodes': 2, 'min_samples_split': 3, 'n_estimators': 25}, 'config_hash': {'algorithm': '68ab9059aa7ec74e0da87c81734b9664243b3eb4', 'config': 'e5241eee9ddf3f4ee29a4711f5bcc92a4d24cd09', 'pipeline': '62463de065924498cdcd2f2f1f7e68535cdb33a5'}, 'duration': 0.6592490673065186, 'iteration': 2, 'loss': 0.07695856019358727, 'max_history_score': 0.9456356408262035, 'max_history_score_std': 0.040053650785990214, 'max_history_step': 'joint', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 1, 'features__selectkbest__k': 2}), 'normalizer': ('normalizer_NoneType', {}), 'rebalance': ('rebalance_NoneType', {})}, 'score': 0.9230414398064127, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': 3, 'max_features': 2, 'max_leaf_nodes': 2, 'min_samples_split': 2, 'n_estimators': 25}, 'config_hash': {'algorithm': 'e3f1f7d7783557a38f40f0476369091edd87092b', 'config': '18ee4d3d1627472ec190326308d8755371a6dc62', 'pipeline': 'c6d1263e344ed8c71b2e6e4ba8e0db2fb6c777c0'}, 'duration': 0.879349946975708, 'iteration': 3, 'loss': 0.07535973554576114, 'max_history_score': 0.9456356408262035, 'max_history_score_std': 0.040053650785990214, 'max_history_step': 'joint', 'pipeline': {'features': ('features_NoneType', {}), 'normalizer': ('normalizer_RobustScaler', {'normalizer__quantile_range': (...), 'normalizer__with_centering': True, 'normalizer__with_scaling': True}), 'rebalance': ('rebalance_NearMiss', {'rebalance__n_neighbors': 2})}, 'score': 0.9246402644542389, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'gini', 'max_depth': 4, 'max_features': 2, 'max_leaf_nodes': 5, 'min_samples_split': 2, 'n_estimators': 50}, 'config_hash': {'algorithm': '47581af7253940f9647ad16d37347d34baf13e5f', 'config': '2af4f82b045c0c48ecb89d42728d1039fbff8878', 'pipeline': '2928b22ed834303cb7bac6e6608531eaddd7df67'}, 'duration': 4.372632026672363, 'iteration': 4, 'loss': 0.09121294615849984, 'max_history_score': 0.9456356408262035, 'max_history_score_std': 0.040053650785990214, 'max_history_step': 'joint', 'pipeline': {'features': ('features_NoneType', {}), 'normalizer': ('normalizer_MinMaxScaler', {}), 'rebalance': ('rebalance_CondensedNearestNeighbour', {'rebalance__n_neighbors': 2})}, 'score': 0.9087870538415002, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'entropy', 'max_depth': 2, 'max_features': 2, 'max_leaf_nodes': None, 'min_samples_split': 2, 'n_estimators': 10}, 'config_hash': {'algorithm': '0a85f98ca2d06103287f153633d88f7a0535e7e8', 'config': '17b2a1e5814f3e933137158708a5b6e9b2475495', 'pipeline': '95defa3bdd8357f11f872d3c280d50a6d8ee398d'}, 'duration': 2.625814914703369, 'iteration': 5, 'loss': 0.15471329185031535, 'max_history_score': 0.9456356408262035, 'max_history_score_std': 0.040053650785990214, 'max_history_step': 'joint', 'pipeline': {'features': ('features_SelectKBest', {'features__k': 2}), 'normalizer': ('normalizer_StandardScaler', {'normalizer__with_mean': False, 'normalizer__with_std': False}), 'rebalance': ('rebalance_CondensedNearestNeighbour', {'rebalance__n_neighbors': 1})}, 'score': 0.8452867081496847, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': 3, 'max_features': None, 'max_leaf_nodes': None, 'min_samples_split': 5, 'n_estimators': 75}, 'config_hash': {'algorithm': 'd7466a2c1d5cb3fa95029d73dc030f4c3c45a159', 'config': 'fa020a592ec5ac234f9f91aac28abc2cd1ec9d33', 'pipeline': '71e0d26f923d42cfe0e2fa748931ef2afe72ed86'}, 'duration': 3.62078595161438, 'iteration': 6, 'loss': 0.17066372828623277, 'max_history_score': 0.9456356408262035, 'max_history_score_std': 0.040053650785990214, 'max_history_step': 'joint', 'pipeline': {'features': ('features_SelectKBest', {'features__k': 1}), 'normalizer': ('normalizer_RobustScaler', {'normalizer__quantile_range': (...), 'normalizer__with_centering': True, 'normalizer__with_scaling': True}), 'rebalance': ('rebalance_CondensedNearestNeighbour', {'rebalance__n_neighbors': 1})}, 'score': 0.8293362717137672, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'entropy', 'max_depth': 3, 'max_features': 3, 'max_leaf_nodes': 5, 'min_samples_split': 5, 'n_estimators': 50}, 'config_hash': {'algorithm': '735caa9785596076014572a24050cde8dc338973', 'config': '0da4498002d6f452c59bb61756abb3ded841e786', 'pipeline': '51a53ea6ef5a2521ee65f76eb2da220ab7086513'}, 'duration': 0.6934049129486084, 'iteration': 7, 'loss': 0.06125875032408601, 'max_history_score': 0.9456356408262035, 'max_history_score_std': 0.040053650785990214, 'max_history_step': 'joint', 'pipeline': {'features': ('features_NoneType', {}), 'normalizer': ('normalizer_NoneType', {}), 'rebalance': ('rebalance_NearMiss', {'rebalance__n_neighbors': 3})}, 'score': 0.938741249675914, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': 4, 'max_features': 2, 'max_leaf_nodes': None, 'min_samples_split': 3, 'n_estimators': 75}, 'config_hash': {'algorithm': 'e71a1fe9515b6805f07914a61f2e7594be9e9afe', 'config': '344e4756fb1bec455d6af51d3727e33b0d27725f', 'pipeline': '248dad1d8b30a17a5de1d0bbdfe3e2acb7a1962b'}, 'duration': 1.3036692142486572, 'iteration': 8, 'loss': 0.06483125918243893, 'max_history_score': 0.9456356408262035, 'max_history_score_std': 0.040053650785990214, 'max_history_step': 'joint', 'pipeline': {'features': ('features_PCA', {'features__n_components': 2}), 'normalizer': ('normalizer_StandardScaler', {'normalizer__with_mean': False, 'normalizer__with_std': True}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 7})}, 'score': 0.9351687408175611, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'entropy', 'max_depth': 2, 'max_features': 2, 'max_leaf_nodes': 2, 'min_samples_split': 3, 'n_estimators': 10}, 'config_hash': {'algorithm': '0a507823f2ad8605ed5950e1fe61df0560f11a00', 'config': '4a538fdcf8e07f90e92a421c0d5c479d651629c7', 'pipeline': '5240329df25c9a533d025c1a401d49835a501b41'}, 'duration': 1.3821029663085938, 'iteration': 9, 'loss': 0.07006416904329793, 'max_history_score': 0.9456356408262035, 'max_history_score_std': 0.040053650785990214, 'max_history_step': 'joint', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 4, 'features__selectkbest__k': 2}), 'normalizer': ('normalizer_PowerTransformer', {}), 'rebalance': ('rebalance_NearMiss', {'rebalance__n_neighbors': 1})}, 'score': 0.9299358309567021, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'gini', 'max_depth': 1, 'max_features': 3, 'max_leaf_nodes': 5, 'min_samples_split': 3, 'n_estimators': 10}, 'config_hash': {'algorithm': 'd32739750d351948f8ff34a87c7d55b0c5e0d90f', 'config': 'c1609e71f1ce8486335adc70bb69a955580ba2c8', 'pipeline': 'f48b42ec5cf999279659966160a16353b75bdaa3'}, 'duration': 0.9055681228637695, 'iteration': 10, 'loss': 0.07532840722495904, 'max_history_score': 0.9456356408262035, 'max_history_score_std': 0.040053650785990214, 'max_history_step': 'joint', 'pipeline': {'features': ('features_PCA', {'features__n_components': 4}), 'normalizer': ('normalizer_PowerTransformer', {}), 'rebalance': ('rebalance_NearMiss', {'rebalance__n_neighbors': 1})}, 'score': 0.924671592775041, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': 3, 'max_features': 1, 'max_leaf_nodes': 5, 'min_samples_split': 3, 'n_estimators': 25}, 'config_hash': {'algorithm': 'f69bac35e71cbec1bfc1fb5942328a3390e7c252', 'config': 'abe36f188644e53e56ed3224236fa157107ed3b2', 'pipeline': 'aaf976c7c663a31fa039582d42f9e07101556a7c'}, 'duration': 0.764197826385498, 'iteration': 11, 'loss': 0.06818446979517778, 'max_history_score': 0.9456356408262035, 'max_history_score_std': 0.040053650785990214, 'max_history_step': 'joint', 'pipeline': {'features': ('features_NoneType', {}), 'normalizer': ('normalizer_PowerTransformer', {}), 'rebalance': ('rebalance_NoneType', {})}, 'score': 0.9318155302048222, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'entropy', 'max_depth': None, 'max_features': None, 'max_leaf_nodes': None, 'min_samples_split': 5, 'n_estimators': 25}, 'config_hash': {'algorithm': 'a0a27aec00db5ddf71eab96663f9bd61c845f5e3', 'config': '76aa002c3c9d4d9722466c60daf5119c18a41d2a', 'pipeline': '1ce34b7894ef342571d974bb19e8ec821a512c6b'}, 'duration': 1.1636500358581543, 'iteration': 12, 'loss': 0.12833700630887557, 'max_history_score': 0.9456356408262035, 'max_history_score_std': 0.040053650785990214, 'max_history_step': 'joint', 'pipeline': {'features': ('features_PCA', {'features__n_components': 1}), 'normalizer': ('normalizer_PowerTransformer', {}), 'rebalance': ('rebalance_NoneType', {})}, 'score': 0.8716629936911244, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'gini', 'max_depth': 1, 'max_features': 2, 'max_leaf_nodes': 2, 'min_samples_split': 2, 'n_estimators': 100}, 'config_hash': {'algorithm': '985c99dff1da9b2c87e4211c5335a9159aa9dbcb', 'config': 'f56a7a9e43a0a699e992dc1262e550b8b7c88538', 'pipeline': '5c934f6d9a8ad1f9afe762986a9cf2074fc95d79'}, 'duration': 2.235443115234375, 'iteration': 13, 'loss': 0.11414635727249167, 'max_history_score': 0.9456356408262035, 'max_history_score_std': 0.040053650785990214, 'max_history_step': 'joint', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 1, 'features__selectkbest__k': 1}), 'normalizer': ('normalizer_RobustScaler', {'normalizer__quantile_range': (...), 'normalizer__with_centering': False, 'normalizer__with_scaling': True}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 6})}, 'score': 0.8858536427275083, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'gini', 'max_depth': 1, 'max_features': 1, 'max_leaf_nodes': None, 'min_samples_split': 5, 'n_estimators': 10}, 'config_hash': {'algorithm': '7d74a39aac2579264a402aef2b6fa7943c19f3d3', 'config': '53f44c0ad925c5c08c25d4fadf5e9ee9d7c181cd', 'pipeline': '6eff5ef31d7d1d534db31913bb67529c8a24c42e'}, 'duration': 2.7847659587860107, 'iteration': 14, 'loss': 0.14061986863711007, 'max_history_score': 0.9456356408262035, 'max_history_score_std': 0.040053650785990214, 'max_history_step': 'joint', 'pipeline': {'features': ('features_PCA', {'features__n_components': 1}), 'normalizer': ('normalizer_RobustScaler', {'normalizer__quantile_range': (...), 'normalizer__with_centering': True, 'normalizer__with_scaling': True}), 'rebalance': ('rebalance_CondensedNearestNeighbour', {'rebalance__n_neighbors': 3})}, 'score': 0.8593801313628899, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'entropy', 'max_depth': 3, 'max_features': None, 'max_leaf_nodes': 5, 'min_samples_split': 2, 'n_estimators': 100}, 'config_hash': {'algorithm': 'c62d7c671832e4414b6b2d7c36cba5ddc83a0ed0', 'config': '5faee50671eaa0ac586722bff234e36a857e662d', 'pipeline': '8b29a55de2add78c49114b9bbe5e800e5524c59d'}, 'duration': 2.3916029930114746, 'iteration': 15, 'loss': 0.08770093336790252, 'max_history_score': 0.9456356408262035, 'max_history_score_std': 0.040053650785990214, 'max_history_step': 'joint', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 3, 'features__selectkbest__k': 4}), 'normalizer': ('normalizer_RobustScaler', {'normalizer__quantile_range': (...), 'normalizer__with_centering': True, 'normalizer__with_scaling': True}), 'rebalance': ('rebalance_NoneType', {})}, 'score': 0.9122990666320975, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': None, 'max_features': 1, 'max_leaf_nodes': 5, 'min_samples_split': 5, 'n_estimators': 10}, 'config_hash': {'algorithm': '290772bfb9b8ed15c48a72829e822fb0a07481d6', 'config': '9a04f25d8eb3db5b2f831abd341a6d384c73a957', 'pipeline': '1ce34b7894ef342571d974bb19e8ec821a512c6b'}, 'duration': 1.4364500045776367, 'iteration': 16, 'loss': 0.08948880822746508, 'max_history_score': 0.9456356408262035, 'max_history_score_std': 0.040053650785990214, 'max_history_step': 'joint', 'pipeline': {'features': ('features_PCA', {'features__n_components': 1}), 'normalizer': ('normalizer_PowerTransformer', {}), 'rebalance': ('rebalance_NoneType', {})}, 'score': 0.9105111917725349, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': 2, 'max_features': 3, 'max_leaf_nodes': 3, 'min_samples_split': 3, 'n_estimators': 100}, 'config_hash': {'algorithm': '7dab6d47f897c2961d3402eff844aff16a7d142a', 'config': '4dbfa2688b239be9f372d3e80223960ba9a1fbdd', 'pipeline': 'cdef51702798fa49f11c11d80baf3ab43d5358fc'}, 'duration': 0.9830451011657715, 'iteration': 17, 'loss': 1.0, 'max_history_score': 0.9456356408262035, 'max_history_score_std': 0.040053650785990214, 'max_history_step': 'joint', 'pipeline': {'features': ('features_SelectKBest', {'features__k': 2}), 'normalizer': ('normalizer_PowerTransformer', {}), 'rebalance': ('rebalance_NearMiss', {'rebalance__n_neighbors': 1})}, 'score': 0.0, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'entropy', 'max_depth': None, 'max_features': 3, 'max_leaf_nodes': None, 'min_samples_split': 5, 'n_estimators': 10}, 'config_hash': {'algorithm': 'def83e48be05ef92a37e1a90585820f2f67ff42b', 'config': '95902552cb76e9798f0fa58782bd72bd1cc272d7', 'pipeline': '1775187bf23f94f4fd0cc1e5c1ef665210edded5'}, 'duration': 2.0033559799194336, 'iteration': 18, 'loss': 0.04922327370149515, 'max_history_score': 0.9507767262985048, 'max_history_score_std': 0.028328108925705902, 'max_history_step': 'joint', 'pipeline': {'features': ('features_PCA', {'features__n_components': 4}), 'normalizer': ('normalizer_StandardScaler', {'normalizer__with_mean': True, 'normalizer__with_std': True}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 5})}, 'score': 0.9507767262985048, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'gini', 'max_depth': 1, 'max_features': 3, 'max_leaf_nodes': None, 'min_samples_split': 2, 'n_estimators': 50}, 'config_hash': {'algorithm': '4e9e3275f817df75115d9d7e3366980fc1b4cf13', 'config': '7770b19007b40bf13005d52eb81f87bc401f15b4', 'pipeline': 'c4dd111513ea35f97dd3aec3e8e7f6268ce035da'}, 'duration': 0.9069631099700928, 'iteration': 19, 'loss': 1.0, 'max_history_score': 0.9507767262985048, 'max_history_score_std': 0.028328108925705902, 'max_history_step': 'joint', 'pipeline': {'features': ('features_PCA', {'features__n_components': 2}), 'normalizer': ('normalizer_RobustScaler', {'normalizer__quantile_range': (...), 'normalizer__with_centering': False, 'normalizer__with_scaling': True}), 'rebalance': ('rebalance_NearMiss', {'rebalance__n_neighbors': 2})}, 'score': 0.0, ...}, ...], 'history_hash': ['51144ca42f9ea5ab2d8d58606e3b3e4d89c6d7b3', '9e54ffcb6a727de032a0a2cd45c5cc37cc150756', 'e5241eee9ddf3f4ee29a4711f5bcc92a4d24cd09', '18ee4d3d1627472ec190326308d8755371a6dc62', '2af4f82b045c0c48ecb89d42728d1039fbff8878', '17b2a1e5814f3e933137158708a5b6e9b2475495', 'fa020a592ec5ac234f9f91aac28abc2cd1ec9d33', '0da4498002d6f452c59bb61756abb3ded841e786', '344e4756fb1bec455d6af51d3727e33b0d27725f', '4a538fdcf8e07f90e92a421c0d5c479d651629c7', 'c1609e71f1ce8486335adc70bb69a955580ba2c8', 'abe36f188644e53e56ed3224236fa157107ed3b2', '76aa002c3c9d4d9722466c60daf5119c18a41d2a', 'f56a7a9e43a0a699e992dc1262e550b8b7c88538', '53f44c0ad925c5c08c25d4fadf5e9ee9d7c181cd', '5faee50671eaa0ac586722bff234e36a857e662d', '9a04f25d8eb3db5b2f831abd341a6d384c73a957', '4dbfa2688b239be9f372d3e80223960ba9a1fbdd', '95902552cb76e9798f0fa58782bd72bd1cc272d7', '7770b19007b40bf13005d52eb81f87bc401f15b4', ...], 'history_index': {'0da4498002d6f452c59bb61756abb3ded841e786': 7, '0f77a69b0a8d34861caf915a51dc588ff8d4efac': 61, '127553d555ed39231b8da3a1ce42d3902e30919b': 59, '17b2a1e5814f3e933137158708a5b6e9b2475495': 5, '18ee4d3d1627472ec190326308d8755371a6dc62': 3, '1b2267555a9226d7eb4df3c63dd12506da370f4d': 56, '28b2db1bf9b505aa8e490d811b55f6655178ede7': 67, '2af4f82b045c0c48ecb89d42728d1039fbff8878': 4, '2d054540972225f4f17fb36d63106b7bb5c406fe': 36, '306511091d7e5d6431b5e5a6320802c4c04cde44': 33, ...}, 'iteration': 88, 'max_history_score': 0.9525008642295394, 'max_history_score_std': 0.02225295065716913, 'max_history_step': 'joint'}
        config = {'algorithm': 'RandomForest', 'seed': 42, 'time': 300}
    114 
    115 
    116 def get_baseline_score(algorithm, X, y, seed):
    117     pipeline, _ = pipeline_conf_to_full_pipeline(

...........................................................................
/home/aquemy/dev/dp_hyperparameters/extension/experiment/objective.py in objective(pipeline_config={'features': ('features_SelectKBest', {'features__k': 2}), 'normalizer': ('normalizer_StandardScaler', {'normalizer__with_mean': True, 'normalizer__with_std': True}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 5})}, algo_config={'bootstrap': True, 'criterion': 'entropy', 'max_depth': 4, 'max_features': 3, 'max_leaf_nodes': None, 'min_samples_split': 2, 'n_estimators': 10}, algorithm='RandomForest', X=array([[1.799e+01, 1.038e+01, 1.228e+02, ..., 2...., ..., 0.000e+00, 2.871e-01,
        7.039e-02]]), y=array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,... 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1]), context={'baseline_score': 0.9545944602886527, 'baseline_score_std': 0.03716322883281839, 'best_config': {'algorithm': {'bootstrap': False, 'criterion': 'entropy', 'max_depth': None, 'max_features': 2, 'max_leaf_nodes': None, 'min_samples_split': 5, 'n_estimators': 10}, 'config_hash': {'algorithm': 'e7a772c2bc361aa61cf7eeb364a26dca2c9b89d6', 'config': 'afb67da069b544b0505b1e8c150edc7498ad37b4', 'pipeline': 'a43db4b4fc4c38610b7b5e484840d2e583089ff4'}, 'duration': 1.0073001384735107, 'iteration': 26, 'loss': 0.04749913577046061, 'max_history_score': 0.9525008642295394, 'max_history_score_std': 0.02225295065716913, 'max_history_step': 'joint', 'pipeline': {'features': ('features_PCA', {'features__n_components': 4}), 'normalizer': ('normalizer_StandardScaler', {'normalizer__with_mean': True, 'normalizer__with_std': False}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 7})}, 'score': 0.9525008642295394, ...}, 'history': [{'algorithm': {'bootstrap': True, 'criterion': 'entropy', 'max_depth': 4, 'max_features': 3, 'max_leaf_nodes': 3, 'min_samples_split': 2, 'n_estimators': 10}, 'config_hash': {'algorithm': '42527c4120073c2a488d1b8df28732f486d1578c', 'config': '51144ca42f9ea5ab2d8d58606e3b3e4d89c6d7b3', 'pipeline': '52f07bda29f9d3a95fabb87e591d0b2581ca8209'}, 'duration': 0.26703310012817383, 'iteration': 0, 'loss': 0.06655431682654922, 'max_history_score': 0.9334456831734508, 'max_history_score_std': 0.03819399139659311, 'max_history_step': 'joint', 'pipeline': {'features': ('features_NoneType', {}), 'normalizer': ('normalizer_RobustScaler', {'normalizer__quantile_range': (...), 'normalizer__with_centering': False, 'normalizer__with_scaling': False}), 'rebalance': ('rebalance_NearMiss', {'rebalance__n_neighbors': 1})}, 'score': 0.9334456831734508, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': None, 'max_features': 2, 'max_leaf_nodes': 3, 'min_samples_split': 2, 'n_estimators': 100}, 'config_hash': {'algorithm': '1b32258c630f07e01ab481ab925ab80aa757e482', 'config': '9e54ffcb6a727de032a0a2cd45c5cc37cc150756', 'pipeline': '37e72d4a97f5e784c9d3133e6379b91bfc3be803'}, 'duration': 1.3065669536590576, 'iteration': 1, 'loss': 0.05436435917379645, 'max_history_score': 0.9456356408262035, 'max_history_score_std': 0.040053650785990214, 'max_history_step': 'joint', 'pipeline': {'features': ('features_NoneType', {}), 'normalizer': ('normalizer_StandardScaler', {'normalizer__with_mean': True, 'normalizer__with_std': True}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 6})}, 'score': 0.9456356408262035, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'entropy', 'max_depth': 1, 'max_features': 1, 'max_leaf_nodes': 2, 'min_samples_split': 3, 'n_estimators': 25}, 'config_hash': {'algorithm': '68ab9059aa7ec74e0da87c81734b9664243b3eb4', 'config': 'e5241eee9ddf3f4ee29a4711f5bcc92a4d24cd09', 'pipeline': '62463de065924498cdcd2f2f1f7e68535cdb33a5'}, 'duration': 0.6592490673065186, 'iteration': 2, 'loss': 0.07695856019358727, 'max_history_score': 0.9456356408262035, 'max_history_score_std': 0.040053650785990214, 'max_history_step': 'joint', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 1, 'features__selectkbest__k': 2}), 'normalizer': ('normalizer_NoneType', {}), 'rebalance': ('rebalance_NoneType', {})}, 'score': 0.9230414398064127, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': 3, 'max_features': 2, 'max_leaf_nodes': 2, 'min_samples_split': 2, 'n_estimators': 25}, 'config_hash': {'algorithm': 'e3f1f7d7783557a38f40f0476369091edd87092b', 'config': '18ee4d3d1627472ec190326308d8755371a6dc62', 'pipeline': 'c6d1263e344ed8c71b2e6e4ba8e0db2fb6c777c0'}, 'duration': 0.879349946975708, 'iteration': 3, 'loss': 0.07535973554576114, 'max_history_score': 0.9456356408262035, 'max_history_score_std': 0.040053650785990214, 'max_history_step': 'joint', 'pipeline': {'features': ('features_NoneType', {}), 'normalizer': ('normalizer_RobustScaler', {'normalizer__quantile_range': (...), 'normalizer__with_centering': True, 'normalizer__with_scaling': True}), 'rebalance': ('rebalance_NearMiss', {'rebalance__n_neighbors': 2})}, 'score': 0.9246402644542389, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'gini', 'max_depth': 4, 'max_features': 2, 'max_leaf_nodes': 5, 'min_samples_split': 2, 'n_estimators': 50}, 'config_hash': {'algorithm': '47581af7253940f9647ad16d37347d34baf13e5f', 'config': '2af4f82b045c0c48ecb89d42728d1039fbff8878', 'pipeline': '2928b22ed834303cb7bac6e6608531eaddd7df67'}, 'duration': 4.372632026672363, 'iteration': 4, 'loss': 0.09121294615849984, 'max_history_score': 0.9456356408262035, 'max_history_score_std': 0.040053650785990214, 'max_history_step': 'joint', 'pipeline': {'features': ('features_NoneType', {}), 'normalizer': ('normalizer_MinMaxScaler', {}), 'rebalance': ('rebalance_CondensedNearestNeighbour', {'rebalance__n_neighbors': 2})}, 'score': 0.9087870538415002, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'entropy', 'max_depth': 2, 'max_features': 2, 'max_leaf_nodes': None, 'min_samples_split': 2, 'n_estimators': 10}, 'config_hash': {'algorithm': '0a85f98ca2d06103287f153633d88f7a0535e7e8', 'config': '17b2a1e5814f3e933137158708a5b6e9b2475495', 'pipeline': '95defa3bdd8357f11f872d3c280d50a6d8ee398d'}, 'duration': 2.625814914703369, 'iteration': 5, 'loss': 0.15471329185031535, 'max_history_score': 0.9456356408262035, 'max_history_score_std': 0.040053650785990214, 'max_history_step': 'joint', 'pipeline': {'features': ('features_SelectKBest', {'features__k': 2}), 'normalizer': ('normalizer_StandardScaler', {'normalizer__with_mean': False, 'normalizer__with_std': False}), 'rebalance': ('rebalance_CondensedNearestNeighbour', {'rebalance__n_neighbors': 1})}, 'score': 0.8452867081496847, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': 3, 'max_features': None, 'max_leaf_nodes': None, 'min_samples_split': 5, 'n_estimators': 75}, 'config_hash': {'algorithm': 'd7466a2c1d5cb3fa95029d73dc030f4c3c45a159', 'config': 'fa020a592ec5ac234f9f91aac28abc2cd1ec9d33', 'pipeline': '71e0d26f923d42cfe0e2fa748931ef2afe72ed86'}, 'duration': 3.62078595161438, 'iteration': 6, 'loss': 0.17066372828623277, 'max_history_score': 0.9456356408262035, 'max_history_score_std': 0.040053650785990214, 'max_history_step': 'joint', 'pipeline': {'features': ('features_SelectKBest', {'features__k': 1}), 'normalizer': ('normalizer_RobustScaler', {'normalizer__quantile_range': (...), 'normalizer__with_centering': True, 'normalizer__with_scaling': True}), 'rebalance': ('rebalance_CondensedNearestNeighbour', {'rebalance__n_neighbors': 1})}, 'score': 0.8293362717137672, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'entropy', 'max_depth': 3, 'max_features': 3, 'max_leaf_nodes': 5, 'min_samples_split': 5, 'n_estimators': 50}, 'config_hash': {'algorithm': '735caa9785596076014572a24050cde8dc338973', 'config': '0da4498002d6f452c59bb61756abb3ded841e786', 'pipeline': '51a53ea6ef5a2521ee65f76eb2da220ab7086513'}, 'duration': 0.6934049129486084, 'iteration': 7, 'loss': 0.06125875032408601, 'max_history_score': 0.9456356408262035, 'max_history_score_std': 0.040053650785990214, 'max_history_step': 'joint', 'pipeline': {'features': ('features_NoneType', {}), 'normalizer': ('normalizer_NoneType', {}), 'rebalance': ('rebalance_NearMiss', {'rebalance__n_neighbors': 3})}, 'score': 0.938741249675914, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': 4, 'max_features': 2, 'max_leaf_nodes': None, 'min_samples_split': 3, 'n_estimators': 75}, 'config_hash': {'algorithm': 'e71a1fe9515b6805f07914a61f2e7594be9e9afe', 'config': '344e4756fb1bec455d6af51d3727e33b0d27725f', 'pipeline': '248dad1d8b30a17a5de1d0bbdfe3e2acb7a1962b'}, 'duration': 1.3036692142486572, 'iteration': 8, 'loss': 0.06483125918243893, 'max_history_score': 0.9456356408262035, 'max_history_score_std': 0.040053650785990214, 'max_history_step': 'joint', 'pipeline': {'features': ('features_PCA', {'features__n_components': 2}), 'normalizer': ('normalizer_StandardScaler', {'normalizer__with_mean': False, 'normalizer__with_std': True}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 7})}, 'score': 0.9351687408175611, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'entropy', 'max_depth': 2, 'max_features': 2, 'max_leaf_nodes': 2, 'min_samples_split': 3, 'n_estimators': 10}, 'config_hash': {'algorithm': '0a507823f2ad8605ed5950e1fe61df0560f11a00', 'config': '4a538fdcf8e07f90e92a421c0d5c479d651629c7', 'pipeline': '5240329df25c9a533d025c1a401d49835a501b41'}, 'duration': 1.3821029663085938, 'iteration': 9, 'loss': 0.07006416904329793, 'max_history_score': 0.9456356408262035, 'max_history_score_std': 0.040053650785990214, 'max_history_step': 'joint', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 4, 'features__selectkbest__k': 2}), 'normalizer': ('normalizer_PowerTransformer', {}), 'rebalance': ('rebalance_NearMiss', {'rebalance__n_neighbors': 1})}, 'score': 0.9299358309567021, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'gini', 'max_depth': 1, 'max_features': 3, 'max_leaf_nodes': 5, 'min_samples_split': 3, 'n_estimators': 10}, 'config_hash': {'algorithm': 'd32739750d351948f8ff34a87c7d55b0c5e0d90f', 'config': 'c1609e71f1ce8486335adc70bb69a955580ba2c8', 'pipeline': 'f48b42ec5cf999279659966160a16353b75bdaa3'}, 'duration': 0.9055681228637695, 'iteration': 10, 'loss': 0.07532840722495904, 'max_history_score': 0.9456356408262035, 'max_history_score_std': 0.040053650785990214, 'max_history_step': 'joint', 'pipeline': {'features': ('features_PCA', {'features__n_components': 4}), 'normalizer': ('normalizer_PowerTransformer', {}), 'rebalance': ('rebalance_NearMiss', {'rebalance__n_neighbors': 1})}, 'score': 0.924671592775041, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': 3, 'max_features': 1, 'max_leaf_nodes': 5, 'min_samples_split': 3, 'n_estimators': 25}, 'config_hash': {'algorithm': 'f69bac35e71cbec1bfc1fb5942328a3390e7c252', 'config': 'abe36f188644e53e56ed3224236fa157107ed3b2', 'pipeline': 'aaf976c7c663a31fa039582d42f9e07101556a7c'}, 'duration': 0.764197826385498, 'iteration': 11, 'loss': 0.06818446979517778, 'max_history_score': 0.9456356408262035, 'max_history_score_std': 0.040053650785990214, 'max_history_step': 'joint', 'pipeline': {'features': ('features_NoneType', {}), 'normalizer': ('normalizer_PowerTransformer', {}), 'rebalance': ('rebalance_NoneType', {})}, 'score': 0.9318155302048222, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'entropy', 'max_depth': None, 'max_features': None, 'max_leaf_nodes': None, 'min_samples_split': 5, 'n_estimators': 25}, 'config_hash': {'algorithm': 'a0a27aec00db5ddf71eab96663f9bd61c845f5e3', 'config': '76aa002c3c9d4d9722466c60daf5119c18a41d2a', 'pipeline': '1ce34b7894ef342571d974bb19e8ec821a512c6b'}, 'duration': 1.1636500358581543, 'iteration': 12, 'loss': 0.12833700630887557, 'max_history_score': 0.9456356408262035, 'max_history_score_std': 0.040053650785990214, 'max_history_step': 'joint', 'pipeline': {'features': ('features_PCA', {'features__n_components': 1}), 'normalizer': ('normalizer_PowerTransformer', {}), 'rebalance': ('rebalance_NoneType', {})}, 'score': 0.8716629936911244, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'gini', 'max_depth': 1, 'max_features': 2, 'max_leaf_nodes': 2, 'min_samples_split': 2, 'n_estimators': 100}, 'config_hash': {'algorithm': '985c99dff1da9b2c87e4211c5335a9159aa9dbcb', 'config': 'f56a7a9e43a0a699e992dc1262e550b8b7c88538', 'pipeline': '5c934f6d9a8ad1f9afe762986a9cf2074fc95d79'}, 'duration': 2.235443115234375, 'iteration': 13, 'loss': 0.11414635727249167, 'max_history_score': 0.9456356408262035, 'max_history_score_std': 0.040053650785990214, 'max_history_step': 'joint', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 1, 'features__selectkbest__k': 1}), 'normalizer': ('normalizer_RobustScaler', {'normalizer__quantile_range': (...), 'normalizer__with_centering': False, 'normalizer__with_scaling': True}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 6})}, 'score': 0.8858536427275083, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'gini', 'max_depth': 1, 'max_features': 1, 'max_leaf_nodes': None, 'min_samples_split': 5, 'n_estimators': 10}, 'config_hash': {'algorithm': '7d74a39aac2579264a402aef2b6fa7943c19f3d3', 'config': '53f44c0ad925c5c08c25d4fadf5e9ee9d7c181cd', 'pipeline': '6eff5ef31d7d1d534db31913bb67529c8a24c42e'}, 'duration': 2.7847659587860107, 'iteration': 14, 'loss': 0.14061986863711007, 'max_history_score': 0.9456356408262035, 'max_history_score_std': 0.040053650785990214, 'max_history_step': 'joint', 'pipeline': {'features': ('features_PCA', {'features__n_components': 1}), 'normalizer': ('normalizer_RobustScaler', {'normalizer__quantile_range': (...), 'normalizer__with_centering': True, 'normalizer__with_scaling': True}), 'rebalance': ('rebalance_CondensedNearestNeighbour', {'rebalance__n_neighbors': 3})}, 'score': 0.8593801313628899, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'entropy', 'max_depth': 3, 'max_features': None, 'max_leaf_nodes': 5, 'min_samples_split': 2, 'n_estimators': 100}, 'config_hash': {'algorithm': 'c62d7c671832e4414b6b2d7c36cba5ddc83a0ed0', 'config': '5faee50671eaa0ac586722bff234e36a857e662d', 'pipeline': '8b29a55de2add78c49114b9bbe5e800e5524c59d'}, 'duration': 2.3916029930114746, 'iteration': 15, 'loss': 0.08770093336790252, 'max_history_score': 0.9456356408262035, 'max_history_score_std': 0.040053650785990214, 'max_history_step': 'joint', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 3, 'features__selectkbest__k': 4}), 'normalizer': ('normalizer_RobustScaler', {'normalizer__quantile_range': (...), 'normalizer__with_centering': True, 'normalizer__with_scaling': True}), 'rebalance': ('rebalance_NoneType', {})}, 'score': 0.9122990666320975, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': None, 'max_features': 1, 'max_leaf_nodes': 5, 'min_samples_split': 5, 'n_estimators': 10}, 'config_hash': {'algorithm': '290772bfb9b8ed15c48a72829e822fb0a07481d6', 'config': '9a04f25d8eb3db5b2f831abd341a6d384c73a957', 'pipeline': '1ce34b7894ef342571d974bb19e8ec821a512c6b'}, 'duration': 1.4364500045776367, 'iteration': 16, 'loss': 0.08948880822746508, 'max_history_score': 0.9456356408262035, 'max_history_score_std': 0.040053650785990214, 'max_history_step': 'joint', 'pipeline': {'features': ('features_PCA', {'features__n_components': 1}), 'normalizer': ('normalizer_PowerTransformer', {}), 'rebalance': ('rebalance_NoneType', {})}, 'score': 0.9105111917725349, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': 2, 'max_features': 3, 'max_leaf_nodes': 3, 'min_samples_split': 3, 'n_estimators': 100}, 'config_hash': {'algorithm': '7dab6d47f897c2961d3402eff844aff16a7d142a', 'config': '4dbfa2688b239be9f372d3e80223960ba9a1fbdd', 'pipeline': 'cdef51702798fa49f11c11d80baf3ab43d5358fc'}, 'duration': 0.9830451011657715, 'iteration': 17, 'loss': 1.0, 'max_history_score': 0.9456356408262035, 'max_history_score_std': 0.040053650785990214, 'max_history_step': 'joint', 'pipeline': {'features': ('features_SelectKBest', {'features__k': 2}), 'normalizer': ('normalizer_PowerTransformer', {}), 'rebalance': ('rebalance_NearMiss', {'rebalance__n_neighbors': 1})}, 'score': 0.0, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'entropy', 'max_depth': None, 'max_features': 3, 'max_leaf_nodes': None, 'min_samples_split': 5, 'n_estimators': 10}, 'config_hash': {'algorithm': 'def83e48be05ef92a37e1a90585820f2f67ff42b', 'config': '95902552cb76e9798f0fa58782bd72bd1cc272d7', 'pipeline': '1775187bf23f94f4fd0cc1e5c1ef665210edded5'}, 'duration': 2.0033559799194336, 'iteration': 18, 'loss': 0.04922327370149515, 'max_history_score': 0.9507767262985048, 'max_history_score_std': 0.028328108925705902, 'max_history_step': 'joint', 'pipeline': {'features': ('features_PCA', {'features__n_components': 4}), 'normalizer': ('normalizer_StandardScaler', {'normalizer__with_mean': True, 'normalizer__with_std': True}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 5})}, 'score': 0.9507767262985048, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'gini', 'max_depth': 1, 'max_features': 3, 'max_leaf_nodes': None, 'min_samples_split': 2, 'n_estimators': 50}, 'config_hash': {'algorithm': '4e9e3275f817df75115d9d7e3366980fc1b4cf13', 'config': '7770b19007b40bf13005d52eb81f87bc401f15b4', 'pipeline': 'c4dd111513ea35f97dd3aec3e8e7f6268ce035da'}, 'duration': 0.9069631099700928, 'iteration': 19, 'loss': 1.0, 'max_history_score': 0.9507767262985048, 'max_history_score_std': 0.028328108925705902, 'max_history_step': 'joint', 'pipeline': {'features': ('features_PCA', {'features__n_components': 2}), 'normalizer': ('normalizer_RobustScaler', {'normalizer__quantile_range': (...), 'normalizer__with_centering': False, 'normalizer__with_scaling': True}), 'rebalance': ('rebalance_NearMiss', {'rebalance__n_neighbors': 2})}, 'score': 0.0, ...}, ...], 'history_hash': ['51144ca42f9ea5ab2d8d58606e3b3e4d89c6d7b3', '9e54ffcb6a727de032a0a2cd45c5cc37cc150756', 'e5241eee9ddf3f4ee29a4711f5bcc92a4d24cd09', '18ee4d3d1627472ec190326308d8755371a6dc62', '2af4f82b045c0c48ecb89d42728d1039fbff8878', '17b2a1e5814f3e933137158708a5b6e9b2475495', 'fa020a592ec5ac234f9f91aac28abc2cd1ec9d33', '0da4498002d6f452c59bb61756abb3ded841e786', '344e4756fb1bec455d6af51d3727e33b0d27725f', '4a538fdcf8e07f90e92a421c0d5c479d651629c7', 'c1609e71f1ce8486335adc70bb69a955580ba2c8', 'abe36f188644e53e56ed3224236fa157107ed3b2', '76aa002c3c9d4d9722466c60daf5119c18a41d2a', 'f56a7a9e43a0a699e992dc1262e550b8b7c88538', '53f44c0ad925c5c08c25d4fadf5e9ee9d7c181cd', '5faee50671eaa0ac586722bff234e36a857e662d', '9a04f25d8eb3db5b2f831abd341a6d384c73a957', '4dbfa2688b239be9f372d3e80223960ba9a1fbdd', '95902552cb76e9798f0fa58782bd72bd1cc272d7', '7770b19007b40bf13005d52eb81f87bc401f15b4', ...], 'history_index': {'0da4498002d6f452c59bb61756abb3ded841e786': 7, '0f77a69b0a8d34861caf915a51dc588ff8d4efac': 61, '127553d555ed39231b8da3a1ce42d3902e30919b': 59, '17b2a1e5814f3e933137158708a5b6e9b2475495': 5, '18ee4d3d1627472ec190326308d8755371a6dc62': 3, '1b2267555a9226d7eb4df3c63dd12506da370f4d': 56, '28b2db1bf9b505aa8e490d811b55f6655178ede7': 67, '2af4f82b045c0c48ecb89d42728d1039fbff8878': 4, '2d054540972225f4f17fb36d63106b7bb5c406fe': 36, '306511091d7e5d6431b5e5a6320802c4c04cde44': 33, ...}, 'iteration': 88, 'max_history_score': 0.9525008642295394, 'max_history_score_std': 0.02225295065716913, 'max_history_step': 'joint'}, config={'algorithm': 'RandomForest', 'seed': 42, 'time': 300}, step='joint')
     45                 y,
     46                 cv=10,
     47                 n_jobs=-1,
     48                 return_estimator=False,
     49                 return_train_score=False,
---> 50                 verbose=0)
     51         score = np.mean(scores['test_score'])
     52         std = np.std(scores['test_score'])
     53         status = STATUS_OK
     54     except Exception as e:

...........................................................................
/home/aquemy/.local/lib/python2.7/site-packages/sklearn/model_selection/_validation.py in cross_validate(estimator=Pipeline(memory=None,
     steps=[('rebalance', ... random_state=42, verbose=0, warm_start=False))]), X=array([[1.799e+01, 1.038e+01, 1.228e+02, ..., 2...., ..., 0.000e+00, 2.871e-01,
        7.039e-02]]), y=array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,... 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1]), groups=None, scoring=None, cv=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1, verbose=0, fit_params=None, pre_dispatch='2*n_jobs', return_train_score=False, return_estimator=False, error_score='raise-deprecating')
    235         delayed(_fit_and_score)(
    236             clone(estimator), X, y, scorers, train, test, verbose, None,
    237             fit_params, return_train_score=return_train_score,
    238             return_times=True, return_estimator=return_estimator,
    239             error_score=error_score)
--> 240         for train, test in cv.split(X, y, groups))
        cv.split = <bound method StratifiedKFold.split of Stratifie...d(n_splits=10, random_state=None, shuffle=False)>
        X = array([[1.799e+01, 1.038e+01, 1.228e+02, ..., 2...., ..., 0.000e+00, 2.871e-01,
        7.039e-02]])
        y = array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,... 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1])
        groups = None
    241 
    242     zipped_scores = list(zip(*scores))
    243     if return_train_score:
    244         train_scores = zipped_scores.pop(0)

...........................................................................
/home/aquemy/.local/lib/python2.7/site-packages/sklearn/externals/joblib/parallel.py in __call__(self=Parallel(n_jobs=-1), iterable=<generator object <genexpr>>)
    925                 # No need to wait for async callbacks to trigger to
    926                 # consumption.
    927                 self._iterating = False
    928 
    929             with self._backend.retrieval_context():
--> 930                 self.retrieve()
        self.retrieve = <bound method Parallel.retrieve of Parallel(n_jobs=-1)>
    931             # Make sure that we get a last message telling us we are done
    932             elapsed_time = time.time() - self._start_time
    933             self._print('Done %3i out of %3i | elapsed: %s finished',
    934                         (len(self._output), len(self._output),

---------------------------------------------------------------------------
Joblib worker traceback:
---------------------------------------------------------------------------
ValueError                                         Mon Jun 17 13:33:45 2019
PID: 26284                                  Python 2.7.15+: /usr/bin/python
...........................................................................
/home/aquemy/.local/lib/python2.7/site-packages/sklearn/externals/joblib/parallel.py in __call__(self=<sklearn.externals.joblib.parallel.BatchedCalls object>)
    220     def __call__(self):
    221         # Set the default nested backend to self._backend but do not set the
    222         # change the default number of processes to -1
    223         with parallel_backend(self._backend, n_jobs=self._n_jobs):
    224             return [func(*args, **kwargs)
--> 225                     for func, args, kwargs in self.items]
        func = <function _fit_and_score>
        args = (Pipeline(memory=None,
     steps=[('rebalance', ... random_state=42, verbose=0, warm_start=False))]), array([[1.799e+01, 1.038e+01, 1.228e+02, ..., 2...., ..., 0.000e+00, 2.871e-01,
        7.039e-02]]), array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,... 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1]), {'score': <function _passthrough_scorer>}, array([ 25,  26,  27,  28,  29,  30,  31,  32,  ..., 561, 562, 563, 564,
       565, 566, 567, 568]), array([  0,   1,   2,   3,   4,   5,   6,   7,  ...,  89,  90,
        92,  93,  96,  97,  98, 101]), 0, None, None)
        kwargs = {'error_score': 'raise-deprecating', 'return_estimator': False, 'return_times': True, 'return_train_score': False}
        self.items = [(<function _fit_and_score>, (Pipeline(memory=None,
     steps=[('rebalance', ... random_state=42, verbose=0, warm_start=False))]), array([[1.799e+01, 1.038e+01, 1.228e+02, ..., 2...., ..., 0.000e+00, 2.871e-01,
        7.039e-02]]), array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,... 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1]), {'score': <function _passthrough_scorer>}, array([ 25,  26,  27,  28,  29,  30,  31,  32,  ..., 561, 562, 563, 564,
       565, 566, 567, 568]), array([  0,   1,   2,   3,   4,   5,   6,   7,  ...,  89,  90,
        92,  93,  96,  97,  98, 101]), 0, None, None), {'error_score': 'raise-deprecating', 'return_estimator': False, 'return_times': True, 'return_train_score': False})]
    226 
    227     def __len__(self):
    228         return self._size
    229 

...........................................................................
/home/aquemy/.local/lib/python2.7/site-packages/sklearn/model_selection/_validation.py in _fit_and_score(estimator=Pipeline(memory=None,
     steps=[('rebalance', ... random_state=42, verbose=0, warm_start=False))]), X=array([[1.799e+01, 1.038e+01, 1.228e+02, ..., 2...., ..., 0.000e+00, 2.871e-01,
        7.039e-02]]), y=array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,... 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1]), scorer={'score': <function _passthrough_scorer>}, train=array([ 25,  26,  27,  28,  29,  30,  31,  32,  ..., 561, 562, 563, 564,
       565, 566, 567, 568]), test=array([  0,   1,   2,   3,   4,   5,   6,   7,  ...,  89,  90,
        92,  93,  96,  97,  98, 101]), verbose=0, parameters=None, fit_params={}, return_train_score=False, return_parameters=False, return_n_test_samples=False, return_times=True, return_estimator=False, error_score='raise-deprecating')
    523 
    524     try:
    525         if y_train is None:
    526             estimator.fit(X_train, **fit_params)
    527         else:
--> 528             estimator.fit(X_train, y_train, **fit_params)
        estimator.fit = <bound method Pipeline.fit of Pipeline(memory=No...random_state=42, verbose=0, warm_start=False))])>
        X_train = array([[1.714e+01, 1.640e+01, 1.160e+02, ..., 2...., ..., 0.000e+00, 2.871e-01,
        7.039e-02]])
        y_train = array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...1, 1, 1, 1, 1, 1, 1, 0, 0,
       0, 0, 0, 0, 1])
        fit_params = {}
    529 
    530     except Exception as e:
    531         # Note fit time as time until error
    532         fit_time = time.time() - start_time

...........................................................................
/usr/local/lib/python2.7/dist-packages/imblearn/pipeline.py in fit(self=Pipeline(memory=None,
     steps=[('rebalance', ... random_state=42, verbose=0, warm_start=False))]), X=array([[1.714e+01, 1.640e+01, 1.160e+02, ..., 2...., ..., 0.000e+00, 2.871e-01,
        7.039e-02]]), y=array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...1, 1, 1, 1, 1, 1, 1, 0, 0,
       0, 0, 0, 0, 1]), **fit_params={})
    234             This estimator
    235 
    236         """
    237         Xt, yt, fit_params = self._fit(X, y, **fit_params)
    238         if self._final_estimator is not None:
--> 239             self._final_estimator.fit(Xt, yt, **fit_params)
        self._final_estimator.fit = <bound method RandomForestClassifier.fit of Rand...e, random_state=42, verbose=0, warm_start=False)>
        Xt = array([[ 1.08850227,  1.96315012],
       [ 0.22... 0.60524064],
       [-0.32982708,  0.14089779]])
        yt = array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
       0, 0, 0, 0])
        fit_params = {}
    240         return self
    241 
    242     def fit_transform(self, X, y=None, **fit_params):
    243         """Fit the model and transform with the final estimator

...........................................................................
/home/aquemy/.local/lib/python2.7/site-packages/sklearn/ensemble/forest.py in fit(self=RandomForestClassifier(bootstrap=True, class_wei...se, random_state=42, verbose=0, warm_start=False), X=array([[ 1.0885023 ,  1.9631501 ],
       [ 0.22...      [-0.32982707,  0.1408978 ]], dtype=float32), y=array([[0.],
       [0.],
       [0.],
       [0...    [0.],
       [0.],
       [0.],
       [0.]]), sample_weight=None)
    328             trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,
    329                              **_joblib_parallel_args(prefer='threads'))(
    330                 delayed(_parallel_build_trees)(
    331                     t, self, X, y, sample_weight, i, len(trees),
    332                     verbose=self.verbose, class_weight=self.class_weight)
--> 333                 for i, t in enumerate(trees))
        i = 9
    334 
    335             # Collect newly grown trees
    336             self.estimators_.extend(trees)
    337 

...........................................................................
/home/aquemy/.local/lib/python2.7/site-packages/sklearn/externals/joblib/parallel.py in __call__(self=Parallel(n_jobs=1), iterable=<generator object <genexpr>>)
    912             # self._original_iterator is None, then this means either
    913             # that pre_dispatch == "all", n_jobs == 1 or that the first batch
    914             # was very quick and its callback already dispatched all the
    915             # remaining jobs.
    916             self._iterating = False
--> 917             if self.dispatch_one_batch(iterator):
        self.dispatch_one_batch = <bound method Parallel.dispatch_one_batch of Parallel(n_jobs=1)>
        iterator = <generator object <genexpr>>
    918                 self._iterating = self._original_iterator is not None
    919 
    920             while self.dispatch_one_batch(iterator):
    921                 pass

...........................................................................
/home/aquemy/.local/lib/python2.7/site-packages/sklearn/externals/joblib/parallel.py in dispatch_one_batch(self=Parallel(n_jobs=1), iterator=<generator object <genexpr>>)
    754                                  self._pickle_cache)
    755             if len(tasks) == 0:
    756                 # No more tasks available in the iterator: tell caller to stop.
    757                 return False
    758             else:
--> 759                 self._dispatch(tasks)
        self._dispatch = <bound method Parallel._dispatch of Parallel(n_jobs=1)>
        tasks = <sklearn.externals.joblib.parallel.BatchedCalls object>
    760                 return True
    761 
    762     def _print(self, msg, msg_args):
    763         """Display the message on stout or stderr depending on verbosity"""

...........................................................................
/home/aquemy/.local/lib/python2.7/site-packages/sklearn/externals/joblib/parallel.py in _dispatch(self=Parallel(n_jobs=1), batch=<sklearn.externals.joblib.parallel.BatchedCalls object>)
    711 
    712         dispatch_timestamp = time.time()
    713         cb = BatchCompletionCallBack(dispatch_timestamp, len(batch), self)
    714         with self._lock:
    715             job_idx = len(self._jobs)
--> 716             job = self._backend.apply_async(batch, callback=cb)
        job = undefined
        self._backend.apply_async = <bound method SequentialBackend.apply_async of <...lib._parallel_backends.SequentialBackend object>>
        batch = <sklearn.externals.joblib.parallel.BatchedCalls object>
        cb = <sklearn.externals.joblib.parallel.BatchCompletionCallBack object>
    717             # A job can complete so quickly than its callback is
    718             # called before we get here, causing self._jobs to
    719             # grow. To ensure correct results ordering, .insert is
    720             # used (rather than .append) in the following line

...........................................................................
/home/aquemy/.local/lib/python2.7/site-packages/sklearn/externals/joblib/_parallel_backends.py in apply_async(self=<sklearn.externals.joblib._parallel_backends.SequentialBackend object>, func=<sklearn.externals.joblib.parallel.BatchedCalls object>, callback=<sklearn.externals.joblib.parallel.BatchCompletionCallBack object>)
    177             raise ValueError('n_jobs == 0 in Parallel has no meaning')
    178         return 1
    179 
    180     def apply_async(self, func, callback=None):
    181         """Schedule a func to be run"""
--> 182         result = ImmediateResult(func)
        result = undefined
        func = <sklearn.externals.joblib.parallel.BatchedCalls object>
    183         if callback:
    184             callback(result)
    185         return result
    186 

...........................................................................
/home/aquemy/.local/lib/python2.7/site-packages/sklearn/externals/joblib/_parallel_backends.py in __init__(self=<sklearn.externals.joblib._parallel_backends.ImmediateResult object>, batch=<sklearn.externals.joblib.parallel.BatchedCalls object>)
    544 
    545 class ImmediateResult(object):
    546     def __init__(self, batch):
    547         # Don't delay the application, to avoid keeping the input
    548         # arguments in memory
--> 549         self.results = batch()
        self.results = undefined
        batch = <sklearn.externals.joblib.parallel.BatchedCalls object>
    550 
    551     def get(self):
    552         return self.results
    553 

...........................................................................
/home/aquemy/.local/lib/python2.7/site-packages/sklearn/externals/joblib/parallel.py in __call__(self=<sklearn.externals.joblib.parallel.BatchedCalls object>)
    220     def __call__(self):
    221         # Set the default nested backend to self._backend but do not set the
    222         # change the default number of processes to -1
    223         with parallel_backend(self._backend, n_jobs=self._n_jobs):
    224             return [func(*args, **kwargs)
--> 225                     for func, args, kwargs in self.items]
        func = <function _parallel_build_trees>
        args = (DecisionTreeClassifier(class_weight=None, criter...=False, random_state=1608637542, splitter='best'), RandomForestClassifier(bootstrap=True, class_wei...se, random_state=42, verbose=0, warm_start=False), array([[ 1.0885023 ,  1.9631501 ],
       [ 0.22...      [-0.32982707,  0.1408978 ]], dtype=float32), array([[0.],
       [0.],
       [0.],
       [0...    [0.],
       [0.],
       [0.],
       [0.]]), None, 0, 10)
        kwargs = {'class_weight': None, 'verbose': 0}
        self.items = [(<function _parallel_build_trees>, (DecisionTreeClassifier(class_weight=None, criter...=False, random_state=1608637542, splitter='best'), RandomForestClassifier(bootstrap=True, class_wei...se, random_state=42, verbose=0, warm_start=False), array([[ 1.0885023 ,  1.9631501 ],
       [ 0.22...      [-0.32982707,  0.1408978 ]], dtype=float32), array([[0.],
       [0.],
       [0.],
       [0...    [0.],
       [0.],
       [0.],
       [0.]]), None, 0, 10), {'class_weight': None, 'verbose': 0})]
    226 
    227     def __len__(self):
    228         return self._size
    229 

...........................................................................
/home/aquemy/.local/lib/python2.7/site-packages/sklearn/ensemble/forest.py in _parallel_build_trees(tree=DecisionTreeClassifier(class_weight=None, criter...=False, random_state=1608637542, splitter='best'), forest=RandomForestClassifier(bootstrap=True, class_wei...se, random_state=42, verbose=0, warm_start=False), X=array([[ 1.0885023 ,  1.9631501 ],
       [ 0.22...      [-0.32982707,  0.1408978 ]], dtype=float32), y=array([[0.],
       [0.],
       [0.],
       [0...    [0.],
       [0.],
       [0.],
       [0.]]), sample_weight=None, tree_idx=0, n_trees=10, verbose=0, class_weight=None)
    114                 simplefilter('ignore', DeprecationWarning)
    115                 curr_sample_weight *= compute_sample_weight('auto', y, indices)
    116         elif class_weight == 'balanced_subsample':
    117             curr_sample_weight *= compute_sample_weight('balanced', y, indices)
    118 
--> 119         tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)
        tree.fit = <bound method DecisionTreeClassifier.fit of Deci...False, random_state=1608637542, splitter='best')>
        X = array([[ 1.0885023 ,  1.9631501 ],
       [ 0.22...      [-0.32982707,  0.1408978 ]], dtype=float32)
        y = array([[0.],
       [0.],
       [0.],
       [0...    [0.],
       [0.],
       [0.],
       [0.]])
        sample_weight = None
        curr_sample_weight = array([1., 2., 0., 0., 0., 1., 1., 2., 3., 0., 1... 0., 2., 2., 0., 3., 0., 2., 0., 1., 0., 1., 1.])
    120     else:
    121         tree.fit(X, y, sample_weight=sample_weight, check_input=False)
    122 
    123     return tree

...........................................................................
/home/aquemy/.local/lib/python2.7/site-packages/sklearn/tree/tree.py in fit(self=DecisionTreeClassifier(class_weight=None, criter...=False, random_state=1608637542, splitter='best'), X=array([[ 1.0885023 ,  1.9631501 ],
       [ 0.22...      [-0.32982707,  0.1408978 ]], dtype=float32), y=array([[0.],
       [0.],
       [0.],
       [0...    [0.],
       [0.],
       [0.],
       [0.]]), sample_weight=array([1., 2., 0., 0., 0., 1., 1., 2., 3., 0., 1... 0., 2., 2., 0., 3., 0., 2., 0., 1., 0., 1., 1.]), check_input=False, X_idx_sorted=None)
    796 
    797         super(DecisionTreeClassifier, self).fit(
    798             X, y,
    799             sample_weight=sample_weight,
    800             check_input=check_input,
--> 801             X_idx_sorted=X_idx_sorted)
        X_idx_sorted = None
    802         return self
    803 
    804     def predict_proba(self, X, check_input=True):
    805         """Predict class probabilities of the input samples X.

...........................................................................
/home/aquemy/.local/lib/python2.7/site-packages/sklearn/tree/tree.py in fit(self=DecisionTreeClassifier(class_weight=None, criter...=False, random_state=1608637542, splitter='best'), X=array([[ 1.0885023 ,  1.9631501 ],
       [ 0.22...      [-0.32982707,  0.1408978 ]], dtype=float32), y=array([[0.],
       [0.],
       [0.],
       [0...    [0.],
       [0.],
       [0.],
       [0.]]), sample_weight=array([1., 2., 0., 0., 0., 1., 1., 2., 3., 0., 1... 0., 2., 2., 0., 3., 0., 2., 0., 1., 0., 1., 1.]), check_input=False, X_idx_sorted=None)
    237         if not 0 <= self.min_weight_fraction_leaf <= 0.5:
    238             raise ValueError("min_weight_fraction_leaf must in [0, 0.5]")
    239         if max_depth <= 0:
    240             raise ValueError("max_depth must be greater than zero. ")
    241         if not (0 < max_features <= self.n_features_):
--> 242             raise ValueError("max_features must be in (0, n_features]")
    243         if not isinstance(max_leaf_nodes, (numbers.Integral, np.integer)):
    244             raise ValueError("max_leaf_nodes must be integral number but was "
    245                              "%r" % max_leaf_nodes)
    246         if -1 < max_leaf_nodes < 2:

ValueError: max_features must be in (0, n_features]
___________________________________________________________________________
Best score: 0.95250086423 (0.0222529506572) [J] | Score: 0.0 (0.0) [J]
Best score: 0.95250086423 (0.0222529506572) [J] | Score: 0.372572595281 (0.00441189245975) [J]
Best score: 0.95250086423 (0.0222529506572) [J] | Score: 0.912235329704 (0.0280559535736) [J]
Best score: 0.95250086423 (0.0222529506572) [J] | Score: 0.924642425028 (0.0402674272515) [J]
JoblibValueError
___________________________________________________________________________
...........................................................................
/home/aquemy/dev/dp_hyperparameters/extension/main.py in <module>()
     27 
     28     serializer.serialize_results(scenario, policy)
     29 
     30 if __name__ == "__main__":
     31     args = cli.parse_args()
---> 32     main(args)

...........................................................................
/home/aquemy/dev/dp_hyperparameters/extension/main.py in main(args=Namespace(customize=[(['control', 'seed'], '42')...='./scenarios/rf_breast_joint.yaml', verbosity=0))
     21         test_size=0.4, 
     22         random_state=scenario['control']['seed']
     23     )
     24 
     25     policy = policies.initiate(scenario['setup']['policy'], config)
---> 26     policy.run(X,y)
        policy.run = <bound method Joint.run of <experiment.policies.joint.Joint object>>
        X = array([[1.799e+01, 1.038e+01, 1.228e+02, ..., 2...., ..., 0.000e+00, 2.871e-01,
        7.039e-02]])
        y = array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,... 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1])
     27 
     28     serializer.serialize_results(scenario, policy)
     29 
     30 if __name__ == "__main__":

...........................................................................
/home/aquemy/dev/dp_hyperparameters/extension/experiment/policies/joint.py in run(self=<experiment.policies.joint.Joint object>, X=array([[1.799e+01, 1.038e+01, 1.228e+02, ..., 2...., ..., 0.000e+00, 2.871e-01,
        7.039e-02]]), y=array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,... 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1]))
     32             algo=tpe.suggest, 
     33             max_evals=None,
     34             max_time=self.config['time'],     
     35             trials=trials,
     36             show_progressbar=False,
---> 37             verbose=0
     38         )
     39 
     40         best_config = self.context['best_config']
     41         super(Joint, self).display_step_results(best_config)

...........................................................................
/home/aquemy/dev/dp_hyperparameters/extension/hyperopt/fmin.py in fmin(fn=<functools.partial object>, space={'algorithm': {'bootstrap': <hyperopt.pyll.base.Apply object>, 'criterion': <hyperopt.pyll.base.Apply object>, 'max_depth': <hyperopt.pyll.base.Apply object>, 'max_features': <hyperopt.pyll.base.Apply object>, 'max_leaf_nodes': <hyperopt.pyll.base.Apply object>, 'min_samples_split': <hyperopt.pyll.base.Apply object>, 'n_estimators': <hyperopt.pyll.base.Apply object>}, 'pipeline': {'features': <hyperopt.pyll.base.Apply object>, 'normalizer': <hyperopt.pyll.base.Apply object>, 'rebalance': <hyperopt.pyll.base.Apply object>}}, algo=<function suggest>, max_evals=9223372036854775807, max_time=300, trials=<hyperopt.base.Trials object>, rstate=<mtrand.RandomState object>, allow_trials_fmin=True, pass_expr_memo_ctrl=None, catch_eval_exceptions=False, verbose=0, return_argmin=True, points_to_evaluate=None, max_queue_len=1, show_progressbar=False)
    406             pass_expr_memo_ctrl=pass_expr_memo_ctrl,
    407             verbose=verbose,
    408             catch_eval_exceptions=catch_eval_exceptions,
    409             return_argmin=return_argmin,
    410             show_progressbar=show_progressbar,
--> 411             max_time=max_time
        max_time = 300
    412         )
    413 
    414     if trials is None:
    415         if points_to_evaluate is None:

...........................................................................
/home/aquemy/dev/dp_hyperparameters/extension/hyperopt/base.py in fmin(self=<hyperopt.base.Trials object>, fn=<functools.partial object>, space={'algorithm': {'bootstrap': <hyperopt.pyll.base.Apply object>, 'criterion': <hyperopt.pyll.base.Apply object>, 'max_depth': <hyperopt.pyll.base.Apply object>, 'max_features': <hyperopt.pyll.base.Apply object>, 'max_leaf_nodes': <hyperopt.pyll.base.Apply object>, 'min_samples_split': <hyperopt.pyll.base.Apply object>, 'n_estimators': <hyperopt.pyll.base.Apply object>}, 'pipeline': {'features': <hyperopt.pyll.base.Apply object>, 'normalizer': <hyperopt.pyll.base.Apply object>, 'rebalance': <hyperopt.pyll.base.Apply object>}}, algo=<function suggest>, max_evals=9223372036854775807, max_time=300, rstate=<mtrand.RandomState object>, verbose=0, pass_expr_memo_ctrl=None, catch_eval_exceptions=False, return_argmin=True, show_progressbar=False)
    636             verbose=verbose,
    637             allow_trials_fmin=False,  # -- prevent recursion
    638             pass_expr_memo_ctrl=pass_expr_memo_ctrl,
    639             catch_eval_exceptions=catch_eval_exceptions,
    640             return_argmin=return_argmin,
--> 641             show_progressbar=show_progressbar)
        show_progressbar = False
    642 
    643 
    644 def trials_from_docs(docs, validate=True, **kwargs):
    645     """Construct a Trials base class instance from a list of trials documents

...........................................................................
/home/aquemy/dev/dp_hyperparameters/extension/hyperopt/fmin.py in fmin(fn=<functools.partial object>, space={'algorithm': {'bootstrap': <hyperopt.pyll.base.Apply object>, 'criterion': <hyperopt.pyll.base.Apply object>, 'max_depth': <hyperopt.pyll.base.Apply object>, 'max_features': <hyperopt.pyll.base.Apply object>, 'max_leaf_nodes': <hyperopt.pyll.base.Apply object>, 'min_samples_split': <hyperopt.pyll.base.Apply object>, 'n_estimators': <hyperopt.pyll.base.Apply object>}, 'pipeline': {'features': <hyperopt.pyll.base.Apply object>, 'normalizer': <hyperopt.pyll.base.Apply object>, 'rebalance': <hyperopt.pyll.base.Apply object>}}, algo=<function suggest>, max_evals=9223372036854775807, max_time=300, trials=<hyperopt.base.Trials object>, rstate=<mtrand.RandomState object>, allow_trials_fmin=False, pass_expr_memo_ctrl=None, catch_eval_exceptions=False, verbose=0, return_argmin=True, points_to_evaluate=None, max_queue_len=1, show_progressbar=False)
    426                     verbose=verbose,
    427                     max_queue_len=max_queue_len,
    428                     show_progressbar=show_progressbar,
    429                     max_time=max_time)
    430     rval.catch_eval_exceptions = catch_eval_exceptions
--> 431     rval.exhaust()
        rval.exhaust = <bound method FMinIter.exhaust of <hyperopt.fmin.FMinIter object>>
    432     if return_argmin:
    433         return trials.argmin
    434     elif len(trials) > 0:
    435         # Only if there are some succesfull trail runs, return the best point in the evaluation space

...........................................................................
/home/aquemy/dev/dp_hyperparameters/extension/hyperopt/fmin.py in exhaust(self=<hyperopt.fmin.FMinIter object>)
    273             raise StopIteration()
    274         return self.trials
    275 
    276     def exhaust(self):
    277         n_done = len(self.trials)
--> 278         self.run(self.max_evals - n_done, block_until_done=self.asynchronous)
        self.run = <bound method FMinIter.run of <hyperopt.fmin.FMinIter object>>
        self.max_evals = 9223372036854775807
        n_done = 0
        self.asynchronous = False
    279         self.trials.refresh()
    280         return self
    281 
    282 

...........................................................................
/home/aquemy/dev/dp_hyperparameters/extension/hyperopt/fmin.py in run(self=<hyperopt.fmin.FMinIter object>, N=9223372036854775807, block_until_done=False)
    232                     if self.asynchronous:
    233                         # -- wait for workers to fill in the trials
    234                         time.sleep(self.poll_interval_secs)
    235                     else:
    236                         # -- loop over trials and do the jobs directly
--> 237                         self.serial_evaluate()
        self.serial_evaluate = <bound method FMinIter.serial_evaluate of <hyperopt.fmin.FMinIter object>>
    238                     try:
    239                         res = [d['result']['loss'] for d in
    240                                          self.trials.trials if
    241                                          d['result']['status'] == 'ok']

...........................................................................
/home/aquemy/dev/dp_hyperparameters/extension/hyperopt/fmin.py in serial_evaluate(self=<hyperopt.fmin.FMinIter object>, N=-1)
    138                 trial['book_time'] = now
    139                 trial['refresh_time'] = now
    140                 spec = base.spec_from_misc(trial['misc'])
    141                 ctrl = base.Ctrl(self.trials, current_trial=trial)
    142                 try:
--> 143                     result = self.domain.evaluate(spec, ctrl)
        result = undefined
        self.domain.evaluate = <bound method Domain.evaluate of <hyperopt.base.Domain object>>
        spec = {'bootstrap': 1, 'criterion': 1, 'features': 1, 'features_PCA_features__n_components': 1, 'max_depth': 4, 'max_features': 2, 'max_leaf_nodes': 3, 'min_samples_split': 2, 'n_estimators': 0, 'normalizer': 2, ...}
        ctrl = <hyperopt.base.Ctrl object>
    144                 except Exception as e:
    145                     logger.info('job exception: %s' % str(e))
    146                     trial['state'] = base.JOB_STATE_ERROR
    147                     trial['misc']['error'] = (str(type(e)), str(e))

...........................................................................
/home/aquemy/dev/dp_hyperparameters/extension/hyperopt/base.py in evaluate(self=<hyperopt.base.Domain object>, config={'bootstrap': 1, 'criterion': 1, 'features': 1, 'features_PCA_features__n_components': 1, 'max_depth': 4, 'max_features': 2, 'max_leaf_nodes': 3, 'min_samples_split': 2, 'n_estimators': 0, 'normalizer': 2, ...}, ctrl=<hyperopt.base.Ctrl object>, attach_attachments=True)
    841             #    or the normal Python part (self.fn)
    842             pyll_rval = pyll.rec_eval(
    843                 self.expr,
    844                 memo=memo,
    845                 print_node_on_error=self.rec_eval_print_node_on_error)
--> 846             rval = self.fn(pyll_rval)
        rval = undefined
        self.fn = <functools.partial object>
        pyll_rval = {'algorithm': {'bootstrap': False, 'criterion': 'entropy', 'max_depth': None, 'max_features': 3, 'max_leaf_nodes': None, 'min_samples_split': 5, 'n_estimators': 10}, 'pipeline': {'features': ('features_PCA', {'features__n_components': 2}), 'normalizer': ('normalizer_PowerTransformer', {}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 6})}}
    847 
    848         if isinstance(rval, (float, int, np.number)):
    849             dict_rval = {'loss': float(rval), 'status': STATUS_OK}
    850         else:

...........................................................................
/home/aquemy/dev/dp_hyperparameters/extension/experiment/objective.py in objective_joint(wconfig={'algorithm': {'bootstrap': False, 'criterion': 'entropy', 'max_depth': None, 'max_features': 3, 'max_leaf_nodes': None, 'min_samples_split': 5, 'n_estimators': 10}, 'pipeline': {'features': ('features_PCA', {'features__n_components': 2}), 'normalizer': ('normalizer_PowerTransformer', {}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 6})}}, algorithm='RandomForest', X=array([[1.799e+01, 1.038e+01, 1.228e+02, ..., 2...., ..., 0.000e+00, 2.871e-01,
        7.039e-02]]), y=array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,... 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1]), context={'baseline_score': 0.9545944602886527, 'baseline_score_std': 0.03716322883281839, 'best_config': {'algorithm': {'bootstrap': False, 'criterion': 'entropy', 'max_depth': None, 'max_features': 2, 'max_leaf_nodes': None, 'min_samples_split': 5, 'n_estimators': 10}, 'config_hash': {'algorithm': 'e7a772c2bc361aa61cf7eeb364a26dca2c9b89d6', 'config': 'afb67da069b544b0505b1e8c150edc7498ad37b4', 'pipeline': 'a43db4b4fc4c38610b7b5e484840d2e583089ff4'}, 'duration': 1.0073001384735107, 'iteration': 26, 'loss': 0.04749913577046061, 'max_history_score': 0.9525008642295394, 'max_history_score_std': 0.02225295065716913, 'max_history_step': 'joint', 'pipeline': {'features': ('features_PCA', {'features__n_components': 4}), 'normalizer': ('normalizer_StandardScaler', {'normalizer__with_mean': True, 'normalizer__with_std': False}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 7})}, 'score': 0.9525008642295394, ...}, 'history': [{'algorithm': {'bootstrap': True, 'criterion': 'entropy', 'max_depth': 4, 'max_features': 3, 'max_leaf_nodes': 3, 'min_samples_split': 2, 'n_estimators': 10}, 'config_hash': {'algorithm': '42527c4120073c2a488d1b8df28732f486d1578c', 'config': '51144ca42f9ea5ab2d8d58606e3b3e4d89c6d7b3', 'pipeline': '52f07bda29f9d3a95fabb87e591d0b2581ca8209'}, 'duration': 0.26703310012817383, 'iteration': 0, 'loss': 0.06655431682654922, 'max_history_score': 0.9334456831734508, 'max_history_score_std': 0.03819399139659311, 'max_history_step': 'joint', 'pipeline': {'features': ('features_NoneType', {}), 'normalizer': ('normalizer_RobustScaler', {'normalizer__quantile_range': (...), 'normalizer__with_centering': False, 'normalizer__with_scaling': False}), 'rebalance': ('rebalance_NearMiss', {'rebalance__n_neighbors': 1})}, 'score': 0.9334456831734508, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': None, 'max_features': 2, 'max_leaf_nodes': 3, 'min_samples_split': 2, 'n_estimators': 100}, 'config_hash': {'algorithm': '1b32258c630f07e01ab481ab925ab80aa757e482', 'config': '9e54ffcb6a727de032a0a2cd45c5cc37cc150756', 'pipeline': '37e72d4a97f5e784c9d3133e6379b91bfc3be803'}, 'duration': 1.3065669536590576, 'iteration': 1, 'loss': 0.05436435917379645, 'max_history_score': 0.9456356408262035, 'max_history_score_std': 0.040053650785990214, 'max_history_step': 'joint', 'pipeline': {'features': ('features_NoneType', {}), 'normalizer': ('normalizer_StandardScaler', {'normalizer__with_mean': True, 'normalizer__with_std': True}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 6})}, 'score': 0.9456356408262035, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'entropy', 'max_depth': 1, 'max_features': 1, 'max_leaf_nodes': 2, 'min_samples_split': 3, 'n_estimators': 25}, 'config_hash': {'algorithm': '68ab9059aa7ec74e0da87c81734b9664243b3eb4', 'config': 'e5241eee9ddf3f4ee29a4711f5bcc92a4d24cd09', 'pipeline': '62463de065924498cdcd2f2f1f7e68535cdb33a5'}, 'duration': 0.6592490673065186, 'iteration': 2, 'loss': 0.07695856019358727, 'max_history_score': 0.9456356408262035, 'max_history_score_std': 0.040053650785990214, 'max_history_step': 'joint', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 1, 'features__selectkbest__k': 2}), 'normalizer': ('normalizer_NoneType', {}), 'rebalance': ('rebalance_NoneType', {})}, 'score': 0.9230414398064127, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': 3, 'max_features': 2, 'max_leaf_nodes': 2, 'min_samples_split': 2, 'n_estimators': 25}, 'config_hash': {'algorithm': 'e3f1f7d7783557a38f40f0476369091edd87092b', 'config': '18ee4d3d1627472ec190326308d8755371a6dc62', 'pipeline': 'c6d1263e344ed8c71b2e6e4ba8e0db2fb6c777c0'}, 'duration': 0.879349946975708, 'iteration': 3, 'loss': 0.07535973554576114, 'max_history_score': 0.9456356408262035, 'max_history_score_std': 0.040053650785990214, 'max_history_step': 'joint', 'pipeline': {'features': ('features_NoneType', {}), 'normalizer': ('normalizer_RobustScaler', {'normalizer__quantile_range': (...), 'normalizer__with_centering': True, 'normalizer__with_scaling': True}), 'rebalance': ('rebalance_NearMiss', {'rebalance__n_neighbors': 2})}, 'score': 0.9246402644542389, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'gini', 'max_depth': 4, 'max_features': 2, 'max_leaf_nodes': 5, 'min_samples_split': 2, 'n_estimators': 50}, 'config_hash': {'algorithm': '47581af7253940f9647ad16d37347d34baf13e5f', 'config': '2af4f82b045c0c48ecb89d42728d1039fbff8878', 'pipeline': '2928b22ed834303cb7bac6e6608531eaddd7df67'}, 'duration': 4.372632026672363, 'iteration': 4, 'loss': 0.09121294615849984, 'max_history_score': 0.9456356408262035, 'max_history_score_std': 0.040053650785990214, 'max_history_step': 'joint', 'pipeline': {'features': ('features_NoneType', {}), 'normalizer': ('normalizer_MinMaxScaler', {}), 'rebalance': ('rebalance_CondensedNearestNeighbour', {'rebalance__n_neighbors': 2})}, 'score': 0.9087870538415002, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'entropy', 'max_depth': 2, 'max_features': 2, 'max_leaf_nodes': None, 'min_samples_split': 2, 'n_estimators': 10}, 'config_hash': {'algorithm': '0a85f98ca2d06103287f153633d88f7a0535e7e8', 'config': '17b2a1e5814f3e933137158708a5b6e9b2475495', 'pipeline': '95defa3bdd8357f11f872d3c280d50a6d8ee398d'}, 'duration': 2.625814914703369, 'iteration': 5, 'loss': 0.15471329185031535, 'max_history_score': 0.9456356408262035, 'max_history_score_std': 0.040053650785990214, 'max_history_step': 'joint', 'pipeline': {'features': ('features_SelectKBest', {'features__k': 2}), 'normalizer': ('normalizer_StandardScaler', {'normalizer__with_mean': False, 'normalizer__with_std': False}), 'rebalance': ('rebalance_CondensedNearestNeighbour', {'rebalance__n_neighbors': 1})}, 'score': 0.8452867081496847, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': 3, 'max_features': None, 'max_leaf_nodes': None, 'min_samples_split': 5, 'n_estimators': 75}, 'config_hash': {'algorithm': 'd7466a2c1d5cb3fa95029d73dc030f4c3c45a159', 'config': 'fa020a592ec5ac234f9f91aac28abc2cd1ec9d33', 'pipeline': '71e0d26f923d42cfe0e2fa748931ef2afe72ed86'}, 'duration': 3.62078595161438, 'iteration': 6, 'loss': 0.17066372828623277, 'max_history_score': 0.9456356408262035, 'max_history_score_std': 0.040053650785990214, 'max_history_step': 'joint', 'pipeline': {'features': ('features_SelectKBest', {'features__k': 1}), 'normalizer': ('normalizer_RobustScaler', {'normalizer__quantile_range': (...), 'normalizer__with_centering': True, 'normalizer__with_scaling': True}), 'rebalance': ('rebalance_CondensedNearestNeighbour', {'rebalance__n_neighbors': 1})}, 'score': 0.8293362717137672, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'entropy', 'max_depth': 3, 'max_features': 3, 'max_leaf_nodes': 5, 'min_samples_split': 5, 'n_estimators': 50}, 'config_hash': {'algorithm': '735caa9785596076014572a24050cde8dc338973', 'config': '0da4498002d6f452c59bb61756abb3ded841e786', 'pipeline': '51a53ea6ef5a2521ee65f76eb2da220ab7086513'}, 'duration': 0.6934049129486084, 'iteration': 7, 'loss': 0.06125875032408601, 'max_history_score': 0.9456356408262035, 'max_history_score_std': 0.040053650785990214, 'max_history_step': 'joint', 'pipeline': {'features': ('features_NoneType', {}), 'normalizer': ('normalizer_NoneType', {}), 'rebalance': ('rebalance_NearMiss', {'rebalance__n_neighbors': 3})}, 'score': 0.938741249675914, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': 4, 'max_features': 2, 'max_leaf_nodes': None, 'min_samples_split': 3, 'n_estimators': 75}, 'config_hash': {'algorithm': 'e71a1fe9515b6805f07914a61f2e7594be9e9afe', 'config': '344e4756fb1bec455d6af51d3727e33b0d27725f', 'pipeline': '248dad1d8b30a17a5de1d0bbdfe3e2acb7a1962b'}, 'duration': 1.3036692142486572, 'iteration': 8, 'loss': 0.06483125918243893, 'max_history_score': 0.9456356408262035, 'max_history_score_std': 0.040053650785990214, 'max_history_step': 'joint', 'pipeline': {'features': ('features_PCA', {'features__n_components': 2}), 'normalizer': ('normalizer_StandardScaler', {'normalizer__with_mean': False, 'normalizer__with_std': True}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 7})}, 'score': 0.9351687408175611, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'entropy', 'max_depth': 2, 'max_features': 2, 'max_leaf_nodes': 2, 'min_samples_split': 3, 'n_estimators': 10}, 'config_hash': {'algorithm': '0a507823f2ad8605ed5950e1fe61df0560f11a00', 'config': '4a538fdcf8e07f90e92a421c0d5c479d651629c7', 'pipeline': '5240329df25c9a533d025c1a401d49835a501b41'}, 'duration': 1.3821029663085938, 'iteration': 9, 'loss': 0.07006416904329793, 'max_history_score': 0.9456356408262035, 'max_history_score_std': 0.040053650785990214, 'max_history_step': 'joint', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 4, 'features__selectkbest__k': 2}), 'normalizer': ('normalizer_PowerTransformer', {}), 'rebalance': ('rebalance_NearMiss', {'rebalance__n_neighbors': 1})}, 'score': 0.9299358309567021, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'gini', 'max_depth': 1, 'max_features': 3, 'max_leaf_nodes': 5, 'min_samples_split': 3, 'n_estimators': 10}, 'config_hash': {'algorithm': 'd32739750d351948f8ff34a87c7d55b0c5e0d90f', 'config': 'c1609e71f1ce8486335adc70bb69a955580ba2c8', 'pipeline': 'f48b42ec5cf999279659966160a16353b75bdaa3'}, 'duration': 0.9055681228637695, 'iteration': 10, 'loss': 0.07532840722495904, 'max_history_score': 0.9456356408262035, 'max_history_score_std': 0.040053650785990214, 'max_history_step': 'joint', 'pipeline': {'features': ('features_PCA', {'features__n_components': 4}), 'normalizer': ('normalizer_PowerTransformer', {}), 'rebalance': ('rebalance_NearMiss', {'rebalance__n_neighbors': 1})}, 'score': 0.924671592775041, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': 3, 'max_features': 1, 'max_leaf_nodes': 5, 'min_samples_split': 3, 'n_estimators': 25}, 'config_hash': {'algorithm': 'f69bac35e71cbec1bfc1fb5942328a3390e7c252', 'config': 'abe36f188644e53e56ed3224236fa157107ed3b2', 'pipeline': 'aaf976c7c663a31fa039582d42f9e07101556a7c'}, 'duration': 0.764197826385498, 'iteration': 11, 'loss': 0.06818446979517778, 'max_history_score': 0.9456356408262035, 'max_history_score_std': 0.040053650785990214, 'max_history_step': 'joint', 'pipeline': {'features': ('features_NoneType', {}), 'normalizer': ('normalizer_PowerTransformer', {}), 'rebalance': ('rebalance_NoneType', {})}, 'score': 0.9318155302048222, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'entropy', 'max_depth': None, 'max_features': None, 'max_leaf_nodes': None, 'min_samples_split': 5, 'n_estimators': 25}, 'config_hash': {'algorithm': 'a0a27aec00db5ddf71eab96663f9bd61c845f5e3', 'config': '76aa002c3c9d4d9722466c60daf5119c18a41d2a', 'pipeline': '1ce34b7894ef342571d974bb19e8ec821a512c6b'}, 'duration': 1.1636500358581543, 'iteration': 12, 'loss': 0.12833700630887557, 'max_history_score': 0.9456356408262035, 'max_history_score_std': 0.040053650785990214, 'max_history_step': 'joint', 'pipeline': {'features': ('features_PCA', {'features__n_components': 1}), 'normalizer': ('normalizer_PowerTransformer', {}), 'rebalance': ('rebalance_NoneType', {})}, 'score': 0.8716629936911244, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'gini', 'max_depth': 1, 'max_features': 2, 'max_leaf_nodes': 2, 'min_samples_split': 2, 'n_estimators': 100}, 'config_hash': {'algorithm': '985c99dff1da9b2c87e4211c5335a9159aa9dbcb', 'config': 'f56a7a9e43a0a699e992dc1262e550b8b7c88538', 'pipeline': '5c934f6d9a8ad1f9afe762986a9cf2074fc95d79'}, 'duration': 2.235443115234375, 'iteration': 13, 'loss': 0.11414635727249167, 'max_history_score': 0.9456356408262035, 'max_history_score_std': 0.040053650785990214, 'max_history_step': 'joint', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 1, 'features__selectkbest__k': 1}), 'normalizer': ('normalizer_RobustScaler', {'normalizer__quantile_range': (...), 'normalizer__with_centering': False, 'normalizer__with_scaling': True}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 6})}, 'score': 0.8858536427275083, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'gini', 'max_depth': 1, 'max_features': 1, 'max_leaf_nodes': None, 'min_samples_split': 5, 'n_estimators': 10}, 'config_hash': {'algorithm': '7d74a39aac2579264a402aef2b6fa7943c19f3d3', 'config': '53f44c0ad925c5c08c25d4fadf5e9ee9d7c181cd', 'pipeline': '6eff5ef31d7d1d534db31913bb67529c8a24c42e'}, 'duration': 2.7847659587860107, 'iteration': 14, 'loss': 0.14061986863711007, 'max_history_score': 0.9456356408262035, 'max_history_score_std': 0.040053650785990214, 'max_history_step': 'joint', 'pipeline': {'features': ('features_PCA', {'features__n_components': 1}), 'normalizer': ('normalizer_RobustScaler', {'normalizer__quantile_range': (...), 'normalizer__with_centering': True, 'normalizer__with_scaling': True}), 'rebalance': ('rebalance_CondensedNearestNeighbour', {'rebalance__n_neighbors': 3})}, 'score': 0.8593801313628899, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'entropy', 'max_depth': 3, 'max_features': None, 'max_leaf_nodes': 5, 'min_samples_split': 2, 'n_estimators': 100}, 'config_hash': {'algorithm': 'c62d7c671832e4414b6b2d7c36cba5ddc83a0ed0', 'config': '5faee50671eaa0ac586722bff234e36a857e662d', 'pipeline': '8b29a55de2add78c49114b9bbe5e800e5524c59d'}, 'duration': 2.3916029930114746, 'iteration': 15, 'loss': 0.08770093336790252, 'max_history_score': 0.9456356408262035, 'max_history_score_std': 0.040053650785990214, 'max_history_step': 'joint', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 3, 'features__selectkbest__k': 4}), 'normalizer': ('normalizer_RobustScaler', {'normalizer__quantile_range': (...), 'normalizer__with_centering': True, 'normalizer__with_scaling': True}), 'rebalance': ('rebalance_NoneType', {})}, 'score': 0.9122990666320975, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': None, 'max_features': 1, 'max_leaf_nodes': 5, 'min_samples_split': 5, 'n_estimators': 10}, 'config_hash': {'algorithm': '290772bfb9b8ed15c48a72829e822fb0a07481d6', 'config': '9a04f25d8eb3db5b2f831abd341a6d384c73a957', 'pipeline': '1ce34b7894ef342571d974bb19e8ec821a512c6b'}, 'duration': 1.4364500045776367, 'iteration': 16, 'loss': 0.08948880822746508, 'max_history_score': 0.9456356408262035, 'max_history_score_std': 0.040053650785990214, 'max_history_step': 'joint', 'pipeline': {'features': ('features_PCA', {'features__n_components': 1}), 'normalizer': ('normalizer_PowerTransformer', {}), 'rebalance': ('rebalance_NoneType', {})}, 'score': 0.9105111917725349, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': 2, 'max_features': 3, 'max_leaf_nodes': 3, 'min_samples_split': 3, 'n_estimators': 100}, 'config_hash': {'algorithm': '7dab6d47f897c2961d3402eff844aff16a7d142a', 'config': '4dbfa2688b239be9f372d3e80223960ba9a1fbdd', 'pipeline': 'cdef51702798fa49f11c11d80baf3ab43d5358fc'}, 'duration': 0.9830451011657715, 'iteration': 17, 'loss': 1.0, 'max_history_score': 0.9456356408262035, 'max_history_score_std': 0.040053650785990214, 'max_history_step': 'joint', 'pipeline': {'features': ('features_SelectKBest', {'features__k': 2}), 'normalizer': ('normalizer_PowerTransformer', {}), 'rebalance': ('rebalance_NearMiss', {'rebalance__n_neighbors': 1})}, 'score': 0.0, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'entropy', 'max_depth': None, 'max_features': 3, 'max_leaf_nodes': None, 'min_samples_split': 5, 'n_estimators': 10}, 'config_hash': {'algorithm': 'def83e48be05ef92a37e1a90585820f2f67ff42b', 'config': '95902552cb76e9798f0fa58782bd72bd1cc272d7', 'pipeline': '1775187bf23f94f4fd0cc1e5c1ef665210edded5'}, 'duration': 2.0033559799194336, 'iteration': 18, 'loss': 0.04922327370149515, 'max_history_score': 0.9507767262985048, 'max_history_score_std': 0.028328108925705902, 'max_history_step': 'joint', 'pipeline': {'features': ('features_PCA', {'features__n_components': 4}), 'normalizer': ('normalizer_StandardScaler', {'normalizer__with_mean': True, 'normalizer__with_std': True}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 5})}, 'score': 0.9507767262985048, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'gini', 'max_depth': 1, 'max_features': 3, 'max_leaf_nodes': None, 'min_samples_split': 2, 'n_estimators': 50}, 'config_hash': {'algorithm': '4e9e3275f817df75115d9d7e3366980fc1b4cf13', 'config': '7770b19007b40bf13005d52eb81f87bc401f15b4', 'pipeline': 'c4dd111513ea35f97dd3aec3e8e7f6268ce035da'}, 'duration': 0.9069631099700928, 'iteration': 19, 'loss': 1.0, 'max_history_score': 0.9507767262985048, 'max_history_score_std': 0.028328108925705902, 'max_history_step': 'joint', 'pipeline': {'features': ('features_PCA', {'features__n_components': 2}), 'normalizer': ('normalizer_RobustScaler', {'normalizer__quantile_range': (...), 'normalizer__with_centering': False, 'normalizer__with_scaling': True}), 'rebalance': ('rebalance_NearMiss', {'rebalance__n_neighbors': 2})}, 'score': 0.0, ...}, ...], 'history_hash': ['51144ca42f9ea5ab2d8d58606e3b3e4d89c6d7b3', '9e54ffcb6a727de032a0a2cd45c5cc37cc150756', 'e5241eee9ddf3f4ee29a4711f5bcc92a4d24cd09', '18ee4d3d1627472ec190326308d8755371a6dc62', '2af4f82b045c0c48ecb89d42728d1039fbff8878', '17b2a1e5814f3e933137158708a5b6e9b2475495', 'fa020a592ec5ac234f9f91aac28abc2cd1ec9d33', '0da4498002d6f452c59bb61756abb3ded841e786', '344e4756fb1bec455d6af51d3727e33b0d27725f', '4a538fdcf8e07f90e92a421c0d5c479d651629c7', 'c1609e71f1ce8486335adc70bb69a955580ba2c8', 'abe36f188644e53e56ed3224236fa157107ed3b2', '76aa002c3c9d4d9722466c60daf5119c18a41d2a', 'f56a7a9e43a0a699e992dc1262e550b8b7c88538', '53f44c0ad925c5c08c25d4fadf5e9ee9d7c181cd', '5faee50671eaa0ac586722bff234e36a857e662d', '9a04f25d8eb3db5b2f831abd341a6d384c73a957', '4dbfa2688b239be9f372d3e80223960ba9a1fbdd', '95902552cb76e9798f0fa58782bd72bd1cc272d7', '7770b19007b40bf13005d52eb81f87bc401f15b4', ...], 'history_index': {'0212926e8a56cc42ae0a654a90c2a3ee92464265': 91, '0da4498002d6f452c59bb61756abb3ded841e786': 7, '0f77a69b0a8d34861caf915a51dc588ff8d4efac': 61, '127553d555ed39231b8da3a1ce42d3902e30919b': 59, '17b2a1e5814f3e933137158708a5b6e9b2475495': 5, '18ee4d3d1627472ec190326308d8755371a6dc62': 3, '1b2267555a9226d7eb4df3c63dd12506da370f4d': 56, '278dd514f71ea681b3e2238dde3b16c35f1697db': 90, '2873878df7d4db8b415ff446bec08003e0c7488d': 92, '28b2db1bf9b505aa8e490d811b55f6655178ede7': 67, ...}, 'iteration': 92, 'max_history_score': 0.9525008642295394, 'max_history_score_std': 0.02225295065716913, 'max_history_step': 'joint'}, config={'algorithm': 'RandomForest', 'seed': 42, 'time': 300})
    108 
    109 def objective_algo(algo_config, current_pipeline_config, algorithm, X, y, context, config):
    110     return objective(current_pipeline_config, algo_config, algorithm, X, y, context, config, step='algorithm')
    111 
    112 def objective_joint(wconfig, algorithm, X, y, context, config):
--> 113     return objective(wconfig['pipeline'], wconfig['algorithm'], algorithm, X, y, context, config, step='joint')
        wconfig = {'algorithm': {'bootstrap': False, 'criterion': 'entropy', 'max_depth': None, 'max_features': 3, 'max_leaf_nodes': None, 'min_samples_split': 5, 'n_estimators': 10}, 'pipeline': {'features': ('features_PCA', {'features__n_components': 2}), 'normalizer': ('normalizer_PowerTransformer', {}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 6})}}
        algorithm = 'RandomForest'
        X = array([[1.799e+01, 1.038e+01, 1.228e+02, ..., 2...., ..., 0.000e+00, 2.871e-01,
        7.039e-02]])
        y = array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,... 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1])
        context = {'baseline_score': 0.9545944602886527, 'baseline_score_std': 0.03716322883281839, 'best_config': {'algorithm': {'bootstrap': False, 'criterion': 'entropy', 'max_depth': None, 'max_features': 2, 'max_leaf_nodes': None, 'min_samples_split': 5, 'n_estimators': 10}, 'config_hash': {'algorithm': 'e7a772c2bc361aa61cf7eeb364a26dca2c9b89d6', 'config': 'afb67da069b544b0505b1e8c150edc7498ad37b4', 'pipeline': 'a43db4b4fc4c38610b7b5e484840d2e583089ff4'}, 'duration': 1.0073001384735107, 'iteration': 26, 'loss': 0.04749913577046061, 'max_history_score': 0.9525008642295394, 'max_history_score_std': 0.02225295065716913, 'max_history_step': 'joint', 'pipeline': {'features': ('features_PCA', {'features__n_components': 4}), 'normalizer': ('normalizer_StandardScaler', {'normalizer__with_mean': True, 'normalizer__with_std': False}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 7})}, 'score': 0.9525008642295394, ...}, 'history': [{'algorithm': {'bootstrap': True, 'criterion': 'entropy', 'max_depth': 4, 'max_features': 3, 'max_leaf_nodes': 3, 'min_samples_split': 2, 'n_estimators': 10}, 'config_hash': {'algorithm': '42527c4120073c2a488d1b8df28732f486d1578c', 'config': '51144ca42f9ea5ab2d8d58606e3b3e4d89c6d7b3', 'pipeline': '52f07bda29f9d3a95fabb87e591d0b2581ca8209'}, 'duration': 0.26703310012817383, 'iteration': 0, 'loss': 0.06655431682654922, 'max_history_score': 0.9334456831734508, 'max_history_score_std': 0.03819399139659311, 'max_history_step': 'joint', 'pipeline': {'features': ('features_NoneType', {}), 'normalizer': ('normalizer_RobustScaler', {'normalizer__quantile_range': (...), 'normalizer__with_centering': False, 'normalizer__with_scaling': False}), 'rebalance': ('rebalance_NearMiss', {'rebalance__n_neighbors': 1})}, 'score': 0.9334456831734508, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': None, 'max_features': 2, 'max_leaf_nodes': 3, 'min_samples_split': 2, 'n_estimators': 100}, 'config_hash': {'algorithm': '1b32258c630f07e01ab481ab925ab80aa757e482', 'config': '9e54ffcb6a727de032a0a2cd45c5cc37cc150756', 'pipeline': '37e72d4a97f5e784c9d3133e6379b91bfc3be803'}, 'duration': 1.3065669536590576, 'iteration': 1, 'loss': 0.05436435917379645, 'max_history_score': 0.9456356408262035, 'max_history_score_std': 0.040053650785990214, 'max_history_step': 'joint', 'pipeline': {'features': ('features_NoneType', {}), 'normalizer': ('normalizer_StandardScaler', {'normalizer__with_mean': True, 'normalizer__with_std': True}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 6})}, 'score': 0.9456356408262035, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'entropy', 'max_depth': 1, 'max_features': 1, 'max_leaf_nodes': 2, 'min_samples_split': 3, 'n_estimators': 25}, 'config_hash': {'algorithm': '68ab9059aa7ec74e0da87c81734b9664243b3eb4', 'config': 'e5241eee9ddf3f4ee29a4711f5bcc92a4d24cd09', 'pipeline': '62463de065924498cdcd2f2f1f7e68535cdb33a5'}, 'duration': 0.6592490673065186, 'iteration': 2, 'loss': 0.07695856019358727, 'max_history_score': 0.9456356408262035, 'max_history_score_std': 0.040053650785990214, 'max_history_step': 'joint', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 1, 'features__selectkbest__k': 2}), 'normalizer': ('normalizer_NoneType', {}), 'rebalance': ('rebalance_NoneType', {})}, 'score': 0.9230414398064127, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': 3, 'max_features': 2, 'max_leaf_nodes': 2, 'min_samples_split': 2, 'n_estimators': 25}, 'config_hash': {'algorithm': 'e3f1f7d7783557a38f40f0476369091edd87092b', 'config': '18ee4d3d1627472ec190326308d8755371a6dc62', 'pipeline': 'c6d1263e344ed8c71b2e6e4ba8e0db2fb6c777c0'}, 'duration': 0.879349946975708, 'iteration': 3, 'loss': 0.07535973554576114, 'max_history_score': 0.9456356408262035, 'max_history_score_std': 0.040053650785990214, 'max_history_step': 'joint', 'pipeline': {'features': ('features_NoneType', {}), 'normalizer': ('normalizer_RobustScaler', {'normalizer__quantile_range': (...), 'normalizer__with_centering': True, 'normalizer__with_scaling': True}), 'rebalance': ('rebalance_NearMiss', {'rebalance__n_neighbors': 2})}, 'score': 0.9246402644542389, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'gini', 'max_depth': 4, 'max_features': 2, 'max_leaf_nodes': 5, 'min_samples_split': 2, 'n_estimators': 50}, 'config_hash': {'algorithm': '47581af7253940f9647ad16d37347d34baf13e5f', 'config': '2af4f82b045c0c48ecb89d42728d1039fbff8878', 'pipeline': '2928b22ed834303cb7bac6e6608531eaddd7df67'}, 'duration': 4.372632026672363, 'iteration': 4, 'loss': 0.09121294615849984, 'max_history_score': 0.9456356408262035, 'max_history_score_std': 0.040053650785990214, 'max_history_step': 'joint', 'pipeline': {'features': ('features_NoneType', {}), 'normalizer': ('normalizer_MinMaxScaler', {}), 'rebalance': ('rebalance_CondensedNearestNeighbour', {'rebalance__n_neighbors': 2})}, 'score': 0.9087870538415002, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'entropy', 'max_depth': 2, 'max_features': 2, 'max_leaf_nodes': None, 'min_samples_split': 2, 'n_estimators': 10}, 'config_hash': {'algorithm': '0a85f98ca2d06103287f153633d88f7a0535e7e8', 'config': '17b2a1e5814f3e933137158708a5b6e9b2475495', 'pipeline': '95defa3bdd8357f11f872d3c280d50a6d8ee398d'}, 'duration': 2.625814914703369, 'iteration': 5, 'loss': 0.15471329185031535, 'max_history_score': 0.9456356408262035, 'max_history_score_std': 0.040053650785990214, 'max_history_step': 'joint', 'pipeline': {'features': ('features_SelectKBest', {'features__k': 2}), 'normalizer': ('normalizer_StandardScaler', {'normalizer__with_mean': False, 'normalizer__with_std': False}), 'rebalance': ('rebalance_CondensedNearestNeighbour', {'rebalance__n_neighbors': 1})}, 'score': 0.8452867081496847, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': 3, 'max_features': None, 'max_leaf_nodes': None, 'min_samples_split': 5, 'n_estimators': 75}, 'config_hash': {'algorithm': 'd7466a2c1d5cb3fa95029d73dc030f4c3c45a159', 'config': 'fa020a592ec5ac234f9f91aac28abc2cd1ec9d33', 'pipeline': '71e0d26f923d42cfe0e2fa748931ef2afe72ed86'}, 'duration': 3.62078595161438, 'iteration': 6, 'loss': 0.17066372828623277, 'max_history_score': 0.9456356408262035, 'max_history_score_std': 0.040053650785990214, 'max_history_step': 'joint', 'pipeline': {'features': ('features_SelectKBest', {'features__k': 1}), 'normalizer': ('normalizer_RobustScaler', {'normalizer__quantile_range': (...), 'normalizer__with_centering': True, 'normalizer__with_scaling': True}), 'rebalance': ('rebalance_CondensedNearestNeighbour', {'rebalance__n_neighbors': 1})}, 'score': 0.8293362717137672, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'entropy', 'max_depth': 3, 'max_features': 3, 'max_leaf_nodes': 5, 'min_samples_split': 5, 'n_estimators': 50}, 'config_hash': {'algorithm': '735caa9785596076014572a24050cde8dc338973', 'config': '0da4498002d6f452c59bb61756abb3ded841e786', 'pipeline': '51a53ea6ef5a2521ee65f76eb2da220ab7086513'}, 'duration': 0.6934049129486084, 'iteration': 7, 'loss': 0.06125875032408601, 'max_history_score': 0.9456356408262035, 'max_history_score_std': 0.040053650785990214, 'max_history_step': 'joint', 'pipeline': {'features': ('features_NoneType', {}), 'normalizer': ('normalizer_NoneType', {}), 'rebalance': ('rebalance_NearMiss', {'rebalance__n_neighbors': 3})}, 'score': 0.938741249675914, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': 4, 'max_features': 2, 'max_leaf_nodes': None, 'min_samples_split': 3, 'n_estimators': 75}, 'config_hash': {'algorithm': 'e71a1fe9515b6805f07914a61f2e7594be9e9afe', 'config': '344e4756fb1bec455d6af51d3727e33b0d27725f', 'pipeline': '248dad1d8b30a17a5de1d0bbdfe3e2acb7a1962b'}, 'duration': 1.3036692142486572, 'iteration': 8, 'loss': 0.06483125918243893, 'max_history_score': 0.9456356408262035, 'max_history_score_std': 0.040053650785990214, 'max_history_step': 'joint', 'pipeline': {'features': ('features_PCA', {'features__n_components': 2}), 'normalizer': ('normalizer_StandardScaler', {'normalizer__with_mean': False, 'normalizer__with_std': True}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 7})}, 'score': 0.9351687408175611, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'entropy', 'max_depth': 2, 'max_features': 2, 'max_leaf_nodes': 2, 'min_samples_split': 3, 'n_estimators': 10}, 'config_hash': {'algorithm': '0a507823f2ad8605ed5950e1fe61df0560f11a00', 'config': '4a538fdcf8e07f90e92a421c0d5c479d651629c7', 'pipeline': '5240329df25c9a533d025c1a401d49835a501b41'}, 'duration': 1.3821029663085938, 'iteration': 9, 'loss': 0.07006416904329793, 'max_history_score': 0.9456356408262035, 'max_history_score_std': 0.040053650785990214, 'max_history_step': 'joint', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 4, 'features__selectkbest__k': 2}), 'normalizer': ('normalizer_PowerTransformer', {}), 'rebalance': ('rebalance_NearMiss', {'rebalance__n_neighbors': 1})}, 'score': 0.9299358309567021, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'gini', 'max_depth': 1, 'max_features': 3, 'max_leaf_nodes': 5, 'min_samples_split': 3, 'n_estimators': 10}, 'config_hash': {'algorithm': 'd32739750d351948f8ff34a87c7d55b0c5e0d90f', 'config': 'c1609e71f1ce8486335adc70bb69a955580ba2c8', 'pipeline': 'f48b42ec5cf999279659966160a16353b75bdaa3'}, 'duration': 0.9055681228637695, 'iteration': 10, 'loss': 0.07532840722495904, 'max_history_score': 0.9456356408262035, 'max_history_score_std': 0.040053650785990214, 'max_history_step': 'joint', 'pipeline': {'features': ('features_PCA', {'features__n_components': 4}), 'normalizer': ('normalizer_PowerTransformer', {}), 'rebalance': ('rebalance_NearMiss', {'rebalance__n_neighbors': 1})}, 'score': 0.924671592775041, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': 3, 'max_features': 1, 'max_leaf_nodes': 5, 'min_samples_split': 3, 'n_estimators': 25}, 'config_hash': {'algorithm': 'f69bac35e71cbec1bfc1fb5942328a3390e7c252', 'config': 'abe36f188644e53e56ed3224236fa157107ed3b2', 'pipeline': 'aaf976c7c663a31fa039582d42f9e07101556a7c'}, 'duration': 0.764197826385498, 'iteration': 11, 'loss': 0.06818446979517778, 'max_history_score': 0.9456356408262035, 'max_history_score_std': 0.040053650785990214, 'max_history_step': 'joint', 'pipeline': {'features': ('features_NoneType', {}), 'normalizer': ('normalizer_PowerTransformer', {}), 'rebalance': ('rebalance_NoneType', {})}, 'score': 0.9318155302048222, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'entropy', 'max_depth': None, 'max_features': None, 'max_leaf_nodes': None, 'min_samples_split': 5, 'n_estimators': 25}, 'config_hash': {'algorithm': 'a0a27aec00db5ddf71eab96663f9bd61c845f5e3', 'config': '76aa002c3c9d4d9722466c60daf5119c18a41d2a', 'pipeline': '1ce34b7894ef342571d974bb19e8ec821a512c6b'}, 'duration': 1.1636500358581543, 'iteration': 12, 'loss': 0.12833700630887557, 'max_history_score': 0.9456356408262035, 'max_history_score_std': 0.040053650785990214, 'max_history_step': 'joint', 'pipeline': {'features': ('features_PCA', {'features__n_components': 1}), 'normalizer': ('normalizer_PowerTransformer', {}), 'rebalance': ('rebalance_NoneType', {})}, 'score': 0.8716629936911244, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'gini', 'max_depth': 1, 'max_features': 2, 'max_leaf_nodes': 2, 'min_samples_split': 2, 'n_estimators': 100}, 'config_hash': {'algorithm': '985c99dff1da9b2c87e4211c5335a9159aa9dbcb', 'config': 'f56a7a9e43a0a699e992dc1262e550b8b7c88538', 'pipeline': '5c934f6d9a8ad1f9afe762986a9cf2074fc95d79'}, 'duration': 2.235443115234375, 'iteration': 13, 'loss': 0.11414635727249167, 'max_history_score': 0.9456356408262035, 'max_history_score_std': 0.040053650785990214, 'max_history_step': 'joint', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 1, 'features__selectkbest__k': 1}), 'normalizer': ('normalizer_RobustScaler', {'normalizer__quantile_range': (...), 'normalizer__with_centering': False, 'normalizer__with_scaling': True}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 6})}, 'score': 0.8858536427275083, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'gini', 'max_depth': 1, 'max_features': 1, 'max_leaf_nodes': None, 'min_samples_split': 5, 'n_estimators': 10}, 'config_hash': {'algorithm': '7d74a39aac2579264a402aef2b6fa7943c19f3d3', 'config': '53f44c0ad925c5c08c25d4fadf5e9ee9d7c181cd', 'pipeline': '6eff5ef31d7d1d534db31913bb67529c8a24c42e'}, 'duration': 2.7847659587860107, 'iteration': 14, 'loss': 0.14061986863711007, 'max_history_score': 0.9456356408262035, 'max_history_score_std': 0.040053650785990214, 'max_history_step': 'joint', 'pipeline': {'features': ('features_PCA', {'features__n_components': 1}), 'normalizer': ('normalizer_RobustScaler', {'normalizer__quantile_range': (...), 'normalizer__with_centering': True, 'normalizer__with_scaling': True}), 'rebalance': ('rebalance_CondensedNearestNeighbour', {'rebalance__n_neighbors': 3})}, 'score': 0.8593801313628899, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'entropy', 'max_depth': 3, 'max_features': None, 'max_leaf_nodes': 5, 'min_samples_split': 2, 'n_estimators': 100}, 'config_hash': {'algorithm': 'c62d7c671832e4414b6b2d7c36cba5ddc83a0ed0', 'config': '5faee50671eaa0ac586722bff234e36a857e662d', 'pipeline': '8b29a55de2add78c49114b9bbe5e800e5524c59d'}, 'duration': 2.3916029930114746, 'iteration': 15, 'loss': 0.08770093336790252, 'max_history_score': 0.9456356408262035, 'max_history_score_std': 0.040053650785990214, 'max_history_step': 'joint', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 3, 'features__selectkbest__k': 4}), 'normalizer': ('normalizer_RobustScaler', {'normalizer__quantile_range': (...), 'normalizer__with_centering': True, 'normalizer__with_scaling': True}), 'rebalance': ('rebalance_NoneType', {})}, 'score': 0.9122990666320975, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': None, 'max_features': 1, 'max_leaf_nodes': 5, 'min_samples_split': 5, 'n_estimators': 10}, 'config_hash': {'algorithm': '290772bfb9b8ed15c48a72829e822fb0a07481d6', 'config': '9a04f25d8eb3db5b2f831abd341a6d384c73a957', 'pipeline': '1ce34b7894ef342571d974bb19e8ec821a512c6b'}, 'duration': 1.4364500045776367, 'iteration': 16, 'loss': 0.08948880822746508, 'max_history_score': 0.9456356408262035, 'max_history_score_std': 0.040053650785990214, 'max_history_step': 'joint', 'pipeline': {'features': ('features_PCA', {'features__n_components': 1}), 'normalizer': ('normalizer_PowerTransformer', {}), 'rebalance': ('rebalance_NoneType', {})}, 'score': 0.9105111917725349, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': 2, 'max_features': 3, 'max_leaf_nodes': 3, 'min_samples_split': 3, 'n_estimators': 100}, 'config_hash': {'algorithm': '7dab6d47f897c2961d3402eff844aff16a7d142a', 'config': '4dbfa2688b239be9f372d3e80223960ba9a1fbdd', 'pipeline': 'cdef51702798fa49f11c11d80baf3ab43d5358fc'}, 'duration': 0.9830451011657715, 'iteration': 17, 'loss': 1.0, 'max_history_score': 0.9456356408262035, 'max_history_score_std': 0.040053650785990214, 'max_history_step': 'joint', 'pipeline': {'features': ('features_SelectKBest', {'features__k': 2}), 'normalizer': ('normalizer_PowerTransformer', {}), 'rebalance': ('rebalance_NearMiss', {'rebalance__n_neighbors': 1})}, 'score': 0.0, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'entropy', 'max_depth': None, 'max_features': 3, 'max_leaf_nodes': None, 'min_samples_split': 5, 'n_estimators': 10}, 'config_hash': {'algorithm': 'def83e48be05ef92a37e1a90585820f2f67ff42b', 'config': '95902552cb76e9798f0fa58782bd72bd1cc272d7', 'pipeline': '1775187bf23f94f4fd0cc1e5c1ef665210edded5'}, 'duration': 2.0033559799194336, 'iteration': 18, 'loss': 0.04922327370149515, 'max_history_score': 0.9507767262985048, 'max_history_score_std': 0.028328108925705902, 'max_history_step': 'joint', 'pipeline': {'features': ('features_PCA', {'features__n_components': 4}), 'normalizer': ('normalizer_StandardScaler', {'normalizer__with_mean': True, 'normalizer__with_std': True}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 5})}, 'score': 0.9507767262985048, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'gini', 'max_depth': 1, 'max_features': 3, 'max_leaf_nodes': None, 'min_samples_split': 2, 'n_estimators': 50}, 'config_hash': {'algorithm': '4e9e3275f817df75115d9d7e3366980fc1b4cf13', 'config': '7770b19007b40bf13005d52eb81f87bc401f15b4', 'pipeline': 'c4dd111513ea35f97dd3aec3e8e7f6268ce035da'}, 'duration': 0.9069631099700928, 'iteration': 19, 'loss': 1.0, 'max_history_score': 0.9507767262985048, 'max_history_score_std': 0.028328108925705902, 'max_history_step': 'joint', 'pipeline': {'features': ('features_PCA', {'features__n_components': 2}), 'normalizer': ('normalizer_RobustScaler', {'normalizer__quantile_range': (...), 'normalizer__with_centering': False, 'normalizer__with_scaling': True}), 'rebalance': ('rebalance_NearMiss', {'rebalance__n_neighbors': 2})}, 'score': 0.0, ...}, ...], 'history_hash': ['51144ca42f9ea5ab2d8d58606e3b3e4d89c6d7b3', '9e54ffcb6a727de032a0a2cd45c5cc37cc150756', 'e5241eee9ddf3f4ee29a4711f5bcc92a4d24cd09', '18ee4d3d1627472ec190326308d8755371a6dc62', '2af4f82b045c0c48ecb89d42728d1039fbff8878', '17b2a1e5814f3e933137158708a5b6e9b2475495', 'fa020a592ec5ac234f9f91aac28abc2cd1ec9d33', '0da4498002d6f452c59bb61756abb3ded841e786', '344e4756fb1bec455d6af51d3727e33b0d27725f', '4a538fdcf8e07f90e92a421c0d5c479d651629c7', 'c1609e71f1ce8486335adc70bb69a955580ba2c8', 'abe36f188644e53e56ed3224236fa157107ed3b2', '76aa002c3c9d4d9722466c60daf5119c18a41d2a', 'f56a7a9e43a0a699e992dc1262e550b8b7c88538', '53f44c0ad925c5c08c25d4fadf5e9ee9d7c181cd', '5faee50671eaa0ac586722bff234e36a857e662d', '9a04f25d8eb3db5b2f831abd341a6d384c73a957', '4dbfa2688b239be9f372d3e80223960ba9a1fbdd', '95902552cb76e9798f0fa58782bd72bd1cc272d7', '7770b19007b40bf13005d52eb81f87bc401f15b4', ...], 'history_index': {'0212926e8a56cc42ae0a654a90c2a3ee92464265': 91, '0da4498002d6f452c59bb61756abb3ded841e786': 7, '0f77a69b0a8d34861caf915a51dc588ff8d4efac': 61, '127553d555ed39231b8da3a1ce42d3902e30919b': 59, '17b2a1e5814f3e933137158708a5b6e9b2475495': 5, '18ee4d3d1627472ec190326308d8755371a6dc62': 3, '1b2267555a9226d7eb4df3c63dd12506da370f4d': 56, '278dd514f71ea681b3e2238dde3b16c35f1697db': 90, '2873878df7d4db8b415ff446bec08003e0c7488d': 92, '28b2db1bf9b505aa8e490d811b55f6655178ede7': 67, ...}, 'iteration': 92, 'max_history_score': 0.9525008642295394, 'max_history_score_std': 0.02225295065716913, 'max_history_step': 'joint'}
        config = {'algorithm': 'RandomForest', 'seed': 42, 'time': 300}
    114 
    115 
    116 def get_baseline_score(algorithm, X, y, seed):
    117     pipeline, _ = pipeline_conf_to_full_pipeline(

...........................................................................
/home/aquemy/dev/dp_hyperparameters/extension/experiment/objective.py in objective(pipeline_config={'features': ('features_PCA', {'features__n_components': 2}), 'normalizer': ('normalizer_PowerTransformer', {}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 6})}, algo_config={'bootstrap': False, 'criterion': 'entropy', 'max_depth': None, 'max_features': 3, 'max_leaf_nodes': None, 'min_samples_split': 5, 'n_estimators': 10}, algorithm='RandomForest', X=array([[1.799e+01, 1.038e+01, 1.228e+02, ..., 2...., ..., 0.000e+00, 2.871e-01,
        7.039e-02]]), y=array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,... 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1]), context={'baseline_score': 0.9545944602886527, 'baseline_score_std': 0.03716322883281839, 'best_config': {'algorithm': {'bootstrap': False, 'criterion': 'entropy', 'max_depth': None, 'max_features': 2, 'max_leaf_nodes': None, 'min_samples_split': 5, 'n_estimators': 10}, 'config_hash': {'algorithm': 'e7a772c2bc361aa61cf7eeb364a26dca2c9b89d6', 'config': 'afb67da069b544b0505b1e8c150edc7498ad37b4', 'pipeline': 'a43db4b4fc4c38610b7b5e484840d2e583089ff4'}, 'duration': 1.0073001384735107, 'iteration': 26, 'loss': 0.04749913577046061, 'max_history_score': 0.9525008642295394, 'max_history_score_std': 0.02225295065716913, 'max_history_step': 'joint', 'pipeline': {'features': ('features_PCA', {'features__n_components': 4}), 'normalizer': ('normalizer_StandardScaler', {'normalizer__with_mean': True, 'normalizer__with_std': False}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 7})}, 'score': 0.9525008642295394, ...}, 'history': [{'algorithm': {'bootstrap': True, 'criterion': 'entropy', 'max_depth': 4, 'max_features': 3, 'max_leaf_nodes': 3, 'min_samples_split': 2, 'n_estimators': 10}, 'config_hash': {'algorithm': '42527c4120073c2a488d1b8df28732f486d1578c', 'config': '51144ca42f9ea5ab2d8d58606e3b3e4d89c6d7b3', 'pipeline': '52f07bda29f9d3a95fabb87e591d0b2581ca8209'}, 'duration': 0.26703310012817383, 'iteration': 0, 'loss': 0.06655431682654922, 'max_history_score': 0.9334456831734508, 'max_history_score_std': 0.03819399139659311, 'max_history_step': 'joint', 'pipeline': {'features': ('features_NoneType', {}), 'normalizer': ('normalizer_RobustScaler', {'normalizer__quantile_range': (...), 'normalizer__with_centering': False, 'normalizer__with_scaling': False}), 'rebalance': ('rebalance_NearMiss', {'rebalance__n_neighbors': 1})}, 'score': 0.9334456831734508, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': None, 'max_features': 2, 'max_leaf_nodes': 3, 'min_samples_split': 2, 'n_estimators': 100}, 'config_hash': {'algorithm': '1b32258c630f07e01ab481ab925ab80aa757e482', 'config': '9e54ffcb6a727de032a0a2cd45c5cc37cc150756', 'pipeline': '37e72d4a97f5e784c9d3133e6379b91bfc3be803'}, 'duration': 1.3065669536590576, 'iteration': 1, 'loss': 0.05436435917379645, 'max_history_score': 0.9456356408262035, 'max_history_score_std': 0.040053650785990214, 'max_history_step': 'joint', 'pipeline': {'features': ('features_NoneType', {}), 'normalizer': ('normalizer_StandardScaler', {'normalizer__with_mean': True, 'normalizer__with_std': True}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 6})}, 'score': 0.9456356408262035, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'entropy', 'max_depth': 1, 'max_features': 1, 'max_leaf_nodes': 2, 'min_samples_split': 3, 'n_estimators': 25}, 'config_hash': {'algorithm': '68ab9059aa7ec74e0da87c81734b9664243b3eb4', 'config': 'e5241eee9ddf3f4ee29a4711f5bcc92a4d24cd09', 'pipeline': '62463de065924498cdcd2f2f1f7e68535cdb33a5'}, 'duration': 0.6592490673065186, 'iteration': 2, 'loss': 0.07695856019358727, 'max_history_score': 0.9456356408262035, 'max_history_score_std': 0.040053650785990214, 'max_history_step': 'joint', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 1, 'features__selectkbest__k': 2}), 'normalizer': ('normalizer_NoneType', {}), 'rebalance': ('rebalance_NoneType', {})}, 'score': 0.9230414398064127, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': 3, 'max_features': 2, 'max_leaf_nodes': 2, 'min_samples_split': 2, 'n_estimators': 25}, 'config_hash': {'algorithm': 'e3f1f7d7783557a38f40f0476369091edd87092b', 'config': '18ee4d3d1627472ec190326308d8755371a6dc62', 'pipeline': 'c6d1263e344ed8c71b2e6e4ba8e0db2fb6c777c0'}, 'duration': 0.879349946975708, 'iteration': 3, 'loss': 0.07535973554576114, 'max_history_score': 0.9456356408262035, 'max_history_score_std': 0.040053650785990214, 'max_history_step': 'joint', 'pipeline': {'features': ('features_NoneType', {}), 'normalizer': ('normalizer_RobustScaler', {'normalizer__quantile_range': (...), 'normalizer__with_centering': True, 'normalizer__with_scaling': True}), 'rebalance': ('rebalance_NearMiss', {'rebalance__n_neighbors': 2})}, 'score': 0.9246402644542389, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'gini', 'max_depth': 4, 'max_features': 2, 'max_leaf_nodes': 5, 'min_samples_split': 2, 'n_estimators': 50}, 'config_hash': {'algorithm': '47581af7253940f9647ad16d37347d34baf13e5f', 'config': '2af4f82b045c0c48ecb89d42728d1039fbff8878', 'pipeline': '2928b22ed834303cb7bac6e6608531eaddd7df67'}, 'duration': 4.372632026672363, 'iteration': 4, 'loss': 0.09121294615849984, 'max_history_score': 0.9456356408262035, 'max_history_score_std': 0.040053650785990214, 'max_history_step': 'joint', 'pipeline': {'features': ('features_NoneType', {}), 'normalizer': ('normalizer_MinMaxScaler', {}), 'rebalance': ('rebalance_CondensedNearestNeighbour', {'rebalance__n_neighbors': 2})}, 'score': 0.9087870538415002, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'entropy', 'max_depth': 2, 'max_features': 2, 'max_leaf_nodes': None, 'min_samples_split': 2, 'n_estimators': 10}, 'config_hash': {'algorithm': '0a85f98ca2d06103287f153633d88f7a0535e7e8', 'config': '17b2a1e5814f3e933137158708a5b6e9b2475495', 'pipeline': '95defa3bdd8357f11f872d3c280d50a6d8ee398d'}, 'duration': 2.625814914703369, 'iteration': 5, 'loss': 0.15471329185031535, 'max_history_score': 0.9456356408262035, 'max_history_score_std': 0.040053650785990214, 'max_history_step': 'joint', 'pipeline': {'features': ('features_SelectKBest', {'features__k': 2}), 'normalizer': ('normalizer_StandardScaler', {'normalizer__with_mean': False, 'normalizer__with_std': False}), 'rebalance': ('rebalance_CondensedNearestNeighbour', {'rebalance__n_neighbors': 1})}, 'score': 0.8452867081496847, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': 3, 'max_features': None, 'max_leaf_nodes': None, 'min_samples_split': 5, 'n_estimators': 75}, 'config_hash': {'algorithm': 'd7466a2c1d5cb3fa95029d73dc030f4c3c45a159', 'config': 'fa020a592ec5ac234f9f91aac28abc2cd1ec9d33', 'pipeline': '71e0d26f923d42cfe0e2fa748931ef2afe72ed86'}, 'duration': 3.62078595161438, 'iteration': 6, 'loss': 0.17066372828623277, 'max_history_score': 0.9456356408262035, 'max_history_score_std': 0.040053650785990214, 'max_history_step': 'joint', 'pipeline': {'features': ('features_SelectKBest', {'features__k': 1}), 'normalizer': ('normalizer_RobustScaler', {'normalizer__quantile_range': (...), 'normalizer__with_centering': True, 'normalizer__with_scaling': True}), 'rebalance': ('rebalance_CondensedNearestNeighbour', {'rebalance__n_neighbors': 1})}, 'score': 0.8293362717137672, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'entropy', 'max_depth': 3, 'max_features': 3, 'max_leaf_nodes': 5, 'min_samples_split': 5, 'n_estimators': 50}, 'config_hash': {'algorithm': '735caa9785596076014572a24050cde8dc338973', 'config': '0da4498002d6f452c59bb61756abb3ded841e786', 'pipeline': '51a53ea6ef5a2521ee65f76eb2da220ab7086513'}, 'duration': 0.6934049129486084, 'iteration': 7, 'loss': 0.06125875032408601, 'max_history_score': 0.9456356408262035, 'max_history_score_std': 0.040053650785990214, 'max_history_step': 'joint', 'pipeline': {'features': ('features_NoneType', {}), 'normalizer': ('normalizer_NoneType', {}), 'rebalance': ('rebalance_NearMiss', {'rebalance__n_neighbors': 3})}, 'score': 0.938741249675914, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': 4, 'max_features': 2, 'max_leaf_nodes': None, 'min_samples_split': 3, 'n_estimators': 75}, 'config_hash': {'algorithm': 'e71a1fe9515b6805f07914a61f2e7594be9e9afe', 'config': '344e4756fb1bec455d6af51d3727e33b0d27725f', 'pipeline': '248dad1d8b30a17a5de1d0bbdfe3e2acb7a1962b'}, 'duration': 1.3036692142486572, 'iteration': 8, 'loss': 0.06483125918243893, 'max_history_score': 0.9456356408262035, 'max_history_score_std': 0.040053650785990214, 'max_history_step': 'joint', 'pipeline': {'features': ('features_PCA', {'features__n_components': 2}), 'normalizer': ('normalizer_StandardScaler', {'normalizer__with_mean': False, 'normalizer__with_std': True}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 7})}, 'score': 0.9351687408175611, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'entropy', 'max_depth': 2, 'max_features': 2, 'max_leaf_nodes': 2, 'min_samples_split': 3, 'n_estimators': 10}, 'config_hash': {'algorithm': '0a507823f2ad8605ed5950e1fe61df0560f11a00', 'config': '4a538fdcf8e07f90e92a421c0d5c479d651629c7', 'pipeline': '5240329df25c9a533d025c1a401d49835a501b41'}, 'duration': 1.3821029663085938, 'iteration': 9, 'loss': 0.07006416904329793, 'max_history_score': 0.9456356408262035, 'max_history_score_std': 0.040053650785990214, 'max_history_step': 'joint', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 4, 'features__selectkbest__k': 2}), 'normalizer': ('normalizer_PowerTransformer', {}), 'rebalance': ('rebalance_NearMiss', {'rebalance__n_neighbors': 1})}, 'score': 0.9299358309567021, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'gini', 'max_depth': 1, 'max_features': 3, 'max_leaf_nodes': 5, 'min_samples_split': 3, 'n_estimators': 10}, 'config_hash': {'algorithm': 'd32739750d351948f8ff34a87c7d55b0c5e0d90f', 'config': 'c1609e71f1ce8486335adc70bb69a955580ba2c8', 'pipeline': 'f48b42ec5cf999279659966160a16353b75bdaa3'}, 'duration': 0.9055681228637695, 'iteration': 10, 'loss': 0.07532840722495904, 'max_history_score': 0.9456356408262035, 'max_history_score_std': 0.040053650785990214, 'max_history_step': 'joint', 'pipeline': {'features': ('features_PCA', {'features__n_components': 4}), 'normalizer': ('normalizer_PowerTransformer', {}), 'rebalance': ('rebalance_NearMiss', {'rebalance__n_neighbors': 1})}, 'score': 0.924671592775041, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': 3, 'max_features': 1, 'max_leaf_nodes': 5, 'min_samples_split': 3, 'n_estimators': 25}, 'config_hash': {'algorithm': 'f69bac35e71cbec1bfc1fb5942328a3390e7c252', 'config': 'abe36f188644e53e56ed3224236fa157107ed3b2', 'pipeline': 'aaf976c7c663a31fa039582d42f9e07101556a7c'}, 'duration': 0.764197826385498, 'iteration': 11, 'loss': 0.06818446979517778, 'max_history_score': 0.9456356408262035, 'max_history_score_std': 0.040053650785990214, 'max_history_step': 'joint', 'pipeline': {'features': ('features_NoneType', {}), 'normalizer': ('normalizer_PowerTransformer', {}), 'rebalance': ('rebalance_NoneType', {})}, 'score': 0.9318155302048222, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'entropy', 'max_depth': None, 'max_features': None, 'max_leaf_nodes': None, 'min_samples_split': 5, 'n_estimators': 25}, 'config_hash': {'algorithm': 'a0a27aec00db5ddf71eab96663f9bd61c845f5e3', 'config': '76aa002c3c9d4d9722466c60daf5119c18a41d2a', 'pipeline': '1ce34b7894ef342571d974bb19e8ec821a512c6b'}, 'duration': 1.1636500358581543, 'iteration': 12, 'loss': 0.12833700630887557, 'max_history_score': 0.9456356408262035, 'max_history_score_std': 0.040053650785990214, 'max_history_step': 'joint', 'pipeline': {'features': ('features_PCA', {'features__n_components': 1}), 'normalizer': ('normalizer_PowerTransformer', {}), 'rebalance': ('rebalance_NoneType', {})}, 'score': 0.8716629936911244, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'gini', 'max_depth': 1, 'max_features': 2, 'max_leaf_nodes': 2, 'min_samples_split': 2, 'n_estimators': 100}, 'config_hash': {'algorithm': '985c99dff1da9b2c87e4211c5335a9159aa9dbcb', 'config': 'f56a7a9e43a0a699e992dc1262e550b8b7c88538', 'pipeline': '5c934f6d9a8ad1f9afe762986a9cf2074fc95d79'}, 'duration': 2.235443115234375, 'iteration': 13, 'loss': 0.11414635727249167, 'max_history_score': 0.9456356408262035, 'max_history_score_std': 0.040053650785990214, 'max_history_step': 'joint', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 1, 'features__selectkbest__k': 1}), 'normalizer': ('normalizer_RobustScaler', {'normalizer__quantile_range': (...), 'normalizer__with_centering': False, 'normalizer__with_scaling': True}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 6})}, 'score': 0.8858536427275083, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'gini', 'max_depth': 1, 'max_features': 1, 'max_leaf_nodes': None, 'min_samples_split': 5, 'n_estimators': 10}, 'config_hash': {'algorithm': '7d74a39aac2579264a402aef2b6fa7943c19f3d3', 'config': '53f44c0ad925c5c08c25d4fadf5e9ee9d7c181cd', 'pipeline': '6eff5ef31d7d1d534db31913bb67529c8a24c42e'}, 'duration': 2.7847659587860107, 'iteration': 14, 'loss': 0.14061986863711007, 'max_history_score': 0.9456356408262035, 'max_history_score_std': 0.040053650785990214, 'max_history_step': 'joint', 'pipeline': {'features': ('features_PCA', {'features__n_components': 1}), 'normalizer': ('normalizer_RobustScaler', {'normalizer__quantile_range': (...), 'normalizer__with_centering': True, 'normalizer__with_scaling': True}), 'rebalance': ('rebalance_CondensedNearestNeighbour', {'rebalance__n_neighbors': 3})}, 'score': 0.8593801313628899, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'entropy', 'max_depth': 3, 'max_features': None, 'max_leaf_nodes': 5, 'min_samples_split': 2, 'n_estimators': 100}, 'config_hash': {'algorithm': 'c62d7c671832e4414b6b2d7c36cba5ddc83a0ed0', 'config': '5faee50671eaa0ac586722bff234e36a857e662d', 'pipeline': '8b29a55de2add78c49114b9bbe5e800e5524c59d'}, 'duration': 2.3916029930114746, 'iteration': 15, 'loss': 0.08770093336790252, 'max_history_score': 0.9456356408262035, 'max_history_score_std': 0.040053650785990214, 'max_history_step': 'joint', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 3, 'features__selectkbest__k': 4}), 'normalizer': ('normalizer_RobustScaler', {'normalizer__quantile_range': (...), 'normalizer__with_centering': True, 'normalizer__with_scaling': True}), 'rebalance': ('rebalance_NoneType', {})}, 'score': 0.9122990666320975, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': None, 'max_features': 1, 'max_leaf_nodes': 5, 'min_samples_split': 5, 'n_estimators': 10}, 'config_hash': {'algorithm': '290772bfb9b8ed15c48a72829e822fb0a07481d6', 'config': '9a04f25d8eb3db5b2f831abd341a6d384c73a957', 'pipeline': '1ce34b7894ef342571d974bb19e8ec821a512c6b'}, 'duration': 1.4364500045776367, 'iteration': 16, 'loss': 0.08948880822746508, 'max_history_score': 0.9456356408262035, 'max_history_score_std': 0.040053650785990214, 'max_history_step': 'joint', 'pipeline': {'features': ('features_PCA', {'features__n_components': 1}), 'normalizer': ('normalizer_PowerTransformer', {}), 'rebalance': ('rebalance_NoneType', {})}, 'score': 0.9105111917725349, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': 2, 'max_features': 3, 'max_leaf_nodes': 3, 'min_samples_split': 3, 'n_estimators': 100}, 'config_hash': {'algorithm': '7dab6d47f897c2961d3402eff844aff16a7d142a', 'config': '4dbfa2688b239be9f372d3e80223960ba9a1fbdd', 'pipeline': 'cdef51702798fa49f11c11d80baf3ab43d5358fc'}, 'duration': 0.9830451011657715, 'iteration': 17, 'loss': 1.0, 'max_history_score': 0.9456356408262035, 'max_history_score_std': 0.040053650785990214, 'max_history_step': 'joint', 'pipeline': {'features': ('features_SelectKBest', {'features__k': 2}), 'normalizer': ('normalizer_PowerTransformer', {}), 'rebalance': ('rebalance_NearMiss', {'rebalance__n_neighbors': 1})}, 'score': 0.0, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'entropy', 'max_depth': None, 'max_features': 3, 'max_leaf_nodes': None, 'min_samples_split': 5, 'n_estimators': 10}, 'config_hash': {'algorithm': 'def83e48be05ef92a37e1a90585820f2f67ff42b', 'config': '95902552cb76e9798f0fa58782bd72bd1cc272d7', 'pipeline': '1775187bf23f94f4fd0cc1e5c1ef665210edded5'}, 'duration': 2.0033559799194336, 'iteration': 18, 'loss': 0.04922327370149515, 'max_history_score': 0.9507767262985048, 'max_history_score_std': 0.028328108925705902, 'max_history_step': 'joint', 'pipeline': {'features': ('features_PCA', {'features__n_components': 4}), 'normalizer': ('normalizer_StandardScaler', {'normalizer__with_mean': True, 'normalizer__with_std': True}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 5})}, 'score': 0.9507767262985048, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'gini', 'max_depth': 1, 'max_features': 3, 'max_leaf_nodes': None, 'min_samples_split': 2, 'n_estimators': 50}, 'config_hash': {'algorithm': '4e9e3275f817df75115d9d7e3366980fc1b4cf13', 'config': '7770b19007b40bf13005d52eb81f87bc401f15b4', 'pipeline': 'c4dd111513ea35f97dd3aec3e8e7f6268ce035da'}, 'duration': 0.9069631099700928, 'iteration': 19, 'loss': 1.0, 'max_history_score': 0.9507767262985048, 'max_history_score_std': 0.028328108925705902, 'max_history_step': 'joint', 'pipeline': {'features': ('features_PCA', {'features__n_components': 2}), 'normalizer': ('normalizer_RobustScaler', {'normalizer__quantile_range': (...), 'normalizer__with_centering': False, 'normalizer__with_scaling': True}), 'rebalance': ('rebalance_NearMiss', {'rebalance__n_neighbors': 2})}, 'score': 0.0, ...}, ...], 'history_hash': ['51144ca42f9ea5ab2d8d58606e3b3e4d89c6d7b3', '9e54ffcb6a727de032a0a2cd45c5cc37cc150756', 'e5241eee9ddf3f4ee29a4711f5bcc92a4d24cd09', '18ee4d3d1627472ec190326308d8755371a6dc62', '2af4f82b045c0c48ecb89d42728d1039fbff8878', '17b2a1e5814f3e933137158708a5b6e9b2475495', 'fa020a592ec5ac234f9f91aac28abc2cd1ec9d33', '0da4498002d6f452c59bb61756abb3ded841e786', '344e4756fb1bec455d6af51d3727e33b0d27725f', '4a538fdcf8e07f90e92a421c0d5c479d651629c7', 'c1609e71f1ce8486335adc70bb69a955580ba2c8', 'abe36f188644e53e56ed3224236fa157107ed3b2', '76aa002c3c9d4d9722466c60daf5119c18a41d2a', 'f56a7a9e43a0a699e992dc1262e550b8b7c88538', '53f44c0ad925c5c08c25d4fadf5e9ee9d7c181cd', '5faee50671eaa0ac586722bff234e36a857e662d', '9a04f25d8eb3db5b2f831abd341a6d384c73a957', '4dbfa2688b239be9f372d3e80223960ba9a1fbdd', '95902552cb76e9798f0fa58782bd72bd1cc272d7', '7770b19007b40bf13005d52eb81f87bc401f15b4', ...], 'history_index': {'0212926e8a56cc42ae0a654a90c2a3ee92464265': 91, '0da4498002d6f452c59bb61756abb3ded841e786': 7, '0f77a69b0a8d34861caf915a51dc588ff8d4efac': 61, '127553d555ed39231b8da3a1ce42d3902e30919b': 59, '17b2a1e5814f3e933137158708a5b6e9b2475495': 5, '18ee4d3d1627472ec190326308d8755371a6dc62': 3, '1b2267555a9226d7eb4df3c63dd12506da370f4d': 56, '278dd514f71ea681b3e2238dde3b16c35f1697db': 90, '2873878df7d4db8b415ff446bec08003e0c7488d': 92, '28b2db1bf9b505aa8e490d811b55f6655178ede7': 67, ...}, 'iteration': 92, 'max_history_score': 0.9525008642295394, 'max_history_score_std': 0.02225295065716913, 'max_history_step': 'joint'}, config={'algorithm': 'RandomForest', 'seed': 42, 'time': 300}, step='joint')
     45                 y,
     46                 cv=10,
     47                 n_jobs=-1,
     48                 return_estimator=False,
     49                 return_train_score=False,
---> 50                 verbose=0)
     51         score = np.mean(scores['test_score'])
     52         std = np.std(scores['test_score'])
     53         status = STATUS_OK
     54     except Exception as e:

...........................................................................
/home/aquemy/.local/lib/python2.7/site-packages/sklearn/model_selection/_validation.py in cross_validate(estimator=Pipeline(memory=None,
     steps=[('rebalance', ...e=42,
            verbose=0, warm_start=False))]), X=array([[1.799e+01, 1.038e+01, 1.228e+02, ..., 2...., ..., 0.000e+00, 2.871e-01,
        7.039e-02]]), y=array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,... 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1]), groups=None, scoring=None, cv=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1, verbose=0, fit_params=None, pre_dispatch='2*n_jobs', return_train_score=False, return_estimator=False, error_score='raise-deprecating')
    235         delayed(_fit_and_score)(
    236             clone(estimator), X, y, scorers, train, test, verbose, None,
    237             fit_params, return_train_score=return_train_score,
    238             return_times=True, return_estimator=return_estimator,
    239             error_score=error_score)
--> 240         for train, test in cv.split(X, y, groups))
        cv.split = <bound method StratifiedKFold.split of Stratifie...d(n_splits=10, random_state=None, shuffle=False)>
        X = array([[1.799e+01, 1.038e+01, 1.228e+02, ..., 2...., ..., 0.000e+00, 2.871e-01,
        7.039e-02]])
        y = array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,... 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1])
        groups = None
    241 
    242     zipped_scores = list(zip(*scores))
    243     if return_train_score:
    244         train_scores = zipped_scores.pop(0)

...........................................................................
/home/aquemy/.local/lib/python2.7/site-packages/sklearn/externals/joblib/parallel.py in __call__(self=Parallel(n_jobs=-1), iterable=<generator object <genexpr>>)
    925                 # No need to wait for async callbacks to trigger to
    926                 # consumption.
    927                 self._iterating = False
    928 
    929             with self._backend.retrieval_context():
--> 930                 self.retrieve()
        self.retrieve = <bound method Parallel.retrieve of Parallel(n_jobs=-1)>
    931             # Make sure that we get a last message telling us we are done
    932             elapsed_time = time.time() - self._start_time
    933             self._print('Done %3i out of %3i | elapsed: %s finished',
    934                         (len(self._output), len(self._output),

---------------------------------------------------------------------------
Joblib worker traceback:
---------------------------------------------------------------------------
ValueError                                         Mon Jun 17 13:33:51 2019
PID: 26342                                  Python 2.7.15+: /usr/bin/python
...........................................................................
/home/aquemy/.local/lib/python2.7/site-packages/sklearn/externals/joblib/parallel.py in __call__(self=<sklearn.externals.joblib.parallel.BatchedCalls object>)
    220     def __call__(self):
    221         # Set the default nested backend to self._backend but do not set the
    222         # change the default number of processes to -1
    223         with parallel_backend(self._backend, n_jobs=self._n_jobs):
    224             return [func(*args, **kwargs)
--> 225                     for func, args, kwargs in self.items]
        func = <function _fit_and_score>
        args = (Pipeline(memory=None,
     steps=[('rebalance', ...e=42,
            verbose=0, warm_start=False))]), array([[1.799e+01, 1.038e+01, 1.228e+02, ..., 2...., ..., 0.000e+00, 2.871e-01,
        7.039e-02]]), array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,... 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1]), {'score': <function _passthrough_scorer>}, array([ 25,  26,  27,  28,  29,  30,  31,  32,  ..., 561, 562, 563, 564,
       565, 566, 567, 568]), array([  0,   1,   2,   3,   4,   5,   6,   7,  ...,  89,  90,
        92,  93,  96,  97,  98, 101]), 0, None, None)
        kwargs = {'error_score': 'raise-deprecating', 'return_estimator': False, 'return_times': True, 'return_train_score': False}
        self.items = [(<function _fit_and_score>, (Pipeline(memory=None,
     steps=[('rebalance', ...e=42,
            verbose=0, warm_start=False))]), array([[1.799e+01, 1.038e+01, 1.228e+02, ..., 2...., ..., 0.000e+00, 2.871e-01,
        7.039e-02]]), array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,... 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1]), {'score': <function _passthrough_scorer>}, array([ 25,  26,  27,  28,  29,  30,  31,  32,  ..., 561, 562, 563, 564,
       565, 566, 567, 568]), array([  0,   1,   2,   3,   4,   5,   6,   7,  ...,  89,  90,
        92,  93,  96,  97,  98, 101]), 0, None, None), {'error_score': 'raise-deprecating', 'return_estimator': False, 'return_times': True, 'return_train_score': False})]
    226 
    227     def __len__(self):
    228         return self._size
    229 

...........................................................................
/home/aquemy/.local/lib/python2.7/site-packages/sklearn/model_selection/_validation.py in _fit_and_score(estimator=Pipeline(memory=None,
     steps=[('rebalance', ...e=42,
            verbose=0, warm_start=False))]), X=array([[1.799e+01, 1.038e+01, 1.228e+02, ..., 2...., ..., 0.000e+00, 2.871e-01,
        7.039e-02]]), y=array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,... 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1]), scorer={'score': <function _passthrough_scorer>}, train=array([ 25,  26,  27,  28,  29,  30,  31,  32,  ..., 561, 562, 563, 564,
       565, 566, 567, 568]), test=array([  0,   1,   2,   3,   4,   5,   6,   7,  ...,  89,  90,
        92,  93,  96,  97,  98, 101]), verbose=0, parameters=None, fit_params={}, return_train_score=False, return_parameters=False, return_n_test_samples=False, return_times=True, return_estimator=False, error_score='raise-deprecating')
    523 
    524     try:
    525         if y_train is None:
    526             estimator.fit(X_train, **fit_params)
    527         else:
--> 528             estimator.fit(X_train, y_train, **fit_params)
        estimator.fit = <bound method Pipeline.fit of Pipeline(memory=No...=42,
            verbose=0, warm_start=False))])>
        X_train = array([[1.714e+01, 1.640e+01, 1.160e+02, ..., 2...., ..., 0.000e+00, 2.871e-01,
        7.039e-02]])
        y_train = array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...1, 1, 1, 1, 1, 1, 1, 0, 0,
       0, 0, 0, 0, 1])
        fit_params = {}
    529 
    530     except Exception as e:
    531         # Note fit time as time until error
    532         fit_time = time.time() - start_time

...........................................................................
/usr/local/lib/python2.7/dist-packages/imblearn/pipeline.py in fit(self=Pipeline(memory=None,
     steps=[('rebalance', ...e=42,
            verbose=0, warm_start=False))]), X=array([[1.714e+01, 1.640e+01, 1.160e+02, ..., 2...., ..., 0.000e+00, 2.871e-01,
        7.039e-02]]), y=array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...1, 1, 1, 1, 1, 1, 1, 0, 0,
       0, 0, 0, 0, 1]), **fit_params={})
    234             This estimator
    235 
    236         """
    237         Xt, yt, fit_params = self._fit(X, y, **fit_params)
    238         if self._final_estimator is not None:
--> 239             self._final_estimator.fit(Xt, yt, **fit_params)
        self._final_estimator.fit = <bound method RandomForestClassifier.fit of Rand...ate=42,
            verbose=0, warm_start=False)>
        Xt = array([[ 6.21317303,  2.32419398],
       [ 3.19...-0.47377138],
       [ 0.45429831, -0.01489235]])
        yt = array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
       0, 0, 0, 0])
        fit_params = {}
    240         return self
    241 
    242     def fit_transform(self, X, y=None, **fit_params):
    243         """Fit the model and transform with the final estimator

...........................................................................
/home/aquemy/.local/lib/python2.7/site-packages/sklearn/ensemble/forest.py in fit(self=RandomForestClassifier(bootstrap=False, class_we...tate=42,
            verbose=0, warm_start=False), X=array([[ 6.213173  ,  2.324194  ],
       [ 3.19...      [ 0.45429832, -0.01489235]], dtype=float32), y=array([[0.],
       [0.],
       [0.],
       [0...    [0.],
       [0.],
       [0.],
       [0.]]), sample_weight=None)
    328             trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,
    329                              **_joblib_parallel_args(prefer='threads'))(
    330                 delayed(_parallel_build_trees)(
    331                     t, self, X, y, sample_weight, i, len(trees),
    332                     verbose=self.verbose, class_weight=self.class_weight)
--> 333                 for i, t in enumerate(trees))
        i = 9
    334 
    335             # Collect newly grown trees
    336             self.estimators_.extend(trees)
    337 

...........................................................................
/home/aquemy/.local/lib/python2.7/site-packages/sklearn/externals/joblib/parallel.py in __call__(self=Parallel(n_jobs=1), iterable=<generator object <genexpr>>)
    912             # self._original_iterator is None, then this means either
    913             # that pre_dispatch == "all", n_jobs == 1 or that the first batch
    914             # was very quick and its callback already dispatched all the
    915             # remaining jobs.
    916             self._iterating = False
--> 917             if self.dispatch_one_batch(iterator):
        self.dispatch_one_batch = <bound method Parallel.dispatch_one_batch of Parallel(n_jobs=1)>
        iterator = <generator object <genexpr>>
    918                 self._iterating = self._original_iterator is not None
    919 
    920             while self.dispatch_one_batch(iterator):
    921                 pass

...........................................................................
/home/aquemy/.local/lib/python2.7/site-packages/sklearn/externals/joblib/parallel.py in dispatch_one_batch(self=Parallel(n_jobs=1), iterator=<generator object <genexpr>>)
    754                                  self._pickle_cache)
    755             if len(tasks) == 0:
    756                 # No more tasks available in the iterator: tell caller to stop.
    757                 return False
    758             else:
--> 759                 self._dispatch(tasks)
        self._dispatch = <bound method Parallel._dispatch of Parallel(n_jobs=1)>
        tasks = <sklearn.externals.joblib.parallel.BatchedCalls object>
    760                 return True
    761 
    762     def _print(self, msg, msg_args):
    763         """Display the message on stout or stderr depending on verbosity"""

...........................................................................
/home/aquemy/.local/lib/python2.7/site-packages/sklearn/externals/joblib/parallel.py in _dispatch(self=Parallel(n_jobs=1), batch=<sklearn.externals.joblib.parallel.BatchedCalls object>)
    711 
    712         dispatch_timestamp = time.time()
    713         cb = BatchCompletionCallBack(dispatch_timestamp, len(batch), self)
    714         with self._lock:
    715             job_idx = len(self._jobs)
--> 716             job = self._backend.apply_async(batch, callback=cb)
        job = undefined
        self._backend.apply_async = <bound method SequentialBackend.apply_async of <...lib._parallel_backends.SequentialBackend object>>
        batch = <sklearn.externals.joblib.parallel.BatchedCalls object>
        cb = <sklearn.externals.joblib.parallel.BatchCompletionCallBack object>
    717             # A job can complete so quickly than its callback is
    718             # called before we get here, causing self._jobs to
    719             # grow. To ensure correct results ordering, .insert is
    720             # used (rather than .append) in the following line

...........................................................................
/home/aquemy/.local/lib/python2.7/site-packages/sklearn/externals/joblib/_parallel_backends.py in apply_async(self=<sklearn.externals.joblib._parallel_backends.SequentialBackend object>, func=<sklearn.externals.joblib.parallel.BatchedCalls object>, callback=<sklearn.externals.joblib.parallel.BatchCompletionCallBack object>)
    177             raise ValueError('n_jobs == 0 in Parallel has no meaning')
    178         return 1
    179 
    180     def apply_async(self, func, callback=None):
    181         """Schedule a func to be run"""
--> 182         result = ImmediateResult(func)
        result = undefined
        func = <sklearn.externals.joblib.parallel.BatchedCalls object>
    183         if callback:
    184             callback(result)
    185         return result
    186 

...........................................................................
/home/aquemy/.local/lib/python2.7/site-packages/sklearn/externals/joblib/_parallel_backends.py in __init__(self=<sklearn.externals.joblib._parallel_backends.ImmediateResult object>, batch=<sklearn.externals.joblib.parallel.BatchedCalls object>)
    544 
    545 class ImmediateResult(object):
    546     def __init__(self, batch):
    547         # Don't delay the application, to avoid keeping the input
    548         # arguments in memory
--> 549         self.results = batch()
        self.results = undefined
        batch = <sklearn.externals.joblib.parallel.BatchedCalls object>
    550 
    551     def get(self):
    552         return self.results
    553 

...........................................................................
/home/aquemy/.local/lib/python2.7/site-packages/sklearn/externals/joblib/parallel.py in __call__(self=<sklearn.externals.joblib.parallel.BatchedCalls object>)
    220     def __call__(self):
    221         # Set the default nested backend to self._backend but do not set the
    222         # change the default number of processes to -1
    223         with parallel_backend(self._backend, n_jobs=self._n_jobs):
    224             return [func(*args, **kwargs)
--> 225                     for func, args, kwargs in self.items]
        func = <function _parallel_build_trees>
        args = (DecisionTreeClassifier(class_weight=None, criter...=False, random_state=1608637542, splitter='best'), RandomForestClassifier(bootstrap=False, class_we...tate=42,
            verbose=0, warm_start=False), array([[ 6.213173  ,  2.324194  ],
       [ 3.19...      [ 0.45429832, -0.01489235]], dtype=float32), array([[0.],
       [0.],
       [0.],
       [0...    [0.],
       [0.],
       [0.],
       [0.]]), None, 0, 10)
        kwargs = {'class_weight': None, 'verbose': 0}
        self.items = [(<function _parallel_build_trees>, (DecisionTreeClassifier(class_weight=None, criter...=False, random_state=1608637542, splitter='best'), RandomForestClassifier(bootstrap=False, class_we...tate=42,
            verbose=0, warm_start=False), array([[ 6.213173  ,  2.324194  ],
       [ 3.19...      [ 0.45429832, -0.01489235]], dtype=float32), array([[0.],
       [0.],
       [0.],
       [0...    [0.],
       [0.],
       [0.],
       [0.]]), None, 0, 10), {'class_weight': None, 'verbose': 0})]
    226 
    227     def __len__(self):
    228         return self._size
    229 

...........................................................................
/home/aquemy/.local/lib/python2.7/site-packages/sklearn/ensemble/forest.py in _parallel_build_trees(tree=DecisionTreeClassifier(class_weight=None, criter...=False, random_state=1608637542, splitter='best'), forest=RandomForestClassifier(bootstrap=False, class_we...tate=42,
            verbose=0, warm_start=False), X=array([[ 6.213173  ,  2.324194  ],
       [ 3.19...      [ 0.45429832, -0.01489235]], dtype=float32), y=array([[0.],
       [0.],
       [0.],
       [0...    [0.],
       [0.],
       [0.],
       [0.]]), sample_weight=None, tree_idx=0, n_trees=10, verbose=0, class_weight=None)
    116         elif class_weight == 'balanced_subsample':
    117             curr_sample_weight *= compute_sample_weight('balanced', y, indices)
    118 
    119         tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)
    120     else:
--> 121         tree.fit(X, y, sample_weight=sample_weight, check_input=False)
        tree.fit = <bound method DecisionTreeClassifier.fit of Deci...False, random_state=1608637542, splitter='best')>
        X = array([[ 6.213173  ,  2.324194  ],
       [ 3.19...      [ 0.45429832, -0.01489235]], dtype=float32)
        y = array([[0.],
       [0.],
       [0.],
       [0...    [0.],
       [0.],
       [0.],
       [0.]])
        sample_weight = None
    122 
    123     return tree
    124 
    125 

...........................................................................
/home/aquemy/.local/lib/python2.7/site-packages/sklearn/tree/tree.py in fit(self=DecisionTreeClassifier(class_weight=None, criter...=False, random_state=1608637542, splitter='best'), X=array([[ 6.213173  ,  2.324194  ],
       [ 3.19...      [ 0.45429832, -0.01489235]], dtype=float32), y=array([[0.],
       [0.],
       [0.],
       [0...    [0.],
       [0.],
       [0.],
       [0.]]), sample_weight=None, check_input=False, X_idx_sorted=None)
    796 
    797         super(DecisionTreeClassifier, self).fit(
    798             X, y,
    799             sample_weight=sample_weight,
    800             check_input=check_input,
--> 801             X_idx_sorted=X_idx_sorted)
        X_idx_sorted = None
    802         return self
    803 
    804     def predict_proba(self, X, check_input=True):
    805         """Predict class probabilities of the input samples X.

...........................................................................
/home/aquemy/.local/lib/python2.7/site-packages/sklearn/tree/tree.py in fit(self=DecisionTreeClassifier(class_weight=None, criter...=False, random_state=1608637542, splitter='best'), X=array([[ 6.213173  ,  2.324194  ],
       [ 3.19...      [ 0.45429832, -0.01489235]], dtype=float32), y=array([[0.],
       [0.],
       [0.],
       [0...    [0.],
       [0.],
       [0.],
       [0.]]), sample_weight=None, check_input=False, X_idx_sorted=None)
    237         if not 0 <= self.min_weight_fraction_leaf <= 0.5:
    238             raise ValueError("min_weight_fraction_leaf must in [0, 0.5]")
    239         if max_depth <= 0:
    240             raise ValueError("max_depth must be greater than zero. ")
    241         if not (0 < max_features <= self.n_features_):
--> 242             raise ValueError("max_features must be in (0, n_features]")
    243         if not isinstance(max_leaf_nodes, (numbers.Integral, np.integer)):
    244             raise ValueError("max_leaf_nodes must be integral number but was "
    245                              "%r" % max_leaf_nodes)
    246         if -1 < max_leaf_nodes < 2:

ValueError: max_features must be in (0, n_features]
___________________________________________________________________________
Best score: 0.95250086423 (0.0222529506572) [J] | Score: 0.0 (0.0) [J]
Best score: 0.95250086423 (0.0222529506572) [J] | Score: 0.940372482931 (0.0338367042727) [J]
Best score: 0.95250086423 (0.0222529506572) [J] | Score: 0.901676605306 (0.0312195468149) [J]
Best score: 0.95250086423 (0.0222529506572) [J] | Score: 0.931691297209 (0.0364892311861) [J]
Best score: 0.95250086423 (0.0222529506572) [J] | Score: 0.878652450091 (0.0457694595456) [J]
Best score: 0.95250086423 (0.0222529506572) [J] | Score: 0.901705773053 (0.0389476899511) [J]
Best score: 0.95250086423 (0.0222529506572) [J] | Score: 0.906723705816 (0.0341026718076) [J]
JoblibValueError
___________________________________________________________________________
...........................................................................
/home/aquemy/dev/dp_hyperparameters/extension/main.py in <module>()
     27 
     28     serializer.serialize_results(scenario, policy)
     29 
     30 if __name__ == "__main__":
     31     args = cli.parse_args()
---> 32     main(args)

...........................................................................
/home/aquemy/dev/dp_hyperparameters/extension/main.py in main(args=Namespace(customize=[(['control', 'seed'], '42')...='./scenarios/rf_breast_joint.yaml', verbosity=0))
     21         test_size=0.4, 
     22         random_state=scenario['control']['seed']
     23     )
     24 
     25     policy = policies.initiate(scenario['setup']['policy'], config)
---> 26     policy.run(X,y)
        policy.run = <bound method Joint.run of <experiment.policies.joint.Joint object>>
        X = array([[1.799e+01, 1.038e+01, 1.228e+02, ..., 2...., ..., 0.000e+00, 2.871e-01,
        7.039e-02]])
        y = array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,... 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1])
     27 
     28     serializer.serialize_results(scenario, policy)
     29 
     30 if __name__ == "__main__":

...........................................................................
/home/aquemy/dev/dp_hyperparameters/extension/experiment/policies/joint.py in run(self=<experiment.policies.joint.Joint object>, X=array([[1.799e+01, 1.038e+01, 1.228e+02, ..., 2...., ..., 0.000e+00, 2.871e-01,
        7.039e-02]]), y=array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,... 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1]))
     32             algo=tpe.suggest, 
     33             max_evals=None,
     34             max_time=self.config['time'],     
     35             trials=trials,
     36             show_progressbar=False,
---> 37             verbose=0
     38         )
     39 
     40         best_config = self.context['best_config']
     41         super(Joint, self).display_step_results(best_config)

...........................................................................
/home/aquemy/dev/dp_hyperparameters/extension/hyperopt/fmin.py in fmin(fn=<functools.partial object>, space={'algorithm': {'bootstrap': <hyperopt.pyll.base.Apply object>, 'criterion': <hyperopt.pyll.base.Apply object>, 'max_depth': <hyperopt.pyll.base.Apply object>, 'max_features': <hyperopt.pyll.base.Apply object>, 'max_leaf_nodes': <hyperopt.pyll.base.Apply object>, 'min_samples_split': <hyperopt.pyll.base.Apply object>, 'n_estimators': <hyperopt.pyll.base.Apply object>}, 'pipeline': {'features': <hyperopt.pyll.base.Apply object>, 'normalizer': <hyperopt.pyll.base.Apply object>, 'rebalance': <hyperopt.pyll.base.Apply object>}}, algo=<function suggest>, max_evals=9223372036854775807, max_time=300, trials=<hyperopt.base.Trials object>, rstate=<mtrand.RandomState object>, allow_trials_fmin=True, pass_expr_memo_ctrl=None, catch_eval_exceptions=False, verbose=0, return_argmin=True, points_to_evaluate=None, max_queue_len=1, show_progressbar=False)
    406             pass_expr_memo_ctrl=pass_expr_memo_ctrl,
    407             verbose=verbose,
    408             catch_eval_exceptions=catch_eval_exceptions,
    409             return_argmin=return_argmin,
    410             show_progressbar=show_progressbar,
--> 411             max_time=max_time
        max_time = 300
    412         )
    413 
    414     if trials is None:
    415         if points_to_evaluate is None:

...........................................................................
/home/aquemy/dev/dp_hyperparameters/extension/hyperopt/base.py in fmin(self=<hyperopt.base.Trials object>, fn=<functools.partial object>, space={'algorithm': {'bootstrap': <hyperopt.pyll.base.Apply object>, 'criterion': <hyperopt.pyll.base.Apply object>, 'max_depth': <hyperopt.pyll.base.Apply object>, 'max_features': <hyperopt.pyll.base.Apply object>, 'max_leaf_nodes': <hyperopt.pyll.base.Apply object>, 'min_samples_split': <hyperopt.pyll.base.Apply object>, 'n_estimators': <hyperopt.pyll.base.Apply object>}, 'pipeline': {'features': <hyperopt.pyll.base.Apply object>, 'normalizer': <hyperopt.pyll.base.Apply object>, 'rebalance': <hyperopt.pyll.base.Apply object>}}, algo=<function suggest>, max_evals=9223372036854775807, max_time=300, rstate=<mtrand.RandomState object>, verbose=0, pass_expr_memo_ctrl=None, catch_eval_exceptions=False, return_argmin=True, show_progressbar=False)
    636             verbose=verbose,
    637             allow_trials_fmin=False,  # -- prevent recursion
    638             pass_expr_memo_ctrl=pass_expr_memo_ctrl,
    639             catch_eval_exceptions=catch_eval_exceptions,
    640             return_argmin=return_argmin,
--> 641             show_progressbar=show_progressbar)
        show_progressbar = False
    642 
    643 
    644 def trials_from_docs(docs, validate=True, **kwargs):
    645     """Construct a Trials base class instance from a list of trials documents

...........................................................................
/home/aquemy/dev/dp_hyperparameters/extension/hyperopt/fmin.py in fmin(fn=<functools.partial object>, space={'algorithm': {'bootstrap': <hyperopt.pyll.base.Apply object>, 'criterion': <hyperopt.pyll.base.Apply object>, 'max_depth': <hyperopt.pyll.base.Apply object>, 'max_features': <hyperopt.pyll.base.Apply object>, 'max_leaf_nodes': <hyperopt.pyll.base.Apply object>, 'min_samples_split': <hyperopt.pyll.base.Apply object>, 'n_estimators': <hyperopt.pyll.base.Apply object>}, 'pipeline': {'features': <hyperopt.pyll.base.Apply object>, 'normalizer': <hyperopt.pyll.base.Apply object>, 'rebalance': <hyperopt.pyll.base.Apply object>}}, algo=<function suggest>, max_evals=9223372036854775807, max_time=300, trials=<hyperopt.base.Trials object>, rstate=<mtrand.RandomState object>, allow_trials_fmin=False, pass_expr_memo_ctrl=None, catch_eval_exceptions=False, verbose=0, return_argmin=True, points_to_evaluate=None, max_queue_len=1, show_progressbar=False)
    426                     verbose=verbose,
    427                     max_queue_len=max_queue_len,
    428                     show_progressbar=show_progressbar,
    429                     max_time=max_time)
    430     rval.catch_eval_exceptions = catch_eval_exceptions
--> 431     rval.exhaust()
        rval.exhaust = <bound method FMinIter.exhaust of <hyperopt.fmin.FMinIter object>>
    432     if return_argmin:
    433         return trials.argmin
    434     elif len(trials) > 0:
    435         # Only if there are some succesfull trail runs, return the best point in the evaluation space

...........................................................................
/home/aquemy/dev/dp_hyperparameters/extension/hyperopt/fmin.py in exhaust(self=<hyperopt.fmin.FMinIter object>)
    273             raise StopIteration()
    274         return self.trials
    275 
    276     def exhaust(self):
    277         n_done = len(self.trials)
--> 278         self.run(self.max_evals - n_done, block_until_done=self.asynchronous)
        self.run = <bound method FMinIter.run of <hyperopt.fmin.FMinIter object>>
        self.max_evals = 9223372036854775807
        n_done = 0
        self.asynchronous = False
    279         self.trials.refresh()
    280         return self
    281 
    282 

...........................................................................
/home/aquemy/dev/dp_hyperparameters/extension/hyperopt/fmin.py in run(self=<hyperopt.fmin.FMinIter object>, N=9223372036854775807, block_until_done=False)
    232                     if self.asynchronous:
    233                         # -- wait for workers to fill in the trials
    234                         time.sleep(self.poll_interval_secs)
    235                     else:
    236                         # -- loop over trials and do the jobs directly
--> 237                         self.serial_evaluate()
        self.serial_evaluate = <bound method FMinIter.serial_evaluate of <hyperopt.fmin.FMinIter object>>
    238                     try:
    239                         res = [d['result']['loss'] for d in
    240                                          self.trials.trials if
    241                                          d['result']['status'] == 'ok']

...........................................................................
/home/aquemy/dev/dp_hyperparameters/extension/hyperopt/fmin.py in serial_evaluate(self=<hyperopt.fmin.FMinIter object>, N=-1)
    138                 trial['book_time'] = now
    139                 trial['refresh_time'] = now
    140                 spec = base.spec_from_misc(trial['misc'])
    141                 ctrl = base.Ctrl(self.trials, current_trial=trial)
    142                 try:
--> 143                     result = self.domain.evaluate(spec, ctrl)
        result = undefined
        self.domain.evaluate = <bound method Domain.evaluate of <hyperopt.base.Domain object>>
        spec = {'bootstrap': 1, 'criterion': 1, 'features': 1, 'features_PCA_features__n_components': 0, 'max_depth': 4, 'max_features': 2, 'max_leaf_nodes': 3, 'min_samples_split': 2, 'n_estimators': 0, 'normalizer': 2, ...}
        ctrl = <hyperopt.base.Ctrl object>
    144                 except Exception as e:
    145                     logger.info('job exception: %s' % str(e))
    146                     trial['state'] = base.JOB_STATE_ERROR
    147                     trial['misc']['error'] = (str(type(e)), str(e))

...........................................................................
/home/aquemy/dev/dp_hyperparameters/extension/hyperopt/base.py in evaluate(self=<hyperopt.base.Domain object>, config={'bootstrap': 1, 'criterion': 1, 'features': 1, 'features_PCA_features__n_components': 0, 'max_depth': 4, 'max_features': 2, 'max_leaf_nodes': 3, 'min_samples_split': 2, 'n_estimators': 0, 'normalizer': 2, ...}, ctrl=<hyperopt.base.Ctrl object>, attach_attachments=True)
    841             #    or the normal Python part (self.fn)
    842             pyll_rval = pyll.rec_eval(
    843                 self.expr,
    844                 memo=memo,
    845                 print_node_on_error=self.rec_eval_print_node_on_error)
--> 846             rval = self.fn(pyll_rval)
        rval = undefined
        self.fn = <functools.partial object>
        pyll_rval = {'algorithm': {'bootstrap': False, 'criterion': 'entropy', 'max_depth': None, 'max_features': 3, 'max_leaf_nodes': None, 'min_samples_split': 5, 'n_estimators': 10}, 'pipeline': {'features': ('features_PCA', {'features__n_components': 1}), 'normalizer': ('normalizer_PowerTransformer', {}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 5})}}
    847 
    848         if isinstance(rval, (float, int, np.number)):
    849             dict_rval = {'loss': float(rval), 'status': STATUS_OK}
    850         else:

...........................................................................
/home/aquemy/dev/dp_hyperparameters/extension/experiment/objective.py in objective_joint(wconfig={'algorithm': {'bootstrap': False, 'criterion': 'entropy', 'max_depth': None, 'max_features': 3, 'max_leaf_nodes': None, 'min_samples_split': 5, 'n_estimators': 10}, 'pipeline': {'features': ('features_PCA', {'features__n_components': 1}), 'normalizer': ('normalizer_PowerTransformer', {}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 5})}}, algorithm='RandomForest', X=array([[1.799e+01, 1.038e+01, 1.228e+02, ..., 2...., ..., 0.000e+00, 2.871e-01,
        7.039e-02]]), y=array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,... 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1]), context={'baseline_score': 0.9545944602886527, 'baseline_score_std': 0.03716322883281839, 'best_config': {'algorithm': {'bootstrap': False, 'criterion': 'entropy', 'max_depth': None, 'max_features': 2, 'max_leaf_nodes': None, 'min_samples_split': 5, 'n_estimators': 10}, 'config_hash': {'algorithm': 'e7a772c2bc361aa61cf7eeb364a26dca2c9b89d6', 'config': 'afb67da069b544b0505b1e8c150edc7498ad37b4', 'pipeline': 'a43db4b4fc4c38610b7b5e484840d2e583089ff4'}, 'duration': 1.0073001384735107, 'iteration': 26, 'loss': 0.04749913577046061, 'max_history_score': 0.9525008642295394, 'max_history_score_std': 0.02225295065716913, 'max_history_step': 'joint', 'pipeline': {'features': ('features_PCA', {'features__n_components': 4}), 'normalizer': ('normalizer_StandardScaler', {'normalizer__with_mean': True, 'normalizer__with_std': False}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 7})}, 'score': 0.9525008642295394, ...}, 'history': [{'algorithm': {'bootstrap': True, 'criterion': 'entropy', 'max_depth': 4, 'max_features': 3, 'max_leaf_nodes': 3, 'min_samples_split': 2, 'n_estimators': 10}, 'config_hash': {'algorithm': '42527c4120073c2a488d1b8df28732f486d1578c', 'config': '51144ca42f9ea5ab2d8d58606e3b3e4d89c6d7b3', 'pipeline': '52f07bda29f9d3a95fabb87e591d0b2581ca8209'}, 'duration': 0.26703310012817383, 'iteration': 0, 'loss': 0.06655431682654922, 'max_history_score': 0.9334456831734508, 'max_history_score_std': 0.03819399139659311, 'max_history_step': 'joint', 'pipeline': {'features': ('features_NoneType', {}), 'normalizer': ('normalizer_RobustScaler', {'normalizer__quantile_range': (...), 'normalizer__with_centering': False, 'normalizer__with_scaling': False}), 'rebalance': ('rebalance_NearMiss', {'rebalance__n_neighbors': 1})}, 'score': 0.9334456831734508, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': None, 'max_features': 2, 'max_leaf_nodes': 3, 'min_samples_split': 2, 'n_estimators': 100}, 'config_hash': {'algorithm': '1b32258c630f07e01ab481ab925ab80aa757e482', 'config': '9e54ffcb6a727de032a0a2cd45c5cc37cc150756', 'pipeline': '37e72d4a97f5e784c9d3133e6379b91bfc3be803'}, 'duration': 1.3065669536590576, 'iteration': 1, 'loss': 0.05436435917379645, 'max_history_score': 0.9456356408262035, 'max_history_score_std': 0.040053650785990214, 'max_history_step': 'joint', 'pipeline': {'features': ('features_NoneType', {}), 'normalizer': ('normalizer_StandardScaler', {'normalizer__with_mean': True, 'normalizer__with_std': True}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 6})}, 'score': 0.9456356408262035, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'entropy', 'max_depth': 1, 'max_features': 1, 'max_leaf_nodes': 2, 'min_samples_split': 3, 'n_estimators': 25}, 'config_hash': {'algorithm': '68ab9059aa7ec74e0da87c81734b9664243b3eb4', 'config': 'e5241eee9ddf3f4ee29a4711f5bcc92a4d24cd09', 'pipeline': '62463de065924498cdcd2f2f1f7e68535cdb33a5'}, 'duration': 0.6592490673065186, 'iteration': 2, 'loss': 0.07695856019358727, 'max_history_score': 0.9456356408262035, 'max_history_score_std': 0.040053650785990214, 'max_history_step': 'joint', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 1, 'features__selectkbest__k': 2}), 'normalizer': ('normalizer_NoneType', {}), 'rebalance': ('rebalance_NoneType', {})}, 'score': 0.9230414398064127, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': 3, 'max_features': 2, 'max_leaf_nodes': 2, 'min_samples_split': 2, 'n_estimators': 25}, 'config_hash': {'algorithm': 'e3f1f7d7783557a38f40f0476369091edd87092b', 'config': '18ee4d3d1627472ec190326308d8755371a6dc62', 'pipeline': 'c6d1263e344ed8c71b2e6e4ba8e0db2fb6c777c0'}, 'duration': 0.879349946975708, 'iteration': 3, 'loss': 0.07535973554576114, 'max_history_score': 0.9456356408262035, 'max_history_score_std': 0.040053650785990214, 'max_history_step': 'joint', 'pipeline': {'features': ('features_NoneType', {}), 'normalizer': ('normalizer_RobustScaler', {'normalizer__quantile_range': (...), 'normalizer__with_centering': True, 'normalizer__with_scaling': True}), 'rebalance': ('rebalance_NearMiss', {'rebalance__n_neighbors': 2})}, 'score': 0.9246402644542389, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'gini', 'max_depth': 4, 'max_features': 2, 'max_leaf_nodes': 5, 'min_samples_split': 2, 'n_estimators': 50}, 'config_hash': {'algorithm': '47581af7253940f9647ad16d37347d34baf13e5f', 'config': '2af4f82b045c0c48ecb89d42728d1039fbff8878', 'pipeline': '2928b22ed834303cb7bac6e6608531eaddd7df67'}, 'duration': 4.372632026672363, 'iteration': 4, 'loss': 0.09121294615849984, 'max_history_score': 0.9456356408262035, 'max_history_score_std': 0.040053650785990214, 'max_history_step': 'joint', 'pipeline': {'features': ('features_NoneType', {}), 'normalizer': ('normalizer_MinMaxScaler', {}), 'rebalance': ('rebalance_CondensedNearestNeighbour', {'rebalance__n_neighbors': 2})}, 'score': 0.9087870538415002, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'entropy', 'max_depth': 2, 'max_features': 2, 'max_leaf_nodes': None, 'min_samples_split': 2, 'n_estimators': 10}, 'config_hash': {'algorithm': '0a85f98ca2d06103287f153633d88f7a0535e7e8', 'config': '17b2a1e5814f3e933137158708a5b6e9b2475495', 'pipeline': '95defa3bdd8357f11f872d3c280d50a6d8ee398d'}, 'duration': 2.625814914703369, 'iteration': 5, 'loss': 0.15471329185031535, 'max_history_score': 0.9456356408262035, 'max_history_score_std': 0.040053650785990214, 'max_history_step': 'joint', 'pipeline': {'features': ('features_SelectKBest', {'features__k': 2}), 'normalizer': ('normalizer_StandardScaler', {'normalizer__with_mean': False, 'normalizer__with_std': False}), 'rebalance': ('rebalance_CondensedNearestNeighbour', {'rebalance__n_neighbors': 1})}, 'score': 0.8452867081496847, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': 3, 'max_features': None, 'max_leaf_nodes': None, 'min_samples_split': 5, 'n_estimators': 75}, 'config_hash': {'algorithm': 'd7466a2c1d5cb3fa95029d73dc030f4c3c45a159', 'config': 'fa020a592ec5ac234f9f91aac28abc2cd1ec9d33', 'pipeline': '71e0d26f923d42cfe0e2fa748931ef2afe72ed86'}, 'duration': 3.62078595161438, 'iteration': 6, 'loss': 0.17066372828623277, 'max_history_score': 0.9456356408262035, 'max_history_score_std': 0.040053650785990214, 'max_history_step': 'joint', 'pipeline': {'features': ('features_SelectKBest', {'features__k': 1}), 'normalizer': ('normalizer_RobustScaler', {'normalizer__quantile_range': (...), 'normalizer__with_centering': True, 'normalizer__with_scaling': True}), 'rebalance': ('rebalance_CondensedNearestNeighbour', {'rebalance__n_neighbors': 1})}, 'score': 0.8293362717137672, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'entropy', 'max_depth': 3, 'max_features': 3, 'max_leaf_nodes': 5, 'min_samples_split': 5, 'n_estimators': 50}, 'config_hash': {'algorithm': '735caa9785596076014572a24050cde8dc338973', 'config': '0da4498002d6f452c59bb61756abb3ded841e786', 'pipeline': '51a53ea6ef5a2521ee65f76eb2da220ab7086513'}, 'duration': 0.6934049129486084, 'iteration': 7, 'loss': 0.06125875032408601, 'max_history_score': 0.9456356408262035, 'max_history_score_std': 0.040053650785990214, 'max_history_step': 'joint', 'pipeline': {'features': ('features_NoneType', {}), 'normalizer': ('normalizer_NoneType', {}), 'rebalance': ('rebalance_NearMiss', {'rebalance__n_neighbors': 3})}, 'score': 0.938741249675914, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': 4, 'max_features': 2, 'max_leaf_nodes': None, 'min_samples_split': 3, 'n_estimators': 75}, 'config_hash': {'algorithm': 'e71a1fe9515b6805f07914a61f2e7594be9e9afe', 'config': '344e4756fb1bec455d6af51d3727e33b0d27725f', 'pipeline': '248dad1d8b30a17a5de1d0bbdfe3e2acb7a1962b'}, 'duration': 1.3036692142486572, 'iteration': 8, 'loss': 0.06483125918243893, 'max_history_score': 0.9456356408262035, 'max_history_score_std': 0.040053650785990214, 'max_history_step': 'joint', 'pipeline': {'features': ('features_PCA', {'features__n_components': 2}), 'normalizer': ('normalizer_StandardScaler', {'normalizer__with_mean': False, 'normalizer__with_std': True}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 7})}, 'score': 0.9351687408175611, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'entropy', 'max_depth': 2, 'max_features': 2, 'max_leaf_nodes': 2, 'min_samples_split': 3, 'n_estimators': 10}, 'config_hash': {'algorithm': '0a507823f2ad8605ed5950e1fe61df0560f11a00', 'config': '4a538fdcf8e07f90e92a421c0d5c479d651629c7', 'pipeline': '5240329df25c9a533d025c1a401d49835a501b41'}, 'duration': 1.3821029663085938, 'iteration': 9, 'loss': 0.07006416904329793, 'max_history_score': 0.9456356408262035, 'max_history_score_std': 0.040053650785990214, 'max_history_step': 'joint', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 4, 'features__selectkbest__k': 2}), 'normalizer': ('normalizer_PowerTransformer', {}), 'rebalance': ('rebalance_NearMiss', {'rebalance__n_neighbors': 1})}, 'score': 0.9299358309567021, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'gini', 'max_depth': 1, 'max_features': 3, 'max_leaf_nodes': 5, 'min_samples_split': 3, 'n_estimators': 10}, 'config_hash': {'algorithm': 'd32739750d351948f8ff34a87c7d55b0c5e0d90f', 'config': 'c1609e71f1ce8486335adc70bb69a955580ba2c8', 'pipeline': 'f48b42ec5cf999279659966160a16353b75bdaa3'}, 'duration': 0.9055681228637695, 'iteration': 10, 'loss': 0.07532840722495904, 'max_history_score': 0.9456356408262035, 'max_history_score_std': 0.040053650785990214, 'max_history_step': 'joint', 'pipeline': {'features': ('features_PCA', {'features__n_components': 4}), 'normalizer': ('normalizer_PowerTransformer', {}), 'rebalance': ('rebalance_NearMiss', {'rebalance__n_neighbors': 1})}, 'score': 0.924671592775041, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': 3, 'max_features': 1, 'max_leaf_nodes': 5, 'min_samples_split': 3, 'n_estimators': 25}, 'config_hash': {'algorithm': 'f69bac35e71cbec1bfc1fb5942328a3390e7c252', 'config': 'abe36f188644e53e56ed3224236fa157107ed3b2', 'pipeline': 'aaf976c7c663a31fa039582d42f9e07101556a7c'}, 'duration': 0.764197826385498, 'iteration': 11, 'loss': 0.06818446979517778, 'max_history_score': 0.9456356408262035, 'max_history_score_std': 0.040053650785990214, 'max_history_step': 'joint', 'pipeline': {'features': ('features_NoneType', {}), 'normalizer': ('normalizer_PowerTransformer', {}), 'rebalance': ('rebalance_NoneType', {})}, 'score': 0.9318155302048222, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'entropy', 'max_depth': None, 'max_features': None, 'max_leaf_nodes': None, 'min_samples_split': 5, 'n_estimators': 25}, 'config_hash': {'algorithm': 'a0a27aec00db5ddf71eab96663f9bd61c845f5e3', 'config': '76aa002c3c9d4d9722466c60daf5119c18a41d2a', 'pipeline': '1ce34b7894ef342571d974bb19e8ec821a512c6b'}, 'duration': 1.1636500358581543, 'iteration': 12, 'loss': 0.12833700630887557, 'max_history_score': 0.9456356408262035, 'max_history_score_std': 0.040053650785990214, 'max_history_step': 'joint', 'pipeline': {'features': ('features_PCA', {'features__n_components': 1}), 'normalizer': ('normalizer_PowerTransformer', {}), 'rebalance': ('rebalance_NoneType', {})}, 'score': 0.8716629936911244, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'gini', 'max_depth': 1, 'max_features': 2, 'max_leaf_nodes': 2, 'min_samples_split': 2, 'n_estimators': 100}, 'config_hash': {'algorithm': '985c99dff1da9b2c87e4211c5335a9159aa9dbcb', 'config': 'f56a7a9e43a0a699e992dc1262e550b8b7c88538', 'pipeline': '5c934f6d9a8ad1f9afe762986a9cf2074fc95d79'}, 'duration': 2.235443115234375, 'iteration': 13, 'loss': 0.11414635727249167, 'max_history_score': 0.9456356408262035, 'max_history_score_std': 0.040053650785990214, 'max_history_step': 'joint', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 1, 'features__selectkbest__k': 1}), 'normalizer': ('normalizer_RobustScaler', {'normalizer__quantile_range': (...), 'normalizer__with_centering': False, 'normalizer__with_scaling': True}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 6})}, 'score': 0.8858536427275083, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'gini', 'max_depth': 1, 'max_features': 1, 'max_leaf_nodes': None, 'min_samples_split': 5, 'n_estimators': 10}, 'config_hash': {'algorithm': '7d74a39aac2579264a402aef2b6fa7943c19f3d3', 'config': '53f44c0ad925c5c08c25d4fadf5e9ee9d7c181cd', 'pipeline': '6eff5ef31d7d1d534db31913bb67529c8a24c42e'}, 'duration': 2.7847659587860107, 'iteration': 14, 'loss': 0.14061986863711007, 'max_history_score': 0.9456356408262035, 'max_history_score_std': 0.040053650785990214, 'max_history_step': 'joint', 'pipeline': {'features': ('features_PCA', {'features__n_components': 1}), 'normalizer': ('normalizer_RobustScaler', {'normalizer__quantile_range': (...), 'normalizer__with_centering': True, 'normalizer__with_scaling': True}), 'rebalance': ('rebalance_CondensedNearestNeighbour', {'rebalance__n_neighbors': 3})}, 'score': 0.8593801313628899, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'entropy', 'max_depth': 3, 'max_features': None, 'max_leaf_nodes': 5, 'min_samples_split': 2, 'n_estimators': 100}, 'config_hash': {'algorithm': 'c62d7c671832e4414b6b2d7c36cba5ddc83a0ed0', 'config': '5faee50671eaa0ac586722bff234e36a857e662d', 'pipeline': '8b29a55de2add78c49114b9bbe5e800e5524c59d'}, 'duration': 2.3916029930114746, 'iteration': 15, 'loss': 0.08770093336790252, 'max_history_score': 0.9456356408262035, 'max_history_score_std': 0.040053650785990214, 'max_history_step': 'joint', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 3, 'features__selectkbest__k': 4}), 'normalizer': ('normalizer_RobustScaler', {'normalizer__quantile_range': (...), 'normalizer__with_centering': True, 'normalizer__with_scaling': True}), 'rebalance': ('rebalance_NoneType', {})}, 'score': 0.9122990666320975, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': None, 'max_features': 1, 'max_leaf_nodes': 5, 'min_samples_split': 5, 'n_estimators': 10}, 'config_hash': {'algorithm': '290772bfb9b8ed15c48a72829e822fb0a07481d6', 'config': '9a04f25d8eb3db5b2f831abd341a6d384c73a957', 'pipeline': '1ce34b7894ef342571d974bb19e8ec821a512c6b'}, 'duration': 1.4364500045776367, 'iteration': 16, 'loss': 0.08948880822746508, 'max_history_score': 0.9456356408262035, 'max_history_score_std': 0.040053650785990214, 'max_history_step': 'joint', 'pipeline': {'features': ('features_PCA', {'features__n_components': 1}), 'normalizer': ('normalizer_PowerTransformer', {}), 'rebalance': ('rebalance_NoneType', {})}, 'score': 0.9105111917725349, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': 2, 'max_features': 3, 'max_leaf_nodes': 3, 'min_samples_split': 3, 'n_estimators': 100}, 'config_hash': {'algorithm': '7dab6d47f897c2961d3402eff844aff16a7d142a', 'config': '4dbfa2688b239be9f372d3e80223960ba9a1fbdd', 'pipeline': 'cdef51702798fa49f11c11d80baf3ab43d5358fc'}, 'duration': 0.9830451011657715, 'iteration': 17, 'loss': 1.0, 'max_history_score': 0.9456356408262035, 'max_history_score_std': 0.040053650785990214, 'max_history_step': 'joint', 'pipeline': {'features': ('features_SelectKBest', {'features__k': 2}), 'normalizer': ('normalizer_PowerTransformer', {}), 'rebalance': ('rebalance_NearMiss', {'rebalance__n_neighbors': 1})}, 'score': 0.0, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'entropy', 'max_depth': None, 'max_features': 3, 'max_leaf_nodes': None, 'min_samples_split': 5, 'n_estimators': 10}, 'config_hash': {'algorithm': 'def83e48be05ef92a37e1a90585820f2f67ff42b', 'config': '95902552cb76e9798f0fa58782bd72bd1cc272d7', 'pipeline': '1775187bf23f94f4fd0cc1e5c1ef665210edded5'}, 'duration': 2.0033559799194336, 'iteration': 18, 'loss': 0.04922327370149515, 'max_history_score': 0.9507767262985048, 'max_history_score_std': 0.028328108925705902, 'max_history_step': 'joint', 'pipeline': {'features': ('features_PCA', {'features__n_components': 4}), 'normalizer': ('normalizer_StandardScaler', {'normalizer__with_mean': True, 'normalizer__with_std': True}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 5})}, 'score': 0.9507767262985048, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'gini', 'max_depth': 1, 'max_features': 3, 'max_leaf_nodes': None, 'min_samples_split': 2, 'n_estimators': 50}, 'config_hash': {'algorithm': '4e9e3275f817df75115d9d7e3366980fc1b4cf13', 'config': '7770b19007b40bf13005d52eb81f87bc401f15b4', 'pipeline': 'c4dd111513ea35f97dd3aec3e8e7f6268ce035da'}, 'duration': 0.9069631099700928, 'iteration': 19, 'loss': 1.0, 'max_history_score': 0.9507767262985048, 'max_history_score_std': 0.028328108925705902, 'max_history_step': 'joint', 'pipeline': {'features': ('features_PCA', {'features__n_components': 2}), 'normalizer': ('normalizer_RobustScaler', {'normalizer__quantile_range': (...), 'normalizer__with_centering': False, 'normalizer__with_scaling': True}), 'rebalance': ('rebalance_NearMiss', {'rebalance__n_neighbors': 2})}, 'score': 0.0, ...}, ...], 'history_hash': ['51144ca42f9ea5ab2d8d58606e3b3e4d89c6d7b3', '9e54ffcb6a727de032a0a2cd45c5cc37cc150756', 'e5241eee9ddf3f4ee29a4711f5bcc92a4d24cd09', '18ee4d3d1627472ec190326308d8755371a6dc62', '2af4f82b045c0c48ecb89d42728d1039fbff8878', '17b2a1e5814f3e933137158708a5b6e9b2475495', 'fa020a592ec5ac234f9f91aac28abc2cd1ec9d33', '0da4498002d6f452c59bb61756abb3ded841e786', '344e4756fb1bec455d6af51d3727e33b0d27725f', '4a538fdcf8e07f90e92a421c0d5c479d651629c7', 'c1609e71f1ce8486335adc70bb69a955580ba2c8', 'abe36f188644e53e56ed3224236fa157107ed3b2', '76aa002c3c9d4d9722466c60daf5119c18a41d2a', 'f56a7a9e43a0a699e992dc1262e550b8b7c88538', '53f44c0ad925c5c08c25d4fadf5e9ee9d7c181cd', '5faee50671eaa0ac586722bff234e36a857e662d', '9a04f25d8eb3db5b2f831abd341a6d384c73a957', '4dbfa2688b239be9f372d3e80223960ba9a1fbdd', '95902552cb76e9798f0fa58782bd72bd1cc272d7', '7770b19007b40bf13005d52eb81f87bc401f15b4', ...], 'history_index': {'0212926e8a56cc42ae0a654a90c2a3ee92464265': 91, '0da4498002d6f452c59bb61756abb3ded841e786': 7, '0f77a69b0a8d34861caf915a51dc588ff8d4efac': 61, '127553d555ed39231b8da3a1ce42d3902e30919b': 59, '157ad7645c10c929b685db679adc21b38e285fff': 93, '17b2a1e5814f3e933137158708a5b6e9b2475495': 5, '18ee4d3d1627472ec190326308d8755371a6dc62': 3, '1b2267555a9226d7eb4df3c63dd12506da370f4d': 56, '278dd514f71ea681b3e2238dde3b16c35f1697db': 90, '2873878df7d4db8b415ff446bec08003e0c7488d': 92, ...}, 'iteration': 99, 'max_history_score': 0.9525008642295394, 'max_history_score_std': 0.02225295065716913, 'max_history_step': 'joint'}, config={'algorithm': 'RandomForest', 'seed': 42, 'time': 300})
    108 
    109 def objective_algo(algo_config, current_pipeline_config, algorithm, X, y, context, config):
    110     return objective(current_pipeline_config, algo_config, algorithm, X, y, context, config, step='algorithm')
    111 
    112 def objective_joint(wconfig, algorithm, X, y, context, config):
--> 113     return objective(wconfig['pipeline'], wconfig['algorithm'], algorithm, X, y, context, config, step='joint')
        wconfig = {'algorithm': {'bootstrap': False, 'criterion': 'entropy', 'max_depth': None, 'max_features': 3, 'max_leaf_nodes': None, 'min_samples_split': 5, 'n_estimators': 10}, 'pipeline': {'features': ('features_PCA', {'features__n_components': 1}), 'normalizer': ('normalizer_PowerTransformer', {}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 5})}}
        algorithm = 'RandomForest'
        X = array([[1.799e+01, 1.038e+01, 1.228e+02, ..., 2...., ..., 0.000e+00, 2.871e-01,
        7.039e-02]])
        y = array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,... 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1])
        context = {'baseline_score': 0.9545944602886527, 'baseline_score_std': 0.03716322883281839, 'best_config': {'algorithm': {'bootstrap': False, 'criterion': 'entropy', 'max_depth': None, 'max_features': 2, 'max_leaf_nodes': None, 'min_samples_split': 5, 'n_estimators': 10}, 'config_hash': {'algorithm': 'e7a772c2bc361aa61cf7eeb364a26dca2c9b89d6', 'config': 'afb67da069b544b0505b1e8c150edc7498ad37b4', 'pipeline': 'a43db4b4fc4c38610b7b5e484840d2e583089ff4'}, 'duration': 1.0073001384735107, 'iteration': 26, 'loss': 0.04749913577046061, 'max_history_score': 0.9525008642295394, 'max_history_score_std': 0.02225295065716913, 'max_history_step': 'joint', 'pipeline': {'features': ('features_PCA', {'features__n_components': 4}), 'normalizer': ('normalizer_StandardScaler', {'normalizer__with_mean': True, 'normalizer__with_std': False}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 7})}, 'score': 0.9525008642295394, ...}, 'history': [{'algorithm': {'bootstrap': True, 'criterion': 'entropy', 'max_depth': 4, 'max_features': 3, 'max_leaf_nodes': 3, 'min_samples_split': 2, 'n_estimators': 10}, 'config_hash': {'algorithm': '42527c4120073c2a488d1b8df28732f486d1578c', 'config': '51144ca42f9ea5ab2d8d58606e3b3e4d89c6d7b3', 'pipeline': '52f07bda29f9d3a95fabb87e591d0b2581ca8209'}, 'duration': 0.26703310012817383, 'iteration': 0, 'loss': 0.06655431682654922, 'max_history_score': 0.9334456831734508, 'max_history_score_std': 0.03819399139659311, 'max_history_step': 'joint', 'pipeline': {'features': ('features_NoneType', {}), 'normalizer': ('normalizer_RobustScaler', {'normalizer__quantile_range': (...), 'normalizer__with_centering': False, 'normalizer__with_scaling': False}), 'rebalance': ('rebalance_NearMiss', {'rebalance__n_neighbors': 1})}, 'score': 0.9334456831734508, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': None, 'max_features': 2, 'max_leaf_nodes': 3, 'min_samples_split': 2, 'n_estimators': 100}, 'config_hash': {'algorithm': '1b32258c630f07e01ab481ab925ab80aa757e482', 'config': '9e54ffcb6a727de032a0a2cd45c5cc37cc150756', 'pipeline': '37e72d4a97f5e784c9d3133e6379b91bfc3be803'}, 'duration': 1.3065669536590576, 'iteration': 1, 'loss': 0.05436435917379645, 'max_history_score': 0.9456356408262035, 'max_history_score_std': 0.040053650785990214, 'max_history_step': 'joint', 'pipeline': {'features': ('features_NoneType', {}), 'normalizer': ('normalizer_StandardScaler', {'normalizer__with_mean': True, 'normalizer__with_std': True}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 6})}, 'score': 0.9456356408262035, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'entropy', 'max_depth': 1, 'max_features': 1, 'max_leaf_nodes': 2, 'min_samples_split': 3, 'n_estimators': 25}, 'config_hash': {'algorithm': '68ab9059aa7ec74e0da87c81734b9664243b3eb4', 'config': 'e5241eee9ddf3f4ee29a4711f5bcc92a4d24cd09', 'pipeline': '62463de065924498cdcd2f2f1f7e68535cdb33a5'}, 'duration': 0.6592490673065186, 'iteration': 2, 'loss': 0.07695856019358727, 'max_history_score': 0.9456356408262035, 'max_history_score_std': 0.040053650785990214, 'max_history_step': 'joint', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 1, 'features__selectkbest__k': 2}), 'normalizer': ('normalizer_NoneType', {}), 'rebalance': ('rebalance_NoneType', {})}, 'score': 0.9230414398064127, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': 3, 'max_features': 2, 'max_leaf_nodes': 2, 'min_samples_split': 2, 'n_estimators': 25}, 'config_hash': {'algorithm': 'e3f1f7d7783557a38f40f0476369091edd87092b', 'config': '18ee4d3d1627472ec190326308d8755371a6dc62', 'pipeline': 'c6d1263e344ed8c71b2e6e4ba8e0db2fb6c777c0'}, 'duration': 0.879349946975708, 'iteration': 3, 'loss': 0.07535973554576114, 'max_history_score': 0.9456356408262035, 'max_history_score_std': 0.040053650785990214, 'max_history_step': 'joint', 'pipeline': {'features': ('features_NoneType', {}), 'normalizer': ('normalizer_RobustScaler', {'normalizer__quantile_range': (...), 'normalizer__with_centering': True, 'normalizer__with_scaling': True}), 'rebalance': ('rebalance_NearMiss', {'rebalance__n_neighbors': 2})}, 'score': 0.9246402644542389, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'gini', 'max_depth': 4, 'max_features': 2, 'max_leaf_nodes': 5, 'min_samples_split': 2, 'n_estimators': 50}, 'config_hash': {'algorithm': '47581af7253940f9647ad16d37347d34baf13e5f', 'config': '2af4f82b045c0c48ecb89d42728d1039fbff8878', 'pipeline': '2928b22ed834303cb7bac6e6608531eaddd7df67'}, 'duration': 4.372632026672363, 'iteration': 4, 'loss': 0.09121294615849984, 'max_history_score': 0.9456356408262035, 'max_history_score_std': 0.040053650785990214, 'max_history_step': 'joint', 'pipeline': {'features': ('features_NoneType', {}), 'normalizer': ('normalizer_MinMaxScaler', {}), 'rebalance': ('rebalance_CondensedNearestNeighbour', {'rebalance__n_neighbors': 2})}, 'score': 0.9087870538415002, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'entropy', 'max_depth': 2, 'max_features': 2, 'max_leaf_nodes': None, 'min_samples_split': 2, 'n_estimators': 10}, 'config_hash': {'algorithm': '0a85f98ca2d06103287f153633d88f7a0535e7e8', 'config': '17b2a1e5814f3e933137158708a5b6e9b2475495', 'pipeline': '95defa3bdd8357f11f872d3c280d50a6d8ee398d'}, 'duration': 2.625814914703369, 'iteration': 5, 'loss': 0.15471329185031535, 'max_history_score': 0.9456356408262035, 'max_history_score_std': 0.040053650785990214, 'max_history_step': 'joint', 'pipeline': {'features': ('features_SelectKBest', {'features__k': 2}), 'normalizer': ('normalizer_StandardScaler', {'normalizer__with_mean': False, 'normalizer__with_std': False}), 'rebalance': ('rebalance_CondensedNearestNeighbour', {'rebalance__n_neighbors': 1})}, 'score': 0.8452867081496847, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': 3, 'max_features': None, 'max_leaf_nodes': None, 'min_samples_split': 5, 'n_estimators': 75}, 'config_hash': {'algorithm': 'd7466a2c1d5cb3fa95029d73dc030f4c3c45a159', 'config': 'fa020a592ec5ac234f9f91aac28abc2cd1ec9d33', 'pipeline': '71e0d26f923d42cfe0e2fa748931ef2afe72ed86'}, 'duration': 3.62078595161438, 'iteration': 6, 'loss': 0.17066372828623277, 'max_history_score': 0.9456356408262035, 'max_history_score_std': 0.040053650785990214, 'max_history_step': 'joint', 'pipeline': {'features': ('features_SelectKBest', {'features__k': 1}), 'normalizer': ('normalizer_RobustScaler', {'normalizer__quantile_range': (...), 'normalizer__with_centering': True, 'normalizer__with_scaling': True}), 'rebalance': ('rebalance_CondensedNearestNeighbour', {'rebalance__n_neighbors': 1})}, 'score': 0.8293362717137672, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'entropy', 'max_depth': 3, 'max_features': 3, 'max_leaf_nodes': 5, 'min_samples_split': 5, 'n_estimators': 50}, 'config_hash': {'algorithm': '735caa9785596076014572a24050cde8dc338973', 'config': '0da4498002d6f452c59bb61756abb3ded841e786', 'pipeline': '51a53ea6ef5a2521ee65f76eb2da220ab7086513'}, 'duration': 0.6934049129486084, 'iteration': 7, 'loss': 0.06125875032408601, 'max_history_score': 0.9456356408262035, 'max_history_score_std': 0.040053650785990214, 'max_history_step': 'joint', 'pipeline': {'features': ('features_NoneType', {}), 'normalizer': ('normalizer_NoneType', {}), 'rebalance': ('rebalance_NearMiss', {'rebalance__n_neighbors': 3})}, 'score': 0.938741249675914, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': 4, 'max_features': 2, 'max_leaf_nodes': None, 'min_samples_split': 3, 'n_estimators': 75}, 'config_hash': {'algorithm': 'e71a1fe9515b6805f07914a61f2e7594be9e9afe', 'config': '344e4756fb1bec455d6af51d3727e33b0d27725f', 'pipeline': '248dad1d8b30a17a5de1d0bbdfe3e2acb7a1962b'}, 'duration': 1.3036692142486572, 'iteration': 8, 'loss': 0.06483125918243893, 'max_history_score': 0.9456356408262035, 'max_history_score_std': 0.040053650785990214, 'max_history_step': 'joint', 'pipeline': {'features': ('features_PCA', {'features__n_components': 2}), 'normalizer': ('normalizer_StandardScaler', {'normalizer__with_mean': False, 'normalizer__with_std': True}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 7})}, 'score': 0.9351687408175611, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'entropy', 'max_depth': 2, 'max_features': 2, 'max_leaf_nodes': 2, 'min_samples_split': 3, 'n_estimators': 10}, 'config_hash': {'algorithm': '0a507823f2ad8605ed5950e1fe61df0560f11a00', 'config': '4a538fdcf8e07f90e92a421c0d5c479d651629c7', 'pipeline': '5240329df25c9a533d025c1a401d49835a501b41'}, 'duration': 1.3821029663085938, 'iteration': 9, 'loss': 0.07006416904329793, 'max_history_score': 0.9456356408262035, 'max_history_score_std': 0.040053650785990214, 'max_history_step': 'joint', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 4, 'features__selectkbest__k': 2}), 'normalizer': ('normalizer_PowerTransformer', {}), 'rebalance': ('rebalance_NearMiss', {'rebalance__n_neighbors': 1})}, 'score': 0.9299358309567021, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'gini', 'max_depth': 1, 'max_features': 3, 'max_leaf_nodes': 5, 'min_samples_split': 3, 'n_estimators': 10}, 'config_hash': {'algorithm': 'd32739750d351948f8ff34a87c7d55b0c5e0d90f', 'config': 'c1609e71f1ce8486335adc70bb69a955580ba2c8', 'pipeline': 'f48b42ec5cf999279659966160a16353b75bdaa3'}, 'duration': 0.9055681228637695, 'iteration': 10, 'loss': 0.07532840722495904, 'max_history_score': 0.9456356408262035, 'max_history_score_std': 0.040053650785990214, 'max_history_step': 'joint', 'pipeline': {'features': ('features_PCA', {'features__n_components': 4}), 'normalizer': ('normalizer_PowerTransformer', {}), 'rebalance': ('rebalance_NearMiss', {'rebalance__n_neighbors': 1})}, 'score': 0.924671592775041, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': 3, 'max_features': 1, 'max_leaf_nodes': 5, 'min_samples_split': 3, 'n_estimators': 25}, 'config_hash': {'algorithm': 'f69bac35e71cbec1bfc1fb5942328a3390e7c252', 'config': 'abe36f188644e53e56ed3224236fa157107ed3b2', 'pipeline': 'aaf976c7c663a31fa039582d42f9e07101556a7c'}, 'duration': 0.764197826385498, 'iteration': 11, 'loss': 0.06818446979517778, 'max_history_score': 0.9456356408262035, 'max_history_score_std': 0.040053650785990214, 'max_history_step': 'joint', 'pipeline': {'features': ('features_NoneType', {}), 'normalizer': ('normalizer_PowerTransformer', {}), 'rebalance': ('rebalance_NoneType', {})}, 'score': 0.9318155302048222, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'entropy', 'max_depth': None, 'max_features': None, 'max_leaf_nodes': None, 'min_samples_split': 5, 'n_estimators': 25}, 'config_hash': {'algorithm': 'a0a27aec00db5ddf71eab96663f9bd61c845f5e3', 'config': '76aa002c3c9d4d9722466c60daf5119c18a41d2a', 'pipeline': '1ce34b7894ef342571d974bb19e8ec821a512c6b'}, 'duration': 1.1636500358581543, 'iteration': 12, 'loss': 0.12833700630887557, 'max_history_score': 0.9456356408262035, 'max_history_score_std': 0.040053650785990214, 'max_history_step': 'joint', 'pipeline': {'features': ('features_PCA', {'features__n_components': 1}), 'normalizer': ('normalizer_PowerTransformer', {}), 'rebalance': ('rebalance_NoneType', {})}, 'score': 0.8716629936911244, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'gini', 'max_depth': 1, 'max_features': 2, 'max_leaf_nodes': 2, 'min_samples_split': 2, 'n_estimators': 100}, 'config_hash': {'algorithm': '985c99dff1da9b2c87e4211c5335a9159aa9dbcb', 'config': 'f56a7a9e43a0a699e992dc1262e550b8b7c88538', 'pipeline': '5c934f6d9a8ad1f9afe762986a9cf2074fc95d79'}, 'duration': 2.235443115234375, 'iteration': 13, 'loss': 0.11414635727249167, 'max_history_score': 0.9456356408262035, 'max_history_score_std': 0.040053650785990214, 'max_history_step': 'joint', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 1, 'features__selectkbest__k': 1}), 'normalizer': ('normalizer_RobustScaler', {'normalizer__quantile_range': (...), 'normalizer__with_centering': False, 'normalizer__with_scaling': True}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 6})}, 'score': 0.8858536427275083, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'gini', 'max_depth': 1, 'max_features': 1, 'max_leaf_nodes': None, 'min_samples_split': 5, 'n_estimators': 10}, 'config_hash': {'algorithm': '7d74a39aac2579264a402aef2b6fa7943c19f3d3', 'config': '53f44c0ad925c5c08c25d4fadf5e9ee9d7c181cd', 'pipeline': '6eff5ef31d7d1d534db31913bb67529c8a24c42e'}, 'duration': 2.7847659587860107, 'iteration': 14, 'loss': 0.14061986863711007, 'max_history_score': 0.9456356408262035, 'max_history_score_std': 0.040053650785990214, 'max_history_step': 'joint', 'pipeline': {'features': ('features_PCA', {'features__n_components': 1}), 'normalizer': ('normalizer_RobustScaler', {'normalizer__quantile_range': (...), 'normalizer__with_centering': True, 'normalizer__with_scaling': True}), 'rebalance': ('rebalance_CondensedNearestNeighbour', {'rebalance__n_neighbors': 3})}, 'score': 0.8593801313628899, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'entropy', 'max_depth': 3, 'max_features': None, 'max_leaf_nodes': 5, 'min_samples_split': 2, 'n_estimators': 100}, 'config_hash': {'algorithm': 'c62d7c671832e4414b6b2d7c36cba5ddc83a0ed0', 'config': '5faee50671eaa0ac586722bff234e36a857e662d', 'pipeline': '8b29a55de2add78c49114b9bbe5e800e5524c59d'}, 'duration': 2.3916029930114746, 'iteration': 15, 'loss': 0.08770093336790252, 'max_history_score': 0.9456356408262035, 'max_history_score_std': 0.040053650785990214, 'max_history_step': 'joint', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 3, 'features__selectkbest__k': 4}), 'normalizer': ('normalizer_RobustScaler', {'normalizer__quantile_range': (...), 'normalizer__with_centering': True, 'normalizer__with_scaling': True}), 'rebalance': ('rebalance_NoneType', {})}, 'score': 0.9122990666320975, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': None, 'max_features': 1, 'max_leaf_nodes': 5, 'min_samples_split': 5, 'n_estimators': 10}, 'config_hash': {'algorithm': '290772bfb9b8ed15c48a72829e822fb0a07481d6', 'config': '9a04f25d8eb3db5b2f831abd341a6d384c73a957', 'pipeline': '1ce34b7894ef342571d974bb19e8ec821a512c6b'}, 'duration': 1.4364500045776367, 'iteration': 16, 'loss': 0.08948880822746508, 'max_history_score': 0.9456356408262035, 'max_history_score_std': 0.040053650785990214, 'max_history_step': 'joint', 'pipeline': {'features': ('features_PCA', {'features__n_components': 1}), 'normalizer': ('normalizer_PowerTransformer', {}), 'rebalance': ('rebalance_NoneType', {})}, 'score': 0.9105111917725349, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': 2, 'max_features': 3, 'max_leaf_nodes': 3, 'min_samples_split': 3, 'n_estimators': 100}, 'config_hash': {'algorithm': '7dab6d47f897c2961d3402eff844aff16a7d142a', 'config': '4dbfa2688b239be9f372d3e80223960ba9a1fbdd', 'pipeline': 'cdef51702798fa49f11c11d80baf3ab43d5358fc'}, 'duration': 0.9830451011657715, 'iteration': 17, 'loss': 1.0, 'max_history_score': 0.9456356408262035, 'max_history_score_std': 0.040053650785990214, 'max_history_step': 'joint', 'pipeline': {'features': ('features_SelectKBest', {'features__k': 2}), 'normalizer': ('normalizer_PowerTransformer', {}), 'rebalance': ('rebalance_NearMiss', {'rebalance__n_neighbors': 1})}, 'score': 0.0, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'entropy', 'max_depth': None, 'max_features': 3, 'max_leaf_nodes': None, 'min_samples_split': 5, 'n_estimators': 10}, 'config_hash': {'algorithm': 'def83e48be05ef92a37e1a90585820f2f67ff42b', 'config': '95902552cb76e9798f0fa58782bd72bd1cc272d7', 'pipeline': '1775187bf23f94f4fd0cc1e5c1ef665210edded5'}, 'duration': 2.0033559799194336, 'iteration': 18, 'loss': 0.04922327370149515, 'max_history_score': 0.9507767262985048, 'max_history_score_std': 0.028328108925705902, 'max_history_step': 'joint', 'pipeline': {'features': ('features_PCA', {'features__n_components': 4}), 'normalizer': ('normalizer_StandardScaler', {'normalizer__with_mean': True, 'normalizer__with_std': True}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 5})}, 'score': 0.9507767262985048, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'gini', 'max_depth': 1, 'max_features': 3, 'max_leaf_nodes': None, 'min_samples_split': 2, 'n_estimators': 50}, 'config_hash': {'algorithm': '4e9e3275f817df75115d9d7e3366980fc1b4cf13', 'config': '7770b19007b40bf13005d52eb81f87bc401f15b4', 'pipeline': 'c4dd111513ea35f97dd3aec3e8e7f6268ce035da'}, 'duration': 0.9069631099700928, 'iteration': 19, 'loss': 1.0, 'max_history_score': 0.9507767262985048, 'max_history_score_std': 0.028328108925705902, 'max_history_step': 'joint', 'pipeline': {'features': ('features_PCA', {'features__n_components': 2}), 'normalizer': ('normalizer_RobustScaler', {'normalizer__quantile_range': (...), 'normalizer__with_centering': False, 'normalizer__with_scaling': True}), 'rebalance': ('rebalance_NearMiss', {'rebalance__n_neighbors': 2})}, 'score': 0.0, ...}, ...], 'history_hash': ['51144ca42f9ea5ab2d8d58606e3b3e4d89c6d7b3', '9e54ffcb6a727de032a0a2cd45c5cc37cc150756', 'e5241eee9ddf3f4ee29a4711f5bcc92a4d24cd09', '18ee4d3d1627472ec190326308d8755371a6dc62', '2af4f82b045c0c48ecb89d42728d1039fbff8878', '17b2a1e5814f3e933137158708a5b6e9b2475495', 'fa020a592ec5ac234f9f91aac28abc2cd1ec9d33', '0da4498002d6f452c59bb61756abb3ded841e786', '344e4756fb1bec455d6af51d3727e33b0d27725f', '4a538fdcf8e07f90e92a421c0d5c479d651629c7', 'c1609e71f1ce8486335adc70bb69a955580ba2c8', 'abe36f188644e53e56ed3224236fa157107ed3b2', '76aa002c3c9d4d9722466c60daf5119c18a41d2a', 'f56a7a9e43a0a699e992dc1262e550b8b7c88538', '53f44c0ad925c5c08c25d4fadf5e9ee9d7c181cd', '5faee50671eaa0ac586722bff234e36a857e662d', '9a04f25d8eb3db5b2f831abd341a6d384c73a957', '4dbfa2688b239be9f372d3e80223960ba9a1fbdd', '95902552cb76e9798f0fa58782bd72bd1cc272d7', '7770b19007b40bf13005d52eb81f87bc401f15b4', ...], 'history_index': {'0212926e8a56cc42ae0a654a90c2a3ee92464265': 91, '0da4498002d6f452c59bb61756abb3ded841e786': 7, '0f77a69b0a8d34861caf915a51dc588ff8d4efac': 61, '127553d555ed39231b8da3a1ce42d3902e30919b': 59, '157ad7645c10c929b685db679adc21b38e285fff': 93, '17b2a1e5814f3e933137158708a5b6e9b2475495': 5, '18ee4d3d1627472ec190326308d8755371a6dc62': 3, '1b2267555a9226d7eb4df3c63dd12506da370f4d': 56, '278dd514f71ea681b3e2238dde3b16c35f1697db': 90, '2873878df7d4db8b415ff446bec08003e0c7488d': 92, ...}, 'iteration': 99, 'max_history_score': 0.9525008642295394, 'max_history_score_std': 0.02225295065716913, 'max_history_step': 'joint'}
        config = {'algorithm': 'RandomForest', 'seed': 42, 'time': 300}
    114 
    115 
    116 def get_baseline_score(algorithm, X, y, seed):
    117     pipeline, _ = pipeline_conf_to_full_pipeline(

...........................................................................
/home/aquemy/dev/dp_hyperparameters/extension/experiment/objective.py in objective(pipeline_config={'features': ('features_PCA', {'features__n_components': 1}), 'normalizer': ('normalizer_PowerTransformer', {}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 5})}, algo_config={'bootstrap': False, 'criterion': 'entropy', 'max_depth': None, 'max_features': 3, 'max_leaf_nodes': None, 'min_samples_split': 5, 'n_estimators': 10}, algorithm='RandomForest', X=array([[1.799e+01, 1.038e+01, 1.228e+02, ..., 2...., ..., 0.000e+00, 2.871e-01,
        7.039e-02]]), y=array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,... 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1]), context={'baseline_score': 0.9545944602886527, 'baseline_score_std': 0.03716322883281839, 'best_config': {'algorithm': {'bootstrap': False, 'criterion': 'entropy', 'max_depth': None, 'max_features': 2, 'max_leaf_nodes': None, 'min_samples_split': 5, 'n_estimators': 10}, 'config_hash': {'algorithm': 'e7a772c2bc361aa61cf7eeb364a26dca2c9b89d6', 'config': 'afb67da069b544b0505b1e8c150edc7498ad37b4', 'pipeline': 'a43db4b4fc4c38610b7b5e484840d2e583089ff4'}, 'duration': 1.0073001384735107, 'iteration': 26, 'loss': 0.04749913577046061, 'max_history_score': 0.9525008642295394, 'max_history_score_std': 0.02225295065716913, 'max_history_step': 'joint', 'pipeline': {'features': ('features_PCA', {'features__n_components': 4}), 'normalizer': ('normalizer_StandardScaler', {'normalizer__with_mean': True, 'normalizer__with_std': False}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 7})}, 'score': 0.9525008642295394, ...}, 'history': [{'algorithm': {'bootstrap': True, 'criterion': 'entropy', 'max_depth': 4, 'max_features': 3, 'max_leaf_nodes': 3, 'min_samples_split': 2, 'n_estimators': 10}, 'config_hash': {'algorithm': '42527c4120073c2a488d1b8df28732f486d1578c', 'config': '51144ca42f9ea5ab2d8d58606e3b3e4d89c6d7b3', 'pipeline': '52f07bda29f9d3a95fabb87e591d0b2581ca8209'}, 'duration': 0.26703310012817383, 'iteration': 0, 'loss': 0.06655431682654922, 'max_history_score': 0.9334456831734508, 'max_history_score_std': 0.03819399139659311, 'max_history_step': 'joint', 'pipeline': {'features': ('features_NoneType', {}), 'normalizer': ('normalizer_RobustScaler', {'normalizer__quantile_range': (...), 'normalizer__with_centering': False, 'normalizer__with_scaling': False}), 'rebalance': ('rebalance_NearMiss', {'rebalance__n_neighbors': 1})}, 'score': 0.9334456831734508, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': None, 'max_features': 2, 'max_leaf_nodes': 3, 'min_samples_split': 2, 'n_estimators': 100}, 'config_hash': {'algorithm': '1b32258c630f07e01ab481ab925ab80aa757e482', 'config': '9e54ffcb6a727de032a0a2cd45c5cc37cc150756', 'pipeline': '37e72d4a97f5e784c9d3133e6379b91bfc3be803'}, 'duration': 1.3065669536590576, 'iteration': 1, 'loss': 0.05436435917379645, 'max_history_score': 0.9456356408262035, 'max_history_score_std': 0.040053650785990214, 'max_history_step': 'joint', 'pipeline': {'features': ('features_NoneType', {}), 'normalizer': ('normalizer_StandardScaler', {'normalizer__with_mean': True, 'normalizer__with_std': True}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 6})}, 'score': 0.9456356408262035, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'entropy', 'max_depth': 1, 'max_features': 1, 'max_leaf_nodes': 2, 'min_samples_split': 3, 'n_estimators': 25}, 'config_hash': {'algorithm': '68ab9059aa7ec74e0da87c81734b9664243b3eb4', 'config': 'e5241eee9ddf3f4ee29a4711f5bcc92a4d24cd09', 'pipeline': '62463de065924498cdcd2f2f1f7e68535cdb33a5'}, 'duration': 0.6592490673065186, 'iteration': 2, 'loss': 0.07695856019358727, 'max_history_score': 0.9456356408262035, 'max_history_score_std': 0.040053650785990214, 'max_history_step': 'joint', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 1, 'features__selectkbest__k': 2}), 'normalizer': ('normalizer_NoneType', {}), 'rebalance': ('rebalance_NoneType', {})}, 'score': 0.9230414398064127, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': 3, 'max_features': 2, 'max_leaf_nodes': 2, 'min_samples_split': 2, 'n_estimators': 25}, 'config_hash': {'algorithm': 'e3f1f7d7783557a38f40f0476369091edd87092b', 'config': '18ee4d3d1627472ec190326308d8755371a6dc62', 'pipeline': 'c6d1263e344ed8c71b2e6e4ba8e0db2fb6c777c0'}, 'duration': 0.879349946975708, 'iteration': 3, 'loss': 0.07535973554576114, 'max_history_score': 0.9456356408262035, 'max_history_score_std': 0.040053650785990214, 'max_history_step': 'joint', 'pipeline': {'features': ('features_NoneType', {}), 'normalizer': ('normalizer_RobustScaler', {'normalizer__quantile_range': (...), 'normalizer__with_centering': True, 'normalizer__with_scaling': True}), 'rebalance': ('rebalance_NearMiss', {'rebalance__n_neighbors': 2})}, 'score': 0.9246402644542389, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'gini', 'max_depth': 4, 'max_features': 2, 'max_leaf_nodes': 5, 'min_samples_split': 2, 'n_estimators': 50}, 'config_hash': {'algorithm': '47581af7253940f9647ad16d37347d34baf13e5f', 'config': '2af4f82b045c0c48ecb89d42728d1039fbff8878', 'pipeline': '2928b22ed834303cb7bac6e6608531eaddd7df67'}, 'duration': 4.372632026672363, 'iteration': 4, 'loss': 0.09121294615849984, 'max_history_score': 0.9456356408262035, 'max_history_score_std': 0.040053650785990214, 'max_history_step': 'joint', 'pipeline': {'features': ('features_NoneType', {}), 'normalizer': ('normalizer_MinMaxScaler', {}), 'rebalance': ('rebalance_CondensedNearestNeighbour', {'rebalance__n_neighbors': 2})}, 'score': 0.9087870538415002, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'entropy', 'max_depth': 2, 'max_features': 2, 'max_leaf_nodes': None, 'min_samples_split': 2, 'n_estimators': 10}, 'config_hash': {'algorithm': '0a85f98ca2d06103287f153633d88f7a0535e7e8', 'config': '17b2a1e5814f3e933137158708a5b6e9b2475495', 'pipeline': '95defa3bdd8357f11f872d3c280d50a6d8ee398d'}, 'duration': 2.625814914703369, 'iteration': 5, 'loss': 0.15471329185031535, 'max_history_score': 0.9456356408262035, 'max_history_score_std': 0.040053650785990214, 'max_history_step': 'joint', 'pipeline': {'features': ('features_SelectKBest', {'features__k': 2}), 'normalizer': ('normalizer_StandardScaler', {'normalizer__with_mean': False, 'normalizer__with_std': False}), 'rebalance': ('rebalance_CondensedNearestNeighbour', {'rebalance__n_neighbors': 1})}, 'score': 0.8452867081496847, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': 3, 'max_features': None, 'max_leaf_nodes': None, 'min_samples_split': 5, 'n_estimators': 75}, 'config_hash': {'algorithm': 'd7466a2c1d5cb3fa95029d73dc030f4c3c45a159', 'config': 'fa020a592ec5ac234f9f91aac28abc2cd1ec9d33', 'pipeline': '71e0d26f923d42cfe0e2fa748931ef2afe72ed86'}, 'duration': 3.62078595161438, 'iteration': 6, 'loss': 0.17066372828623277, 'max_history_score': 0.9456356408262035, 'max_history_score_std': 0.040053650785990214, 'max_history_step': 'joint', 'pipeline': {'features': ('features_SelectKBest', {'features__k': 1}), 'normalizer': ('normalizer_RobustScaler', {'normalizer__quantile_range': (...), 'normalizer__with_centering': True, 'normalizer__with_scaling': True}), 'rebalance': ('rebalance_CondensedNearestNeighbour', {'rebalance__n_neighbors': 1})}, 'score': 0.8293362717137672, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'entropy', 'max_depth': 3, 'max_features': 3, 'max_leaf_nodes': 5, 'min_samples_split': 5, 'n_estimators': 50}, 'config_hash': {'algorithm': '735caa9785596076014572a24050cde8dc338973', 'config': '0da4498002d6f452c59bb61756abb3ded841e786', 'pipeline': '51a53ea6ef5a2521ee65f76eb2da220ab7086513'}, 'duration': 0.6934049129486084, 'iteration': 7, 'loss': 0.06125875032408601, 'max_history_score': 0.9456356408262035, 'max_history_score_std': 0.040053650785990214, 'max_history_step': 'joint', 'pipeline': {'features': ('features_NoneType', {}), 'normalizer': ('normalizer_NoneType', {}), 'rebalance': ('rebalance_NearMiss', {'rebalance__n_neighbors': 3})}, 'score': 0.938741249675914, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': 4, 'max_features': 2, 'max_leaf_nodes': None, 'min_samples_split': 3, 'n_estimators': 75}, 'config_hash': {'algorithm': 'e71a1fe9515b6805f07914a61f2e7594be9e9afe', 'config': '344e4756fb1bec455d6af51d3727e33b0d27725f', 'pipeline': '248dad1d8b30a17a5de1d0bbdfe3e2acb7a1962b'}, 'duration': 1.3036692142486572, 'iteration': 8, 'loss': 0.06483125918243893, 'max_history_score': 0.9456356408262035, 'max_history_score_std': 0.040053650785990214, 'max_history_step': 'joint', 'pipeline': {'features': ('features_PCA', {'features__n_components': 2}), 'normalizer': ('normalizer_StandardScaler', {'normalizer__with_mean': False, 'normalizer__with_std': True}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 7})}, 'score': 0.9351687408175611, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'entropy', 'max_depth': 2, 'max_features': 2, 'max_leaf_nodes': 2, 'min_samples_split': 3, 'n_estimators': 10}, 'config_hash': {'algorithm': '0a507823f2ad8605ed5950e1fe61df0560f11a00', 'config': '4a538fdcf8e07f90e92a421c0d5c479d651629c7', 'pipeline': '5240329df25c9a533d025c1a401d49835a501b41'}, 'duration': 1.3821029663085938, 'iteration': 9, 'loss': 0.07006416904329793, 'max_history_score': 0.9456356408262035, 'max_history_score_std': 0.040053650785990214, 'max_history_step': 'joint', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 4, 'features__selectkbest__k': 2}), 'normalizer': ('normalizer_PowerTransformer', {}), 'rebalance': ('rebalance_NearMiss', {'rebalance__n_neighbors': 1})}, 'score': 0.9299358309567021, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'gini', 'max_depth': 1, 'max_features': 3, 'max_leaf_nodes': 5, 'min_samples_split': 3, 'n_estimators': 10}, 'config_hash': {'algorithm': 'd32739750d351948f8ff34a87c7d55b0c5e0d90f', 'config': 'c1609e71f1ce8486335adc70bb69a955580ba2c8', 'pipeline': 'f48b42ec5cf999279659966160a16353b75bdaa3'}, 'duration': 0.9055681228637695, 'iteration': 10, 'loss': 0.07532840722495904, 'max_history_score': 0.9456356408262035, 'max_history_score_std': 0.040053650785990214, 'max_history_step': 'joint', 'pipeline': {'features': ('features_PCA', {'features__n_components': 4}), 'normalizer': ('normalizer_PowerTransformer', {}), 'rebalance': ('rebalance_NearMiss', {'rebalance__n_neighbors': 1})}, 'score': 0.924671592775041, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': 3, 'max_features': 1, 'max_leaf_nodes': 5, 'min_samples_split': 3, 'n_estimators': 25}, 'config_hash': {'algorithm': 'f69bac35e71cbec1bfc1fb5942328a3390e7c252', 'config': 'abe36f188644e53e56ed3224236fa157107ed3b2', 'pipeline': 'aaf976c7c663a31fa039582d42f9e07101556a7c'}, 'duration': 0.764197826385498, 'iteration': 11, 'loss': 0.06818446979517778, 'max_history_score': 0.9456356408262035, 'max_history_score_std': 0.040053650785990214, 'max_history_step': 'joint', 'pipeline': {'features': ('features_NoneType', {}), 'normalizer': ('normalizer_PowerTransformer', {}), 'rebalance': ('rebalance_NoneType', {})}, 'score': 0.9318155302048222, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'entropy', 'max_depth': None, 'max_features': None, 'max_leaf_nodes': None, 'min_samples_split': 5, 'n_estimators': 25}, 'config_hash': {'algorithm': 'a0a27aec00db5ddf71eab96663f9bd61c845f5e3', 'config': '76aa002c3c9d4d9722466c60daf5119c18a41d2a', 'pipeline': '1ce34b7894ef342571d974bb19e8ec821a512c6b'}, 'duration': 1.1636500358581543, 'iteration': 12, 'loss': 0.12833700630887557, 'max_history_score': 0.9456356408262035, 'max_history_score_std': 0.040053650785990214, 'max_history_step': 'joint', 'pipeline': {'features': ('features_PCA', {'features__n_components': 1}), 'normalizer': ('normalizer_PowerTransformer', {}), 'rebalance': ('rebalance_NoneType', {})}, 'score': 0.8716629936911244, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'gini', 'max_depth': 1, 'max_features': 2, 'max_leaf_nodes': 2, 'min_samples_split': 2, 'n_estimators': 100}, 'config_hash': {'algorithm': '985c99dff1da9b2c87e4211c5335a9159aa9dbcb', 'config': 'f56a7a9e43a0a699e992dc1262e550b8b7c88538', 'pipeline': '5c934f6d9a8ad1f9afe762986a9cf2074fc95d79'}, 'duration': 2.235443115234375, 'iteration': 13, 'loss': 0.11414635727249167, 'max_history_score': 0.9456356408262035, 'max_history_score_std': 0.040053650785990214, 'max_history_step': 'joint', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 1, 'features__selectkbest__k': 1}), 'normalizer': ('normalizer_RobustScaler', {'normalizer__quantile_range': (...), 'normalizer__with_centering': False, 'normalizer__with_scaling': True}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 6})}, 'score': 0.8858536427275083, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'gini', 'max_depth': 1, 'max_features': 1, 'max_leaf_nodes': None, 'min_samples_split': 5, 'n_estimators': 10}, 'config_hash': {'algorithm': '7d74a39aac2579264a402aef2b6fa7943c19f3d3', 'config': '53f44c0ad925c5c08c25d4fadf5e9ee9d7c181cd', 'pipeline': '6eff5ef31d7d1d534db31913bb67529c8a24c42e'}, 'duration': 2.7847659587860107, 'iteration': 14, 'loss': 0.14061986863711007, 'max_history_score': 0.9456356408262035, 'max_history_score_std': 0.040053650785990214, 'max_history_step': 'joint', 'pipeline': {'features': ('features_PCA', {'features__n_components': 1}), 'normalizer': ('normalizer_RobustScaler', {'normalizer__quantile_range': (...), 'normalizer__with_centering': True, 'normalizer__with_scaling': True}), 'rebalance': ('rebalance_CondensedNearestNeighbour', {'rebalance__n_neighbors': 3})}, 'score': 0.8593801313628899, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'entropy', 'max_depth': 3, 'max_features': None, 'max_leaf_nodes': 5, 'min_samples_split': 2, 'n_estimators': 100}, 'config_hash': {'algorithm': 'c62d7c671832e4414b6b2d7c36cba5ddc83a0ed0', 'config': '5faee50671eaa0ac586722bff234e36a857e662d', 'pipeline': '8b29a55de2add78c49114b9bbe5e800e5524c59d'}, 'duration': 2.3916029930114746, 'iteration': 15, 'loss': 0.08770093336790252, 'max_history_score': 0.9456356408262035, 'max_history_score_std': 0.040053650785990214, 'max_history_step': 'joint', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 3, 'features__selectkbest__k': 4}), 'normalizer': ('normalizer_RobustScaler', {'normalizer__quantile_range': (...), 'normalizer__with_centering': True, 'normalizer__with_scaling': True}), 'rebalance': ('rebalance_NoneType', {})}, 'score': 0.9122990666320975, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': None, 'max_features': 1, 'max_leaf_nodes': 5, 'min_samples_split': 5, 'n_estimators': 10}, 'config_hash': {'algorithm': '290772bfb9b8ed15c48a72829e822fb0a07481d6', 'config': '9a04f25d8eb3db5b2f831abd341a6d384c73a957', 'pipeline': '1ce34b7894ef342571d974bb19e8ec821a512c6b'}, 'duration': 1.4364500045776367, 'iteration': 16, 'loss': 0.08948880822746508, 'max_history_score': 0.9456356408262035, 'max_history_score_std': 0.040053650785990214, 'max_history_step': 'joint', 'pipeline': {'features': ('features_PCA', {'features__n_components': 1}), 'normalizer': ('normalizer_PowerTransformer', {}), 'rebalance': ('rebalance_NoneType', {})}, 'score': 0.9105111917725349, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': 2, 'max_features': 3, 'max_leaf_nodes': 3, 'min_samples_split': 3, 'n_estimators': 100}, 'config_hash': {'algorithm': '7dab6d47f897c2961d3402eff844aff16a7d142a', 'config': '4dbfa2688b239be9f372d3e80223960ba9a1fbdd', 'pipeline': 'cdef51702798fa49f11c11d80baf3ab43d5358fc'}, 'duration': 0.9830451011657715, 'iteration': 17, 'loss': 1.0, 'max_history_score': 0.9456356408262035, 'max_history_score_std': 0.040053650785990214, 'max_history_step': 'joint', 'pipeline': {'features': ('features_SelectKBest', {'features__k': 2}), 'normalizer': ('normalizer_PowerTransformer', {}), 'rebalance': ('rebalance_NearMiss', {'rebalance__n_neighbors': 1})}, 'score': 0.0, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'entropy', 'max_depth': None, 'max_features': 3, 'max_leaf_nodes': None, 'min_samples_split': 5, 'n_estimators': 10}, 'config_hash': {'algorithm': 'def83e48be05ef92a37e1a90585820f2f67ff42b', 'config': '95902552cb76e9798f0fa58782bd72bd1cc272d7', 'pipeline': '1775187bf23f94f4fd0cc1e5c1ef665210edded5'}, 'duration': 2.0033559799194336, 'iteration': 18, 'loss': 0.04922327370149515, 'max_history_score': 0.9507767262985048, 'max_history_score_std': 0.028328108925705902, 'max_history_step': 'joint', 'pipeline': {'features': ('features_PCA', {'features__n_components': 4}), 'normalizer': ('normalizer_StandardScaler', {'normalizer__with_mean': True, 'normalizer__with_std': True}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 5})}, 'score': 0.9507767262985048, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'gini', 'max_depth': 1, 'max_features': 3, 'max_leaf_nodes': None, 'min_samples_split': 2, 'n_estimators': 50}, 'config_hash': {'algorithm': '4e9e3275f817df75115d9d7e3366980fc1b4cf13', 'config': '7770b19007b40bf13005d52eb81f87bc401f15b4', 'pipeline': 'c4dd111513ea35f97dd3aec3e8e7f6268ce035da'}, 'duration': 0.9069631099700928, 'iteration': 19, 'loss': 1.0, 'max_history_score': 0.9507767262985048, 'max_history_score_std': 0.028328108925705902, 'max_history_step': 'joint', 'pipeline': {'features': ('features_PCA', {'features__n_components': 2}), 'normalizer': ('normalizer_RobustScaler', {'normalizer__quantile_range': (...), 'normalizer__with_centering': False, 'normalizer__with_scaling': True}), 'rebalance': ('rebalance_NearMiss', {'rebalance__n_neighbors': 2})}, 'score': 0.0, ...}, ...], 'history_hash': ['51144ca42f9ea5ab2d8d58606e3b3e4d89c6d7b3', '9e54ffcb6a727de032a0a2cd45c5cc37cc150756', 'e5241eee9ddf3f4ee29a4711f5bcc92a4d24cd09', '18ee4d3d1627472ec190326308d8755371a6dc62', '2af4f82b045c0c48ecb89d42728d1039fbff8878', '17b2a1e5814f3e933137158708a5b6e9b2475495', 'fa020a592ec5ac234f9f91aac28abc2cd1ec9d33', '0da4498002d6f452c59bb61756abb3ded841e786', '344e4756fb1bec455d6af51d3727e33b0d27725f', '4a538fdcf8e07f90e92a421c0d5c479d651629c7', 'c1609e71f1ce8486335adc70bb69a955580ba2c8', 'abe36f188644e53e56ed3224236fa157107ed3b2', '76aa002c3c9d4d9722466c60daf5119c18a41d2a', 'f56a7a9e43a0a699e992dc1262e550b8b7c88538', '53f44c0ad925c5c08c25d4fadf5e9ee9d7c181cd', '5faee50671eaa0ac586722bff234e36a857e662d', '9a04f25d8eb3db5b2f831abd341a6d384c73a957', '4dbfa2688b239be9f372d3e80223960ba9a1fbdd', '95902552cb76e9798f0fa58782bd72bd1cc272d7', '7770b19007b40bf13005d52eb81f87bc401f15b4', ...], 'history_index': {'0212926e8a56cc42ae0a654a90c2a3ee92464265': 91, '0da4498002d6f452c59bb61756abb3ded841e786': 7, '0f77a69b0a8d34861caf915a51dc588ff8d4efac': 61, '127553d555ed39231b8da3a1ce42d3902e30919b': 59, '157ad7645c10c929b685db679adc21b38e285fff': 93, '17b2a1e5814f3e933137158708a5b6e9b2475495': 5, '18ee4d3d1627472ec190326308d8755371a6dc62': 3, '1b2267555a9226d7eb4df3c63dd12506da370f4d': 56, '278dd514f71ea681b3e2238dde3b16c35f1697db': 90, '2873878df7d4db8b415ff446bec08003e0c7488d': 92, ...}, 'iteration': 99, 'max_history_score': 0.9525008642295394, 'max_history_score_std': 0.02225295065716913, 'max_history_step': 'joint'}, config={'algorithm': 'RandomForest', 'seed': 42, 'time': 300}, step='joint')
     45                 y,
     46                 cv=10,
     47                 n_jobs=-1,
     48                 return_estimator=False,
     49                 return_train_score=False,
---> 50                 verbose=0)
     51         score = np.mean(scores['test_score'])
     52         std = np.std(scores['test_score'])
     53         status = STATUS_OK
     54     except Exception as e:

...........................................................................
/home/aquemy/.local/lib/python2.7/site-packages/sklearn/model_selection/_validation.py in cross_validate(estimator=Pipeline(memory=None,
     steps=[('rebalance', ...e=42,
            verbose=0, warm_start=False))]), X=array([[1.799e+01, 1.038e+01, 1.228e+02, ..., 2...., ..., 0.000e+00, 2.871e-01,
        7.039e-02]]), y=array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,... 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1]), groups=None, scoring=None, cv=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1, verbose=0, fit_params=None, pre_dispatch='2*n_jobs', return_train_score=False, return_estimator=False, error_score='raise-deprecating')
    235         delayed(_fit_and_score)(
    236             clone(estimator), X, y, scorers, train, test, verbose, None,
    237             fit_params, return_train_score=return_train_score,
    238             return_times=True, return_estimator=return_estimator,
    239             error_score=error_score)
--> 240         for train, test in cv.split(X, y, groups))
        cv.split = <bound method StratifiedKFold.split of Stratifie...d(n_splits=10, random_state=None, shuffle=False)>
        X = array([[1.799e+01, 1.038e+01, 1.228e+02, ..., 2...., ..., 0.000e+00, 2.871e-01,
        7.039e-02]])
        y = array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,... 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1])
        groups = None
    241 
    242     zipped_scores = list(zip(*scores))
    243     if return_train_score:
    244         train_scores = zipped_scores.pop(0)

...........................................................................
/home/aquemy/.local/lib/python2.7/site-packages/sklearn/externals/joblib/parallel.py in __call__(self=Parallel(n_jobs=-1), iterable=<generator object <genexpr>>)
    925                 # No need to wait for async callbacks to trigger to
    926                 # consumption.
    927                 self._iterating = False
    928 
    929             with self._backend.retrieval_context():
--> 930                 self.retrieve()
        self.retrieve = <bound method Parallel.retrieve of Parallel(n_jobs=-1)>
    931             # Make sure that we get a last message telling us we are done
    932             elapsed_time = time.time() - self._start_time
    933             self._print('Done %3i out of %3i | elapsed: %s finished',
    934                         (len(self._output), len(self._output),

---------------------------------------------------------------------------
Joblib worker traceback:
---------------------------------------------------------------------------
ValueError                                         Mon Jun 17 13:34:05 2019
PID: 26398                                  Python 2.7.15+: /usr/bin/python
...........................................................................
/home/aquemy/.local/lib/python2.7/site-packages/sklearn/externals/joblib/parallel.py in __call__(self=<sklearn.externals.joblib.parallel.BatchedCalls object>)
    220     def __call__(self):
    221         # Set the default nested backend to self._backend but do not set the
    222         # change the default number of processes to -1
    223         with parallel_backend(self._backend, n_jobs=self._n_jobs):
    224             return [func(*args, **kwargs)
--> 225                     for func, args, kwargs in self.items]
        func = <function _fit_and_score>
        args = (Pipeline(memory=None,
     steps=[('rebalance', ...e=42,
            verbose=0, warm_start=False))]), array([[1.799e+01, 1.038e+01, 1.228e+02, ..., 2...., ..., 0.000e+00, 2.871e-01,
        7.039e-02]]), array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,... 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1]), {'score': <function _passthrough_scorer>}, array([ 25,  26,  27,  28,  29,  30,  31,  32,  ..., 561, 562, 563, 564,
       565, 566, 567, 568]), array([  0,   1,   2,   3,   4,   5,   6,   7,  ...,  89,  90,
        92,  93,  96,  97,  98, 101]), 0, None, None)
        kwargs = {'error_score': 'raise-deprecating', 'return_estimator': False, 'return_times': True, 'return_train_score': False}
        self.items = [(<function _fit_and_score>, (Pipeline(memory=None,
     steps=[('rebalance', ...e=42,
            verbose=0, warm_start=False))]), array([[1.799e+01, 1.038e+01, 1.228e+02, ..., 2...., ..., 0.000e+00, 2.871e-01,
        7.039e-02]]), array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,... 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1]), {'score': <function _passthrough_scorer>}, array([ 25,  26,  27,  28,  29,  30,  31,  32,  ..., 561, 562, 563, 564,
       565, 566, 567, 568]), array([  0,   1,   2,   3,   4,   5,   6,   7,  ...,  89,  90,
        92,  93,  96,  97,  98, 101]), 0, None, None), {'error_score': 'raise-deprecating', 'return_estimator': False, 'return_times': True, 'return_train_score': False})]
    226 
    227     def __len__(self):
    228         return self._size
    229 

...........................................................................
/home/aquemy/.local/lib/python2.7/site-packages/sklearn/model_selection/_validation.py in _fit_and_score(estimator=Pipeline(memory=None,
     steps=[('rebalance', ...e=42,
            verbose=0, warm_start=False))]), X=array([[1.799e+01, 1.038e+01, 1.228e+02, ..., 2...., ..., 0.000e+00, 2.871e-01,
        7.039e-02]]), y=array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,... 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1]), scorer={'score': <function _passthrough_scorer>}, train=array([ 25,  26,  27,  28,  29,  30,  31,  32,  ..., 561, 562, 563, 564,
       565, 566, 567, 568]), test=array([  0,   1,   2,   3,   4,   5,   6,   7,  ...,  89,  90,
        92,  93,  96,  97,  98, 101]), verbose=0, parameters=None, fit_params={}, return_train_score=False, return_parameters=False, return_n_test_samples=False, return_times=True, return_estimator=False, error_score='raise-deprecating')
    523 
    524     try:
    525         if y_train is None:
    526             estimator.fit(X_train, **fit_params)
    527         else:
--> 528             estimator.fit(X_train, y_train, **fit_params)
        estimator.fit = <bound method Pipeline.fit of Pipeline(memory=No...=42,
            verbose=0, warm_start=False))])>
        X_train = array([[1.714e+01, 1.640e+01, 1.160e+02, ..., 2...., ..., 0.000e+00, 2.871e-01,
        7.039e-02]])
        y_train = array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...1, 1, 1, 1, 1, 1, 1, 0, 0,
       0, 0, 0, 0, 1])
        fit_params = {}
    529 
    530     except Exception as e:
    531         # Note fit time as time until error
    532         fit_time = time.time() - start_time

...........................................................................
/usr/local/lib/python2.7/dist-packages/imblearn/pipeline.py in fit(self=Pipeline(memory=None,
     steps=[('rebalance', ...e=42,
            verbose=0, warm_start=False))]), X=array([[1.714e+01, 1.640e+01, 1.160e+02, ..., 2...., ..., 0.000e+00, 2.871e-01,
        7.039e-02]]), y=array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...1, 1, 1, 1, 1, 1, 1, 0, 0,
       0, 0, 0, 0, 1]), **fit_params={})
    234             This estimator
    235 
    236         """
    237         Xt, yt, fit_params = self._fit(X, y, **fit_params)
    238         if self._final_estimator is not None:
--> 239             self._final_estimator.fit(Xt, yt, **fit_params)
        self._final_estimator.fit = <bound method RandomForestClassifier.fit of Rand...ate=42,
            verbose=0, warm_start=False)>
        Xt = array([[ 6.02345109],
       [ 3.05064312],
    ...99],
       [ 2.28565482],
       [ 6.67010017]])
        yt = array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
       0, 0, 0, 0])
        fit_params = {}
    240         return self
    241 
    242     def fit_transform(self, X, y=None, **fit_params):
    243         """Fit the model and transform with the final estimator

...........................................................................
/home/aquemy/.local/lib/python2.7/site-packages/sklearn/ensemble/forest.py in fit(self=RandomForestClassifier(bootstrap=False, class_we...tate=42,
            verbose=0, warm_start=False), X=array([[ 6.0234513 ],
       [ 3.0506432 ],
    ....2856548 ],
       [ 6.6701    ]], dtype=float32), y=array([[0.],
       [0.],
       [0.],
       [0...    [0.],
       [0.],
       [0.],
       [0.]]), sample_weight=None)
    328             trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,
    329                              **_joblib_parallel_args(prefer='threads'))(
    330                 delayed(_parallel_build_trees)(
    331                     t, self, X, y, sample_weight, i, len(trees),
    332                     verbose=self.verbose, class_weight=self.class_weight)
--> 333                 for i, t in enumerate(trees))
        i = 9
    334 
    335             # Collect newly grown trees
    336             self.estimators_.extend(trees)
    337 

...........................................................................
/home/aquemy/.local/lib/python2.7/site-packages/sklearn/externals/joblib/parallel.py in __call__(self=Parallel(n_jobs=1), iterable=<generator object <genexpr>>)
    912             # self._original_iterator is None, then this means either
    913             # that pre_dispatch == "all", n_jobs == 1 or that the first batch
    914             # was very quick and its callback already dispatched all the
    915             # remaining jobs.
    916             self._iterating = False
--> 917             if self.dispatch_one_batch(iterator):
        self.dispatch_one_batch = <bound method Parallel.dispatch_one_batch of Parallel(n_jobs=1)>
        iterator = <generator object <genexpr>>
    918                 self._iterating = self._original_iterator is not None
    919 
    920             while self.dispatch_one_batch(iterator):
    921                 pass

...........................................................................
/home/aquemy/.local/lib/python2.7/site-packages/sklearn/externals/joblib/parallel.py in dispatch_one_batch(self=Parallel(n_jobs=1), iterator=<generator object <genexpr>>)
    754                                  self._pickle_cache)
    755             if len(tasks) == 0:
    756                 # No more tasks available in the iterator: tell caller to stop.
    757                 return False
    758             else:
--> 759                 self._dispatch(tasks)
        self._dispatch = <bound method Parallel._dispatch of Parallel(n_jobs=1)>
        tasks = <sklearn.externals.joblib.parallel.BatchedCalls object>
    760                 return True
    761 
    762     def _print(self, msg, msg_args):
    763         """Display the message on stout or stderr depending on verbosity"""

...........................................................................
/home/aquemy/.local/lib/python2.7/site-packages/sklearn/externals/joblib/parallel.py in _dispatch(self=Parallel(n_jobs=1), batch=<sklearn.externals.joblib.parallel.BatchedCalls object>)
    711 
    712         dispatch_timestamp = time.time()
    713         cb = BatchCompletionCallBack(dispatch_timestamp, len(batch), self)
    714         with self._lock:
    715             job_idx = len(self._jobs)
--> 716             job = self._backend.apply_async(batch, callback=cb)
        job = undefined
        self._backend.apply_async = <bound method SequentialBackend.apply_async of <...lib._parallel_backends.SequentialBackend object>>
        batch = <sklearn.externals.joblib.parallel.BatchedCalls object>
        cb = <sklearn.externals.joblib.parallel.BatchCompletionCallBack object>
    717             # A job can complete so quickly than its callback is
    718             # called before we get here, causing self._jobs to
    719             # grow. To ensure correct results ordering, .insert is
    720             # used (rather than .append) in the following line

...........................................................................
/home/aquemy/.local/lib/python2.7/site-packages/sklearn/externals/joblib/_parallel_backends.py in apply_async(self=<sklearn.externals.joblib._parallel_backends.SequentialBackend object>, func=<sklearn.externals.joblib.parallel.BatchedCalls object>, callback=<sklearn.externals.joblib.parallel.BatchCompletionCallBack object>)
    177             raise ValueError('n_jobs == 0 in Parallel has no meaning')
    178         return 1
    179 
    180     def apply_async(self, func, callback=None):
    181         """Schedule a func to be run"""
--> 182         result = ImmediateResult(func)
        result = undefined
        func = <sklearn.externals.joblib.parallel.BatchedCalls object>
    183         if callback:
    184             callback(result)
    185         return result
    186 

...........................................................................
/home/aquemy/.local/lib/python2.7/site-packages/sklearn/externals/joblib/_parallel_backends.py in __init__(self=<sklearn.externals.joblib._parallel_backends.ImmediateResult object>, batch=<sklearn.externals.joblib.parallel.BatchedCalls object>)
    544 
    545 class ImmediateResult(object):
    546     def __init__(self, batch):
    547         # Don't delay the application, to avoid keeping the input
    548         # arguments in memory
--> 549         self.results = batch()
        self.results = undefined
        batch = <sklearn.externals.joblib.parallel.BatchedCalls object>
    550 
    551     def get(self):
    552         return self.results
    553 

...........................................................................
/home/aquemy/.local/lib/python2.7/site-packages/sklearn/externals/joblib/parallel.py in __call__(self=<sklearn.externals.joblib.parallel.BatchedCalls object>)
    220     def __call__(self):
    221         # Set the default nested backend to self._backend but do not set the
    222         # change the default number of processes to -1
    223         with parallel_backend(self._backend, n_jobs=self._n_jobs):
    224             return [func(*args, **kwargs)
--> 225                     for func, args, kwargs in self.items]
        func = <function _parallel_build_trees>
        args = (DecisionTreeClassifier(class_weight=None, criter...=False, random_state=1608637542, splitter='best'), RandomForestClassifier(bootstrap=False, class_we...tate=42,
            verbose=0, warm_start=False), array([[ 6.0234513 ],
       [ 3.0506432 ],
    ....2856548 ],
       [ 6.6701    ]], dtype=float32), array([[0.],
       [0.],
       [0.],
       [0...    [0.],
       [0.],
       [0.],
       [0.]]), None, 0, 10)
        kwargs = {'class_weight': None, 'verbose': 0}
        self.items = [(<function _parallel_build_trees>, (DecisionTreeClassifier(class_weight=None, criter...=False, random_state=1608637542, splitter='best'), RandomForestClassifier(bootstrap=False, class_we...tate=42,
            verbose=0, warm_start=False), array([[ 6.0234513 ],
       [ 3.0506432 ],
    ....2856548 ],
       [ 6.6701    ]], dtype=float32), array([[0.],
       [0.],
       [0.],
       [0...    [0.],
       [0.],
       [0.],
       [0.]]), None, 0, 10), {'class_weight': None, 'verbose': 0})]
    226 
    227     def __len__(self):
    228         return self._size
    229 

...........................................................................
/home/aquemy/.local/lib/python2.7/site-packages/sklearn/ensemble/forest.py in _parallel_build_trees(tree=DecisionTreeClassifier(class_weight=None, criter...=False, random_state=1608637542, splitter='best'), forest=RandomForestClassifier(bootstrap=False, class_we...tate=42,
            verbose=0, warm_start=False), X=array([[ 6.0234513 ],
       [ 3.0506432 ],
    ....2856548 ],
       [ 6.6701    ]], dtype=float32), y=array([[0.],
       [0.],
       [0.],
       [0...    [0.],
       [0.],
       [0.],
       [0.]]), sample_weight=None, tree_idx=0, n_trees=10, verbose=0, class_weight=None)
    116         elif class_weight == 'balanced_subsample':
    117             curr_sample_weight *= compute_sample_weight('balanced', y, indices)
    118 
    119         tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)
    120     else:
--> 121         tree.fit(X, y, sample_weight=sample_weight, check_input=False)
        tree.fit = <bound method DecisionTreeClassifier.fit of Deci...False, random_state=1608637542, splitter='best')>
        X = array([[ 6.0234513 ],
       [ 3.0506432 ],
    ....2856548 ],
       [ 6.6701    ]], dtype=float32)
        y = array([[0.],
       [0.],
       [0.],
       [0...    [0.],
       [0.],
       [0.],
       [0.]])
        sample_weight = None
    122 
    123     return tree
    124 
    125 

...........................................................................
/home/aquemy/.local/lib/python2.7/site-packages/sklearn/tree/tree.py in fit(self=DecisionTreeClassifier(class_weight=None, criter...=False, random_state=1608637542, splitter='best'), X=array([[ 6.0234513 ],
       [ 3.0506432 ],
    ....2856548 ],
       [ 6.6701    ]], dtype=float32), y=array([[0.],
       [0.],
       [0.],
       [0...    [0.],
       [0.],
       [0.],
       [0.]]), sample_weight=None, check_input=False, X_idx_sorted=None)
    796 
    797         super(DecisionTreeClassifier, self).fit(
    798             X, y,
    799             sample_weight=sample_weight,
    800             check_input=check_input,
--> 801             X_idx_sorted=X_idx_sorted)
        X_idx_sorted = None
    802         return self
    803 
    804     def predict_proba(self, X, check_input=True):
    805         """Predict class probabilities of the input samples X.

...........................................................................
/home/aquemy/.local/lib/python2.7/site-packages/sklearn/tree/tree.py in fit(self=DecisionTreeClassifier(class_weight=None, criter...=False, random_state=1608637542, splitter='best'), X=array([[ 6.0234513 ],
       [ 3.0506432 ],
    ....2856548 ],
       [ 6.6701    ]], dtype=float32), y=array([[0.],
       [0.],
       [0.],
       [0...    [0.],
       [0.],
       [0.],
       [0.]]), sample_weight=None, check_input=False, X_idx_sorted=None)
    237         if not 0 <= self.min_weight_fraction_leaf <= 0.5:
    238             raise ValueError("min_weight_fraction_leaf must in [0, 0.5]")
    239         if max_depth <= 0:
    240             raise ValueError("max_depth must be greater than zero. ")
    241         if not (0 < max_features <= self.n_features_):
--> 242             raise ValueError("max_features must be in (0, n_features]")
    243         if not isinstance(max_leaf_nodes, (numbers.Integral, np.integer)):
    244             raise ValueError("max_leaf_nodes must be integral number but was "
    245                              "%r" % max_leaf_nodes)
    246         if -1 < max_leaf_nodes < 2:

ValueError: max_features must be in (0, n_features]
___________________________________________________________________________
Best score: 0.95250086423 (0.0222529506572) [J] | Score: 0.0 (0.0) [J]
Best score: 0.95250086423 (0.0222529506572) [J] | Score: 0.940279578256 (0.0113511631643) [J]
Best score: 0.95250086423 (0.0222529506572) [J] | Score: 0.910388039063 (0.0286925068532) [J]
Best score: 0.95250086423 (0.0222529506572) [J] | Score: 0.926333074064 (0.0412585531496) [J]
Best score: 0.95250086423 (0.0222529506572) [J] | Score: 0.745908953418 (0.196268587991) [J]
JoblibValueError
___________________________________________________________________________
...........................................................................
/home/aquemy/dev/dp_hyperparameters/extension/main.py in <module>()
     27 
     28     serializer.serialize_results(scenario, policy)
     29 
     30 if __name__ == "__main__":
     31     args = cli.parse_args()
---> 32     main(args)

...........................................................................
/home/aquemy/dev/dp_hyperparameters/extension/main.py in main(args=Namespace(customize=[(['control', 'seed'], '42')...='./scenarios/rf_breast_joint.yaml', verbosity=0))
     21         test_size=0.4, 
     22         random_state=scenario['control']['seed']
     23     )
     24 
     25     policy = policies.initiate(scenario['setup']['policy'], config)
---> 26     policy.run(X,y)
        policy.run = <bound method Joint.run of <experiment.policies.joint.Joint object>>
        X = array([[1.799e+01, 1.038e+01, 1.228e+02, ..., 2...., ..., 0.000e+00, 2.871e-01,
        7.039e-02]])
        y = array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,... 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1])
     27 
     28     serializer.serialize_results(scenario, policy)
     29 
     30 if __name__ == "__main__":

...........................................................................
/home/aquemy/dev/dp_hyperparameters/extension/experiment/policies/joint.py in run(self=<experiment.policies.joint.Joint object>, X=array([[1.799e+01, 1.038e+01, 1.228e+02, ..., 2...., ..., 0.000e+00, 2.871e-01,
        7.039e-02]]), y=array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,... 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1]))
     32             algo=tpe.suggest, 
     33             max_evals=None,
     34             max_time=self.config['time'],     
     35             trials=trials,
     36             show_progressbar=False,
---> 37             verbose=0
     38         )
     39 
     40         best_config = self.context['best_config']
     41         super(Joint, self).display_step_results(best_config)

...........................................................................
/home/aquemy/dev/dp_hyperparameters/extension/hyperopt/fmin.py in fmin(fn=<functools.partial object>, space={'algorithm': {'bootstrap': <hyperopt.pyll.base.Apply object>, 'criterion': <hyperopt.pyll.base.Apply object>, 'max_depth': <hyperopt.pyll.base.Apply object>, 'max_features': <hyperopt.pyll.base.Apply object>, 'max_leaf_nodes': <hyperopt.pyll.base.Apply object>, 'min_samples_split': <hyperopt.pyll.base.Apply object>, 'n_estimators': <hyperopt.pyll.base.Apply object>}, 'pipeline': {'features': <hyperopt.pyll.base.Apply object>, 'normalizer': <hyperopt.pyll.base.Apply object>, 'rebalance': <hyperopt.pyll.base.Apply object>}}, algo=<function suggest>, max_evals=9223372036854775807, max_time=300, trials=<hyperopt.base.Trials object>, rstate=<mtrand.RandomState object>, allow_trials_fmin=True, pass_expr_memo_ctrl=None, catch_eval_exceptions=False, verbose=0, return_argmin=True, points_to_evaluate=None, max_queue_len=1, show_progressbar=False)
    406             pass_expr_memo_ctrl=pass_expr_memo_ctrl,
    407             verbose=verbose,
    408             catch_eval_exceptions=catch_eval_exceptions,
    409             return_argmin=return_argmin,
    410             show_progressbar=show_progressbar,
--> 411             max_time=max_time
        max_time = 300
    412         )
    413 
    414     if trials is None:
    415         if points_to_evaluate is None:

...........................................................................
/home/aquemy/dev/dp_hyperparameters/extension/hyperopt/base.py in fmin(self=<hyperopt.base.Trials object>, fn=<functools.partial object>, space={'algorithm': {'bootstrap': <hyperopt.pyll.base.Apply object>, 'criterion': <hyperopt.pyll.base.Apply object>, 'max_depth': <hyperopt.pyll.base.Apply object>, 'max_features': <hyperopt.pyll.base.Apply object>, 'max_leaf_nodes': <hyperopt.pyll.base.Apply object>, 'min_samples_split': <hyperopt.pyll.base.Apply object>, 'n_estimators': <hyperopt.pyll.base.Apply object>}, 'pipeline': {'features': <hyperopt.pyll.base.Apply object>, 'normalizer': <hyperopt.pyll.base.Apply object>, 'rebalance': <hyperopt.pyll.base.Apply object>}}, algo=<function suggest>, max_evals=9223372036854775807, max_time=300, rstate=<mtrand.RandomState object>, verbose=0, pass_expr_memo_ctrl=None, catch_eval_exceptions=False, return_argmin=True, show_progressbar=False)
    636             verbose=verbose,
    637             allow_trials_fmin=False,  # -- prevent recursion
    638             pass_expr_memo_ctrl=pass_expr_memo_ctrl,
    639             catch_eval_exceptions=catch_eval_exceptions,
    640             return_argmin=return_argmin,
--> 641             show_progressbar=show_progressbar)
        show_progressbar = False
    642 
    643 
    644 def trials_from_docs(docs, validate=True, **kwargs):
    645     """Construct a Trials base class instance from a list of trials documents

...........................................................................
/home/aquemy/dev/dp_hyperparameters/extension/hyperopt/fmin.py in fmin(fn=<functools.partial object>, space={'algorithm': {'bootstrap': <hyperopt.pyll.base.Apply object>, 'criterion': <hyperopt.pyll.base.Apply object>, 'max_depth': <hyperopt.pyll.base.Apply object>, 'max_features': <hyperopt.pyll.base.Apply object>, 'max_leaf_nodes': <hyperopt.pyll.base.Apply object>, 'min_samples_split': <hyperopt.pyll.base.Apply object>, 'n_estimators': <hyperopt.pyll.base.Apply object>}, 'pipeline': {'features': <hyperopt.pyll.base.Apply object>, 'normalizer': <hyperopt.pyll.base.Apply object>, 'rebalance': <hyperopt.pyll.base.Apply object>}}, algo=<function suggest>, max_evals=9223372036854775807, max_time=300, trials=<hyperopt.base.Trials object>, rstate=<mtrand.RandomState object>, allow_trials_fmin=False, pass_expr_memo_ctrl=None, catch_eval_exceptions=False, verbose=0, return_argmin=True, points_to_evaluate=None, max_queue_len=1, show_progressbar=False)
    426                     verbose=verbose,
    427                     max_queue_len=max_queue_len,
    428                     show_progressbar=show_progressbar,
    429                     max_time=max_time)
    430     rval.catch_eval_exceptions = catch_eval_exceptions
--> 431     rval.exhaust()
        rval.exhaust = <bound method FMinIter.exhaust of <hyperopt.fmin.FMinIter object>>
    432     if return_argmin:
    433         return trials.argmin
    434     elif len(trials) > 0:
    435         # Only if there are some succesfull trail runs, return the best point in the evaluation space

...........................................................................
/home/aquemy/dev/dp_hyperparameters/extension/hyperopt/fmin.py in exhaust(self=<hyperopt.fmin.FMinIter object>)
    273             raise StopIteration()
    274         return self.trials
    275 
    276     def exhaust(self):
    277         n_done = len(self.trials)
--> 278         self.run(self.max_evals - n_done, block_until_done=self.asynchronous)
        self.run = <bound method FMinIter.run of <hyperopt.fmin.FMinIter object>>
        self.max_evals = 9223372036854775807
        n_done = 0
        self.asynchronous = False
    279         self.trials.refresh()
    280         return self
    281 
    282 

...........................................................................
/home/aquemy/dev/dp_hyperparameters/extension/hyperopt/fmin.py in run(self=<hyperopt.fmin.FMinIter object>, N=9223372036854775807, block_until_done=False)
    232                     if self.asynchronous:
    233                         # -- wait for workers to fill in the trials
    234                         time.sleep(self.poll_interval_secs)
    235                     else:
    236                         # -- loop over trials and do the jobs directly
--> 237                         self.serial_evaluate()
        self.serial_evaluate = <bound method FMinIter.serial_evaluate of <hyperopt.fmin.FMinIter object>>
    238                     try:
    239                         res = [d['result']['loss'] for d in
    240                                          self.trials.trials if
    241                                          d['result']['status'] == 'ok']

...........................................................................
/home/aquemy/dev/dp_hyperparameters/extension/hyperopt/fmin.py in serial_evaluate(self=<hyperopt.fmin.FMinIter object>, N=-1)
    138                 trial['book_time'] = now
    139                 trial['refresh_time'] = now
    140                 spec = base.spec_from_misc(trial['misc'])
    141                 ctrl = base.Ctrl(self.trials, current_trial=trial)
    142                 try:
--> 143                     result = self.domain.evaluate(spec, ctrl)
        result = undefined
        self.domain.evaluate = <bound method Domain.evaluate of <hyperopt.base.Domain object>>
        spec = {'bootstrap': 1, 'criterion': 1, 'features': 1, 'features_PCA_features__n_components': 1, 'max_depth': 3, 'max_features': 2, 'max_leaf_nodes': 3, 'min_samples_split': 2, 'n_estimators': 4, 'normalizer': 1, ...}
        ctrl = <hyperopt.base.Ctrl object>
    144                 except Exception as e:
    145                     logger.info('job exception: %s' % str(e))
    146                     trial['state'] = base.JOB_STATE_ERROR
    147                     trial['misc']['error'] = (str(type(e)), str(e))

...........................................................................
/home/aquemy/dev/dp_hyperparameters/extension/hyperopt/base.py in evaluate(self=<hyperopt.base.Domain object>, config={'bootstrap': 1, 'criterion': 1, 'features': 1, 'features_PCA_features__n_components': 1, 'max_depth': 3, 'max_features': 2, 'max_leaf_nodes': 3, 'min_samples_split': 2, 'n_estimators': 4, 'normalizer': 1, ...}, ctrl=<hyperopt.base.Ctrl object>, attach_attachments=True)
    841             #    or the normal Python part (self.fn)
    842             pyll_rval = pyll.rec_eval(
    843                 self.expr,
    844                 memo=memo,
    845                 print_node_on_error=self.rec_eval_print_node_on_error)
--> 846             rval = self.fn(pyll_rval)
        rval = undefined
        self.fn = <functools.partial object>
        pyll_rval = {'algorithm': {'bootstrap': False, 'criterion': 'entropy', 'max_depth': 4, 'max_features': 3, 'max_leaf_nodes': None, 'min_samples_split': 5, 'n_estimators': 100}, 'pipeline': {'features': ('features_PCA', {'features__n_components': 2}), 'normalizer': ('normalizer_StandardScaler', {'normalizer__with_mean': True, 'normalizer__with_std': False}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 7})}}
    847 
    848         if isinstance(rval, (float, int, np.number)):
    849             dict_rval = {'loss': float(rval), 'status': STATUS_OK}
    850         else:

...........................................................................
/home/aquemy/dev/dp_hyperparameters/extension/experiment/objective.py in objective_joint(wconfig={'algorithm': {'bootstrap': False, 'criterion': 'entropy', 'max_depth': 4, 'max_features': 3, 'max_leaf_nodes': None, 'min_samples_split': 5, 'n_estimators': 100}, 'pipeline': {'features': ('features_PCA', {'features__n_components': 2}), 'normalizer': ('normalizer_StandardScaler', {'normalizer__with_mean': True, 'normalizer__with_std': False}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 7})}}, algorithm='RandomForest', X=array([[1.799e+01, 1.038e+01, 1.228e+02, ..., 2...., ..., 0.000e+00, 2.871e-01,
        7.039e-02]]), y=array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,... 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1]), context={'baseline_score': 0.9545944602886527, 'baseline_score_std': 0.03716322883281839, 'best_config': {'algorithm': {'bootstrap': False, 'criterion': 'entropy', 'max_depth': None, 'max_features': 2, 'max_leaf_nodes': None, 'min_samples_split': 5, 'n_estimators': 10}, 'config_hash': {'algorithm': 'e7a772c2bc361aa61cf7eeb364a26dca2c9b89d6', 'config': 'afb67da069b544b0505b1e8c150edc7498ad37b4', 'pipeline': 'a43db4b4fc4c38610b7b5e484840d2e583089ff4'}, 'duration': 1.0073001384735107, 'iteration': 26, 'loss': 0.04749913577046061, 'max_history_score': 0.9525008642295394, 'max_history_score_std': 0.02225295065716913, 'max_history_step': 'joint', 'pipeline': {'features': ('features_PCA', {'features__n_components': 4}), 'normalizer': ('normalizer_StandardScaler', {'normalizer__with_mean': True, 'normalizer__with_std': False}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 7})}, 'score': 0.9525008642295394, ...}, 'history': [{'algorithm': {'bootstrap': True, 'criterion': 'entropy', 'max_depth': 4, 'max_features': 3, 'max_leaf_nodes': 3, 'min_samples_split': 2, 'n_estimators': 10}, 'config_hash': {'algorithm': '42527c4120073c2a488d1b8df28732f486d1578c', 'config': '51144ca42f9ea5ab2d8d58606e3b3e4d89c6d7b3', 'pipeline': '52f07bda29f9d3a95fabb87e591d0b2581ca8209'}, 'duration': 0.26703310012817383, 'iteration': 0, 'loss': 0.06655431682654922, 'max_history_score': 0.9334456831734508, 'max_history_score_std': 0.03819399139659311, 'max_history_step': 'joint', 'pipeline': {'features': ('features_NoneType', {}), 'normalizer': ('normalizer_RobustScaler', {'normalizer__quantile_range': (...), 'normalizer__with_centering': False, 'normalizer__with_scaling': False}), 'rebalance': ('rebalance_NearMiss', {'rebalance__n_neighbors': 1})}, 'score': 0.9334456831734508, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': None, 'max_features': 2, 'max_leaf_nodes': 3, 'min_samples_split': 2, 'n_estimators': 100}, 'config_hash': {'algorithm': '1b32258c630f07e01ab481ab925ab80aa757e482', 'config': '9e54ffcb6a727de032a0a2cd45c5cc37cc150756', 'pipeline': '37e72d4a97f5e784c9d3133e6379b91bfc3be803'}, 'duration': 1.3065669536590576, 'iteration': 1, 'loss': 0.05436435917379645, 'max_history_score': 0.9456356408262035, 'max_history_score_std': 0.040053650785990214, 'max_history_step': 'joint', 'pipeline': {'features': ('features_NoneType', {}), 'normalizer': ('normalizer_StandardScaler', {'normalizer__with_mean': True, 'normalizer__with_std': True}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 6})}, 'score': 0.9456356408262035, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'entropy', 'max_depth': 1, 'max_features': 1, 'max_leaf_nodes': 2, 'min_samples_split': 3, 'n_estimators': 25}, 'config_hash': {'algorithm': '68ab9059aa7ec74e0da87c81734b9664243b3eb4', 'config': 'e5241eee9ddf3f4ee29a4711f5bcc92a4d24cd09', 'pipeline': '62463de065924498cdcd2f2f1f7e68535cdb33a5'}, 'duration': 0.6592490673065186, 'iteration': 2, 'loss': 0.07695856019358727, 'max_history_score': 0.9456356408262035, 'max_history_score_std': 0.040053650785990214, 'max_history_step': 'joint', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 1, 'features__selectkbest__k': 2}), 'normalizer': ('normalizer_NoneType', {}), 'rebalance': ('rebalance_NoneType', {})}, 'score': 0.9230414398064127, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': 3, 'max_features': 2, 'max_leaf_nodes': 2, 'min_samples_split': 2, 'n_estimators': 25}, 'config_hash': {'algorithm': 'e3f1f7d7783557a38f40f0476369091edd87092b', 'config': '18ee4d3d1627472ec190326308d8755371a6dc62', 'pipeline': 'c6d1263e344ed8c71b2e6e4ba8e0db2fb6c777c0'}, 'duration': 0.879349946975708, 'iteration': 3, 'loss': 0.07535973554576114, 'max_history_score': 0.9456356408262035, 'max_history_score_std': 0.040053650785990214, 'max_history_step': 'joint', 'pipeline': {'features': ('features_NoneType', {}), 'normalizer': ('normalizer_RobustScaler', {'normalizer__quantile_range': (...), 'normalizer__with_centering': True, 'normalizer__with_scaling': True}), 'rebalance': ('rebalance_NearMiss', {'rebalance__n_neighbors': 2})}, 'score': 0.9246402644542389, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'gini', 'max_depth': 4, 'max_features': 2, 'max_leaf_nodes': 5, 'min_samples_split': 2, 'n_estimators': 50}, 'config_hash': {'algorithm': '47581af7253940f9647ad16d37347d34baf13e5f', 'config': '2af4f82b045c0c48ecb89d42728d1039fbff8878', 'pipeline': '2928b22ed834303cb7bac6e6608531eaddd7df67'}, 'duration': 4.372632026672363, 'iteration': 4, 'loss': 0.09121294615849984, 'max_history_score': 0.9456356408262035, 'max_history_score_std': 0.040053650785990214, 'max_history_step': 'joint', 'pipeline': {'features': ('features_NoneType', {}), 'normalizer': ('normalizer_MinMaxScaler', {}), 'rebalance': ('rebalance_CondensedNearestNeighbour', {'rebalance__n_neighbors': 2})}, 'score': 0.9087870538415002, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'entropy', 'max_depth': 2, 'max_features': 2, 'max_leaf_nodes': None, 'min_samples_split': 2, 'n_estimators': 10}, 'config_hash': {'algorithm': '0a85f98ca2d06103287f153633d88f7a0535e7e8', 'config': '17b2a1e5814f3e933137158708a5b6e9b2475495', 'pipeline': '95defa3bdd8357f11f872d3c280d50a6d8ee398d'}, 'duration': 2.625814914703369, 'iteration': 5, 'loss': 0.15471329185031535, 'max_history_score': 0.9456356408262035, 'max_history_score_std': 0.040053650785990214, 'max_history_step': 'joint', 'pipeline': {'features': ('features_SelectKBest', {'features__k': 2}), 'normalizer': ('normalizer_StandardScaler', {'normalizer__with_mean': False, 'normalizer__with_std': False}), 'rebalance': ('rebalance_CondensedNearestNeighbour', {'rebalance__n_neighbors': 1})}, 'score': 0.8452867081496847, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': 3, 'max_features': None, 'max_leaf_nodes': None, 'min_samples_split': 5, 'n_estimators': 75}, 'config_hash': {'algorithm': 'd7466a2c1d5cb3fa95029d73dc030f4c3c45a159', 'config': 'fa020a592ec5ac234f9f91aac28abc2cd1ec9d33', 'pipeline': '71e0d26f923d42cfe0e2fa748931ef2afe72ed86'}, 'duration': 3.62078595161438, 'iteration': 6, 'loss': 0.17066372828623277, 'max_history_score': 0.9456356408262035, 'max_history_score_std': 0.040053650785990214, 'max_history_step': 'joint', 'pipeline': {'features': ('features_SelectKBest', {'features__k': 1}), 'normalizer': ('normalizer_RobustScaler', {'normalizer__quantile_range': (...), 'normalizer__with_centering': True, 'normalizer__with_scaling': True}), 'rebalance': ('rebalance_CondensedNearestNeighbour', {'rebalance__n_neighbors': 1})}, 'score': 0.8293362717137672, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'entropy', 'max_depth': 3, 'max_features': 3, 'max_leaf_nodes': 5, 'min_samples_split': 5, 'n_estimators': 50}, 'config_hash': {'algorithm': '735caa9785596076014572a24050cde8dc338973', 'config': '0da4498002d6f452c59bb61756abb3ded841e786', 'pipeline': '51a53ea6ef5a2521ee65f76eb2da220ab7086513'}, 'duration': 0.6934049129486084, 'iteration': 7, 'loss': 0.06125875032408601, 'max_history_score': 0.9456356408262035, 'max_history_score_std': 0.040053650785990214, 'max_history_step': 'joint', 'pipeline': {'features': ('features_NoneType', {}), 'normalizer': ('normalizer_NoneType', {}), 'rebalance': ('rebalance_NearMiss', {'rebalance__n_neighbors': 3})}, 'score': 0.938741249675914, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': 4, 'max_features': 2, 'max_leaf_nodes': None, 'min_samples_split': 3, 'n_estimators': 75}, 'config_hash': {'algorithm': 'e71a1fe9515b6805f07914a61f2e7594be9e9afe', 'config': '344e4756fb1bec455d6af51d3727e33b0d27725f', 'pipeline': '248dad1d8b30a17a5de1d0bbdfe3e2acb7a1962b'}, 'duration': 1.3036692142486572, 'iteration': 8, 'loss': 0.06483125918243893, 'max_history_score': 0.9456356408262035, 'max_history_score_std': 0.040053650785990214, 'max_history_step': 'joint', 'pipeline': {'features': ('features_PCA', {'features__n_components': 2}), 'normalizer': ('normalizer_StandardScaler', {'normalizer__with_mean': False, 'normalizer__with_std': True}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 7})}, 'score': 0.9351687408175611, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'entropy', 'max_depth': 2, 'max_features': 2, 'max_leaf_nodes': 2, 'min_samples_split': 3, 'n_estimators': 10}, 'config_hash': {'algorithm': '0a507823f2ad8605ed5950e1fe61df0560f11a00', 'config': '4a538fdcf8e07f90e92a421c0d5c479d651629c7', 'pipeline': '5240329df25c9a533d025c1a401d49835a501b41'}, 'duration': 1.3821029663085938, 'iteration': 9, 'loss': 0.07006416904329793, 'max_history_score': 0.9456356408262035, 'max_history_score_std': 0.040053650785990214, 'max_history_step': 'joint', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 4, 'features__selectkbest__k': 2}), 'normalizer': ('normalizer_PowerTransformer', {}), 'rebalance': ('rebalance_NearMiss', {'rebalance__n_neighbors': 1})}, 'score': 0.9299358309567021, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'gini', 'max_depth': 1, 'max_features': 3, 'max_leaf_nodes': 5, 'min_samples_split': 3, 'n_estimators': 10}, 'config_hash': {'algorithm': 'd32739750d351948f8ff34a87c7d55b0c5e0d90f', 'config': 'c1609e71f1ce8486335adc70bb69a955580ba2c8', 'pipeline': 'f48b42ec5cf999279659966160a16353b75bdaa3'}, 'duration': 0.9055681228637695, 'iteration': 10, 'loss': 0.07532840722495904, 'max_history_score': 0.9456356408262035, 'max_history_score_std': 0.040053650785990214, 'max_history_step': 'joint', 'pipeline': {'features': ('features_PCA', {'features__n_components': 4}), 'normalizer': ('normalizer_PowerTransformer', {}), 'rebalance': ('rebalance_NearMiss', {'rebalance__n_neighbors': 1})}, 'score': 0.924671592775041, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': 3, 'max_features': 1, 'max_leaf_nodes': 5, 'min_samples_split': 3, 'n_estimators': 25}, 'config_hash': {'algorithm': 'f69bac35e71cbec1bfc1fb5942328a3390e7c252', 'config': 'abe36f188644e53e56ed3224236fa157107ed3b2', 'pipeline': 'aaf976c7c663a31fa039582d42f9e07101556a7c'}, 'duration': 0.764197826385498, 'iteration': 11, 'loss': 0.06818446979517778, 'max_history_score': 0.9456356408262035, 'max_history_score_std': 0.040053650785990214, 'max_history_step': 'joint', 'pipeline': {'features': ('features_NoneType', {}), 'normalizer': ('normalizer_PowerTransformer', {}), 'rebalance': ('rebalance_NoneType', {})}, 'score': 0.9318155302048222, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'entropy', 'max_depth': None, 'max_features': None, 'max_leaf_nodes': None, 'min_samples_split': 5, 'n_estimators': 25}, 'config_hash': {'algorithm': 'a0a27aec00db5ddf71eab96663f9bd61c845f5e3', 'config': '76aa002c3c9d4d9722466c60daf5119c18a41d2a', 'pipeline': '1ce34b7894ef342571d974bb19e8ec821a512c6b'}, 'duration': 1.1636500358581543, 'iteration': 12, 'loss': 0.12833700630887557, 'max_history_score': 0.9456356408262035, 'max_history_score_std': 0.040053650785990214, 'max_history_step': 'joint', 'pipeline': {'features': ('features_PCA', {'features__n_components': 1}), 'normalizer': ('normalizer_PowerTransformer', {}), 'rebalance': ('rebalance_NoneType', {})}, 'score': 0.8716629936911244, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'gini', 'max_depth': 1, 'max_features': 2, 'max_leaf_nodes': 2, 'min_samples_split': 2, 'n_estimators': 100}, 'config_hash': {'algorithm': '985c99dff1da9b2c87e4211c5335a9159aa9dbcb', 'config': 'f56a7a9e43a0a699e992dc1262e550b8b7c88538', 'pipeline': '5c934f6d9a8ad1f9afe762986a9cf2074fc95d79'}, 'duration': 2.235443115234375, 'iteration': 13, 'loss': 0.11414635727249167, 'max_history_score': 0.9456356408262035, 'max_history_score_std': 0.040053650785990214, 'max_history_step': 'joint', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 1, 'features__selectkbest__k': 1}), 'normalizer': ('normalizer_RobustScaler', {'normalizer__quantile_range': (...), 'normalizer__with_centering': False, 'normalizer__with_scaling': True}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 6})}, 'score': 0.8858536427275083, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'gini', 'max_depth': 1, 'max_features': 1, 'max_leaf_nodes': None, 'min_samples_split': 5, 'n_estimators': 10}, 'config_hash': {'algorithm': '7d74a39aac2579264a402aef2b6fa7943c19f3d3', 'config': '53f44c0ad925c5c08c25d4fadf5e9ee9d7c181cd', 'pipeline': '6eff5ef31d7d1d534db31913bb67529c8a24c42e'}, 'duration': 2.7847659587860107, 'iteration': 14, 'loss': 0.14061986863711007, 'max_history_score': 0.9456356408262035, 'max_history_score_std': 0.040053650785990214, 'max_history_step': 'joint', 'pipeline': {'features': ('features_PCA', {'features__n_components': 1}), 'normalizer': ('normalizer_RobustScaler', {'normalizer__quantile_range': (...), 'normalizer__with_centering': True, 'normalizer__with_scaling': True}), 'rebalance': ('rebalance_CondensedNearestNeighbour', {'rebalance__n_neighbors': 3})}, 'score': 0.8593801313628899, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'entropy', 'max_depth': 3, 'max_features': None, 'max_leaf_nodes': 5, 'min_samples_split': 2, 'n_estimators': 100}, 'config_hash': {'algorithm': 'c62d7c671832e4414b6b2d7c36cba5ddc83a0ed0', 'config': '5faee50671eaa0ac586722bff234e36a857e662d', 'pipeline': '8b29a55de2add78c49114b9bbe5e800e5524c59d'}, 'duration': 2.3916029930114746, 'iteration': 15, 'loss': 0.08770093336790252, 'max_history_score': 0.9456356408262035, 'max_history_score_std': 0.040053650785990214, 'max_history_step': 'joint', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 3, 'features__selectkbest__k': 4}), 'normalizer': ('normalizer_RobustScaler', {'normalizer__quantile_range': (...), 'normalizer__with_centering': True, 'normalizer__with_scaling': True}), 'rebalance': ('rebalance_NoneType', {})}, 'score': 0.9122990666320975, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': None, 'max_features': 1, 'max_leaf_nodes': 5, 'min_samples_split': 5, 'n_estimators': 10}, 'config_hash': {'algorithm': '290772bfb9b8ed15c48a72829e822fb0a07481d6', 'config': '9a04f25d8eb3db5b2f831abd341a6d384c73a957', 'pipeline': '1ce34b7894ef342571d974bb19e8ec821a512c6b'}, 'duration': 1.4364500045776367, 'iteration': 16, 'loss': 0.08948880822746508, 'max_history_score': 0.9456356408262035, 'max_history_score_std': 0.040053650785990214, 'max_history_step': 'joint', 'pipeline': {'features': ('features_PCA', {'features__n_components': 1}), 'normalizer': ('normalizer_PowerTransformer', {}), 'rebalance': ('rebalance_NoneType', {})}, 'score': 0.9105111917725349, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': 2, 'max_features': 3, 'max_leaf_nodes': 3, 'min_samples_split': 3, 'n_estimators': 100}, 'config_hash': {'algorithm': '7dab6d47f897c2961d3402eff844aff16a7d142a', 'config': '4dbfa2688b239be9f372d3e80223960ba9a1fbdd', 'pipeline': 'cdef51702798fa49f11c11d80baf3ab43d5358fc'}, 'duration': 0.9830451011657715, 'iteration': 17, 'loss': 1.0, 'max_history_score': 0.9456356408262035, 'max_history_score_std': 0.040053650785990214, 'max_history_step': 'joint', 'pipeline': {'features': ('features_SelectKBest', {'features__k': 2}), 'normalizer': ('normalizer_PowerTransformer', {}), 'rebalance': ('rebalance_NearMiss', {'rebalance__n_neighbors': 1})}, 'score': 0.0, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'entropy', 'max_depth': None, 'max_features': 3, 'max_leaf_nodes': None, 'min_samples_split': 5, 'n_estimators': 10}, 'config_hash': {'algorithm': 'def83e48be05ef92a37e1a90585820f2f67ff42b', 'config': '95902552cb76e9798f0fa58782bd72bd1cc272d7', 'pipeline': '1775187bf23f94f4fd0cc1e5c1ef665210edded5'}, 'duration': 2.0033559799194336, 'iteration': 18, 'loss': 0.04922327370149515, 'max_history_score': 0.9507767262985048, 'max_history_score_std': 0.028328108925705902, 'max_history_step': 'joint', 'pipeline': {'features': ('features_PCA', {'features__n_components': 4}), 'normalizer': ('normalizer_StandardScaler', {'normalizer__with_mean': True, 'normalizer__with_std': True}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 5})}, 'score': 0.9507767262985048, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'gini', 'max_depth': 1, 'max_features': 3, 'max_leaf_nodes': None, 'min_samples_split': 2, 'n_estimators': 50}, 'config_hash': {'algorithm': '4e9e3275f817df75115d9d7e3366980fc1b4cf13', 'config': '7770b19007b40bf13005d52eb81f87bc401f15b4', 'pipeline': 'c4dd111513ea35f97dd3aec3e8e7f6268ce035da'}, 'duration': 0.9069631099700928, 'iteration': 19, 'loss': 1.0, 'max_history_score': 0.9507767262985048, 'max_history_score_std': 0.028328108925705902, 'max_history_step': 'joint', 'pipeline': {'features': ('features_PCA', {'features__n_components': 2}), 'normalizer': ('normalizer_RobustScaler', {'normalizer__quantile_range': (...), 'normalizer__with_centering': False, 'normalizer__with_scaling': True}), 'rebalance': ('rebalance_NearMiss', {'rebalance__n_neighbors': 2})}, 'score': 0.0, ...}, ...], 'history_hash': ['51144ca42f9ea5ab2d8d58606e3b3e4d89c6d7b3', '9e54ffcb6a727de032a0a2cd45c5cc37cc150756', 'e5241eee9ddf3f4ee29a4711f5bcc92a4d24cd09', '18ee4d3d1627472ec190326308d8755371a6dc62', '2af4f82b045c0c48ecb89d42728d1039fbff8878', '17b2a1e5814f3e933137158708a5b6e9b2475495', 'fa020a592ec5ac234f9f91aac28abc2cd1ec9d33', '0da4498002d6f452c59bb61756abb3ded841e786', '344e4756fb1bec455d6af51d3727e33b0d27725f', '4a538fdcf8e07f90e92a421c0d5c479d651629c7', 'c1609e71f1ce8486335adc70bb69a955580ba2c8', 'abe36f188644e53e56ed3224236fa157107ed3b2', '76aa002c3c9d4d9722466c60daf5119c18a41d2a', 'f56a7a9e43a0a699e992dc1262e550b8b7c88538', '53f44c0ad925c5c08c25d4fadf5e9ee9d7c181cd', '5faee50671eaa0ac586722bff234e36a857e662d', '9a04f25d8eb3db5b2f831abd341a6d384c73a957', '4dbfa2688b239be9f372d3e80223960ba9a1fbdd', '95902552cb76e9798f0fa58782bd72bd1cc272d7', '7770b19007b40bf13005d52eb81f87bc401f15b4', ...], 'history_index': {'0212926e8a56cc42ae0a654a90c2a3ee92464265': 91, '0da4498002d6f452c59bb61756abb3ded841e786': 7, '0f77a69b0a8d34861caf915a51dc588ff8d4efac': 61, '127553d555ed39231b8da3a1ce42d3902e30919b': 59, '157ad7645c10c929b685db679adc21b38e285fff': 93, '17b2a1e5814f3e933137158708a5b6e9b2475495': 5, '18ee4d3d1627472ec190326308d8755371a6dc62': 3, '1b2267555a9226d7eb4df3c63dd12506da370f4d': 56, '278dd514f71ea681b3e2238dde3b16c35f1697db': 90, '2873878df7d4db8b415ff446bec08003e0c7488d': 92, ...}, 'iteration': 104, 'max_history_score': 0.9525008642295394, 'max_history_score_std': 0.02225295065716913, 'max_history_step': 'joint'}, config={'algorithm': 'RandomForest', 'seed': 42, 'time': 300})
    108 
    109 def objective_algo(algo_config, current_pipeline_config, algorithm, X, y, context, config):
    110     return objective(current_pipeline_config, algo_config, algorithm, X, y, context, config, step='algorithm')
    111 
    112 def objective_joint(wconfig, algorithm, X, y, context, config):
--> 113     return objective(wconfig['pipeline'], wconfig['algorithm'], algorithm, X, y, context, config, step='joint')
        wconfig = {'algorithm': {'bootstrap': False, 'criterion': 'entropy', 'max_depth': 4, 'max_features': 3, 'max_leaf_nodes': None, 'min_samples_split': 5, 'n_estimators': 100}, 'pipeline': {'features': ('features_PCA', {'features__n_components': 2}), 'normalizer': ('normalizer_StandardScaler', {'normalizer__with_mean': True, 'normalizer__with_std': False}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 7})}}
        algorithm = 'RandomForest'
        X = array([[1.799e+01, 1.038e+01, 1.228e+02, ..., 2...., ..., 0.000e+00, 2.871e-01,
        7.039e-02]])
        y = array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,... 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1])
        context = {'baseline_score': 0.9545944602886527, 'baseline_score_std': 0.03716322883281839, 'best_config': {'algorithm': {'bootstrap': False, 'criterion': 'entropy', 'max_depth': None, 'max_features': 2, 'max_leaf_nodes': None, 'min_samples_split': 5, 'n_estimators': 10}, 'config_hash': {'algorithm': 'e7a772c2bc361aa61cf7eeb364a26dca2c9b89d6', 'config': 'afb67da069b544b0505b1e8c150edc7498ad37b4', 'pipeline': 'a43db4b4fc4c38610b7b5e484840d2e583089ff4'}, 'duration': 1.0073001384735107, 'iteration': 26, 'loss': 0.04749913577046061, 'max_history_score': 0.9525008642295394, 'max_history_score_std': 0.02225295065716913, 'max_history_step': 'joint', 'pipeline': {'features': ('features_PCA', {'features__n_components': 4}), 'normalizer': ('normalizer_StandardScaler', {'normalizer__with_mean': True, 'normalizer__with_std': False}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 7})}, 'score': 0.9525008642295394, ...}, 'history': [{'algorithm': {'bootstrap': True, 'criterion': 'entropy', 'max_depth': 4, 'max_features': 3, 'max_leaf_nodes': 3, 'min_samples_split': 2, 'n_estimators': 10}, 'config_hash': {'algorithm': '42527c4120073c2a488d1b8df28732f486d1578c', 'config': '51144ca42f9ea5ab2d8d58606e3b3e4d89c6d7b3', 'pipeline': '52f07bda29f9d3a95fabb87e591d0b2581ca8209'}, 'duration': 0.26703310012817383, 'iteration': 0, 'loss': 0.06655431682654922, 'max_history_score': 0.9334456831734508, 'max_history_score_std': 0.03819399139659311, 'max_history_step': 'joint', 'pipeline': {'features': ('features_NoneType', {}), 'normalizer': ('normalizer_RobustScaler', {'normalizer__quantile_range': (...), 'normalizer__with_centering': False, 'normalizer__with_scaling': False}), 'rebalance': ('rebalance_NearMiss', {'rebalance__n_neighbors': 1})}, 'score': 0.9334456831734508, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': None, 'max_features': 2, 'max_leaf_nodes': 3, 'min_samples_split': 2, 'n_estimators': 100}, 'config_hash': {'algorithm': '1b32258c630f07e01ab481ab925ab80aa757e482', 'config': '9e54ffcb6a727de032a0a2cd45c5cc37cc150756', 'pipeline': '37e72d4a97f5e784c9d3133e6379b91bfc3be803'}, 'duration': 1.3065669536590576, 'iteration': 1, 'loss': 0.05436435917379645, 'max_history_score': 0.9456356408262035, 'max_history_score_std': 0.040053650785990214, 'max_history_step': 'joint', 'pipeline': {'features': ('features_NoneType', {}), 'normalizer': ('normalizer_StandardScaler', {'normalizer__with_mean': True, 'normalizer__with_std': True}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 6})}, 'score': 0.9456356408262035, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'entropy', 'max_depth': 1, 'max_features': 1, 'max_leaf_nodes': 2, 'min_samples_split': 3, 'n_estimators': 25}, 'config_hash': {'algorithm': '68ab9059aa7ec74e0da87c81734b9664243b3eb4', 'config': 'e5241eee9ddf3f4ee29a4711f5bcc92a4d24cd09', 'pipeline': '62463de065924498cdcd2f2f1f7e68535cdb33a5'}, 'duration': 0.6592490673065186, 'iteration': 2, 'loss': 0.07695856019358727, 'max_history_score': 0.9456356408262035, 'max_history_score_std': 0.040053650785990214, 'max_history_step': 'joint', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 1, 'features__selectkbest__k': 2}), 'normalizer': ('normalizer_NoneType', {}), 'rebalance': ('rebalance_NoneType', {})}, 'score': 0.9230414398064127, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': 3, 'max_features': 2, 'max_leaf_nodes': 2, 'min_samples_split': 2, 'n_estimators': 25}, 'config_hash': {'algorithm': 'e3f1f7d7783557a38f40f0476369091edd87092b', 'config': '18ee4d3d1627472ec190326308d8755371a6dc62', 'pipeline': 'c6d1263e344ed8c71b2e6e4ba8e0db2fb6c777c0'}, 'duration': 0.879349946975708, 'iteration': 3, 'loss': 0.07535973554576114, 'max_history_score': 0.9456356408262035, 'max_history_score_std': 0.040053650785990214, 'max_history_step': 'joint', 'pipeline': {'features': ('features_NoneType', {}), 'normalizer': ('normalizer_RobustScaler', {'normalizer__quantile_range': (...), 'normalizer__with_centering': True, 'normalizer__with_scaling': True}), 'rebalance': ('rebalance_NearMiss', {'rebalance__n_neighbors': 2})}, 'score': 0.9246402644542389, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'gini', 'max_depth': 4, 'max_features': 2, 'max_leaf_nodes': 5, 'min_samples_split': 2, 'n_estimators': 50}, 'config_hash': {'algorithm': '47581af7253940f9647ad16d37347d34baf13e5f', 'config': '2af4f82b045c0c48ecb89d42728d1039fbff8878', 'pipeline': '2928b22ed834303cb7bac6e6608531eaddd7df67'}, 'duration': 4.372632026672363, 'iteration': 4, 'loss': 0.09121294615849984, 'max_history_score': 0.9456356408262035, 'max_history_score_std': 0.040053650785990214, 'max_history_step': 'joint', 'pipeline': {'features': ('features_NoneType', {}), 'normalizer': ('normalizer_MinMaxScaler', {}), 'rebalance': ('rebalance_CondensedNearestNeighbour', {'rebalance__n_neighbors': 2})}, 'score': 0.9087870538415002, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'entropy', 'max_depth': 2, 'max_features': 2, 'max_leaf_nodes': None, 'min_samples_split': 2, 'n_estimators': 10}, 'config_hash': {'algorithm': '0a85f98ca2d06103287f153633d88f7a0535e7e8', 'config': '17b2a1e5814f3e933137158708a5b6e9b2475495', 'pipeline': '95defa3bdd8357f11f872d3c280d50a6d8ee398d'}, 'duration': 2.625814914703369, 'iteration': 5, 'loss': 0.15471329185031535, 'max_history_score': 0.9456356408262035, 'max_history_score_std': 0.040053650785990214, 'max_history_step': 'joint', 'pipeline': {'features': ('features_SelectKBest', {'features__k': 2}), 'normalizer': ('normalizer_StandardScaler', {'normalizer__with_mean': False, 'normalizer__with_std': False}), 'rebalance': ('rebalance_CondensedNearestNeighbour', {'rebalance__n_neighbors': 1})}, 'score': 0.8452867081496847, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': 3, 'max_features': None, 'max_leaf_nodes': None, 'min_samples_split': 5, 'n_estimators': 75}, 'config_hash': {'algorithm': 'd7466a2c1d5cb3fa95029d73dc030f4c3c45a159', 'config': 'fa020a592ec5ac234f9f91aac28abc2cd1ec9d33', 'pipeline': '71e0d26f923d42cfe0e2fa748931ef2afe72ed86'}, 'duration': 3.62078595161438, 'iteration': 6, 'loss': 0.17066372828623277, 'max_history_score': 0.9456356408262035, 'max_history_score_std': 0.040053650785990214, 'max_history_step': 'joint', 'pipeline': {'features': ('features_SelectKBest', {'features__k': 1}), 'normalizer': ('normalizer_RobustScaler', {'normalizer__quantile_range': (...), 'normalizer__with_centering': True, 'normalizer__with_scaling': True}), 'rebalance': ('rebalance_CondensedNearestNeighbour', {'rebalance__n_neighbors': 1})}, 'score': 0.8293362717137672, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'entropy', 'max_depth': 3, 'max_features': 3, 'max_leaf_nodes': 5, 'min_samples_split': 5, 'n_estimators': 50}, 'config_hash': {'algorithm': '735caa9785596076014572a24050cde8dc338973', 'config': '0da4498002d6f452c59bb61756abb3ded841e786', 'pipeline': '51a53ea6ef5a2521ee65f76eb2da220ab7086513'}, 'duration': 0.6934049129486084, 'iteration': 7, 'loss': 0.06125875032408601, 'max_history_score': 0.9456356408262035, 'max_history_score_std': 0.040053650785990214, 'max_history_step': 'joint', 'pipeline': {'features': ('features_NoneType', {}), 'normalizer': ('normalizer_NoneType', {}), 'rebalance': ('rebalance_NearMiss', {'rebalance__n_neighbors': 3})}, 'score': 0.938741249675914, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': 4, 'max_features': 2, 'max_leaf_nodes': None, 'min_samples_split': 3, 'n_estimators': 75}, 'config_hash': {'algorithm': 'e71a1fe9515b6805f07914a61f2e7594be9e9afe', 'config': '344e4756fb1bec455d6af51d3727e33b0d27725f', 'pipeline': '248dad1d8b30a17a5de1d0bbdfe3e2acb7a1962b'}, 'duration': 1.3036692142486572, 'iteration': 8, 'loss': 0.06483125918243893, 'max_history_score': 0.9456356408262035, 'max_history_score_std': 0.040053650785990214, 'max_history_step': 'joint', 'pipeline': {'features': ('features_PCA', {'features__n_components': 2}), 'normalizer': ('normalizer_StandardScaler', {'normalizer__with_mean': False, 'normalizer__with_std': True}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 7})}, 'score': 0.9351687408175611, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'entropy', 'max_depth': 2, 'max_features': 2, 'max_leaf_nodes': 2, 'min_samples_split': 3, 'n_estimators': 10}, 'config_hash': {'algorithm': '0a507823f2ad8605ed5950e1fe61df0560f11a00', 'config': '4a538fdcf8e07f90e92a421c0d5c479d651629c7', 'pipeline': '5240329df25c9a533d025c1a401d49835a501b41'}, 'duration': 1.3821029663085938, 'iteration': 9, 'loss': 0.07006416904329793, 'max_history_score': 0.9456356408262035, 'max_history_score_std': 0.040053650785990214, 'max_history_step': 'joint', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 4, 'features__selectkbest__k': 2}), 'normalizer': ('normalizer_PowerTransformer', {}), 'rebalance': ('rebalance_NearMiss', {'rebalance__n_neighbors': 1})}, 'score': 0.9299358309567021, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'gini', 'max_depth': 1, 'max_features': 3, 'max_leaf_nodes': 5, 'min_samples_split': 3, 'n_estimators': 10}, 'config_hash': {'algorithm': 'd32739750d351948f8ff34a87c7d55b0c5e0d90f', 'config': 'c1609e71f1ce8486335adc70bb69a955580ba2c8', 'pipeline': 'f48b42ec5cf999279659966160a16353b75bdaa3'}, 'duration': 0.9055681228637695, 'iteration': 10, 'loss': 0.07532840722495904, 'max_history_score': 0.9456356408262035, 'max_history_score_std': 0.040053650785990214, 'max_history_step': 'joint', 'pipeline': {'features': ('features_PCA', {'features__n_components': 4}), 'normalizer': ('normalizer_PowerTransformer', {}), 'rebalance': ('rebalance_NearMiss', {'rebalance__n_neighbors': 1})}, 'score': 0.924671592775041, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': 3, 'max_features': 1, 'max_leaf_nodes': 5, 'min_samples_split': 3, 'n_estimators': 25}, 'config_hash': {'algorithm': 'f69bac35e71cbec1bfc1fb5942328a3390e7c252', 'config': 'abe36f188644e53e56ed3224236fa157107ed3b2', 'pipeline': 'aaf976c7c663a31fa039582d42f9e07101556a7c'}, 'duration': 0.764197826385498, 'iteration': 11, 'loss': 0.06818446979517778, 'max_history_score': 0.9456356408262035, 'max_history_score_std': 0.040053650785990214, 'max_history_step': 'joint', 'pipeline': {'features': ('features_NoneType', {}), 'normalizer': ('normalizer_PowerTransformer', {}), 'rebalance': ('rebalance_NoneType', {})}, 'score': 0.9318155302048222, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'entropy', 'max_depth': None, 'max_features': None, 'max_leaf_nodes': None, 'min_samples_split': 5, 'n_estimators': 25}, 'config_hash': {'algorithm': 'a0a27aec00db5ddf71eab96663f9bd61c845f5e3', 'config': '76aa002c3c9d4d9722466c60daf5119c18a41d2a', 'pipeline': '1ce34b7894ef342571d974bb19e8ec821a512c6b'}, 'duration': 1.1636500358581543, 'iteration': 12, 'loss': 0.12833700630887557, 'max_history_score': 0.9456356408262035, 'max_history_score_std': 0.040053650785990214, 'max_history_step': 'joint', 'pipeline': {'features': ('features_PCA', {'features__n_components': 1}), 'normalizer': ('normalizer_PowerTransformer', {}), 'rebalance': ('rebalance_NoneType', {})}, 'score': 0.8716629936911244, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'gini', 'max_depth': 1, 'max_features': 2, 'max_leaf_nodes': 2, 'min_samples_split': 2, 'n_estimators': 100}, 'config_hash': {'algorithm': '985c99dff1da9b2c87e4211c5335a9159aa9dbcb', 'config': 'f56a7a9e43a0a699e992dc1262e550b8b7c88538', 'pipeline': '5c934f6d9a8ad1f9afe762986a9cf2074fc95d79'}, 'duration': 2.235443115234375, 'iteration': 13, 'loss': 0.11414635727249167, 'max_history_score': 0.9456356408262035, 'max_history_score_std': 0.040053650785990214, 'max_history_step': 'joint', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 1, 'features__selectkbest__k': 1}), 'normalizer': ('normalizer_RobustScaler', {'normalizer__quantile_range': (...), 'normalizer__with_centering': False, 'normalizer__with_scaling': True}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 6})}, 'score': 0.8858536427275083, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'gini', 'max_depth': 1, 'max_features': 1, 'max_leaf_nodes': None, 'min_samples_split': 5, 'n_estimators': 10}, 'config_hash': {'algorithm': '7d74a39aac2579264a402aef2b6fa7943c19f3d3', 'config': '53f44c0ad925c5c08c25d4fadf5e9ee9d7c181cd', 'pipeline': '6eff5ef31d7d1d534db31913bb67529c8a24c42e'}, 'duration': 2.7847659587860107, 'iteration': 14, 'loss': 0.14061986863711007, 'max_history_score': 0.9456356408262035, 'max_history_score_std': 0.040053650785990214, 'max_history_step': 'joint', 'pipeline': {'features': ('features_PCA', {'features__n_components': 1}), 'normalizer': ('normalizer_RobustScaler', {'normalizer__quantile_range': (...), 'normalizer__with_centering': True, 'normalizer__with_scaling': True}), 'rebalance': ('rebalance_CondensedNearestNeighbour', {'rebalance__n_neighbors': 3})}, 'score': 0.8593801313628899, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'entropy', 'max_depth': 3, 'max_features': None, 'max_leaf_nodes': 5, 'min_samples_split': 2, 'n_estimators': 100}, 'config_hash': {'algorithm': 'c62d7c671832e4414b6b2d7c36cba5ddc83a0ed0', 'config': '5faee50671eaa0ac586722bff234e36a857e662d', 'pipeline': '8b29a55de2add78c49114b9bbe5e800e5524c59d'}, 'duration': 2.3916029930114746, 'iteration': 15, 'loss': 0.08770093336790252, 'max_history_score': 0.9456356408262035, 'max_history_score_std': 0.040053650785990214, 'max_history_step': 'joint', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 3, 'features__selectkbest__k': 4}), 'normalizer': ('normalizer_RobustScaler', {'normalizer__quantile_range': (...), 'normalizer__with_centering': True, 'normalizer__with_scaling': True}), 'rebalance': ('rebalance_NoneType', {})}, 'score': 0.9122990666320975, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': None, 'max_features': 1, 'max_leaf_nodes': 5, 'min_samples_split': 5, 'n_estimators': 10}, 'config_hash': {'algorithm': '290772bfb9b8ed15c48a72829e822fb0a07481d6', 'config': '9a04f25d8eb3db5b2f831abd341a6d384c73a957', 'pipeline': '1ce34b7894ef342571d974bb19e8ec821a512c6b'}, 'duration': 1.4364500045776367, 'iteration': 16, 'loss': 0.08948880822746508, 'max_history_score': 0.9456356408262035, 'max_history_score_std': 0.040053650785990214, 'max_history_step': 'joint', 'pipeline': {'features': ('features_PCA', {'features__n_components': 1}), 'normalizer': ('normalizer_PowerTransformer', {}), 'rebalance': ('rebalance_NoneType', {})}, 'score': 0.9105111917725349, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': 2, 'max_features': 3, 'max_leaf_nodes': 3, 'min_samples_split': 3, 'n_estimators': 100}, 'config_hash': {'algorithm': '7dab6d47f897c2961d3402eff844aff16a7d142a', 'config': '4dbfa2688b239be9f372d3e80223960ba9a1fbdd', 'pipeline': 'cdef51702798fa49f11c11d80baf3ab43d5358fc'}, 'duration': 0.9830451011657715, 'iteration': 17, 'loss': 1.0, 'max_history_score': 0.9456356408262035, 'max_history_score_std': 0.040053650785990214, 'max_history_step': 'joint', 'pipeline': {'features': ('features_SelectKBest', {'features__k': 2}), 'normalizer': ('normalizer_PowerTransformer', {}), 'rebalance': ('rebalance_NearMiss', {'rebalance__n_neighbors': 1})}, 'score': 0.0, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'entropy', 'max_depth': None, 'max_features': 3, 'max_leaf_nodes': None, 'min_samples_split': 5, 'n_estimators': 10}, 'config_hash': {'algorithm': 'def83e48be05ef92a37e1a90585820f2f67ff42b', 'config': '95902552cb76e9798f0fa58782bd72bd1cc272d7', 'pipeline': '1775187bf23f94f4fd0cc1e5c1ef665210edded5'}, 'duration': 2.0033559799194336, 'iteration': 18, 'loss': 0.04922327370149515, 'max_history_score': 0.9507767262985048, 'max_history_score_std': 0.028328108925705902, 'max_history_step': 'joint', 'pipeline': {'features': ('features_PCA', {'features__n_components': 4}), 'normalizer': ('normalizer_StandardScaler', {'normalizer__with_mean': True, 'normalizer__with_std': True}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 5})}, 'score': 0.9507767262985048, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'gini', 'max_depth': 1, 'max_features': 3, 'max_leaf_nodes': None, 'min_samples_split': 2, 'n_estimators': 50}, 'config_hash': {'algorithm': '4e9e3275f817df75115d9d7e3366980fc1b4cf13', 'config': '7770b19007b40bf13005d52eb81f87bc401f15b4', 'pipeline': 'c4dd111513ea35f97dd3aec3e8e7f6268ce035da'}, 'duration': 0.9069631099700928, 'iteration': 19, 'loss': 1.0, 'max_history_score': 0.9507767262985048, 'max_history_score_std': 0.028328108925705902, 'max_history_step': 'joint', 'pipeline': {'features': ('features_PCA', {'features__n_components': 2}), 'normalizer': ('normalizer_RobustScaler', {'normalizer__quantile_range': (...), 'normalizer__with_centering': False, 'normalizer__with_scaling': True}), 'rebalance': ('rebalance_NearMiss', {'rebalance__n_neighbors': 2})}, 'score': 0.0, ...}, ...], 'history_hash': ['51144ca42f9ea5ab2d8d58606e3b3e4d89c6d7b3', '9e54ffcb6a727de032a0a2cd45c5cc37cc150756', 'e5241eee9ddf3f4ee29a4711f5bcc92a4d24cd09', '18ee4d3d1627472ec190326308d8755371a6dc62', '2af4f82b045c0c48ecb89d42728d1039fbff8878', '17b2a1e5814f3e933137158708a5b6e9b2475495', 'fa020a592ec5ac234f9f91aac28abc2cd1ec9d33', '0da4498002d6f452c59bb61756abb3ded841e786', '344e4756fb1bec455d6af51d3727e33b0d27725f', '4a538fdcf8e07f90e92a421c0d5c479d651629c7', 'c1609e71f1ce8486335adc70bb69a955580ba2c8', 'abe36f188644e53e56ed3224236fa157107ed3b2', '76aa002c3c9d4d9722466c60daf5119c18a41d2a', 'f56a7a9e43a0a699e992dc1262e550b8b7c88538', '53f44c0ad925c5c08c25d4fadf5e9ee9d7c181cd', '5faee50671eaa0ac586722bff234e36a857e662d', '9a04f25d8eb3db5b2f831abd341a6d384c73a957', '4dbfa2688b239be9f372d3e80223960ba9a1fbdd', '95902552cb76e9798f0fa58782bd72bd1cc272d7', '7770b19007b40bf13005d52eb81f87bc401f15b4', ...], 'history_index': {'0212926e8a56cc42ae0a654a90c2a3ee92464265': 91, '0da4498002d6f452c59bb61756abb3ded841e786': 7, '0f77a69b0a8d34861caf915a51dc588ff8d4efac': 61, '127553d555ed39231b8da3a1ce42d3902e30919b': 59, '157ad7645c10c929b685db679adc21b38e285fff': 93, '17b2a1e5814f3e933137158708a5b6e9b2475495': 5, '18ee4d3d1627472ec190326308d8755371a6dc62': 3, '1b2267555a9226d7eb4df3c63dd12506da370f4d': 56, '278dd514f71ea681b3e2238dde3b16c35f1697db': 90, '2873878df7d4db8b415ff446bec08003e0c7488d': 92, ...}, 'iteration': 104, 'max_history_score': 0.9525008642295394, 'max_history_score_std': 0.02225295065716913, 'max_history_step': 'joint'}
        config = {'algorithm': 'RandomForest', 'seed': 42, 'time': 300}
    114 
    115 
    116 def get_baseline_score(algorithm, X, y, seed):
    117     pipeline, _ = pipeline_conf_to_full_pipeline(

...........................................................................
/home/aquemy/dev/dp_hyperparameters/extension/experiment/objective.py in objective(pipeline_config={'features': ('features_PCA', {'features__n_components': 2}), 'normalizer': ('normalizer_StandardScaler', {'normalizer__with_mean': True, 'normalizer__with_std': False}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 7})}, algo_config={'bootstrap': False, 'criterion': 'entropy', 'max_depth': 4, 'max_features': 3, 'max_leaf_nodes': None, 'min_samples_split': 5, 'n_estimators': 100}, algorithm='RandomForest', X=array([[1.799e+01, 1.038e+01, 1.228e+02, ..., 2...., ..., 0.000e+00, 2.871e-01,
        7.039e-02]]), y=array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,... 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1]), context={'baseline_score': 0.9545944602886527, 'baseline_score_std': 0.03716322883281839, 'best_config': {'algorithm': {'bootstrap': False, 'criterion': 'entropy', 'max_depth': None, 'max_features': 2, 'max_leaf_nodes': None, 'min_samples_split': 5, 'n_estimators': 10}, 'config_hash': {'algorithm': 'e7a772c2bc361aa61cf7eeb364a26dca2c9b89d6', 'config': 'afb67da069b544b0505b1e8c150edc7498ad37b4', 'pipeline': 'a43db4b4fc4c38610b7b5e484840d2e583089ff4'}, 'duration': 1.0073001384735107, 'iteration': 26, 'loss': 0.04749913577046061, 'max_history_score': 0.9525008642295394, 'max_history_score_std': 0.02225295065716913, 'max_history_step': 'joint', 'pipeline': {'features': ('features_PCA', {'features__n_components': 4}), 'normalizer': ('normalizer_StandardScaler', {'normalizer__with_mean': True, 'normalizer__with_std': False}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 7})}, 'score': 0.9525008642295394, ...}, 'history': [{'algorithm': {'bootstrap': True, 'criterion': 'entropy', 'max_depth': 4, 'max_features': 3, 'max_leaf_nodes': 3, 'min_samples_split': 2, 'n_estimators': 10}, 'config_hash': {'algorithm': '42527c4120073c2a488d1b8df28732f486d1578c', 'config': '51144ca42f9ea5ab2d8d58606e3b3e4d89c6d7b3', 'pipeline': '52f07bda29f9d3a95fabb87e591d0b2581ca8209'}, 'duration': 0.26703310012817383, 'iteration': 0, 'loss': 0.06655431682654922, 'max_history_score': 0.9334456831734508, 'max_history_score_std': 0.03819399139659311, 'max_history_step': 'joint', 'pipeline': {'features': ('features_NoneType', {}), 'normalizer': ('normalizer_RobustScaler', {'normalizer__quantile_range': (...), 'normalizer__with_centering': False, 'normalizer__with_scaling': False}), 'rebalance': ('rebalance_NearMiss', {'rebalance__n_neighbors': 1})}, 'score': 0.9334456831734508, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': None, 'max_features': 2, 'max_leaf_nodes': 3, 'min_samples_split': 2, 'n_estimators': 100}, 'config_hash': {'algorithm': '1b32258c630f07e01ab481ab925ab80aa757e482', 'config': '9e54ffcb6a727de032a0a2cd45c5cc37cc150756', 'pipeline': '37e72d4a97f5e784c9d3133e6379b91bfc3be803'}, 'duration': 1.3065669536590576, 'iteration': 1, 'loss': 0.05436435917379645, 'max_history_score': 0.9456356408262035, 'max_history_score_std': 0.040053650785990214, 'max_history_step': 'joint', 'pipeline': {'features': ('features_NoneType', {}), 'normalizer': ('normalizer_StandardScaler', {'normalizer__with_mean': True, 'normalizer__with_std': True}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 6})}, 'score': 0.9456356408262035, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'entropy', 'max_depth': 1, 'max_features': 1, 'max_leaf_nodes': 2, 'min_samples_split': 3, 'n_estimators': 25}, 'config_hash': {'algorithm': '68ab9059aa7ec74e0da87c81734b9664243b3eb4', 'config': 'e5241eee9ddf3f4ee29a4711f5bcc92a4d24cd09', 'pipeline': '62463de065924498cdcd2f2f1f7e68535cdb33a5'}, 'duration': 0.6592490673065186, 'iteration': 2, 'loss': 0.07695856019358727, 'max_history_score': 0.9456356408262035, 'max_history_score_std': 0.040053650785990214, 'max_history_step': 'joint', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 1, 'features__selectkbest__k': 2}), 'normalizer': ('normalizer_NoneType', {}), 'rebalance': ('rebalance_NoneType', {})}, 'score': 0.9230414398064127, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': 3, 'max_features': 2, 'max_leaf_nodes': 2, 'min_samples_split': 2, 'n_estimators': 25}, 'config_hash': {'algorithm': 'e3f1f7d7783557a38f40f0476369091edd87092b', 'config': '18ee4d3d1627472ec190326308d8755371a6dc62', 'pipeline': 'c6d1263e344ed8c71b2e6e4ba8e0db2fb6c777c0'}, 'duration': 0.879349946975708, 'iteration': 3, 'loss': 0.07535973554576114, 'max_history_score': 0.9456356408262035, 'max_history_score_std': 0.040053650785990214, 'max_history_step': 'joint', 'pipeline': {'features': ('features_NoneType', {}), 'normalizer': ('normalizer_RobustScaler', {'normalizer__quantile_range': (...), 'normalizer__with_centering': True, 'normalizer__with_scaling': True}), 'rebalance': ('rebalance_NearMiss', {'rebalance__n_neighbors': 2})}, 'score': 0.9246402644542389, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'gini', 'max_depth': 4, 'max_features': 2, 'max_leaf_nodes': 5, 'min_samples_split': 2, 'n_estimators': 50}, 'config_hash': {'algorithm': '47581af7253940f9647ad16d37347d34baf13e5f', 'config': '2af4f82b045c0c48ecb89d42728d1039fbff8878', 'pipeline': '2928b22ed834303cb7bac6e6608531eaddd7df67'}, 'duration': 4.372632026672363, 'iteration': 4, 'loss': 0.09121294615849984, 'max_history_score': 0.9456356408262035, 'max_history_score_std': 0.040053650785990214, 'max_history_step': 'joint', 'pipeline': {'features': ('features_NoneType', {}), 'normalizer': ('normalizer_MinMaxScaler', {}), 'rebalance': ('rebalance_CondensedNearestNeighbour', {'rebalance__n_neighbors': 2})}, 'score': 0.9087870538415002, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'entropy', 'max_depth': 2, 'max_features': 2, 'max_leaf_nodes': None, 'min_samples_split': 2, 'n_estimators': 10}, 'config_hash': {'algorithm': '0a85f98ca2d06103287f153633d88f7a0535e7e8', 'config': '17b2a1e5814f3e933137158708a5b6e9b2475495', 'pipeline': '95defa3bdd8357f11f872d3c280d50a6d8ee398d'}, 'duration': 2.625814914703369, 'iteration': 5, 'loss': 0.15471329185031535, 'max_history_score': 0.9456356408262035, 'max_history_score_std': 0.040053650785990214, 'max_history_step': 'joint', 'pipeline': {'features': ('features_SelectKBest', {'features__k': 2}), 'normalizer': ('normalizer_StandardScaler', {'normalizer__with_mean': False, 'normalizer__with_std': False}), 'rebalance': ('rebalance_CondensedNearestNeighbour', {'rebalance__n_neighbors': 1})}, 'score': 0.8452867081496847, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': 3, 'max_features': None, 'max_leaf_nodes': None, 'min_samples_split': 5, 'n_estimators': 75}, 'config_hash': {'algorithm': 'd7466a2c1d5cb3fa95029d73dc030f4c3c45a159', 'config': 'fa020a592ec5ac234f9f91aac28abc2cd1ec9d33', 'pipeline': '71e0d26f923d42cfe0e2fa748931ef2afe72ed86'}, 'duration': 3.62078595161438, 'iteration': 6, 'loss': 0.17066372828623277, 'max_history_score': 0.9456356408262035, 'max_history_score_std': 0.040053650785990214, 'max_history_step': 'joint', 'pipeline': {'features': ('features_SelectKBest', {'features__k': 1}), 'normalizer': ('normalizer_RobustScaler', {'normalizer__quantile_range': (...), 'normalizer__with_centering': True, 'normalizer__with_scaling': True}), 'rebalance': ('rebalance_CondensedNearestNeighbour', {'rebalance__n_neighbors': 1})}, 'score': 0.8293362717137672, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'entropy', 'max_depth': 3, 'max_features': 3, 'max_leaf_nodes': 5, 'min_samples_split': 5, 'n_estimators': 50}, 'config_hash': {'algorithm': '735caa9785596076014572a24050cde8dc338973', 'config': '0da4498002d6f452c59bb61756abb3ded841e786', 'pipeline': '51a53ea6ef5a2521ee65f76eb2da220ab7086513'}, 'duration': 0.6934049129486084, 'iteration': 7, 'loss': 0.06125875032408601, 'max_history_score': 0.9456356408262035, 'max_history_score_std': 0.040053650785990214, 'max_history_step': 'joint', 'pipeline': {'features': ('features_NoneType', {}), 'normalizer': ('normalizer_NoneType', {}), 'rebalance': ('rebalance_NearMiss', {'rebalance__n_neighbors': 3})}, 'score': 0.938741249675914, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': 4, 'max_features': 2, 'max_leaf_nodes': None, 'min_samples_split': 3, 'n_estimators': 75}, 'config_hash': {'algorithm': 'e71a1fe9515b6805f07914a61f2e7594be9e9afe', 'config': '344e4756fb1bec455d6af51d3727e33b0d27725f', 'pipeline': '248dad1d8b30a17a5de1d0bbdfe3e2acb7a1962b'}, 'duration': 1.3036692142486572, 'iteration': 8, 'loss': 0.06483125918243893, 'max_history_score': 0.9456356408262035, 'max_history_score_std': 0.040053650785990214, 'max_history_step': 'joint', 'pipeline': {'features': ('features_PCA', {'features__n_components': 2}), 'normalizer': ('normalizer_StandardScaler', {'normalizer__with_mean': False, 'normalizer__with_std': True}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 7})}, 'score': 0.9351687408175611, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'entropy', 'max_depth': 2, 'max_features': 2, 'max_leaf_nodes': 2, 'min_samples_split': 3, 'n_estimators': 10}, 'config_hash': {'algorithm': '0a507823f2ad8605ed5950e1fe61df0560f11a00', 'config': '4a538fdcf8e07f90e92a421c0d5c479d651629c7', 'pipeline': '5240329df25c9a533d025c1a401d49835a501b41'}, 'duration': 1.3821029663085938, 'iteration': 9, 'loss': 0.07006416904329793, 'max_history_score': 0.9456356408262035, 'max_history_score_std': 0.040053650785990214, 'max_history_step': 'joint', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 4, 'features__selectkbest__k': 2}), 'normalizer': ('normalizer_PowerTransformer', {}), 'rebalance': ('rebalance_NearMiss', {'rebalance__n_neighbors': 1})}, 'score': 0.9299358309567021, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'gini', 'max_depth': 1, 'max_features': 3, 'max_leaf_nodes': 5, 'min_samples_split': 3, 'n_estimators': 10}, 'config_hash': {'algorithm': 'd32739750d351948f8ff34a87c7d55b0c5e0d90f', 'config': 'c1609e71f1ce8486335adc70bb69a955580ba2c8', 'pipeline': 'f48b42ec5cf999279659966160a16353b75bdaa3'}, 'duration': 0.9055681228637695, 'iteration': 10, 'loss': 0.07532840722495904, 'max_history_score': 0.9456356408262035, 'max_history_score_std': 0.040053650785990214, 'max_history_step': 'joint', 'pipeline': {'features': ('features_PCA', {'features__n_components': 4}), 'normalizer': ('normalizer_PowerTransformer', {}), 'rebalance': ('rebalance_NearMiss', {'rebalance__n_neighbors': 1})}, 'score': 0.924671592775041, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': 3, 'max_features': 1, 'max_leaf_nodes': 5, 'min_samples_split': 3, 'n_estimators': 25}, 'config_hash': {'algorithm': 'f69bac35e71cbec1bfc1fb5942328a3390e7c252', 'config': 'abe36f188644e53e56ed3224236fa157107ed3b2', 'pipeline': 'aaf976c7c663a31fa039582d42f9e07101556a7c'}, 'duration': 0.764197826385498, 'iteration': 11, 'loss': 0.06818446979517778, 'max_history_score': 0.9456356408262035, 'max_history_score_std': 0.040053650785990214, 'max_history_step': 'joint', 'pipeline': {'features': ('features_NoneType', {}), 'normalizer': ('normalizer_PowerTransformer', {}), 'rebalance': ('rebalance_NoneType', {})}, 'score': 0.9318155302048222, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'entropy', 'max_depth': None, 'max_features': None, 'max_leaf_nodes': None, 'min_samples_split': 5, 'n_estimators': 25}, 'config_hash': {'algorithm': 'a0a27aec00db5ddf71eab96663f9bd61c845f5e3', 'config': '76aa002c3c9d4d9722466c60daf5119c18a41d2a', 'pipeline': '1ce34b7894ef342571d974bb19e8ec821a512c6b'}, 'duration': 1.1636500358581543, 'iteration': 12, 'loss': 0.12833700630887557, 'max_history_score': 0.9456356408262035, 'max_history_score_std': 0.040053650785990214, 'max_history_step': 'joint', 'pipeline': {'features': ('features_PCA', {'features__n_components': 1}), 'normalizer': ('normalizer_PowerTransformer', {}), 'rebalance': ('rebalance_NoneType', {})}, 'score': 0.8716629936911244, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'gini', 'max_depth': 1, 'max_features': 2, 'max_leaf_nodes': 2, 'min_samples_split': 2, 'n_estimators': 100}, 'config_hash': {'algorithm': '985c99dff1da9b2c87e4211c5335a9159aa9dbcb', 'config': 'f56a7a9e43a0a699e992dc1262e550b8b7c88538', 'pipeline': '5c934f6d9a8ad1f9afe762986a9cf2074fc95d79'}, 'duration': 2.235443115234375, 'iteration': 13, 'loss': 0.11414635727249167, 'max_history_score': 0.9456356408262035, 'max_history_score_std': 0.040053650785990214, 'max_history_step': 'joint', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 1, 'features__selectkbest__k': 1}), 'normalizer': ('normalizer_RobustScaler', {'normalizer__quantile_range': (...), 'normalizer__with_centering': False, 'normalizer__with_scaling': True}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 6})}, 'score': 0.8858536427275083, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'gini', 'max_depth': 1, 'max_features': 1, 'max_leaf_nodes': None, 'min_samples_split': 5, 'n_estimators': 10}, 'config_hash': {'algorithm': '7d74a39aac2579264a402aef2b6fa7943c19f3d3', 'config': '53f44c0ad925c5c08c25d4fadf5e9ee9d7c181cd', 'pipeline': '6eff5ef31d7d1d534db31913bb67529c8a24c42e'}, 'duration': 2.7847659587860107, 'iteration': 14, 'loss': 0.14061986863711007, 'max_history_score': 0.9456356408262035, 'max_history_score_std': 0.040053650785990214, 'max_history_step': 'joint', 'pipeline': {'features': ('features_PCA', {'features__n_components': 1}), 'normalizer': ('normalizer_RobustScaler', {'normalizer__quantile_range': (...), 'normalizer__with_centering': True, 'normalizer__with_scaling': True}), 'rebalance': ('rebalance_CondensedNearestNeighbour', {'rebalance__n_neighbors': 3})}, 'score': 0.8593801313628899, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'entropy', 'max_depth': 3, 'max_features': None, 'max_leaf_nodes': 5, 'min_samples_split': 2, 'n_estimators': 100}, 'config_hash': {'algorithm': 'c62d7c671832e4414b6b2d7c36cba5ddc83a0ed0', 'config': '5faee50671eaa0ac586722bff234e36a857e662d', 'pipeline': '8b29a55de2add78c49114b9bbe5e800e5524c59d'}, 'duration': 2.3916029930114746, 'iteration': 15, 'loss': 0.08770093336790252, 'max_history_score': 0.9456356408262035, 'max_history_score_std': 0.040053650785990214, 'max_history_step': 'joint', 'pipeline': {'features': ('features_FeatureUnion', {'features__pca__n_components': 3, 'features__selectkbest__k': 4}), 'normalizer': ('normalizer_RobustScaler', {'normalizer__quantile_range': (...), 'normalizer__with_centering': True, 'normalizer__with_scaling': True}), 'rebalance': ('rebalance_NoneType', {})}, 'score': 0.9122990666320975, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': None, 'max_features': 1, 'max_leaf_nodes': 5, 'min_samples_split': 5, 'n_estimators': 10}, 'config_hash': {'algorithm': '290772bfb9b8ed15c48a72829e822fb0a07481d6', 'config': '9a04f25d8eb3db5b2f831abd341a6d384c73a957', 'pipeline': '1ce34b7894ef342571d974bb19e8ec821a512c6b'}, 'duration': 1.4364500045776367, 'iteration': 16, 'loss': 0.08948880822746508, 'max_history_score': 0.9456356408262035, 'max_history_score_std': 0.040053650785990214, 'max_history_step': 'joint', 'pipeline': {'features': ('features_PCA', {'features__n_components': 1}), 'normalizer': ('normalizer_PowerTransformer', {}), 'rebalance': ('rebalance_NoneType', {})}, 'score': 0.9105111917725349, ...}, {'algorithm': {'bootstrap': True, 'criterion': 'gini', 'max_depth': 2, 'max_features': 3, 'max_leaf_nodes': 3, 'min_samples_split': 3, 'n_estimators': 100}, 'config_hash': {'algorithm': '7dab6d47f897c2961d3402eff844aff16a7d142a', 'config': '4dbfa2688b239be9f372d3e80223960ba9a1fbdd', 'pipeline': 'cdef51702798fa49f11c11d80baf3ab43d5358fc'}, 'duration': 0.9830451011657715, 'iteration': 17, 'loss': 1.0, 'max_history_score': 0.9456356408262035, 'max_history_score_std': 0.040053650785990214, 'max_history_step': 'joint', 'pipeline': {'features': ('features_SelectKBest', {'features__k': 2}), 'normalizer': ('normalizer_PowerTransformer', {}), 'rebalance': ('rebalance_NearMiss', {'rebalance__n_neighbors': 1})}, 'score': 0.0, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'entropy', 'max_depth': None, 'max_features': 3, 'max_leaf_nodes': None, 'min_samples_split': 5, 'n_estimators': 10}, 'config_hash': {'algorithm': 'def83e48be05ef92a37e1a90585820f2f67ff42b', 'config': '95902552cb76e9798f0fa58782bd72bd1cc272d7', 'pipeline': '1775187bf23f94f4fd0cc1e5c1ef665210edded5'}, 'duration': 2.0033559799194336, 'iteration': 18, 'loss': 0.04922327370149515, 'max_history_score': 0.9507767262985048, 'max_history_score_std': 0.028328108925705902, 'max_history_step': 'joint', 'pipeline': {'features': ('features_PCA', {'features__n_components': 4}), 'normalizer': ('normalizer_StandardScaler', {'normalizer__with_mean': True, 'normalizer__with_std': True}), 'rebalance': ('rebalance_SMOTE', {'rebalance__k_neighbors': 5})}, 'score': 0.9507767262985048, ...}, {'algorithm': {'bootstrap': False, 'criterion': 'gini', 'max_depth': 1, 'max_features': 3, 'max_leaf_nodes': None, 'min_samples_split': 2, 'n_estimators': 50}, 'config_hash': {'algorithm': '4e9e3275f817df75115d9d7e3366980fc1b4cf13', 'config': '7770b19007b40bf13005d52eb81f87bc401f15b4', 'pipeline': 'c4dd111513ea35f97dd3aec3e8e7f6268ce035da'}, 'duration': 0.9069631099700928, 'iteration': 19, 'loss': 1.0, 'max_history_score': 0.9507767262985048, 'max_history_score_std': 0.028328108925705902, 'max_history_step': 'joint', 'pipeline': {'features': ('features_PCA', {'features__n_components': 2}), 'normalizer': ('normalizer_RobustScaler', {'normalizer__quantile_range': (...), 'normalizer__with_centering': False, 'normalizer__with_scaling': True}), 'rebalance': ('rebalance_NearMiss', {'rebalance__n_neighbors': 2})}, 'score': 0.0, ...}, ...], 'history_hash': ['51144ca42f9ea5ab2d8d58606e3b3e4d89c6d7b3', '9e54ffcb6a727de032a0a2cd45c5cc37cc150756', 'e5241eee9ddf3f4ee29a4711f5bcc92a4d24cd09', '18ee4d3d1627472ec190326308d8755371a6dc62', '2af4f82b045c0c48ecb89d42728d1039fbff8878', '17b2a1e5814f3e933137158708a5b6e9b2475495', 'fa020a592ec5ac234f9f91aac28abc2cd1ec9d33', '0da4498002d6f452c59bb61756abb3ded841e786', '344e4756fb1bec455d6af51d3727e33b0d27725f', '4a538fdcf8e07f90e92a421c0d5c479d651629c7', 'c1609e71f1ce8486335adc70bb69a955580ba2c8', 'abe36f188644e53e56ed3224236fa157107ed3b2', '76aa002c3c9d4d9722466c60daf5119c18a41d2a', 'f56a7a9e43a0a699e992dc1262e550b8b7c88538', '53f44c0ad925c5c08c25d4fadf5e9ee9d7c181cd', '5faee50671eaa0ac586722bff234e36a857e662d', '9a04f25d8eb3db5b2f831abd341a6d384c73a957', '4dbfa2688b239be9f372d3e80223960ba9a1fbdd', '95902552cb76e9798f0fa58782bd72bd1cc272d7', '7770b19007b40bf13005d52eb81f87bc401f15b4', ...], 'history_index': {'0212926e8a56cc42ae0a654a90c2a3ee92464265': 91, '0da4498002d6f452c59bb61756abb3ded841e786': 7, '0f77a69b0a8d34861caf915a51dc588ff8d4efac': 61, '127553d555ed39231b8da3a1ce42d3902e30919b': 59, '157ad7645c10c929b685db679adc21b38e285fff': 93, '17b2a1e5814f3e933137158708a5b6e9b2475495': 5, '18ee4d3d1627472ec190326308d8755371a6dc62': 3, '1b2267555a9226d7eb4df3c63dd12506da370f4d': 56, '278dd514f71ea681b3e2238dde3b16c35f1697db': 90, '2873878df7d4db8b415ff446bec08003e0c7488d': 92, ...}, 'iteration': 104, 'max_history_score': 0.9525008642295394, 'max_history_score_std': 0.02225295065716913, 'max_history_step': 'joint'}, config={'algorithm': 'RandomForest', 'seed': 42, 'time': 300}, step='joint')
     45                 y,
     46                 cv=10,
     47                 n_jobs=-1,
     48                 return_estimator=False,
     49                 return_train_score=False,
---> 50                 verbose=0)
     51         score = np.mean(scores['test_score'])
     52         std = np.std(scores['test_score'])
     53         status = STATUS_OK
     54     except Exception as e:

...........................................................................
/home/aquemy/.local/lib/python2.7/site-packages/sklearn/model_selection/_validation.py in cross_validate(estimator=Pipeline(memory=None,
     steps=[('rebalance', ... random_state=42, verbose=0, warm_start=False))]), X=array([[1.799e+01, 1.038e+01, 1.228e+02, ..., 2...., ..., 0.000e+00, 2.871e-01,
        7.039e-02]]), y=array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,... 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1]), groups=None, scoring=None, cv=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1, verbose=0, fit_params=None, pre_dispatch='2*n_jobs', return_train_score=False, return_estimator=False, error_score='raise-deprecating')
    235         delayed(_fit_and_score)(
    236             clone(estimator), X, y, scorers, train, test, verbose, None,
    237             fit_params, return_train_score=return_train_score,
    238             return_times=True, return_estimator=return_estimator,
    239             error_score=error_score)
--> 240         for train, test in cv.split(X, y, groups))
        cv.split = <bound method StratifiedKFold.split of Stratifie...d(n_splits=10, random_state=None, shuffle=False)>
        X = array([[1.799e+01, 1.038e+01, 1.228e+02, ..., 2...., ..., 0.000e+00, 2.871e-01,
        7.039e-02]])
        y = array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,... 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1])
        groups = None
    241 
    242     zipped_scores = list(zip(*scores))
    243     if return_train_score:
    244         train_scores = zipped_scores.pop(0)

...........................................................................
/home/aquemy/.local/lib/python2.7/site-packages/sklearn/externals/joblib/parallel.py in __call__(self=Parallel(n_jobs=-1), iterable=<generator object <genexpr>>)
    925                 # No need to wait for async callbacks to trigger to
    926                 # consumption.
    927                 self._iterating = False
    928 
    929             with self._backend.retrieval_context():
--> 930                 self.retrieve()
        self.retrieve = <bound method Parallel.retrieve of Parallel(n_jobs=-1)>
    931             # Make sure that we get a last message telling us we are done
    932             elapsed_time = time.time() - self._start_time
    933             self._print('Done %3i out of %3i | elapsed: %s finished',
    934                         (len(self._output), len(self._output),

---------------------------------------------------------------------------
Joblib worker traceback:
---------------------------------------------------------------------------
ValueError                                         Mon Jun 17 13:34:13 2019
PID: 26455                                  Python 2.7.15+: /usr/bin/python
...........................................................................
/home/aquemy/.local/lib/python2.7/site-packages/sklearn/externals/joblib/parallel.py in __call__(self=<sklearn.externals.joblib.parallel.BatchedCalls object>)
    220     def __call__(self):
    221         # Set the default nested backend to self._backend but do not set the
    222         # change the default number of processes to -1
    223         with parallel_backend(self._backend, n_jobs=self._n_jobs):
    224             return [func(*args, **kwargs)
--> 225                     for func, args, kwargs in self.items]
        func = <function _fit_and_score>
        args = (Pipeline(memory=None,
     steps=[('rebalance', ... random_state=42, verbose=0, warm_start=False))]), array([[1.799e+01, 1.038e+01, 1.228e+02, ..., 2...., ..., 0.000e+00, 2.871e-01,
        7.039e-02]]), array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,... 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1]), {'score': <function _passthrough_scorer>}, array([ 25,  26,  27,  28,  29,  30,  31,  32,  ..., 561, 562, 563, 564,
       565, 566, 567, 568]), array([  0,   1,   2,   3,   4,   5,   6,   7,  ...,  89,  90,
        92,  93,  96,  97,  98, 101]), 0, None, None)
        kwargs = {'error_score': 'raise-deprecating', 'return_estimator': False, 'return_times': True, 'return_train_score': False}
        self.items = [(<function _fit_and_score>, (Pipeline(memory=None,
     steps=[('rebalance', ... random_state=42, verbose=0, warm_start=False))]), array([[1.799e+01, 1.038e+01, 1.228e+02, ..., 2...., ..., 0.000e+00, 2.871e-01,
        7.039e-02]]), array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,... 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1]), {'score': <function _passthrough_scorer>}, array([ 25,  26,  27,  28,  29,  30,  31,  32,  ..., 561, 562, 563, 564,
       565, 566, 567, 568]), array([  0,   1,   2,   3,   4,   5,   6,   7,  ...,  89,  90,
        92,  93,  96,  97,  98, 101]), 0, None, None), {'error_score': 'raise-deprecating', 'return_estimator': False, 'return_times': True, 'return_train_score': False})]
    226 
    227     def __len__(self):
    228         return self._size
    229 

...........................................................................
/home/aquemy/.local/lib/python2.7/site-packages/sklearn/model_selection/_validation.py in _fit_and_score(estimator=Pipeline(memory=None,
     steps=[('rebalance', ... random_state=42, verbose=0, warm_start=False))]), X=array([[1.799e+01, 1.038e+01, 1.228e+02, ..., 2...., ..., 0.000e+00, 2.871e-01,
        7.039e-02]]), y=array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,... 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1]), scorer={'score': <function _passthrough_scorer>}, train=array([ 25,  26,  27,  28,  29,  30,  31,  32,  ..., 561, 562, 563, 564,
       565, 566, 567, 568]), test=array([  0,   1,   2,   3,   4,   5,   6,   7,  ...,  89,  90,
        92,  93,  96,  97,  98, 101]), verbose=0, parameters=None, fit_params={}, return_train_score=False, return_parameters=False, return_n_test_samples=False, return_times=True, return_estimator=False, error_score='raise-deprecating')
    523 
    524     try:
    525         if y_train is None:
    526             estimator.fit(X_train, **fit_params)
    527         else:
--> 528             estimator.fit(X_train, y_train, **fit_params)
        estimator.fit = <bound method Pipeline.fit of Pipeline(memory=No...random_state=42, verbose=0, warm_start=False))])>
        X_train = array([[1.714e+01, 1.640e+01, 1.160e+02, ..., 2...., ..., 0.000e+00, 2.871e-01,
        7.039e-02]])
        y_train = array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...1, 1, 1, 1, 1, 1, 1, 0, 0,
       0, 0, 0, 0, 1])
        fit_params = {}
    529 
    530     except Exception as e:
    531         # Note fit time as time until error
    532         fit_time = time.time() - start_time

...........................................................................
/usr/local/lib/python2.7/dist-packages/imblearn/pipeline.py in fit(self=Pipeline(memory=None,
     steps=[('rebalance', ... random_state=42, verbose=0, warm_start=False))]), X=array([[1.714e+01, 1.640e+01, 1.160e+02, ..., 2...., ..., 0.000e+00, 2.871e-01,
        7.039e-02]]), y=array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...1, 1, 1, 1, 1, 1, 1, 0, 0,
       0, 0, 0, 0, 1]), **fit_params={})
    234             This estimator
    235 
    236         """
    237         Xt, yt, fit_params = self._fit(X, y, **fit_params)
    238         if self._final_estimator is not None:
--> 239             self._final_estimator.fit(Xt, yt, **fit_params)
        self._final_estimator.fit = <bound method RandomForestClassifier.fit of Rand...   random_state=42, verbose=0, warm_start=False)>
        Xt = array([[ 511.77661626,  -83.00917472],
       [-...1400763],
       [ 137.57589321,  169.53026541]])
        yt = array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
       0, 0, 0, 0])
        fit_params = {}
    240         return self
    241 
    242     def fit_transform(self, X, y=None, **fit_params):
    243         """Fit the model and transform with the final estimator

...........................................................................
/home/aquemy/.local/lib/python2.7/site-packages/sklearn/ensemble/forest.py in fit(self=RandomForestClassifier(bootstrap=False, class_we...    random_state=42, verbose=0, warm_start=False), X=array([[ 511.7766  ,  -83.00918 ],
       [-114....      [ 137.5759  ,  169.53026 ]], dtype=float32), y=array([[0.],
       [0.],
       [0.],
       [0...    [0.],
       [0.],
       [0.],
       [0.]]), sample_weight=None)
    328             trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,
    329                              **_joblib_parallel_args(prefer='threads'))(
    330                 delayed(_parallel_build_trees)(
    331                     t, self, X, y, sample_weight, i, len(trees),
    332                     verbose=self.verbose, class_weight=self.class_weight)
--> 333                 for i, t in enumerate(trees))
        i = 99
    334 
    335             # Collect newly grown trees
    336             self.estimators_.extend(trees)
    337 

...........................................................................
/home/aquemy/.local/lib/python2.7/site-packages/sklearn/externals/joblib/parallel.py in __call__(self=Parallel(n_jobs=1), iterable=<generator object <genexpr>>)
    912             # self._original_iterator is None, then this means either
    913             # that pre_dispatch == "all", n_jobs == 1 or that the first batch
    914             # was very quick and its callback already dispatched all the
    915             # remaining jobs.
    916             self._iterating = False
--> 917             if self.dispatch_one_batch(iterator):
        self.dispatch_one_batch = <bound method Parallel.dispatch_one_batch of Parallel(n_jobs=1)>
        iterator = <generator object <genexpr>>
    918                 self._iterating = self._original_iterator is not None
    919 
    920             while self.dispatch_one_batch(iterator):
    921                 pass

...........................................................................
/home/aquemy/.local/lib/python2.7/site-packages/sklearn/externals/joblib/parallel.py in dispatch_one_batch(self=Parallel(n_jobs=1), iterator=<generator object <genexpr>>)
    754                                  self._pickle_cache)
    755             if len(tasks) == 0:
    756                 # No more tasks available in the iterator: tell caller to stop.
    757                 return False
    758             else:
--> 759                 self._dispatch(tasks)
        self._dispatch = <bound method Parallel._dispatch of Parallel(n_jobs=1)>
        tasks = <sklearn.externals.joblib.parallel.BatchedCalls object>
    760                 return True
    761 
    762     def _print(self, msg, msg_args):
    763         """Display the message on stout or stderr depending on verbosity"""

...........................................................................
/home/aquemy/.local/lib/python2.7/site-packages/sklearn/externals/joblib/parallel.py in _dispatch(self=Parallel(n_jobs=1), batch=<sklearn.externals.joblib.parallel.BatchedCalls object>)
    711 
    712         dispatch_timestamp = time.time()
    713         cb = BatchCompletionCallBack(dispatch_timestamp, len(batch), self)
    714         with self._lock:
    715             job_idx = len(self._jobs)
--> 716             job = self._backend.apply_async(batch, callback=cb)
        job = undefined
        self._backend.apply_async = <bound method SequentialBackend.apply_async of <...lib._parallel_backends.SequentialBackend object>>
        batch = <sklearn.externals.joblib.parallel.BatchedCalls object>
        cb = <sklearn.externals.joblib.parallel.BatchCompletionCallBack object>
    717             # A job can complete so quickly than its callback is
    718             # called before we get here, causing self._jobs to
    719             # grow. To ensure correct results ordering, .insert is
    720             # used (rather than .append) in the following line

...........................................................................
/home/aquemy/.local/lib/python2.7/site-packages/sklearn/externals/joblib/_parallel_backends.py in apply_async(self=<sklearn.externals.joblib._parallel_backends.SequentialBackend object>, func=<sklearn.externals.joblib.parallel.BatchedCalls object>, callback=<sklearn.externals.joblib.parallel.BatchCompletionCallBack object>)
    177             raise ValueError('n_jobs == 0 in Parallel has no meaning')
    178         return 1
    179 
    180     def apply_async(self, func, callback=None):
    181         """Schedule a func to be run"""
--> 182         result = ImmediateResult(func)
        result = undefined
        func = <sklearn.externals.joblib.parallel.BatchedCalls object>
    183         if callback:
    184             callback(result)
    185         return result
    186 

...........................................................................
/home/aquemy/.local/lib/python2.7/site-packages/sklearn/externals/joblib/_parallel_backends.py in __init__(self=<sklearn.externals.joblib._parallel_backends.ImmediateResult object>, batch=<sklearn.externals.joblib.parallel.BatchedCalls object>)
    544 
    545 class ImmediateResult(object):
    546     def __init__(self, batch):
    547         # Don't delay the application, to avoid keeping the input
    548         # arguments in memory
--> 549         self.results = batch()
        self.results = undefined
        batch = <sklearn.externals.joblib.parallel.BatchedCalls object>
    550 
    551     def get(self):
    552         return self.results
    553 

...........................................................................
/home/aquemy/.local/lib/python2.7/site-packages/sklearn/externals/joblib/parallel.py in __call__(self=<sklearn.externals.joblib.parallel.BatchedCalls object>)
    220     def __call__(self):
    221         # Set the default nested backend to self._backend but do not set the
    222         # change the default number of processes to -1
    223         with parallel_backend(self._backend, n_jobs=self._n_jobs):
    224             return [func(*args, **kwargs)
--> 225                     for func, args, kwargs in self.items]
        func = <function _parallel_build_trees>
        args = (DecisionTreeClassifier(class_weight=None, criter...=False, random_state=1608637542, splitter='best'), RandomForestClassifier(bootstrap=False, class_we...    random_state=42, verbose=0, warm_start=False), array([[ 511.7766  ,  -83.00918 ],
       [-114....      [ 137.5759  ,  169.53026 ]], dtype=float32), array([[0.],
       [0.],
       [0.],
       [0...    [0.],
       [0.],
       [0.],
       [0.]]), None, 0, 100)
        kwargs = {'class_weight': None, 'verbose': 0}
        self.items = [(<function _parallel_build_trees>, (DecisionTreeClassifier(class_weight=None, criter...=False, random_state=1608637542, splitter='best'), RandomForestClassifier(bootstrap=False, class_we...    random_state=42, verbose=0, warm_start=False), array([[ 511.7766  ,  -83.00918 ],
       [-114....      [ 137.5759  ,  169.53026 ]], dtype=float32), array([[0.],
       [0.],
       [0.],
       [0...    [0.],
       [0.],
       [0.],
       [0.]]), None, 0, 100), {'class_weight': None, 'verbose': 0})]
    226 
    227     def __len__(self):
    228         return self._size
    229 

...........................................................................
/home/aquemy/.local/lib/python2.7/site-packages/sklearn/ensemble/forest.py in _parallel_build_trees(tree=DecisionTreeClassifier(class_weight=None, criter...=False, random_state=1608637542, splitter='best'), forest=RandomForestClassifier(bootstrap=False, class_we...    random_state=42, verbose=0, warm_start=False), X=array([[ 511.7766  ,  -83.00918 ],
       [-114....      [ 137.5759  ,  169.53026 ]], dtype=float32), y=array([[0.],
       [0.],
       [0.],
       [0...    [0.],
       [0.],
       [0.],
       [0.]]), sample_weight=None, tree_idx=0, n_trees=100, verbose=0, class_weight=None)
    116         elif class_weight == 'balanced_subsample':
    117             curr_sample_weight *= compute_sample_weight('balanced', y, indices)
    118 
    119         tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)
    120     else:
--> 121         tree.fit(X, y, sample_weight=sample_weight, check_input=False)
        tree.fit = <bound method DecisionTreeClassifier.fit of Deci...False, random_state=1608637542, splitter='best')>
        X = array([[ 511.7766  ,  -83.00918 ],
       [-114....      [ 137.5759  ,  169.53026 ]], dtype=float32)
        y = array([[0.],
       [0.],
       [0.],
       [0...    [0.],
       [0.],
       [0.],
       [0.]])
        sample_weight = None
    122 
    123     return tree
    124 
    125 

...........................................................................
/home/aquemy/.local/lib/python2.7/site-packages/sklearn/tree/tree.py in fit(self=DecisionTreeClassifier(class_weight=None, criter...=False, random_state=1608637542, splitter='best'), X=array([[ 511.7766  ,  -83.00918 ],
       [-114....      [ 137.5759  ,  169.53026 ]], dtype=float32), y=array([[0.],
       [0.],
       [0.],
       [0...    [0.],
       [0.],
       [0.],
       [0.]]), sample_weight=None, check_input=False, X_idx_sorted=None)
    796 
    797         super(DecisionTreeClassifier, self).fit(
    798             X, y,
    799             sample_weight=sample_weight,
    800             check_input=check_input,
--> 801             X_idx_sorted=X_idx_sorted)
        X_idx_sorted = None
    802         return self
    803 
    804     def predict_proba(self, X, check_input=True):
    805         """Predict class probabilities of the input samples X.

...........................................................................
/home/aquemy/.local/lib/python2.7/site-packages/sklearn/tree/tree.py in fit(self=DecisionTreeClassifier(class_weight=None, criter...=False, random_state=1608637542, splitter='best'), X=array([[ 511.7766  ,  -83.00918 ],
       [-114....      [ 137.5759  ,  169.53026 ]], dtype=float32), y=array([[0.],
       [0.],
       [0.],
       [0...    [0.],
       [0.],
       [0.],
       [0.]]), sample_weight=None, check_input=False, X_idx_sorted=None)
    237         if not 0 <= self.min_weight_fraction_leaf <= 0.5:
    238             raise ValueError("min_weight_fraction_leaf must in [0, 0.5]")
    239         if max_depth <= 0:
    240             raise ValueError("max_depth must be greater than zero. ")
    241         if not (0 < max_features <= self.n_features_):
--> 242             raise ValueError("max_features must be in (0, n_features]")
    243         if not isinstance(max_leaf_nodes, (numbers.Integral, np.integer)):
    244             raise ValueError("max_leaf_nodes must be integral number but was "
    245                              "%r" % max_leaf_nodes)
    246         if -1 < max_leaf_nodes < 2:

ValueError: max_features must be in (0, n_features]
___________________________________________________________________________
Best score: 0.95250086423 (0.0222529506572) [J] | Score: 0.0 (0.0) [J]
Best score: 0.95250086423 (0.0222529506572) [J] | Score: 0.901705773053 (0.0389476899511) [J]
Best score: 0.95250086423 (0.0222529506572) [J] | Score: 0.941851395731 (0.0251761548167) [J]
Best score: 0.95250086423 (0.0222529506572) [J] | Score: 0.935294054101 (0.0326138397164) [J]
Best score: 0.957888255121 (0.0223317684306) [J] | Score: 0.957888255121 (0.0223317684306) [J]
Best score: 0.957888255121 (0.0223317684306) [J] | Score: 0.929875334889 (0.0228624708235) [J]
Best score: 0.957888255121 (0.0223317684306) [J] | Score: 0.940432978999 (0.0288740498871) [J]
Best score: 0.957888255121 (0.0223317684306) [J] | Score: 0.416377149771 (0.0431444514643) [J]
Best score: 0.957888255121 (0.0223317684306) [J] | Score: 0.942188445251 (0.0229029771972) [J]
Best score: 0.957888255121 (0.0223317684306) [J] | Score: 0.938709921355 (0.0256300568002) [J]
Best score: 0.957888255121 (0.0223317684306) [J] | Score: 0.956225693544 (0.0246238983722) [J]
Best score: 0.957888255121 (0.0223317684306) [J] | Score: 0.952716921614 (0.0188336743071) [J]
Best score: 0.957888255121 (0.0223317684306) [J] | Score: 0.952716921614 (0.0188336743071) [J]
Best score: 0.957888255121 (0.0223317684306) [J] | Score: 0.947514259787 (0.0254505297205) [J]
Best score: 0.957888255121 (0.0223317684306) [J] | Score: 0.949238397718 (0.0209621361411) [J]
Best score: 0.957888255121 (0.0223317684306) [J] | Score: 0.952716921614 (0.0188336743071) [J]
Best score: 0.957888255121 (0.0223317684306) [J] | Score: 0.952685593294 (0.0189020892327) [J]
Best score: 0.957888255121 (0.0223317684306) [J] | Score: 0.949238397718 (0.0248526962352) [J]
Best score: 0.957888255121 (0.0223317684306) [J] | Score: 0.947452683433 (0.0243436865212) [J]
Best score: 0.957888255121 (0.0223317684306) [J] | Score: 0.929968239564 (0.0264542200945) [J]
Best score: 0.957888255121 (0.0223317684306) [J] | Score: 0.93695553539 (0.0256598652035) [J]
Best score: 0.957888255121 (0.0223317684306) [J] | Score: 0.898197001123 (0.048502101752) [J]
Best score: 0.957888255121 (0.0223317684306) [J] | Score: 0.942188445251 (0.0266727703709) [J]
Best score: 0.957888255121 (0.0223317684306) [J] | Score: 0.938679673321 (0.023363626851) [J]
Best score: 0.957888255121 (0.0223317684306) [J] | Score: 0.75446050471 (0.120932644961) [J]
Best score: 0.957888255121 (0.0223317684306) [J] | Score: 0.943942831216 (0.0315122297246) [J]
Best score: 0.957888255121 (0.0223317684306) [J] | Score: 0.928119868637 (0.0259195827728) [J]
Best score: 0.957888255121 (0.0223317684306) [J] | Score: 0.93341543514 (0.0384312817112) [J]
Best score: 0.957888255121 (0.0223317684306) [J] | Score: 0.80239175525 (0.140282685209) [J]
Best score: 0.957888255121 (0.0223317684306) [J] | Score: 0.931536816178 (0.0224337613163) [J]
Best score: 0.957888255121 (0.0223317684306) [J] | Score: 0.935168740818 (0.0241550156313) [J]
Best score: 0.957888255121 (0.0223317684306) [J] | Score: 0.936862630715 (0.0189599312751) [J]
Best score: 0.957888255121 (0.0223317684306) [J] | Score: 0.952654264973 (0.0289432387382) [J]
Best score: 0.957888255121 (0.0223317684306) [J] | Score: 0.93344676346 (0.0296078130061) [J]
Best score: 0.957888255121 (0.0223317684306) [J] | Score: 0.950992783683 (0.0240257906691) [J]
Best score: 0.957888255121 (0.0223317684306) [J] | Score: 0.931567064212 (0.0250030923413) [J]
Best score: 0.957888255121 (0.0223317684306) [J] | Score: 0.949237317432 (0.0311164950034) [J]
Best score: 0.966815746262 (0.0273903070753) [J] | Score: 0.966815746262 (0.0273903070753) [J]
Best score: 0.966815746262 (0.0273903070753) [J] | Score: 0.938678593034 (0.0319648073723) [J]
Best score: 0.966815746262 (0.0273903070753) [J] | Score: 0.901613948665 (0.0352711537378) [J]
Best score: 0.966815746262 (0.0273903070753) [J] | Score: 0.961521260047 (0.0317782077311) [J]
Best score: 0.970264022124 (0.0290873007591) [J] | Score: 0.970264022124 (0.0290873007591) [J]
Best score: 0.970264022124 (0.0290873007591) [J] | Score: 0.964938207588 (0.0301656378192) [J]
Best score: 0.970264022124 (0.0290873007591) [J] | Score: 0.95616411719 (0.0208179911109) [J]
Best score: 0.970264022124 (0.0290873007591) [J] | Score: 0.931659968888 (0.0332883022755) [J]
Best score: 0.970264022124 (0.0290873007591) [J] | Score: 0.910355630455 (0.0317590105163) [J]
Best score: 0.970264022124 (0.0290873007591) [J] | Score: 0.961429435658 (0.0300302752649) [J]
Best score: 0.970264022124 (0.0290873007591) [J] | Score: 0.933321450177 (0.0286531936515) [J]
Best score: 0.970264022124 (0.0290873007591) [J] | Score: 0.889300838303 (0.0486314562905) [J]
Best score: 0.970264022124 (0.0290873007591) [J] | Score: 0.933322530464 (0.0228337897941) [J]
Best score: 0.970264022124 (0.0290873007591) [J] | Score: 0.961398107337 (0.0278102990556) [J]
Best score: 0.970264022124 (0.0290873007591) [J] | Score: 0.87529167747 (0.0499928998607) [J]
Best score: 0.970264022124 (0.0290873007591) [J] | Score: 0.957949831475 (0.0269982511622) [J]
Best score: 0.970264022124 (0.0290873007591) [J] | Score: 0.919286362458 (0.0291501478713) [J]
Best score: 0.970264022124 (0.0290873007591) [J] | Score: 0.936832382681 (0.0365178431803) [J]
Best score: 0.970264022124 (0.0290873007591) [J] | Score: 0.91756114424 (0.0405680638693) [J]
Best score: 0.970264022124 (0.0290873007591) [J] | Score: 0.936893959036 (0.0245406078294) [J]
Best score: 0.970264022124 (0.0290873007591) [J] | Score: 0.968448059805 (0.024365505075) [J]
Best score: 0.970264022124 (0.0290873007591) [J] | Score: 0.936862630715 (0.0329173353695) [J]
Best score: 0.970264022124 (0.0290873007591) [J] | Score: 0.901645276986 (0.0386696056256) [J]
Best score: 0.970264022124 (0.0290873007591) [J] | Score: 0.935139573071 (0.0300900812993) [J]
Best score: 0.970264022124 (0.0290873007591) [J] | Score: 0.906849019099 (0.0402167708939) [J]
Best score: 0.970264022124 (0.0290873007591) [J] | Score: 0.915683605566 (0.0374435330264) [J]
Best score: 0.970264022124 (0.0290873007591) [J] | Score: 0.929813758534 (0.0231001650905) [J]
Best score: 0.970264022124 (0.0290873007591) [J] | Score: 0.957919583441 (0.0235215350296) [J]
Best score: 0.970264022124 (0.0290873007591) [J] | Score: 0.963152493302 (0.023816263106) [J]
Best score: 0.970264022124 (0.0290873007591) [J] | Score: 0.943879094287 (0.0344434905752) [J]
Best score: 0.970264022124 (0.0290873007591) [J] | Score: 0.950836142079 (0.0255609624627) [J]
Best score: 0.970264022124 (0.0290873007591) [J] | Score: 0.887454627949 (0.0403100945657) [J]
#################### STEP RESULT ####################
BEST PIPELINE:
 {
    "features": [
        "features_NoneType", 
        {}
    ], 
    "normalizer": [
        "normalizer_PowerTransformer", 
        {}
    ], 
    "rebalance": [
        "rebalance_SMOTE", 
        {
            "rebalance__k_neighbors": 6
        }
    ]
}
BEST ALGO CONFIG:
 {
    "bootstrap": true, 
    "criterion": "entropy", 
    "max_depth": null, 
    "max_features": null, 
    "max_leaf_nodes": null, 
    "min_samples_split": 5, 
    "n_estimators": 75
}
BEST SCORE: 0.970264022124 (0.0290873007591)
##################################################
